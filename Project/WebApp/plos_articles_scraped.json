[
  {
    "title": "The impact of economic growth target management on urban green land utilization efficiency",
    "authors": "Yu Wang, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0321779",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321779",
    "content": "Improving urban green land utilization efficiency (UGLUE) is the key to promoting green and sustainable development in China. Clarifying the impact of economic growth target management (EGTM) on UGLUE and its mechanism of action is of great significance to improving UGLUE. Selecting 273 cities in China from 2010 to 2021 as the research sample, this paper uses panel data model, and spatial Durbin model (SDM) to empirically examine the impact, transmission mechanism and spatial spillover effect of EGTM (including economic growth target values, hard constraints and soft constraints of economic growth targets) on UGLUE. In addition, this paper uses panel threshold model to verify the threshold role of environmental regulation in the relationship between EGTM and UGLUE. The research found that: (1) Local economic growth target value and its hard constraints have a negative impact on UGLUE, while soft constraints are conducive to improving UGLUE. (2) Green technology innovation and industrial structure upgrading are the main transmission channels. (3) As the intensity of environmental regulation increases, the negative impact of economic growth target value and its hard constraints on UGLUE weakens, while the positive impact of its soft constraints on UGLUE strengthens. (4) The economic growth target value and its hard constraints of surrounding areas can reduce the UGLUE in the region, while its soft constraints can improve the UGLUE in the region. (5) Economic growth targets have the greatest negative impact on UGLUE in the central region and resource-based cities. In the future, the importance of GDP growth rate in official performance evaluations should be reduced. More flexible “soft constraints” should be used to set economic growth targets.\n\nCitation:Wang Y (2025) The impact of economic growth target management on urban green land utilization efficiency. PLoS ONE 20(4):\n           e0321779.\n        \n        https://doi.org/10.1371/journal.pone.0321779\n\nEditor:Qingsong He, Huazhong University of Science and Technology, CHINA\n\nReceived:November 27, 2024;Accepted:March 11, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Yu Wang. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the article and itssupporting informationfiles.\n\nFunding:This study was supported by the Harbin University of Commerce Doctoral Research Support Program (24BQ20).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nWith the continuous advancement of industrialization and urbanization, the area of urban construction land in China has expanded rapidly [1]. Statistical data show that from 2006 to 2020, the area of urban construction land in China has increased from 31765.70 km2to 58355.3 km2, with an average annual growth rate of 4.44% [2]. The rapid expansion of urban construction land has led to issues such as economic stagnation, a shortage of arable land, and environmental pollution, which contradict the strategy of promoting sustainable development [3]. In order to control the expansion speed of urban construction land, China has introduced a strict land use system, requiring local governments not to exceed the scale of urban construction land without authorization. How to increase economic output and promote sustainable development in China with limited land resources is an urgent problem to be solved in various regions. UGLUE refers to the maximization of economic, social and ecological benefits with the lowest input of land factors [4]. It embodies the core concept of sustainable development [5], that is, the sustainable unity of economy, society and environment. Only by improving UGLUE and promoting the sustainable use of land, can sustainable development be truly realized.\n\nIn the past, scholars have explored ways to improve UGLUE from the perspectives of economic factors [6], social factors [7], industrial factors [8], and technological factors [9]. In recent years, scholars have shifted their research perspective to policy factors at the macroeconomic level and began to pay attention to their impact on UGLUE [10]. However, no research has yet incorporated the policy factor of EGTM into the analytical framework of UGLUE. EGTM refers to the higher-level government incentivizing winning the promotion tournament by setting relevant targets [11]. To win the “promotion tournament”, local government officials set more aggressive local economic growth targets based on the economic growth targets set by central government. To achieve this goal, local governments allocate resources to areas that can quickly achieve economic growth goals [12]. This leads to a large number of urban land being used inefficiently, thus affecting UGLUE. Based on this, what is the impact of EGTM on UGLUE? What is its mechanism of action? Answering these questions not only provides new clues for understanding the extensive use of urban land caused by the acceleration of economic growth, but also provides policy implications for improving the government’s EGTM system.\n\nBased on this, this paper innovatively incorporates EGTM and UGLUE into the same analytical framework. Based on theoretical analysis, this paper uses panel data of 273 cities in China from 2010 to 2021, panel regression model, mediation effect model and SDM to empirically analyze the direct impact, mediation effect and spatial spillover effect of EGTM on UGLUE. Using the panel threshold model to test the threshold effect of environmental regulation in the relationship between the two. The results show that: (1) The improvement of local economic growth goals and the adoption of hard constraints have a negative impact on UGLUE, while the soft constraints are conducive to improving UGLUE. Its transmission channels are green technology innovation and industrial structure upgrading. (2) With the increase of environmental regulation intensity, the negative impact of economic growth target and its hard constraints on UGLUE is weakened. The positive impact of soft constraints on UGLUE is enhanced. (3) EGTM has a positive spatial spillover effect.\n\nThe marginal contribution of this paper lies in: First, in terms of research perspective, previous studies have studied the influencing factors of UGLUE from the perspectives of economic agglomeration, facility construction, technological innovation, lacking attention to the effect of EGTM. From the perspective of EGTM, this paper examines the impact of EGTM on UGLUE and its mechanism of action for the first time, broadening the research boundary of land use. Second, in terms of research methods, the existing studies on EGTM use ordinary panel regression models that do not consider spatial spillover effects for empirical analysis. However, in fact, the local government’s economic growth target setting has the benchmarking competition characteristics of mutual reference imitation between cities. This paper introduces the SDM to explore the spatial spillover effect of EGTM on UGLUE, which helps to better understand the interaction strategy of target management between regions. Third, in terms of research samples, most of the existing studies on EGTM remain at a single level such as national, inter-provincial, typical cities and specific industries. There are few studies on the overall cities. Considering the fierce competition between different prefecture-level cities in the same province, this paper takes EGTM specific to the city level. Taking 273 cities in China as research samples to examine the impact of local government behavior on UGLUE in more detail.\n\nUGLUE refers to maximizing land economic output at the cost of minimizing ecological and environmental losses under the constraints of urban land resources[13]. Related research mainly includes two aspects: The measurement and influencing factors of UGLUE. First, the measurement of UGLUE. The measurement subjects mainly include provinces [14], cities [15] and extensions. The measurement method has transitioned from a single indicator measurement method [16] to a multi-indicator comprehensive measurement method [17]. Since the measurement of UGLUE is not limited to economic results, but also covers social, ecological and other indicators, scholars use a multi-indicator comprehensive measurement method to measure UGLUE. Some scholars used stochastic frontier analysis (SFA) to measure UGLUE [14]. However, since SFA requires a specific form and the assumptions are too strict, it has certain limitations in measuring UGLUE. Therefore, some scholars began to use data envelopment analysis (DEA) to measure UGLUE [18–22]. Second, the factors affecting UGLUE. The factors affecting UGLUE can be divided into two categories: Internal resources and external environment. Internal resources mainly include transportation infrastructure [23], industrial structure [24], urban structure [25], intelligence level [26], etc. These factors come from the inherent development conditions of city. The external environment mainly includes land transfer [27], land finance [28], policy pilot [29], and environmental regulation [30,31]. These factors come from the government’s institutional arrangements. However, no research has focused on the relationship between the institutional arrangement factor of EGTM and UGLUE.\n\nEGTM serves as a crucial instrument for fostering swift economic expansion across various nations. At present, research on the policy effects of EGTM mainly focuses on its impact on economic growth [32], government spending [33], environmental pollution [34], energy consumption [35], and technological innovation [36]. No research has shifted its perspective to land and explored the impact of economic growth targets on UGLUE. In terms of research methods, scholars mainly use the least squares method (OLS) [37], the iterative three-stage least squares method (3SLS) [38], and the fixed effect model [39] to empirically analyze the policy effectiveness of economic growth targets. The horizontal competition phenomenon of local governments in setting economic growth targets is not fully considered. In terms of sample selection, the research on economic growth targets mainly stays at the single level of countries [33], provinces [32], and specific industries [40]. There are few studies on the city as a whole, which ignores the fierce competition between different prefecture-level cities and the heterogeneous role of economic growth targets in the process of changing land use patterns.\n\nPublic choice theory suggests that government officials are ‘rational economic men’ who not only aim to maximize social welfare when making policy decisions but also pursue their own interests [41]. Under China’s’ promotion tournament’ model, which uses GDP as an assessment indicator, the EGTM system serves as a significant tool for local governments to enhance economic growth within their respective areas [42]. In order to maximize their own political interests during their term, local government officials often set economic growth targets that deviate from actual conditions, thereby hindering the improvement of UGLUE (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.g001\n\nThe impact of local EGTM on UGLUE is specifically reflected in the following two aspects: First, the crowding-out effect of policy input tools. In the context of fiscal decentralization, local governments need to achieve their economic growth targets through various policy tools (such as tax tools, expenditure tools, and environmental governance tools). Although these tools can help local governments achieve their economic growth targets in the short term, they also lead to an imbalance in the allocation of local fiscal resources, which is not conducive to improving UGLUE. Regarding local fiscal revenue and environmental governance expenditure, when local governments take measures such as reducing tax rates or providing tax incentives to stimulate economic growth, their fiscal revenue may decrease in the short term. The limited fiscal resources lead to cuts in investment in green infrastructure and environmental protection projects. Concerning the imbalance in resource allocation, when local governments set excessively high economic growth targets, they tend to prioritize the use of land for industrial development and infrastructure projects over ecological initiatives like parks and green spaces [43]. This biased land use can reduce environmental quality. Second, the structural effect of fiscal resource investment. Local governments tilt resources to support productive projects with short cycles and quick results, while ignoring innovative investments with long cycles and slow results. An investment structure that “emphasizes production and neglects innovation” has been formed, which aggravates environmental pressure. In addition, as a large amount of financial resources flow into traditional industries, fiscal expenditures for environmental protection are squeezed out. Effective control of environmental pollution and ecological restoration work are difficult to carry out, thereby reducing UGLUE.\n\nIn their annual government work reports, local governments typically establish specific economic growth targets, often accompanied by adverbs indicating varying levels of intensity. For example, expressions such as “strive to” and “ensure” reflect hard constraints, indicating that local governments are more committed to achieving these targets. Local governments take short-term economic measures to quickly achieve economic growth targets, which reduces UGLUE by squeezing out funds for environmental protection projects. The use of “left and right” and “up and down” reflects the soft constraints characteristics, providing more flexibility for the realization of economic growth targets. While pursuing economic growth, local governments can also consider improving environmental quality [44], thereby improving UGLUE. Specifically, local governments do not have to rely too much on short-term economic measures to achieve their goals quickly. On the contrary, local governments are able to invest part of their resources in green infrastructure and environmental projects that are critical to improving UGLUE [45]. In addition, local governments have more autonomy to optimize the allocation of financial resources. By increasing investment in innovative and livelihood projects and optimizing the investment structure, they can enhance the ecological value of land resources. The following hypothesis is proposed:\n\nThe setting of economic growth target value and its hard constraints have a “crowding-out effect” on the R&D investment in green technologies, thereby inhibiting green technology innovation. From the perspective of corporate financing, under the pressure of economic growth targets, the government allocates a substantial quantity of economic resources to infrastructure construction [35]. As the available funds in the market decrease, financial institutions raise interest rates to balance the supply and demand for funds. The financing costs of enterprises increase. Since R&D activities are characterized by high investment, long cycle and high risk, they put tremendous pressure on corporate cash flow [46]. Compared with long-term R&D investment, companies may be more inclined to invest in short-term projects. In addition, firms with high debt are more likely to cut R&D spending when funding is tight to reduce risks [47]. From the perspective of private investment, local governments provide robust support for the real estate industry, leading to an increase in housing prices. Driven by high profits, companies have a strong arbitrage motivation. They withdraw their own capital from green technology development and invest it in the real estate market [48]. Innovation funds are squeezed, hindering green tech innovation.\n\nIn the context of China’s economic transformation, the central government advocates slowing down the pace of economic growth and focusing on the quality of economic growth. Some regions begin to set soft constraints on economic growth targets. Soft constraints make the government no longer blindly pursue economic growth and scale, but take into account the protection of environment. Green innovation is important for environmental protection [49]. Local governments invest financial resources in the field of green innovation through financial subsidies, tax incentives, technical support and other measures. Enterprises are encouraged to carry out green technology innovation activities. This incentive effect can promote cooperation between enterprises. Through resource sharing, experience exchange and collaborative R&D, enterprises can achieve complementary advantages and jointly cope with the challenges in the process of green technology innovation.\n\nTechnological innovation theory holds that innovation is an important driving force for endogenous economic growth [50]. Green technology innovation can reduce fossil energy consumption and increase the use of clean energy in the front-end production process [51]. Improve the degree of pollutant purification from the end-of-pipe treatment and reduce pollutant emissions. In the process of land use, both economic and environmental benefits can achieve synergistic growth, thereby improving UGLUE. The following hypothesis is proposed:\n\nEconomic growth targets value and its hard constraints hinder industrial upgrading via state-owned monopolies and infrastructure. Regarding the monopoly of the state-owned economy, local governments excessively allocate production factors such as capital and land toward state-owned enterprises that lack the motivation for innovation [52]. Emerging and green industries cannot develop due to lack of financial and policy support. The pace of upgrading the entire industrial structure slows down. Regarding infrastructure construction, the government invests funds in “short-cycle, low-risk” infrastructure construction, driving the expansion of manufacturing industries such as steel and cement that already have overcapacity problems. The upgrading of traditional extensive industries is inhibited.\n\nWhen the economic growth target setting changes from “hard constraints” to “soft constraints”, the government considers environmental protection. The economic growth mode changes from factor-driven to innovation-driven, which is conducive to industrial upgrading. Specifically, the government encourages enterprises to carry out green production through a series of incentives, such as tax incentives, financial support and technological innovation incentives. The traditional industry is gradually transforming to the intelligent and green direction. Meanwhile, the government also strengthens the supervision of high pollution and high emission industries. By raising environmental standards and strengthening law enforcement, these industries are forced to carry out technological transformation or gradually withdraw from the market. Environmental protection industry has a huge space for development.\n\nThe upgrading of industrial structure has a “structural dividend” effect [53]. It can promote the concentration of low-pollution industries in the city center and the relocation of traditional high-pollution industries to the peripher. The economic and environmental benefits of urban land achieve coordinated development. The following hypothesis is proposed:\n\nEnvironmental regulation plays a key role in the impact of local EGTM on UGLUE. When the intensity of environmental regulation is low, local governments prioritize economic growth and focus on the economic benefits of land while ignoring their environmental benefits. In allocating resources, local governments invest more, local governments invest more resources in high-pollution areas that can rapidly promote economic growth and reduce UGLUE. As the intensity of environmental regulation increases, the government’s short-term economic behavior is constrained by environmental regulation. The negative impact of economic growth targets on UGLUE is weakened. From the government’s perspective, when the intensity of environmental regulation is high, the government sets up environmental barriers for enterprises when attracting investment. Highly polluting and high-emission industrial enterprises are prohibited from entering [54]. In addition, local governments also implement tax incentives and financial subsidies for low-pollution, high-output enterprises. These preferential policies can motivate enterprises to boost their investment in green production. From the perspective of enterprises, stronger environmental regulations produce the “Porter effect” [55], prompting enterprises to innovate clean technologies. The green land use pattern is formed. Hypothesis 4 is proposed:\n\nHigher-level governments struggle to set clear, objective criteria for evaluating local governments. As a result, local governments are allowed to compete independently and the winners are selected by comparing the competition results. A top-down benchmarking competition assessment model is formed [56]. In this model, local governments respond strategically to the economic growth targets of governments at the same level. A race for economic growth targets is formed among local governments [57].\n\nFaced with tremendous pressure for economic growth, local governments are forced to adopt a series of radical policies to stimulate economic growth. They invest financial resources in infrastructure construction and traditional industrial projects, marginalizing ecological projects such as green infrastructure and parks. In addition, the misallocation of financial resources also makes it difficult to carry out ecological restoration work, thereby reducing the UGLUE of local region. Hypothesis 5 is proposed:\n\nThe following model is constructed in this study:\n\nAmong them,UGLUEitrepresents the green utilization efficiency of urban land in cityiin yeart.EGTMitrepresents the economic growth target management of cityiin yeart, including economic growth target value, hard constraints and soft constraints.Xitrepresents the control variable.is the individual effect.is the residual term. Since the economic growth target value (EG), hard constraints (EHC) and soft constraints (ESC) are all macro time series variables. If the year fixed effect is controlled in the model, the impact of EGTM on UGLUE may be absorbed by year fixed effect. Therefore, referring to the prior literature [58], this paper adopts the regional fixed effect model instead of year-region two-way fixed effect model. Considering that not controlling the year fixed effect may omit some variables that change over time, this paper adds macroeconomic variables to the model. These include economic development level, degree of openness to the outside world, and population size, which alleviate the problem of omitted variables that may exist in the time section.\n\nConsidering the possible threshold effect of economic development goals on UGLUE, this paper constructs the following model:\n\nAmong them,I()is the indicative function.ERis the threshold variable of environmental regulation.is the specific threshold value to be estimated.\n\nThis paper uses SDM to examine the possible spatial spillover effects of EGTM on UGLUE. The model is set as follows:\n\nWijis the spatial weight matrix. The geographical distance weight matrix is regarded as spatial weight matrix.is the spatial autocorrelation coefficient.is the estimated coefficient of the impact of the EGTM of surrounding area on UGLUE in this area.\n\nUGLUE: This paper uses the super-efficiency SBM model considering non-expected output to measure UGLUE. The specific formula is as follows:\n\nAmong them,is the slack of input, expected output and undesired output;ρis the efficiency value of the decision-making unit (DMU), which ranges from 0 to 1. When, that is, when, the DMU is effective, otherwise the DMU is invalid.\n\nBased on the super-efficiency SBM, this paper constructs the following global Malmquist index:\n\nAmong them,is the global Malmquist index from periodtto periodt+1.indicates that compared with periodt, the UGLUE in periodt+1is improved.indicates that compared with periodt, the UGLUE in periodt+1is reduced.\n\nTable 1shows the input–output indicators.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t001\n\nEGTM: This paper examines EGTM from two aspects: Economic growth target value and its constraints. The economic growth target value is expressed as the target value mentioned in the work report of each city government [38]. Economic growth target constraints include hard constraints and soft constraints. This paper uses the modal particles used in the city government reports when announcing growth targets as identification variables [37]. Economic growth targets that use words such as “above”, “exceed”, “higher than”, and “ensure” are considered hard constraints, while economic growth targets that use modal particles such as “around”, “up and down”, and “between” are considered soft constraints.\n\nEnvironmental regulation: There are two measurement methods. One is to characterize it through the frequency of environmental protection vocabulary and pollution control investment mentioned in local documents [59]. The other is to reversely infer environmental regulation through pollution control results and reflect the level of regional environmental regulation by pollutant emissions [60]. This paper uses the frequency of environmental protection words in city government work reports obtained through text analysis to measure environmental regulation. Environmental protection vocabulary includes environmental protection, environmental protection, pollution, energy consumption, emission reduction, pollution discharge, ecology, green, low carbon, air, chemical oxygen demand, sulfur dioxide, carbon dioxide, PM10 and PM2.5, etc.\n\nAmong them,Sirepresents the proportion of the output of cityiin the total outputY.represents the proportion of the labor force used by cityiin the total labor force.is the proportion of labor used by cityiwhen the labor force is effectively allocated.is the labor output elasticity of each city estimated using the production function. To ensure the consistency of the estimation results, we take the absolute value of degree of labor distortion.\n\nTaking 273 cities in China from 2010 to 2021 as a sample, this study explores the impact of EGTM on UGLUE. Among them, data on economic growth targets and environmental regulations come from the work reports of prefecture-level city governments. Green patent data come from the patent search platform of the State Intellectual Property Office. Other data come from the China Statistical Yearbook, China City Statistical Yearbook, and China Urban Construction Statistical Yearbook. Interpolation and linear fitting methods are used to fill in missing values in some prefecture-level city data. The monetary price index is deflated based on the price index with 2010 as the base year. To eliminate the impact of heteroskedasticity, I logarithmize GTI, GDPP, and POP.Table 2shows the descriptive statistics of variables.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t002\n\nFig 2shows the changing trend of UGLUE based on the ML index from 2010 to 2021. The ML mean is 1.0498, indicating that from 2010 to 2021, UGLUE has shown an overall upward trend. This trend is due to the increasing demand for land resources caused by the accelerated urbanization process. In the case of limited land resources, policymakers have to focus on optimizing land management and promoting sustainable land use. In addition, the public pays more and more attention to the quality of the living environment, which prompts them to pay more attention to how to improve environmental quality through green land use. The UGLUE declined in 2010–2011 and 2012–2015. During this period, China’s economy may still be in a slow recovery stage from financial crisis. Under economic pressure, regions may pay more attention to short-term economic growth at the expense of environmental protection. The enforcement of land use-related policies has weakened.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.g002\n\nFig 3shows the spatial distribution of UGLUE in China in 2010, 2014, 2018 and 2021. More and more cities have achieved growth in UGLUE. In 2021, the number of cities with increased UGLUE reaches 231. Most urban land has been effectively utilized. However, the UGLUE in some cities such as Chongqing, Shenzhen and Nanjing is still on a downward trend. The land use mode needs to be changed urgently.\n\nhttp://www.esri.com/software/arcgis).\n\nhttp://www.esri.com/software/arcgis).\n\nhttps://doi.org/10.1371/journal.pone.0321779.g003\n\nThe benchmark regression results are shown inTable 3. Based on test results, we choose the estimation results of fixed effect model for analysis. The estimated coefficients of economic growth target value and its hard constraints are -0.0346 and -0.0309 respectively, which indicates that both reduce UGLUE.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t003\n\nThis conclusion is consistent with existing research. In order to achieve economic growth targets, local governments tend to invest in infrastructure projects with short cycles and quick results [64], which creates huge demand for highly polluting raw materials such as building materials, steel, and cement, exacerbating environmental pollution. In addition, government investment in infrastructure also squeezes out environmental protection funding [65], making it difficult to carry out environmental restoration work. UGLUE is reduced. At present, infrastructure investment is still one of the important means for local governments to promote economic growth. From January to May 2024, the national fixed asset investment is 188006 billion yuan. Among them, infrastructure investment increases by 5.7% year-on-year, 1.7 percentage points higher than the total investment. In the future, the government should optimize the investment structure and gradually reduce its reliance on traditional infrastructure investment. Existing studies have mainly focused on the impact of economic growth targets on environmental pollution [66], but not on their impact on UGLUE. Currently, there is limited understanding of how economic growth policies affect urban land use patterns in practice. This study fills this gap.\n\nThe estimated coefficient of soft constraints is positive at the 5% significance level, indicating that soft constraints improve UGLUE. Traditional studies usually analyzed the effects of economic growth target constraints as a whole [67]. They ignored the potential environmental benefits of soft policy constraints. Wang and Lei [68] emphasized that economic policies need to balance growth and environmental protection. However, few studies have linked soft constraints to UGLUE. The soft constraint characteristics of economic growth targets enable local governments to pay more attention to long-term interests when formulating economic development plans. When planning urban land use, the government gives priority to environmental protection factors, such as setting up ecological protection areas and promoting green buildings, so as to improve UGLUE. Under the soft constraint of economic growth targets, Chengdu implemented the “Urban Green Heart Plan” in 2021 to increase the ecological benefits of land. In addition, Chengdu has continuously improved the city’s green coverage rate by implementing a series of ecological projects, such as the Ring City Ecological Zone and Jinjiang Park. By 2024, the green coverage rate of Chengdu’s built-up area has increased to 44.7%.\n\nRegarding the control variables, the estimated coefficients of economic development level and population size are significantly positive. With economic growth, governments and enterprises invest more funds in the research and development of advanced land use technologies, thus promoting the intensive use of urban land. People are paying more and more attention to their own health and environmental quality. They not only adopt green lifestyles themselves, but also encourage enterprises to produce technology-intensive rather than resource-intensive products and reduce pollutant emissions. The expansion of population size can bring about “scale effect” and “agglomeration effect”, which helps share knowledge and technology, thereby improving UGLUE. The degree of openness and labor distortion have a negative impact on UGLUE. At present, China mainly relies on highly polluting resource-intensive industries to drive exports, which consumes a large amount of land resources and increase pollutant emissions. The concentration of labor in pollution-intensive industries leads to a shortage of labor in technology-intensive industries.\n\nTo avoid the impact of the epidemic from interfering with research conclusions, the sample data in 2020 and 2021 are eliminated and then regression analysis is performed (Table 4). The results demonstrate the robustness of benchmark regression results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t004\n\nThere are obvious differences between the administrative levels of municipalities and general prefecture-level cities. We delete Beijing, Tianjin, Shanghai and Chongqing to reduce the estimation bias caused by the large systematic differences between samples.\n\nIn order to eliminate the estimation bias caused by omitted factors, this paper further controls the year fixed effect on the basis of baseline regression. The estimated results are consistent with the baseline regression results. This shows that the baseline regression results have a certain degree of robustness.\n\nUGLUE may be affected by non-quantifiable indicators such as cultural concepts and institutional environment. Ignoring non-quantifiable indicators may cause endogenous problems. In addition, the government may set corresponding economic growth targets based on its forecasts of local land use, leading to reverse causality problems. To solve the endogeneity problem caused by omitted variables and reverse causality, this paper uses instrumental variable method to test. According to the instrumental variable selection criteria, this paper uses the economic growth target of the province where each city is located as instrumental variable. In terms of relevance, China has a “promotion tournament” with GDP as the assessment standard [69]. To win the “promotion tournament”, local governments “add layers of weight” to the economic growth targets set by higher-level governments, which is consistent with the relevance of instrumental variables. In terms of exogeneity, the UGLUE in individual prefecture-level cities has little correlation with the mean economic growth target of the province where they are located. For the hard and soft constraints of economic growth targets, this paper uses the interaction term of the number of prefecture-level cities in the province where the prefecture-level cities are located (related to individual changes) and the average of the national economic growth targets for next two years (related to time) as its instrumental variables.\n\nAs shown inTable 5, the regression coefficients of instrumental variables all pass the 1% significance test, indicating that they have a certain correlation. The regression coefficient of economic growth target value and its hard constraints is still significantly positive. The regression coefficient of soft constraints is still significantly negative. This demonstrates the robustness of estimation results. The test results show that the instrumental variables have certain rationality and effectiveness.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t005\n\nDue to China’s vast territory, the constraints of local EGTM are also different, which may have different impacts on UGLUE. According to the standards given by the National Bureau of Statistics, this article divides 273 prefecture-level cities into three regions: Eastern, central and western.Table 6shows that the economic growth target value has the greatest negative impact on UGLUE in central regions, followed by eastern regions and has the least negative impact on UGLUE in western regions. Compared with western region, the central region has more developed industries and manufacturing industries, which tend to be more dependent on land resources. Under the pressure of economic growth targets, local governments are more inclined to support the development of these industries. Land resources are over-exploited and inefficiently used.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t006\n\nAccording to the National Sustainable Development Plan for Resource-Based Cities (2013–2020) issued by the State Council, this paper divides China’s 273 cities into 108 resource-based cities and 165 non-resource-based cities, and further analyzes the heterogeneous impact of EGTM on the UGLUE in cities with different resource endowments.Table 7shows that the negative impact of economic growth target value on the UGLUE in resource-based cities is greater than that in non-resource-based cities. Resource-based cities take the mining and processing of the region’s unique natural resource endowments (such as minerals, forests and other natural resources) as leading industries. Under the pressure of economic growth targets, compared with non-resource-based cities, resource-based city governments are more inclined to achieve economic growth by supporting industries such as resource mining and processing, thereby exacerbating environmental pollution and reducing UGLUE. Soft constraints can significantly improve the UGLUE of non-resource-based cities, but the impact on UGLUE of non-resource-based cities is not significant. The industrial structure of non-resource-based cities is diversified, covering multiple fields such as manufacturing, services, and high-tech industries. Under the soft constraints of economic growth targets, non-resource-based cities can adjust their industrial structure more flexibly and promote the development of emerging industries, thereby improving UGLUE. Resource-based cities have a single industrial structure. Even if soft constraints are set on economic growth targets, local governments cannot effectively improve UGLUE.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t007\n\nAccording to Cleary [70], this paper employs the Fisher’s combined probability test method for testing differences between groups of coefficients (Table 8). The number of sampling iterations is 1,000. The p-values for the tests on differences between groups for economic growth target values and their soft constraints are less than 0.1, indicating that the impact of economic growth target values and their soft constraints on UGLUE varies significantly across different geographical locations and cities with different resource endowments. The hard constraints cannot pass the inter-group difference test, suggesting that the impact of hard constraints on UGLUE does not differ significantly across different geographical locations and resource-endowed cities.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t008\n\nTo test the impact of EGTM on UGLUE through green technology innovation, this study selects the number of green patent applications as an indicator of green technology innovation [71]. Group regression analysis is conducted using this indicator. To avoid any influence of EGTM on green technology innovation within the sample period that might bias the grouping results, the study divides the sample into two groups. The groups are categorized as high and low based on the median level of green technology innovation at the beginning of the sample period (2010) for regression analysis.\n\nAs shown inTable 9, regions with higher levels of green technology innovation experience a greater impact of EGTM on UGLUE compared to regions with lower levels of green technology innovation. EGTM can influence UGLUE through green technology innovation, which is similar to the conclusion of Guo et al. [72]. The difference is that their study focused on environmental pollution, while this study takes into account both land use and environmental pollution. This study provides a more comprehensive perspective on the relationship between economic policies, technological innovation, and sustainable development.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t009\n\nTo achieve economic growth, governments often increase investment in infrastructure, which reduces the availability of funds in the market. Consequently, financial institutions raise loan interest rates. This increases financing costs for companies [73] and makes it challenging to sustain investment in green technology development. In addition, local governments vigorously support the real estate industry to promote economic growth, leading to rising housing prices. In pursuit of short-term profits, some companies invest funds originally intended for green technology research and development into the real estate market, further squeezing out innovation funds.\n\nThe soft constraint of economic growth targets prompts local governments to take environmental protection into account when investing in infrastructure, and encourages companies to increase investment in green technology research. Green technology innovation can reduce the consumption of fossil energy from production source and improve the degree of pollutant purification in end-of-pipe treatment, thereby improving UGLUE [74].\n\nTo test how EGTM influences UGLUE through the upgrading of industrial structures, this paper selects the ratio of the tertiary industry value-added to the secondary industry value-added as the measure of industrial upgrading [75]. This indicator is used for group regression analysis. The median level of industrial upgrading at the start of the sample period (2010) is used to divide the sample into two groups: high and low.\n\nAs shown inTable 10, EGTM has a greater impact on UGLUE in regions with a high level of industrial upgrading than in regions with a low level of industrial upgrading. EGTM can affect UGLUE through the upgrading of industrial structure. Ren et al. [34] pointed out that there is an interactive relationship between EGTM and industrial structure upgrading. However, they did not explore the relationship between EGTM, industrial structure upgrading and land use in depth. In pursuit of short-term economic growth, local governments excessively tilt production factors such as capital and land toward heavy industry enterprises that lack innovation momentum [76]. Emerging industries that require large initial investments and long growth cycles are restricted from development. The pace of industrial structure upgrading slows down.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t010\n\nWhen the setting of economic growth targets shifts from “hard constraints” to “soft constraints”, Local governments have more flexibility in resource allocation. This enables them to rationally allocate resources while promoting economic growth. Specifically, they can invest financial resources in technology research and development and environmental protection industries. The upgrading of industrial structure is promoted, which can guide low-pollution industries to gather in the city center and traditional high-pollution industries to move to the periphery of city [77]. The economic development of urban land and environmental protection are balanced.\n\nThis paper adopts the Bootstrap self-sampling method and repeats the sampling 300 times. The test results corresponding to each threshold quantity are shown inTable 11. The single threshold tests of explanatory variables (EG, EHC and ESC) all pass 10% significance test, but the double threshold tests fail to pass significance test. This shows that environmental regulation has a single threshold effect in the impact of EGTM on UGLUE.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t011\n\nAs can be seen fromFig 4, when environmental regulation is used as the threshold variable, the threshold values of economic growth management (EG, EHC and ESC) for UGLUE are all 0.3268.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.g004\n\nTable 12shows the estimation results of panel threshold model. When the intensity of environmental regulation is lower than 0.3268. The estimated coefficients of economic growth target value and its hard constraints are negative at the 1% significance level. The estimated coefficient of soft constraints is positive but not significant. When the intensity of environmental regulation is higher than 0.3268, the absolute value of economic growth target regression coefficient decreases. The estimated coefficient of hard constraints becomes positive. The estimated coefficient of soft constraints has increased and passed the 5% significance test. When the intensity of environmental regulation is low, local governments tend to pay more attention to economic growth, resulting in a large amount of land resources being used for high-pollution, high-value industries. As the intensity of environmental regulation increases, the governments guide enterprises to develop in the direction of low pollution and high value by setting up environmental barriers and providing preferential policies.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t012\n\nExisting research mostly focuses on the direct effects of EGTM [35]. Few studies have explored how economic growth targets influence neighboring regions’ UGLUE through spatial interactions. In fact, the economic growth targets set by various levels of government in China are not independent but form an EGTM system. There are complex spatial strategic interactions among these targets. Therefore, it is necessary to introduce spatial econometric models to analyze the impact of spatial strategic interactions between governments at the same level on UGLUE.\n\nTable 13shows the global Moran’s I values of UGLUE, EG, EHC and ESC from 2010 to 2021. From 2010 to 2021, the global Moran’s I value of UGLUE, economic growth target value, hard constraints and soft constraints is significantly positive, which shows that UGLUE, economic growth target value, hard constraints and soft constraints all have positive spatial correlation.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t013\n\nAccording to the test results inTable 14, this paper chooses the estimation results of SDM for interpretation. The spatial lag coefficient of economic growth target value and its hard constraints is negative at the 1% significance level, indicating that the economic growth target and its hard constraints have a negative spatial spillover effect on UGLUE. There is a “race to the top” among local governments in setting economic growth targets, which increases the pressure on local economic growth [78]. Governments in different regions often set higher growth targets to avoid falling behind other regions in economic growth. This competitive target setting increases the pressure on local economic growth. Under tremendous pressure, local governments focus on economic growth, ignore environmental protection [79]. UGLUE is reduced. In the future, environmental protection should be included in government performance evaluation system, so that there will be not only economic competition but also environmental competition among governments. Based on this, local governments have to consider both the economic and ecological benefits of land use.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321779.t014\n\nBased on sample data from 273 cities in China from 2010 to 2021, this paper uses panel data model to empirically test the impact of EGTM (including economic growth target value, its hard constraints and soft constraints) on UGLUE and its transmission mechanism. The panel threshold model is used to verify the threshold role of environmental regulation in the relationship between EGTM and UGLUE. The SDM is used to verify the spatial spillover effect of EGTM on UGLUE. The conclusions are as follows: (1) The local economic growth target value and its hard constraints have a negative impact on UGLUE. The soft constraint of “leaving room for maneuver” is conducive to improving UGLUE. (2) Green technology innovation and industrial structure upgrading are the transmission mechanisms of EGTM affecting UGLUE. (3) The intensity of environmental regulation has a threshold effect on the impact of EGTM on UGLUE. As the intensity of environmental regulation increases, the negative impact of economic growth target value and its hard constraints on UGLUE weakens. The positive impact of economic growth target soft constraints on UGLUE increases. (4) EGTM has a spatial spillover effect on UGLUE. The economic growth target value and its hard constraints of surrounding areas can reduce the UGLUE in local region, while its soft constraints can improve the UGLUE in local region. (5) Regarding geographical location heterogeneity, economic growth targets have the greatest negative impact on UGLUE in the central region, followed by the eastern region, and have the least negative impact on UGLUE in the western region. Regarding resource endowment heterogeneity, the negative impact of economic growth targets on UGLUE in resource-based cities is greater than that in non-resource-based cities. The positive impact of soft constraints on UGLUE in resource-based cities is smaller than that in non-resource-based cities.\n\nBased on the research conclusions, this paper puts forward the following policy recommendations:\n\nThe limitations of this study are primarily reflected in two aspects. First, the analysis primarily relies on quantifiable data to examine the relationship between economic policy and UGLUE, failing to fully capture the cultural, political, and social factors that affect UGLUE. Non-quantifiable factors such as local officials’ policy preferences and regional cultural differences could significantly impact UGLUE. Second, the data used in this study are limited to the period from 2010 to 2021. The data within this timeframe may not fully reflect the long-term effects and time lags following economic policy adjustments. Future research could incorporate qualitative research methods, such as case studies, expert interviews, or focus group discussions, to delve deeper into the impact of non-quantifiable factors on UGLUE. Additionally, extending the timeframe could help observe the long-term effects of policy changes on UGLUE.\n\nhttps://doi.org/10.1371/journal.pone.0321779.s001\n\n(XLSX)",
    "category": "earth_sciences"
  },
  {
    "title": "Spatial patterns and influencing factors of traditional villages in the Pearl River–Xijiang River Economic Belt (PRXREB)",
    "authors": "Meng Dai, Xiuli Huang, Yuanquan Xu, Zhibo Han, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0321646",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321646",
    "content": "The spatial patterns and influencing factors of traditional villages are critical for their preservation and heritage. This study employs spatial analysis and geostatistical methods to explore the spatial distribution of national traditional villages within the PRXREB as of 2023. The results indicate an uneven and clustered distribution, identifying four distinct clusters within the region. The analysis shows that most traditional villages are located near major rivers and roads, as well as in areas with slopes less than 10°. Importantly, the distribution of traditional villages in the PRXREB is shaped by the interplay of multiple factors rather than isolated individual factors, the complex interplay between natural factors and socio-economic conditions likely shapes the sustainable development of traditional villages by affecting long-term economic development path. Particularly, some traditional villages in Guangxi with challenging natural environments face risks due to population loss and inadequate transportation infrastructure. We find that the spatial distribution of traditional villages is significantly positively correlated with the spatial distribution of regional population and various economic indicators. The per capita disposable income of urban residents (PIUR) is the most influential factor, and economic development helps promote the protection and inheritance of traditional villages, but there are also regional differences. Based on these insights, we propose targeted recommendations to support the sustainable development and conservation of traditional villages in the PRXREB.\n\nCitation:Dai M, Huang X, Xu Y, Han Z (2025) Spatial patterns and influencing factors of traditional villages in the Pearl River–Xijiang River Economic Belt (PRXREB). PLoS ONE 20(4):\n           e0321646.\n        \n        https://doi.org/10.1371/journal.pone.0321646\n\nEditor:Yile Chen,, Macau University of Science and Technology, MACAO\n\nReceived:August 28, 2024;Accepted:March 7, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Dai et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:This work was supported by the Scientific Research Fund Project of Pearl River-Xijiang River Economic Belt Development Research Institute of Guangxi Normal University (ZX2020012), the Foundation of Talent Projects of Guangxi (2021AC19302, 2021AC19294), the Innovation and Entrepreneurship Education in Universities Special Project of Guangxi Education Science Program (2021ZJY1405) and the Basic Scientific Research Ability Improvement Project for Young Academics of Guangxi (2022KY0052).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nTraditional villages hold significant historical, landscape, and cultural value, serving as vital representations of rural civilization and settlement forms. However, the rate of urbanization worldwide has reached 56%, with a consistent annual increase in most countries [1]. Within the context of the urban-rural dual structure system, the aggressive expansion of cities has led to rural depopulation and marginalization. The decline and loss of heritage in traditional villages are becoming increasingly severe. Understanding the spatial distribution of traditional villages and their natural, social, and economic environments is crucial for their revitalization. Therefore, studying the spatial layout and developmental factors influencing traditional villages has become essential for their sustainable development and protection.\n\nCurrent studies on the traditional villages can be divided into three categories. The first category focus on spatial analysis of traditional village distributions. Utilizing GIS and remote sensing technologies, these studies map and analyze the distribution and clustering of villages [2]. Such methods help delineate patterns and clusters related to natural factors. Some researchers have conducted detailed studies on the spatial distribution of traditional villages at regional [2,3], provincial [4–6], and county levels [7–9], with some studies focusing on typical villages in micro-units [10–13]. For example, Wei et al found that The traditional villages in the Yellow River Basin exhibit an east-west density gradient, with a higher concentration in the east and sparser distribution in the west [2]. The spatial dynamics, spatial pattern, and morphological characteristics of traditional villages in different province exhibit clear geographic imbalances, with the impacts of various driving factors differing significantly [4–6]. Similarly, the spatial distribution of traditional villages across counties is uneven, with small and medium-sized villages predominating [7–9]. At the micro-scale, scholars primarily focus on the spatial characteristics and development of traditional villages, heritage conservation, landscape evaluation, rural tourism, and ecological planning [10–12]. They suggest that rural planning and design should be based on current conditions, with an emphasis on strengthening public infrastructure planning, adapting to local conditions, and realizing bottom-up development [13]. Although existing research has analyzed the distribution characteristics and driving mechanisms of traditional villages at multiple levels, most studies focus on a single river basin or province as the study area. Few basin-specific studies primarily concentrate on the Yellow River Basin and the southwestern mountainous areas of China, and there is a lack of research on the cultural-ecological interaction mechanisms in the China-ASEAN corridor.\n\nThe second category examines the socio-economic impacts on village spatial distributions. This strand of research explores the impact of economic policies and migration on the sustainability of rural villages. The socio-economic factors include architectural space [14,15], settlement culture [16], landscape patterns [17], community livelihood [18], medical environment [19], urban–rural relationship and social mobility [5,20], etc. Econometric models and demographic analyses assess the effects of urban expansion on rural depopulation and cultural erosion. However, many studies overlook the bidirectional nature of socio-economic dynamics and their spatial manifestations, limiting their applicability to broader policy contexts.\n\nThe third category assesses the effectiveness of heritage preservation strategies within traditional villages [6,21]. Revitalizing rural areas is now a key global strategy in addressing these challenges. For example, Germany has adopted a multifaceted approach, including land consolidation, area planning, rural infrastructure enhancement, and educational initiatives, to boost rural resilience and revitalization [22]. In contrast, Japan, Thailand, and Vietnam have implemented the “One Village, One Product” initiative to stimulate rural industrial growth and revitalization [23–25]. The United States is focusing on fostering community dynamism as a means of rural revitalization [26]. Sweden, meanwhile, is advancing rural revitalization by introducing external social capital to enhance rural productive capacities [27]. In China, rural revitalization strategies involve blending rural and urban development and promoting new models of urbanization, particularly through the branding of traditional villages. These qualitative methods, including ethnographic studies and community-based participatory research, provide insights into successful preservation initiatives. However, these approaches tend to be localized and may not scale well across different regions.\n\nDespite the Chinese government recognition of 8,171 national traditional villages release in 2023, their disappearance rate surpasses their acknowledgment, highlighting the urgency of their conservation [28]. As the first cross-provincial basin economic belt, the Pearl River–Xijiang River Economic Belt (PRXREB) is strategically significant for the transformation and development of the Pearl River Delta, linking the developed eastern regions with the less developed western regions, particularly in the Guangxi Zhuang Autonomous Region and Guangdong Province. The regional differences within this economic belt have made it a focal point for multidisciplinary scholarly research [29–31]. Investigating the spatial distribution and influencing factors of traditional villages in the PRXREB, identifying the bottlenecks in rural development, and providing scientific bases for conservation strategies are vital for preserving the cultural, landscape, and historical heritage of this region [32,33].\n\nIn our study, 120 national traditional villages within the 11 cities of the PRXREB are selected as the research objects. We aim to merge spatial and socio-economic perspectives to offer a comprehensive understanding of the dynamics affecting traditional villages in the PRXREB. Our goal is to develop targeted recommendations that facilitate both cultural heritage preservation and sustainable development [34]. We seek to provide a new perspective on regional development in the PRXREB, offer theoretical support and practical guidance for the understanding and protection of traditional villages, and provide scientific evidence for local governments and policymakers, helping them balance economic development with traditional village conservation and promoting regional sustainable development. The structure of the paper is as follows: Section 2 describes the data and methodology, Section 3 presents the spatial patterns of traditional villages in the PRXREB, Section 4 analyzes the influencing factors of traditional villages in the PRXREB, Section 5 discusses the findings and policy recommendations, and Section 6 concludes with results and future research directions.\n\nLocated in the Pearl River Basin in the south of China, the PRXREB borders Yunnan Province and Guizhou Province in the north, crosses Guangdong and the Guangxi Zhuang Autonomous Region, and connects Hong Kong and Macao in the south. The PRXREB contains four cities in Guangdong Province, namely, Guangzhou, Foshan, Zhaoqing, and Yunfu, and seven cities in the Guangxi Zhuang Autonomous Region, namely, Nanning, Liuzhou, Wuzhou, Guigang, Baise, Laibin, and Chongzuo, and it covers 0.165 million km2, accounting for 6.6% of the national territory of southwest China (2.5 million km2). Moreover, the PRXREB is located in the western part of the hills of the Guangxi Zhuang Autonomous Region and Guangdong Province, with its high terrain in the northwest and low terrain in the southeast; the terrain is inclined from the northwest to the southeast, and the landform is generally composed of mountains, hills, plains, and rivers. The mountains and hills account for 53.88% of the total area of the PRXREB. There are many mountains in the western region, a dense network of rivers in the east-central part, and a lower altitude and flat terrain in the Pearl River Delta.\n\nNow, the PRXREB is inhabited by several ethnic groups in compact communities, including the Hans, the Miaos, the Yaos, the Dongs, and the Zhuangs, and most of the ethnic minorities live in the Guangxi Region. Among the 120 national traditional villages in this economic belt, there are 50 villages in Guangdong Province and 70 villages in the Guangxi Region. Although the spatial distributions of these traditional villages have certain similarities, in Guangxi and Guangdong, there is a huge gap between the human environment and economic development, as well as in the characteristics of the living preservation and development of traditional villages. As the direct hinterland of the Guangdong–Hong Kong–Macao Greater Bay Area, the PRXREB has an important strategic position in the national coordinated regional development and the opening up and cooperation with ASEAN, as it is an important link for the southwest region and even the Southeast Asia and South Asia regions driven by the Guangdong–Hong Kong–Macao Greater Bay Area, as well as a sea channel for the southwest region of China.\n\nData on the traditional villages located in the PRXREB were obtained from the website of Chinese Traditional Villages (source:http://www.chuantongcunluo.com/index.php/Home/gjml/gjml/wid/2506.html, accessed on 8 Sep 2023), and the coordinates of those villages were collected from the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/, accessed on 8 Nov 2024). A digital elevation model (DEM) was derived from Aster GDEMV3 data (spatial resolution: 30 m) provided by the NASA Earthdata (source:https://search.earthdata.nasa.gov/search, accessed on 10 Nov 2024). The spatial distribution of the population in the PRXREB was obtained from WorldPop (spatial resolution: 100 m, source:https://www.worldpop.org/, accessed on 15 Sep 2023). River and road network data were downloaded from the Open Street Map (source:https://www.openstreetmap.org/, accessed on 20 Sep 2023). In addition, economy data were collected from the China statistical yearbooks and government reports of relevant cities in the PRXREB.Table 1describes the study data in detail.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.t001\n\nIn our study, geographical indicators, such as the nearest neighbor index, geographic concentration index, kernel density estimation, and the geographic detector, were mainly used to characterize the spatial variations in the traditional villages in the PRXREB, and the influences of the terrain, roads and transportation, rivers, and economic development on the spatial distributions of the study objects were explored. The framework of this study is shown inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.g001\n\nThe geographical concentration index can be used to measure the concentration of traditional villages in different cities in the PRXREB. The calculation formula is\n\nwhereis the geographical concentration index, which ranges from 0 to 100. c is the number of cities.is the number of traditional villages in city.is the total number of traditional villages in the PRXREB. If the geographical concentration index of a city is greater than that when traditional villages are evenly distributed in the cities of the economic belt, then it means that the traditional villages in each city are concentrated; otherwise, they are dispersed.\n\nThe nearest neighbor index [35] is defined as the ratio of the observed mean distance to the expected mean distance of the traditional villages, which can measure the proximity of the traditional villages in geographic space. Its formula is as follows:\n\nwhereis the nearest neighbor index. If, the distribution of traditional villages is uniform. If, the distribution of traditional villages is clustered. If, the distribution of traditional villages is random.is the observed mean distance between each traditional village and its nearest neighbor.is the expected mean distance between each traditional village and its nearest neighbor. When the traditional villages in the PRXREB fit the Poisson distribution,is calculated as follows:\n\nwhere n is the total number of traditional villages, and A is the area under study.\n\nThe kernel density estimation [36] uses a moving window to estimate the density of the traditional villages, and it can identify the clusters of the traditional villages in the PRXREB. The calculation formula is\n\nwhereis the estimated density of the traditional village at. The larger the value of, the denser the traditional village.represents the coordinates of the traditional village.is the number of traditional villages.is the search bandwidth.is the kernel function.\n\nThe geographic detector [37] is a geostatistical method for exploring the relationship between the factors and spatial patterns of t she traditional villages, and it includes 4 detectors: the factor detector, risk detector, ecological detector, and interaction detector. We applied the factor detector and interaction detector to explore the importance of each factor and how different factors interact with each other.\n\nThe factor detector can quantify the importance of the factors in the spatial pattern of the traditional villages. The calculation formula is\n\nwhereis between 0 and 1, indicating the consistency of the spatial distribution between traditional villages and its influencing factors. The larger the value of, the more important the factor in the spatial pattern of the traditional villages.means that the factor completely controls the spatial pattern of the traditional villages, andmeans that the factor has no relationship with the spatial pattern of the traditional villages.is the number of the influencing factor’s strata.andare the number of and the variance in the traditional villages at strata.andare the numbers of and the variance in all traditional villages in the PRXREB.\n\nThe interaction detector can explore the interaction between different influencing factors on the spatial pattern of traditional villages and quantify the importance of the factors in the spatial pattern of the traditional villages. By comparing the q-value of the interaction of two different factors with the q-value of a single factor, the interaction detector can be classified into 5 types:\n\nwhereis the value of the interaction of two different factors,and, and it is calculated usingEquation 5.andare the values of factorsand, respectively.\n\nIn our study, traditional villages in the PRXREB are presented as spatially visualized points. The statistics of the traditional villages in the PRXREB are calculated and graded inFig 2. According to the data shown inFig 2, the spatial distributions of the traditional villages in the PRXREB are unbalanced and vary among cities. Specifically, the spatial distribution characteristics of the traditional villages are dominated by two major clusters: one is Liuzhou, Laibin, and Nanning in Guangxi Province, accounting for 46.67% of the total number of traditional villages in the PRXREB, and the other is Foshan, Guangzhou, and Zhaoqing in Guangdong Province, accounting for 39.17% of the total number of traditional villages in the PRXREB. The distributions of the traditional villages in the other cities are relatively dispersed.\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g002\n\nThrough the geographical concentration index, the spatial distribution equilibrium of the traditional villages can be quantified. According toEquation 3, geographic concentration indexof the traditional villages in the PRXREB is 39.45; however, if 120 traditional villages are evenly distributed in each city in the PRXREB, the geographic concentration indexis 30.15.indicates that the spatial distribution of the traditional villages in the PRXREB is unbalanced and agglomerated.\n\nThe result of the nearest neighbor index of the traditional villages in the PRXREB is shown inTable 2. Among the traditional villages in the PRXREB, the average distancereaches, while the expected theoretical distribution average distanceis. The nearest neighbor index () is 0.47, which is less than 1 and passes the significance test, indicating that the spatial distribution of the traditional villages in the PRXREB is significantly clustered.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.t002\n\nFurther, the kernel density estimation was used to visualize the distribution patterns of the traditional villages in the PRXREB (Fig 3). The result shows that the spatial distribution of the traditional villages in the PRXREB is extremely unbalanced. The spatial distribution of the traditional villages in the PRXREB is sparse, with an average density of 6.8 villages per 10,000 km2, which is much lower than that of 7.10 villages per 10,000km2nationwide. Furthermore, four main clusters were identified, as shown inFig 3. The largest cluster of traditional villages is located in Foshan, west of Guangzhou, southeast of Zhaoqing, and northeast of Fuyun, with a core density of 26.96–32.35 villages per 10,000 km2. The second cluster is located in the north of Liuzhou. The traditional villages in the east of Laibin, north of Guigang, and northwest of Wuzhou form the third cluster, and the last cluster is located in the southwest of Naning. More importantly, the four clusters are mostly distributed on the fringes of the cities.\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g003\n\nNatural and socioeconomic factors significantly influence the spatial pattern of the traditional villages in the PRXREB. After reviewing the relevant literature and considering data availability [4,38], five natural and eight socioeconomic factors were selected for analysis. The five natural factors were elevation, slope, aspect, distance to a road (Road), and distance to a river (River). The eight socioeconomic factors were population (Pop), GDP, primary industry (PI), secondary industry (SI), tertiary industry (TI) in GDP, per capita GDP (PGDP), the per capita disposable income of urban residents (PIUR), and the per capita disposable income of rural residents (PIRR). The statistical information of each factor is shown inS2andS3 Tables.\n\nElevation is a critical factor in the evolution of the traditional villages in the PRXREB. It affects soil characteristics, water features, and climate, which, in turn, influence the villages’ spatial arrangements and their agricultural and lifestyle practices. Based on DEM, the altitudes of the traditional villages in the PRXREB are displayed inFig 4. The result indicates that the average elevation of the economic belt reaches 254.08 meters. As the elevation increases, fewer traditional villages exist. There are 45 traditional villages distributed in low mountains and hills, accounting for 37.5% of the traditional villages in the PRXREB. The regional environment where these 45 traditional villages are located has various geographic advantages, such as a good environment and climate, a low topographic relief amplitude, a simple landform, and superior agricultural development conditions, which were conducive to the formation and development of the traditional villages.\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g004\n\nGenerally, the elevation of the traditional villages in the seven cities of the Guangxi Zhuang Autonomous Region is higher than that in the four cities of Guangdong Province (Fig 5), among which Baise has the highest elevation, exceeding 1 km. However, the general central tendency of the village elevation in the seven cities in Guangxi is lower than that in the four cities in Guangdong. In Guangxi, the central tendency of the traditional villages in Nanning and Chongzuo is relatively higher, while the dispersion degree of the elevation of the villages in Laibin and Liuzhou is larger. The distribution of the elevation of the traditional villages located in Guangzhou, Laibin, Guigang, and Nanning is strongly skewed. Specifically, the traditional villages in the three cities Guangzhou, Laibin, and Guigang present a left-skewed distribution, which represents the elevation of most traditional villages that have a median elevation higher than all the traditional villages in those cities. Meanwhile, the traditional villages in Nanning show a right-skewed distribution.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.g005\n\nSlopes affect natural airflow, sunshine duration, and radiation intensity, which impact the site selection, spatial layout, orientation, and ecological environment of traditional villages and residential houses. Based on the digital elevation model (DEM), the slopes of the PRXREB were extracted and divided into five categories [39] which is shown inTable 3. Finally, the distribution of the slopes and the number of traditional villages in the PRXREB were determined, and they are shown inFigs 6and7.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.t003\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.g007\n\nFig 7shows that most traditional villages in the PRXREB are located in low-slope areas. Specifically, there are 12 traditional villages distributed in flat areas of the PRXREB, with a slope below 2°, accounting for 10% of the total number of traditional villages. No traditional village is located in areas with a slope of more than 15°. The environment of the areas with a slope greater than 15° is terrible and not suitable for site selection or farming activities, with poor soil, intensive erosion, serious water loss, and a fragile ecosystem. Generally, the relief amplitude of the traditional villages in the four cities of Guangdong is smaller than that of the traditional villages in the seven cities of Guangxi. The average slope of the traditional villages in the four cities of Guangdong is 4°, and the average slope of the traditional villages in the seven cities of Guangxi is 7°. Among the 11 cities in the PRXREB, most of the traditional villages in Guangzhou and Foshan are distributed in areas below 5°, most of the villages in Liuzhou and Wuzhou are distributed in areas between 7° and 9°, and the three traditional villages in Baise are all distributed in areas above 8°. The interquartile range of the traditional villages in Baise, Yunfu, Foshan, and Wuzhou is smaller. However, the interquartile range of Laibin, Zhaoqing, and Liuzhou is larger. Guangzhou, Foshan, Nanning, and Laibin show a left-skewed distribution, and Zhaoqing, Yunfu, Chongzuo, and Guigang show a right-skewed distribution.\n\nRDLS refers to the maximum relative elevation difference within a certain area, which can reflect the environmental conditions. Based on [40], we calculated the RDLS of the traditional villages as follows:\n\nwhereis the average elevation of the traditional village,andrepresent the highest and lowest elevations of the traditional village,is the area of flat land in the traditional village, andis the total area of the traditional village. To characterize the regional differences in RDLS in China, we chose a height of 500 m in low hilly areas as the standard height for evaluating RDLS. The value of RDLS indicates the multiple of the surface relief to the height of the base mountain. If the value is less than 1, then the relief land surface is lower than the height of the base mountain.Fig 8shows that most traditional villages in the PRXREB are located in low-RDLS areas. Specifically, 55% of traditional villages are located in areas with an RDLS less than 0.25. Areas with a low RDLS are conducive to building houses and making it easier for people to travel and live. Only 10 traditional villages have an RDLS greater than 1, of which 4 villages are located in Laibin and the remaining 6 villages are located in Liuzhou.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.g008\n\nRoad network density is closely related to the level of regional economic development. Roads and transportation provide basic support for identifying the pattern of regional economic development. The distribution of major roads and rivers in the PRXREB is shown inFig 9. It can be seen inFig 9that there are obvious differences in the distribution of the traditional villages in Guangxi and Guangdong. The traditional villages in Guangxi are mainly distributed in areas with a low road density, while the traditional villages in Guangdong are located in areas with a high road density. A higher road density near a village means that it has high transportation convenience and is easier to communicate with the outside world.\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g009\n\nTo quantify the transportation convenience of the traditional villages in the PRXREB, the shortest distance from each village to major roads was calculated (Fig 10). It should be noted that, since the railways and expressways in China can only be accessed from a small number of stations, the major roads in our study only include national highways, provincial highways, and urban secondary roads and above. The results show that the average shortest straight-line distance between the traditional villages and major roads is 7.31km in the PRXREB. The average shortest distance from the traditional villages to the main road in the four cities of Guangdong is within 5km, which is generally less than the distance between the seven cities of Guangxi, indicating that the transportation convenience of the traditional villages in Guangdong is better than that of the traditional villages in Guangxi. Inconvenient transportation has prevented the traditional villages in Guangxi from being influenced by the culture of the outside world, and it has protected the local historical buildings, traditional customs, and cultural heritage. However, convenient transportation has enabled the integration of multiculturalism in Guangdong villages, promoted the development of the local economy, and improved the living environment and the quality of life of local villagers. In addition, the interquartile range of the average shortest distance from the traditional villages to the major roads in Guangzhou, Foshan, Yunfu, Wuzhou, and Chongzuo is small. The largest interquartile range is in Laibin. Guangzhou, Foshan, Zhaoqing, Yunfu, Baise, Laibin, Chongzuo, and Guigang have a strongly skewed distribution in terms of the distance from the traditional villages to major roads. Among the eight cities, Guangzhou, Foshan, Zhaoqing, and Yunfu in Guangdong show a left-skewed distribution, and Baise, Laibin, Chongzuo, and Guigang in Guangxi show a right-skewed distribution.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.g010\n\nRivers provide basic material support for human production and life, and they are also an important factor that may affect the layout of the location, landscape, development scale, and spatial distribution of the traditional villages in the region. According toFig 11, the traditional villages are mostly distributed along the main streams and tributaries of rivers, which is more notable in the Pearl River Basin and moreclusteredin the Pearl River Delta.\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g011\n\nAccording to the shortest straight-line distance analysis of the major rivers in the PRXREB (Fig 12), there are 50, 25, 13, 15, 7, and 2 traditional villages distributed within 5km, 10km, 15km, 20km, 25km, and 30km from the main river, accounting for 44.64%, 22.32%, 11.61%, 13.39%, 6.25%, and 1.79%, respectively. In Yunfu and Nanning, the interquartile range of the distance between village roads and major rivers is small. However, in Zhaoqing, Nanning, Liuzhou, Baise, and Laibin, the interquartile range of the distance between village roads and major rivers is large. Guangzhou, Zhaoqing, Yunfu, Nanning, Baise, Chongzuo, and Guigang have a strongly skewed distribution in terms of the distance from traditional villages to major rivers, and they present a left-skewed distribution. More than half of the villages are less than 10 kilometers away from the main river in a straight line; this shows that ancient villagers preferred to build their residences near rivers, which could solve not only the domestic water problem but also the inconvenient road transportation problem.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.g012\n\nRivers in Chinese history determined the growth of population centers. Rivers provided the necessary water source for ancient Chinese agricultural production and supported the production and life of a large population; rivers were important channels for transportation, commodity circulation and cultural exchange, promoting economic prosperity and population mobility; riverside areas were often flat and open, and were mostly the economic, cultural and political centers of ancient China, making them more likely to attract population concentration.\n\nThe population is an important cornerstone for the long-term existence and sustainable development of traditional villages. A population density distribution map of the PRXREB in 2023 is shown inFig 13. The result shows that most of the population was concentrated in urban areas and that the population density in Guangzhou, Foshan, and Nanning was relatively high. According to the demographic statistics released by the government (S2 Table), the populations of Guangzhou, Foshan, and Nanning were 18.83 million, 9.62 million, and 8.94 million in 2023, accounting for 29.97%, 15.30%, and 14.23% of the total population in the PRXREB, respectively.\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\n(Source of base map: the open source map data service provided by the National Platform for Common GeoSpatial Information Services (https://www.tianditu.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g013\n\nPrevious studies used the total population of cities to analyze traditional villages [38]. However, there were large differences in the population data of various traditional villages, as well as between the rural population and the entire city population. Therefore, the population density of a city cannot accurately represent the population of traditional villages. To obtain the population data of each traditional village, first, the point of the traditional village was taken as the center; then, a circular area with a radius of 2 km was obtained; and, finally, the average population density in this circular area was calculated as the population density of the traditional village. The minimum distance between villages in the PRXREB is about 2 km. If the radius exceeds 2 km, it could lead to overlapping coverage areas between some villages, so we choose 2 km as the radius of the circular area. Finally, the population densities of the traditional villages in the different cities are shown inFig 14. It can be concluded fromFig 14that the population density of the traditional villages in the cities of Guangdong is higher than that of the traditional villages in the cities of Guangxi. The population density and interquartile range of Guangzhou are the highest, followed by those of Foshan and Yunfu. The population density of the traditional villages in Baise, Wuzhou, and Chongzuo is less than 2 people per 10,000 m2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.g014\n\nThe population was the basis for the formation of settlements. A sufficient population provided conditions for the formation and inheritance of villages [41]. However, with the development of the economy, the population began to migrate to urban areas, so the population density in urban areas became relatively high. This also indicates that the current traditional villages far away from cities faced the problems of population loss and aging, which brought challenges to the inheritance of traditional villages.\n\nSocioeconomic factors significantly influence the preservation and evolution of the traditional villages in the PRXREB. It is evident that there is a relationship between the economic development of the cities in the economic belt and the spatial distribution of the traditional villages.Table 4illuminates those economically stronger cities such as Guangzhou, Foshan, Nanning, and Liuzhou, which lead in terms of economic metric, there is a higher concentration of traditional villages, representing 67.5% of the total. Conversely, regions with slower urbanization and less intensive development, such as Zhaoqing in Guangdong and Laibin in Guangxi, demonstrate a more robust preservation of traditional villages. Despite their lower GDP contribution (9.84% of the total of the 11 cities), these areas account for 19.17% of the traditional villages, emphasizing a correlation between the pace of economic development and village preservation.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.t004\n\nRegional culture and customs had a profound impact on the formation and development of traditional villages. Lingnan culture is the common cultural foundation of Guangdong and Guangxi, creating the same history, connection, language, and customs in the PRXREB, and this promoted the complementarity and integration of regional economies and improved the competitiveness of the PRXREB. Lingnan culture was divided into Guangfu culture, Chaoshan culture, and Hakka culture, and its spirit “to be a pioneer” promoted the formation and development of traditional villages with profound cultures and distinct regional features. Moreover, the PRXREB was inhabited by twelve ethnic groups, among which the Hans, the Miaos, the Yaos, the Dongs, etc., were the aborigines in the region. The population of minorities accounts for more than 80% of the residents in Guangxi. The integration and exchange of the cultures of the Han nationality and the ethnic minorities formed the unique cultures of the national-level traditional villages.\n\nHistorically, the site selection process of traditional villages in the PRXREB has been shaped by factors such as resource access, trade routes, and cultural heritage. Villages were typically located along riverbanks or near water sources to ensure access to essential resources for agricultural production and daily life. The site selection was closely influenced by natural resource factors, including the abundance of water sources, soil fertility, transportation convenience, and climate conditions. Additionally, as transportation hubs connecting different regions, the establishment of these villages was closely linked to the formation of important trade routes. These villages not only facilitated the exchange of goods and culture but also stimulated local economic development. Over time, they developed unique socio-economic structures.\n\nFurthermore, as carriers of cultural transmission, the site selection and development of villages were also influenced by cultural factors such as religious beliefs, family settlements, and the transmission of customs. These cultural elements not only shaped the spatial layout of the villages but also influenced the social relationships and economic activities of their inhabitants.\n\nWith the progress of modernization, the socio-economic conditions in the PRXREB have undergone significant changes. Many traditional villages are now facing challenges such as population decline, resource depletion, and economic stagnation. However, some villages have maintained their vitality by adapting to new economic opportunities, such as emerging industries in tourism, specialized agriculture, and handicrafts, thereby successfully achieving economic transformation. In addition, the improvement of modern infrastructure (such as transportation, communication, and public service facilities) has had a profound impact on the survival and development of traditional villages. Villages that effectively leverage new infrastructure are better positioned to integrate into the modern economic system, while those that fail to adapt—due to factors such as remote locations, poor transportation access, or population loss—are at risk of further decline.\n\nThe factors should be classified before using geographic detectors [37]. Arbitrary classifications may fail to characterize the relationship between factors and the spatial patterns of traditional villages. After reviewing the literature [38,42], the natural break method was chosen to classify all economic factors, Ele, Slope, and RDLS, and the manual method was chosen to classify the remaining factors. The classification results of all factors are shown inTable 5.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.t005\n\nThe importance of the influencing factors on the spatial pattern of traditional villages is shown inTable 6. Thevalue represents the importance of the influencing factor, and thevalue determines the result of the hypothesis test. The smaller thevalue, the more significant the result.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321646.t006\n\nTable 6shows that most factors had significant influences on the spatial pattern of the traditional villages in the PRXREB (). Most socioeconomic factors had significant influences on the spatial pattern of the traditional villages in the PRXREB. The PIUR factor had the largest influence, explaining 0.499 of the spatial patterns of the traditional villages. The following socioeconomic factors were PGDP, GDP, PIRR, PI and TI, whose contributions were 0.438, 0.348, 0.262, 0.253, and 0.168, respectively. The natural factors of distance to a road and elevation explained only 0.179 and 0.149, respectively.\n\nIn addition, natural factors were also related to the spatial pattern of the traditional villages in the PRXREB, but their influence was smaller than that of the socioeconomic factors. The factor detector illustrated that the distance to a road () was the most influential natural factor, followed by elevation (0.149). Generally, road density was positively correlated with the economy. Economically developed regions built more roads to improve transportation convenience, so the distance to the main road was smaller, and vice versa.\n\nSpecifically, urban residents’ income emerged as the most influential factor shaping the distribution of the traditional villages. Increased incomes in urban areas boost consumption in sectors such as services and tourism. The traditional villages in the PRXREB, renowned for their rich ethnic minority cultures, unique regional traits, and abundant tourism resources, attract urban visitors. This trend has spurred the growth of tourism-focused products in rural areas, enhancing both agricultural and cultural tourism, which, in turn, has boosted the tertiary and primary sectors, raising rural incomes. Consequently, factors such as GDP, PI, TI, PGDP, PIUR and PIRR are pivotal in shaping the distribution of these villages. Moreover, the growth of tourism in these villages necessitates high-quality ecological environments and infrastructure, particularly in transportation, making road accessibility a key factor.\n\nFurther analysis revealed that the interplay between various factors either amplified their collective impact on the spatial distribution of the traditional villages (Fig 15). It was found that interactions between natural and socioeconomic factors significantly strengthened their collective influence, with socioeconomic interactions proving to be more potent than natural ones. Notably, PIUR, when combined with other factors, displayed interaction values surpassing its individual impact, with all exceeding 50% in explanatory power. This suggests that PIUR’s interaction with other factors doubly enhances its impact on the spatial distribution of the traditional villages. The combined effect of PGDP and distance to a river was particularly significant (0.65), indicating a major influence on the spatial distribution of these villages. Interactions involving PGDP, PIUR, River, Road, GDP, and PI were notably strong. Even factors that individually had a lesser impact were significantly elevated through these interactions. Even the single factors with a low impact in the factor detector had a significantly improved influence after interacting with the above four factors. These results indicate that the traditional villages rely on their advantages to develop tourism, promote the development of the tertiary industry, increase the income of villagers, and drive the growth of GDP. After the local government became rich, it invested more funds in infrastructure construction, especially in road construction, thereby improving transportation convenience and the living environment, with the aim of attracting more tourists. This created greater profits and better promoted local economic development. Therefore, the effects of those factors were enhanced.\n\n(“*” indicates bi-enhancements, and “**” indicates nonlinear enhancements).\n\n(“*” indicates bi-enhancements, and “**” indicates nonlinear enhancements).\n\nhttps://doi.org/10.1371/journal.pone.0321646.g015\n\nThese findings indicate that the spatial pattern of the traditional villages in the PRXREB is not merely a consequence of individual factors operating in isolation but rather is shaped by their combined interactions. Thus, when devising development strategies for these villages, it is crucial to consider the synergistic effects of multiple factors.\n\nThe PRXREB is a significant economic region in southern China, and the distribution and development of traditional villages here are deeply influenced by both economic and environmental factors. Economic factors are the main drivers of traditional village distribution. The level of economic development directly impacts resource allocation and population movement. Traditional villages in economically developed regions tend to receive more investment and infrastructure development, attracting immigrants and diversifying economic activities. Furthermore, with ongoing economic transformation, improvements in transportation, communication, and utilities are facilitating changes in the industrial structure and economic models of traditional villages. This transformation not only alters their economic foundation but also reshapes their spatial layout.\n\nNatural factors also play a crucial role in the spatial distribution of traditional villages. Areas rich in water resources and fertile soil have fostered unique agricultural practices, making them prime locations for the establishment and development of traditional villages in the PRXREB. With increasing environmental awareness, the protection of ecological environments and the development of green economic strategies provide a foundation for the long-term sustainability of these villages. Additionally, the region’s favorable warm and humid climate supports diverse agricultural practices, further attracting farmers and influencing the spatial distribution of villages.\n\nInfluenced by both economic and natural factors, traditional villages in the PRXREB exhibit unique spatial patterns and development models. These experiences offer valuable lessons for encouraging other traditional villages to diversify their economic activities, invest in infrastructure, protect the ecological environment, and achieve sustainable development.\n\nTraditional villages are vital in the cultural aspect of China’s rural revitalization efforts [32]. The study of spatial distribution patterns and their underlying principles forms a cornerstone of geographical research [43]. This research has revealed diverse spatial distributions among traditional villages in the PRXREB, emphasizing the impact of economic, nature and transportation factors. These findings corroborate existing research that notes the ‘uneven and insufficient’ development within these regions.\n\nThe formation of traditional villages is a long and complex historical process, which often takes hundreds of years to accumulate and evolve. During these hundreds of years, natural environmental factors such as topography, climate conditions, and natural resources will affect the spatial layout, architectural style, and production and living styles of traditional villages. Socioeconomic factors such as population growth, economic development, and traffic changes will also promote the temporal and spatial evolution and transformation of traditional villages. Cultural traditional factors such as religious beliefs, folk customs, and family systems constitute the spiritual core of traditional villages, inheriting the memory of history and the essence of culture. The interaction of various factors such as natural environment, social economy, and cultural traditions has jointly shaped the unique style and profound heritage of traditional villages.\n\nThe analysis reveals that harsh natural conditions indirectly influence village distribution by constraining regional economic development, which is consistent with the results of previous studies [44]. Specifically, challenging environmental features can directly impede agricultural productivity and other economic activities. These natural limitations typically result in poorer local economies, which affect population density and residential choices, thereby altering the spatial distribution of traditional villages. Although natural conditions are primary constraints, the actual influences on village distribution stem from the resulting economic and social conditions, such as limited employment opportunities and inadequate infrastructure [45].\n\nDespite the potential of modern technology to mitigate some adverse effects of natural conditions, these improvements often necessitate significant economic investment and technical support [12]. In economically underdeveloped regions, the capacity to adapt to and modify the environment is limited, and the adverse impacts of natural conditions remain significant. Consequently, a complex interaction between natural and socio-economic factors not only affects the immediate spatial distribution of villages but also shapes the region’s social structure, cultural landscape, and sustainable development through its influence on long-term economic paths [46].\n\nIn conclusion, the interplay between natural environments and socio-economic factors forms a complex system essential for studying the spatial distribution of traditional villages. Future research should employ multivariate statistical methods to delve deeper into the correlations and mechanisms of these factors, enhancing our understanding and aiding in the preservation of these cultural and historical heritages [47].\n\nDeveloping rural tourism uniquely tailored to these areas is seen as an eco-friendly strategy for conserving traditional rural landscapes [10], especially in less developed regions of China. This strategy plays a pivotal role in shaping human settlement environments, reflecting dynamic changes in economic growth and material culture brought about by rural tourism. However, the rapid expansion of distinct rural tourism, often undertaken without sufficient planning, is encroaching upon ecological, productive, and living spaces [48], leading to uneven distribution of public resources, ecological degradation, and rampant commercialization. These issues amplify the conflicts between uniformity and uniqueness in rural settings, potentially destabilizing traditional rural environments and endangering the preservation of rural cultural heritage [47,49]. It is crucial to balance tourism development with the preservation of traditional rural characteristics to mitigate new conservation challenges related to traditional architecture and culture.\n\nBased on a spatial analysis and geographical statistics, the spatial patterns of traditional villages in the PRXREB are quantitatively analyzed and determined, and the influences of natural and socioeconomic factors alone and in combination on traditional villages are explored. Finally, the measures of traditional village protection and revitalization are discussed. The main conclusions are as follows:\n\nHowever, the study has limitations that future research should address. Future research should leverage advanced methods such as big data technology to gather more detailed, micro-level data. This could involve analyzing mobile signal data, social media data, and POIs to gain insights into tourism trends, population movements, and settlement densities, thus enriching data sources and enhancing the study’s explanatory depth [50]. Additionally, there is a gap in knowledge regarding the interplay of various factors at specific rural sites [44]. Shifting the focus from urban to rural areas, especially under rural revitalization strategies, is essential to examine the spatial interconnections between rural tourism and living environments. Furthermore, expanding the temporal dimension in the study of influencing factors will help to uncover the spatiotemporal patterns of traditional rural areas and the intensity of various spatiotemporal influences.\n\nhttps://doi.org/10.1371/journal.pone.0321646.s001\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321646.s002\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321646.s003\n\n(XLSX)",
    "category": "earth_sciences"
  },
  {
    "title": "Economic suitability of direct seeded rice across different geographies in India",
    "authors": "Shiladitya Dey, Kumar Abbhishek, Suman Saraswathibatla, Debabrata Das, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0321472",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321472",
    "content": "Puddled transplanted rice (PTR) is being replaced by dry direct-seeded rice (dDSR) to address manpower, water, and agricultural costs. The economic suitability of dDSR in different agro-climatic regions limits its widespread adoption. We use plot and household data to estimate the impact of dDSR adoption in four Indian rice-growing states. We first used propensity score matching (PSM) to assess how dDSR adoption affected operation-wise cultivation costs, paddy yield, and net income. The yield effect on DSR adoption was estimated using endogenous switch regression (ESR) to account for observed and unobserved heterogeneity. Both PSM and ESR-based results show that DSR adoption may increase paddy yield in Uttar Pradesh, Andhra Pradesh, and Telangana and decrease it in Madhya Pradesh, but net income from paddy farming increased significantly (Rs5009/acre to 8134 based on different locations) in all four states. Adopting dDSR helps resource-poor Indian farmers reduce paddy production costs and increase income. Therefore, Central and State governments must implement policies and strategies to encourage non-adopters to adopt dDSR.\n\nCitation:Dey S, Abbhishek K, Saraswathibatla S, Das D (2025) Economic suitability of direct seeded rice across different geographies in India. PLoS ONE 20(4):\n           e0321472.\n        \n        https://doi.org/10.1371/journal.pone.0321472\n\nEditor:Jaipal Singh Choudhary, ICAR Research Complex for Eastern Region, INDIA\n\nReceived:September 27, 2024;Accepted:March 6, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Dey et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nRice is essential for global food security, serving as a staple for half of the world’s population. [1]. India leads in paddy cultivation area and ranks second in production. India produces 21% of global rice [2]. Global demand for milled rice is projected to increase by 96 million tonnes by 2040 compared to 2015 [3]. Rice production must rise for food security and sustainability. Furthermore, enhanced production must be ecologically sustainable, utilizing less water, labour, and agrochemicals. This can be accomplished by bridging rice output gaps and conserving natural resources like soil and water, particularly in India’s Indo-Gangetic Plain and Southern States.\n\nGroundwater is used extensively in conventional paddy cultivation. Puddled Transplanted Rice (PTR) involves physically transplanting paddy into tilled and puddled soil. Evaporation and percolation consume 60–80% more water than required by the crops, raising paddy cultivation costs [4,5]. Consequently, water-efficient, ecological, and cost-effective paddy cultivation necessitates water conservation [6]. Dry-direct seeded rice (dDSR) saves water in paddy production, where seeds are directly sown in the main field and established by pre-monsoon rainfall [6]. The majority of research shows that dDSR reduces paddy water use by 35–57% compared to PTR, although the total volume of saved water varies greatly with soil type [5–7]. Nevertheless, there is apprehension that water reduction lowers dDSR yield [8,9]. Therefore, it is crucial to determine whether dDSR adoption is economically viable in different geographies with different soil types and properties.\n\nDSR productivity is often lower than PTR due to panicle sterility, poor crop stand, micronutrient deficiencies, higher weed pressure, and root-knot nematodes. Conversely, research also reports that DSR yields 2–3 t ha− 1more grain than PTR due to improved panicle number, test weight, and lower sterility percentage [10,11].Table 1encapsulates these conflicting data, indicating that DSR may not consistently outperform PTR in analogous rice ecologies. Therefore, it is essential to ascertain the economic and yield viability of DSR across various geographies.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321472.t001\n\nSuch performance-based effectiveness of dDSR has been further reported in various Indian agro-climatic zones [16]. In summary, dDSR is a promising technology in rice ecologies; nevertheless, soil type, water management, and climate may constrain its efficacy [17–20]. We observed that most of the studies compared PTR and DSR irrigation water savings and yield using experimental plots with a mention of long-term changes in soil chemical and physical properties, greenhouse gas emissions and global warming potential [21–26]. While extensively examining the various impacts of DSR on environmental and crop performance, studies have notably failed to ascertain whether resource-constrained small and medium farmers may benefit from DSR compared to PTR. Moreover, the suitability of DSR across various agro-climatic situations from an economic standpoint is in question. This study evaluates DSR establishment methods in India’s four rice-growing agro-climatic zones. Our plot-level data comes from Uttar Pradesh (UP), Madhya Pradesh (MP), Andhra Pradesh (AP), and Telangana (TS). This study enriches the current literature in three ways. First, it utilises farm-level survey data to evaluate the effects of DSR on rice productivity, operational cultivation costs, and net revenue, addressing the limitations of experimental plot data that may not correctly represent the realities of paddy farmers. [27–30]. Second, endogenous switching regression accounts for observed and unobserved heterogeneity [31]. Third, the study evaluates DSR’s economic viability using yield, income, and cultivation costs for four agro-climatic zones. We report that we could not find any such analysis of the DSR’s economic impact using survey data from four different agro-climatic conditions.\n\nThe decision to adopt the DSR method is a binary choice for the farmer. Farmers will use the technology if the net gain from adopting DSR is greater than not adopting it. The farmers’ net income from adopting DSR compared to non-adoption is represented as(Equation (1). Ifindicates that the farmer’s net gain from adopting DSR is greater than the benefit from not adopting it. However,is not possible to be measured directly. Nonetheless, it can be expressed as a function of quantifiable components inside the latent variable model described below:\n\nwhereis a binary variable equal to 1 if the household has adopted the dDSR and 0 if it has not. The coefficientαrepresents the parameters that need to be measured.represents the characteristics of households and farms in vector form. The error termis assumed to follow a normal distribution. Equation (2) illustrates the probability of implementing the DSR establishment method:\n\nHere,Grepresents the cumulative distribution function for. Regression models such as logit and probit are typically derived based on the assumptions about the functional form ofG. Various socioeconomic and demographic parameters, yield, and net revenue from production are expected to influence the adoption of DSR technology. In order to establish a connection between the decision to adopt DSR and the possible consequences of adoption, we will examine a risk-neutral production system that aims to maximize net return  ∋ . This system operates in a competitive market for both output and input and utilizes a single-output technology that is quasi-concave in the vector of variable inputs,H. This can be expressed as equation (3):\n\nRis the selling price of the paddy,Pis the expected production level,Lis a common vector for input costs, anddescribes the attributes and features of households and farms. The net return from adopting DSR can be represented as a mathematical function of the choice of DSR adoption K, the output price, input variables, and household features, as shown in Equation (4).\n\nEquations 4 suggest that the decision to adopt DSR technology, output and input pricing, and household and farm characteristics can affect input demand, net return, and farm productivity.\n\nThe PSM method can offer an impartial evaluation of the impact of the treatment (i.e., adoption of DSR), provided that the outcomes are not influenced by the assignment to treatment, given the pre-treatment baseline covariates. The PSM approach primarily quantifies the impact of the treatment on the population that received it, as represented by equation (5).\n\nWhere  ∀  is the average treatment effect on treated (ATT),indicates the outcome values of the DSR adopters, andis the value of the same variables for non-adopters. However, the study does not estimate. Instead, the study measures the differencebetweenand. Hence,acts as a potential bias estimator.\n\nThe PSM approach can mitigate the sample selection bias when experimental and/or panel data are unavailable [32]. The PSM model uses conditional probability to determine the likelihood of farmers adopting DSR technology depending on their pre-adoption characteristics [33]. The PSM model relies on the unconfoundedness assumption, also known as the conditional independence assumption. This assumption implies that, after controlling forE, DSR technology adoption is random and unrelated to the outcome variables. PSM can be represented by Equation6.\n\nWhereis the indicator for DSR adoption, andEis the pre-adoption attributes. The conditional distribution ofEin givenis the same in both DSR adopters and non-adopters.\n\nThe PSM technique does not necessitate making assumptions about the functional form, which involves describing the relationship between outcomes and predictors of outcomes. The primary limitation of the PSM technique is the assumption of unconfoundedness. Even after conditioning, there may still be systemic variations in the outcomes of non-adopters and adopters due to unmeasured baseline variables. However, the PSM technique allows checking the specification to eliminate biases that exceed the average.\n\nOnce the propensity score (PS) has been established, the average treatment effect on the treated (ATT) can be calculated using equation7:\n\nVarious matching strategies can be employed to match adopters with non-adopters who have similar PS. This study utilizes nearest neighbor matching (NNM), kernel-based matching (KBM), and radius matching (RM) to assess the reliability of the results.\n\nPSM method reduces selection bias caused by observables. However, it does not affect selection bias produced by the unobservable. The PSM method limits conclusions to individuals or farmers whose attributes are present in both the sample and control groups. In this study, we aim to measure the effects of the adoption of DSR over PTR methods on costs, productivity, and income through cross-sectional household data. It is crucial to mention that, like in past research, in this study, the treatment and control groups are not randomly allocated [34]. Smallholder households may self-select into the treatment group by adopting DSR, an example of endogeneity and self-selection. The second concern is estimating the impact of the adoption of DSR through an empirical method. However, in our case, we anticipate that household and farm characteristics may affect DSR’s adoption, which further influences outcome variables.\n\nThe Endogenous Switch Regression (ESR) model can overcome the abovementioned concerns associated with impact assessment. The ESR model treats the adoption of DSR as a regime shifter. Moreover, ESR considers the observed and unobserved variations among smallholders in the two adoption schemes. Two steps make up the ESR regime. An initial step is a binary choice criterion function or selection equation. In such a situation, the smallholder will evaluate the available resources and management alternatives before deciding whether to adopt DSR. The farmer matches the expected utility of DSR adoption,, to the expected utility of PTR (or Conventional method). Farmers will adopt DSR ifand will not adopt if.is the adoption dummy variable that is unobservable, but we do observe. Initially, we will estimate with probit (using Equation8)\n\nThe vectorsinclude farm and farmer’s socioeconomic and demographic attributes, ∂  is the vector of parameters to be measured,is a random error. In the following step, using the findings of the criterion function, we specify two regime equations that explain the outcome variable of interest. The link between a vector of explanatory variablesWand the outcomePmay be expressed as. More precisely, there are two distinct regimes (Equation9):\n\nWhereγandδare parameters to be measured. Moreover, variables underandare allowed to overlap, and error termshave tri-variate normal distribution with zero mean and non-singular covariate matrix [35]. The absence of simultaneous observation of Regime 1 and Regime 2 results in an undefined covariance between, and. Furthermore, the expected values of, andare not zero due to the correlation between the error term of the selection Equation8. We assume that( ∂  is estimable only up to scalar).andare variances of the disturbance term used in Equation 9. Moreover,andare covariance ofandand covariance ofandrespectively. The correlation between the error terms in the selection Equation (8) and the regime Equation (9), which are assessed as truncated error terms, causes the expected values of the error terms in Equation (9) to be non-zero [35]. The expected value is calculated as the product of the variance and Inverse Mills Ratios (IMRs) assessed at, denoted asand, respectively, in Equations10and11.\n\nThe ESR model can be implemented using a two-stage approach, where regime equations incorporate IMRs. In our investigation, we employ the full information maximum likelihood technique described by Lokshin & Sajaia [36]. For the ESR model to be accurately stated, the factors influencing the selection equation (Equation8) must include at least one instrument. Additionally, the factors influencing the outcome variables in equation (Equation9) should be correlated with the adoption of DSR but not directly correlated with the outcome variables. The ESR model’s conditional expectations compare the expected outcome variables of DSR adopters and non-adopters in four hypothetical counterfactual circumstances. These cases involve scenarios where adopter smallholders did not adopt, and non-adopter smallholders did adopt DSR. According to Noltze et al. [37], the following four scenarios can be summarized as:\n\nDSR households with adoption (observed):\n\nDSR households without DSR adoption (counterfactual):\n\nPTR households without adoption (observed):\n\nPTR households with adoption (counterfactual):\n\nIn addition to the marginal impacts ofWon crop yield and cost of cultivation, we are aiming to determine the treatment impact of DSR adoption. According to Greene [30], Fuglie and Bosch [35], and Alene and Manyong [38] equations 12(a)–12(b) can be utilized to calculate the overall impact of adopting DSR (average treatment effect on the treated, or ATT) and the average treatment effects on those who did not adopt DSR, i.e., the average treatment effect on untreated (ATU). Moreover, we can obtain ATT and ATU from Equation13and Equation14.\n\nFace-to-face questionnaire surveys were implemented at the participants’ residences or fields to collect the data. Verbal consent was obtained from all respondents before the interview. Verbal consent was obtained for two reasons: First, it was anticipated that a substantial number of the respondents would be illiterate and apprehensive about signing consent documents. Secondly, the socioeconomic survey did not collect biological data or tissues or human samples for clinical trials. The interviewers clarified the procedure and emphasized that the subjects’ participation was voluntary and that the data collected would be used for research purposes.\n\nThe data used in this study is derived from the households of farmers surveyed in Uttar Pradesh (UP), Madhya Pradesh (MP), Andhra Pradesh (AP), and Telangana State (TS), the four major rice-producing states in India. In these states, labor availability is among the lowest compared to other states, so the DSR method may prove viable and practical. A multi-stage sampling procedure (from state to district to village to farmers) was implemented for the face-to-face questionnaire survey. A survey was conducted on 537 farmers from four different states. Certain surveyed farmers implemented DSR and PTR on distinct plots, whereas others exclusively utilized DSR or PTR on their respective plots. We take each farm or plot as a separate establishment for the analysis done in the paper. In UP, there were 155 DSR plots and 197 PTR plots; in MP, there were 162 DSR plots and 141 PTR plots; in AP, there were 133 DSR plots and 217 PTR plots; while in TS, there were 197 DSR plots and 205 PTR plots. Our plot-level analysis for yield and cost estimation has 1407 observations.Fig 1shows that, across the location, among the surveyed households, 46.5–56% of farmers have adopted the DSR practice for producing paddy in the Kharif season.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321472.g001\n\nThe results for descriptive statistics for socioeconomic variables show that higher education, access to extension services (like agricultural officer/expert visits, agricultural university and Krishi Vigyan Kendra and Krishi Mela services), and community organization membership promote DSR adoption in all four states, regardless of age (Table 2). Nonetheless, if irrigation is not an issue, farmers choose PTR. The DSR approach (Rs.719.5/acre) is 79% less expensive than the PTR method (Rs.3420.5/acre) for land preparation, irrespective of location, owing to reduced tillage operations. The costs of establishing DSR and PTR crops (sowing and transplanting) differ significantly by region. DSR seeding incurs a cost of Rs.1260 per acre, almost one-third of the Rs.3787 per acre required for PTR transplanting. DSR incurs reduced seed and seed treatment expenses (43.5%) compared to PTR owing to diminished seed rates. DSR incurs higher expenses for weeding and pest management than PTR. A 10% increase in weed control cost in DSR enhances paddy yield by 2.72%, 2.82%, 2.83%, and 3.01% in UP, MP, AP, and TS, respectively. However, a similar increase in weed control costs in PTR results in a 1.2%, 1.0%, 1.01%, and 1.1% increase in paddy yield in UP, MP, AP, and TS, respectively. Nevertheless, DSR weed and pest management expenses exceed PTRs by 6.4% and 19.2%, respectively. DSR plots require less family and hired labor (13.4 and 29.3 days/acre) than PTR plots (15.8 and 35.7 days/acre). DSR is less expensive to cultivate than PTR in UP (23.45%), MP (33.1%), AP (19.4%), and TS (38.7%). The 10% increase in fertilizer cost enhances the paddy yield by 1.44%, 2.12%, 3.51%, and 3.66% in DSR. Cost savings are maximized in land preparation, sowing/transplanting, seed rate, and seed treatment. Furthermore, our results show that farmers prioritize yield when selecting new technologies or varieties in areas of moderate production. DSR plots produce 1777 kg/acre less in MP than TPR plots, which yield 2043 kg/acre. In UP, AP, and TS, paddy yields increased by 3.1%, 5.7%, and 6.4% in DSR compared to TPR.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321472.t002\n\nPrior to evaluating the effects of DSR adoption, it is necessary to ensure that the distribution of relevant variables is balanced between adopters of the DSR establishment technique and non-adopters. The comprehensive outcomes of the covariate balancing test for each state, both pre- and post- matching are presented inTable 3. In PSM, the standardized mean difference for all covariates is decreased by 32% to 46%, regardless of the matching algorithm employed. It signifies a significant decrease in overall bias achieved via matching. Furthermore, upon matching, the ρ-values of the likelihood ratio tests indicate that the joint significance of covariates is rejected, whereas it was not rejected before matching. Following matching, the pseudo-R2values for all three matching algorithms decrease substantially, irrespective of the states. The low pseudo-R2, insignificant ρ-values of the likelihood ratio test, and low mean standardized bias suggest that the propensity score effectively achieves a state of equilibrium in the distribution of covariates between the two groups (DSR adopters and non-adopters).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321472.t003\n\nThe average impact of DSR adoption in different geographies (UP, MP, AP, and TS) is estimated using the PSM method. The study uses three matching algorithms, i.e., nearest neighbor matching (NNM), kernel-based matching (KBM), and radius matching (RM), to measure the average treatment effect on treated (ATT). ATT measures the difference in outcomes between DSR adopters and non-adopters.S1-S4 Tablesrepresents the impact of DSR adoption on the cost of cultivation, yield, and income for the UP, MP, AP, and TS, respectively. The results support our findings and inferences in descriptive analysis.\n\nTable 4shows the comparative impact of DSR adoption in 4 different geographies. The results indicate that land preparation savings are highest in TS (Rs3480/acre) and lowest in AP (Rs1586/acre). The seed and seed treatment cost is also saved (Rs279/acre to Rs545/acre based on the location) in DSR. This trend is found in all four geographies. In PTR, the seed rate (25–30 kg/acre) is 2.5 to 3 times higher than DSR (8–10 kg/acre). Hence, farmers invest more in PTR seed costs than DSR.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321472.t004\n\nFarmers save the crop establishment cost of Rs1580/acre to Rs3172/acre based on the location by adopting DSR. We observed that the saving is maximum in MP and lowest in UP. Nevertheless, the cultivation cost in PTR exceeds that of DSR irrespective of geographies. The additional savings in crop establishment are higher in TS and AP than in UP and MP. In all the locations except MP, fertilizer costs play an insignificant role in the PTR and DSR methods. In MP, adopters of DSR experienced less fertilizer cost of Rs772/acre due to improved nutrient efficiency with split application than DSR non-adopters.\n\nIrrigation costs across all locations are significantly lower in DSR than in PTR. The overall water requirement in DSR is 30–50% less than in PTR, resulting in less irrigation cost in DSR than PTR. Unlike irrigation, the plant protection costs (weed and pest control costs) are higher in DSR. Results also indicate that farmers with DSR adoption can save 9.33 to 11.20 man-days (Hired and Family labor) compared to DSR farmers. Our findings show that the total cost of cultivation is significantly less (Rs5043/acre to Rs7718/acre) in DSR than in conventional PTR farming. Except for MP, an increased yield of 58 kg/acre, 92 kg/acre, and 126 kg/acre under DSR is reported in UP, AP, and TS, respectively. In MP, the yield under DSR is significantly lower (179 kg/acre) than PTR. Nevertheless, results indicate that the net income from paddy cultivation using the DSR method is significantly higher, irrespective of different geographies. For states like UP, MP, and AP, the net income from DSR adoption varies between Rs5009/acre to Rs6237/acre, while in TS, the net income from DSR adoption is Rs 8133/acre higher than PTR.\n\nThe findings identified that the PSM technique may be biased due to unobservable variables. Consequently, this investigation has implemented the FILM-based ESR model to mitigate the inherent biases and reliability issues linked to the PSM model.Table 5illustrates the average treatment effect of DSR adoption on paddy yield in both actual and counterfactual scenarios. The data is derived from the ESR method. Compared to non-DSR adopters, DSR adopters attain increased yields in UP, AP, and TS. However, conventional PTR farmers of MP achieve better yields (10.69%) than DSR farmers. In UP, AP, and TS, if DSR non-adopters decide to adopt DSR, their yield can improve by 3.58%, 3.15%, and 4.49%, respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321472.t005\n\nTable 6provides parameter estimates for the yield effects of the DSR adoption on a double-log specification of the Production Function. The Cobb-Douglas specification could not be rejected, as indicated by the Wald test in the lower panel ofTable 6. The estimated covariance terms are also displayed in the bottom portion ofTable 6. Statistical analysis indicates heterogeneity, which could result in biased estimates if not corrected. The IMR coefficient is negative, indicating that the estimates would have been downward biased if the correction had not been made. In addition to the inputs used in rice cultivation, the analysis considers variations in several socio-economic and demographic explanatory variables (e.g., age, farm experience, assured irrigation facility, education of the decision maker, etc.) in our criterion (selection) model, to minimize the biases in outcomes. The criterion function (selection equation in the model) and the regime equations are concurrently estimated in the ESR method to determine whether an observation belongs to a particular regime. The criterion equation includes all explanatory and instrumental variables [36]. In this study, we employed 11 socio-economic and demographic variables (Table 6) as instruments in the criterion function.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321472.t006\n\nThe parameter estimates of the criterion function are presented inTable 6. Costs associated with land preparation, seed and seed treatment, crop establishment, irrigation, weed control, fertilizer, and labor costs are the significant factors influencing the adoption of the DSR method across different geographies (UP, MP, AP, and TS). Furthermore, the adoption of DSR is significantly influenced by factors such as the farmer’s education, community organization membership, assured irrigation, and extension service.\n\nThe outcomes indicate that in the DSR method, the weed control cost has the highest positive elasticity. A 10% increase in weed control cost enhances paddy yield by 2.72%, 2.82%, 2.83%, and 3.01% in UP, MP, AP, and TS, respectively. The cost of weed control also has a positive, albeit minor, impact on rice production under PTR. A 1% increase in weed control costs results in a 0.12%, 0.10%, 0.11%, and 0.11% increase in paddy yield in UP, MP, AP, and TS. Like weed, irrigation cost also shows a positive elasticity with paddy productivity across all states. Similarly, the fertilizer cost shows positive elasticity with yield across all the locations. A 10% increase in fertilizer cost enhances the paddy yield by 1.44%, 2.12%, 3.51%, and 3.66%. In AP and TS, the land preparation costs in DSR also show positive elasticity with paddy yield: a 1% increase in land preparation cost augments the productivity of paddy by 0.07% and 0.18% in AP and TS. The DSR method exhibits positive elasticity for total labor: a 1% increase in total labor cost results in a rise in paddy yield of 0.22%–0.23% across all geographies.\n\nFarmers prefer DSR over PTR because of reduced cultivation expenses. However, increased weed pressure and the necessity for more frequent irrigation sometimes diminish its attractiveness. Lack of capacity building among farmers, including low educational attainment and limited access to extension services, may explain MP’s lower yield under DSR adoption [39,40]. However, the paddy yield increases with DSR adoption in UP, AP, and TS. Several South-Asian studies support this finding [30,39,41–43]. According to these studies, puddling in PTR can lead to loss of soil structure and make the soil compact, negatively affecting root growth and water infiltration. Conversely, in DSR, the plant’s root growth is more profound and stronger as they are not confined to the hardpan. This can lead to better nutrient uptake, overall plant health, and increased yield. Additionally, the practice of alternate wetting and drying irrigation methods in DSR enhances microbial growth within the plant root environment due to the oxygenated rhizosphere. The interaction between microbes and plant roots further boosts the plant’s access to nutrients, resulting in improved biological yield compared to PTR. Conversely, maintaining flooded conditions in fields restricts the growth of aerobic microorganisms in the rhizosphere.\n\nBesides crop physiology and nutrient dynamics, other agronomic practices influence farmers’ decision to adopt DSR. The parameter estimates of the criterion function indicate that costs related to land preparation, seed and seed treatment, crop establishment, irrigation, weed control, fertilizer, and labor are among the significant factors influencing the adoption of the DSR across the geographies. Irrigation cost exhibits a positive elasticity with paddy productivity across all states. Optimum irrigation in DSR plots based on crop requirements and water availability in soil contributes to increased paddy yield. Frequent irrigation mitigates crop water stress and reduces weed growth effectively. Our observations in this study comparing different geographies indicate that the capacity of soil to retain water strongly influences the decisions for determining the quantity and timing of irrigation. UP and MP possess sandy loam and black soil, which exhibit enhanced water-holding capacity. Consequently, these regions have reduced irrigation culture compared to AP and TS, which feature red lateritic soil with lower water-holding capacity. Therefore, compared to UP and MP, an increase in irrigation adds to input costs but gets compensated by the likelihood of paddy yield in AP and TS. However, if we see the conventional PTR, intensive land preparation activities, including primary and secondary tillage, puddling, harrowing, and leveling, in order to maintain a ponded water level of 3–5 cm for a duration of up to 90–100 days (for medium duration paddy variety) enhances the land preparation and irrigation costs. While DSR adopters apply intermittent water through alternate wetting and drying, depending on soil moisture conditions. Thereby, the total water requirement in DSR is 30–50% lower than that of PTR, leading to reduced irrigation costs in DSR compared to PTR.\n\nOverall, the costs of different intercultural operations compared to the improvement in crop yield are the fundamental determinants for adoption. If the addition of costs results in significant improvement in grain yields, farmers may invest upfront. However, while conducting this study, we observed a peculiar case where the crop yield under DSR dropped considerably more than PTR in the state of MP. This can be attributed to compacted heavy soil conditions resulting in complications such as delayed emergence, an increased risk of seedling diseases, and root rot. The drudgery involved growing the nursery on a designated piece of land, transporting the nursery to various plots, and transplanting the seedlings, further enhancing the cost of paddy cultivation PTR. The DSR method does not necessitate extensive land preparation activities, which have both positive and negative aspects. The minimal land preparation and lack of transplanting activities in DSR contribute to significant savings in working hours and costs for hired and family laborers. However, the absence of intensive tillage activities and the implementation of alternate wetting-drying irrigation practices contribute to elevated weed pressure in DSR. Consequently, both pre-emergence and post-emergence weedicides are applied in DSR plots to protect the seedlings from weed competition and nutrient depletion. Pest attacks are also more prevalent in DSR than in PTR. Hence, in DSR, farmers implement measures to safeguard seeds against insect and pest infestations to enhance germination rates and crop yield. Pre-treatment of seeds with insecticides and pesticides increases the overall seed treatment costs associated with DSR. The states in peninsular regions of India can compensate for the costs mentioned above through a markedly higher DSR yield than PTR. Among the four states, DSR is most profitable in TS. The most net return from DSR in TS can be attributed to larger landholdings and enhanced mechanization, effectively lowering labor costs. Additionally, improved market channels and price realization attributed to making DSR more profitable in TS than in other regions.\n\nWe also observed that the adoption of DSR is further influenced by socio-economic and demographic variables [36]. Farmers with more formal education are more likely to understand the information provided by agricultural experts and extension agents, enabling them to make well-informed judgments on new technology adoption. In addition, farmers with a formal education are more adept at forecasting the possible consequences of future technologies on agricultural productivity and financial viability. Therefore, there is a positive association between the educational level of the household head and their willingness to adopt innovative and sustainable farming practices, such as DSR. This observation is consistent with the findings published by Duraisamy [44], Idrisa et al. [45], and Huffman [46]. Adeoti [47] and Nonvide [48] found that farmers with greater levels of education demonstrate improved capacities to adopt and efficiently utilize sustainable technology.\n\nSimilarly, membership in a group or organization is a reliable measure of social capital. Social networks facilitate the exchange of knowledge and promote peer-to-peer learning among farmers. Social organizations functioned as an informal means of providing insurance during periods of distress. When group members endorse deploying new technology, it creates a favorable mindset among farmers, facilitating technology acceptance. This could explain why farmers with a group membership are more likely to adopt DSR practices. Farmers also obtain information regarding the most recent technologies through interaction with the extension agent. Farmers can address any uncertainties related to the technology by establishing direct communication with extension personnel. The guidance offered by extension agents on optimizing yields and reducing cultivation costs effectively encourages farmers to adopt DSR in paddy farming.\n\nAssured irrigation negatively affects the adoption of DSR technology. It indicates that farmers with assured access to irrigation choose PTR. The DSR method is primarily designed to conserve water in rice cultivation, minimize methane emissions from paddy fields, and improve soil health. Nevertheless, farmers who have assured irrigation are mostly unaware of the detrimental impacts of flood irrigation on soil and the ecosystem [47]. Furthermore, in some states, the state government offers electricity for irrigation at a reduced cost or for free, which motivates farmers to continue flood irrigation based on the PTR method rather than adopt the water-saving DSR method.\n\nThe findings also suggest that an increase in the use of crop insurance has a favorable effect on the adoption of DSR for the farmers in UP and AP. Farmers who adopt DSR instead of conventional PTR also believe that if their crop yield is negatively affected by their lack of proficiency in adopting the new technique, crop insurance will offer an extra layer of protection against the resulting losses. Utilizing a certain risk management instrument encourages the adoption of other risk management solutions.\n\nThe results inTable 6also suggest that landholding size positively impacts the adoption of DSR in MP and TS. This discovery is consistent with the results of prior investigations. The farmers in UP and AP are mostly smallholders. They believe that they cannot attain food security and expected income if they lose their average yield due to adopting new technology. However, in both states, the yield in DSR is higher than that of PTR. Still, the adoption of DSR is low compared to PTR. This is because delay in monsoon causes low seed germination. Sometimes, intense rainfall within 15–20 days after sowing damages both seed and seedlings. In such a scenario, farmers need to invest more in seed procurement and additional labor for gap-filling. Moreover, socio-psychological factors, like the risk of losing yield if they fail to control weeds, risk of social exclusion from the community if they adopt a new practice, and difficulty in machine harvesting as DSR plots mature 10–15 days earlier than PTR, restricts the farmers to adopt DSR. Meanwhile, large landowners in MP and TS allocate their land under both interventions (PTR and DSR). They are confident that they can recoup their income and guarantee food security through PTR despite the potential decrease in yield as a result of the implementation of DSR, given their relatively large farm size.\n\nThe intricate linkage of weed control with irrigation scheduling exhibits the highest positive elasticity in DSR adoption. Effective management of weeds, especially during the seedling phase, is done by applying pre and post-emergence herbicides while maintaining the moist conditions for up to 30 days to achieve optimum results with manual weeding whenever required. However, the expense associated with weed control exerts a beneficial, though limited, influence on rice production within the context of PTR. Similarly, the fertilizer cost exhibits a positive elasticity with yield across the north Indian states, which can be referred to as highly fertile soil compared to AP and TS. Therefore, an increase in the application rate of fertilizers, especially nitrogen-based fertilizers, significantly improves paddy yield in peninsular Indian states.\n\nWe also observed that the land preparation costs in DSR exhibit a positive elasticity with crop yield in both AP and TS. Farmers in AP and TS implement permanent bunds, conduct laser land leveling, and occasionally engage in mild puddling to enhance soil water-holding capacity. This is necessitated by the lower water holding capacity and undulating terrain in these regions compared to UP and MP. The DSR method demonstrates a positive elasticity concerning total labor. In DSR, the labor cost exhibits negligible elasticity concerning paddy productivity, indicating that labor productivity rises with the adoption of DSR.\n\nThe yield of rice in DSR is further influenced by both the quantity and quality of the seeds chosen by the farmer. Suboptimal seed rate and quality can result in reduced germination rates. Treated seeds, whether through physical, chemical, or biological methods, are preferable for DSR as they protect against avian consumption or damage to the seeds, enhance germination rates, and support early-stage growth. Failure to select quality and suitable seeds under DSR can significantly reduce yields across various geographical regions. Kumar & Ladha [29] and Yadav et al. have determined that an optimal seed rate is essential for achieving optimal paddy production in DSR. Exceeding the optimal seed quantity may result in a decrease in yield. The increased density of seedlings or plants within a given area leads to heightened competition, subsequently reducing overall yield.\n\nOur study examines the adoption of DSR among farmers in four Indian rice-producing states using the PSM approach. The ESR method measures the effects of selection bias and heterogeneity caused by DSR, allowing for a more comprehensive understanding of its economic suitability in different agro-climatic geographies. We conclude that adopting DSR can lead to variations in paddy yield depending on agro-climatic conditions. However, net income from paddy farming experienced a significant increase regardless of state/agro-climatic conditions. Increased investments in weed management, irrigation, and fertilizer can lead to higher yields in DSR. Socioeconomic variables such as education, community organization membership, extension services, and crop insurance positively impact DSR adoption, while assured irrigation negatively affects it. Our study points out that India has started facing significant challenges in water and manpower availability at critical periods of agricultural operations, which are key to agricultural development, particularly in paddy production. We wish to raise the alarm that the water table is steadily decreasing in many northern and peninsular India regions. Therefore, it is essential to advocate for adopting resource-conserving technologies like DSR to guarantee food security for present and future generations. Policymakers should create provisions for incentives to promote DSR adoption, prioritizing the development of skill sets in weed management through optimal management techniques. Our study picks certain peculiar though important repercussions like the effect of subsidies on power for agricultural uses and the role of the socio-psychological state of mind in the adoption of DSR. For the first time, this study reported both aspects of DSR impact, allowing the audience to better guide their decisions. However, the study has limitations, including its inability to account for variations in seed quality, labor skills, soil health metrics, irrigation water quality, and land degradation. Future research should focus on linkages between rural economies, extension approaches, and social networks, examine environmental consequences, soil properties, and productivity improvements resulting from DSR, and analyze yield and cost implications.\n\nEffect of adopting DSR practices on income, production, and expenses associated with paddy cultivation in Uttar Pradesh.\n\nhttps://doi.org/10.1371/journal.pone.0321472.s001\n\n(DOCX)\n\nEffect of adopting DSR practices on income, production, and expenses associated with paddy cultivation in Madhya Pradesh.\n\nhttps://doi.org/10.1371/journal.pone.0321472.s002\n\n(DOCX)\n\nEffect of adopting DSR practices on income, production, and expenses associated with paddy cultivation in Andhra Pradesh.\n\nhttps://doi.org/10.1371/journal.pone.0321472.s003\n\n(DOCX)\n\nEffect of adopting DSR practices on income, production, and expenses associated with paddy cultivation in Telangana.\n\nhttps://doi.org/10.1371/journal.pone.0321472.s004\n\n(DOCX)\n\nWe acknowledge the support of our field team for collecting primary data to support this study.",
    "category": "earth_sciences"
  },
  {
    "title": "Exploring temperature and humidity environment combined with air quality index, black carbon, the short-term effect of combined exposure on respiratory disease mortality in Southwest China",
    "authors": "Hengyu Su, Di Wu, Song Chen, Kaiyang Guo, Huifang Xie, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0319545",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319545",
    "content": "This study investigates the correlation, impact, and hysteresis effect of joint exposure to the Temperature-Humidity Index (THI), Air Quality Index (AQI), and Black Carbon (BC) on respiratory disease mortality (RDM) in urban areas of the southwest basin of China, characterized by a subtropical monsoon climate. Dose-response analysis of THI, AQI, BC using a non-restrictive cubic spline model, a time series analysis was conducted to assess the relative risk (RR) of death from respiratory diseases using the distributed lag nonlinear model (DLNM) and the generalized additive model (GAM) based on the quasi-Poisson distribution. The RCS curve of THI exhibits a ‘U’ shape, with THI=67 representing the lowest point of mortality risk. The RCS curves for BC and AQI are linear and demonstrate a positive correlation with mortality outcomes. The peak mortality risk associated with the AQI typically occurs at Lag 2-3, with T3A3 (THI ≥ 75 and AQI ≥P90) contributing to the highest excess mortality [excess increased risk rate (ER) = 0.55, 95% CI: 0.20, 0.81]. The peak risk of mortality associated with BC occurs at Lag0, with the highest excess mortality resulting from T3B3 (THI ≥ 75 and BC ≥P90) combined events (ER=0.28, 95% CI: 0.10, 0.58). The cumulative relative risk (CRR) was highest in T3, with the peak CRR of 3.99 (95% CI: 1.26, 7.11) observed in definition T3A3. The relative risk of interaction (RERI) reveals varying degrees of positive additive interactions (RERI > 0) among AQI, BC, and THI.\n\nCitation:Su H, Wu D, Chen S, Guo K, Xie H (2025) Exploring temperature and humidity environment combined with air quality index, black carbon, the short-term effect of combined exposure on respiratory disease mortality in Southwest China. PLoS ONE 20(4):\n           e0319545.\n        \n        https://doi.org/10.1371/journal.pone.0319545\n\nEditor:Venkatramanan S, National College Autonomous, INDIA\n\nReceived:November 7, 2024;Accepted:February 4, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Su et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data are not publicly available due to confidentiality agreements and government restrictions on the identifiable nature of the data, but are available upon reasonable request from Naifan Zhang (send requests to1830487645@qq.com). All results generated throughout the study are included in the Supplementary Material, which is directly accessible.\n\nFunding:The authors acknowledge that the research was supported by internal funds provided by School of Public Health, Xinjiang Medical University. These internal funds were used to cover the costs of conducting the study, including materials, equipment, and personnel expenses. No external funding was received, and there are no conflicts of interest arising from the use of these internal funds. The authors also acknowledge the support of the 14-th Five-Year Plan Distinctive Program of Public Health and Preventive Medicine in Higher Education Institutions of Xinjiang Uygur Autonomous Region. This fund is designated as the project support program fund for the school college, and our corresponding author is the recipient of this funding.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nIn the context of global climate change, air pollution and significant alterations in climate are primary factors contributing to the morbidity and mortality associated with respiratory diseases [1]. Previous studies have demonstrated that the combined effects of climate change and air pollution on respiratory diseases are significant and non-linear [2].\n\nAs a significant component of PM2.5, Black Carbon poses a substantial threat to human health and is particularly associated with respiratory diseases. Long-term exposure to BC can lead to symptoms such as coughing, chest pain, drowsiness, and skin irritation [3]. Furthermore, it can result in a range of respiratory diseases, including lung damage [4]. The International Agency for Research on Cancer (IARC) has classified BC as a Category 2B carcinogen [5].\n\nPrevious studies have primarily concentrated on the health effects of temperature, including extreme climate events such as heat waves and cold waves, while treating meteorological indicators like humidity as confounding factors. Indeed, meteorological factors, such as humidity, have a modifying effect on the health impacts of temperature, as they influence human perception of temperature [6,7]. To the best of our knowledge, the Temperature-Humidity Index (THI) is utilized for public health monitoring in the United States and several European countries. In Japan, THI is employed to develop an early warning system for heat waves, which assesses and manages the effects of warm and humid weather, as well as urban heat island phenomena, on the health of residents. In China, THI is predominantly utilized in agriculture, animal husbandry, and tourism. However, there is a scarcity of studies and applications addressing the respiratory health of residents in conjunction with atmospheric pollutants in the field of public health. Most research regarding the effects of air pollution and climate change on respiratory diseases is primarily focused on eastern China, particularly in the Yangtze River Delta, the Pearl River Delta, and the southeastern coastal regions [8–10]. There are fewer studies conducted in southwest China, and no research has specifically defined the impact of joint exposure to Temperature and Humidity Indices, along with atmospheric pollutants, on respiratory disease mortality in unique geographical environments.\n\nConsequently, it is essential to integrate the thresholds of local geographical and meteorological characteristics to establish a relevant definition of combined events. This study investigates the joint and interactive effects of temperature, humidity, and atmospheric pollutants on respiratory disease mortality in a region of southwest China. It aims to identify critical combinations of risk exposures under various definitions. Provide evidence to understand the health risks of mixed exposure to BC and AQI on respiratory diseases in warm and humid environments. This study employs the THI to integrate temperature and humidity, thereby providing a more comprehensive definition and modeling analysis of the environmental conditions. Additionally, it aims to establish a targeted health warning system to mitigate exposure risks. The definition and identification of exposure events are critical prerequisites for the development of an effective health early warning system.\n\nThe study area is situated in the Sichuan Basin, China, specifically in the southwest region of the Chengdu Plain. It experiences a humid subtropical climate characterized by high temperatures and humidity throughout the year. Surrounded by mountains, this area faces significant pollution challenges, making it one of the most polluted regions in China. As of the end of 2023, the permanent population was recorded at 2.955 million, with men and women each representing 50.00% of the total. The demographic distribution shows that individuals aged 0-14 comprise 14.01% of the population, those aged 15-59 account for 61.26%, and the population aged 60 and above constitutes 24.73%, with individuals aged 65 and above making up 20.02%.\n\nConsidering the availability and timeliness of mortality, air pollution, and meteorological data, we obtained daily death records from January 2018 to December 2023 from the regional Centers for Disease Control and Prevention system. This dataset includes the date of death, the ethnicity of the deceased, household registration details, the direct cause of death, and the underlying cause of death. Two experts from the Centers for Disease Control and Prevention screened the data according to the codes of the International Statistical Classification of Diseases (10th edition, ICD-10) pertaining to respiratory diseases (J00-J99), to ensure the accuracy and scientific integrity of the data.\n\nThe European Center for Medium-Range Weather Forecasts (ECMWF) (https://cds.climate.copernicus.eu/) provides data on daily average temperature, daily maximum temperature, daily minimum temperature, relative humidity, wind speed, and surface pressure. The THI serves as an indicator that integrates daily average temperature and relative humidity to assess the heat of the climate [11]. The Copernicus Atmosphere Monitoring Service (CAMS) provides daily data on various air pollutants, including PM2.5, PM10, SO2, CO, O3, NO2, BC, and the AQI. The accuracy of ECMWF data can range from 70% to 90%, with information gathered through a global meteorological observation network that includes ground weather stations, ocean buoys, and meteorological satellites. The CAMS collects atmospheric composition data using various methods, including satellite remote sensing technology, ground monitoring stations, weather balloons, and meteorological models. Its high precision and accurate spatial matching contribute to the reliability of research findings. Both meteorological and air pollutant data were 1 × 1km raster data, and patient addresses were API matched to calculate individual exposure for each patient.\n\nWe meticulously cleaned, screened, and organized the data in alignment with the objectives of the research. Initially, specific time periods and diseases were identified, and data were excluded for individuals who were not present in the area during their lifetime, as well as for those who resided in the area for less than five years prior to their death. We subsequently removed any missing values and cross-verified values that deviated by more than three standard deviations from the long-term mean. Finally, death statistics are aligned by date with air pollutant and meteorological data.\n\nThe definition of exposure events is informed by the RCS exposure response curve, in conjunction with the ‘GB3095-2012’ standard established by the World Meteorological Organization (WMO), the National Meteorological Administration, and the China Meteorological Administration for heat wave definitions, as well as previous research. We categorize the Temperature-Humidity Index (THI) as follows: T1 (THI <  63), T2 (63 ≤  THI <  75), and T3 (THI ≥  75). Furthermore, by integrating the BC and AQI percentiles from this study and referencing the Technical Specifications for Ambient Air Quality Assessment (HJ6632013), the Guidelines for the Preparation of Urban Heavy Air Pollution Emergency Plans, and the Sichuan Province Heavy Pollution Weather Emergency Plan (2018 Revision) - Quantitative Indicators, we redefine the BC and AQI categories as B1 (P≥ 50), B2 (P≥ 75), B3 (P≥ 90), A1 (P≥ 50), A2 (P≥ 75), and A3 (P≥ 90). Notably, A1 encompasses A2 and A3, while B1 includes B2 and B3. This study utilizes the RCS intersection value as a node, treating the combined meteorological event variable as a continuous variable, thereby fixing it within the ranges above or below different percentiles. This approach aims to investigate the relationship between THI and extreme AQI and BC, as well as to explore the impact of exposure to combined events with varying threshold ranges on respiratory mortality, ultimately refining the thresholds for early warning models.\n\nThe comprehensive event definition comprises three THI, along with three definitions for two pollutants, resulting in a total of 18 distinct definitions. The combined event, denoted as XiYj, is defined by the individual definitions of Xi and Yj, indicating that both events occur simultaneously.\n\nThe combined meteorological event variables were the continuous variables. The THI, AQI, BC, and mortality data did not conform to a normal distribution upon testing. Consequently, the statistical package of R version 4.3.0 was utilized to perform Spearman correlation analysis to assess the relationships between each variable. This analysis served as a foundation for the subsequent establishment of GAM and DLNM. This study employs a time series analysis that integrates a GAM and a DLNM utilizing a quasi-Poisson distribution. Initially, we employ the GAM to analyze nonlinear relationships within time series data, effectively fitting potential patterns and trends using various smoothing functions. Subsequently, we utilize the DLNM to dynamically capture the temporal and dose-response effects, addressing the intricate relationships between environmental factors and health outcomes. This approach culminates in the establishment of an exposure-lag-response model. When used in conjunction, the two can fully leverage their complementary characteristics, thereby enhancing the novelty, depth, and breadth of the analysis. The objective is to estimate the exposure-lag-response relationship among THI, AQI, BC, and Respiratory Disease Mortality (RDM). The analysis includes plotting specific incremental effects and the CRR associated with these variables. Additionally, the hysteresis response curve is examined to illustrate the effects. The results from the additive interaction model are used to assess the existence of interactions.\n\nThe calculation formula for THI was established from previous studies [12,13]:\n\nTavgis the daily mean temperature (°C) and RHavgis the daily average relative humidity (%).\n\nUtilizing the ‘rms’ package, we will establish restricted cubic splines to investigate the dose-response relationship between the THI, AQI, BC, and mortality outcomes. This analysis aims to identify the threshold cut-off points for each factor concerning respiratory disease mortality and to define exposure events. The fundamental expression of the model is presented as follows [14]:\n\nY stands for the dependent variable (response variable). β0 represents the intercept, which represents the predicted value of the dependent variable Y when all independent variables X are zero. β1, β2,..., βk represent the slope coefficients, which represent the expected change in the dependent variable Y when an independent variable Xi is increased by one unit. Each coefficient represents the degree to which the independent variable affects the dependent variable. X, X1, X2,..., Xk represent the independent variable (explanatory variable) and are used to predict the dependent variable Y. ε represents the error term, which represents the difference between the predicted value of the model and the actual observed value.\n\nWe incorporated the cross basis function of the combined event into the model, selecting the longest lag period (lag) of 7 days based on prior studies [8,9], as well as the AIC, to effectively capture the overall impact of the combined event while controlling for temporal trends and other confounding factors. The fundamental algebraic expression of this model is provided as follows [8]:\n\nIn the formula, Log represents the connection function; ytdenotes the number of RDM individuals on day t; α is the intercept; β, y, and λ are the corresponding regression coefficients; Q signifies the combined event;lindicates the longest lag number of days; Tt,lrefers to the combined event cross basis matrix; ns is the cubic spline function employed to account for unmeasured confounding factors related to time, seasonality, and long-term trends; ‘time’ is the time variable, with df set to 7 per year, which is utilized to smooth out seasonality and cycles of sexual influence; ‘meteorology’ encompasses other meteorological factors, with df set to 3; DOWt represents the day of the week for the t-th day, primarily used to control for the day-of-the-week effect; and Holidayt indicates whether the t-th day is a statutory holiday or falls within winter and summer vacations.\n\nIn this study, THI, AQI, and BC levels were increased by one interquartile range (IQR) to investigate the relationship between changes in their concentrations and mortality outcomes. The results are reported using the relative risk of death (RR, 95% CI) and the excess increased risk rate (ER, 95% CI) [8,9,11].\n\nWe utilize the relative risk due to interaction (RERI) to assess the comprehensive impact of the THI, AQI, and BC. A RERI of 0 signifies no additional risk, while a RERI greater than 0 indicates that the combined effects of the THI, along with gaseous pollutants, on health are greater than the individual effects of each factor. Conversely, a RERI less than 0 suggests that the joint effects are less than additive.\n\nAmong these, RR11represents the relative risk of the combined event, RR01denotes the relative risk associated with THI, and RR10indicates the relative risk related to the AQI or BC event.\n\nThe cumulative effect of combined events on mortality over a lag period of 0 to 7 days was defined as the cumulative relative risk (CRR, 95% CI). This study estimates the single-day lagged effects from lag 0 to lag 7, where lag 0 and lag 1 correspond to the lagged effects of exposure factors on respiratory disease deaths on the first and second days, respectively. Additionally, we evaluated the cumulative lagged effect from lag 01 to lag 07, which reflects the cumulative lagged impact of exposure factors on disease mortality from day 2 to day 1.\n\nTo assess the robustness of our modeling strategy, we conducted a sensitivity analysis by varying the degrees of freedom (df) for factors 3, 5, and 6 in several key models. All analyses were performed using R software version 4.3.0, employing the ‘splines’ and ‘lme4’ packages to carry out stratified analyses by gender, age, and other variables. A p-value of less than 0.05 was considered statistically significant.\n\nTable 1presents a summary of respiratory disease mortality, the AQI, the THI, and black carbon levels in the region from January 1, 2018, to December 31, 2023. During this period, a total of 13,847 individuals succumbed to respiratory diseases, with daily mortality rates fluctuating between 0 and 51. The average THI value recorded in the area is 63.70, with a range of 53.66 to 73.63. The average AQI value is 76.50, spanning from 62.00 to 106.00, while the average BC concentration is 1.64, with values ranging from 1.19 to 1.98.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319545.t001\n\nFig 1presents the results of the restricted cubic spline analysis for the THI, AQI, and BC in relation to respiratory disease mortality. All three variables exhibit an exposure-response relationship with the mortality outcome. Notably, the exposure-response curve for THI is characterized by a nonlinear, U-shaped pattern, with a minimum risk of death observed at a THI value of 67. In contrast, the relationships between AQI, BC, and the mortality outcome are linear.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319545.g001\n\nBased on the results of the restricted cubic spline presented inFig 2,Table 2provides the relevant definitions and the number of independent exposure events. Notably, T1 exhibits the highest number of events as defined by the THI.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319545.t002\n\nNote: Combined event definitions refer to the independent definitions presented inTable 2; for instance, T1A3 denotes the combined event defined by T1 and A3.\n\nNote: Combined event definitions refer to the independent definitions presented inTable 2; for instance, T1A3 denotes the combined event defined by T1 and A3.\n\nhttps://doi.org/10.1371/journal.pone.0319545.g002\n\nTable 3presents the number of merged events, revealing that the maximum count under the T1 definition is 739, categorized as T1B1. In contrast, the highest number of merge events in a T2 scenario is 311, designated as T2A1. For the T3 definition, the largest number of combined events is found in T3A1, totaling 302. To ensure an adequate sample size, events with durations exceeding 10 days were filtered to further assess health effects.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319545.t003\n\nTable 4presents the results of the Spearman correlation analysis. Among the variables analyzed, PM2.5and PM10exhibit the highest correlation, with a coefficient of r =  0.99. With the exception of the correlations between THI and wind speed, as well as THI and AQI, all other pairs demonstrate varying degrees of correlation that are statistically significant.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319545.t004\n\nFig 2illustrates the lag structure associated with the combined events of respiratory death. The RRs along with their 95% confidence intervals are detailed inS1–S6 Tables. It is important to highlight that the effects of various scenarios and causes exhibit significant variability.\n\nIn the analysis of respiratory disease mortality outcomes (Fig 2), the peak of the hysteresis curve for the combined events of T1, T2, T3, and AQI typically occurs during lag 2-3, exhibiting an overall “inverted V” shape. Among the various T1 definitions, T1A3 resulted in the highest excess mortality during lag 3, with an RR of 1.26 (95% CI: 1.11, 1.41). For T2, T2A3 recorded the highest RR during lag 2, at 1.15 (95% CI: 1.04, 1.26). In the T3 definition, T3A3 showed the highest RR during lag 3, measuring 1.55 (95% CI: 1.20, 1.81).\n\nUnder different definitions, the combined event of Temperature-Humidity Index (THI) and black carbon reveals a hysteresis curve that exhibits a gradual downward trend, with peaks occurring during the lag0 period. Among the three definitions of THI, T1B3, T2B3, and T3B2 demonstrate the highest excess mortality risks, recorded at 1.18 (95% CI: 1.04, 1.33), 1.28 (95% CI: 1.12, 1.45), and 1.87 (95% CI: 1.21, 2.53), respectively.\n\nWhen exposed to the same increment, the relative risk (RR) of the combined event defined by T3, AQI, and BC is generally higher than that of the combination of T1 and T2.\n\nFig 3illustrates the CRR for lags of 0–7 days. Notably, the CRR for the T3 segment is greater than that for both T1 and T2. The CRR for the AQI varies from T2A1 (1.07; 95% CI: 0.92, 1.22) to T3A3 (4.99; 95% CI: 2.26, 7.72). The CRR for BC ranges from T2B1 (1.06; 95% CI: 0.95, 1.17) to T1B3 (2.84; 95% CI: 1.56, 4.12).\n\nNote: Combined event definitions refer to the independent definitions presented inTable 2; for instance, T1A3 denotes the combined event defined by T1 and A3.\n\nNote: Combined event definitions refer to the independent definitions presented inTable 2; for instance, T1A3 denotes the combined event defined by T1 and A3.\n\nhttps://doi.org/10.1371/journal.pone.0319545.g003\n\nSynergistic effects of exposure events on respiratory disease mortality can be observed in combination events characterized by extremely high concentrations of pollutants and THI. Six definitions (T1A3, T2A3, T3A3, T1B3, T2B3, T3B2) were identified as having a synergistic effect on respiratory mortality, particularly in T3 (Table 5).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319545.t005\n\nThe AIC (or BIC) values presented inS7 Tableindicate that the number of nodes for THI, BC, and AQI are 3, 3, and 4, respectively. Furthermore, the sensitivity analysis results for the remaining definitions demonstrate robustness, as shown inS8andS9 Tables.\n\nTo investigate the effects of combined exposure to THI,AQI, and BC on mortality from respiratory diseases, we systematically analyzed the impact of these combined exposures under 18 distinct definitions. To the best of our knowledge, this study is among the few that specifically defines a combined event involving the THI, AQI, and BC levels in China. Our findings indicate that the adverse health effects of combined events differ depending on the definitions used. The lagged structure of integrated events varies across definitional strata. Therefore, determining the appropriate definition of exposure events is crucial for health risk assessment and the development of early warning systems.\n\nCurrently, China employs a unified set of grading standards for the THI and AQI; however, these standards have not been utilized to establish a high-temperature early warning system, making it challenging to adapt to various climate zones. Consequently, we conducted a dose-response analysis of THI, AQI, and BC using a RCS model tailored to the specific local environment. In this analysis, we defined thresholds T1, T2, T3, A1, A2, A3, B1, B2, and B3. Similarly, in Shanghai, China, Liang employed the wet bulb globe temperature (WBGT) index to establish the minimum incidence threshold point, based on the exposure-response relationship [15]. It is important to note that the definition of the THI threshold in this study diverges from the traditional grading definition [11,16]. This may result from the uncertainty surrounding recent climate change and the specificities of different regions. The average concentration and variation range of BC observed in this study were lower than those reported in previous studies [17,18]. This discrepancy may be attributed to China’s vigorous efforts to control air pollution in recent years. The results of this study indicate that black carbon exhibits significant harmful effects under the definitions of T1, T2, and T3. A study conducted in Beijing [18] also found that the interaction between temperature and BC increased the excess number of deaths from respiratory diseases by 1.80%. To our knowledge, there are limited articles that define subgroups and analyze interactions with THI concerning BC thresholds. Consequently, it is essential to establish an early warning system for THI and black carbon risk, both in this region and across China.\n\nIn this study, the relationship between the RCS curve of THI and respiratory disease mortality outcomes was found to be nonlinear, exhibiting a ‘U’ shape. Specifically, THI = 67 represented the lowest point of mortality risk. This finding aligns with the results of Zhang [11], where a THI of approximately 55 to 70 demonstrated a negative correlation with the risk of death from respiratory diseases within the population. This may be attributed to the existence of optimal intervals among temperature, humidity, and the resulting outcome; thus, there may also be an optimal region for the combined effects of these two factors. When the THI index falls below or exceeds specific thresholds (T1, T3), a greater change in the index correlates with an increased risk of death. Although the biological mechanisms underlying thermohumidity events remain unclear, one possible explanation is that during low THI events, reduced humidity impairs human respiratory mucosal function and ciliary motility. This impairment facilitates the adherence of bacteria to the mucosa, thereby increasing the risk of infection [19]. An experiment demonstrates that mice exposed to low humidity exhibit impaired mucociliary clearance, diminished innate antiviral defenses, and compromised tissue repair, resulting in increased susceptibility to inflammasome caspase-mediated diseases [20]. During high THI events, elevated temperatures combined with high humidity can hinder the body’s ability to dissipate heat. This may result in heat-related illnesses such as heat stroke and heat cramps, while also increasing the strain on the human respiratory system [21,22]. Similarly, Andrews [23] defined various heat exposure indices and found that a higher heat exposure index is associated with a greater risk to human survival. Liang also found that, compared with high temperature conditions, hot and humid weather in Shanghai was significantly associated with a higher risk of outpatient visits and an increased risk of all-cause morbidity [15]. However, these findings are inconsistent with those of Fallah Ghalhari G, who identified an inverse correlation between the heat stress excitation threshold and mortality [24]. This discrepancy may be attributed to the lower humidity levels in the Middle East, as well as variations in socioeconomic factors among the study samples. It is anticipated that excessive heat stress will become prevalent in low- and middle-income countries located in tropical or subtropical regions. There is no nonlinear relationship between the exposure-response curves of AQI, BC, and respiratory disease mortality outcomes, which aligns with the findings of most studies [3–5,17]. In the United States, the AQI is commonly employed to convey daily air quality information to the public. Cromar [25] discovered a positive association between AQI and respiratory disease incidence among adults in California. Some studies [26] have indicated that the estimated health impact of a 1 μg/m3increase in black carbon exposure, as observed in time series studies, is greater than that of PM10or PM2.5. When expressed as black carbon, the estimated increase in life expectancy resulting from reductions in black carbon concentrations is 4 to 9 times greater than that associated with equivalent changes in PM2.5mass. Animal experiments [27] have revealed that lung macrophages containing black carbon particles exhibit selective mitochondrial structural damage and a reduction in oxidative respiration. BC exposure metabolically rewires lung macrophages to promote immunosuppression and accelerates the development of lung cancer. Gao [28] also found that BC particles induce lung disease, characterized by an increased expression of factors related to inflammation, necrosis, and fibrosis. The detrimental effects of BC on the lungs involve the targeting of lysosomes. The research results indicate that the integration of the THI index and black carbon is highly significant for developing a risk assessment system for the heat wave early warning system in our country. It is crucial to delineate and define thresholds based on the exposure-response relationship specific to each region, thereby ensuring adaptability to local conditions. In unique environments, risk warnings should be implemented to effectively safeguard the lives and property of local residents.\n\nIn this study, combined events present varying degrees of health risks. Notably, the mortality risk associated with the combined event of THI and AQI typically peaks with a delay of 2 to 3 days. This finding aligns with the research conducted by Surit P [29], who identified a correlation between the AQI and hospital visits for pneumonia occurring the day following exposure (RR = 1.024, 95% CI: 1.003-1.046). Furthermore, the AQI is linked to an increase in ICU admissions and mortality rates associated with respiratory illnesses. This study found that, with the same increase in exposure, the mortality risk and cumulative mortality risk of respiratory diseases in the population caused by combined T3 and AQI events appear to be more severe. Luo [30] found that as the AQI index increases, the severity of air pollution, as classified by the AAQI and HAQI indices, also intensifies, leading to a higher mortality rate from respiratory diseases. This study demonstrates a timely impact on the risk of death associated with the combined events of THI and BC. Under various definitions, higher concentrations of black carbon correlate with an increased cumulative risk of mortality. The cumulative mortality risk associated with the combined effects of T2 and black carbon is lower than that resulting from the combined exposure defined under T3. This discrepancy may be attributed to the influence of humidity, which alters the properties and pathogenic mechanisms of black carbon. Fang [31] found that, compared to weather characterized by normal temperature and high humidity, hot and dry weather poses a greater risk than hot and humid weather. This finding further elucidates the potential modifying effect of humidity. As humidity continues to rise, the risk of illness or death resulting from the combined effects of temperature and humidity also increases. This may be attributed to high humidity, which reduces the efficiency of heat dissipation through human pores, leading to decreased sweating and other related symptoms. Consequently, this increases the likelihood of heatstroke and other heat-related illnesses. This indirectly highlights that the overall mortality risk associated with combined exposure to high THI, AQI, and BC remains relatively high.\n\nStudies [32] indicate that combined events have more severe health impacts than individual air pollution events. Furthermore, the results of this study demonstrate that simultaneous exposure to extreme THI and high pollutant events has a more significant impact on human health, aligning with the findings of previous research on combined events. In the definitions of T1, T2, and T3, the CRR values ranging from 0 to 7 for the combined events T1A2, T1A3, T2A2, T2A3, T3A2, and T3A3 in this region are consistently higher than those for T1A1, T2A1, and T3A1. This pattern is also observed in the combined events related to black carbon. The combined events of T3 and AQI demonstrated additive interactions, with the T3A3 combined event exhibiting the highest Relative Excess Risk due to Interaction (RERI). Additionally, the RERI for T2B3 was found to be the highest in the combined event associated with black carbon. The results indicate that, within the context of climate change, the impacts of pollutants and meteorological factors on human health are interdependent rather than isolated. Their combined exposure produces an additive effect on the human body, warranting significant attention. Consequently, in addressing air pollution control and public health prevention, it is imperative to focus on their comprehensive effects, as highlighted by various data analyses.\n\nA stricter definition increases the relative risk; however, its protective capability remains limited. Conversely, a looser definition can encompass a greater number of risk exposure events, thereby offering broader protection, albeit with a comparatively lower relative risk [33]. However, mitigating risk events may inadvertently lead to an increase in warnings, while also escalating associated costs [34]. To balance the costs associated with the construction of early warning systems and the anticipated health benefits, further research is essential to explore appropriate definitions. THI is a dynamic metric influenced by temperature and humidity levels. Both BC and the AQI serve as monitoring results. Consequently, THI, BC, and AQI do not require seasonal division; rather, they should be defined solely by their respective numerical ranges. Thus, the findings of this study carry practical implications. Due to the significant lag effect associated with pollutants, there is also a corresponding lag effect on combined events, which peaks within the 0 to 3 lag days. This indicates a short-term effect; however, a strict definition of pollution appears to have an insignificant impact on health outcomes. Our findings indicate that when comparing individual pollutant exposures across various definitions of the THI, the results consistently demonstrate that the initial peak of lagged health effects does not occur earlier or later. This suggests a joint effect of AQI, BC, and THI events. The stability of these outcomes is beneficial for the issuance of early warning announcements, the establishment of early warning systems, and the development and implementation of related policies.\n\nThe definition of the hygrothermal effect index differs from that of air pollution’s impact on health outcomes [10], which may partially account for the relatively low health effects associated with T2. In light of the potential exposure lag response curve, cumulative relative risk results, and the effectiveness of risk early warning systems, we have thoroughly considered and discussed the establishment of an early warning system. Firstly, we recommend that the local climate environment, as well as economic and social conditions, be comprehensively evaluated. The thresholds for various influencing factors can vary significantly depending on the climate zone, and economic conditions may also influence the quality and standards of the early warning system. Secondly, given the hysteresis associated with the impacts, we propose extending the setting time for the early warning system and issuing alerts within one week following the occurrence of comprehensive exposure events to enhance population protection and prevention efforts. Furthermore, for the specific development and dissemination of the early warning system, we suggest collaboration with relevant agencies, such as the local CDC. This partnership should leverage the expertise of the CDC’s infectious disease and environmental institutes, ensuring mutual support in providing technical assistance. Subsequently, relevant outreach departments should promote the system through various media channels to ensure that the majority of residents understand, recognize, and accept this system, thereby enhancing its practical implementation. Lastly, we recommend categorizing heat wave warning levels for exposure events into three tiers: low (T2), medium (T1), and high (T3). Given the heightened risks associated with combined events, we further propose dividing pollutant warnings into three categories based on the definitions of AQI and BC concentrations: ‘+Low’, ‘+Medium’, and ‘+High’. The THI’s early warning system can be integrated with the existing heat wave early warning system. The simultaneous activation of similar components in both systems can reduce the costs associated with issuing early warnings. Moreover, the THI early warning system exhibits greater sensitivity in detecting changes in the external dynamic environment and takes into account the specific characteristics of the local environment. This provides relevant health departments with more scientific and accurate foundational information for effectively addressing heat and humidity incidents.\n\nThe calculation of the AQI primarily relies on monitoring the concentrations of various air pollutants. These pollutants typically include PM2.5,PM10, O3, SO2, and CO. BC is a component of PM2.5; therefore, fluctuations in BC concentration are largely dependent on changes in PM2.5concentration. However, due to the rapid changes in climate, alterations in its material properties, and shifts in its pathogenic mechanisms, an increasing number of studies are now beginning to investigate its effects on the human body separately [35]. This is one of the reasons why BC is examined independently in this study. As a combination of exposure events, BC can be studied in conjunction with other pollutants such as SO2, NO2, and O3to investigate the effects of their combined exposure on the population. The environment we inhabit is not made up of a single substance or event. The occurrence of extreme temperatures, sunshine, precipitation, cyclones, and other weather phenomena frequently alters our lifestyle and surroundings. Relevant studies have demonstrated that short-term exposure to elevated levels of high temperatures, NO2, O3, and CO is significantly associated with an increased risk of respiratory mortality. Furthermore, men and the elderly are particularly susceptible to these environmental factors [36]. Du found that climate factors and air pollution have lagged and nonlinear effects on the epidemic of hand, foot, and mouth disease. Furthermore, the influence of climate factors on health may vary based on the AQI [37]. There is a connection between various weather types and air pollutants. For instance, coastal cities are more vulnerable to different patterns of atmospheric circulation and types of cyclones [38]. In the context of climate change, it is essential to focus on the bidirectional interaction between meteorological conditions and air pollutants, as well as the effects of their combined exposure on the population. This emphasis underscores the significance of our research.\n\nOur study presents several notable strengths. First, we investigated the impact of combined events using various definitions of THI, AQI, and BC, which offers robust epidemiological evidence regarding their influence on respiratory disease mortality in China. Second, we established a total of 18 distinct definitions. To our knowledge, the variability in the definition of combined events is greater than that observed in other relevant independent exposure studies. The construction of these definitions considers the full impact of exposure lag effects, and employing unrestricted cubic splines to delineate the ranges enhances both the scientific rigor and precision of our findings. Third, we have systematically proposed a comprehensive scientific basis and construction methodology for an early warning system, which provides valuable insights and frameworks for developing early warning systems in other regions, as well as across China as a whole.\n\nThis study has several potential limitations that warrant consideration. First, the research was conducted in a single study area and over a short time scale, which may introduce variability in the results. Additionally, this study primarily concentrated on short-term effects and did not fully investigate the long-term outcomes related to combined exposure events and respiratory deaths. This limitation may affect the comprehensiveness of the findings. To enhance and broaden the findings of this study, it is essential to incorporate additional research conducted in diverse climate zones, additional relevant studies are necessary to enhance the reliability of these findings. Second, we were unable to perform a more detailed analysis of the sensitive population due to a lack of information regarding their socioeconomic characteristics. Third, exposure data were not through individual monitoring, which may introduce biases in health risk assessments.\n\nIn summary, this study presents evidence of a correlation between an increased risk of mortality from respiratory diseases and combined environmental events. Raising awareness of the interplay between AQI, BC, and THI is crucial, as it can facilitate the management of associated health risks. Moreover, the integration of multiple definitions significantly improves the model’s capacity to identify exposure events and can be adapted for combined exposure health risk assessments in other research domains.\n\nTable S1.Relative risk of combined events T1A1 T1A2 T1A3.Table S2.Relative risk of combined events T2A1 T2A2 T2A3.Table S3.Relative risk of combined events T3A1 T3A2 T3A3.Table S4.Relative risk of combined events T1B1 T1B2 T1B3.Table S5.Relative risk of combined events T2B1 T2B2 T2B3.Table S6.Relative risk of combined events T3B1 T3B2 T3B3.Table S7.The results of AIC(BIC) of combined events definition.Table S8.Sensitivity analysis for cumulative effect estimates of combined event (T3A1,T3B1) on respiratory mortality at lag 0 and lag 0-7 days.Table S9.Sensitivity analysis for cumulative effect estimates of combined event (T3A2,T3B2) on respiratory mortality at lag 0 and lag 0-7 days.\n\nhttps://doi.org/10.1371/journal.pone.0319545.s001\n\n(DOCX)",
    "category": "earth_sciences"
  },
  {
    "title": "Exposure to air pollutants contributes to increased rate of neovascular age-related macular degeneration in Israel",
    "authors": "Alon Sela, Rinat Levinshtein, Shiri Shulman, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0317436",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0317436",
    "content": "Age-related macular degeneration (AMD) is a multi-factorial degenerative disease of the retina and the leading cause for vision loss in the developed world. Air pollution is considered the greatest environmental threat to public health globally. Accumulating evidence indicates that air pollution may be a modifiable risk factor for chronic eye diseases of the lens and retina, including AMD. We examined the concentration of seven air pollution particles and their influence on the prevalence of neovascular AMD in Israel. Records of patients with AMD between 2016 and 2019 were crossed with their residential areas and correlated with pollution data. AMD rates were correlated with 5 types of gas: nitrogen dioxide (NO2), nitrogen oxide (NO), carbon monoxide (CO), ozone (O3), sulphur dioxide (SO2), and particulate matter - PM2.5and PM10. A total of 93 localities across Israel were included in the analysis. AMD rates were higher in localities with greater air pollution. NO2, NOx, and PM2.5were positively correlated with AMD rates, while O3was negatively correlated with AMD rates. However, analysis of the effect of all air pollutant particles combined, showed a complex and highly non-linear effect on AMD rate, with the strongest non-linearity observed for carbon monoxide. NO2, NOx, and PM2.5 contribute to higher rate of AMD in Israel while O3seems to have a protective role (probably due to ultraviolet filtering) on AMD rates. The interaction between air pollutants and AMD seems to be complex and non-linear and should be further studied.\n\nCitation:Sela A, Levinshtein R, Shulman S (2025) Exposure to air pollutants contributes to increased rate of neovascular age-related macular degeneration in Israel. PLoS ONE 20(4):\n           e0317436.\n        \n        https://doi.org/10.1371/journal.pone.0317436\n\nEditor:Der-Chong Tsai, National Yang Ming Chiao Tung University Hospital, TAIWAN\n\nReceived:February 4, 2024;Accepted:December 27, 2024;Published:April 18, 2025\n\nCopyright:© 2025 Sela et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data and code are available fromhttps://osf.io/zvtae/The medical data is available only on an aggregative level (city level) due to patient care privacy. The code and the aggregated data is available in a designated Open Science Foundation repository.\n\nFunding:Ariel-Assuta mutual research grant ARC2. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAir pollution is considered the greatest environmental threat to public health around the world. Approximately 7 million people die prematurely every year due to air pollution [1]. Air pollutants are classified as primary or secondary. Primary pollutants are directly emitted to the atmosphere and include particulate matter (PM), black carbon, sulphur oxides (SO2), nitrogen oxides (NOX), ammonia (NH3), carbon monoxide (CO), methane, non-methane volatile organic compounds, including benzene, and certain metals and polycyclic aromatic hydrocarbons, including benzo[a]pyrene. Secondary pollutants are formed in the atmosphere from precursor gases through chemical reactions and microphysical processes, and include PM, ozone (O3), nitrogen dioxide (NO2) and several oxidised volatile organic compounds [2].\n\nAir pollution sources are both natural and man-made. Man made air pollution originates in industry, diesel and petrol engines, friction from brakes and tyres, building and construction dust and road surfaces. Natural sources of air pollutants include volcanoes, sea spray, pollen and soil [2,3]. PM is classified by its size. PM2.5are particles < 2.5/1000 micron in diameter. Similarly, PM10refers to larger particles with a diameter < 10 microns. Some particles, such as dust, dirt, or smoke, are relatively large or dark enough to be seen with the naked eye.\n\nDue to their ability to penetrate the blood stream through the lungs, small-sized particles of 2.5 micron/1000 mm or lower (PM2.5), have been shown to be more harmful than larger sized particles. Specifically, they have been associated with increased risk for cardiovascular disease, including stroke [4–6], hypertension [7,8], oxidative stress [9], various malignancies, and chronic airway inflammatory diseases [10]. Accumulating evidence indicates that air pollution may be a modifiable risk factor for chronic eye diseases of the lens and retina [11].\n\nAge-related macular degeneration (AMD) is a multi-factorial degenerative disease of the retina that manifests in degeneration of the retinal pigment epithelium and choriocapillaris via several pathways including oxidative damage and complement activation [12]. Late AMD may be associated with abnormal blood vessel growth under the retina which cause fluid accumulation, haemorrhages and eventually scarring with eventual visual loss. In such neovascular AMD cases, treatment with intravitreal injections of anti-vascular endothelial growth factor (anti-VEGF) drugs is indicated. This disease, and specifically its neovascular form, is a leading cause of vision loss in the developed world. It is estimated that in 2020, AMD caused moderate or severe vision loss in 6.22 million people and blindness in 1.84 million people [13]. It has been estimated that by 2050 the number of new cases of early and late AMD would reach 39.05 million and 6.41 million, respectively [14].\n\nThe aetiology of AMD is not clear. While age is the most consistent risk factor, additional risk factors may play a role, including ethnicity, genetics, oxidative stress, hypertension, lifestyle habits (diet, smoking) and environmental factors [15,16].\n\nThe effect of various air pollutants, on the risk for developing AMD has been studied in several countries, including Taiwan [17] where PM2.5particles were associated with AMD, while other studies [18] studied this association for CO and NO2particles. Dust storms was associated with AMD in Taiwan [19], and PM2.5particles in China [20]. PM2.5, PM10, NO2and CO in Korea [21] and in Canada PM2.5[22]. In the UK, PM2.5was associated with self-reported AMD while PM10, NO2 and NOx affected retinal thickness abnormalities [23]. Most of these studies investigated the relationship between PM2.5 and AMD; but the relationship between all specific air pollutants and AMD in one single place is still lacking. We aimed here to further solidify the relationship between AMD and 7 different air pollution types (including Ozone), based on data from 77 localities in Israel to better understand the complex interactions between air pollution and the development of AMD. All Data and code are fully available on the project repository (Supporting data and code are found in theOpen Science Foundation (OSF) page(https://osf.io/zvtae/).\n\nThis retrospective analysis was approved by the Assuta Medical Centres’ Ethics Committee (approval number ASMC-0001-19). The need for patient informed consent was waived due to its retrospective nature.\n\nRecords related to yearly air pollution data between 2016 and 2019 were obtained from the Israel Ministry for the Protection of the Environment.\n\nAge distributions for localities across Israel in 2017 were obtained from the Israel Central Bureau of Statistics. This dataset included statistical data related to ethnicity distributions and locality size stratified by the number of residents (10,000–20,000, 20,000–50,000, 50,000–100,000, 100,000–200,000, 200,000–500,000, over 500,000).\n\nRecords of patients with neovascular AMD who received intravitreal anti-VEGF injections were retrieved from Assuta Medical Centres’ Eye Clinic, where members of Maccabi Healthcare Services are treated.\n\nMaccabi Healthcare Services is the second largest health maintenance organization in Israel (one of the four health maintenance organizations in Israel, which every citizen and permanent resident is entitled to be insured in under the National Health Insurance Law 1994). The initial database consisted of 90,000 records of patient visits to Assuta Eye Clinic between January 2016 and December 2018. Each record included open text describing the diagnostic procedure of an eye examination or an anti-VEGF injection that was given to a patient. The patient records were first anonymised and then grouped by the patient’s city of residence. For this initial preprocessing the data was accessed between June 2020 to August 2020. This preprocessing resulted in an aggregated number of AMD patients in 184 locations in Israel. Overall, the data included 3200 patients.\n\nThis dataset was combined with another dataset from the census of the Israel Central Bureau of Statistics[24] and the proportion of members in each health maintenance organization per city was determined. Records of small localities, in which the total number of Maccabi Healthcare Services members was less than 300 were excluded from the analysis, as well as localities that had less than 20 patients with AMD. The final analysis included 93 localities.\n\nThe localities were also separated into mostly Hebrew speaking, mixed Hebrew and mostly Arabic speaking localities, from which some limited reference to ethnicity can be made. One should note however that this distinction should be taken with great care, since in the population of mostly Hebrew speaking localities, about 60% of Hebrew speaking Maccabi pacients come from Arab countries and in terms of population genetics, this population is more like African/ Middle eastern populations.\n\nSince the proportions of healthcare maintenance organization members differs by locality, to estimate the rate of AMD in each locality, the number of individuals with AMD were divided by the proportion of Maccabi Healthcare Services members (% of Maccabi patients in the locality *  locality’s population).\n\nOne should note however that this data was constructed based on textual medical records of patients in the Assuta eye Clinic. The treating ophthalmologists do not collect lifestyle records such as BMI or other health related parameters. Also, the initial approval to use the data did not include an extraction of parameters such as smoking habits not weight.\n\nThis limits this retrospective study to use the data for the purpose declared and not to other purposes.\n\nThe association between AMD rates and air pollution was performed on seven different air pollution particles, i.e., 5 types of gas: nitrogen dioxide (NO2), nitrogen oxide (NO), carbon monoxide (CO), ozone (O3), sulphur dioxide (SO2), and 2 particulate matter sizes: PM2.5and PM10.\n\nThe influence of these air pollution particles on AMD rates in different localities was analysed by several regression models as well as by a cross correlation analysis - a method used in nonlinear systems to detect interactions. The dependent variable in each regression model was the number of patients with AMD per 100,000 persons.\n\nFirst, separate regression models were performed to examine the effect of each air pollution particle separately on the rate of AMD. Then, several multiple regression analyses models were performed to examine the effect of combinations of different air pollution particle types on AMD rate. Pearson correlation was also used to explain the correlation among different air pollution particles.\n\nThe cross-correlation analysis was used to refine and revalidate the finding of the multiple regressions. Mainly, these methods were needed since the effects between the air pollution particles and AMD seem to be non-linear. The cross-corelation method is commonly used in physics and in signal processing or in bioinformatics, where it is applied to study non-linear time series between seemingly disconnected variables [25,26]. The correlation between AMD rates and air pollution concentrations was examined while comparing these corelations to the internal “noise” that exists in the data. Although cross-correlation methods are usually used to find correlations between different points in time, here, we used these methods to determine correlations between different points in space (i.e., localities). The cross-correlation implied shuffling the data of different localities and comparing the maximal effects in the shuffled data to the non-shuffled data. Thus, the noise to signal was estimated by comparing the correlation between AMD rates and air pollutants in any cityi, to the correlations when AMD rates were for a cityibut the air pollution records were for a cityi+k().This process was repeated for different values of k. By this method, the signal whenk = 0was extracted out of the noise (). If the maximal correlation function appeared when the time lag was 0, and if it was significant (>2–3 standard deviations above the noise), then the signal of correlation was considered significant over the noise.\n\nNeovascular AMD rate ranged from 0.006% to 1.04%. The rate was higher in localities in central Israel compared to localities in the periphery of the country (Fig 1a) and corresponded with higher air pollution measured in localities in central Israel (Fig 1b).\n\n(a) AMD rates in the 93 localities analysed. Green bars indicate localities in central Israel, red bars indicate localities in peripheral regions of the country. (b) Air pollution rates in Israel on 7 February 2022 [27]. Higher air pollution (red flags) was observed in localities in central Israel.\n\n(a) AMD rates in the 93 localities analysed. Green bars indicate localities in central Israel, red bars indicate localities in peripheral regions of the country. (b) Air pollution rates in Israel on 7 February 2022 [27]. Higher air pollution (red flags) was observed in localities in central Israel.\n\nhttps://doi.org/10.1371/journal.pone.0317436.g001\n\nThe average concentration of the 5 gases and particulate matter measured in the 93 localities are shown inTable 1. On average, CO particles had the highest concentration (166.4 ±  43.2 µg/m3) followed by O3(72.2 ±  8.7 µg/m3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317436.t001\n\nCorrelation analysis showed that only O3was negatively correlated with the other air pollutants. All correlations between the other air pollutants were positive (Table 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317436.t002\n\nThe change in coefficient signs between the independent and multiple regression models (for example, the NO2coefficient changed from 3.4 in the independent [single factor] regression model to −26.7 in the multiple regression model) suggested a complex non-linear relationship between air pollution particles and the rate of AMD.\n\nTo further validate these finding, we examined the non-linear effects by additional methods. To that end, we used a cross-correlation analysis (Fig 2) which examines the associations between the seven air pollution particles, and AMD rate and compared them to the internal noise in the data (Fig 3). For this, the index of the localities was changed by a lag, such that the correlation between the pollution data of city i is examined with the AMD rates of city j. A peek correlation should be observed in Lag = 0 (x-axis), indicating a maximal correlation (i.e., above the noise in the data) only when the pairs “AMD in city i” and “air pollution in city j” are aligned with each other, i.e., (i=j). In these cross-correlation plots, the green horizontal lines show the three standard deviations limit (99% confidence), while the blue dashed line shows the two standard deviations limit (95% confidence). The correlation at lag=0 surpassed the three standard deviations limit for NO2, NOx, and CO pollutants, and barely for PM2.5. The data shows that PM10surpassed the two standard deviations limits (the blue dashed line) in both directions, similar to the case of O3, in which the autocorrelation is in the negative direction. These values should be compared to the shuffled vectors, which indicate the noise. These results show a clear effect of NO2, NOxCO on AMD rates and of PM2.5 to a lower extent, a weak negative effect of O3, and a weaker positive effect of PM10and no effect of SO2particles.\n\nEach point represents a locality. (A) NOx, R2= 0.151, p = 0.0001, (B) NO2, R2= 0.121, p = 0.00064, (C) CO, R2= 0.178, p = 1.498e−05, (D) PM10, R2= 0.088, p = 0.0037, (E) PM2.5, R2= 0.092, p = 0.00064 (F) O3, R2= 0.121, p = 0.0018 For SO2 (not shown), p = 0.926.\n\nEach point represents a locality. (A) NOx, R2= 0.151, p = 0.0001, (B) NO2, R2= 0.121, p = 0.00064, (C) CO, R2= 0.178, p = 1.498e−05, (D) PM10, R2= 0.088, p = 0.0037, (E) PM2.5, R2= 0.092, p = 0.00064 (F) O3, R2= 0.121, p = 0.0018 For SO2 (not shown), p = 0.926.\n\nhttps://doi.org/10.1371/journal.pone.0317436.g002\n\nIf an effect is found, we expect to see the cross-correlation bar only in 0. The blue dashed line represents the statistical significance of 95%. The green line represents a statistical significance of 3 standard deviations. A clear effect of 99% (bar is above/below the green line) was observed forNO2,NOx,CO, and PM2.5particles. For PM10the effect was only found for 95% confidence, while the effect ofO2andSO2was on the edge of acceptance, and thus might need further validation in a larger data set. The histograms are examples of the correlation values, to demonstrate the noise to signal ratio.\n\nIf an effect is found, we expect to see the cross-correlation bar only in 0. The blue dashed line represents the statistical significance of 95%. The green line represents a statistical significance of 3 standard deviations. A clear effect of 99% (bar is above/below the green line) was observed forNO2,NOx,CO, and PM2.5particles. For PM10the effect was only found for 95% confidence, while the effect ofO2andSO2was on the edge of acceptance, and thus might need further validation in a larger data set. The histograms are examples of the correlation values, to demonstrate the noise to signal ratio.\n\nhttps://doi.org/10.1371/journal.pone.0317436.g003\n\nTo further demonstrate this method, the lower right and lower middle sub-images ofFig 2are examples for NO2(which is significant), and for SO2(which is insignificant) showing the distribution of correlation values across 500 random permutations of cities. In these images, the red line represents theactualcorelation, while the dashed green line represents the 3 standard deviations control limits. These images show that the actual correlation (red horizontal line) of NO2is far to the right compared to the 99% (3 standard deviations) control limit, while this is not so for SO2.\n\nThese results strengthen our claim thatNO2,NOx,CO, and PM2.5contribute to the prevalence of AMD, even if these effects might be non-linear and with complex interactions between the different gases and particles.\n\nTo conclude, in these separate analyses, the coefficients of the air pollution gases in the univariate regression were all positive, reflecting an increase in the number of neovascular age-related macular degeneration (3.4 for NO2, 4.18 for NOx, 0.8 for CO, 0.74 for SO2) except for ozone (−3.018 for O3). The effect of SO2on AMD rate was not significant in the regression analysis or in the cross-correlation method. This suggests that while greater air pollution will result in higher rates of AMD, higher rates ofO3are likely to result in lower AMD rates. Regarding PM, the coefficient of PM10was found to be lower than those of the smaller particles (14.93 and 9.89 for PM2.5and PM10respectively). In the cross-correlation analysis, the effect of the larger particles was less significant but still above the 95% confidence limits (Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317436.t003\n\nAnalysis of the combined effect of air pollutants showed a more complex and non-linear effect on AMD rates (Table 4). A strong non-linear effect of air pollution variables was observed from comparing the simple regressiony=f(x1),y=f(x2),...,y=f(x7) to the multiple regressiony=f(x1, x2,..., x7).While in the separate regression modes all coefficients except O3were positive, and all pollutants but SO2were significant, in a multivariate regression model that included all 7 air pollutants the coefficients of O3, NO2and PM2.5were negative (Table 4). The inverse results also appeared in a second multiple regression model (Table 4) that included only NO2, NOxand SO2, where the coefficients were −23.80, 21.27 and −10.96, respectively. These inverse coefficients can appear when the interactions between the dependent and independent variables are highly non-linear.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317436.t004\n\nOur analysis of AMD rates and air pollution in 93 localities across Israel showed that AMD rates were higher in localities with greater air pollution. The interaction between air pollution particles and AMD seems to be complex and non-linear. All particles examined, except O3, were positively correlated with higher AMD rates. O3seems to have a protective role (probably due to ultraviolet [UV] filtering) on AMD rates. However, analysis of the effect of all air pollutant particles combined showed a complex and non-linear effect on AMD rate.\n\nOne possibility that needs to be overruled is that this is simply due to older people preferring larger cities (which are more polluted generally). To check this possibility, we calculated first the mean ages in each city. We then plot these cities mean ages against the major air pollution particles.\n\nWe could not find any evidence that cities with higher mean population ages are more polluted cities. We also validated this issue statistically. We separated the localities into two groups: One consisting of cities with an above average age and the second with those with below average ages. We then compare (t-test two sided) the mean levels of air pollution particles between the two groups. The p-values of these 7 t-tests are: 1. p-values = 0.63 (No2), 2. p-values = 0.55 (NOx), 3. p-values = 0.29 (CO), p-values = 0.90 (O3), p-values = 0.68 PM10, p-values = 0.38 (PM2.5), p-values = 0.12 (So2). As a p-value <  0.05 reflects a significant difference, based on these tests, we reject the hypothesis that cities with older citizens also have higher levels of air pollution. We conclude therefore that air pollution is likely to be the cause of the higher prevalence of AMD, and in any case, this is not due to polluted localities consisting of older habitants.\n\nOne needs to notice that AMD and air pollution were collected between 2015–2020 (AMD)/ 2016–2019 (Air pollution). This period does not permit a true longitude study of air pollution over many rears. Nevertheless, since air pollution is also highly correlated with the type of the location (large city blocks, small villages in rural regions or industrial zones), changes in which rural regions become highly industrial require tens of years.\n\nFuture studies should inspect longer periods, and possibly, check for the AMD rates in regions which were once rural, and later became highly industrials. It might be challenging however to find such rejoins since industrial rejoins tend to grow at the peripheral sides of cities and less in fully rural places.\n\nMost studies published to date have examined the relationship between exposure to PM2.5and the risk for AMD. In a population-based cohort study conducted in Taiwan (n = 4,284,128) between 2001 and 2011, the annual mean PM2.5exposure during the study period was 34.23 ±  7.17 μg/m3, and a chronic exposure to PM2.5increased the risk of AMD by 19% (95% confidence interval [CI] 1.13–1.25) for each 10 μg/m3increase in PM2.5. However, the risk reached a plateau and even showed some decreasing trend when PM2.5was higher than 35 μg/m3, suggested to be due to a ceiling effect or competing lethal diseases [17]. Similarly, a study with participants of the UK Biobank (n = 115,954) reported an increased risk for self-reported AMD with continuous increasing concentrations (µg/m3) of PM2.5(odds ratio [OR] = 1.08 [95% CI 1.01–1.16], p = 0.036), thinner photoreceptor synaptic region, thicker photoreceptor inner segment layer and thinner retinal pigment epithelium [23]. A cross-sectional analysis using data from the Canadian Longitudinal Study on Aging (n = 30,097), reported an increased risk of self-reported visually impairing AMD with an increase of one interquartile range (IQR) in PM2.5(OR = 1.52 [95% CI 1.10–2.09]); however, in multi-pollutant models after adjustment for sociodemographic characteristics and disease, increased PM2.5was not found to be associated with AMD. Furthermore, the mean PM2.5level was 6.5 µg/m3[22] – lower than the mean value reported in the study conducted in Taiwan [17]. In a national cross-sectional survey conducted across 10 provinces in rural China (n = 36,081), the average annual PM2.5level during the study period was 63.1 ±  15.3 µg/m3. A significant positive association was detected between AMD and PM2.5level, temperature, and relative humidity, in both independent and combined effect models [20].\n\nIn a study that investigated the association between ambient air pollution and AMD in 15,115 middle-aged and older adults (≥40 years) from the Korean NationalHealth and NutritionExamination Survey 2008–2012, ambient NO2andCOin current-to-5 prior years and PM10in 2-to-5 prior years were significantly associated with higher prevalence of early AMD, while O3in current-to-5 prior years was significantly associated with lower prevalence of early AMD. Interestingly, the relationship between air pollution and the prevalence of early AMD was more significant than the relationship between air pollution and the prevalence of late AMD, suggesting that air pollution affects the early stages of disease development [21]. A prospective analysis using Taiwan’s Longitudinal Health Insurance Program between 2000 and 2010 (n = 39,819) showed a higher risk for AMD in those exposed to high versus low concentrations of NO2(hazard ratio [HR] = 1.91 [95% CI 1.64–2.23], p < 0.001) and CO (1.84 [95% CI 1.5–2.15], p < 0.001) [18].\n\nIn another study conducted in Taiwan, AMD cases were also significantly associated with exposure to dust storm events, which carry high concentrations of PM [19].\n\nAs to these previous studies, the link between air pollution and AMD in [17], examined PM2.5 exposure using satellite-based remote sensing but ignored a known bias from sensing air pollution in upper atmospheric layers. In contrast [18], focused on ground-level traffic-related pollutants (NO2and CO), aligning with our approach, but excluded a broad set of pollutants such as O3, Nox, SO2,PM10and PM2.5. Study [19] investigated natural dust storms, emphasizing non-anthropogenic factors. The large-scale Chinese study [20], focused solely on PM2.5, while the Korean study [21] included O3, NO2, CO, and PM10 but excluded Nox, SO2and PM2.5. Notably, as in our case, the Korean study suggested protective effects of O3by prevention of UV exposure, but did not elaborate on UV-induced DNA damage pathways. Differences in climate and genetic diversity between Korea and Israel further distinguish these studies.\n\nThe Canadian study [22] identified PM2.5as the sole AMD-related pollutant, potentially due to its linear analysis method and reliance on self-reported AMD stages and ignored the other air pollutants. By comparison, the UK study [23] used (as we did) ophthalmologist-diagnosed AMD based on OCT imaging (and not self-reported questionnaires), finding PM2.5linked to higher self-reported AMD rates, while Nox, NO2and PM10were associated with retinal anomalies typically linked to AMD, though requiring expert analysis for confirmation.\n\nOur study stands and contributes to the growing evidence on air pollution’s detrimental effects on AMD. It analyses the full and comprehensive set of pollutant, while defining AMD based on OCT imaging rather than self-reports. Unlike remote sensing methods, the ground-level pollution measurements offer greater accuracy.\n\nAs air pollution’s impacts extend beyond the known global warming effects and as we show here (and by others) include real and concrete vision impairments for older adults. With the expected growth in life expectance and the growing levels of air pollution, further attention to this issue is warranted.\n\nSeveral potential mechanisms underlie the effects of air pollution on AMD. PM2.5has been associated with poor retinal structure, which may lead to AMD [23,27].\n\nExposure to high levels of PM, SO2, NO2, NOx, CO, and SO2can cause cellular damage through systemic oxidative stress, consequent lipid peroxidation, which activates the innate immune system and increases inflammation in the retina and cells, potentially resulting in increased risk of AMD [17,21,28,29]. The non-linear effects observed between air pollution and the rate of AMD might be explained through two separate DNA repair mechanisms: one repairing damage resulting of UV radiation and the other repairing oxidation damage. Oxidative stress reflects an imbalance between the production of reactive oxygen species and the body’s ability to remove it. Reactive oxygen species cause DNA base modifications as well as strand breaks. The primary mechanism for repairing oxidative damage is base excision repair, which involves the removal of the damaged DNA base and its replacement with a new one. UV damage primarily occurs through the formation of cyclobutene pyrimidine dimers and 6–4 photoproducts. These lesions block replication and transcription, leading to mutations and cell death. The primary DNA repair mechanism responsible for UV damage is the nucleotide excision repair [30]. which involves the removal of a segment of DNA containing the damaged lesion and its replacement with a new, undamaged strand. High air pollution rates seem to be associated with higher rates of ground level O3,which were shown to filter the UV radiation [31]. As O3filters UV radiation it may protect the retina from damage, in line with our findings that greater exposure to O3reduced the prevalence of AMD. Furthermore, regions in the world (such as Tibet, Nepal, and other high-altitude regions), which have relatively low air pollution, but high rates of UV radiation, have increased rates of AMD [32,33]. While these are mainly possible assumptions, the exact mechanism underlying the contribution of air pollution to AMD still requires further research.\n\nThis study’s strength lies in its evaluation of the effects of several known gas and PM pollutants. Additionally, the diagnosis of AMD was according to treatment criteria, which are more accurate than self-report or other forms of electronic medical records diagnosis.\n\nThe main limitation of the study is its retrospective nature. In addition, the changes over time could not be addressed. Furthermore, there may be long time lag between exposure to air pollution and AMD diagnosis. Lastly, we only addressed rates of neovascular AMD, which is a late manifestation of AMD that may also be affected by several other factors.\n\nIn the current work, we examined seven air pollution particles and their influence on the prevalence of AMD in 93 localities across Israel. NO2, NOx, CO and PM2.5and PM2.5were positively correlated with AMD rates, while O3was negatively correlated with AMD rates. However, analysis of the effect of all air pollutant particles combined showed a complex and non-linear effect on AMD rate, where only NO2 and NOx significantly influenced the rate of AMD. When using cross-correlation methods, which better fit an analysis of nonlinear phenomena, we found that CO is also strongly correlated with AMD. The predicted growth in life expectancy and environmental pollution are expected to increase the prevalence of AMD. A growing body of literature is accumulating from different countries, ethnicities and climates, pointing to the harmful effect of air pollution and its clear influence on AMD. While reducing air pollution is a major concern to global warming, increased rates of blindness at old age needs to alert decision makers no less, especially with prolonged lifespan.\n\nFurther investment in research related to this alerting topic needs to be concluded, to better understand the exact biological paths by which air pollution damages the retina. This may also shed light on the pathogenesis of this complex degenerative disease and possibly to find additional treatments. The role of countries and health organization is to raise awareness to this additional effect of air pollution on AMD and help to further reduce the rates of this blinding disease and by this - to reduce long term treatment expenses.\n\nFor initial air pollution data (N = 1,214 localities).\n\nhttps://doi.org/10.1371/journal.pone.0317436.s001\n\n(DOCX)\n\nRates of AMD in different localities across Israel.\n\nhttps://doi.org/10.1371/journal.pone.0317436.s002\n\n(PNG)\n\n(A) No2, (B), NOx, (C) CO, (D) PM2. Also, t-test were performed to check if cities with older populations have significantly more air pollution. For all seven air pollution particles, we reject this possibility.\n\nhttps://doi.org/10.1371/journal.pone.0317436.s003\n\n(PNG)\n\nWe find gender is rather equally distributed between the cities. Nevertheless, as seen in the image below, more women in our data suffer from AMD in age ranges of 75-90. This could also be due to different life span between genders.\n\nhttps://doi.org/10.1371/journal.pone.0317436.s004\n\n(PNG)\n\nWhile there are restrictions on ethnicity labelling in medical records in Israel. We do however have language-based clues for ethnicities. (1) represent Jewish towns (where the spoken language is Hebrew). (2) are mixed towns (where ethnicities are mixed, and the spoken language are Arabic and Hebrew, i.e., the population in a mixture of Arabs and Jews, (3) are towns where the spoken language is mostly Arabic, and ethnicities are mostly of Arab origins. One should note that the spoken language is not a clear ethnical recognition, as over 60% of Jewish population is of middle eastern origin.\n\nhttps://doi.org/10.1371/journal.pone.0317436.s005\n\n(PNG)\n\nWhile it seems like AMD is less prevalent in Arab towns, the data set of Maccabi health care is also balanced toward Jewish towns (which are more common in Maccabi health care). Further research is required to conclude this claim on a larger sample.\n\nhttps://doi.org/10.1371/journal.pone.0317436.s006\n\n(PNG)\n\nStronger correlation is clearly observed at LAG = 0, when city air pollution and AMD rates are aligned. There are restrictions on a full ethnicity labelling in medical records in Israel. We do however have language-based clues for ethnicities. (1) represent Jewish towns (where ethnicities can be highly varied). (2) are Arab towns, where ethnicities are mostly middle eastern. (3) are mixed towns, where again, ethnicities are mixed. While it seems as AMD is less prevalent in Arab towns, the data set is balanced toward Jewish towns (which are more common in Maccabi health). Further research is required to conclude this claim on a larger sample.\n\nhttps://doi.org/10.1371/journal.pone.0317436.s007\n\n(PNG)",
    "category": "earth_sciences"
  },
  {
    "title": "Evaluation of rural comprehensive development level and obstacle factors in various countries around the world",
    "authors": "Yiyong Chen, Ling Zhu, Jinzhao Du, Wuyang Hong, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0317282",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0317282",
    "content": "At present, major developing countries in the world are entering a stage of rapid urbanization, and rural transformation and development are accelerating. Conducting international comparisons of rural development, evaluating and diagnose rural development levels of various countries and summarizing the advantages of rural areas in developed countries. These summaries and comparisons are important for developing countries to implement rural revitalization and promote the transformation of rural regional systems. Basing on the connotation of rural development, this study constructs an evaluation index system for rural development level worldwide. Through AHP-entropy method, TOPSIS method, obstacle model, and regression model, this study analyzes the rural comprehensive development level of 175 countries and regions and obstacle factors on the basis of statistical data from the United Nations and World Bank. Results suggest significant differences in the comprehensive development level of rural areas among countries at the global level. In addition. The comprehensive development level of rural areas exhibits definite correlations with national income level, per capita GDP, and the Human Development Index (HDI), among which it shows the weakest correlation with the level of urbanization. The main obstacle factors to rural development in various countries are agricultural mechanization level, agricultural land output rate, average per labor of cultivated land area, number of doctors per thousand, and per capita income of farmers. The factors affecting the rural development level are resource endowment, economic development level, education level, and government support for agriculture. Based on the research findings, this study proposes strategic recommendations for improving the rural comprehensive development level from the perspectives of agricultural and rural development and the living standards of farmers.\n\nCitation:Chen Y, Zhu L, Du J, Hong W (2025) Evaluation of rural comprehensive development level and obstacle factors in various countries around the world. PLoS ONE 20(4):\n           e0317282.\n        \n        https://doi.org/10.1371/journal.pone.0317282\n\nEditor:Changjian Wang, Guangzhou Institute of Geography, Guangdong Academy of Sciences, CHINA\n\nReceived:February 27, 2024;Accepted:December 24, 2024;Published:April 18, 2025\n\nCopyright:© 2025 Chen et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data cannot be shared publicly because of the data comes from a third party, we are not authorized to share the data, Data are available from the Worldbank and FAO (contact viahttps://data.worldbank.org.cn/andhttps://www.fao.org/faostat/zh/#data) for researchers who meet the criteria for access to confidential data. The data underlying the results presented in the study are available fromhttps://data.worldbank.org.cn/andhttps://www.fao.org/faostat/zh/#data. The sources of all data can be viewed inTable 1.\n\nFunding:Fund; Major Program of the National Natural Science Foundation of China (42293273).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nIn recent years, numerous major developing countries across the globe have entered a period of rapid urbanization. With rural populations continuing to migrate to cities, rural transformation and development are accelerating. Urbanization has attracted much attention worldwide. Most countries are consistently encouraging urban expansion to stimulate economic development and enhance the overall quality of national life. However, the issue on rural decline, stemming from the process of urbanization, had been inadequately addressed [1,2]. Particularly in the process of urbanization in developing countries, the discord and division between urban and rural areas are severe, and the kinetic energy of rural development is insufficient. And it is accompanied by practical problems such as rural depopulation, soil erosion, and aging population, which exacerbate the risks and crises associated with rural transformation and development [3,4]. Achieving the Sustainable Development Goals (SDGs) will be difficult in a world characterized by a huge urban–rural development gap [5]. Carrying out international comparisons of rural development, evaluating and diagnosing the rural development levels of different countries, summarizing the strengths of developed nations in rural development, and identifying obstacles to rural development are crucial steps in implementing rural revitalization and promoting the transformation of rural regional systems in developing countries.\n\nNumerous studies have been conducted on rural transformation and development, including sustainable development [6–8], development and transformation [8–10], rural revitalization [1,11–13], and rural development evaluation [14–16], among others. Quantitative evaluation of rural development level is a key concern for scholars. The earliest quantitative research on rural areas in Western countries can be traced back to the 1960s. Božović and Đurašković emphasized that more attention should be paid to human factors in future agricultural development [17], Li et al. [18] believed that achieving a balanced development of modern agriculture necessitates considering multiple dimensions, including the economy, society, population, environment, and resources. These perspectives provide valuable insights for rural development and construction in developing countries.\n\nIn terms of evaluating rural development level, many scholars have explored methods for measuring the levels of rural revitalization, urban–rural integration, or rural development. Cloke and Edwards [19] proposed an analytical framework for rural development from the perspectives of population, transportation, and land use. Gulumser et al. [20] conducted a comprehensive evaluation on rural structures in Turkey by using indicators from the Organization for Economic Co-operation and Development and European Union. Wu [21] and Zhang [22] performed evaluations of rural revitalization and rural modernization development in specific provinces, respectively. Geng et al. [23] constructed a comprehensive index system within a 5E framework for forecasting rural development. Xie et al. [24]measured urban–rural integration at the city level using multi-source data. Yang et al [25] explored evaluation methods for high-quality development of agricultural economy. Tang et al. [26] investigated evaluation methods for the level of cultural-tourism integration development in traditional villages.\n\nRural areas are complex territorial systems with multifaceted structural elements [12]. In the quantitative evaluation of rural development, the establishment of an evaluation index system holds particular significance. Cloke [27] initially introduced the concept of a rurality index in the 1970s. Vicki et al. [28] further elaborated on the rurality index proposed by Cloke, and Woods [29] extended Cloke’s rurality index system. Many scholars [19,30,31] improved the research framework for the rurality index, considering research methods, index selection, and weight determination. There is a wealth of research findings on the evaluation of rural development levels. For example, Zhang et al. [32], Qian et al. [33], and Qin et al. [34] established evaluation index systems for agricultural and rural development levels at varying scales. Zhang [22], Liang et al. [35], and Chen et al. [36] evaluated agricultural and rural development levels and explored the associated obstacles at national, regional, and provincial levels. Most studies primarily focus on countries or regions at the research scale, such as Qin et al. [37], Xin et al. [38], and Zhang et al. [39], who measured and ranked rural modernization in China. Qin et al. [34] and Luo [40] assessed agricultural and rural development levels in Shandong and Wuhan, respectively.\n\nRegarding the composition of the indicator system, Martin K. et al. [41]constructed an evaluation index incorporating aspects of the economy, society, and environment, grounded in the sustainability of agricultural systems. Waldorf [42]conducted county-level rural development evaluation using criteria such as “population size, population density, proportion of urban population, and distance to the nearest city”. Rezaei and Karami [43] and Carof et al. [44] evaluated rural development holistically, considering economic, social, and ecological (environmental) dimensions. Binsswanger et al. [45]appraised rural development based on five facets: farmers themselves, government policies, infrastructure development, geographical location, and natural resources. Qian [33] structured the index system around three levels: agriculture, rural areas, and farmers, whereas Qin [34] constructed an index system with four levels: factor output, development support, output benefits, and multifunctional expansion. Guo and Hu [46] attempted to integrate general requirements for rural revitalization strategy, the “five-in-one” overall layout, prioritized agricultural and rural development, and integrated urban–rural development to establish an evaluation system. Some scholars developed a five-dimensional evaluation system for rural development on the basis of China’s “Twenty Character” Policy for Rural Revitalization Strategy [39,47]. These studies primarily focus on developing countries or regions, and their findings provide valuable references.\n\nFew scholars have undertaken a comprehensive global evaluation of rural development across various countries, providing an international perspective on the state of diagnosing the level of rural development in developing countries. These studies that comprehensively compare rural development across countries worldwide shed light on the development trajectories of developed nations, exploring China’s unique characteristics and existing gaps, and distill lessons Western countries can offer. These insights serve as valuable references for the rural development strategies of developing countries, including China. In light of this gap in the literature, this study, building upon existing research, constructs an evaluation index system for rural development in countries worldwide to quantitatively assess the rural development levels across nations. The study also explores the constraining factors affecting rural development, identifies the primary disparities between typical developing countries and developed nations, synthesizes the experiences of developed countries, and presents tailored recommendations for future rural development in developing countries.\n\nResearch on the comprehensive evaluation of rural development is continuously enriching. The development of agricultural economies, the social life of rural residents, and rural ecological environments represent the primary focus areas of current studies. Agriculture, rural areas, and farmers are the core elements of rural development, with the well-being of the farmers at its heart [48]. Both agricultural and rural development are equally critical, and key strategies include enhancing agricultural productivity and improving living conditions in rural areas. Historical and contemporary perspectives underscore the importance of adopting a broad historical view when addressing issues related to agriculture, rural areas, and farmers. Problems associated with these three aspects—commonly referred to as ‘San Nong’ issues—are considered an inevitable outcome of the agricultural society’s transformation [49]. This phenomenon is evident in the industrial transformation processes of various countries globally. This manuscript constructs an evaluation index system from the perspectives of agriculture, rural areas, and farmers.\n\nThe methodology for the comprehensive evaluation of rural development is becoming increasingly systematic and diversified. Typically, this involves the construction of a complete evaluation system, followed by the assignment of weights to various indicators using specific methods, and the application of scientific evaluation models for calculation. This manuscript employs a combination of subjective Analytic Hierarchy Process (AHP) and objective entropy weight method to determine the weights of each indicator. Subsequently, the Topsis method and others are utilized to derive the final evaluation results [50,51].\n\nThis manuscript draws upon existing research findings and is grounded in adherence to fundamental principles such as scientific validity, representativeness, accessibility, and global applicability, and global applicability, and also takes into consideration the availability of global data, this study establishes an evaluation system comprising 27 specific indicators across eight dimensions. These dimensions include agricultural production, output quality and benefits, green sustainability, agricultural support, social development, human settlement environment, quality of life, and cultural education. These indicators are organized around three subsystems: agricultural development, rural development, and farmers’ lives. (Table 1). In addition, the selected indicators were subjected to a collinearity diagnosis, with Variance Inflation Factor (VIF) values below 10, confirming the rationality and representativeness of the indicator selection.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.t001\n\nTwenty experts in this field are invited to subjectively assign weights to the evaluation indexes and create a judgment matrix. Subsequently, hierarchical ordering and consistency testing are conducted to derive the subjective weights for various evaluation indicators. The Consistency Ratio (CR) values of the judgment matrices, 0.097 and 0.056 respectively, are both less than 0.1, indicating that they pass the consistency test.\n\nThe main steps are data standardization, calculation of information entropy, and the determination of weights based on information entropy.\n\nThe AHP method is employed to assign weights to the three criteria layers and eight sub-criteria layers of the evaluation index system. Subsequently, the entropy method is utilized to ascertain the weights of the standard layer within the criteria layer. Finally, the combined weights are calculated.\n\nThe TOPSIS comprehensive evaluation method assesses research objects by ranking their distance from the evaluation object to the optimal and inferior solutions. This method is widely used in various evaluation studies [51,52].\n\nStep 1. Construct a weighted matrix.\n\nStep 2. Determine the optimal solutionand the inferior solution by basing on the weighted matrix constructed in the previous step.\n\nStep 3. Calculate the Euclidean distance D from various index schemes to the optimal solutionand the inferior solution.\n\nStep 4. Evaluate the rural comprehensive development level.\n\nWhererefers to comprehensive rural development level of theithcountry. A larger value indicates a higher comprehensive rural development level.\n\nTo further analyze the factors constraining the comprehensive development level of rural areas in various countries, this study determines obstacle factors affecting comprehensive development progress. This analysis is based on the comprehensive evaluation results of rural development level, utilizing factor contribution degree, deviation degree, and obstacle degree of indexes, combined with the obstacle model analysis method.\n\nFactor contribution degree () refers to the influence of individual indexes on overall objective and is represented by index weight (Eq 7). Index deviation degree () refers to the distance between single index and development objective, that is, the distance from standardized value of index to 100% (Eq 8). Obstacle degree () quantifies the hindrance level of each index to the comprehensive development level of rural areas and is calculated using Eq 9:\n\nIn this study, multiple linear regression model [53] is used to establish relationships between the comprehensive development level in rural areas (dependent variable) and multiple factors X1,X2,…,Xn(independent variables).\n\nRural areas are complex regions influenced by multiple factors, and comprehensive rural development is likewise the result of multiple factors. Economic, industrial, geographical, demographic, resource-based, and topographic all impact development in rural areas. Basing on existing research [54–56], we select measurement indexes related to natural resources, economic and industrial development, population and social development, and transportation infrastructure as the main influencing factors. The selection is made with consideration of the representativeness and accessibility of these indexes. Specifically, it includes:\n\nThe data primarily originates from the World Bank (https://data.worldbank.org.cn/) and the Food and Agricultural Organization of the United Nations (https://www.fao.org/home/zh/). It includes data on agricultural production, agricultural output quality, government expenditure on agricultural support, rural social development, natural environment, and socio-economic development. The data is consistently standardized, encompassing basic information from the majority of countries globally, and is highly reliable for global-level comparisons. It is primarily based on 2020 data, with any missing 2020 data replaced by the latest available data. Countries with significant missing data are excluded. The dataset comprises a total of 175 countries and regions. The World Bank’s public database, which aggregates data at the national level, primarily sources its data from the statistical systems of its member countries. These systems adhere to internationally recognized standards and norms, thereby ensuring reliable and high-quality data. The Bank’s various regions and departments collaborate closely to maintain stringent quality control and integrity of the data throughout its collection, compilation, and dissemination. This data is published in various formats in an extensive array of data publications. The FAO Statistical Database, managed by the United Nations, is the largest global database on food, agriculture, and natural resource management. Verified and published by subject experts and statistical personnel, this database provides high-quality data to assist governments in enhancing their operational quality. These data, having consistent statistical standards and covering the basic information of the vast majority of countries worldwide, are highly credible and suitable for global comparisons.\n\nThe objective of this manuscript is to assess the current state of rural development across a range of countries globally. Consequently, the manuscript primarily employs the most comprehensive and recent data available from the year 2020. In instances where certain indicators were absent, interpolation was employed using the most recent available data. Furthermore, countries and regions with substantial data gaps, such as Gibraltar and Monaco, were excluded from the analysis. Similarly, regions with low comparability, such as the Channel Islands and the Cayman Islands, were also excluded from the analysis. In conclusion, a total of 175 countries and regions were included in the evaluation.\n\nThe combination weighing process involves the adoption of the AHP and entropy methods. The consistency ratios (CR) obtained from the CR test judgment matrices are 0.097 and 0.056, both falling below the 0.1 threshold, thus satisfying the consistency test. The final weightings are displayed inTable 2. At the criterion level, the weights assigned to agricultural development, rural development, and farmers’ living standards are 0.569, 0.242, and 0.189, respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.t002\n\nThe overall evaluation results for rural comprehensive development levels are illustrated inFig 1, with an average score of 0.382. The natural breakpoint method is employed to categorize comprehensive rural development into five intervals: high level (above 0.462), moderate to high level (0.413–0.462), moderate level (0.368–0.413), moderate to low level (0.324–0.368), and low level (below 0.324) (Fig 2). Notable countries with the highest rural development levels globally include Switzerland, Japan, South Korea, Germany, and the United States. Countries with the lowest rural development levels consist of Afghanistan, Myanmar, Pakistan, Kenya, South Sudan, and other less developed nations. China, as the world’s largest developing country, stands at a moderate level of rural comprehensive development with a score of 0.39, slightly surpassing the global average but still trailing behind developed nations.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.g002\n\nFrom a spatial perspective, rural areas in North America, Oceania, and Europe exhibit relatively high development levels, exemplified by countries like Canada, Australia, and Germany. In contrast, most rural areas in Africa fall below the global average level, including nations such as Egypt, Kenya, and the Congo. Asia and South America generally fare well, mostly achieving moderate or higher levels of development.Regions such as North America, which benefit from higher natural, economic, and social levels, exhibit correspondingly advanced levels of rural comprehensive development. Conversely, regions such as Africa, where economic development is significantly lagging behind that of Europe and other regions, exhibit comparatively poorer levels of rural development. This pattern demonstrates a clear dichotomy between the northern and southern regions, with the former exhibiting higher levels of development than the latter.\n\nIn this study, by applying a three-dimensional K-means clustering analysis, we identified distinct patterns of performance across the key dimensions of agriculture, rural areas, and farmers among various countries. Three prominent clusters were described, representing different performance patterns among national groups(Fig 3):\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.g003\n\nThe World Bank classifies world economies into four categories based on per capita gross national income: low income (<$1035), medium to low income ($1036–$4045), medium to high income ($4046–$12535), and high income (>$12536). A significant disparity in rural development levels is observed among different income types (Fig 4), with high-income countries showcasing substantially superior rural development compared with the other three categories.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.g004\n\nCountries are categorized into four levels based on per capita GDP: high poverty level (<$2000), poverty level ($2000–$5000), moderate level ($5000–$10896), and developed level (>$10896, i.e., the world average in 2020).Fig 5demonstrates a close relationship between rural development levels and economic status. However, significant variations persist among countries at the same development level. Some highly developed countries, such as Argentina, Turkey, Panama, and Chile, exhibit relatively lower rural development levels.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.g005\n\nCountries are divided into four categories based on their HDI scores in 2020: low HDI (<0.550), moderate HDI (0.550–0.699), high HDI (0.700–0.799), and extremely high HDI (≥0.800).Fig 6illustrates that the rural comprehensive development level is closely aligned with HDI. Nations with high and extremely high HDI scores boast high or relatively high rural comprehensive development levels. Among low HDI countries, 25% exhibit moderate to low levels of rural development, whereas 75% are characterized by relatively lower development levels.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.g006\n\nCountries are classified into three stages of urbanization on the basis of the 30% and 70% thresholds: initial stage, accelerated stage, and later stage. A clear intersection between urbanization level and rural comprehensive development is discernible, as illustrated inFig 7. During the initial and accelerated stages of urbanization, countries tend to exhibit lower rural comprehensive development levels, whereas the late stage of urbanization generally corresponds to higher development levels.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.g007\n\nTable 3demonstrates the correlation between the rural comprehensive development level and various factors such as income type, per capita GDP, HDI, and urbanization rate. The ranking of rural comprehensive development level exhibits strong correlations with income type, per capita GDP, and HDI, as indicated by correlation coefficients of 0.935, 0.934, and 0.937, respectively. However, the correlation between the ranking of urbanization rate and rural comprehensive development level is relatively modest at 0.693. This suggests that the ranking of rural comprehensive development aligns with overall national income, per capita GDP, and HDI ranking but diverges significantly from the ranking of urbanization levels. For instance, Panama, despite being a high-income country, maintains a moderate level of rural development. By contrast, Guyana, still in the initial stage of urbanization, exhibits a moderate to high level of rural development.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.t003\n\nTo further analyze the key factors hindering the comprehensive development of rural areas in various countries, the obstacle model measures the obstacle degree of individual indexes across countries and identifies the primary obstacle factors that constrain rural comprehensive development. Factors with obstacle degrees (O_ij) greater than 5% are considered main obstacle factors [32,57], and their frequency of occurrence is summarized.\n\nThe eight main obstacle factors affecting rural comprehensive development worldwide are agricultural mechanization level, agricultural land output rate, per unit land area grain yield, arable land per person, government expenditure on agricultural support, physician number, road network density, and per capita income. Additionally, agricultural water consumption and forest area proportion are identified as obstacle factors in some countries, but less frequently.\n\nComparing obstacle factors between developed and underdeveloped countries reveals notable differences. Common obstacle factors across both groups include agricultural mechanization level, agricultural land output rate, per unit land area grain yield, the physicians number and arable land per person. In underdeveloped countries, per capita income is a prominent obstacle factor. Conversely, developed countries face challenges related to government expenditure on agriculture, among others.\n\nThe multiple linear regression analysis model yields an adjusted R2of 0.898 and an F-value of 103.124, both significant at the 0.01 level. Tolerance values exceed 0.1, and the variance inflation factor (VIF) remains below 3 after testing, indicating no significant multicollinearity among independent variables (Table 4). The Durbin–Watson value stands at 2.084, suggesting that residuals are independent, and standardized residuals approximate a normal distribution. These results affirm the reasonable setup of the model.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317282.t004\n\nOn a global scale, indicators related to agricultural production, such as green sustainable development level and crop production index, have relatively low obstacle degrees to rural development. Although countries vary significantly in green sustainable development levels, the obstacle degree remains relatively low. Crop production index and livestock production index show little variation among different countries. Improving agricultural production efficiency and increasing government expenditure on agricultural support remain the primary pathways for the vast majority of countries to enhance the comprehensive development level of rural areas. In terms of rural development, factors such as electricity, drinking water, networks, and other infrastructure, along with the Forest area proportion in rural areas, are not core obstacles. However, global disparities in healthcare levels and road network density remain significant. In terms of farmers’ life, this study employs numerous indicators for comprehensive evaluation, but only per capita income serves as an obstacle factor. This underscores that enhancing per capita income remains a central lever for improving rural living standards. Per capita income directly measures farmers’ life [59], which is the ultimate goal of rural revitalization and the most pressing obstacle to address\n\nDrawing on prior research, this study has devised an evaluation index framework for rural development encompassing agricultural, rural, and farmer dimensions. It aims to comprehensively assess and juxtapose rural development across diverse countries. Both obstacle and regression models are employed to pinpoint hindrances and influencing factors. Additionally, this research has distilled the experiences of developed nations, formulating specific recommendations for China’s future rural development. The results indicate the following:\n\nBuilding upon these research findings and considering the particular circumstances of developing nations, including China, the following recommendations are put forward to improve rural development in the future:",
    "category": "earth_sciences"
  },
  {
    "title": "The impact of policy incentives and value perception on rural residents’ clean heating behavior: Evidence from northern China",
    "authors": "Yuxuan You, Xia Xu, Guanqiu Yin, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321936",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321936",
    "content": "Implementing energy transition in rural areas is crucial for China to achieve its low-carbon transition in energy consumption and dual-carbon goals. This study aimed to elucidate policy effects and further analyze the mediating effect of value perception to provide a reference for building a long-term rural energy transition mechanism. We constructed a “policy incentives–value perception–behavior” theoretical analysis framework and used survey data collected from residents of northern China. A logit model was employed to empirically test the effects of advocacy, demonstration, and subsidy policies on residents’ clean heating behavior. We used a mediation effect model to examine the mediating effects of economic, functional, social, and emotional value perceptions. The results showed that all three policies significantly positively impacted residents’ clean heating choices, with subsidy policies exerting the best effect. These findings suggest that implementing policy incentives can influence residents’ behavior by enhancing their value perceptions. However, different types of policies may act through distinct pathways. Compared with previous studies that focused solely on the impact of policy or value perception on clean heating behavior, this study explored their interactive relationship and found that external policy incentives can be transformed into internal driving forces. Therefore, value perception should be considered during policy formulation to build a long-term mechanism for promoting energy transition in rural areas.\n\nCitation:You Y, Xu X, Yin G (2025) The impact of policy incentives and value perception on rural residents’ clean heating behavior: Evidence from northern China. PLoS ONE 20(4):\n           e0321936.\n        \n        https://doi.org/10.1371/journal.pone.0321936\n\nEditor:Jiachao Peng, Wuhan Institute of Technology, CHINA\n\nReceived:August 26, 2024;Accepted:March 12, 2025;Published:April 17, 2025\n\nCopyright:© 2025 You et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:This study was supported by the National Social Science Foundation of China (22&ZD083); Liaoning Provincial Department of Education General Project (JYTYB2024033); Humanities and Social Sciences Project of the Ministry of Education (23YJC790177); Liaoning Province Social Science Key Planning Project (L22AGL016). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nRural energy transition is related to sustainable environmental, economic, and social development. As early as the 1960s–70s, developed countries had completed the transition from bulk coal to natural gas heating in winter. However, in the rural areas of northern China, scattered coal combustion has remained the mainstay owing to dispersed settlements and a lack of infrastructure [1]. This heating method causes severe winter pollution [2,3]. Clean energy (cleaner coal, gas, electricity, geothermal, solar, etc.) is generally more efficient and causes less pollution [4–6]; however, owing to the relatively high cost of clean energy and the lack of policy interventions, rural areas using clean heating accounted for less than 20% at the end of 2016 [7]. To promote the energy transition, the Chinese government issued “Planning of Winter Clean Heating in North China.” By 2022, China had invested 107.1 billion yuan in five clean heating batches comprising 88 pilot cities. However, because of the excessive economic burden, inexperience with electric heating equipment, and other problems, residents showed low willingness to adopt clean heating. Consequently, the clean heating penetration rate is extremely low, and loose coal is reburned in many rural areas [8,9]. An understanding of the factors that influence residents’ energy demand is necessary to achieve a rural energy consumption transition.\n\nGiven the intense concerns regarding air pollution and carbon emissions, clean heating in the residential sector has become a trending topic. Many studies have established the importance of residents’ family endowments, individual characteristics, and attitudes as internal influencing factors on clean heating behavior (CHB). Early studies analyzed the impact of household income on the structure of energy consumption, as represented by the energy ladder theory, which suggests that household energy choices move from primitive to transitional as income increases. Based on this theory, studies have compared consumption structure characteristics and energy transition speed in rural and urban areas [10,11]. Rural residents’ willingness to pay for clean energy increases as their income rises [12], and higher-income households prefer cleaner heating choices [13,14]. Off-farm work can significantly increase rural household income and, ultimately, energy use [15,16]. Choosing clean heating is also related to factors such as age, gender, and education [17–20]. In addition to these socioeconomic factors, rural residents’ decisions depend on their attitudes, and value perception is the most fundamental reason for the formation of farmers’ attitudes. A household survey conducted in Greece showed a significant relationship between household willingness to adopt new heating technologies and people’s environmental awareness and perceptions [20]. Fan and Huo. (2021) [21] assessed the likelihood of rural residents’ participation in CHB in terms of their perceptions of ease of use, convenience, and other characteristics of clean heating technologies. Additionally, Xiong et al. (2021) [22] evaluated rural residents’ environmental perceptions and explored the role of their perception intensity in heating behavior.\n\nThe use of clean energy is a common externality issue. Governments in Europe and Japan have examined residents’ use of clean energy and its economic effects to create reasonable policy incentives [23,24]. For Chinese cities in the Beijing–Tianjin–Hebei area, the higher the financial support for clean heating, the higher the clean heating rate [25]. Some studies have analyzed how to set reasonable subsidy standards. Li et al. (2021) [26] constructed a model containing clean heating options, rekindling rate, and clean heating costs, and measured the optimal subsidy standard and amount. Yan et al. (2020) [27] used the minimum data method to incorporate the pollution emissions reduction target and heating subsidy standard into the same model and found that a monthly compensation of 9 yuan/m2could reduce pollutant emissions by 96.7%. Other scholars have argued that fuel subsidization is unsustainable [28,29]. Some studies have actively explored the effects of policies such as demonstrations and technical support [26,30,31]. However, specific problems were found in policy implementation, such as problems with economic affordability among poor farmers, high clean energy costs, low sustainability of subsidies, and incompleteness of subsidy policies [21]. The gap between subsidies in China and the population’s actual needs is approximately 50% [32]. Households are also likely to return to coal heating within 3 years following the cessation of the local financial support policy [33].\n\nIn summary, existing studies have analyzed the factors influencing residents’ CHB based on both intrahousehold and policy factors. However, the literature has several shortcomings. First, it focuses mainly on subsidy policies. As shown above, their effect is limited. When many subsidies are available, the local financial burden becomes heavy. Thus, a multidimensional policy mix is required. Second, most previous studies separately explored the impact of value perception and policy incentives on CHB, while neglecting their interactive relationship. Policies have alternative and complementary functions to marketing, and if relevant policies can be assimilated into residents’ value perceptions, they will contribute to building a long-term promotion mechanism for rural energy transition. Third, these studies’ analyses used relatively little household-level research data. Most relied upon macrodata or case studies to evaluate policy effects. Residents are both implementers and beneficiaries of clean heating, and a better understanding of heating energy use at the household level is needed.\n\nIn view of this, the present study obtained the survey data of rural residents in northern China, constructed a theoretical analysis framework based on the perspective of external incentives and endogenous driving forces, employed a logit and mediation effect model to test the impact of policy incentives on residents’ CHB, and further explored the mediation effect of value perception to provide a theoretical basis for improving clean heating policy and promoting rural energy transition. This study contributes to the existing literature in three ways. First, in addition to examining subsidy policies, we analyzed the influence of advocacy and demonstration policies on CHB. Second, we constructed a theoretical analysis framework comprising “policy incentives–value perception–behavior” to answer the questions of whether and how external policy incentives can become internal drivers. Finally, combining both policy and value perception in the model helped to avoid the endogeneity problem caused by the omission of variables, and replacing the policy variable with whether a city was a pilot city improved the reliability of the results.\n\nCHB has external effects. If the economic cost greatly exceeds the direct benefits generated during implementation, rural residents will be insufficiently motivated to adopt clean heating [34]. Therefore, when promoting a heating strategy, the government should maximize the internalization of the externality of CHB through a series of policy tools to promote the adoption of clean heating [35]. Currently, the main types of clean heating policies in northern China are advocacy, demonstrations, and subsidization. Advocacy policies refer to the government’s promotion and popularization of clean heating, which can increase residents’ awareness of the benefits of clean heating and clean heating products [36]. Demonstration policies refer to the government’s adoption of relevant agricultural demonstration projects to dispel rural residents’ concerns about using clean heating products and transform their wait-and-see attitude into heating behavior [37]. Finally, residents reap direct benefits through government-implemented economic compensation and reward measures, which enhance their enthusiasm for adopting clean heating [38]. Therefore, we proposed the following hypothesis:\n\nHypothesis 1 (H1): Policy incentives significantly positively impact the CHB of rural residents in northern China.\n\nAccording to the theory of behavioral economics, a person’s rational or irrational behavior is affected by their cognitive level and perception [39,40]. Value perception is a subjective balance between effort and gain based on existing cognition, and is thus a key variable in exploring individual willingness and behavior. When rural residents pay to adopt clean heating, they gain benefits such as convenience of life, environmental improvement, and maintenance of physical health. However, they also face risks and costs including increased heating costs, the maintenance costs associated with heating equipment, and an unstable energy supply [41]. Hence, when rural residents are deciding whether to adopt clean heating, they evaluate its benefits and risks, thus forming a subjective perception of value.\n\nValue perceptions can be divided into economic, social, functional, and emotional. Additionally, the establishment of rural residents’ value perception is influenced not only by personal characteristics but also by external factors [42,43] including government incentives and neighborhood behaviors. The government employs affirmative incentives such as subsidies, demonstrations, and advocacy to enhance rural residents’ perceptions of the value of clean heating, helping them recognize its long-term advantages. As policy incentives increase, residents’ appreciation of the value of clean heating strengthens steadily, thereby fostering a greater inclination toward adopting a clean heating method. Therefore, the policy not only directly impacts rural residents’ CHB but also indirectly affects their behavior by changing their value perception. Therefore, we proposed a second hypothesis:\n\nHypothesis 2 (H2):Policy incentives indirectly affect CHB by influencing residents’ value perception.\n\nBased on the above theoretical analysis, we constructed a framework for policy incentives, value perception, and clean heating decision-making among rural residents in northern China (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321936.g001\n\nWe obtained the data used in this study from an online survey conducted in January–March 2023 among rural residents of northern China. We obtained ethical clearance from the Shenyang Agricultural University (reference number: SYAU2023012309). The survey was conducted in the northern regions designated in the “Clean Winter Heating Plan in Northern China” (referred to as the “Plan” hereinafter); these include 15 provinces and cities: Heilongjiang, Jilin, Liaoning, Inner Mongolia, Beijing, Tianjin, Henan, Hebei, Shanxi, Shandong, Shaanxi, Ningxia, Gansu, Qinghai, and Xinjiang. To collect larger samples from different areas, we distributed an online questionnaire to rural residents for voluntary and anonymous completion. The questionnaire included a specific item inquiring about the heating methods respondents used throughout winter. To ensure the inclusion of suitable participants, sample selection involved a blend of stratified and snowball sampling. Initially, we categorized the northern region into pilot and non-pilot areas in accordance with the guidelines outlined in the “Plan.” Subsequently, 50 cities were randomly selected from both areas. Approximately 10 rural residents who practiced independent winter heating were selected from each city to complete the questionnaire. Following a snowball sampling approach, participants were asked to provide information about other potential survey candidates. To improve the sample’s representativeness, we administered supplementary surveys based on an analysis of the main survey respondents’ distribution across different areas. The supplementary surveys were conducted to adjust the sample sizes in the pilot and non-pilot areas to achieve a balanced distribution and ensure an adequate number of samples from representative regions. During the supplementary survey phase, the northeastern region sample size increased owing to the region’s low winter temperatures and long periods requiring heating. To reduce the potential sample selection bias inherent in snowball sampling, we selected the first batch of survey participants from among rural residents with diverse occupations. To improve the quality of the questionnaire responses, we included logical analysis questions to determine whether the respondents had answered seriously and whether the data provided were logically consistent. Moreover, geographical restrictions were imposed based on respondents’ IP addresses to prevent multiple responses from the same individual. Questionnaires with excessively short completion times, responses that were inconsistent with the research area, and errors and omissions were filtered to ensure the accuracy, validity, and representativeness of the research data. We collected 546 questionnaires from respondents in 104 cities, of which 57 were pilot cities (54.81%), and 47 were non-pilot cities (45.19%). The questionnaire covered rural residents’ personal and household characteristics, clean heating features, and value perceptions. Samples with missing data, abnormal values were excluded. Finally, we obtained 477 valid questionnaires, resulting in an effective response rate of 87.36%.\n\nGiven that the adoption of clean heating among rural residents in the northern regions represents a typical binary decision-making scenario, we employed a binary logit model to analyze various influential factors. We established the regression model as follows:\n\nwhererepresents policy incentives divided into advocacy, demonstration, and subsidy policies;is the control variable;is CHB; andPis the probability of CHB. The binary logit expression is:\n\nWe constructed a mediator model to test the mechanism of policy incentives’ effect on CHB to determine whether they promote CHB through value perception. Based on a previous study [44], the mediator model was constructed as follows:\n\nwhereis the mediator variable, andεis the perturbations term. The mediating effect was tested in three steps. Step 1 entailed regressing Model (4). A significant coefficientaindicated that policy incentives affected residents’ CHB, and we proceeded to the next step. Step 2 entailed regressing Model (5). A significant coefficientbindicated that policy incentives affected value perception, and we proceeded to the next step. Step 3 entailed regressing Model (6). Significant coefficientsa′andcindicated that the impact of policy incentives on rural residents’ CHB was at least partially realized through their value perceptions. Ifa′was not significant in Model (6), value perception showed a full mediating role. Furthermore,ain Model (4) represents the total effect,refers to the mediating effect, anda′is the direct effect. Calculating the proportion of the direct and mediating effects in the total effect facilitated a comparison of the degree of the direct and mediating effects.\n\nWe investigated rural residents’ CHB, that is, whether residents adopted clean energy sources with ultra-low emissions for heating purposes, such as natural gas, electricity, geothermal energy, biomass, solar energy, or clean coal. If a resident adopted clean heating, the assigned value of the dependent variable was 1; if a resident did not adopt clean heating, the value of the dependent variable was 0.\n\nThe core independent variable was policy incentives in the context of clean heating policies in rural northern China. We categorized policy incentives into three types: advocacy, demonstration, and subsidy. We measured advocacy policy implementation by assessing whether the government advocated clean heating through the provision of related technical information. We measured demonstration policy implementation by determining whether a clean heating demonstration project existed near a given village. We measured subsidy policy implementation by asking whether residents received clean heating subsidies. A relevant policy was assigned a value of 1, and 0 otherwise.\n\nBased on Sweeney’s (2001) [45] value perception measurement scale and considering the distinctive attributes of clean heating products, we selected four value perception dimensions. We measured economic value perception using the following items: “The price of clean heating is reasonable,” “I have been treated well in terms of clean heating subsidies,” and “Clean heating is worthwhile.” We measured social value perception using the items “Clean heating gives me more topics to discuss when interacting with others,” “Clean heating helps me create a positive impression on others,” and “Clean heating enhances my confidence in social situations.” We measured functional value perception using the following items: “Clean heating improves the speed and convenience of heating,” “Clean heating reduces the occurrence of respiratory illnesses,” and “Clean heating provides me with diverse heating options.” We measured emotional value perception using the items “I feel an urge to use clean heating products,” “I enjoy using clean heating products,” and “Clean heating products contribute to a positive perception of my overall life satisfaction.” All value perceptions factors were assessed on a 5-point Likert scale.\n\nWe used three categories of control variables: individual characteristics of the household head including variables such as gender, age, education, and social connections; family characteristics such as the number of family members, heating area (in m2), presence of village cadres within the household, engagement in non-agricultural employment, and total household income; and external factors such as the demonstration effect and herd mentality, which influence residents’ heating behavior during policy implementation. Consequently, we incorporated the neighborhood effect factor.Table 1lists the variables’ meanings and descriptive statistics.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321936.t001\n\nThe efficacy of policy implementation depends on its target group’s responsive actions. Positive audience responses are often received when good policies are implemented effectively, whereas negative responses may arise otherwise.Table 2presents the estimated results of the logit model used to examined the impact of policy incentives on CHB. Models (1)–(3) were employed to assess the impacts of advocacy, demonstration, and subsidy policies on CHB. These models’ estimated coefficients were 1.525, 1.348, and 2.363, respectively, and all were statistically significant at the 1% level. Advocacy policies significantly impacted residents’ CHB as evidenced by the Model (1) results. This notable effect can be attributed to the proactive influence of clean heating promotion policies, which enhance public awareness by providing information and guidance, thereby facilitating the adoption and widespread implementation of clean heating. The greater the number and intensity of government policy promotion methods, the higher the likelihood of rural residents continuing to adopt clean heating under the influence of policy promotion [46]. Model (2) revealed that demonstration policies also significantly influenced CHB. This effect could be credited to demonstrations’ efficacy at showcasing successful instances of clean heating, offering consultation, training, and guidance to the public, and demonstrating the feasibility and tangible benefits of clean heating. These initiatives enable rural residents to comprehend and select appropriate clean heating technologies and equipment, thereby fostering the adoption of clean heating methods. The results of Model (3) indicated a significant impact of subsidy policy on rural residents’ CHB, underscoring that subsidy policies effectively stimulate CHB by directly reducing the costs associated with its usage and alleviating the economic burden of adopting clean heating technology. In summary, policy incentives directly shape residents’ CHB, validating H1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321936.t002\n\nThe analytical results confirmed the significant positive impact of policy incentives on the CHB of rural residents in northern China. Subsequently, we employed Sobel mediation analysis, referring to the mediating effect model, to explore the mechanism through which policy incentives influence CHB and whether policy incentives further impact it through value perception.Table 3presents the results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321936.t003\n\nEstimation models (1 and 3), pertaining to the mediating effect of advocacy policies, produced coefficients of 0.363 and 0.295, respectively, that were significant at the 1% level. These results indicated that economic and social value perceptions mediated advocacy policies’ impact on rural residents’ CHB, and the proportion of the total effect mediated was 0.079 and 0.056, respectively. This finding implies that advocacy policies facilitate the adoption of clean heating by enhancing residents’ economic and social value perceptions. Such policies effectively communicate the importance and benefits of clean heating to the public through advertising, promotional activities, education, and training. Consequently, rural residents have become increasingly aware of the social issues associated with traditional heating methods and have developed a clearer understanding of alternative heating options, thereby encouraging their adoption of clean heating. Moreover, the implementation of policies such as clean heating subsidies, tax reductions, loans, and rewards has elevated rural residents’ perceptions of the economic value of clean heating. They have recognized that the benefits derived from clean heating outweigh the costs incurred, and this realization has intensified their motivation to embrace clean heating technology.\n\nEstimation models (3–6), used to examine the mediating effects of demonstration policies, produced coefficients of 0.340, 0.275, 0.245, and 0.269 for economic, social, functional, and emotional value perception, respectively, all of which were significant at the 1% and 5% levels. These results indicated that economic, social, functional, and emotional value perceptions partially mediated demonstration policies’ impact on CHB. The corresponding mediating effects were 0.133, 0.098, 0.063, and 0.081. Demonstrations inspire and direct the public by presenting successful instances of clean heating. This approach enables rural residents to gain a more intuitive understanding of the convenient, rapid, efficient, and health-promoting energy clean heating can deliver, thus fostering their appreciation of its functional value. Furthermore, as rural residents witness their neighbors, friends, communities, or others effectively embracing clean heating technology and experiencing tangible benefits, their emotional connection to clean heating is reinforced, thereby stimulating its adoption. Additionally, the promotion effect demonstration policies achieve contributes to the formation of social recognition and consensus regarding clean heating, and, as a growing number of individuals adopt clean heating technology, CHB becomes increasingly synonymous with social responsibility and environmental awareness [47]. This emerging social identity and consensus create positive social pressure among residents, amplifying their perception of the social value of clean heating from an external perspective. Consequently, residents are incentivized to embrace CHB to attain social recognition and align themselves with social expectations.\n\nLastly, we used Models (7) and (8) to examine the mediating effects of subsidy policies. The impact coefficients for economic and emotional value perception were 0.187 and 0.218, respectively, and both were significant at the 5% level. These results highlighted the partial roles of economic and emotional value perceptions in mediating subsidy policies’ impact on residents’ CHB, thus contributing to the overall mediating effect. The mediating effect values were 0.061 and 0.036, respectively. This finding suggests that rural residents demonstrate a rational preference for seeking benefits and avoiding risks when making decisions regarding the adoption of clean heating. Subsidy policies commonly manifest as direct financial subsidies, tax exemptions or deductions, and incentivized energy pricing. As rural residents perceive greater benefits and lower risks, their perception of the value associated with clean heating increases. Consequently, residents are more inclined to adopt clean heating methods.\n\nThe benchmark regression model measured the core independent variable based on residents’ subjective evaluations. Those who adopted clean heating were more concerned about relevant policies, and their evaluations reflected actual policy levels, whereas residents who had not adopted clean heating were likely to underestimate the policy level. An endogeneity issue may have arisen because of this causal relationship. Therefore, we conducted a robustness test wherein we replaced the policy incentive variables with whether the respondent household was in a pilot city. The policy implementation level is higher in pilot versus non-pilot cities. We referenced the “Plan” to determine the classification of pilot and non-pilot cities.\n\nThe control variables remained consistent, and the estimated results after replacing the explanatory variables are shown inTable 4. Clean heating pilot city residents showed a higher probability of adopting clean heating, with significance at the 1% level. This finding is consistent with the previously reported analysis results, thereby demonstrating the robustness of the empirical results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321936.t004\n\nThe results showed that the impacts of advocacy, demonstration, and subsidy policies on CHB were positive and significant at the 1% level, with coefficients of 1.525, 1.348, and 2.363, respectively. These findings suggest that advocacy, demonstration, and subsidy policies effectively promote clean heating, with subsidy policies being the most effective. The findings are consistent with those of previous studies. Jin et al. (2022) [2] showed that policy incentives can reduce relative costs and increase people’s ability and willingness to pay to adopt clean heating. However, clean heating technology has not yet matured, and equipment investment and maintenance costs are high [38]. The unit heating costs of electricity and natural gas are higher than that of scattered coal, and the economic cost is a constraint for residents considering clean heating [1,14]. Chen and Mu. (2022) [48] reported similar results indicating that, compared with other types, subsidy policies had the best effect on farmers’ adoption of water-saving technologies. These consistent findings conﬁrm that policy incentives are not monolithic; rather, they must be implemented in combination with various measures. Therefore, policymakers should focus on subsidy policies and strengthen advocacy and demonstration policy implementation to reduce the financial burden and improve effectiveness.\n\nPolicy incentives can increase value perception and ultimately influence residents’ CHB. Regardless of the choice of advocacy, demonstration, or subsidy policies, the main purpose is to use certain instruments to directly or indirectly transmit information and attributes to guide residents’ behavior. Most studies have analyzed the impact of policy incentives or value perceptions on CHB [20–22,25,31]. Some have explored the moderating effect of their interaction on behavior [48,49]. This study incorporated both in the same analytical framework and revealed value perceptions’ mediating effect. Policy incentives can affect residents’ CHB by influencing their value perception. This finding suggests that external policy incentives can be transformed into internal driving forces. Therefore, to build a long-term mechanism, value perceptions should be considered when formulating policies. Doing so would improve the low clean heating adoption rate in rural areas and help to alleviate the problem of reburning loose coal.\n\nThe action paths for different policy types differ. Our results showed that advocacy policies influenced CHB through perceptions of economic and social value. Demonstration policies promoted CHB by increasing residents’ perceptions of economic, social, functional, and emotional value. The paths of economic and emotional value perceptions in relation to subsidy policies were significant. The results also showed that increased economic value perception was a common path for all three policies. However, demonstration policy had the most comprehensive path. The long-term, stable economic and environmental value of clean heating is usually difficult for residents to perceive, thus weakening the positive effects of policy incentives. Through demonstrations, residents can feel the effects of applying clean heating technology, and these feelings comprehensively improve their value perceptions. A study that analyzed the impact of policy tools on farmers’ behavior in conservation farming on black soil reached a similar conclusion [50].\n\nThis study makes an important theoretical contribution. Planned behavior theory suggests that an individual’s behavior depends mainly on attitudes and that value perception is the basis of one’s attitudes. According to perceived value theory, an individual’s behavior is the result of their comparative weighing of benefits and risks. Motivation theory postulates that behavior is influenced not only by internal factors but also by external ones such as government policies. We combined these theories and constructed a theoretical analysis framework of “policy incentive–value perception–behavior,” which we paired with empirical analyses. Doing so broadened the perspective of the analysis of related issues and yielded an important contribution to the existing research. This study also makes a practical contribution. Government policies not only directly influence the clean heating choice but also assimilate into value perception. This finding is a useful reference for improving rural energy transition policies and building long-term promotion mechanisms.\n\nHowever, this study has several limitations. First, we conducted a random sample survey in the form of questionnaire that was distributed online. Although we covered many districts, including pilot and non-pilot districts, the sample size was not balanced across districts, and detailed information such as specific policy content was not considered. Given the lack of continuous observations and survey data in existing studies, future studies should conduct analyses based on panel data obtained from indoor surveys. Second, this study did not consider other external factors such as regional resource endowments, energy prices, and equipment installation prices. To avoid advocating “one policy for all,” differentiating the types of clean heating to empirically test for differing policy effects is necessary in further research to provide a basis for differentiated policy formulation.\n\nPromoting energy transition is a common global trend in the context of resource constraints and increasingly severe environmental problems. Promoting clean heating in rural areas is crucial for China to achieve its dual-carbon and low-carbon transition in energy consumption goals. Based on 2023 research data, we analyzed the influence of policy incentives on CHB among rural residents in northern China. We examined the mediating effects of value perception and conducted a robustness test. Our findings led to the following conclusions. First, a direct effects estimation showed that policy incentives exert a direct positive impact on CHB among residents of northern China. Moreover, distinct variations exist in the influence of different policy types (i.e., advocacy, demonstration, and subsidy policies) on rural residents’ CHB. Notably, subsidy policy is the most influential factor for encouraging CHB. Second, we found that policy incentives indirectly affect residents’ CHB through the mediating role of value perception. Value perception acts as a critical mediating factor in the relationship between policy incentives and CHB, with varying mechanisms observed for different policy types: advocacy policies enhance residents’ economic and social value perceptions, thereby promoting the adoption of clean heating methods; demonstration policies facilitate the adoption of clean heating by influencing economic, social, functional, and emotional value perceptions; and subsidy policies effectively promote CHB by enhancing residents’ economic and emotional value perceptions.\n\nBased on a comprehensive analysis, our findings have several policy implications. First, the government should prioritize recognizing the pivotal role of policy incentives in promoting clean heating practices among rural residents. Establishing and continuously enhancing a robust clean heating compensation mechanism while ensuring the focused implementation of government incentives are essential actions. The government should tailor the measures to each region’s specific circumstances, considering diverse factors such as economics, resource conditions, and regional climates. In doing so, the government can effectively develop targeted and refined policy schemes to improve the efficacy of clean heating systems. Additionally, the government must ensure the prompt and efficient disbursement of subsidies and innovatively structure clean heating subsidization to demonstrate an understanding of diverse residents’ economic capacities. Implementing subsidies can optimize policies’ overall effectiveness. This approach can facilitate a seamless transition toward cleaner, more sustainable heating in rural areas, ultimately contributing to the larger goals of environmental preservation and sustainable development.\n\nSecond, in addition to focusing on subsidy policies, the government should prioritize advocacy and demonstration policies. The government can effectively convey the importance and benefits of clean heating to rural residents through diverse communication channels, such as radio, television, brochures, and social media. A supportive service mechanism that provides clear, accurate information regarding clean heating must be established to address rural residents’ questions and concerns. This can be achieved by providing hotlines, online platforms, and on-site consultation services to ensure that residents receive timely support and assistance. Furthermore, technical staff are needed to provide on-site guidance, training courses, and other tools to help residents comprehend the working principles, operational procedures, and maintenance requirements of clean heating technology. By effectively leveraging advocacy and demonstration policies, the government can mitigate the various challenges and obstacles related to the adoption of clean heating methods.\n\nLastly, to foster the adoption of clean heating, enhancing residents’ value perception through various means is crucial, as is acknowledging the perceived trade-off between the benefits and costs of clean heating. The government should consider local conditions and choose suitable clean heating technologies to continually enhance indoor comfort. Additionally, residents should be educated on the health impact of indoor air quality as this can increase their perception of the functional value of clean heating. Furthermore, efforts should be made to improve the insulation performance of self-constructed houses and reduce the energy consumption of heating equipment to minimize economic costs. Simultaneously promoting energy technology safety and ensuring energy supply security are essential for mitigating residents’ perceptions of technical safety and energy supply risks.\n\nhttps://doi.org/10.1371/journal.pone.0321936.s001\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321936.s002\n\n(DOCX)\n\nThe authors sincerely thank professor Jie Lyu from Shenyang Agricultural University for his comments and suggestions.",
    "category": "earth_sciences"
  },
  {
    "title": "Predicting the spatial pattern of land use change and carbon storage in Xinjiang: A Markov-FLUS-InVEST model approach",
    "authors": "Mengting Jin, Xingxing Duan, Yunfei Zhang, Quan Xu, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321929",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321929",
    "content": "Land-use changes significantly influence carbon storage capacity by altering the structure, layout, and function of terrestrial ecosystems. Predicting the relationship between future land-use changes and carbon storage is essential for optimizing land-use patterns and making rational, ecology-based decisions. Using multi-period land-use data from Xinjiang, we analyzed the spatial pattern of carbon storage. Based on land-use change patterns in Xinjiang from 2000 to 2020, we coupled the Markov-Future Land Use Simulation (FLUS)-Integrated Valuation of Ecosystem Services and Tradeoffs (InVEST) model to simulate and predict land-use spatial patterns in Xinjiang for 2035 under two scenarios: natural growth and ecological protection. Carbon storage and its spatiotemporal dynamic changes under these scenarios were evaluated, and the Geodetector was employed to analyze the spatial heterogeneity of carbon storage from a statistical perspective, revealing the influence of various driving factors. The results showed that: (1) From 2000–2020, grassland and unused land were the primary land-use types in Xinjiang, accounting for over 28.85% and 60.17% of the total area, respectively. By 2035, cropland, forest, water, and construction land areas are expected to increase, while grassland and unused land areas are projected to decrease. Under the ecological protection scenario, cropland, forest land, and grassland—major main contributors to carbon storage—will be effectively conserved to some extent. (2) From 2000 to 2020, Xinjiang’s carbon storage capacity exhibited an overall increasing trend, with a cumulative increase of 137.515×105t and a growth rate of 1.58%. However, this capacity is projected to decline by 2035, with an estimated reduction of 168.344×105t compared to that in 2020. Ecological protection is anticipated to mitigate this decline, increasing carbon storage by 13.227×105t relative to the natural growth scenario. (3) Geodetector analysis indicated that land-use types had the greatest carbon storage explanatory power for carbon storage (q = 0.80), followed by soil types (q = 0.41), net primary productivity (q = 0.32), and geomorphology (q = 0.22). This highlights land-use types as the most critical environmental factor determining the spatial pattern of carbon storage. These findings provide scientific insights and recommendations for the sustainable development management and the enhancement of carbon storage functions.\n\nCitation:Jin M, Duan X, Zhang Y, Xu Q (2025) Predicting the spatial pattern of land use change and carbon storage in Xinjiang: A Markov-FLUS-InVEST model approach. PLoS ONE 20(4):\n           e0321929.\n        \n        https://doi.org/10.1371/journal.pone.0321929\n\nEditor:Sudeshna Bhattacharjya,, ICAR-Indian Institute of Soil Science, India\n\nReceived:August 18, 2024;Accepted:March 13, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Jin et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The data underlying this study are available from the Open Science Framework database athttps://osf.io/nqyug/(DOI:10.17605/OSF.IO/NQYUG).\n\nFunding:Mengting Jin was supported by the Science and Technology Innovation Foundation of the Command Center for Comprehensive Survey of Natural Resources (KC20230015) and the China Geological Survey Project (DD20220962). She played a role in data collection, methodology, and project administration. Quan Xu was supported by the China Geological Survey Project (DD20240740). He played a role in data collection and methodology.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nSevere global climate change presents significant challenges to human survival and sustainable development [1,2]. Carbon storage in terrestrial ecosystems constisutes a critical component of global carbon storage, playing a key role in mitigating global climate change by absorbing and releasing greenhouse gases and effectively regulating regional climates [3]. Land-use and cover change (LUCC) is one of the primary driving factors influencing changes in carbon stocks. LUCC impacts vegetation and soil carbon storage in terrestrial ecosystems, thereby alteing regional carbon storage, ecosystem structure, and function, ultimately affecting carbon cycling processes [4,5]. In the context of China’s dual carbon strategy—aiming to peak carbon emissions by 2030 and achieve carbon neutrality by 2060—Xinjiang has emerged as a strategically significant region. Therefore, investigating the spatiotemporal patterns of land use and cover changes and their impacts on carbon storage is essential.\n\nCurrent methods for assessing the impact of LUCC on carbon storage include field surveys and model simulations [6]. Unlike traditional field surveys, model simulations can evaluate carbon stock changes at various scales and provide spatially visualized evaluation results. Among the many available evaluation models (e.g., ARIES, GUMBO, MIMES, CITYgreen), the Integrated Valuation of Ecosystem Services and Tradeoffs (InVEST) model has been widely adopted due to its low data requirements, fast processing speed, and high assessment accuracy [7–9]. Developed by the Natural Capital Project in the United States, InVEST is a modeling system designed to evaluate the functional volume and economic value of ecosystem services, supporting ecosystem management and decision-making. He et al. [10] used a new model to assess the impacts of urban expansion on regional carbon storage by linking the Land Use Scenario Dynamics-urban and InVEST models. Similarly, Wang et al. [11] applied the InVEST model to estimate carbon storage in the Taihang Mountains from 2005 to 2020. They examined the main drivers of the spatial evolution of carbon storage and analyzed their driving mechanisms. These studies highlight that the InVEST model is one of the most widely used approaches for evaluating regional carbon storage.\n\nExploring the impact of LUCC on ecosystem carbon storage under different scenarios can provide quantified and spatially visualized distribution results. This information is valuable for decision-makers in formulating effective land-use policies and ecological protection plans, as well as optimizing the national spatial pattern [12–14]. However, most existing studies primarily focus on analyzing historical carbon stock changes resulting from land-use alterations, with relatively few studies addressing future land-use changes under multiple scenarios and their impact on carbon storage. Additionally, limited research investigates the spatial heterogeneity of carbon storage using spatial statistics to uncover the influence of diverse driving factors on the spatiotemporal evolution characteristics of carbon storage [15,16].\n\nTo address these gaps, we simulated future land-use patterns in Xinjiang under natural growth and ecological protection scenarios using the Future Land Use Simulation (FLUS) model [17], based on land-use data from 2000 to 2020. Subsequently, we employed the InVEST model to evaluate the spatiotemporal evolution of carbon storage in Xinjiang from 2000 to 2020 and predicted conditions for 2035 under different scenarios. Finally, we applied Geodetector to analyze the impact of various driving factors on the spatial distribution of carbon storage.\n\nXinjiang is located inland, between 73°40′E to 96°18′E longitude and 34°25′N to 48°10′N latitude. The region features complex terrain, including various landforms such as mountains and basins. It has a typical temperate continental climate characterized by abundant sunshine and significant temperature differences. The area is generally arid with relatively low annual precipitation—averaging approximately 150 mm. Precipitation varies significantly across the region, with northern Xinjiang receiving more rainfall than southern Xinjiang, while temperatures are higher in southern Xinjiang compared to the north [18]. The topography of Xinjiang affects carbon stocks in a number of ways, with vegetation cover and soil conditions in mountainous areas being conducive to carbon fixation and storage, while basins and unutilized areas have relatively low carbon stocks. Factors such as topographic relief, altitude and moisture conditions also influence carbon cycling and distribution to some extent [19].\n\nXinjiang is China’s largest provincial-level administrative region, covering 1.66 million km2, which accounts for one-sixth of China’s total land area. It has a border length exceeding 5,000 km, sharing boundaries with eight neighboring countries. Historically, Xinjiang was a critical hub of the ancient Silk Road, and today it plays an essential role in China’s “Belt and Road” policy. Its strategic geopolitical importance cannot be overstated. Consequently, studying the spatiotemporal evolution of carbon storage in Xinjiang holds significant practical value. A schematic of the study area is provided inFig 1.\n\nThe basemap is obtained from the Standard Map Service System (http://bzdt.ch.mnr.gov.cn/).\n\nThe basemap is obtained from the Standard Map Service System (http://bzdt.ch.mnr.gov.cn/).\n\nhttps://doi.org/10.1371/journal.pone.0321929.g001\n\nThe data used in this study (Table 1) were obtained from the Resource and Environmental Science Data Platform.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.t001\n\nThe land use data is derived from remote sensing satellite imagery, including Landsat 8 OLI and GF-2, among others. This dataset is acquired through a high-resolution remote sensing technology system that integrates unmanned aerial vehicles and ground surveys, complemented by human-computer interactive interpretation methods grounded in geoscience knowledge. The classification and overall accuracy were assessed using a confusion matrix. The first category of land use achieved a comprehensive accuracy of over 93%, while the second category’s comprehensive accuracy exceeded 90%, satisfying the user’s requirement for a drawing accuracy at a scale of 1:100,000 [20,21]. Based on the “Classification Standard for Land Use Status” (GBT 21010–2017) and accompanying data descriptions, land-use types were categorized into six classes: cropland, forest land, grassland, water area, construction land, and unused land.\n\nBased on previous research [18], the selected driving factors included the Digital Elevation Model (DEM), slope, aspect, rainfall, land surface temperature (LST), net primary productivity (NPP) of vegetation, luminous index, soil types, and geomorphology. To ensure consistency across datasets, the projection method was unified and transformed into the Albers_Conic_Equal_Area system. Additionally, the spatial resolution was resampled to 1 km using cubic convolution interpolation.\n\nThe study involved three key steps: (1) a multi-scenario land use simulation using the FLUS model, (2) calculations of the spatiotemporal characteristics of carbon storage using the InVEST model, and (3) an analysis of the driving forces behind carbon stock using the Geodetector. The methods applied in each of these steps are detailed in the following subsections. The technological roadmap is illustrated inFig 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.g002\n\nFLUS is a land-use prediction model based on cellular automata [22]. Using transformation rules and quantitative relationships between land-use types and driving factors, the model employs a roulette selection algorithm to simulate the spatial pattern of land use under different scenarios and years [23]. It also spatially allocates simulated land-use demand [24,25]. In this study, we used GeoSOS-FLUS V2.4 software to predict land-use changes in Xinjiang under different scenarios for the year 2035.\n\nBased on existing land-use data, we applied the Markov model to simulate future land-use type areas in Xinjiang for 2035. Driving factors for land-use change included the DEM, slope, aspect, rainfall, temperature, land surface temperature (LST), net primary productivity (NPP) of vegetation, luminous index, soil types, and geomorphology. Notably, temperature refers to the thermal state of the atmosphere, measured in a sheltered environment, which indicates atmospheric warmth. In contrast, LST reflects the ground’s thermal condition, measured at the interface between the Earth’s surface and the air. LST is influenced by various factors such as terrain type, vegetation, and soil moisture.\n\nWe also incorporated neighborhood factors and transfer matrix parameters into the simulation. Neighborhood factors represent the difficulty of converting one land-use type to another, with values ranging from 0 to 1. A score closer to 1 indicates a strong expansion ability for that land-use type. Transfer matrices are represented by values of 0 and 1: a value of 1 indicates that a conversion between two land-use types is permissible, while 0 indicates that it is not. Detailed parameter settings are provided inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.t002\n\nTwo land-use scenarios were simulated: natural growth and ecological protection. In the natural growth scenario, land-use types were allowed to evolve based on current conditions without deliberate modification, and the corresponding matrix value was set to 1. In the ecological protection scenario, enhanced protection measures were applied to ecological lands, such as forests, grasslands, and water bodies, while the expansion ability of other land-use types was restricted. For this scenario, the corresponding matrix value was set to 0.\n\nFinally, we estimated the spatial distribution of various land-use types in Xinjiang for 2035 under both scenarios by modifying the input parameters of the FLUS model.\n\nIn this study, the carbon storage module of the InVEST model was used to assess the spatiotemporal changes in carbon storage in Xinjiang. This module calculates ecosystem carbon storage by integrating land-use and carbon density data [26]. It categorizes ecosystem carbon storage into four primary carbon pools: aboveground vegetation carbon (Cabove), belowground vegetation carbon (Cbelow), soil organic carbon (Csoil), and dead organic carbon (Cdead).\n\nAboveground vegetation carbon pool: Includes the carbon stored in all living vegetation above the ground. Belowground vegetation carbon pool: Refers to the carbon stored in the root systems of living plants. Soil organic carbon pool: Typically represents the organic carbon stored in mineral and organic soils. Dead organic carbon pool: Represents the carbon stored in litter and dead plants [27,28]. The formula for calculating carbon storage is as follows:\n\nWhereCrepresents the total carbon storage per unit area for each land-use type,Caboverepresents the carbon density of aboveground biomass,Cbelowrepresents the carbon density of belowground biomass,Csoilrepresents the soil carbon density,Cdeadrepresents the carbon density of dead biomass, andCtotalrepresents the total carbon storage of all land cover types.Akrepresents the area of each land cover type,Ckrepresents the carbon density of each unit, andnrepresents the number of land-use types. The carbon density data used in this study were obtained from previous relevant research [29], and the carbon density values for each land-use type are shown inTable 3.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.t003\n\nThe Geodetector is a software tool used to measure and attribute spatially stratified heterogeneity. This method does not make linear assumptions, and it has a simple form with clear physical meaning [30]. The basic idea is to divide the study area into several subregions. If the sum of the variances of the subregions is smaller than the total variance of the region, spatial heterogeneity exists. If the spatial distribution of two variables tends to be consistent, there is a statistical correlation between them [31,32]. The Geodetector includes four detectors:\n\nThe spatial differentiation of the probe-dependent variable (Y) and the extent to which the probe driving factor (X) explains the spatial differentiation ofY, measured by the q value, is expressed as:\n\nWhere:h= 1,...,Lrepresents the strata of variableYor factorX;NhandNare the number of units in layerhand the entire region, respectively;σh2andσ2are the variances of layerhand areaYvalues, respectively; andSSWandSSTare the Within Sum of Squares and Total Sum of Squares, respectively.\n\nRecognizing the interaction between different driving factors involves assessing the combined effects of two factors (X1andX2) on the dependent variableYby determining whether their interaction increases or decreases the explanatory power ofY, or whether these factors have independent effects onY. The relationships between these two factors can be classified into the following categories:\n\nA t-test was used to determine whether there was a significant difference between the means of the attributes in two subregions. It was calculated as follows,\n\nWhererepresents the average value of the attributes in subregionh,nhis the number of samples in subregionh, andVaris the variance.\n\nThe F-test was used to assess whether there was a significant difference in the spatial distribution of attribute Y due to the influence of two factors, X1 and X2. This was achieved by comparing the effects on Y as follows,\n\nwhereNX1andNX2represent the sample sizes of the two factorsX1andX2, respectively;SSWX1andSSWX2denote the sums of the within-group variances formed byX1andX2, respectively; andL1andL2represent the numbers of strata forX1andX2, respectively.\n\nWe used Geodetector Software (Beta) for ArcGlS Pro to investigate the impact of various driving factors on carbon storage in Xinjiang. Carbon storage was the dependent variable (Y), and the driving factors were the independent variables (X). Random sampling was used to avoid the influence of spatial autocorrelations and human factors. One thousand sample points were randomly generated within the study area, and the carbon storage and driving factor values for each point were extracted for analysis.\n\nBetween 2000 and 2020, grassland and unused land were the dominant land-use types in Xinjiang, accounting for more than 28.85% and 60.17% of the total area, respectively (Fig 3andTable 4). The most common land-use types were cropland, forestland, and water bodies, which accounted for 3.73%, 1.75%, and 2.07% of the total area, respectively. Construction land covered the smallest area, accounting for only 0.27% of the total area. Over the 20 years, cropland, grassland, and construction land showed increasing trends, with increases of 21,712 km2, 4,084 km2, and 3,371 km2, respectively. In contrast, areas of forestland, water bodies, and unused land showed decreasing trends, with decreases of 8,138 km2, 11,638 km2, and 8,023 km2, respectively. From the perspective of spatial distribution, the increases in cropland, grassland, and construction land are mainly concentrated in Tacheng, the Bortala Mongol Autonomous Prefecture, and the oasis areas in southern Xinjiang. The decreases in forest land and water bodies are primarily observed in the Korla and Ili regions.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.g003\n\nConcerning land-use transfer, the increase in cropland and forestland was mainly due to the development of unused land, while the increase in construction land resulted primarily from the conversion of cropland, grassland, and unused land. Most forestland was converted to grassland, and areas of water bodies gradually decreased and became unused land. It is evident that, with the continuous development of the social economy between 2000 and 2020, Xinjiang focused on expanding farmland, conducting afforestation, and constructing infrastructure. Areas of unused land gradually decreased, accelerating urbanization and playing a positive role in Xinjiang’s economic development and environmental protection. However, due to the impacts of human activities and climate change, there have also been some negative effects on ecological lands such as forestland and water bodies.\n\nIn the 2035 natural growth scenario, cropland, forestland, water bodies, and construction land in Xinjiang are expected to increase by 5,629 km2, 6,020 km2, 11,850 km2, and 1,268 km2, respectively, with increases of 8.75%, 30.14%, 49.97%, and 19.50%. Areas of grassland and unused land are expected to decrease by 19,972 km2and 6,353 km2, respectively, with decreases of 5.86% and 0.92%. From the perspective of land-use transfer, the increase in cropland, forestland, and construction land will mainly occur through the conversion of grassland. In contrast, the increased water body areas will mainly result from the conversion of grassland and unused land. Grassland areas are predicted to decrease significantly, primarily due to their conversion into unused land.\n\nUnder the ecological protection scenario, the change in the land-use pattern in Xinjiang was predicted to be similar to that under the natural growth scenario, but with different area changes. Compared to the natural growth scenario, cropland, forestland, and grassland would increase by 133 km2, 397 km2, and 180 km2, respectively, while water bodies, construction land, and unused land would decrease by 13 km2, 646 km2, and 51 km2, respectively. Under the ecological protection scenario, croplands, forestlands, and grasslands, which are the primary contributors to carbon storage, were effectively protected to a some extent.\n\nThe spatial distribution of carbon storage in Xinjiang is shown inFig 4. In terms of quantity, the total amount of carbon stored in Xinjiang every 5 years from 2000 to 2020 was 8689.373×105t, 8692.023×105t, 8697.929×105t, 8700.356×105t, and 8826.889×105t, respectively, exhibiting an overall increasing trend. There was a cumulative increase of 137.515×105t, with a growth rate of 1.58%. On average, the amount of carbon stored increased by 6.876×105t per year. The most significant change in Xinjiang’s carbon storage occurred between 2015 and 2020, with an increase of 126.532×105t, accounting for 92.01% of the cumulative increase. In terms of area, the area of carbon stock increase amounted to 188,928 km2and the area of decrease amounted to 182,667 km2. From a spatial distribution perspective, regions demonstrating significant increases in carbon storage are predominantly concentrated in the mountainous areas of Xinjiang. In contrast, areas showing decreased carbon storage levels are primarily distributed along the periphery of both the Taklimakan Desert and the Gurbantunggut Desert in Xinjiang.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.g004\n\nAs shown inFig 5, high carbon storage areas were mainly concentrated in cropland, forestland, and grassland areas due to the different land-use types with varying carbon sequestration capabilities. In contrast, the carbon densities of water bodies, construction land, and unused land were relatively low, resulting in a lower carbon storage content. Between 2000 and 2020, the increased cropland and grassland areas in Xinjiang resulted in a relative increase in carbon storage. The changes in carbon storage were mainly influenced by changes in land-use types.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.g005\n\nUnder the natural growth scenario, the overall trend of carbon storage in Xinjiang is expected to decrease, with a projected reduction of 168.344×105t in 2035 compared to 2020. This decline in carbon storage is primarily attributed to the conversion of large areas of grassland into construction land and unused land, leading in a decrease in both soil carbon storage and the carbon storage of aboveground and belowground vegetation. As a result, the total amount of carbon stored in Xinjiang would decline. However, the ecological protection scenario would mitigate this reduction in carbon storage. By limiting the conversion of forestland and grassland to other land-use types, carbon storage could increase by 13.227×105t compared to the natural growth scenario. The implementation of ecological protection policies could enhance the effectiveness of regional ecological conservation and facilitate sufficirnt carbon sequestration in Xinjiang.\n\nThe results of the analysis based on the Geodetector are shown inFig 6.Fig 6apresents the calculated results for all driver divergence probes. The divergence factor q ranges from 0 to 1, with larger values indicating stronger explanatory power of the driver regarding carbon stock, and vice versa. The results revealed that land-use types had the highest q value (0.80), followed by soil types (0.41), NPP (0.32), and geomorphology (0.22), while the q values for the other factors were relatively small. Furthermore, from the perspective of interaction detection, the q-value increased to 0.83 after the interactions between land-use types and both soil types and geomorphological factors. This further enhanced the explanatory power of carbon storage, suggesting that these factors jointly play a positive role.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321929.g006\n\nFig 6bpresents the interaction types among all driving factors, enabling an assessment of whether the combined effect of any two factors enhances or reduces the explanatory power for carbon stocks. The results indicate that pairwise interactions between all factors can produce an enhancing effect. Specifically, land-use types serve as a two-factor enhancer when interacting with DEM, slope, rain, temperature, LST, NPP, soil types, and geomorphology, respectively. In contrast, land-use types act as a nonlinear enhancer when interacting with aspect and luminous index, respectively. All these interactions contribute to a further improvement in the explanatory power of carbon stocks.\n\nFig 6cpresents the ecological detection results for all the driving factors, which indicate whether there was a significant difference in their impact on the spatial distribution of carbon storage. (“Y” indicates a significant difference, while “N” indicates no significant difference.) From the results, it can be seen that land-use types, LST, NPP, and soil types are all significantly different from other factors, indicating that these types of factors act independently on carbon stock distribution, respectively.\n\nIn conclusion, the analysis showed that, among these driving factors, land-use type was the most relevant and robust explanatory factor for change in carbon storage, and it was the primary environmental factor determining the spatial pattern of carbon storage.\n\nRapid urbanization leads to large-scale encroachment of construction land on croplands, forests, and grasslands [33]. From 2000 to 2020, the overall trend of carbon storage in Xinjiang increased. However, under the two typical future scenarios, the carbon storage trend is expected to decrease. Employing the ecological protection scenario would mitigate this trend to some extent compared to the natural growth scenario because it comprehensively coordinates the functions of various land types and is more conducive to slowing the loss of carbon storage. Implementing such protectionist policies would help maintain a regional carbon balance and be of great significance for optimizing the spatial pattern of Xinjiang’s land.\n\nThe results showed that between 2000 and 2020, grassland was the dominant land-use type in Xinjiang, and its carbon storage capacity was higher than that of other ecosystems. Therefore, protecting grasslands is key to achieving the sustainable development of carbon storage functions in Xinjiang. The changes in carbon storage under different scenarios show that Xinjiang should prioritize protecting its grassland resources to prevent degradation. It is essential to focus on optimizing the land-use structure with a low-carbon orientation and to promote the transformation of low-coverage grassland and unused land into high-coverage grassland through policies that establish grazing bans and protection zones, restrict associated land development, and strengthen the legal management of grasslands. Additionally, it is crucial to improve the grassland monitoring network and consolidate the achievements of grassland ecological restoration.\n\nLand-use change is a complex process influenced by multiple driving factors [34,35]. In this study, factors such as DEM, slope, aspect, precipitation, and temperature were selected as the driving factors for simulating future land-use patterns. These factors exhibited an excellent fitting effect on the various land-use types, and the simulated results were highly accurate (Kappa = 0.94), thus meetting the research requirements. Our results were supported by those of previous relevant studies[29].\n\nIn future research, policy-related factors should be added into the driving factor system to reveal the impact of land use policies on carbon storage. At the same time, more driving factors should be further screened and optimized to improve the accuracy of land-use simulation and driving force analysis. Moreover, to accurately estimate regional carbon storage changes and enhance the accuracy of model verification, efforts should be made to strengthen the acquisition of carbon density data, as well as to conduct localization calibration and field measurements of core indicators.",
    "category": "earth_sciences"
  },
  {
    "title": "Design and development of an irrigation monitoring and control system based on blynk internet of things and thingspeak",
    "authors": "Fahmy Rinanda Saputri, Ricardo Linelson, Muhammad Salehuddin, Danial Md Nor, Muhammad Imran Ahmad, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321250",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321250",
    "content": "The scarcity of water resources exacerbated by climate change poses a major challenge for sustainable agriculture. This study presents an Internet of Things (IoT)-enabled irrigation system designed for real-time monitoring and precise water control. Using the Blynk platform and ThingSpeak for data management, the system integrates sensors for soil moisture, temperature, and humidity with a NodeMCU module to optimize irrigation practices. Initial results demonstrate the system’s effectiveness in improving water use efficiency and supporting sustainable agricultural practices, providing a low-cost, accessible solution for small and medium-scale farmers.\n\nCitation:Saputri FR, Linelson R, Salehuddin M, Nor DM, Ahmad MI (2025) Design and development of an irrigation monitoring and control system based on blynk internet of things and thingspeak. PLoS ONE 20(4):\n           e0321250.\n        \n        https://doi.org/10.1371/journal.pone.0321250\n\nEditor:Antar S. H. Abdul-Qawy, SUMAIT University, TANZANIA, UNITED REPUBLIC OF\n\nReceived:November 28, 2024;Accepted:March 1, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Saputri et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nList of abbreviations::Arduino IDE,\n            Arduino Integrated Development Environment; DC,\n            Direct Current; DHT11,\n            Digital Humidity and Temperature 11; IoT,\n            Internet of Things; LCD,\n            Liquid Crystal Display; NodeMCU V3,\n            Node Microcontroller Unit Version 3; PLC,\n            Programmable Logic Controller; SDGs,\n            Sustainable Development Goals; UV-C,\n            Ultraviolet-C; Wi-Fi,\n            Wireless Fidelity\n\nThe increasing extremity of global climate change has created significant challenges for the agricultural sector, particularly in managing limited water resources [1,2]. Rising temperatures and shifts in soil moisture patterns disrupt traditional irrigation methods, posing risks to crop yields. In response, Internet of Things (IoT)-based automatic irrigation systems have emerged as a promising solution, enabling real-time, demand-based watering guided by environmental data from sensors [3–6]. These systems enhance water use efficiency by utilizing sensors to monitor soil moisture, temperature, and other environmental factors that affect crop water requirements, providing smart solutions to address climate change challenges [7]. This study stands out by integrating Blynk for real-time control and ThingSpeak for cloud data storage, offering a more effective, accessible, and cost-efficient solution for farmers facing the impacts of climate change.\n\nPrevious research, such as the development of an IoT-based smart agriculture framework that integrates renewable energy, precision irrigation, and Android app-based control, as well as the implementation of a real-time fire detection system to improve the resilience of agricultural operations, demonstrate progress in utilizing smart technology for sustainability [8–10]. In addition, previous studies also have advanced IoT-based irrigation systems to enhance water use efficiency. For instance, Hari et al. developed an IoT irrigation system utilizing a Programmable Logic Controller (PLC), though this system lacked cloud-based data storage for archiving historical data [11]. Reddy et al. incorporated cloud technology in their IoT irrigation system, yet did not focus on sensor accuracy and precision [12]. Additionally, studies by Stolojescu-Crisan et al. and Velmurugan et al. emphasized soil moisture sensors and weather prediction but did not integrate ThingSpeak for data storage and Blynk for simultaneous control and monitoring [13,14]. This study addresses these gaps by integrating Blynk for real-time irrigation control and ThingSpeak for cloud-based data storage, enabling both immediate feedback and long-term insights. This combination provides farmers with enhanced control and the ability to analyze historical data to optimize irrigation practices and improve water efficiency, overcoming the limitations of previous systems.\n\nThis research addresses these limitations by incorporating water-resistant temperature sensors and capacitive soil moisture sensors (V2.0), along with rigorous testing for accuracy, precision, bias, and error, to improve data reliability. The IoT platform Blynk is used for real-time control, while ThingSpeak serves as a cloud database, creating an adaptable and implementable solution for farmers [15,16]. Additionally, the Node Microcontroller Unit Version 3 (NodeMCU V3) ESP-12 microcontroller, with Wireless Fidelity (Wi-Fi) connectivity and low power consumption, offers a cost-effective solution for small- to medium-scale farmers. This system integrates a Digital Humidity and Temperature 11 (DHT11) sensor for air humidity, a water-resistant DS1820 sensor for temperature, and soil moisture sensors to monitor environmental conditions in real-time. Irrigation frequency is calibrated to maintain optimal soil moisture at 30–50% and temperatures of 20–30°C, which are crucial for crop productivity.\n\nThe importance of real-time monitoring has been proven in various studies, such as those that monitor environmental conditions in buildings using various sensors connected via IoT [17,18]. Furthermore, this research will also design a real-time monitoring system for automatic irrigation, which enables efficient water management by utilizing soil moisture sensors and an IoT platform. Meanwhile, controlling the irrigation system can be done using the Blynk application, as applied in previous research which was used to control Ultraviolet-C (UV-C) lamps automatically via IoT [19]. This integration of IoT technologies in agriculture aims to improve water usage efficiency and support decision-making processes for farmers by providing them with real-time, data-driven insights into soil moisture levels.\n\nThe aims of this study are to evaluate the effectiveness of an automatic irrigation system in maintaining optimal soil moisture levels through sensor data, assess the impact of IoT technology on irrigation control and farmer decision-making, and analyze trends in soil moisture data to inform future irrigation practices. This approach aims to enhance water use efficiency in agriculture and support sustainable resource management in the context of climate challenges. Developed using Blynk for control and ThingSpeak for cloud storage, this system is implemented through Arduino Integrated Development Environment (Arduino IDE), allowing for seamless integration between hardware and software. Besides remote monitoring, the system features a 16x2 Liquid Crystal Display (LCD) for local display, providing real-time feedback to users on soil moisture levels. Additionally, a Direct Current (DC) mini pump is activated automatically to irrigate crops when soil moisture falls below the preset threshold, ensuring crops receive adequate water. Soil moisture sensor calibration has been performed to increase accuracy, ensuring reliable data for informed irrigation decisions and reducing water waste. [20]. By integrating Blynk IoT and ThingSpeak, this study provides a low-cost, accessible automatic irrigation solution particularly suited for developing regions with limited access to advanced technology. This innovation aligns with the United Nations Sustainable Development Goals (SDGs), specifically SDG 2: Zero Hunger, SDG 6: Clean Water and Sanitation, and SDG 13: Climate Action. By improving water use efficiency and promoting sustainable agriculture practices, it not only enhances resilience to climate change but also supports long-term food security. This research contributes to addressing the impacts of climate change, ensuring sustainable agricultural development, and improving access to clean water resources, ultimately fostering a more resilient and sustainable future.\n\nThis research was conducted to develop an automated irrigation monitoring and control system integrated with IoT-based data transmission to improve water usage efficiency and enable remote monitoring for agricultural applications. The research methodology is organized into several stages, including research design, system development and algorithm implementation, testing, and data acquisition. Each stage is explained chronologically below.\n\nThis research employs a mixed method approach, combining quantitative and qualitative methodologies. The quantitative approach involves real-time data collection from sensors, including soil moisture, temperature, and air humidity, to evaluate the system’s effectiveness in maintaining optimal land conditions. The qualitative approach is based on field observations and experiments conducted by researchers to assess the system’s usability, flexibility, and practicality. This integrated approach ensures a comprehensive understanding of the system’s performance in real-world scenarios.\n\nThe research procedure involved both hardware and software development, combining a C++-based program and circuit assembly. The selection of the C++ language is based on the use of the Arduino IDE, which provides built-in libraries to support the integration of hardware such as sensors and relay modules. C++ enables efficient program development and makes it easy to test directly on the microcontroller, making it ideal for IoT applications.\n\nThe research procedure is organized into several phases to ensure the system operates effectively and meets the design specifications. The main stages include System Design, Programming and IoT Integration, and System Testing. In the System Design phase, the hardware and software components necessary for the system are identified. This includes wiring soil moisture sensors, temperature sensors, and relay modules to the NodeMCU, followed by developing a schematic diagram to visualize the connections between components. The Programming and IoT Integration phase involves writing the control program for the NodeMCU using the Arduino IDE. Additionally, the NodeMCU is integrated with the Blynk application and ThingSpeak platform, enabling real-time monitoring of soil moisture, temperature, and humidity data. Finally, in the System Testing phase, multiple tests are conducted to verify system performance. Sensor Testing ensures accurate readings of soil moisture, temperature, and humidity, while Relay Module Testing validates that the relay operates according to the control logic.\n\nWi-Fi and Cloud Connection Testing confirms stable data transmission to both Blynk and ThingSpeak, and Pump Control Testing evaluates the automated irrigation functionality by verifying that the pump activates when soil moisture drops below 60% and deactivates when the optimal threshold is met. This structured approach allows for the step-by-step validation of system functionality and reliability. The steps are as follows:\n\nIn the software part, this research uses the Arduino IDE as a programming platform to write, compile, and upload code to the NodeMCU. The Blynk app, which is IoT-based, enables real-time monitoring and control of the system through a smartphone or PC. ThingSpeak is used as the IoT data storage platform, which serves to store and analyze long-term data from sensors, as well as provide visualization of soil moisture trends and environmental conditions. This combination of hardware and software supports automatic, real-time monitoring and control of irrigation.\n\nThe research began with a literature review to understand current automated irrigation systems, IoT integration for remote monitoring, and water conservation strategies. This review helped establish the system’s requirements, which include real-time monitoring, automatic irrigation control based on soil moisture levels, and remote access to sensor data via IoT platforms such as Blynk IoT and ThingSpeak.\n\nBased on these requirements, the system was designed to include multiple environmental sensors, a relay-controlled water pump, and an LCD 16x2 display for on-site monitoring. The ESP8266 microcontroller was selected as the main control unit for its Wi-Fi capability, enabling easy integration with the IoT platforms.Fig 1illustrates the schematic diagram of the complete system, designed to map the interconnections between components. Based onFig 1, the automatic irrigation system in this study utilizes several key components, including NodeMCU as the main microcontroller with Wi-Fi connectivity to control the entire system and send data to the IoT platform. The sensors used include Capacitive Soil Moisture Sensor V2.0 to measure soil moisture, Temperature Waterproof Sensor DS18B20 to monitor the ambient temperature, and Humidity Sensor DHT11 to record air humidity. In addition, the system is equipped with a 5V relay module that controls the water pump, a 16x2 I2C LCD to display data locally, and a 5V/2A power supply as a power source. Additional components such as a 4.7 kΩ resistor are used to support communication with the DS18B20 sensor, while jumper cables connect all components in the system.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g001\n\nThis automatic irrigation system works by collecting real-time data from soil moisture, temperature (DS18B20), and air humidity (DHT11) sensors, which are processed by NodeMCU as the main controller module. Based on the soil moisture data, the NodeMCU regulates the activation of the relay module to turn on the water pump automatically if the moisture is below a predetermined threshold. The system is equipped with a 16x2 LCD screen for local monitoring and uses the Blynk platform for real-time control via mobile devices, as well as ThingSpeak for cloud-based data storage and long-term analysis.Table 1summarizes the main hardware components used in the automatic irrigation system along with their respective functions. This table provides an overview of the components and their roles in the system.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.t001\n\nThe programming code for the NodeMCU is written using the Arduino IDE. The code includes setup for the NodeMCU to read data from soil moisture, temperature, and humidity sensors and to transmit this data to the Blynk app and ThingSpeak database. Additionally, it incorporates the logic for controlling the relay module, which manages the water pump status based on soil moisture levels. Finally, the NodeMCU configuration is completed to connect to a smartphone hotspot or Wi-Fi network.\n\nThe flowchart diagram of this automatic irrigation system encompasses three main aspects: the plant watering process, data transmission to the cloud database, and the data transmission and control flow of the system. This diagram illustrates the workflow for plant watering and data transmission to the cloud database, which includes Blynk and ThingSpeak. The Blynk application can be accessed via a smartphone app or through the websitehttps://blynk.io/from a smartphone, PC, or laptop. ThingSpeak can be accessed viahttps://thingspeak.mathworks.com/using the same devices.\n\nFig 2illustrates the process of the Automatic Irrigation Monitoring System, starting with the initialization of sensors, including the DS18B20 (temperature sensor), DHT11 (humidity sensor), soil moisture sensor, and relay. The system then detects sensor data, such as temperature, humidity, and soil moisture levels. This data is also sent in real-time to the Blynk app, which can be accessed via smartphone or PC, and stored in ThingSpeak for historical analysis. This process enables data access at any time and enhances data-driven irrigation management, making it easier to adjust based on monitored conditions.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g002\n\nFig 3shows if in Automatic Mode when the moisture is below 60%, the water pump is turned on; if it is above or equal to 60%, the water pump is turned off. If in Manual Mode, when the Pump Button is pressed ON, the pump will turn on. If the Pump Button is pressed OFF, the pump will turn off. The Pump Button can be pressed or controlled by using the Blynk IoT smartphone application or website.Table 2presents a summary of the configuration parameters, system settings, and pump operation modes in the automatic irrigation system. These parameters define how the system operates under different conditions, both automatically and manually.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g003\n\nBlock diagram inFig 4shows the process of data transmission and control in the IoT-based automatic irrigation system. In the IoT-based automatic irrigation system, input consists of data from soil moisture, temperature (DS18B20), and humidity (DHT11) sensors, which are sent to the NodeMCU for processing. The process involves the NodeMCU analyzing the sensor data to determine whether the soil moisture level is below a predefined threshold (e.g., 60%), in which case it activates the relay to turn on the water pump. If the soil moisture reaches the optimal threshold, the pump is automatically turned off.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g004\n\nThe NodeMCU also connects to Wi-Fi to transmit the data to cloud platforms such as Blynk or ThingSpeak. The output includes real-time data displayed on the Blynk app, stored in ThingSpeak for long-term analysis, and shown on an LCD for local monitoring. This workflow enhances irrigation efficiency by enabling data-driven management and providing access to real-time and historical data via the cloud for improved decision-making. In addition, the system consumes 0.8 W when the pump is off and 1.0 W when the pump is on, making it energy-efficient for continuous operation.\n\nThe testing and data acquisition phase involved verifying the system’s functionality and performance under controlled conditions. Functionality testing assessed the system’s ability to automatically activate and deactivate the irrigation pump based on soil moisture levels, with controlled manipulation of soil moisture to observe corresponding pump responses. Accuracy and precision testing involved comparing sensor readings against reference measurements, with calibration adjustments made to ensure reliable data. Real-time data on soil moisture, temperature, and humidity were collected through Blynk and ThingSpeak, with historical data on ThingSpeak enabling analysis of soil moisture patterns. Sensor precision was calculated using the equation (1).\n\nwhere σ represents the standard deviation of the sensor readings and x̄ is the mean of the sensor readings. The accuracy percentage of the sensors can be determined using Equation (2).\n\nIn this context, bias is calculated as the difference between the true value x true and the mean reading x̄, as shown in Equation (3). Then, to determine the percentage error of the sensors, Equation (4) is used.\n\nIn these equations, σ represents the standard deviation of the sensor readings, x̄ is the mean of the sensor readings, and x true is the actual measured value by the calibrated tool. These calculations provide essential metrics for evaluating the sensor’s precision, accuracy, bias, and error percentage.\n\nIoT connectivity testing validated the Wi-Fi connection and successful data transmission to Blynk and ThingSpeak under various network conditions, ensuring reliable remote monitoring and data logging. Historical data logged on ThingSpeak supported environmental trend analysis and optimized automatic irrigation for efficient water usage.\n\nThe prototype of the IoT-based automatic irrigation system was tested outdoors in South Tangerang, Indonesia, which has tropical climate. South Tangerang has a tropical monsoon climate with high humidity and significant seasonal rainfall variations. The soil consists of a mixture of loam and sandy loam, which affects water retention and drainage. Challenges in the region include fluctuating weather conditions, high evapotranspiration rates, and heavy rainfall, all of which impact soil moisture and irrigation requirements [20]. The deployment aimed to validate system performance in real-world conditions, assessing its reliability in soil moisture monitoring, automatic watering, and IoT data transmission. The testing site was selected to ensure realistic conditions for evaluating water efficiency, system responsiveness, and data accuracy.\n\nThis study was conducted in accordance with the research contract approved by the Research and Community Service Institute (LPPM) of Universitas Multimedia Nusantara under contract Number 0007-RD-LPPM-UMN/P-INT/VI/2024. The research methodology and implementation adhered to the institutional guidelines and relevant regulations. No additional ethical approval was required as the study did not involve human or animal subjects. No deviations from the approved study protocol occurred during the research process.\n\nThe results of research are provided in the figures and data visualization.Fig 5illustrates the design of the automated irrigation system employed in this study. The researchers utilized an integrated Wi-Fi module with NodeMCU to ensure connectivity with the Blynk application, where the data is subsequently sent to the ThingSpeak database. For initial testing, the researchers employed a smartphone hotspot for convenience. However, in the final stage, the system will be fully integrated with a fixed Wi-Fi network at the farming site to enhance communication reliability and stability. This setup will ensure the system operates optimally for real-time irrigation monitoring and control.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g005\n\nThe Blynk IoT dashboards such inFigs 6–8provide an intuitive interface for monitoring and controlling the irrigation system. Initially, as shown inFigs 6–8are the initial view, automatic control mode, and manual control mode respectively. In automatic control mode, the pump will automatically turn on according to the preset threshold. In manual mode, the user can manually activate the pump by pressing the “Pump ON” button. Then,Fig 9is the ThingSpeak Database Website Dashboard.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.g009\n\nThis study conducted efficiency and accuracy tests to evaluate the performance of the DS18B20 and DHT11 sensors in measuring temperature and humidity. The measurements were compared against data from a hygrometer, which served as the calibration reference.\n\nTable 3presents the air temperature measurements obtained using the hygrometer and the DS18B20 sensor, including bias, precision, accuracy, and error values. The average bias for the DS18B20 sensor was −0.9°C, with a bias of −0.8, precision of 98.4%, accuracy of 96.9%, and error of 3.1%. High precision and accuracy indicate that the DS18B20 sensor delivers highly accurate results, with minimal deviation from the hygrometer used as a reference.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.t003\n\nTable 4presents the results of the air temperature measurements using the hygrometer and DS18B20 sensor after calibration, including bias, precision, accuracy, and error. The average temperature measured by the DS18B20 sensor was 30.0°C with a standard deviation of 0, bias of 0.7°C, precision of 100%, accuracy of 97.8%, and error of 2.2%. The high precision and accuracy indicate that the DS18B20 sensor delivers excellent performance after calibration.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.t004\n\nTable 5displays the air humidity measurements obtained from the hygrometer and the DHT11 sensor, including bias, precision, accuracy, and error values. The DHT11 sensor exhibited an average bias of −0.2, precision of 98.8%, accuracy of 96.7%, and error of 3.3%.Table 6shows the results of air humidity measurements obtained from the hygrometer and DHT11 sensor after calibration. The DHT11 sensor exhibited an average humidity of 65.0%, with a standard deviation of 0%, bias of 1.0%, precision of 100%, accuracy of 100%, and error of 0.8%. Despite the high precision and accuracy, minor variations with the hygrometer data were observed, indicating that the DHT11 sensor, while reliable, may require further monitoring. However, the study is limited by restricted field testing, and the system’s long-term reliability remains unverified. Future research should focus on extended field trials to assess durability and performance across diverse agricultural environments and climates.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.t005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.t006\n\nTable 7presents data showing the increase in soil moisture in response to the amount of water injected, measured in milliliters (mL). The data, recorded by the Capacitive Soil Moisture Sensor V2.0, reveals a strong linear relationship between the injected water volume and the increase in soil moisture. For example, applying 10 mL of water resulted in a 29% increase in moisture, while 20 mL increased the moisture to 53%, and 50 mL reached a maximum of 100% moisture. The V2.0 Capacitive Soil Moisture Sensor demonstrated excellent precision and accuracy during testing. Precision, which is calculated based on repeated measurements under consistent conditions, consistently came in at 100%, indicating highly reliable readings. In addition, the accuracy of the sensor reached 100%, ensuring that the measured value was in line with the actual soil moisture level. These results confirm the suitability of the sensor for precise monitoring in automated irrigation systems.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321250.t007\n\nThe strong linear relationship between water volume and soil moisture is evident from the data inTable 7, where an increase in the injected water volume consistently leads to a corresponding increase in soil moisture, measured by the Capacitive Soil Moisture Sensor V2.0. This relationship demonstrates the predictive and direct effect that the volume of water has on the moisture content of the soil. For instance, 10 mL of water results in a 29% increase in moisture, while 50 mL achieves a maximum of 100% moisture, showing that the system can reliably measure and react to changes in moisture levels.\n\nHowever, the data also suggests the presence of threshold effects at higher water volumes. As the water volume increases beyond 40 mL, the increase in soil moisture becomes less pronounced, reaching 100% moisture with 50 mL. This diminishing return implies that there is a point at which adding more water does not significantly improve soil moisture content. Once the soil reaches saturation, additional water may not be effectively absorbed, potentially leading to waterlogging, which can be detrimental to plant health by reducing root oxygenation and promoting anaerobic conditions.\n\nA cost analysis was conducted to assess the feasibility of implementing an IoT-based automatic irrigation system for smallholder farmers. This system, built using a NodeMCU microcontroller, DS18B20 temperature sensor, DHT11 humidity sensor, soil moisture sensor, relay module, DC pump, LCD display, and additional peripherals, has a hardware cost of IDR 235,000 (~USD 15.00). The system operates on a 5V USB power source with an average power consumption of 1.0W, resulting in minimal operational costs. Daily energy consumption is 24Wh or 0.024kWh, calculated as 1.0W × 24 hours. Based on an electricity rate of IDR 1,352/kWh, the daily electricity cost amounts to IDR 32.45. Over a year, this translates to an annual electricity cost of approximately IDR 11,843.52 with a calculation of IDR 32.45/day × 365 days.\n\nWhen compared to traditional irrigation, which requires 1000mL of water per plant, twice a day, this IoT-based system reduces water usage by 30% through real-time monitoring and optimization of irrigation based on soil moisture levels. By maintaining soil moisture within the ideal range of 30%–60%, the system prevents overwatering and minimizes water wastage, promoting healthier plant growth. The soil moisture levels are categorized as dry (0%–30%), moist (30%–60%), and wet (60%–100%), and the system continuously monitors these conditions using sensors to ensure optimal irrigation.\n\nThis IoT-based solution is particularly impactful for smallholder farmers, offering a scalable and cost-effective approach to sustainable water management. The modular design allows for customization to suit varying farm sizes and types, making it adaptable for subsistence farming or small-scale agricultural operations. By reducing water usage and increasing irrigation efficiency, the system promotes sustainability while supporting improved crop productivity.\n\nFor larger agricultural operations, the benefits are equally compelling. The system’s ability to automate irrigation processes and provide real-time monitoring across expansive areas optimizes water use and minimizes wastage. This level of precision can significantly enhance crop yields while reducing labor and operational costs associated with traditional irrigation methods. Additionally, continuous data collection and analysis enable informed decision-making, further improving farm management efficiency and sustainability.\n\nThe broader implications of adopting IoT-based irrigation systems are transformative. By making advanced technology accessible and adaptable for farmers of all scales, these systems encourage the widespread adoption of sustainable practices. The resulting improvements in water efficiency and crop productivity contribute to long-term agricultural resilience, fostering food security and environmental sustainability across diverse farming contexts. This aligns directly with the United Nations Sustainable Development Goals (SDGs), specifically SDG 2: Zero Hunger, SDG 6: Clean Water and Sanitation, and SDG 13: Climate Action. By addressing these goals, IoT-based irrigation systems support the creation of resilient agricultural systems that can adapt to climate change, ensure efficient resource use, and provide equitable access to technological advancements for all farmers.\n\nThis study successfully developed an IoT-based automatic irrigation system that addresses the challenge of water scarcity in sustainable agriculture, particularly in regions with limited rainfall. The system utilizes the Blynk platform and ThingSpeak database for real-time monitoring and precise water control, integrating a DS18B20 temperature sensor, DHT11 humidity sensor, and soil moisture sensor through an ESP8266 NodeMCU module for seamless connectivity.\n\nTesting results revealed that the DS18B20 sensor achieved 98.4% precision and 96.9% accuracy, with a bias of −0.9°C, while the DHT11 sensor showed 98.8% precision, 96.7% accuracy, a −0.2% average bias, and a 3.3% error margin. After calibration, both sensors reached 100% precision and accuracy, closely aligning with reference standards. Soil moisture data indicated a strong correlation between irrigation volume and moisture levels, where an additional 10 mL of water increased soil moisture by 29%.\n\nThis IoT-enabled system provides farmers with enhanced control over irrigation, making it possible to optimize water use and make data-driven decisions. The findings validate the system’s potential to improve water management in agriculture, supporting sustainable practices with high precision and accuracy. Future improvements could include integrating machine learning for predictive analytics to further enhance irrigation efficiency by anticipating water needs based on weather patterns and soil conditions. Additionally, expanding the system to include other environmental sensors or integrating it with broader smart farming technologies could offer a solution for sustainable agricultural management.\n\nhttps://doi.org/10.1371/journal.pone.0321250.s001\n\n(DOCX)\n\nThe authors would like to sincerely acknowledge Universitas Multimedia Nusantara (UMN) for facilities support in this research. Their support has been instrumental in the successful completion of this study. The authors are deeply grateful for the opportunity to conduct this research with their assistance, which has significantly contributed to its development and outcomes.",
    "category": "earth_sciences"
  },
  {
    "title": "Comprehensive scoping review on adherence to 24-hour movement guidelines and socioeconomic indicators in children and adolescents",
    "authors": "Letícia Gonçalves, Suellem Zanlorenci, Melquesedek Ferreira Da Silva Almeida, Jérémy Vanhelst, Diego Augusto Santos Silva, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321103",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321103",
    "content": "Adherence to the 24-hour movement behavior guidelines has been used to identify potential impacts on health indicators in children and adolescents. However, information on the association between socioeconomic indicators and adherence to the guidelines remains unclear.\n\nThe scoping review aims to identify and synthesize scientific evidence on the associations between socioeconomic indicators and adherence to the 24-hour movement behavior guidelines in children and adolescents.\n\nA systematic search was conducted in PubMed, Web of Science, Scopus, SPORTDiscus, SciELO, CINAHL, and EMBASE. Studies were selected if they included a population of children and adolescents aged 5–17 years and addressed the relationship between adherence to the 24-hour movement behavior guidelines and socioeconomic indicators.\n\nFrom 1,871 articles identified, 10 studies with data from 562,505 children and adolescents across 10 countries were included. Self-reported questionnaires were the most common measurement method for variables related to the 24-hour movement behaviors (n=6). The Canadian 24-Hour Movement Guidelines were the most frequently used reference for classifying target behaviors (n=4). Socioeconomic indicators at the individual and/or family level were used in most investigations, specifically parental education (n=7) and household income (n=6). Most findings were inconclusive regarding the relationship between adherence to the 24-hour movement behavior guidelines and socioeconomic indicators.\n\nStudies on this interrelation have been limited, with inconclusive results regarding associations between socioeconomic indicators and adherence to the 24-hour movement behavior guidelines in children and adolescents. Further research is needed to better understand these relationships.\n\nCitation:Gonçalves L, Zanlorenci S, Da Silva Almeida MF, Vanhelst J, Santos Silva DA (2025) Comprehensive scoping review on adherence to 24-hour movement guidelines and socioeconomic indicators in children and adolescents. PLoS ONE 20(4):\n           e0321103.\n        \n        https://doi.org/10.1371/journal.pone.0321103\n\nEditor:Stevo Popovic, University of Montenegro: Univerzitet Crne Gore, MONTENEGRO\n\nReceived:January 22, 2025;Accepted:March 2, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Gonçalves et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:This study was funded by the Coordination for the Improvement of Higher Education Personnel (Fundação Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - CAPES) – Brazil, grant number 001 (to D.A.S.S.), and also by the National Council for Scientific and Technological Development (Conselho Nacional de Desenvolvimento Científico e Tecnológico - CNPq) – Brazil, grant number 309589/2021-5 (to D.A.S.S.).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nTwenty-four-hour movement behaviors are defined as the integration of variables that encompass sleep, sedentary behavior, and physical activity, distributed across the entire day [1,2]. Investigating these behaviors—specifically high levels of physical activity, low levels of sedentary behavior, and optimal sleep duration – has been widely used to identify and understand their potential effects on positive changes in health indicators among children and adolescents. These health indicators include reductions in reduced adiposity [3,4], improved bone, skeletal, and cardiometabolic health, as well as social and emotional factors [4], and a lower risk of mortality [3].\n\nAccording to the Canadian 24-Hour Movement Guidelines [1,2], children and adolescents aged 5–17 years should engage in at least 60 minutes of moderate to vigorous physical activity daily, including a variety of aerobic activities. Additionally, muscle- and bone-strengthening activities should be incorporated at least three days per week. The guidelines also recommend several hours per day of light physical activities, both structured and unstructured [1,2]. For sedentary behavior, a limit of no more than 2 hours per day of recreational screen time is advised, along with minimizing prolonged sitting periods [1,2]. Furthermore, uninterrupted sleep is recommended: 9–11 hours per night for children aged 5–13 years, and 8–10 hours per night for adolescents aged 14–17 years, with consistent bedtimes and wake-up times [1,2].\n\nAlthough the contribution of 24-hour movement behaviors to overall health is well established [5,6], a review across 23 countries estimated that 19.21% of children and adolescents aged 3–18 did not meet the recommendations between 2016 and 2021 [7]. Likewise, the joint association of these behaviors with socioeconomic indicators has been minimally explored [7]. Evidence shows that children and adolescents with low socioeconomic status are generally less physically active than their higher socioeconomic status counterparts [8,9]. Additionally, an increasing body of research indicates that low socioeconomic status is associated with poorer perceived sleep quality, shorter sleep duration, less consistent sleep patterns throughout the week, and greater daytime sleepiness [10,11]. In high-income countries, socioeconomic status has been inversely associated with sedentary behavior, whereas in low- and middle-income countries, socioeconomic status shows a positive association with sedentary behavior [12].\n\nSeveral previously published literature reviews have examined the relationship between socioeconomic indicators and various health outcomes in children and adolescents [8,13–16]. In summary, most of these reviews have shown that the better the investigated socioeconomic indicators, the better the health outcomes [8,13–16]. Regarding the association between socioeconomic indicators and the set of 24-hour movement behaviors, no single direction appears to prevail. This is likely because most studies have focused on only one movement behavior (physical activity, or sedentary behavior/screen time, or sleep) [8,13–16], which limits understanding, as results may differ when considering the combined and simultaneous association of all three movement behaviors.\n\nExisting review on this topic is available [7] but have primarily focused on a limited range of socioeconomic variables, especially contextual ones (i.e., Human Development Index and geographic location of countries/regions). Additionally, the influence or heterogeneity of results based on individual-level socioeconomic indicators (e.g., family income, family economic status, parental education level, and housing) and contextual indicators (e.g., region of residence, area of residence, socioeconomic deprivation, etc.) has not been adequately explored in the assessment of their association with 24-hour movement behaviors across studies. Identifying and synthesizing evidence regarding the association between this set of behaviors and socioeconomic indicators could help establish priorities, guide public health policies, and develop strategies that promote adherence to the 24-hour movement behavior guidelines. Furthermore, given the complexity and interdependence of these behaviors [2], investigating these interrelationships could identify subgroups more disadvantaged in terms of adherence, thus facilitating the creation of more effective and targeted interventions.\n\nTherefore, the objective of this scoping review is to identify and synthesize scientific evidence on the associations between socioeconomic indicators and adherence to the 24-hour movement behavior guidelines in children and adolescents aged 5–17. The hypothesis of this study is that socioeconomic indicators significantly influence adherence to the 24-hour movement behavior guidelines in children and adolescents, with better socioeconomic conditions being associated with greater adherence to the guidelines.\n\nThe present scoping review was conducted following the PRISMA-ScR checklist [17] and the Joanna Briggs Institute Reviewers’ guidelines [18]. The final protocol for this scoping review was previously registered on the Open Science Framework (OSF) platform (https://osf.io/bhx4s, accessed on July 18, 2024). This review followed six steps recommended by JBI: 1) identification of the research question; 2) screening of evidence related to the topic; 3) selection of evidence; 4) analysis of information; 5) grouping, synthesis, and presentation of information/data. The sixth step, considered optional, will not be utilized (i.e., assessment of the quality of the risk of bias).\n\nThe formulation of the research question was guided by the “Population”, “Concept”, and “Context” elements – (PCC) [18]. Accordingly, the following definitions were established for this review: P – children and adolescents aged 5–17 years, as the 24-hour movement behavior guidelines target this age group [2]; C – evidence related to adherence to the 24-hour movement behavior guidelines, which encompass a combination of physical activity, sedentary behavior, and sleep; C – evidence related to individual-level socioeconomic indicators (e.g., family income, family economic status, parental education level, housing, etc.) and contextual indicators (e.g., region of residence, area of residence, socioeconomic deprivation, etc.). Based on these elements, the following research question was defined:What is the scientific evidence on the associations between socioeconomic indicators and adherence to the 24-hour movement behavior guidelines in children and adolescents aged 5–17 years?\n\nEligible studies for this review included: original research published in scientific journals, whether quantitative or qualitative; studies that considered information on adherence to the 24-hour movement behavior guidelines and be conducted with children and adolescents aged 5–17 years, without any diagnosed diseases or special clinical conditions; and publications in any language. The primary outcomes of interest were studies that examined the association between individual-level and contextual socioeconomic indicators and adherence to the 24-hour movement behavior guidelines.\n\nThe exclusion criteria for this review were as follows: a) studies published prior to 2015, as original articles analyzing 24-hour movement behaviors emerged in 2015, and the first 24-hour movement behavior guidelines were launched in 2016 [2]; b) articles with objectives unrelated to the present review (not addressing evidence related to the PCC elements); c) dissertations, theses, book chapters, conference abstracts and presentations, opinion articles, methodological articles, and reviews; d) studies not available in full in the investigated data sources, even after contacting the authors via email.\n\nEvidence searches were conducted in July 2024 and adapted for application across all databases based on the method developed for PubMed, using a combination of terms for 24-hour movement behavior, socioeconomic indicators, and children and adolescents. The descriptors for each of these terms were identified from studies referenced in the literature [4,7,19], as well as consultations with the Medical Subject Headings (MeSH) platform and Health Sciences Descriptors (DECS). Descriptors in Portuguese, English, and Spanish were included in seven electronic databases (PubMed, Web of Science, Scopus, SPORTDiscus, SciELO, CINAHL, and EMBASE), tailored to each platform’s search requirements. Additional details regarding the search strategy are available inS1 File. Manual searches were also conducted in the reference lists of included studies and in review articles that analyzed topics similar to those of this review. Additionally, experts in the field were contacted to identify any further relevant studies.\n\nTwo independent researchers performed the study screening in each database, beginning with title and abstract review, followed by full-text examination of the studies selected based on inclusion/exclusion criteria. During data extraction, any discrepancies between the two researchers regarding study inclusion or exclusion were resolved by a third researcher. The search results were exported to the Rayyan software (Intelligent Systematic Review), a tool for screening, duplicate identification, and data extraction in a blinded system. In addition, the reference lists of the selected studies were examined to identify any additional studies relevant for potential inclusion in this review.\n\nData from each study were extracted and organized using Microsoft®Excel (Microsoft 2010, Version 14.7.7). First, descriptive information was gathered about each selected study, including study location, data collection year, study design, sample characteristics (sample size, sex, and age range), study objectives, author, and publication year. Additionally, specific characteristics of the selected studies were also recorded, such as tests/instruments used, classification applied for 24-hour movement behaviors, socioeconomic indicators, statistical analysis, and main findings.\n\nSubsequently, methods for measuring 24-hour movement behaviors were identified, including device-based measurements, questionnaires, or a combination of both. Information on the socioeconomic indicators used in relation to 24-hour movement behaviors was also collected. Finally, the relationship between adherence to 24-hour movement behaviors and socioeconomic indicators was extracted, including information on the measurement methods used for target behaviors (device-based measurements, questionnaire-based measures, or both), type of socioeconomic indicator (individual or contextual), and the observed relationship outcome (positive, negative, or null association).\n\nThe review results were presented in a flowchart format, following JBI and PRISMA-ScR recommendations [17,18] aligning with the review’s objective. Additionally, tables were employed to illustrate the results, providing an evidence-based description of whether associations between 24-hour movement behaviors and socioeconomic indicators were identified, as well as detailing the methods used in each study.\n\nThe initial search across the seven databases yielded 1,871 articles. After removing duplicates (n=724), the titles and abstracts of 1,147 articles were screened. Of these, 1,089 were excluded for not meeting the inclusion criteria. Consequently, 58 articles were considered eligible for full-text review. Among these, 49 were excluded for failing to meet eligibility criteria, resulting in nine articles for this review. Following an additional review of the reference lists of the included articles, one more article was selected. As a result, a total of 10 studies were included in the scoping review ().\n\nFlowchart of searches for documents in this scoping review.\n\nFlowchart of searches for documents in this scoping review.\n\nhttps://doi.org/10.1371/journal.pone.0321103.g001\n\nThese studies provided results from 562,505 participants across 10 countries, including Saudi Arabia [20], China [21,22], Mozambique [23], New Zealand [5], South Korea [24], the United Kingdom [25], the United States [26], Brazil [27], and Germany [28]. The data collection period across studies ranged from 2009 [5] to 2022 [28]. Of the included studies, nine were cross-sectional, and one was longitudinal [5], including children with an average age ranging from 6.5 ± 1.1 years [26] to 14.8 ±1.6 years [24]. Regarding sample size, the smallest study included 623 participants [5], while the largest included 114,072 participants [21]. All studies investigated both male and female children and adolescents (n=10).\n\nRegarding the objectives of the studies, it was observed that eight studies (n=8) investigated the prevalence of adherence to the 24-hour movement guidelines, key correlates, as well as group differences [5,21–23,25–28] which included measures of body adiposity [21,25,26], residence location [23], sociodemographic correlates [5,22,26] and regional socioeconomic deprivation [28]. Two of the studies included in this review collected data during the COVID-19 public health emergency [20,28]; and one study analyzed a six-year trend and the intersectional correlates of adherence to the 24-hour movement guidelines [24] (S1 Table).\n\nSelf-reported questionnaires were the most commonly used method for measuring variables related to 24-hour movement behaviors (physical activity, sedentary behavior/screen time, and sleep), appearing in six studies (n=6) [20–22,24,27,28]. Among these, five studies collected self-reported data directly from children or adolescents [21,22,24,27,28], while in one study, parents or guardians provided responses [20] (Table 1 andS2 Table).\n\nAdditionally, four studies were identified that combined two measurement methods (accelerometer-based motion devices and self-reported questionnaires) for assessing 24-hour movement behaviors, using either the accelerometer or self-reports for at least one target behavior [5,23,25,26]. Of these, three studies used accelerometers to measure two variables, including physical activity and sleep [5,23,26], while one study used accelerometers exclusively for physical activity [25]. These studies also varied in the model and placement of the device, with two studies using wrist-worn accelerometers [25,26], one using a hip-worn accelerometer [23], and one study utilizing accelerometers placed on the lower back and thigh [5]. Regarding the self-report method, two studies collected responses directly from children or adolescents [23,25], while in two studies, responses were provided by parents or guardians [5,26] (Table 1andS2 Table).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321103.t001\n\nRegarding the classification used to assess 24-hour movement behaviors, four studies were identified that reported using the Canadian 24-Hour Movement Guidelines (n=4) [21,22,24,28]. One study reported using two sets of guidelines, including the Canadian 24-Hour Movement Guidelines and the World Health Organization’s 2020 recommendations on physical activity and sedentary behavior (n=1) [20]. Another study reported using New Zealand’s 24-Hour Movement Guidelines (n=1) [5], while one study applied the Asia-Pacific 24-Hour Movement Guidelines (n=1) [26]. Two studies did not specify the recommendations used (n=2) [23,25] and one study applied specific recommendations for each variable investigated [27], including physical activity [29], screen time [30], and sleep [31] (S2 Table).\n\nRegarding the socioeconomic indicators measured at the individual and/or family level in the included studies (i.e., assessing the social and economic situation of a person, considering individual aspects), parental education was the most commonly investigated indicator, appearing in seven studies [5,20–24,26]. This was followed by sixstudies examining annual income and/or income tertile [5,21,22,25,26]. Two studies explored parental employment status and/or weekly working hours [5,23], family composition [5,21], socioeconomic status [24,27], and social class [24]. One study investigated the number of televisions in the household [23], and another study examined the number of functional cars in the home [23]. Additional details on these indicators are available inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321103.t002\n\nConsidering socioeconomic indicators measured at the contextual level in the included studies (i.e., assessing social and economic aspects of a population or environment based on the specific context being analyzed), three studies included residence location (urban/rural) [5,21,22]. Two studies examined the geographical region of residence: one study conducted in Brazil stratified data across five geographic regions (North, Northeast, Southeast, South, and Central-West) [27], while another study in Saudi Arabia used stratification across 13 province [20]. Additionally, one study included school location [23], neighborhood crime rate [23], regional deprivation index [5], jurisdictional income level [26], and regional socioeconomic deprivation [28]. Further information on these indicators is provided inTable 2.\n\nOf the studies analyzed, eight utilized multivariable models [21–28] and two used bivariate models in their statistical analyses [5,20] to examine the association between adherence to 24-hour movement behaviors and socioeconomic indicators (S2 Table).\n\nBased on the evidence summarized in this review and presented inTables 3and4, 24-hour movement behaviors were primarily measured using two types of instruments: accelerometer-based motion devices and self-reported questionnaires. The socioeconomic indicators in the reviewed studies were measured at either the individual and/or family level or at the contextual level.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321103.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321103.t004\n\nOf the seven studies that investigated parental education as a socioeconomic indicator, three reported a positive association with 24-hour movement behaviors (i.e., as parental education increased, the likelihood or prevalence of adherence to the 24-hour movement behavior guidelines also increased, and vice versa) [5,21,24], while three studies reported a negative association with adherence to the guidelines (i.e., as parental education increased, the likelihood or prevalence of adherence to the 24-hour movement behavior guidelines decreased, and vice versa) [20,23,26]. Among the studies showing a positive association, two measured all movement behaviors using self-reported questionnaires [21,24], and one study used a questionnaire to measure one of the movement behaviors and an accelerometer to measure the other two target behaviors [5] (Tables 3and4).\n\nOf the six studies that investigated income as a socioeconomic indicator, two reported a positive association with 24-hour movement behaviors (i.e., as income increased, the likelihood or prevalence of adherence to the 24-hour movement behavior guidelines also increased, and vice versa) [21,25]. Conversely, two studies reported a negative association with adherence to the 24-hour movement behavior guidelines (i.e., as income increased, the likelihood or prevalence of adherence to the 24-hour movement behavior guidelines decreased, and vice versa) [20,26]. Among the studies showing a positive association, one measured all movement behaviors using a self-reported questionnaire [21], while the other used a questionnaire to measure two of the movement behaviors and an accelerometer device to measure the remaining behavior [25] (Tables 3and4).\n\nOf the three studies that investigated the socioeconomic status indicator, only one found a positive association with 24-hour movement behaviors (i.e., participants with higher socioeconomic status had greater chances of meeting the 24-hour movement behavior guidelines compared to those with lower socioeconomic status). This study assessed all 24-hour movement behaviors using a self-reported questionnaire [24] (Tables 3and4).\n\nRegarding socioeconomic indicators measured at the contextual level, among the three studies that investigated residence location (urban/rural), one study found a positive association with 24-hour movement behaviors (i.e., those residing in urban areas had higher chances of meeting the 24-hour movement behavior guidelines compared to those in rural areas, with the authors’ reference category being urban regions) [21], while another study presented a negative association with adherence to the 24-hour movement behavior guidelines [22]. The study that showed a positive association between the variables measured all movement behaviors using a self-reported questionnaire (Tables 3and4) [21].\n\nAdditionally, one study that investigated the socioeconomic indicator of residential regions reported a negative association with 24-hour movement behaviors measured by a self-reported questionnaire (i.e., those living in more developed regions had lower chances of meeting the 24-hour movement behavior guidelines, with the authors’ reference category being developed regions) [27]. Another study examined regional socioeconomic deprivation [28] and also reported a negative association with 24-hour movement behaviors measured by self-reported questionnaire (i.e., individuals residing in more deprived areas had lower chances of meeting the 24-hour movement behavior guidelines compared to those from wealthier regions).\n\nOne study that investigated school location as a socioeconomic indicator reported a negative association with adherence to 24-hour movement behaviors (i.e., participants from rural schools were more likely to meet the 24-hour movement behavior guidelines compared to those from urban schools, with the reference category defined by the authors as urban regions) [23]. In this study, two of the targeted 24-hour movement behaviors were measured by accelerometer, and the third behavior was assessed by questionnaire [23]. Additionally, the study that investigated jurisdictional income [26] reported a negative association with 24-hour movement behaviors (i.e., the higher the jurisdictional income, the lower the likelihood of meeting the 24-hour movement behavior guidelines), with two of the target behaviors measured by accelerometer and the third by questionnaire (Tables 3and4).\n\nAll studies that investigated the socioeconomic indicators of parental employment, family composition, number of TVs at home, number of cars at home, neighborhood crime rate, and regional deprivation index found no association between these indicators and 24-hour movement behaviors (Tables 3and4).\n\nThis scoping review synthesized evidence from 10 studies that aimed to examine the association between socioeconomic indicators and adherence to 24-hour movement behavior guidelines in children and adolescents aged 5–17 years. The main findings of this review were as follows: (a) most studies employed self-reported questionnaires to assess all 24-hour movement behaviors, with responses provided directly by children or adolescents; (b) the majority of studies used the Canadian 24-Hour Movement Guidelines for classifying 24-hour movement behaviors; (c) to examine associations with 24-hour movement behaviors, most studies included socioeconomic indicators measured at the individual and/or family level, specifically parental education and income; (d) although few studies investigated additional socioeconomic indicators, the family composition was a variable for which all studies reported no association with 24-hour movement behaviors; (e) the studies included in this review found no association between the main socioeconomic indicators analyzed at the individual/family level, such as income and parental education, and 24-hour movement behaviors; (f) few studies included in this review collected data during the COVID-19 public health emergency.\n\nRegarding the evaluation of tests/instruments for 24-hour movement behaviors, most studies employed self-reported questionnaires, a method known for its validity, reliability, low cost, and ability to capture contextual information (i.e., individuals report where, with whom, etc.) as well as retrospective data, thus allowing for the analysis of these behaviors over extended periods in large-scale studies [32]. However, this tool, like others used in these studies, has certain limitations, particularly its susceptibility to memory biases (i.e., children may have difficulty recalling durations and might overestimate or underestimate certain behaviors) [33,34]. Additionally, it is important to note that relevant factors, such as age differences (younger individuals may still be developing their concept of time, which can affect the validity of questionnaires) [32], sex, and parental education level [34], were not adequately reported in the methods of most studies. This may have contributed to the underestimation or overestimation of results. Therefore, adopting additional strategies to analyze 24-hour movement behaviors and socioeconomic indicators measured via questionnaires should be considered, as this could enhance the generalizability of findings across different cultural, ethnic, and economic contexts.\n\nThe studies included in this scoping review indicated that the Canadian 24-Hour Movement Guidelines were used as the reference for classifying the movement behavior variables analyzed. This finding may be explained by the fact that these guidelines were the first to be developed with a 24-hour movement approach, are widely recognized, and offer a holistic view of behaviors compared to various separate guidelines [35]. This approach facilitates appropriate comparisons and analyses, as these variables are interdependent (i.e., a change in one behavior often occurs at the expense of others) [35]. However, while the guidelines include evidence based on diverse populations and the interrelationship with health indicators [35], they also present limitations, as they can be influenced by various socioeconomic, cultural, and other correlates (e.g., age, sex, race, etc.) [36] which may pose barriers to adherence and are sometimes generalized and addressed in a decontextualized manner. Therefore, future studies are encouraged to consider evidence in a complex, individualized, and integrated way [36], with adaptations based on different contexts (specifically when investigating socioeconomic indicators and their relationship with 24-hour movement behaviors) [36], as it is likely that the associations identified may vary depending on how these parameters are approached.\n\nThis review found that parental education was the most frequently investigated socioeconomic indicator in relation to 24-hour movement behaviors. It is suggested that this parental education may directly impact the adoption of these movement behaviors, as parents with higher education levels tend to have greater knowledge, which can positively influence [37,38] the adoption of preventive health behaviors in children and adolescents, such as regular physical activity, adequate sleep, and reduced sedentary time [38,39]. Conversely, parents with lower education levels may face barriers related to a lack of knowledge about the promotion of these healthy behaviors and may be less likely to influence their children to adopt them [40]. Parental education level has been widely used among studies and shown to be a valuable indicator of the influence of socioeconomic disparities on promoting healthy behaviors [38] . However, the adoption of healthy behaviors is complex, and more studies utilizing other socioeconomic indicators are needed, as the magnitude of associations may vary depending on the socioeconomic indicator and the context investigated [41].\n\nAnother socioeconomic indicator identified in this review in association with 24-hour movement behaviors in children and adolescents was family income. The relationship between these variables appears to be significant, as family income is an independent predictor of variables related to 24-hour movement behaviors or overall health [38]. That is, as income increases, individuals are likely to experience less exposure to negative psychosocial factors (e.g., stress, insecurity, future concerns) and have greater access to financial resources that create a more supportive environment (e.g., housing, healthcare) [38] for adopting these healthy behaviors [38,42]. In this context, although the studies included in this review did not identify a consensus regarding the relationship between family income and adherence to 24-hour movement behavior guidelines, this may be due to the varying methods of income measurement across the studies. These differences include varied data analyses (multivariable approaches [21,22,25,26] versus bivariate approaches [5] and different categorizations of income, despite all studies including questions to capture this variable. These methodological differences in income treatment could contribute to the lack of consistency in the findings.\n\nThe results described in the literature and included in this review did not report an association between adherence to 24-hour movement behavior guidelines and family composition across all studies analyzed. The plausibility for this lack of association may be related to the fact that family composition alone may not be a sole determinant in the adoption of healthy behaviors; rather, it is the modulating role of the family (i.e., regardless of family structure) that influences the adoption of 24-hour movement behaviors. This includes family social support, which contributes to the adoption of these behaviors (e.g., encouragement, engagement, logistical support, and parenting style) [43–46]. Therefore, these results should be interpreted with caution, as the significant effects of caregiver influence were not considered in the analyzed studies.\n\nAlthough most studies described in the literature and reported in this review did not reach a consensus on the association between different socioeconomic indicators and 24-hour movement behaviors, certain caveats should be considered, as studies showed divergent results for the same indicators. These include: (a) methodological differences between studies investigating 24-hour movement behaviors, with some using device-derived methods [5,23,25,26] and others using questionnaires [21,22,24,27,28] for the same variables; (b) a lack of standardization in measurement instruments and an absence of references for classifying socioeconomic variables, which reflects heterogeneous inclusion of these aspects in the context of a literature review and may have contributed to the inconsistency in results; (c) another factor that could explain the inconsistent results is the lack of strategies to moderate or mediate the analyzed relationship, which would allow for a better interpretation of the obtained results. A larger body of evidence is suggested to confirm the direction of these associations, considering that, beyond directly impacting adherence to 24-hour movement behavior guidelines [5,21–28], socioeconomic indicators have been directly linked to general living and health conditions [47,48].\n\nTwo of the studies included in this review collected data during the COVID-19 public health emergency [20,28]. The study by Alanazi et al. (2022) aimed to assess the impact of pandemic restrictions on 24-hour movement behaviors, and according to the authors’ findings, adherence to 24-hour movement behavior decreased as parental education and income levels increased. The study by Suchert et al. (2023) aimed to examine the relationship between regional socioeconomic deprivation and adherence to the 24-hour movement guidelines among children and adolescents. The authors found adolescents witch in highest socioeconomic deprivation were less likely to meet the 24-hour movement guidelines when compared to adolescents from richer regions. Although the findings from pre-pandemic studies indicated either similar or divergent patterns compared to those conducted during the pandemic, this review highlights that the COVID-19 pandemic led to changes both in socioeconomic indicators for many families worldwide, who faced job losses and salary cuts [49], as well as in the daily routines of children and adolescents, potentially affecting their physical activity, screen time/sedentary behavior, and sleep habits [20].Therefore, this review is comprehensive enough to include information from the entire body of literature, even those studies conducted during a critical period for humanity, such as the COVID-19 pandemic.\n\nThe strengths of this review include the extensive number of databases and amount of information analyzed, as well as the structured presentation of results according to tests and instruments, classifications, various socioeconomic indicators, and statistical analyses used in the reviewed studies. However, certain limitations should be noted, such as the limited number of studies with the primary objective of investigating the association between 24-hour movement behaviors and socioeconomic indicators, which reduces the ability to establish conclusive associations. Although a rigorous methodological approach was applied in the information search, gray literature was not considered, as it may present methodological weaknesses in study design and reliability of findings [50]. Furthermore, although the evidence reported by the studies did not indicate a clear direction, there is limited information available in the literature regarding the interrelationship of 24-hour movement behaviors and socioeconomic indicators, contributing to the inconclusive nature of these associations. Additionally, most of the evidence is derived from cross-sectional studies, which prevents inferences about causality and directionality. Longitudinal studies are needed, as they could offer insights into the role of 24-hour movement behaviors in children and adolescents and potential variations based on socioeconomic indicators over time. Additionally, comparing studies that used different measurement instruments for socioeconomic indicators, whether at the individual or contextual level, posed a challenge for this review. Depending on the instrument employed, the aspects considered may vary, which can influence the association with 24-hour movement behaviors. Such heterogeneity can be viewed as a limitation of the present review. Lastly, it is important to note that most methods and instruments used for assessing 24-hour movement behaviors in children present limitations. In particular, both accelerometers and questionnaires, widely used for this purpose, face methodological challenges such as variability in calibration, the need for standardized usage protocols, and potential inaccuracies in subjective reporting. These limitations may undermine the precision and comparability of results, posing an obstacle to more robust and reliable assessments of these behaviors.\n\nBased on the findings of this scoping review, it can be concluded that the results of the included studies were inconclusive regarding the relationship between socioeconomic indicators at the individual/family level and/or the contextual level and adherence to 24-hour movement behaviors, primarily because these aspects have been underreported in the literature. In terms of methods for assessing 24-hour movement behaviors, self-reporting—directly completed by children or adolescents—was commonly used. To classify 24-hour movement behaviors, most studies applied the Canadian 24-Hour Movement Guidelines. Furthermore, the majority of studies in this review included socioeconomic indicators measured at the individual and/or family level, specifically parental education and income, in examining associations with 24-hour movement behaviors. Additional findings from this review indicated that, although few studies investigated family composition as a socioeconomic indicator, all reported a null association with 24-hour movement behaviors.\n\nFuture research in this area should delve deeper into socioeconomic indicators at the contextual level, such as neighborhood characteristics and access to community resources, which remain underexplored in the literature. Expanding the scope of socioeconomic indicators beyond parental education and income is also crucial to capture a broader understanding of social influences on adherence to these behaviors. Research in culturally and economically diverse contexts is another priority to better understand how socioeconomic conditions influence movement behaviors across populations. Longitudinal studies are also recommended to provide insights into how movement behaviors change over time in response to shifts in socioeconomic indicators at both individual and contextual levels. Lastly, it is important to explore how 24-hour movement guidelines, such as the Canadian guidelines, can be adapted to different socioeconomic and cultural contexts to enhance adherence among vulnerable populations.\n\nhttps://doi.org/10.1371/journal.pone.0321103.s001\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321103.s002\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321103.s003\n\n(PDF)",
    "category": "earth_sciences"
  },
  {
    "title": "Exploring mobility patterns and social health of older Canadians living at home to inform decision aids about housing: A mixed-methods study",
    "authors": "Diogo Mochcovitch, Allyson Jones, Joshua Goutte, Karine V. Plourde, Roberta de Carvalho Corôa, Marie Elf, Louise Meijering, Jodi Sturge, Pierre Bérubé, Stéphane Roche, Sabrina Guay-Bélanger, France Légaré, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320876",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320876",
    "content": "Many tools support housing decisions for older adults but often overlook mobility patterns and social health. We explored these factors in older Canadians living at home to inform housing decisions.\n\nWe conducted a mixed-methods study with 20 older adults (65+) from Quebec and Alberta living independently or in senior residences with outdoor mobility. Data collection included sociodemographic information, GPS tracking, walking interviews, daily journals, and in-depth interviews. Data from interviews, which explored physical and social assets and barriers to social health and mobility, were analyzed using deductive content analysis in NVivo 12. GPS data were subjected to spatial analysis in QGIS (Quantum Geographic Information System) to map activity spaces and mobility patterns by the number and distance of activities, activity types, and modes of transportation. Daily journals were transcribed into an Excel spreadsheet and compared with GPS data. Overall analysis was guided hierarchically by qualitative data, utilizing verbatim narratives and visualization (activity space maps) to illustrate data convergence.\n\nAmong 20 participants, 14 completed all activities, including GPS trackers. GPS maps showed participants mostly left home to drive for shopping or walking. Over 14 days, participants made an average of 10.4 (±5.8) trips and traveled 186.9 km (±130.4), averaging 16.8 km (±29.8) per day. Transportation modes included car (n=9), walking (n=5), and bus (n=2). Daily journals revealed that participants typically traveled alone. Interviews identified physical assets as libraries and supermarkets (n=10), while social assets were family support when desired (n=13) neighborhood familiarity (n=14), both contributing to social health. Winter weather was the most cited mobility barrier (n=13).\n\nThese findings provide actionable insights to guide the development of user-informed decision support tools tailored to the housing decisions of Canadian older adults.\n\nCitation:Mochcovitch D, Jones A, Goutte J, Plourde KV, de Carvalho Corôa R, Elf M, et al.  (2025) Exploring mobility patterns and social health of older Canadians living at home to inform decision aids about housing: A mixed-methods study. PLoS ONE 20(4):\n           e0320876.\n        \n        https://doi.org/10.1371/journal.pone.0320876\n\nEditor:Li-Pang Chen, National Chengchi University, TAIWAN\n\nReceived:August 30, 2024;Accepted:February 25, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Mochcovitch et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:As data were collected and stored, they were all de-identified using anonymous identifiers to ensure confidentiality. However, due to the nature of GPS data, there remains a risk of potential re-identification within raw datasets. The Ethics Committee approved the collection and analysis of the data only for the specific study and not for other purposes. The Ethics Committee requires that the data collected remains securely stored and not be shared. Researchers interested in accessing this data may submit a request to the Comité d'éthique de la recherche du CIUSSS de la Capitale Nationale at Simon Trempe at 555 boul. Wilfrid-Hamel, bureau E-115, Québec (Québec), G1M 3X7, or via email atsimon.trempe.ciussscn@ssss.gouv.qc.ca(more information on the ethics committee is available athttps://www.ciusss-capitalenationale.gouv.qc.ca/mission-universitaire/recherche/ethique-recherche/sante-population-premiere-ligne). We report all data relevant to answer our research question in the paper.\n\nFunding:This publication is part of the COORDINATEs study (project number: 9003037412), which is funded by the Joint Programming Initiative More Years, Better Lives, represented by the Canadian Institutes of Health Research (CIHR). Grant details: Acronym of the collaborative project: COORDINATEs Full title of the project: teChnology tO suppORt DecIsioN Making about Aging aT homE Grant number awarded: #155230 Initials of the author who received the funding: FL The sponsor did not play any role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nWith the increase in life expectancy, challenges related to the health, well-being and housing of older adults arise. Among problems faced in the later phase of life, loss of autonomy, feelings of insecurity, and frailty most frequently impact well-being [1]. Loss of autonomy notably hinders the performance of daily tasks [2]. These factors including their social isolation can affect the social health of older adults [3].\n\nWhen older adults lose autonomy, they face various health-related decisions. In spite of many fitness programs developed for older adults to increase physical activity and improve their physical function, loss of autonomy is associated with physiological aging [4].\n\nA cross-sectional survey conducted with a pan-Canadian web-based panel of older adults aged 65 and over, assessed clinically significant decisional conflict (CSDC) [5]. The survey revealed that housing decisions – specifically, the decision-making process regarding whether to age at home or move into institutional residential care – are the most commonly reported difficult decisions faced by older adults. This finding was confirmed by studies among caregivers of older adults [6] and their home care providers [7].\n\nStudies show a strong relationship between wellbeing and social participation among older adults [8]. Other studies suggest that moving home may remove these social networks and other informal support systems [9]. One review of support for older adults making housing decisions suggests that such support is generally undermined by lack of attention to the whole person and lack of preparation for the move [10]. Secondly, while there are studies showing that mobility among older adults is important to a sense of autonomy and social engagement [11–14], few studies have explored the relationship between mobility and social health in the context of older adults’ housing decisions [9,15]. As an example, an older adult who is used to visiting nearby community centers may be relocated to an area with limited access to public transportation, thereby restricting their social interactions and undermining their social health. If tools that support housing decisions, such as decision aids, fail to take mobility as a social asset into account, increased decision regret is likely [16].\n\nA decision aid is a tool that supports informed value congruent decision making by guiding people to evaluate the evidence on the benefits and limitations of different options based on personal values and priorities before making a decision [17]. More often than not, decision aids to support housing decisions focus exclusively on the older adults’ health condition and on their physical safety [18].\n\nMany housing decisions are about moving an older adult into institutional residential care. If physical safety and nursing care are the principal considerations in this decision, an institutional setting may be regarded as the best choice. However, most older Canadians wish to grow old in their own homes for reasons other than their physical health and safety [10]. Without considering these additional reasons, loss and disappointment may follow their decision.\n\nThe social health of older adults is as important as their physical health to their overall well-being [8,19]. Indeed, the influence of social relationships on the risk of death are comparable with well-established risk factors for mortality such as smoking and alcohol consumption [20]. There is a growing interest in expanding the focus of health to include social health [21,22]. Social health emphasizes the individual’s capacity to engage in social activities, maintain a sense of purpose and fulfillment in life, and retain some degree of independence (e.g., going for a walk alone) [22]. Social health entails sustaining meaningful relationships, social participation, functioning to the full extent of one’s potential, and coping with the practical consequences of aging. For older adults, these capacities contribute to healthy aging [23].\n\nMobility plays a key role in social health. Although the definition of mobility refers solely to the physical ability to move independently from one place to another [24,25], there are influencing factors that shape the underlying purpose of this movement (e.g., social interactions, family engagements, work, and leisure activities) [26]. In this study, we consider mobility as a physical phenomenon, but also the influencing factors that determine its purpose. A related concept in gerontological research relevant to housing decisions is understanding how older adults interact with their existing physical and social environments, how this interaction changes with time, and how this impacts their social health [27]. Some studies have used the idea of “lifespace mobility,” or the range of physical environments in which older adults move during a specified time period, to measure mobility and its determinants [28–31]. The notion of “activity space,” which also combines these notions of space and time, is the collection of places outside a person’s home (but not necessarily within their own neighborhoods) that they routinely or occasionally visit, and the corresponding travel routes that they use to get there [22,32,33]. The concept has been widely used in studies investigating the social determinants of health, access to health care, diet, physical activity and social inequalities [34–36]. A few studies have explored activity spaces in the lives of older adults [22,35–38], but none in the context of developing decision aids for making housing choices.\n\nWhile healthcare professionals and family caregivers involved in housing decisions with older adults may be conscious of their growing health burdens and safety needs [6,7], they may be less aware of these existing social and physical assets and older adults’ access to them, which should play an equally important role in the housing decision [39–41]. For instance, it is important to identify the social supports, such as friends and family, that currently help maintain an older adult’s social health [42]. Or volunteering in their community may provide them with a healthy sense of self-worth, and their mobility may make this possible [43]. Therefore, it is important to understand the motivations that help them remain mobile and maintain their physical health, and to consider whether, if they decide to move to a different home or neighborhood, these social and physical assets will still be available to them.\n\nBased on these gerontological concepts, we sought a new perspective on how older adults’ mobility patterns, i.e., the quantified mobility of outdoor travels [26], and activity spaces affect their social health. Following earlier exploratory studies [22,44,45], we hypothesized that measuring the mobility patterns of older adults, in combination with qualitative interviews and journals regarding the social advantages that are associated with that mobility, would provide a portrait of their existing social and physical assets that constitutes essential information for their housing decisions. Existing research often isolates these factors [46–48] or relies on self-reported data [49–51]. Therefore, with the overall goal of informing the design of decision aids, we aimed to map the activity spaces of older adults in two Canadian provinces by combining GPS data with narrative sources (interviews).\n\nThis mixed-methods study is part of a larger international initiative, teChnology tO suppORt DecIsioN Making about Aging aT homE (COORDINATEs), an interdisciplinary multipronged research program conducted in Canada, Sweden and the Netherlands to understand the mobility patterns and experiences of older adults living at home and how this data can improve autonomy and inform shared-decision making about housing options [45]. As this research involves a variety of different data sources, we opted for a mixed methods approach guided by the Good Reporting of A Mixed Methods Study (GRAMMS) guideline [52]. At the same time, our study design can be better described as a convergent mixed-methods approach [53] whereby the different methods are integrated through building on one data source after another [54]. In this method, the results from GPS data are used together to inform our understanding of other qualitative data sources.\n\nWe took a matching approach to converging data [55], involving intentionally designing our data collection instruments to have related items so that all instruments would elucidate data about the same issues of mobility and social health. In terms of the methodological dimension of our data merging, we took a qualitatively driven approach, i.e., guided hierarchically by the qualitative data. Concretely, we used the technique of matching data from qualitative questions with the quantitative GPS data, integrating our data at the interpretation and reporting level using both narrative (the discussion) and visualization (the activity space maps) to illustrate where the databases converged, complemented, conflicted, or diverged.\n\nEthical approvals were obtained from the Health Ethics Research Board at the University of Alberta (Pro00087478) for Alberta and from the Integrated University Health and Social Services Centres (CIUSSS) de la Capitale Nationale (2019–1519) for Quebec. Written and informed consent was obtained and secured from all participants prior to their enrollment in the study.\n\nThe Canadian sub-study recruited participants from two provinces, Alberta, and Quebec, using a variety of outreach methods. The screening took place in a fall prevention clinic [56], through community engagement, and by distributing flyers and posting them in seniors’ residences. Eligibility criteria included: a) aged 65 years or older, b) living autonomously at home or in a seniors’ residence, c) independent outdoor mobility.\n\nWhile much data on older adults is gathered from staff members in residential settings or family members, we wished to capture the direct experience of older adults themselves, as this would empower them to discuss their current and future needs [57,58]. A combined approach to gathering data improves data accuracy by cross-validating information through multiple sources [53,59]. Data were gathered using five distinct methods: i) a sociodemographic and other self-reported information, ii) a walking interview iii) GPS tracking, iv) daily journal entries, and v) an in-depth interview. The data were collected at different times in each province. In Quebec, data collection took place between August 10, 2019, and March 5, 2020. In Alberta, it began on February 1, 2020, but was interrupted due to the COVID-19 public health emergency. It resumed between September 29, 2021, and February 28, 2022.\n\nUpon meeting the inclusion criteria and providing written consent, participants completed the survey, which was comprised of sociodemographic information, perception of self-reported health status, assistance required for daily tasks, and technology use. For self-reported health status, we used a 5-point Likert scale [60], allowing participants to rate their health based on subjective experience, with options ranging from poor, fair, good, very good, to excellent. For questions regarding assistance required with daily tasks, we based our items on the Instrumental Activities of Daily Living (IADL) Scale, which assesses the ability to perform complex everyday tasks (e.g., managing finances and medications) evaluating whether the participants receive or provide help with those tasks [61]. Regarding technology use, we asked participants to specify the types of technology they typically use in their daily life.\n\nEach participant was shown how to use a GPS tracking device (QStarz BT-1000X) and for over 14 days they attached the devices around their waists when they left the house. A minimum of 14 days is recommended to accurately record a person’s routine activity spaces [62]. We used GPS tracking to provide an objective measure of physical distance and type of participants’ activity spaces. GPS observations [63] also allowed greater precision of time spent in particular areas or at specific activities rather than capturing only particular locations. Finally, GPS tracking captured locations in smaller time intervals (e.g.,1 or 5 seconds intervals), and had a longer battery life than smartphones which meant less data was lost.\n\nThe daily journal was a paper-based matrix which participants completed over the 14 days, detailing their activities outside their home. Each daily entry included information such as purpose of the activity, mode of transportation, companions or absence thereof, and if they needed to use a mobility aid. The journal also complemented the GPS data with information about what the people or places visited meant to them.\n\nParticipants were interviewed by a research assistant while they were walking in familiar places and routes, typically close to their homes. The purpose of walking interviews was to capture details about participants’ activity spaces on a moment-by-moment basis. Participants were asked about the physical environment (street quality, sidewalk quality, problems, or need to change their routes) and social environment (e.g., the people they would meet, visits with family, friends, etc.). These interviews typically took 15 minutes with some participants taking rest breaks during the walk.\n\nAnother interview session was scheduled with participants after the 14-day period at a mutually convenient time for a thorough in-depth interview which generally lasted 45 to 60 minutes. This interview was another opportunity, through prompts in their daily journals, to offer further insights into their overall experience.\n\nThe goal of our data analysis was to match qualitative data with quantitative data, integrating or merged data at the interpretation and reporting level using both narrative and visualization (activity space maps) to illustrate where the databases converged, complemented, conflicted, or diverged.\n\nWe conducted this analysis in a hierarchical manner, layering one source upon another, with GPS data and interviews serving as primary sources, complemented by daily journal entries. We chose this approach due to the building nature of the data [54], where the interviews deepened our understanding of the mobility captured by the GPS tracking, uncovering the factors influencing the mobility. For instance, GPS data may reveal a participant’s choice to take a longer route to the supermarket instead of a shorter one, while interview data could indicate that this choice serves as a coping strategy to avoid a noisy avenue that causes stress. The combination of methods allowed us to produce a comprehensive analysis of social health in the mobility patterns of older adults [53]. For participants who did not provide all primary data sources (e.g., those who did not use the GPS properly but provided interview data), their data were still analyzed but only in the relevant sections (e.g., their responses were included in the qualitative analysis and categorized under the appropriate themes and codes).\n\nUpon completion of data collection, interviews were transcribed, and data anonymized (manual encryption of personally identifiable information). A deductive content analysis was performed on the transcripts based on an adapted version of the Asset-Based Approach to Community Development (ABCD) framework [44,64] using NVivo 12. Qualitative and quantitative data (socio-demographic, self-reported health and ability to perform daily tasks) were then organized into a descriptive summary. Statistical Analysis System (SAS) software was used to describe characteristics of participants.\n\nFor analysis of the GPS data, cleaning of tracks was done to eliminate the congregation of points around the households of the participants. Where the information regarding participants homes’ and where they went (based on diary data, see below) was already known so we were not omitting any information. While there were instances of data points being recorded erroneously, there was a distinct pattern in which the errors appeared, and it was obvious that these were not feasible patterns for any participants (two points at different locations at the same time). The data was sorted by time and then traced from one point to another, and the only points discarded were the congregations of points when a participant was not moving. The main purpose of the GPS analysis was to illustrate the activity space of participants, so the cleaning process was done for illustrative purposes only and no track was omitted due to any undesirable outcomes by any of the authors.\n\nGPS location data (distance travelled, activity type and duration) was used to track participants’ mobility. Relationships between mode of transport and distance were evaluated and key statistical indicators (mean/ standard deviation) of the distance in each mode of transport were used to create activity space maps.\n\nThe following indicators were used to assess activity spaces, and the social and physical abilities of the participants:\n\nNumber and distance of activities:We used QGIS software to determine the distance (kilometers) of the trips and average distance travelled per day. QGIS is a free, open-source cross-platform geographic information system application that helps view, edit, print, and analyze geospatial data [65]. The purpose was to understand participants’ physical ability and the distance travelled from home. The number of trips per person was also measured over the 14 days.\n\nActivity type:We examined the stops on participants’ trips using QGIS software and assigned them to a specific activity using a Google Maps base map, such as restaurants, stores, pharmacies, medical clinics or hospitals, sports centers, cultural centers, and grocery stores. The type of activity chosen was also a sociability indicator such as going to a bingo hall which has greater potential for social interactions than going to a pharmacy.\n\nMode of transportation:The type of transportation was analyzing using GPS data along with the QGIS software. To distinguish whether participants were walking, taking the bus, or driving, we relied on the speed data point as a key indicator, given the substantial speed variations between these activities.\n\nFinally, types of activity were correlated with distances travelled and modes of transportation.\n\nThe daily journals were our second data source for information about distances travelled and modes of transportation. They were collected, digitized, and subsequently transcribed into Excel spreadsheets. This information in Excel was compared with GPS data to confirm or supplement it (e.g., destination, purpose of activity, mode of transportation).\n\nGiven that the debriefing interview centered on themes explored during the walking interview, which in turn served as a corroborative cross-check of the daily journal entries, we decided to merge the walking and debriefing interviews to gain a comprehensive understanding of the interviews and their underlying themes. Interviews were transcribed verbatim by independent researchers. The resulting transcriptions were then imported into NVivo 12 software, facilitating the qualitative data analysis process. Employing an approach based on a priori codebook from our previous work [44] and adapted to the Canadian context, two independent researchers (KP and DM) conducted a deductive content analysis [66] with 7 overarching themes: physical and social assets (e.g., benches, family members), neighborhood descriptions (e.g., services, stores), mobility descriptions (e.g., with whom, weather, means of transportation), approaches to mobility challenges (e.g., adapt, avoid, cancel), navigation strategies (e.g., points of reference, asking for help), and the impact of Covid-19 on mobility patterns. We also coded reactions to the data collection methods (GPS and daily journal), a seventh theme. We coded and cross-referenced themes to derive meaningful insights. To ensure the integrity of the analysis, the researchers engaged in consensus-building discussions during codification to reach the same understanding of code definitions. After this first consensus, we sought input from an experienced third-party qualitative researcher (RC) to assure consensus. A supplementary secondary analysis [67,68] of the most prevalent codes were performed to establish broader categories. This allowed us to facilitate the interpretation and narrative presentation of qualitative results in relation to the quantitative data sources. Four broader cross-sectional categories relating to social health and mobility were generated: Physical and social assets, social and physical obstacles, adaptation strategies, and the impact of Covid-19. Frequencies of all coding themes are presented inS1 Appendix.\n\nTo illustrate the multi-dimensional nature of participants’ mobility patterns and social health, we purposively selected a heterogenous group of 4 participants, 2 from Quebec and 2 from Alberta. For each participant we combined their data [69,70] (i.e., GPS data, diary entries and interview responses) to create personal activity space maps. These maps were generated using QGIS software, with basemaps accessed via the Quick Map Services plugin [71] and sourced from ESRI’s Light Gray Canvas basemap [72]. Our choice of the 4 participants for these illustrative activity space maps was driven by our search for the most contrasting mobility patterns, activity spaces, modes of transportation and social health, allowing us to highlight differences between participants and provinces.\n\nOf the 25 people approached; 20 participants agreed to participate in the study. Five individuals from Alberta opted out of participating in GPS tracker usage, while one individual died during the research, leaving data only in the form of the responses to the questionnaire. As a result, 14 individuals agreed to utilize GPS devices to map out their activity spaces. Five participants (4 from Alberta and 1 from Quebec) encountered difficulties with the device, especially in charging it, and were unable to record GPS data. Ultimately, 9 participants used the GPS appropriately. Of the total 14 participants who utilized GPS (both appropriately and inappropriately), 7 also successfully completed the daily journal (1 from Alberta, 6 from Quebec).Fig 1shows the participants’ flowchart.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320876.g001\n\nTable 1shows details of responses about sociodemographic, self-reported health, assistance with daily tasks, and use of technology. In Alberta, 86% were women (n=12) and their ages ranged from 67 to 89 years old and in Quebec 33% were women (n=2) and their ages ranged from 62 to 90. Overall, they had lived in their current neighborhoods for an average of 15 (±7.9) years. Most were married (n=6) or widowed (n=6). Nearly half had completed higher education (n=9). Nearly half were living with others but independent (n=9), 40% were living alone and independent, and 15% were in a senior residence. “Senior residences” are more akin to adult-only buildings and focus on accommodating autonomous older people (whereas to qualify for public long-term care, residents have been hospitalized and can no longer return home) [73–75]. Half reported they were in “good” health (n=10). In terms of access to technology, 85% used the Internet and 40% used social media while 60% used a smartphone and 60% used a tablet.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320876.t001\n\nOf the 9 participants who provided GPS data (5 from Quebec and 4 from Alberta), we generated 9 maps describing their activity spaces. Overall, the mean number of trips per person over the 14 days was 10.4 (±5.8). The average distance travelled per person was 186.9 km (±130.4), and average distance per day was 16.8km (±29.8). Mean distance travelled regardless of the type of transportation was 125 km (±75.4) in Alberta and 236km (±151.2) in Quebec.\n\nIn terms of the participants’ activity spaces, we divided them into 6 categories over the 14 days of GPS data collection: stores, healthcare facilities, pharmacies, socially focused visits (e.g., children or friends), cultural events, and sports and leisure activities (e.g., take a walk, go to a park). For all participants in both Alberta and Quebec, the most frequent purpose of leaving home was to go to a store.\n\nTransportation was categorized data into 3 groups: walking, using a car, and taking a bus. Most participants used more than one type of transportation. Eight participants used a car as their main means of transportation, while 1 participant relied solely on the bus. In Alberta, 1 participant used a car and walking in the same trip. In Quebec, among the 5 participants who used the GPS, 4 used walking as one of their means of transportation. Although residents in both cities relied heavily on cars for transportation, more people in Quebec used public transport than in Calgary, despite Calgary being almost twice the physical size of Quebec [76].Table 2provides a detailed overview of the mobility description.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320876.t002\n\nFor 1 participant in Alberta, stores were his only activity spaces, and he exclusively used the car. However, the most active Alberta participant had 10 activity spaces and used both walking and car. The 5 Quebec participants also primarily visited stores, but they had more than one activity space, two of which related to sports and leisure (e.g., parks). The most active participant had a total of 23 activity spaces and used walking, car, and bus to go out. Participants’ means of transportation, distance and activity spaces are presented inTable 2.\n\nDaily journals were completed by 7 participants (n=1 Alberta and n=6 Quebec). In additional to corroborating GPS data, 6 mentioned that they typically travelled alone and 4 were occasionally accompanied by a family member. Some mentioned they went out “just to get some air.” Three mentioned being accompanied by friends, while one participant did not undertake any trips during this COVID period and simply followed their regular exercise routines at their seniors’ residence.\n\nOf the 14 participants interviewed, most of the social and physical assets mentioned were related to walking. During the walking interviews, most participants (n=10) emphasized the importance of their local institutions (such as libraries and supermarkets) as essential physical assets that helped them stay active. They also mentioned the importance of benches or shelters where they could stop to rest (n=10): “I get tired. I walk in the park and the minute I see a bench I sit down for two or three minutes, then I go on” (P3). One participant organized her route according to the available resting places: “The reason I take this walk is because I have many places where I can stop the walk as soon as I want to” (P103). The design and layout of walking routes also significantly impacted mobility choices (n=13): “There are some excellent walks in this area. Like leaving the main entrance if you walk around, there’s a path down here” (P113). Others mentioned the importance of support equipment for walking in winter, such as crampons, walkers, and railings.\n\nThe majority (n=13) demonstrated an appreciation of easy walking access to services: “It’s all well-organized. There’s a pharmacy, a library here, and another library over there” (P5). The importance of familiarity of one’s neighborhood was also highlighted by comments from 3 participants on how moving had or would in the future result in loss of orientation and loss of activity options.\n\nIn the context of participants’ social and emotional responses towards their neighborhood, all 14 participants demonstrated a deep sense of attachment, encompassing not only their geographic surroundings but also the interpersonal relationships with their neighbors. One participant vividly expressed this emotional connection by stating, “I love this neighborhood. I have nice neighbors. I can walk to many places, and I can take the bus downtown. I love this neighborhood” (P111). Familiar places can also stimulate happy memories: “The water was high... It reminded me of being in the Gaspé when I was nine years old” (P3). Walks were often highly social as well as physical activities: “I meet people who are out walking like me. And we talk about the temperature, the nice weather, and about our illnesses” (P3). Dogs turned out to be a physical asset as a motivator go out walking. They are also social assets: “I say all the time that I go out for the sake of Henri [the dog] – but really, it’s for me... It’s ‘good morning, madame, good morning, madame’” (P3).\n\nThe main social asset identified by participants was family and neighbors (n=13). Indeed, participants mentioned that family members were their main companions (n=11), mostly their partner and/or children: “When I go to my doctor’s appointments... it’s my daughter who comes because she’s too afraid I’ll forget things” (P6). Proximity to family or neighbors (n=13) emerged as a major social asset, although sometimes participants were ambivalent about this: “My daughter drops by every now and again, but I never know when she’s going to arrive” (P104).\n\nThree participants, even some in their eighties, mentioned volunteer activities as another social asset: helping out at the hospital, library or even just going walking with fellow volunteers. Participants also mentioned the significance of driving to maintaining their independence. As one participant expressed it, “I’m going to keep driving until I’m 80, and I’m just turning 78 now” (P106). Walking is similarly important for self-esteem and independence: “I complete my entire walk, heading down to the turning point when I go around, and I complete the loop back to my house, if I go for the full route” (P103).\n\nDuring the winter months, mobility changed for the most of older adults (n=13) both in Alberta and Quebec “When it’s cold I don’t go out, I just stay home, so there we go” (P104). Both snow and freezing rain were frequently mentioned as mobility hazards. One participant missed gardening in the winter, and others mentioned missing their friends or relatives: “I have to wait until spring to go to Chicoutimi to visit my cousin” (P2). Putting on winter clothing was also a discouragement to going out. “It’s not motivating, first you have to put on huge boots, pants, and even if I had the special pants, you also need a big coat, a vest... ah no” (P3). In many locations the city did not clear the sidewalks and participants reported having to walk on the street: “The city doesn’t … do the roads here, because of course it’s not an important road” (P103).\n\nCertain participants indicated a requirement for specialized mobility aids, particularly canes (n=6): “I have a walker and a cane, and I also have two sticks, so depending on what I’m doing, I alternate with some of them” (Participant 110). Most participants (n=11) disclosed that they had to adapt their routes due to mobility impediments. One even had mobility difficulties accessing her own seniors’ residence: “What I do is... just go down to the arcade and then take a stairway up and do it that way. It’s not really handicap friendly” (P106).\n\nOlder adult participants also mentioned losing friends due to their loss of autonomy, loss of hearing, the relocation of their friends, or their death.\n\nTo cope with stress and navigate the obstacles, participants adopted regular routines with points of reference (n=8) as a guiding framework for their trips: “We get to walk down Heritage towards…and on Hammer Hill, towards Heritage Drive which is a city block away on the sidewalk and stop for a moment or two. And then we get to Heritage Drive and then walk back, that’s about a 10-minute walk to 15 minutes” (P109).\n\nOver the time the study was conducted, Alberta had declared a state of emergency due to the Covid-19 pandemic that lasted 21 months. The city of Calgary had periods of police-enforced curfew and lockdown in 2020–2021 [77]. Certain Alberta participants pointed out that the pandemic had lasting impact on mobility routines: “I used to do exercise over there, but I don’t know. We don’t go out to eat... Covid seems to… just make me shut down. I haven’t done it” (P110).\n\nOf the 9 GPS maps generated, we selected 4 contrasting participants’ maps—2 from each province (Participants 01 and 04 from Quebec, and Participants 106 and 111 from Alberta). The selection was based on their mobility patterns and modes of transportation, considering the frequency of outings from their houses and the distance traveled in kilometers. In Quebec, Participant 01 was less active, resulting in fewer activity spaces and a less elaborate mobility pattern in comparison with Participant 04, who had more varied and complex activity spaces and was more independent using all 3 means of transport, including the bus. In Alberta, Participant 106 was relatively inactive and used just one means of transportation while Participant 111 had multiple means of transportation and varied activity spaces. The GPS data generated allowed us to also create small inset maps to zoom in on activity spaces near the participants’ residence.\n\nParticipant 1:Based on the GPS analysis, Participant 1 incorporated walks into his daily routine. These are for the purpose of exercise rather than to reach a particular destination. The car journeys on the other hand, to the pharmacy and grocery stores, appeared to be for essential supplies or to visit friends or family.Fig 2shows his activity spaces map.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320876.g002\n\nInterviews confirmed these findings, but also provided a context for and a historical perspective on these car journeys: Participant 1 mentioned that he had lived in his neighborhood for the past 25 years and had witnessed its growth with the emergence of new buildings and streets. There were not many services available in his neighborhood and he had to drive longer distances from his house in search of services. Even though there were no services near his home, Participant 1 would only move if his needed to for health reasons: “I wouldn’t exchange this neighborhood for another. Just change for change’s sake, it’s not worth it...... let’s say you get sick, then you might move nearer to the hospital, then you might move to the city.”\n\nHis daily journal showed that all trips made by car were with someone from his family. The GPS also suggested his walks lacked a predetermined and specific destination (the map showed no services on her route), and the interview indeed revealed that he preferred to walk around the neighborhood to see the mountains every day. His sense of attachment to his community, his enjoyment of the mountains, and his reluctance to relocate unless facing significant health issues points towards the complex interplay of personal, community and health considerations in the decision-making processes of older adults regarding their living arrangements.\n\nParticipant 4:Participant 4 had fewer and short walk than Participant 1, but according to GPS analysis her walks were to specific destinations: receive medical care or to go to the pharmacy.Fig 3shows her activity spaces map.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320876.g003\n\nShe also took the bus and drives. She mentioned appreciating the proximity of services in their neighborhood, but also pointed out that one of the reasons she walked less is the lack of places to rest during her walk. She was able to use the bus for certain closer destinations, but also made long car journeys. In contrast, there were more varied activities with Participant 4’s than in Participant 1’s. The journals of the Quebec participants revealed that Participant 1 undertook only planned activities during the 2 weeks, while half of Participant 4’s activities were unplanned, suggesting that her easy access to neighborhood services and use of several means of transportation are more conducive to last minute outings. It could also reflect her personality or lifestyle.\n\nBased on GPS data, Participant 4 often undertook extensive journeys by car. The daily journal showed that all these car trips were accompanied by another individual, whereas the walks and bus journeys were alone. This highlights that while more independent exploration is possible via walking and bus travel, driving may have required a companion. It was unknown, however whether Participant 4 was the driver or passenger Still, the unplanned activity spaces in this participants’ life suggested an individual in robust health with aspirations to engage in a myriad of pursuits – a sentiment corroborated by the interview findings. Participant 4 indeed maintains an active circle of friends, affording her opportunities for unplanned and frequent visits and leisure in their company. Moreover, Participant 4’s daily journal entries revealed a significant connection with her granddaughter and other children, demonstrating the importance of familial bonds in her life. The triangulation of data illuminated both her personal agency in pursuing her social interactions and her deeply rooted responsibilities within her family dynamic as motivations for dynamic aging in place. For Participant 4, these multiple physical and social assets and varied activity spaces and mobility patterns should be important elements in any future housing decisions.\n\nParticipant 106:In the case of the Alberta participants, there was a similar contrast between the 2 maps as between the two maps in Quebec. Participant 106, over the course of 2 weeks, made a total of 5 car trips, all of which were essential, involving visits to medical care facilities, the pharmacy, and grocery stores. Additionally, there was a single stop at a church. Notably, this participant did not engage in any walking activities as presented inFig 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320876.g004\n\nIndeed, Participant 106 displayed locomotion difficulty from the start of the walking interview, indicating impediments to her mobility. She has great difficulty even leaving her own building: “Oh yes. I have to negotiate with my walker. These stairs are really hard to negotiate… And there’s no railing.”\n\nFrom the interview we know that although Participant 106 is aware of the importance of exercising and desires to take walks, she does not engage in activities she would like to pursue because of the absence of physical aids that could assist with her mobility.\n\nVisiting friends also becomes difficult, and her both her physical and social health suffer as a consequence, although she appreciates the offers of help from her neighbors: “It’s amazing how many people, if they see you struggling, they just run over... It’s very touching.”\n\nThe effort required to overcome the physical barriers to mobility experienced by Participant 106 not only restricts her access to social interactions but also exacerbates the sense of social isolation that can accompany aging. This participant had made the decision to move into an adult-only building, and while there may be some advantages to this housing option, perhaps the full extent of the social and physical assets of her previous residence and the potential assets in the new residence had not been fully taken into account in this housing decision.\n\nParticipant 111:Participant 111, in contrast, frequently drives to different places. From the GPS perspective, Participant 111 provided more data and more information, presenting a panorama of her activity spaces and robust social health as presented inFig 5.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320876.g005\n\nAt first sight, Participant 111’s mobility patterns seemed less strategic than those of Participant 106. Because there appeared to be less routine, data building was especially important in the case of Participant 111. The interviews revealed that her dog is an important part of her life: “My life is all about dog walks. I didn’t really have to go anywhere.” These walks give her a sense of meaning, increase her mobility and motivate her to walk extensively in her neighborhood (orange line inFig 5). Participant 111 also leads an engaging and spontaneous social life, frequently visiting friends’ homes and organizing walks in different parks, both individually and with a group. As shown on the map, Participant 111 uses a mixed mode of transportation, using a car to travel to the park for walks. The interviews revealed that she picks up her friends on the way. This active social involvement contributes to the extensive mobility displayed in the GPS data. Overall, Participant 111’s sociability and mobility patterns highlight an active lifestyle, positioning her as a central figure within her social circle. As with Participant 4, these multiple physical and social assets, varied activity spaces and creative mobility patterns should be important elements in any future housing decisions.\n\nThe convergence of sources provided new insights, revealing that the use of complementary sources sheds light not only on variations in their modes of transportation, and how the older adults navigated these spaces, but also the social aspects of their lives not captured by the individual data sources.\n\nWe used the concept of activity space to explore the mobility patterns and social health of Canadian older adults living at home, which could inform decisions about housing options which, in turn, could be considered in the design of decision aids for making housing decisions. Large variations were seen with mobility patterns in distances travelled over the observation period, with Quebec participants travelling greater distances. Cars were the most frequently reported means of transportation with the primary destination being going to a store. Also, most respondents travelled alone. We found that the most frequently reported social asset was the proximity of family members and neighbors and attachment to neighborhood, while the most frequently reported physical asset were benches and neighborhood institutions, as also found in the sister study in the Netherlands [44]. The most frequently reported social and physical obstacles were related to winter weather and mobility. Participants mentioned points of reference and physical supports such as canes as adaptation strategies to address mobility obstacles. Lastly, the merging of sources provided new insights, revealing variations in participants’ modes of transportation and how they navigated these spaces, and also highlighting social aspects not captured by the individual data sources.\n\nThese results lead us to make the following observations.\n\nFirst, activity space maps illustrated a marked difference in number and type of activities between Alberta and Quebec which may speak to both the built-environment, green-space and the physical infrastructure. In both provinces, stores were the most frequently visited places. Our results show resonance with other studies [78,79] in which the primary focus of trips outside the home for older adults is going to stores. However, in Quebec, participants were more inclined to visit family and friends and participate in cultural events, also found in another Canadian study on participation in social activities [80]. In Quebec, independence and autonomy were reinforced by the proximity of walkable neighborhoods with more available and accessible services for older adults. As our results also demonstrated that most trips outside the home were made alone, walkable neighborhoods contributed to enabling them to maintain their autonomy. Even though the car was the predominant mode of transportation in both provinces, in Quebec, participants routinely used the car in combination with another means of transportation, such as walking or taking the bus, whereas in Alberta, participants mostly relied on the car for their activities. This may suggest a lack of public transportation infrastructure or conversely a stronger car culture in Alberta, a province associated with the oil industry [81]. It may also suggest stronger presence of family in Quebec, a province that historically has much higher intraprovincial retention than Alberta. Quebec’s attachment to the French language also means they are more likely to remain within the province [82]. Furthermore, participants with more varied activity spaces were those who utilized more than one means of transportation. This implies that a broader range of transportation options for older adults which provides greater access to more places. According to the World Health Organization (WHO) [83], mobility is fundamental for older adults, and preserving it stands as the most effective strategy for remaining actively engaged within their community. Designers of decisions aids for housing decisions should take mobility into account as well as comparison of existing and future transport options, along with importance of car transportation, when they present older adults with housing options.\n\nSecond, family constituted a significant social asset, exerting a substantial influence on their social networks and social support [84]. Other studies confirm that the absence of familial support negatively affects the social connections and overall social well-being of older adults and their life satisfaction [85]. In terms of autonomy in daily life, even if the older adult does not need direct aid from a family member, their offer of availability improves well-being and contributes to their perception of emotional support [86]. As hinted in our results, this availability can also sometimes be invasive. However, in general, the proximity and accessibility of family are important considerations in making housing decisions. The interviews also revealed a strong feeling of community attachment to the neighborhood and neighbors, with many participants echoing similar narratives of attachment, underscoring the importance of a social fabric that has developed over time. Participants’ emotions about their neighborhoods are tightly interwoven with the decision-making process about housing. The concept of neighborhood goes beyond being a mere geographical contingency; it reveals significance to a community and expresses its local culture and has the potential to shape collective identity and increase social interactions. In the field of gerontology research, the neighborhood category is progressively gaining recognition as a primary and decisional factor in the health and well-being of older adults [87–89]. In our research, we observed that residents in Alberta needed to travel greater distances to reach stores for their shopping needs. This stands in contrast to participants from Quebec, who underscored the importance of local establishments such as grocery stores. They emphasized that the ability to walk to nearby stores (i.e., walkability) is a determining factor for the well-being of older adults. Regarding physical assets, our findings suggest that older adults adapt their walking routes based on the presence of benches, emphasizing the crucial role of a surrounding environment that takes their mobility needs into account. Ottoni et al. [90], who conducted research in Vancouver, Canada, demonstrated that benches positively impact the mobility of older adults. Their contribution extends beyond being a mere physical asset, they change behaviors. This was also demonstrated by Sturge et al. [44], who noted that while they are necessary breaks for older walkers, the accidental encounters they provide create additional intergenerational social integration. Benches enhance the utilization and enjoyment of green areas, also elevating the social capital of older adults [90]. As the built environment plays a significant role in influencing the mobility of older adults [44,79,91–94], their housing decisions should consider factors such as the accessibility of benches in the immediate surroundings.\n\nAn accessible neighborhood offers both a physical and a social asset as well, in terms of its institutions (e.g., libraries, grocery stores), which play a crucial role as they provide important venues for social engagement. For example, other studies [95,96] have indicated that public libraries, in particular, foster social connections among older adults. In addition, as some participants noted, their visits were not solely to interact with known individuals but also to engage with the broader community and new people, emphasizing the importance of access to neighborhood institutions for fulfilling the inherent human need for social contact and the formation of new connections.\n\nThird, obstacles to social health included the weather which was frequently expressed as an impediment to their activities outside the home. Canadian winter weather decreases social connection and increases the risk of social isolation [97]. The reduction of the walkability of roads by snow and ice directly influences older adult’s physical health and well-being [98]. Many have adapted their activities to overcome the challenge by adjusting their routes or using canes and crampons, which can increase the risk of falls. Preventing falls is one of the most significant concerns in terms of public health for older adults. According to the World Health Organization (WHO), one-third of older adults fall each year. In older adults aged 70 or older, this percentage varies between 32 and 70 [99,100]. Mondor et al. [101] demonstrate that in winter, especially during freezing rain and snowstorms, there is an increase in fall-related injuries in older adults, posing a serious public health issue in Canada. In both Alberta and Quebec, freezes and thaws can occur in quick succession, covering the ground in a sheet of ice. This is evident as the number of hospital admissions for fall-related issues is growing among those aged 65 and older [102]. Walkability for older adults decreases in winter, and decision aids about housing decisions for older adults in places with severe winters such as Quebec and Alberta (where temperatures of -35 degrees C are not uncommon) need to consider the impact of winter conditions and the adequacy of local snow-clearing on their housing options, as well as whether their existing coping strategies are transferable.\n\nFourth, by combining and building on different data sources, we were able to capture various intersecting layers in the lives of our participants, providing a better understanding of their needs for information regarding upcoming housing decisions or for the design of decision aids. Considering only GPS data as the primary and objective data provided information of participants’ routines in terms of places, distances, and means of transportation, but cross-referencing these data with the interview data enabled us to explore nuances not captured initially. For example, Participant 106 revealed during her interview that she was aware of the importance of walking and mobility; however, her building, exclusively for older adults, restricted mobility due to COVID. The information regarding restricted mobility in her building would have been an important consideration prior to moving there, and such questions should be included in decision aids. The combined data of Participant 111 also demonstrated that with GPS data alone, it would be difficult to understand her mobility patterns: in fact, many of her car trips involved taking friends with her to go to their walking group and walking her dog. These activities suggest a whole additional range of mobility-related social and physical assets of the older person in their current location that should be taken into account in any future design of decision aids about housing, as a move might affect these more subtle aspects of their quality of life. Otherwise, these precious assets, so easily taken for granted, may only be appreciated in retrospect. The best people to inform decision aid designers of these more subtle aspects of their lives are the older people themselves. Designers cannot create adequate decision aids for older adults without involving them iteratively throughout the design process [103]. One contributing factor may be the perception of older adults as passive users [104,105] in the design process of tools aimed at them. By altering their role and positioning this population as protagonists in the conceptualization phase [106], the development process should enable them to explain their needs and difficulties and express what they currently appreciate most about their lives [107]. This will ultimately empower them as co-creators of the tools that help them make their difficult housing decisions.\n\nLastly, using multiple data collection methods and building one on top of another [54] offered a unique perspective on older adults’ space and mobility patterns. Early mobility studies primarily focused on either GPS data or self-reported data, without integrating these approaches in the same analysis [53]. However, with progress in technology and new GPS processing methods, recent studies have begun to integrate both qualitative methods (such as travel diaries, walking interviews) and quantitative GPS data, demonstrating the applicability and coherence of adopting this method [70,108–111]. Although this convergent mixed-methods study [53] diverges from the strictest definition of a mixed-methods study, it gave added nuance to our findings. The social health, for example, cannot be measured solely through GPS. It requires contact and trust between the research team and participants, developed through two interview sessions that were able to reveal nuances not discernible through GPS alone. The small sample gave us the richness of information but limited generalizability. However, we did not seek the big picture, we explored the culture, geography and language of the two very different provinces to explore the heterogeneity of older adults’ mobility and social assets, suggesting that the future design of decision aids for housing decisions must be flexible to such differences.\n\nOur study has some limitations. Not all participants were able to use the GPS properly or fill out the daily journal, which limited the analysis. During the interview, some participants had negative impressions of wearing the GPS devices. Some found them uncomfortable, inconvenient, awkward (“It was amazing that my equipment did not land in the toilet”), and that the device attracted unwanted attention. One participant had privacy concerns (“it’s just too personal”), and another felt they were being tested by researchers comparing the daily journal with the GPS data. Future research assessing mobility patterns will benefit from less intrusive technology (e.g., smart watches) and improved methods for encouraging participants to complete data entries in the daily journal. In addition, the Covid-19 pandemic hampered data collection in Alberta. However, after the isolation period, we resumed our research and asked participants about their mobility patterns and experiences during the pandemic, shedding light on another perspective not initially planned in this study.\n\nSecond, our sample sizes were small, which limits the extent to which our findings can be generalized. However, our data merging followed a qualitatively driven approach, and sample sizes in qualitative research are typically smaller than in quantitative research [110,111]. Despite the smaller sample, our sampling strategy allowed us to work with “information-rich” participants [112]. Importantly, our goal was not to generalize but to explore a diverse range of experiences related to social health and mobility patterns from the direct experiences of older adults themselves.\n\nThis mixed-methods exploration of the activity spaces and mobility patterns of older adults in Quebec and Alberta revealed that despite a decline in autonomy, numerous existing social and physical assets associated with mobility make important contributions to their social health, such as access to several means of transportation and to public institutions, familiarity with their neighborhoods, and the proximity of friends and family.\n\nThis study underlines the importance of integrating mobility patterns and their associated social assets into housing decision frameworks. It provides guidance for the development of user-informed decision support tools, tailored specifically to Canadian older adults’ housing decisions, that consider older adults’ existing physical and social assets in common real-life situations. These actionable insights can inform the creation of tools that promote healthier aging and facilitate more person-centered housing decisions.\n\nhttps://doi.org/10.1371/journal.pone.0320876.s001\n\n(DOCX)\n\nWe thank Louisa Blair for her manuscript revision, Souleymane Gadio and Georgina Dofara for their support in the descriptive analysis. We appreciate the support of Greybox Solutions in providing us with an in-kind contribution.",
    "category": "earth_sciences"
  },
  {
    "title": "The challenges of climate change and human impacts faced by Mexican coasts: A comprehensive evaluation",
    "authors": "María Luisa Martínez, Rodolfo Silva, Valeria Chávez, Jorge López-Portillo, Karla Salgado, Etzaguery Marín-Coria, Octavio Pérez-Maqueo, Carmelo Maximiliano-Cordova, Rosario Landgrave, Víctor de la Cruz, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320087",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320087",
    "content": "The extensive shoreline of Mexico is heterogeneous and diverse, but it is increasingly exposed to degradation and loss. This is the first study performed at a national level and with a multidisciplinary approach, that aims to assess the impact of climate change and human-related pressures affecting Mexican coasts. From 1863 to 2022, 386 tropical cyclones have landed on Mexican coasts, six of them of category 5 (most on the Atlantic). Sea level rise projections showed that the Atlantic coast is the most vulnerable, whereas intense coastal erosion ( > 25m/year) is more widespread on the northern Pacific coast. Human impacts include coastal urbanization, ecosystem degradation and coastal armouring. Six million people live on Mexican coasts, mostly in the Caribbean. Mangroves and coastal dunes each cover nearly 800,000 ha. The mangroves are relatively well preserved, but almost half the area of the coastal dunes is degraded. Coastal armouring is widespread along the coasts, but most of these structures (55%) are found on the Yucatan peninsula. Activities required to improve the condition of Mexican coasts and make them a sustainable place to live would include: adaptation of human settlements to the conditions of the dynamic coasts; appropriate coastal protection measures that do not induce downdrift erosion; dealing with coastal risks by restoring and preserving coastal ecosystems.\n\nCitation:Martínez ML, Silva R, Chávez V, López-Portillo J, Salgado K, Marín-Coria E, et al.  (2025) The challenges of climate change and human impacts faced by Mexican coasts: A comprehensive evaluation. PLoS ONE 20(4):\n           e0320087.\n        \n        https://doi.org/10.1371/journal.pone.0320087\n\nEditor:Delei Li, Institute of Oceanology Chinese Academy of Sciences, CHINA\n\nReceived:September 6, 2024;Accepted:February 13, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Martínez et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and its Supporting Information files.\n\nFunding:This study was funded by CEMIE-Océano (Mexican Centre for Innovation in Ocean Energy), grant number FSE-2014-06-249795 financed by CONACYT-SENER-Sustentabilidad Energética; Secretaría de Protección Civil de Veracruz (Secretariat of Civil Protection of the State of Veracruz), grant number COVEICYDET/CD/2022/SE-03/03, and CONAHCYT grant number CF-2023-G-1497 . The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:No author has any conflict of interest regarding this study.\n\nRecent global analyses reveal large-scale degradation of many of the coastal ecosystems that are valuable for flood defense [1,2], while the economic value and population density in Low Elevation Coastal Zones (i.e., regions up to 10 meters above sea level) continue to increase [3], often putting further pressure on these systems. There is therefore a need to fundamentally rethink our coastal management strategies at local and national level. For muddy coasts, the use of mangroves and salt marshes for flood defense, has been extensively reviewed [4]. However, for sandy coasts, innovations, such as mega nourishments [5], or using seagrasses to prevent erosion [6], have been implemented in individual studies only; a broader perspective is lacking.\n\nIn this sense, the biophysical state of beach-dune ecosystems can be considered as an indicator of the health of the surrounding ecosystems as they function as an ecological membrane [7,8]. The diagnosis of mass and energy fluxes on the coasts is essential for their optimal management [9]. Monitoring is fundamental in this process [10]. The combination of local (e.g., coastal defences) and regional impacts (e.g., dam construction), along with uncertainties about rates of sea level rise and climate change accentuate the need for affordable future flood defenses [10,11]. For the development of appropriate legislation and the use of governance arrangements that facilitate adaptation to changing needs, particularly in developing countries, e.g., [12], inexpensive national data is needed.\n\nMexico is privileged to have coastlines fronting two oceans: the Pacific in the west and the Atlantic in the east, amounting to over 11,000 km, third in the Americas [13,14]. Along Mexico’s coasts there are a wide range of ecosystems: coral reefs, seagrass beds, mangroves, sandy beaches, and coastal dunes, all contributing to the high biodiversity found in Mexico. These ecosystems provide unique services, such as the filtration of large volumes of seawater [15], storm protection [4,16], recreation and scenic beauty [17,18], nutrient cycling [19], the filtration of pollutants [7], sand production [6,20], the support of coastal fisheries [21] and provision of critical habitats for many endangered species, including birds (such as flamingoes), turtles and some invertebrates (such as the horseshoe crab) [22].\n\nAs in many countries, a wide range of climate change- and human-related pressures affect the coasts of Mexico. Increasingly, these pressures cause extreme conditions that impact natural ecosystems, human settlements, and infrastructure. Hence, the recovery of the coasts and their ecosystems is increasingly complex, and the likelihood of reaching a point of no return becomes more probable as environmental degradation grows.\n\nThese naturally drive the dynamics of the coasts and their ecosystems. The energetic waves, storm surges, and strong winds shape and modify the coastal geomorphology. However, when they affect human lives and assets, these are seen as hazards and natural catastrophes. Mexico is one of the countries most impacted by tropical cyclones, which land on both shores [23] every year. Since 1902, they have caused 4,477 casualties and $ 27,178,977 (USD x 1,000) in economic damages [24]. Storm-related risks are relatively high in Mexico since over 10 million people live less than 10 km from the shoreline [25], with a high incidence of tropical storms. Recent climate-change related trends indicate that tropical cyclones are becoming more frequent and intense, thus increasingly affecting the coasts.\n\nSea level is a sensitive index of climate change and variability. A previous study on Mexico’s Atlantic coasts [26] showed that 30% of tourist destinations are exposed to flooding induced by climate change-related events such as sea level rise. Furthermore, 66% of the hotels on these coasts are on squeezed beaches, pointing to a potential socioeconomic problem looming for Mexico’s sun, sand, and sea tourist destinations.\n\nThe interaction between the sand, tides, waves, and wind means that erosion and accretion naturally occur on the coasts. These natural and episodic phenomena are generally associated with erosion, a natural coastal process. However, the sand returns to the coast during calm conditions. Consequently, the beach and dunes will recover if the sediment budget is unaffected by natural or human-related processes [27]. Nevertheless, the combination of sea level rise and increased storminess, with human-induced alterations of coastal sediment supply and transport processes, tend to increase shoreline erosion, with the coasts generally migrating inland [28]. Although erosion is a natural process on the coast, it becomes problematic for coastal settlements and infrastructure.\n\nCoastal populations and settlements [29] analyzed urban settlement patterns in the Low Elevation Coastal Zone (LECZ), the contiguous area along the coast less than 10 meters above sea level. These authors report that this zone covers 2 percent of the world’s land area but contains 10 percent of the world’s population and 13 percent of the world’s urban population. Mexico is no exception to this pattern. Despite the ecological importance of its coasts, inadequate management has promoted human encroachment along the shores. The accelerated expansion of sun, sand, sea tourism in the last 50 years has increased the coasts’ socioeconomic significance, mainly on sandy beaches [30]. The continuous and mostly disordered urban sprawl on some coastlines has resulted in habitat degradation or loss and terrestrial and oceanic pollution. Human encroachment is exposing the coasts to pressures at unprecedented scale and intensity [29,31].\n\nIdeally, the conflict between natural coastal dynamics and human assets would result in the retreat inland of human settlements and infrastructure to allow the dynamic natural functioning of coastal ecosystems, providing storm protection. However, for socioeconomic reasons, this retreat is generally impossible. Consequently, other actions are implemented, such as beach nourishment and coastal armoring (building infrastructure for coastal protection) [32]. These human modifications limit the flexibility and functionality that coastal ecosystems need to respond to the naturally extreme conditions of the coast [28]. In addition, the ecological consequences of inadequate engineering actions can exacerbate downdrift erosion and induce biodiversity loss.\n\nIn brief, we can say that Mexico’s coasts are facing pressures from different origins that expose them to increasingly extreme conditions. Detailed studies have yet to analyze these pressures at a national level to assess the status of the coasts, as well as the knowledge and gaps in mitigation and management practices across different coastal ecosystems. Given this background, the goals of this work were threefold. First, we aimed to analyze the environmental dynamics of the Mexican coasts, considering climate change-related impacts such as the occurrence and frequency of tropical cyclones, and the projections of sea level rise. Shoreline changes (erosion and accretion) were also addressed because they are associated with tropical cyclones and sea level rise. Our second aim was to evaluate the impact of human activities on the coasts. We thus assessed human encroachment (populations and settlements), the state of conservation of natural ecosystems, and the presence of coastal armoring used to protect the coasts from erosion and flooding. Our third goal was to identify advances and gaps in management and mitigation practices and propose better and more effective coastal management responses and strategies that avoid reaching conditions of no return. These extreme no-return conditions mean we can no longer recover the coasts’ structure and functionality, which would have unimaginable consequences for human settlements. Dealing with extreme conditions is particularly relevant, especially considering the millions of people living near or at the coast (and the many more who visit the coasts in their leisure time) worldwide and in Mexico.\n\nInformation from the National Center for Disaster Prevention (CENAPRED in Spanish) was used to track hurricanes in Mexico (http://www.atlasnacionalderiesgos.gob.mx/descargas/?dir=). The historical record of tropical storms and hurricanes that have hit Mexico spans from 1949 to 2012 in the Atlantic basin and from 1950 to 2012 in the Pacific. We focused on hurricanes categories 1-5 for both basins because these are the most damaging tropical cyclones. We analyzed the yearly frequency of tropical cyclones per state from the publicly available data of the NOAA (National Oceanic and Atmospheric Administration) from 1863 to 2022 (https://www.coast.noaa.gov/hurricanes/#map=4/32/-80).\n\nCalculations were made for Mexico from the estimates reported by the IPCC [33] (https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf), using the RCP 8.5 scenario as a reference, which predicts a rise of 1.01 m by 2100 [33,34]. We developed a simple coastal flooding model (“bathtub model”) with the Digital Elevation Model of Mexico from the National Institute of Geography and Statistics (INEGI in Spanish) (https://www.inegi.org.mx/app/geo2/elevacionesmex/). This simple model does not consider other processes affecting coastal flooding, such as flow velocity, the geodynamics of the coast, or tides (that are microtidal for most of Mexican coastlines). Nevertheless, it helps identify areas exposed to flood risk [35–37].\n\nShoreline changes [38] determined long-term shoreline changes (1984–2016) on sandy beaches worldwide, using satellite images at a resolution of 500 m. To determine the shoreline change rate (m/yr), they applied linear regression to the shoreline positions of each transect. We used this data set to identify three trends in shoreline change rates on Mexican coasts: accretion (>0.5 m/yr), erosion (<-0.5 m/yr), and stable (-0.5 to 0.5 m/yr). In our analysis, we considered only change rates with uncertainties of less than 3 m/year, based on the values reported in the dataset.\n\nWe used the georeferenced population censuses of 1990, 2000, 2010, and 2020 from the INEGI database (https://www.inegi.org.mx/programas/ccpv/2020/). We focused on coastal states and their coastal populations, defined as all populations located on the coast at ≤ 10 m above sea level. The population growth rate (PGR) between two points in time,t1andt0, was calculated for inland and coastal settlements using the following equation:\n\nwhereP1andP0are the number of inhabitants at timest1andt0, respectively, and the time interval (t1‐t0) represents 10 years. Thus, it represents the percent change in ten years.\n\nFrom the information available regarding the state of conservation of coastal ecosystems in Mexico, we focused on mangroves and coastal dunes, ecosystems found on the terrestrial side of the coasts. The distribution and state of conservation of coastal dunes was obtained from [39], and the information for mangroves was gathered from the National Commission for the Knowledge and Use of Biodiversity (CONABIO in Spanish), published in 2020 (http://www.conabio.gob.mx/informacion/gis/).\n\nWe used photo interpretation and Geographic Information System methods for mapping defense structures and ports and later for data processing (GIS) (QGIS for Windows 10, V 2009). We performed all the estimations and analyses with the available georeferenced aerial photographs for 1995 and 2019. The 1995 images were satellite orthophotos (294), and the 2019 images were obtained from Google Earth Pro (Landsat/Copernicus satellites). The satellite images were georeferenced using the WGS 84 reference and the EPSG:4326 ellipsoid. The images were computer-rectified to eliminate scale and distortion effects [40,41]. The inventory considered different types of coastal protection structures (S1 1). The impact on coastal dynamics of each type is different [32], so they were inventoried separately. Docks’ external and internal perimeters were mapped for ports, minus floating structures, such as piers.\n\nWe created a database with each type of structure’s geographic location. We used MatLab to organize the information and determine the number of structures per state for each year. Finally, we calculated the rate of change in the number of structures per state from 1995 to 2019.\n\nFrom 1863 to 2022, 386 tropical cyclones landed on Mexican coasts, 206 on the Pacific, and 180 on the Atlantic (Fig 1;Table 1). Most of the storms were tropical depressions and tropical storms, but hurricanes also occurred often (Table 1). Hurricanes of category 1 to 3 (gusts of wind ranging from 74 to 129 mph) were more frequent in the Pacific than in the Atlantic. However, intense hurricanes (categories 4 and 5 with winds ranging from 130-157 mph and higher) occurred more in the Atlantic than the Pacific (Fig 1,Table 1), especially hurricanes of Category 5 (Table 1). The state most frequently affected by hurricane Category 5 is primarily Quintana Roo, located on the Atlantic coast (Mexican Caribbean). In turn, tropical storms are widespread along many states, both along the Pacific (Baja California Sur, Oaxaca, and Sinaloa) and the Atlantic (Quintana Roo, Tamaulipas, and Veracruz) (Table 1).\n\nData from CENAPRED, Mexico.\n\nData from CENAPRED, Mexico.\n\nhttps://doi.org/10.1371/journal.pone.0320087.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320087.t001\n\nAccording to the 1.01 sea level increment predicted by the IPCC (2023), many Mexican coasts will be flooded by 2100. The Gulf of Mexico and the Caribbean are the coastlines most likely to be flooded by the sea, especially the southeastern Gulf of Mexico. This projection is of concern since many large settlements are here, notably Villahermosa, the capital of the state of Tabasco (Fig 2).\n\nData from IPCC (2023).\n\nData from IPCC (2023).\n\nhttps://doi.org/10.1371/journal.pone.0320087.g002\n\nUsing the results of [38],Fig 3shows the rates of shoreline change (a) accretion, (b) stable, and (c) erosion. The coasts of the southern Pacific are very stable, except around the Isthmus of Tehuantepec (between Oaxaca and Chiapas). The coasts of the northern Pacific have more dynamic trends, particularly in many regions of the states of Sinaloa and Nayarit, where more erosion was recorded compared with other states. Dynamic erosion patterns and accretion occur north of the Gulf of Mexico and the Yucatan Peninsula. At the same time, the coast of the central part of the Gulf of Mexico is more stable. Accreting coasts occur along the coasts of Nayarit, with some areas along other states such as Yucatán and Tamaulipas.\n\n(a) Erosion ( <-0.5 m/yr). (b) Stable (-0.5 to 0.5 m/yr). (c) Accretion (>0.5 m/yr).\n\n(a) Erosion ( <-0.5 m/yr). (b) Stable (-0.5 to 0.5 m/yr). (c) Accretion (>0.5 m/yr).\n\nhttps://doi.org/10.1371/journal.pone.0320087.g003\n\nIn Mexico, 6,399,268 people live in the low elevation coastal zones (LECZ) (defined as <  10 m above sea level and 20 km inland from the shoreline), which is 6% of the population living in 10.3% of the national surface area.Fig 4shows that some coastal states are more densely populated than others: Sinaloa on the Pacific and Quintana Roo on the Caribbean have the most densely populated coasts, followed by Veracruz on the Gulf of Mexico. Baja California, Baja California Sur, Colima, and Jalisco, all in the Pacific basin, have the lowest population densities. The proportion of inhabitants living in LECZ compared to the total population per state is very high in the Yucatan Peninsula (especially Quintana Roo), which has the most popular tourist resorts (Cancun and the Mayan Riviera). The population growth rate has fallen over recent decades but has remained highest in the LECZ (Fig 5).\n\n(a) Population found in LECZ (at ≤ 10 m above sea level). (b) Percent of population in LECZ (orange) compared to the total population of each state (green).\n\n(a) Population found in LECZ (at ≤ 10 m above sea level). (b) Percent of population in LECZ (orange) compared to the total population of each state (green).\n\nhttps://doi.org/10.1371/journal.pone.0320087.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320087.g005\n\nThe distribution of mangroves and coastal dunes is broad along Mexico’s coasts, covering almost 800,000 hectares each. The state of conservation of these two ecosystems is very different, mainly because mangroves are legally protected, while coastal dunes are not. The coastal dunes in the north of Mexico are in good condition overall, but not so those on the south of the Pacific, Gulf of Mexico, and the Caribbean (Fig 6a), which are in a bad or very bad condition by [39]. Mangroves, in contrast, seem to be in a better-preserved condition throughout Mexico, although some areas in southeastern Mexico and the South Pacific are disturbed (Fig 6b).\n\n(a) Coastal dunes. (b) Mangroves.\n\n(a) Coastal dunes. (b) Mangroves.\n\nhttps://doi.org/10.1371/journal.pone.0320087.g006\n\nThe distribution of coastal armoring along the Mexican coasts is uneven (S2). The Yucatán Peninsula has the most coastal protection infrastructure (55% of all the coastal infrastructures in Mexico), especially the states of Yucatán (35%) and Quintana Roo (14%), although Veracruz, on the Gulf of Mexico, also has many. On the Pacific, Sonora and Baja California Sur also have quite a high number of structures. The increase in the number of these is very high in Baja California, Sonora, Jalisco, Yucatán, Campeche, and Quintana Roo and very low elsewhere.\n\nThe types and abundance of coastal structures inventoried vary by state (Table 2). For instance, Veracruz and Sonora have the most jetties, whereas most groins are in Yucatán. Baja California Sur and Sinaloa have the largest number of seawalls, and Baja California and Sonora have the most ports. Breakwaters are common in Baja California Sur, Jalisco, and Quintana Roo.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320087.t002\n\nThis is the first study performed at a national level to analyze with a multidisciplinary approach the different pressures facing Mexican coasts and the conservation status of some of its coastal ecosystems. It helped us find advances and gaps in the current condition and management practices. Our findings show that the meteorological conditions on Mexican coasts are worsening: tropical cyclones occur more frequently and with greater intensity, and sea level rise projections suggest several vulnerable areas. Furthermore, shoreline erosion over recent decades is also a matter of concern in many places.\n\nIn addition to the above, as the coastal population grows, the impact of human activities associated with maritime commerce, increasing sun, sand, and sea tourism, and growing coastal armoring make the degradation of coastal ecosystems more challenging. Ecosystem degradation exacerbates societal vulnerability because of decreased storm protection. The increased exposure (more humans at the coast) and vulnerability (reduced protection from ecosystems owing to their loss and degradation, and human induced erosion) result in more significant risks for coastal populations in Mexico [42]. These factors show that the call for action for better management of the Mexican coasts is urgent.\n\nDecision-makers and society must recognize that combining socioeconomic needs with ecological processes is vital because coastal biodiversity and ecosystem services are irreplaceable. However, they are only sometimes recognized as necessary for society even though many human interests are affected by the degradation of the coastal ecosystems. To tackle the enormous range of threats facing human settlements on the coast and the natural ecosystems there, we need transdisciplinary research and radical management actions now and in the immediate future. The challenges vary geographically, as summarized in S3; thus, the actions required are site-specific.\n\nThe information in this study enables us to identify critical directions for future research and pinpoint actions required to improve the condition of Mexican coasts. Better coastal management should thus reduce the risk of flooding and erosion for human settlements and promote the conservation of coastal ecosystems. We have grouped these strategies into two sets of research directions and actions that would help humans live with nature and make the coasts more sustainable.\n\nAs coasts are naturally dynamic, coastal ecosystems are frequently exposed to various disturbance events, such as storms, waves, winds, tides and erosion. However, the ecosystems will regenerate, rebuild, and expand if the natural flow of water, sediments, nutrients, and propagules is free to occur [16]. Humans need to be aware of these dynamics and live with them instead of trying unsuccessfully to control and avoid them.\n\nThe environmental dynamics of the coastal states differ throughout Mexico. For instance, Baja California Sur and Quintana Roo are frequently affected by tropical cyclones. Regarding the projections of sea level rise, it is likely to affect the Gulf of Mexico and the Caribbean coasts. However, erosion is critical in Sinaloa, Nayarit, Yucatán, and Quintana Roo. These states require new paradigms of coastal management more urgently than others to progressively incorporate the natural dynamics of the coasts (biotic and abiotic aspects), ideally based on sound ecological science. Better capacities in diagnosis and predictions are necessary to understand the ecological consequences of human activities and disturbances on natural ecosystems and their dynamics.\n\nThe accelerated human encroachment on the coasts and increasing flooding and erosion risks associated with extreme hydrometeorological events means the coasts’ protection is becoming critical worldwide. However, there is no consensus on the meaning of “coastal protection” [43]. To some, it may mean building structures to halt coastal erosion and protect properties and human assets. However, to others, it may mean allowing coastal ecosystems to function naturally and conserving their dynamics while infrastructure and population are translated landwards [44].\n\nThe outcomes of each of these alternatives are contrasting. A hard-protected coastline will have modified sediment and hydrodynamic flows, and erosion problems may often move down drift [45]. In turn, if natural processes shape the coasts, these can respond to environmental fluctuations as long as their dynamic nature can occur. For these reasons, creating and restoring natural coastal ecosystems is considered a cost-effective means of protection, which is sustainable and ecologically sound [4]. Additional ecosystem services include scenic beauty, recreation, water quality, and habitat [46,47], a further advantage. Hence, maintaining balanced natural connectivity in mass and energy fluxes must be recognized as one of the main attributes of any coastal protection project [9].\n\nSociety can adopt many strategies for decreasing flooding and erosion risks [48]. These should aim at reducing the risks, increasing resilience (the ability of a system to continue operating and return to a pre-disturbance condition), and reducing the vulnerability of a system. In this sense [48], propose three categories of strategies for coastal protection: Protect, Accommodate, and Retreat.Protectionincludes coastal armoring, soft engineering solutions (such as beach nourishment), and ecosystem-based solutions (restoring and protecting coastal ecosystems).Accommodationstrategies refer to land regulation systems and preparedness programs. TheRetreatoption means the realignment of infrastructure to allow the natural dynamics of the coast to occur. Protection actions become most relevant for coastal settlements and infrastructure, whereas accommodation and retreating refer to land use and development policies. We will focus on the protection option as this is the most urgently needed, given the risks to which human settlements are already exposed.\n\nThe protection offered by green infrastructure can be an effective solution, at least in the less extreme but more frequent circumstances. [9] proposed that such protection varies according to the degree of naturalness of the solution: Nature Reclamation, Engineered Ecosystems, Ecologically Enhanced Engineering, and De-engineering/Relocation. Nature Reclamation (NR) is the ideal solution when habitat conservation and restoration are feasible. Where and when NR is not possible, Engineered Ecosystems, which are rehabilitated ecosystems, help recover critical services without reaching the level of complexity of natural systems. Ecologically Enhanced Engineering is functional where space and risk conditions necessitate traditional hard and/or soft engineering measures. These are modified to change physical processes, indirectly producing certain benefits from natural processes that are maintained or adapted to imitate natural ecosystems. De-engineering/Relocation: It is sometimes more convenient to relocate human interests to more convenient locations and conditions, restoring the system and moving towards a more natural functioning. These alternatives can be combined (hybrid solutions), depending on the specific conditions of the site to be protected and taking into consideration the space and time required to implement them, the related costs, and the allowable uncertainties in the response of the local economy and the coastal environment [9].\n\nFrom the data analyzed (1995 and 2019), it is evident that coastal armoring in Mexico has increased, most noticeably on the coasts of Yucatán, Quintana Roo, Veracruz, Sonora, Baja California Sur, and Campeche. However, questions arise on the necessity, quality, and consequences of such prolific coastal armoring; a diagnosis of the performance of this coastal armoring is needed, and if it is environmentally and socially adequate [32]. Future projects should explore new, softer coastal defense approaches as a more proactive means of protecting the coasts from erosion and flooding.\n\nWhatever type of coastal protection is selected, monitoring its effectiveness and environmental impacts is essential to avoid unwanted side effects, such as chronic downdrift erosion or biodiversity loss. We should not repeat past wrongful protection schemes. Instead, we need to rely on recent knowledge, and the best management and protection practices should be selected based on local conditions and scientific evidence [10].\n\nThe degradation and loss of natural ecosystems lead to biodiversity loss and reduced ecosystem functioning, resulting in a decrease in the potential of the ecosystems to buffer and protect the coast from the impact of meteorological disturbances. Additionally, the scenic beauty, fisheries, and water filtration may also be negatively affected, probably leading to socioeconomic costs [16,46,49]. Restoring coastal ecosystems would provide many ecosystem services and goods (storm protection, recreation, nurseries, and water quality) worth millions of dollars [50]. A further benefit of protecting dunes is their importance in the biodiversity of Mexico’s flora. For instance, Mexico’s coastal dunes cover approximately 800,000 ha, representing 0.04% of the nation’s total land surface [39]. Nevertheless, because of their topographic heterogeneity, variability in weather regimes, and diversity of vegetation types, they host 2072 plant species [51], the equivalent of 9.4% of the Mexican flora.\n\nThe latest advances in science and technology are vital to protect and restore Mexico’s coasts and their natural ecosystems from further degradation and loss. Critical issues in ecosystem protection policies include the creation of biological corridors to promote genetic exchange, the restoration of fragments and more extensive areas with natural ecosystems, controlling the arrival and expansion of invasive species, and protecting endangered or threatened species [48]. Current research shows that emphasis on protecting coastal dunes and mangroves in the southeastern states of Mexico is vital because degradation and losses are most severe.\n\nMany coastal cities are exposed to erosion and flooding by storm surges and sea level rise and are thus very vulnerable. Sustainable coastal cities need to thrive and function according to the natural dynamics of their environment, which are impossible to control. So, the society (inhabitants, visitors, and authorities) must be prepared for a dynamic and unpredictable environment [10].\n\nAs the risk of flooding and erosion in coastal cities increases, vulnerability assessment and adaptation options are urgently needed [52,53]. For example, we can avoid new constructions in areas prone to flooding or erosion. Alternatively [50], recommend replacing these low-lying areas with natural ecosystems (such as wetlands) that trap sediments to rebuild the land or insisting on new buildings standing on piles to survive moderate flooding. On the other hand, new tourist destinations should be planned better at the national level, considering how best to combine the preservation of natural coastal ecosystems with the region’s socioeconomic development while maintaining a low-risk condition. The construction of entirely new sustainable cities designed explicitly for tourism is a once-in-a-lifetime opportunity to have cities adapted to coastal dynamics and natural hazards and which, additionally, could have high-performance green buildings (using renewable energy, for example) and adequate transportation with zero or reduced CO2emissions [16]. Combining infrastructure with the buffering service natural ecosystems provide will help coastal cities become more sustainable and less vulnerable to natural hazards.\n\n[48] analyzed community perception and community adaptation to climate change in coastal areas of Mexico. They encountered difficulties in effective adaptation measures: institutional discrepancies regarding conservation and development, weak governance structures that impede having an informed society, and the overexploitation of natural resources. A successful coastal protection project should consider using local resources and the participation of local actors [9]. Better organization and planning are needed to achieve a sustainable coast. Additionally, communities in sustainable cities should be fair, respectful, and tolerant.\n\nFinally, the inhabitants and authorities of coastal cities should not be misled: a zero-risk coast does not exist and never will. Consequently, coastal cities should be prepared for the uncertainties derived from the dynamic and unpredictable setting [10].\n\nAn unfortunate and recent example occurred while we were writing this article. On October 24th, 2023, category 5 hurricane Otis landed directly on Acapulco’s significant touristic coastal city (on the Mexican Pacific), with 800,000 inhabitants and 50% tourist occupancy. Otis behaved unexpectedly: within a few hours, it developed from being a tropical storm to a hurricane category 5, possibly because of abnormally high temperatures on the surface of the Pacific Ocean. It is among the most damaging hurricanes ever affecting Mexico; the first hurricane category 5 that has ever landed on Acapulco in the last hundred years. Indeed, no natural ecosystem could have avoided the dreadful damages caused by 350 km/hr gusts of winds. However, perhaps, as Acapulco is rebuilt (hopefully very soon), we can think of better ways of reconstructing the destroyed buildings by improving construction norms and window frames (most of them destroyed) and restoring degraded ecosystems so that this iconic coastal city is even more beautiful than before Otis. Acapulco is an unfortunate example of why, now, more than ever, coastal cities must be prepared for the unexpected.\n\nProcesses such as the availability of sediment in the swash zone, wind, waves, tides, and storm surges can significantly influence shoreline changes. However, along the Mexican coasts, the escalating threats and pressures discussed here are primarily associated with more extreme environmental dynamics, such as tropical cyclones and sea level rise. These factors, combined with intensified human activities—such as encroachment, ecosystem loss and degradation, and coastal armoring—further exacerbate the situation. The consequences are diverse, including loss of biodiversity and ecosystem services, increased vulnerability, and risk. Indeed, the voracious growth of human activities, especially tourism on the coasts, is seriously affecting many coastal ecosystems, resulting in either degradation or loss. Such changes could have irreversible consequences for ecosystem functions, including those considered most necessary for society: scenic beauty, storm protection, water filtration, and providing habitats for fisheries.\n\nOne alternative to address the challenges in this study is the concept of “living with nature,” which means that humans must learn to live on naturally dynamic coasts while restoring and protecting natural coastal ecosystems effectively, which will help provide nature-based storm protection. Furthermore, we need to make the coasts a sustainable place to live, which means adapting cities to a dynamic environment, rebuilding the social capital, and learning to live with risk. The pressures and extreme conditions the Mexican coastlines face vary geographically; thus, the challenges and needs for action are site-specific.\n\nThe socio-economic conditions of Mexico are similar to those of other developing, megadiverse countries, where primary activities (e.g., agriculture and extractive industries) and services (e.g., trade and tourism) are fundamental to the economy. In such countries integrated monitoring programmes of the seas and coasts are generally very limited. We believe that this study could be adapted, extended and applied in other countries that need to establish their own coastal management programmes at a national level.\n\nWe are grateful to Jill Taylor for proofreading earlier versions of this article, which improved the clarity of some sections. We also appreciate the very thorough revision of the editor and the two reviewers (Giorgio Anfuso and Haidon Pan) which greatly improved the text.\n\nhttps://doi.org/10.1371/journal.pone.0320087.s001\n\n(CSV)",
    "category": "earth_sciences"
  },
  {
    "title": "The dependency structure of the financial multiplex network model: New evidence from the cross-correlation of idiosyncratic returns, volatility, and trading volume",
    "authors": "Dariusz Siudak, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0320799",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320799",
    "content": "This work describes the design of a novel financial multiplex network composed of three layers obtained by applying the MST-based cross-correlation network, using the data from 465 companies listed on the US market. The study employs a combined approach of complex multiplex networks, to examine the statistical properties of asset interdependence within the financial market. In addition, it performs an extensive analysis of both the similarities and the differences between this financial multiplex network, its individual layers, and the commonly studied stock return network. The results highlight the importance of the financial multiplex network, demonstrating that its network layers offer unique information within the multiplex dataset. Empirical analysis reveals dissimilarities between the financial multiplex network and the stock return monoplex network, indicating that the two networks provide distinct insights into the structure of the stock market. Furthermore, the financial multiplex network outperforms the singleplex network of stock returns because it has a structure that better determines the future Sharpe ratio. These findings add substantially to our understanding of the financial market system in which multiple types of relationship among financial assets play an important role.\n\nCitation:Siudak D (2025) The dependency structure of the financial multiplex network model: New evidence from the cross-correlation of idiosyncratic returns, volatility, and trading volume. PLoS ONE 20(4):\n           e0320799.\n        \n        https://doi.org/10.1371/journal.pone.0320799\n\nEditor:Srebrenka Letina, University of Glasgow, UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\n\nReceived:October 7, 2024;Accepted:February 25, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Dariusz Siudak. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The data can be found in the research data repository: Siudak, Dariusz (2024), “The multiplex stock market network”, Mendeley Data, V2, doi:10.17632/kc5chp4tzd.2;https://data.mendeley.com/datasets/kc5chp4tzd/2.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nComplex networks have emerged as a robust modeling methodology, particularly adept at capturing the multidimensionality and nonlinear dynamics inherent in financial systems. The intricate interconnections and interdependencies within financial markets necessitate analytical frameworks capable of representing such complexity. Recent studies have demonstrated the effectiveness of complex network approaches in modeling the multifaceted nature of financial markets, providing insights into systemic risk and market behavior [1]. Additionally, the nonlinear interactions prevalent in financial systems have been effectively analyzed using complex network methodologies, offering a deeper understanding of market dynamics [2,3]. The complex network approach is a powerful analytical framework that has been used to study and understand a wide range of complex systems [4,5]. Recent studies have focused on the statistical and topological characteristics of financial networks using a complex network approach [6]. This approach has been widely and effectively applied to the study of the interconnectedness on the stock market [7], and provides a convenient and suitable means to gain a deeper understanding of the structural and functional properties of complex financial systems [8–10].\n\nAll companies in a financial market are interconnected and form a linked network based on different quantities. The correlation between entities has a deep inner impact. Therefore, a well-known approach to building enterprise networks is to construct a cross-correlation network [11,12]. This approach involves measuring the cross-correlation between pairs of time series, which indicates the degree to which the two series are correlated. By constructing a network based on these cross-correlation values, researchers can identify patterns and relationships that may not be apparent from looking at the individual time series in isolation. Complex financial systems can be modeled using a multiplex network consisting of several network layers. This type of multilayered financial network has not been explored in depth. There are multiple types of relationships among financial assets. Therefore, it is crucial to analyze financial markets through the lens of multilayer networks rather than isolated monoplex networks, which identifies the research gap. This study provides the backbone for a novel approach, and assumes that the atomistic view of relationships in the financial market is no longer valid. For the purposes of this study, the multiplex network structure includes layers representing different time series-based asset relationships, namely, the firm-specific factor of the log-stock return, the volatility of the stock return, and the stock market turnover.\n\nIn recent years, there has been a growing interest in the use of multilayer networks to model complex financial systems [13–23]. A multilayer network is a type of network that consists of multiple layers, each representing a different aspect of the system under study. Multiplex networks are a subset of multilayer networks. A multiplex network is formed by a set of vertices interacting simultaneously in multiple network layers [24], in which nodes are connected by more than one type of edge and each type of link represents a separate network layer [25]. By modeling financial systems as multilayer networks, it becomes possible to capture the interdependencies and interactions between different components of the system in a more realistic and nuanced way. One of the key advantages of multilayer networks is their ability to capture the heterogeneity and complexity of financial systems, as it can be difficult to represent this using monoplex network models. Unlike traditional network models that represent the system as a single layer of nodes and edges, a multilayer network captures multiple interconnected layers, each representing a different aspect of the system. In other words, monoplex network theory is not sufficient to model and explain the complex multi-faceted relationships of the financial market.\n\nNetwork models play a crucial role in portfolio optimization by providing insights into the structure and dynamics of asset relationships within complex financial systems. Network models allow for a detailed mapping of how asset returns are interconnected and illustrate the dependency between network topology and its function, particularly in the context of financial networks. The structure of a network can significantly influence risk evaluation and asset performance in portfolio construction [26–29]. Financial network models significantly enhance portfolio optimization by providing a framework to analyze the complex interrelationships between assets [30], facilitating the identification of high-performing investments [31], and improving the robustness of portfolio strategies through dynamic analysis and noise reduction. Network peripherality serves as an important indicator for identifying optimal assets [32,33]. The recent studies reveal that peripheral nodes in a network can potentially yield better portfolio performance compared to central nodes [11,34–36], where the risk-return ratio plays a pivotal role. Stocks located in the network’s peripheral region exhibit a more diversified composition and demonstrate reduced vulnerability to irregular stock price fluctuations during market volatility [8]. This insight allows for the selection of assets that are more profitable, well-diversified, and less risky. On the other hand, the superiority of portfolios based on peripheral stocks or centrality vertices is contingent upon the prevailing conditions of the stock market over a specified time horizon [37,38]. This indicates that this area has not been well explored. Nonetheless, empirical results of the study [39] demonstrated that network-based approaches yield better out-of-sample performance compared to traditional pairwise correlation methods.\n\nThe aim of establishing the financial multiplex network was to integrate three essential elements of asset connections within the financial market into a unified network structure. The first layerconsiders the stock return, which has been purged of the systematic risk premium driven by common market factors. The second layeraddresses risk, while the third layerconsiders stock trading liquidity. The financial multiplex network elucidates the interconnectivity of financial assets by incorporating data pertaining to their idiosyncratic returns, risk profiles, and trading liquidity. Idiosyncratic return analysis plays a crucial role in understanding the unique characteristics and performance of individual assets, as demonstrated in the following studies [40–43]. El-Nader and Al-Halabi [42] observe a positive idiosyncratic premium return for the UK financial market. The advantage of analyzing idiosyncratic return networks over the stock return network lies in its ability to capture individual asset-specific characteristics and interactions. This granularity allows for a more nuanced understanding of the relationships between individual assets and their 0s to overall market behavior. Therefore, the idiosyncratic return network offers a superior representation compared to the conventional network, which relies on total stock return, as evidenced in the following studies [44–47]. The idiosyncratic return network offers a superior representation compared to conventional networks by providing a more refined and accurate depiction of the relationships between financial assets. This advantage arises from the idiosyncratic return network’s ability to isolate the unique risk and return characteristics of each asset, effectively filtering out the influence of systematic factors such as market-wide or sectoral trends. By focusing on residual returns, the idiosyncratic return network eliminates systematic bias, reducing noise and enhancing the detection of meaningful, asset-specific connections. This results in a clearer and more precise understanding of the intrinsic dependencies between assets. Conventional networks, which incorporate both systematic and idiosyncratic risks, often overestimate correlations driven by external factors, thereby obscuring genuine interdependencies. By concentrating on asset-specific characteristics and avoiding distortions introduced by common systematic factors, the idiosyncratic return network enhances the practical applicability of network-based insights in financial decision-making. Therefore, the idiosyncratic return network represents a significant advancement in the study and application of financial network analysis, offering deeper insights into asset interdependencies. In addition, a network based on total return, compared to the idiosyncratic return network, replicates to a greater extent the information received from the volatility network. The exclusion of systematic risk for the first layer of the multiplex network is intended to diversify the three-layer network, in order to avoid the redundancy of information carried by the second layer (volatility network).\n\nBy integrating these multiple layers, the multiplex network enables a more comprehensive understanding of the structure of the system and can reveal hidden patterns and interdependencies that may not be apparent in single-layer models. In this context, multiplex networks offer a promising avenue for advancing our understanding of the complex interplay between financial entities, and the underlying factors that shape financial systems.\n\nThe paper proposes a novel financial network that is compiled using the concept of a multiplex network, meaning a network that incorporates multiple datasets of connections between assets. Three layers of the stock network are combined into one linked multiplex structure. Various types of interactions among the same set of stocks are described by the three layers of the financial market system, and this fills the research gap. In this study, the topological properties of the financial multiplex network (FMN), its three layers, and, in addition, the commonly studied cross-correlation of the stock return network (SRN) are investigated. This work also conducts a comprehensive analysis of the similarities and differences between the multiplex network and its separate layers and the stock return network.Fig 1illustrates the overall framework of the study. Specifically, the following research questions are examined:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.g001\n\nAll three layers of the multiplex dataset are constructed from cross-correlation matrices. By computing the correlation coefficient for all pairs of assets, one can obtain a fully connected network in which all the edges between each pair of stocks are presented. Such fully connected networks inherently contain a significant amount of noise. Therefore, it is essential to filter out the relevant information contained in the complex structure of the cross-correlation matrix among the stocks on the financial market. In this study, I use the minimal spanning tree (MST) approach to identify the most important connections within each network layer and to reduce the complexity. The MST approach is used because of its computational simplicity, robustness, and intuitive visualization. Furthermore, the MST approach offers an automatic procedure with no parameters to select, thus ensuring comparability between networks. It involves constructing a tree that spans all nodes in the network while minimizing the total length of the edges that connect them [33,48], sectors [49,50], markets, or indices [51,52], and in detecting changes in market structure and dynamics over time [38].\n\nTo the best of my knowledge, this is the first study on the creation of the multiplex network that combines three different types of relationship between the assets on the financial market, analyzes its statistical properties, and provides a multi-faceted comparison with the three layers and with a separate network of the cross-correlation of the log-return of the stock. The identification and quantification of interactions between network layers can be carried out employing such tools as link-overlapping indicators, similarity measures, and link correlations [17,53]. The results of this study, based on data from the US stock market, reveal the relevant dissimilarity between the multiplex network and the other networks in terms of their topological properties. Specifically, differences in network structure, connectivity, community structure, and disassortative behavior are observed. Furthermore, compared to the other networks (the layers and the SRN), only the multiplex network has the small-world network property. However, all the networks, namely the multiplex network, its three layers, and the stock return network, have in common that they obey the power-law vertex degree distribution. The results reported in this work provide evidence for the significance of the FMN in the sense that different network layers contribute distinct information to the multiplex dataset. In addition, the empirical analyses show that the FMN is different from the SRN, which means that the two networks take into account different information regarding the structure of the stock market. Moreover, it has been demonstrated that the FMN exhibits greater robustness to random node failures than the SRN, as the critical threshold for randomly removed vertices is considerably higher in the FMN.\n\nAn analysis of the effect of selected centrality measures of the two compared networks (FMN and SRN) on the out-of-sample Sharpe ratio was carried out. The findings revealed that a complex multiplex network structure achieves a higher dependency structure for the future stock performance under the risk–return relationship in the financial market than the monoplex network structure.\n\nThe main contribution of this research is twofold. First, in the area of complex networks, it involves the conceptualization of a novel financial network model, which provides a new perspective for the comprehensive analysis of stock price movements within the financial market. The multiplex dataset (FMN) encompasses a broader information spectrum compared to the singleplex network (SRN) and exhibits a noticeable structure that diverges significantly from the simple cross-correlation of stock return network. The significance of the network approach stems from its potential for broad application in the research process involving complex networks. The dimension of multiplex networks forms an integral part of a diverse spectrum of financial market research, thereby expanding the scope of financial market analysis.\n\nSecondly, in the area of financial studies, the financial multiplex network represents the financial market structure in a risk-return relationship with liquidity conditions. It provides a comprehensive view of the financial market by integrating various aspects of interconnections among stocks. The financial multiplex network has richer topological properties than the commonly investigated stock return network. Therefore, the application of the multiplex network approach allows for a more nuanced understanding of the intricacies and complexities of the financial market.\n\nComprehending the intricate interconnections among assets is of paramount importance for market participants, especially investors. The proposed methodological framework outlines insightful information for decision-makers and investors to improve their portfolio and risk management strategies. The findings of this study are expected to contribute to an understanding of the interconnectivity among stocks, thereby enabling the development of optimal portfolio selection to maximize stock performance under the return-risk ratio, based on the topology and centrality measures of the financial multiplex network. The optimal return-risk trade-offs can be improved through the implementation of an adequate diversification strategy, which can be further optimized through the analysis of the dependency structure of the financial multiplex network.\n\nThis paper has been divided into the following parts. Section2provides a brief review of the literature. Section3describes the data and methodology used in the empirical part, and Section4shows the results. The last section discusses the results obtained and provides concluding remarks.\n\nThe stock market can naturally be represented as a multiplex network due to the complex and multi-layered interactions among various financial instruments, institutions, and agents. The natural multiplexity of financial markets arises from the coexistence of diverse and interrelated layers of interaction. This framework allows for the integration of heterogeneous and simultaneously relationships between market participants, capturing their complex interdependencies and the multidimensionality of financial interactions. In the context of financial markets, each layer of the multiplex network can include different types of dependencies [54], highlighting the multifaceted nature of interactions among entities [55]. The interbank market is another example of a naturally multiplexed network representation [13], or, in a broader context, a model of a multilayer financial network that considers different types of interactions among banks, capital markets, and other market participants [56]. Multiplex networks consist of layers that coexist, interact, and evolve within a broader complex system, each characterized by distinct structures and functions [57]. Another study [58] analyzes financial networks as multilayer structures, examining various types of dependencies among financial institutions. The work [23] proposes a framework for a multiplex network, which is based on stock dependencies, sector-specific and location-specific layers.\n\nResearch into the financial markets has mainly focused on the configuration of an isolated monoplex network. However, there are studies that take into account the multilayered structure of a multi-relational financial system. The multilayer network approach is a widely used methodology in financial studies, wherein the constituent layers encompass trade, foreign direct investment, and financial market indices [59]; information spillovers, including return spillover, volatility spillover, and extreme risk spillover [60]; Spearman’s correlation coefficient, gray relational analysis, and the maximum information coefficient [61]; Pearson, Kendall, tail, and partial correlations [54]; as well as ownership, interlocking directorates, R&D partnerships, and cross-correlation of stock returns [62]. The multilayer network approach has also been applied in the construction of a risk contagion model for financial institutions [18,63–65]. Furthermore, Zhao et al. [66], using the temporal network framework as a special case of a multilayered network, and Lacasa et al. [67] proposed a horizontal visibility graph algorithm to convert a multidimensional time series into the multilayer network.\n\nIn real complex systems, there is interdependency between multiple networks [68]. Stock return, volatility, and trading volume are three of the most important features in the context of financial market analysis. In the financial system, the rate of return is derived from the systematic risk premium, which is driven by common factors, and the individual firm-risk premium, which is caused by company-specific factors. A recent analysis by Li et al. [40] reveals that the idiosyncratic return pattern closely resembles the total return pattern during the pre-crisis period, whereas the systematic return trend aligns more closely with the total return patterns during the crash period. The Fama–French model has been used to show, in [41] that the idiosyncratic volatility plays a significant role in explaining the cross-section expected stock returns. Eom and Park [44] investigate the effects of market factors on correlation networks and portfolio diversification. They have found that the MST stock network, based on residuals without a common factor property, plays a key role in building a more diversified portfolio, achieving better performance under the risk–return relationship than the MST network with market factor characteristics. Borghesi et al. [46] point out that applying the firm-specific factor of the stock return network by removing the market mode in clustering leads to less noise, makes the cluster structure more evident, and achieves robustness. Musmeci et al. [47] compare the clustering method for the log-return of the stock price with the market mode and the log-return of the idiosyncratic return. A network based on the idiosyncratic log-returns increases the degree of economic information that the clustering methods retrieve, and means that the clustering is more homogeneous in terms of the number of stocks in the modules. Finally, Todorova [45] investigates the idiosyncratic return through a network approach and finds a positive relationship between network centrality and stock returns.\n\nOne of the underlying factors that holds significance in the modeling of financial markets is volatility, which is perceived as a proxy of the riskiness of financial assets. The network of the stock return volatility is one of the most commonly investigated [69,70]. A pioneering study in this domain [71] reveals that the volatility network exhibits more fluctuating degree values than the stock return network. The results of other studies demonstrate a positive correlation between volatility and the largest eigenvalue, and a negative correlation with the number of communities [72], that higher market volatility corresponds to the denser MST-based network [73], that the connectivity of the network is more fragile to selective removal than to random attacks [74], and, finally, that as stocks become increasingly interconnected, their volatility tends to retain a memory of their past behavior [75].\n\nA non-linear causal relationship between the trading volume and the stock return is observed in the financial markets [76–80]. Moreover, Podobnik et al. [81] find evidence for power-law cross-correlations between the absolute values of the log-return of stock price and the logarithmic change in trading volume, concluding that the current price return depends not only on previous returns but also on previous volume change, and vice versa. In the network approach, stock returns and turnover volume have been incorporated into a singleplex network design, using the MST-based multidimensional symbolic method [82]. The trading volume network is the subject of the following studies [83–86].\n\nThe data set consists of 465 stocks that were continuously traded on the NYSE or NASDAQ for the period from April 8, 2013 to March 10, 2023. The entire data set was divided into two data sets covering the period starting April 8, 2013 and ending March 8, 2018, with 1240 trading days, for data set 1, and from March 9, 2018 to March 10, 2023, with 1260 trading days (approximately 5 years), for data set 2. The 465 companies remaining in the dataset were included in the S&P500 index on the last day of the time span, and each stock has 2500 data points. The data set for a single observation of each stock contains: i) daily closing price adjusted for splits and dividends; ii) maximum price on the trading day; iii) minimum price on the trading day; and iv) daily trading volume. In addition, data were collected on: a) daily S&P500 index adjusted close prices; and b) interest rates on the 13-week Treasury Bill. All the networks 1) idiosyncratic return; 2) volatility; 3) trading volume; 4) multiplex stock market network, and 5) cross-correlation of stock return were constructed using data set 2. However, the idiosyncratic return network construction methodology requires stock prices, S&P500 indexes, and the 13-week Treasury Bill returns data to be obtained for an additional period encompassing data set 1. These historical data were collected from Yahoo Finance (https://finance.yahoo.com; accessed on 11.03.2023). The five networks mentioned above are binary and undirected. All statistical analyses were performed using the following programs: [87–89]. Additional analyzed data are provided in theS1 Filesupplementary Information files.\n\nLetbe an undirected and unweighted network consisting of a set of vertices (stocks), where, and a set of edges (relations) between the nodes. The adjacency matrixof a monoplex network is theN-dimensional, unweighted, and symmetric matrix with elements\n\nThe adoption of a binary representation of financial networks is justified by several advantages over weighted networks that retain the distance metric on the edges. First, unweighted networks derived from the distance matrix simplify the complexity of the network’s structure by reducing the granularity of edge weights. This approach focuses solely on the presence or absence of relationships between assets rather than their precise strength or magnitude. Furthermore, unweighted networks are inherently robust to minor fluctuations and noise in the underlying distance metrics. In financial datasets, the inherent noise and vulnerability to minor fluctuations in correlations can lead to potential overinterpretation of trivial variations in edge weights. By employing binarization, this risk is significantly reduced, thereby enhancing the reliability of the resulting network which effectively delineates only the most critical structural characteristics of the system, thus laying a more dependable foundation for subsequent analysis. Finally, unweighted networks present a uniform framework for comparative analyses across various layers of multiplex network. Weighted networks, by their very nature, complicate such comparisons because of the discrepancies in edge weights that do not have a direct comparability in different contexts. In other words, the added dimension of weighted networks brings with it more complexity, which may hide the basic topology and not allow direct comparison.\n\nDenote bythe adjusted closing price of stockat time. The daily logarithmic returns of the stock pricescan be calculated as\n\nThe cross-correlation function based on the two log-return time series for each pair of stocksiandjcan be computed using the Pearson correlation coefficient\n\nwhere the notation  …  means the average value over a time period. The correlation coefficientsestablish a symmetricmatrixCwithelements and unity on the diagonal. The similarity measure between each pair of stocks requires the three axioms of Euclidean distance to be satisfied: i) positive definiteness; ii) symmetry; and iii) triangular inequality [90]. The correlation coefficients are converted into distance metrics using an appropriate transformation function\n\nwheredenotes the distance metric between companiesiandj, and ranges from 0, which corresponds to a strong positive correlation coefficientto 2, which corresponds to a strong negative correlation coefficient.\n\nTo filter out the huge amount of information from a fully-connected distance matrixof dimension, the MST method is applied. The MST is the spanning tree of the shortest length, effectively reducing the information space fromedges tomost important links, while connecting a set ofNvertices without cycles or self-loops. The MST extraction problem is solved using Kruskal’s algorithm [91], which spans nodes using a subset of edges with a minimal sum of weights and forms an acyclic graph. The final binary network is obtained through its dichotomization. This network is referred to as the stock return network (SRN).\n\nThe following section presents the construction of three monoplex financial networks using three types of relations among assets.\n\nIdiosyncratic return network.The premium of the firm-specific risk is utilized as a proxy for the idiosyncratic return of the company. To compute the idiosyncratic risk premium, the CAPM model is applied to filter out the common factor of the capital market\n\nwhererepresent the return of stockiat timet, the market return at timet, and the risk-free rate at timet;refers to the premium of the systematic risk in the capital market;denote the estimated regression coefficient of firmi(the intercept of the security market line) and the exogenous risk of stocki, respectively; andcorresponds to the residual which represent the idiosyncratic component of the stock return dependent on firm-specific factors. The above are made for the combined time span of data sets 1 and 2. To separate the firm-specific return from the common factor property, the observed returns are regressed using the ordinary least squares (OLS) method. This approach has been applied in the work of numerous researchers in the field: [40,44,45,47,92,93].\n\nFollowing [92], the daily log return of the S&P500 index is adopted as\n\nwhereis the daily adjusted closing price of the S&P500 index at timet,and the risk-free rate is computed based on the interest rate on the 13-week Treasury Bill expressed in terms of one day\n\nwheredenotes the annual interest rate of the 13-week Treasury Bill.\n\nThe residualswithout the common factor property are utilized to construct the idiosyncratic return network for data set 2. The logarithmic returns of the residuals are calculated (Eq. (2)) and the rest of the MST-based procedure is followed as for the construction of the cross-correlation of stock return network (Eqs. (3), (4)).\n\nTo produce the volatility network, the approach adopted in [69,74] is used, in which, for the daily stock price data, the volatilityfor each stockiand trading daytis calculated by utilizing the proxy\n\nwhereandare the highest and lowest price of the trading day.\n\nThe selection of the above volatility measure employed in constructing the volatility network is grounded in its ability to accurately capture intraday price movements while remaining computationally efficient. Moreover, the methodology employed is supported by a number of considerations. Firstly, it directly measures the magnitude of price movements within a single trading day, thereby providing a robust proxy for realized volatility. Compared to methodologies based solely on returns or closing prices, this approach incorporates data from the entire trading day, enhancing its sensitivity to transient price dynamics. Secondly, the normalization by the sum of the highest and lowest prices ensures the scale independence of the measure, making it suitable for comparing stocks with varying price levels. This property is critical for constructing volatility networks, where relationships between stocks are assessed based on relative rather than absolute volatility levels. Finally, the simplicity of the formula makes it computationally efficient and more robust against the noise often present in high-frequency trading data. By using only the highest and lowest prices, the approach avoids potential biases introduced by closing prices, which may not fully exhibit intraday variability due to market microstructure effects or end-of-day trading behaviors.\n\nThen the correlation of the volatilityand the distance, applying Eqs. (3)-(4), are computed. Next, the Kruskal algorithm is used to build the MST-based volatility network. In the final step, the network is dichotomized.\n\nThis type of financial network is based on the cross-correlation of trading volumes between a pair of two stocks. Denote bythe stock trading volume of companyon trading day. The construction of this MST-based network is exactly the same as the construction of the stock return correlation network, where the correlation coefficients (Eq. (3)) are computed for the time series of the logarithmic expression of the trading volume.\n\nThe multiplex system of the financial network consists ofNvertices andLbinary layers. In our case there are three layers: 1) the idiosyncratic return network; 2) the volatility network, and 3) the trading volume network. The multiplex network can be expressed by the vector of the adjacency matrices of theLlayers [94]\n\nwhereif nodesiandjare connected by an edge on layerlandotherwise.\n\nIn most interconnected complex systems, interactions occur not only among nodes in the same layer, but also between pairs of layers [95]. However, the multiplex network in the financial market consisting of the three network layers that is designed as described in Section 3.2.2, there are no edges between the layers. In a system that displays overlapping edges, the total number of links across all layers is meaningful [25]. Therefore, the multiplex financial network is created by joining the three single network layers. In other words, the multiplex network is obtained from the multilayer structure by combining all links that occur in at least one single layer. Note that possible multiple edges are omitted. The adjacency matrix of the multiplex financial networkis defined as\n\nFig 2depicts a time-series representation of the residuals () derived from Eq. (5), which represent the firm-specific idiosyncratic component of stock returns.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.g002\n\nThe MST-based graphs of the systematic risk network, volatility network, trading volume network, and multiplex network are shown inFig 3, and that of the stock return network inFig 4. Heat maps of the network connections are presented inS1 FileAppendix A (Supplementary files). All three layers and the MST-based stock return network demonstrate a typical tree-like structure with a few hub-nodes, while the multiplex network is a graph with a much higher density of connections. A wider assessment of the created networks is carried out on the basis of the global network indicators presented inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.g004\n\nAll networks have the same number of nodes. Since all three layers and the stock return network are MST-based networks, they all consist of the same number of edges, degree (928), and mean degree (1.996). In contrast, the multiplex network with the same number of vertices has more than twice the number of edges and has higher average degrees that exceed 4.5. There is a significantly higher number of maximum degreescompared to the other networks and a much smaller fraction of pendant nodes (0.03), the so-called leaf fraction, which means the fraction of vertices with no more than one link. For the remaining networks, the leaf fraction is approximately equal to half the number of nodes. This means that the multiplex network does not have any of the typical tree, chain, or star-like network structures, and the most connected vertices in the multiplex network has more connections than the hubs of other networks.\n\nThe stock return network and all three layers of the multiplex network are sparse graphs with a density of 0.004. This indicates that the probability of an edge between two randomly selected vertices is 0.4%. By contrast, the multiplex network is more dense and the probability is 1%.\n\nThe tree-like structure of the stock return network and the three layers is confirmed by the high value of the mean geodesic distance, which exceeds the value of 10. This means that between two selected nodes in these networks there are, on average, 9 intermediate nodes for the trading volume network and approximately 18–19 for the idiosyncratic risk network. The average shortest path length for the multiplex network is only 4.2 (approximately 3 intermediate nodes between two stocks), which indicates that the multiplex network is more compact than the other graphs. The compactness of the multiplex network is confirmed by the low values of the network diameter (9) and graph radius (6) compared to the other networks, for which the values range from 25 to 46 and from 13 to 23, respectively. It is worth noting that the diameter of the multiplex network (9) is lower than the minimal value of the graph radius of the remaining networks (13). This indicates that the FMN presents short cuts.\n\nSince all the networks except the multiplex one are MST-based networks, which are graphs without loops, the global clustering coefficient and transitivity are equal to 0 (there are no triangles). By contrast, we observe positive values of the above indicators for the FMN. The likelihood of two adjacent neighbors of a vertex being clustered together is 15.2%. It should be emphasized that, based on the density, mean geodesic distance, network diameter and clustering coefficient, the properties of a small-world network may be exhibited by the multiplex network. The verification of this issue is the subject of Section 4.2.\n\nThe net tree length (NTL) is used to assess the length of the MST-based networks. For this reason, the multiplex network is not considered, because it does not meet the minimum spanning tree criteria, due toand the graph containing loops. We observe that the NTL is substantively shorter for the SRN and for one layer – the volatility network. As the NTL increases, the MST network structure becomes less tightly held. Comparing the shrunken trees of stock returns and volatility with those of idiosyncratic return and trading volume suggests that stock prices and volatility tend to move in the same direction more strongly than the firm-specific factor of the stock return and the turnover of assets. The SRN shows a higher level of correlation than the idiosyncratic return network layer because the construction of this layer is based on the common factor-free stock return.\n\nThe FMN has a significantly lower value for the mean occupation layer (MOL) compared to all three layers of the multiplex network and the SRN. This suggests that the FMN is more densely connected than the other networks, with each vertex located only approximately two nodes away from the center. A lower MOL value for the multiplex network indicates that the transmission of all information provided by each of the three layers from the central vertex to the other stocks requires fewer intermediate nodes than is required for the other networks. This is a consequence of the higher density of the multiplex network, in which local connectivity of the network as connected triples of nodes is allowed. Nonetheless, MOL values ranging from 7.9 to 13.9 for the SRN and all three layers confirm that these MST-based networks exhibit a tree-like structure.\n\nBased on the network degree centrality index (NCDI), it can be concluded that the FMN network is the most centralizedof all the networks considered, and that the idiosyncratic return network is the least centralized. In other words, the most connected nodes in the FMN network have a higher degree than in the other networks. This confirms the finding that the FMN network has a significantly higher maximum degreethan the other networks.\n\nThe compactness of the FMN is confirmed by the network closeness centrality index (NCCI), which is approximately 2–4 times larger than the NCCI of the remaining networks. This implies that there are several vertices in the FMN that are very close to other nodes, the so-called short cuts. On the other hand, the FMN shows a much lower level of betweenness than the other networks. The network betweenness centralization index (NCBI) is 18.5%, while it ranges from 62.5% to 70.3% for the other networks. The observed higher centralization of the SRN and all three layers of the multiplex network in terms of betweenness is due to their tree-like structures, where several vertices act as central intermediate nodes. In contrast, the FMN network exhibits a much more evenly distributed betweenness centrality. It should be stressed that the NCCI is larger than the NCBI only for the multiplex network, which clearly indicates a different shape and structure of this network.\n\nModularity (Q) values for all four networks – SRN, idiosyncratic return, volatility, and trading volume – range from 0.901 to 0.904, indicating that the networks have a strong community structure. The modularity result obtained is significantly high. However, the multiplex network has a lower modularity value of 0.555, but still shows significant community partitioning. There is also a difference in the number of communities. The Louvain Fast Unfolding algorithm [96] identifies fewer communities (14) for the multiplex network than for the other networks (from 19 to 20) for the same number of nodes (). This is the result of the clustering tendency observed in the multilayer network but not in the other networks.\n\nTo assess whether the analyzed networks are scale-free, 930,000 iterations (2,000 iterations per vertex) a powerful statistical approach developed in [97] are performed. The power-law exponents of all the networks range from 2.534 (volatility layer) to 4.921 (idiosyncratic return layer) and the correspondingp-values are larger than 0.1, indicating that both networks, the SRN and the FMN, and each layer of the multiplex network obey a power-law vertex degree distribution. This implies that these networks have a scale-free structure, which means that they are composed of self-similar structures at different scales. The power-law degree distribution indicates that the network is highly heterogeneous, meaning that there are a few highly connected hub-nodes that play a crucial role in the overall connectivity of the network, and many vertices with low degree. This observed nature, which is typical of a scale-free network, distinguishes the analyzed financial networks from random networks in the sense of E–R random graphs, whose degree distribution follows the Poisson distribution.S1 FileAppendix B (Supplementary files) provides more information on the analysis of the power-law degree distributions, such as the KS test statistics, and the lower bound (), and a graphical presentation of the degree distributions using the complementary cumulative distribution function (CDF). It should be noted that a power-law degree distribution is also observed for the overlapping degree of the multiplex network\n\nwhere the exponentis 2.972 (p-value = 0.144).\n\nSince the constructed financial multiplex network is a fully multiplexed system in which every node is presented in each of the three layers, a suitable measure of the distribution of the degree of the vertexiamong the separate layers is the multiplex participation coefficient (MPC) [54,94]\n\nThe MPC measures the distribution of the edges connected to nodeiacross multiple layers.takes values in the range, where 1 indicates that nodeihas the same number of edges on each of theLlayers, and 0 means that vertexihas connections in only one layer. The average multiplex participation coefficient (MPC) is equal toP=0.933, indicating that the participation of most vertices by degree is uniformly distributed among the three layers of the multiplex network. The MPC distribution is depicted inFig 5.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.g005\n\nTable 2reports the degree–degree correlation analysis with the Quadratic Assignment Procedure (QAP) results. The results show substantial negative assortativity coefficients for all networks. This means that the indicated networks display disassortative behavior, where stocks tend to be adjacent to assets with dissimilar degrees. This can be interpreted as a tendency towards heterogeneity in the connections between vertices. Although the multiplex network has a negative assortativity coefficient, it is closest to 0 with a value of -0.072, indicating that there is a poor tendency to connect vertices with other nodes of dissimilar degrees.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t002\n\nIt should be emphasized that the QAP analysis [98], performed with 930,000 iterations, demonstrates a high probability (equal to or close to 1) that the observed assortativity coefficient values are significantly different from the expected value close to 0, which characterizes a non-randomly created network.\n\nA preliminary analysis of the networks confirms the presence of sectoral assortativity (seeTable 3). A positive assortativity coefficient indicates that networks exhibit assortative behavior, characterized by a tendency to form connections between assets belonging to the same sector. This property is most prominent in the idiosyncratic return layer. Previous research has demonstrated that stocks in correlation-based networks consistently form clusters closely aligned with economic sector classifications [6,28,46,72,90,92,99–103]. Likewise, the results are statistically significant when employing the QAP approach.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t003\n\nThe small-world characteristics of a corporate network [104] are widely acknowledged as a stylized fact [105] and refers to the idea that any two nodes in a large complex network can be linked to each other through a relatively short chain of intermediaries. The multiplex network is the only one considered here because the other networks do not exhibit the property of cliquishness. In other words, the global clustering coefficient and transitivity are only greater than zero for the multiplex network (seeTable 2), which means that the other networks do not show the small-world phenomenon. The indicators utilized to evaluate the small-world character of the network are presented inTable 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t004\n\nThe multiplex network is numerically large and sparsely connected, since, whereand. We compare the values ofandwith the asymptotic approximation of the clustering coefficient and the mean shortest path length for the equivalent E–R random network with the same number of nodes and edges. Since the relationsandare satisfied, indicating that the multiplex network exhibits the small-world property. Additional evidence of the small-world phenomenon leads to a similar conclusion. Sinceandare observed, the ratio oftoλis much larger than one ().S1 FileFig. C1 presented in Appendix C (Supplementary files) depicts the relationship betweenandλ.\n\nThe small-world property of the multiplex network means that there are short cuts that reduce the distance between nodes that are not directly connected. These long-range connections allow for closer relationships between stocks and shorter paths between vertices that are otherwise separated by many intermediate nodes. Short cuts play a crucial role in creating a more compact and interconnected network. The presence of short cuts in a multiplex network results from the compactness created by several nodes that have a high degree of connectivity and act as hubs within the graph. Although the existence of hub-nodes has been detected for all the networks (the power-law property), only the FMN is a scale-free and small-world network.\n\nSimilarity refers to the degree of association between two or more networks, which is measure of how the networks are related. The similarity coefficient can be used to evaluate the similarity between two different networks by comparing the sets of edges that they have in common. The Pearson correlation coefficient, the Jaccard index and the Czekanowski–Sørensen–Dice similarity coefficient, are utilized.\n\nTable 5reports the correlation coefficients between the individual networks. The correlation between each layer and the multiplex network is moderate, which suggests that the different layers contribute distinct information towards the final form of the multiplex network. In comparison, the correlation between the FMN and the SRN is lower, at 0.514. This is due to the varied relationship between the different layers of the multiplex network and the stock return network, where the layer of the network based on the firm-specific factor of the stock return is the most similar to the SRN, while the layer of the graph based on the trading volume is the least similar. Moreover, the similarity between the three layers is moderate (ρis approximately 0.4) or weak (below 0.3). It should be pointed out that, based on the QAP analysis, all the correlation coefficients are statistically significant at the level of 0.1%. A better measure of similarity between networks is the matching measure.Table 6presents the Jaccard similarity measure (lower triangle) and the Czekanowski–Sørensen–Dice similarity coefficient (upper triangle).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t006\n\nThe Jaccard similarity between each layer and the FMN is 0.439, which means that 43.9% of the edges overlap, while the remaining 56.1% of the links are derived from the other two layers. The edge overlapping between the FMN and the SRN is less than one third (362/1,158 = 0.313). As we saw in the analysis based on the correlation coefficient, the smallest similarity to the SRN is shown by the layer of the trading volume network (12.9%), and the greatest similarity is shown by the layer of the multiplex network based on the firm-specific factor of stock return (53.9%). When comparing the separate layers of the multiplex network, the edge overlap is relatively low, indicating their mutual diversity. The values of the Czekanowski–Sørensen–Dice coefficients confirm the above observations. The Sørensen–Dice coefficient tends to give slightly higher similarity values than the Jaccard similarity index because the Sørensen–Dice measure gives more weight to the common elements and less weight to the non-common elements. After conducting 9,300 QAP iterations, it was determined that all the similarity measures inTable 6exhibit statistical significance. Specifically, the observed matching coefficients are larger than would be expected by random chance with a probability of 1.0. It is noteworthy that the similarity measures, including Pearson correlation coefficients, the Jaccard index, and Czekanowski-Sørensen-Dice matching coefficients, for each layer with the FMN, yield identical values. This phenomenon results from aggregating three layers with varying similarities into a multiplex form, where some edges overlap across layers, and each layer contains the same number of edgesdue to the MST properties.\n\nComputing the Jaccard similarity coefficient for the four networks is recommended, considering all three layers and the multiplex network. The formula in the following can be used to extend the Jaccard coefficient to more than two sets\n\nwhererepresent the edges of each network, andsis the number of sets.Table 7shows the Jaccard index for all three layers.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t007\n\nThe Jaccard index for all three layers and the multiplex network is 7.95%, which means that, of the 1,056 edges contained in all four networks together, only 84 overlap (84/1,056 = 0.0795).Fig 6depicts a graphical illustration of the edge overlapping for the multiplex network and its three layers, as well as for the FMN with the SRN. The Jaccard index for three layers and for each pair of layers ranges from 10.2% to 11.5%. This indicates a higher proportion of overlapping edges within each pair of layers compared to the multiplexed representation.\n\na) FMN with all three layers (red edges; 7.95%); b) FMN with the SRN (green edges; 31.3%).\n\na) FMN with all three layers (red edges; 7.95%); b) FMN with the SRN (green edges; 31.3%).\n\nhttps://doi.org/10.1371/journal.pone.0320799.g006\n\nAnother approach is the edge overlapping ratioin the compared networks, which is defined as the ratio of the common edges found insconsecutive networks and the maximum number of edges in the network\n\nwhererepresent the sets of links of networks;are the number of edges in each network. The EOR index is an original proposal defined in this study.\n\nIt should be noted that the edge overlapping ratio (EOR) proposed in this study for the FMN and its three layers corresponds exactly to the value of the Jaccard index (EOR = 7.95%). This convergence is because the denominator of the EOR – the maximum number of edges of one network – corresponds to the denominator of the Jaccard index, i.e., the union of the sets of edges of all the networks considered. On the other hand, the numerators of both indexes are the same by definition.\n\nHowever, the EOR for the FMN with the SRN is different from Jaccard’s ratio and is 34.4%. In other words, the overlapping edges cover 34.3% of the maximum number of links in one of these networks (362/1056). The edge overlapping ratio for comparisons between individual layers of the multiplex network and the SRN is included inS1 FileAppendix D (Supplementary files).\n\nAnother quantity used to analyze multiplex networks is the correlation of degrees across layers. In order to determine the inter-layer degree correlations, the mutual information of the degree sequences can be used. The inter-layer mutual information between the degree distributions of two layers is defined as follows [67]\n\nwhereis the joint probability that a node has degreekin both layers\n\nwheredenotes the number of vertices with degreesandin layersαandβ, respectively. The higher the value of the inter-layer mutual information, the more correlated are the degree distributions of the two layers.\n\nThe inter-layer mutual informationIfor individual pairs of the three layers is as follows: 0.419 for the idiosyncratic return–volatility pair; 0.449 for volatility–trading volume; and 0.359 for idiosyncratic return–trading volume. The average quantity among all possible pairs is 0.409, which means that the degree distribution is not strongly correlated between the multiplex layers.\n\nAnother method of testing the importance of different layers is to perform the Multiple Regression Quadratic Assignment Procedure (MR-QAP) network regressions [106]. In this study, three multiple regression models are proposed to determine whether the structure of each layer explains i) the financial multiplex network and ii) the stock return network\n\nwhereis the adjacency matrix of the financial multiplex network;the adjacency matrix of the stock return network;αindicates a constant;mean regression coefficients; anddenote the adjacency matrices of the idiosyncratic return network, the volatility network, and the trading volume network, respectively.\n\nThese regression models estimate how the layers of the multiplex network affect the two networks – the multiplex financial network and the stock return network. The objective of Model 1, defined in Eq. (20), is to assess the effect of its individual components (layers) on the generation of the FMN. Model 1 serves as the initial framework for Model 2, which is described by Eq. (21). Both Model 1 and Model 2 are used to evaluate the differences in the strength of the impact that each layer of the multiplex network has on the FMN and SRN, respectively. To evaluate the statistical significance of the specified models, the MR-QAP test is used, which, as an extension of the bivariate QAP model, is a permutation test for multiple linear regression model coefficients for network data organized in square matrices [107]. The Double-Semi-Partialing (DSP) approach introduced by Dekker et al. [107], which is a residual permutation method, is utilized. Under permutations, the DSP method reduces the potential effects of multicollinearity between the focal variable and the control variables.\n\nTable 8reports the results of the estimation of the three cross-network regression models formulated by Eqs. (20)-(22). Based on the regression coefficients of Model 1, the positive effect of all three layers on the multiplex network can be observed, with the trading volume network layer having the strongest effect on the FMN. Positive regression coefficients are reported for Model 2. The strongest effect on the SRN is the multiplex network layer concerning idiosyncratic return. The explanation for this is that the rate of return is the sum of the systematic and the idiosyncratic risk premiums. It is important to emphasize that the proportion of variance in the dependent variable that can be explained by the independent variables in Model 2 is. This means that about half of the information contained in the SRN is determined by the transfer of information embedded in the three layers of the financial multiplex network. The remaining variability is explained by other factors not included in Model 2. It should be pointed out that, in contrast to Model 1, where the trading volume layer has the strongest influence on the formation of the FMN, this layer in Model 2 exerts the weakest influence on the SRN. This change underscores the differences between the FMN and SRN.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t008\n\nThe third model (Model 3) deals with the impact of the SRN on the FMN. The modeled reverse relationship exhibits a much lower overall measure of goodness-of-fit, expressed by the coefficient of determination, than Model 2. However, Models 2 and 3 are not directly comparable, as one contains a multiplex network and the other the three layers of the multiplex network.\n\nIn all the regression models, the F-test value and the regression coefficients for all variables are statistically significant, while, by applying 46,500 iterations of Double-Semi-Partialing of MR-QAP, the observed quantities are statistically significantly larger than expected under the random chance assumption.\n\nSince all networks – the FMN, its layers, and the SRN – are scale-free graphs, we can determine the network’s robustness to random vertex failures. Evaluation in this regard has been carried out using the critical threshold of network failure, which, by applying the Molloy-Reed criterion to form a giant component in a network, can be defined as follows [108]\n\nwhereanddenote the second and first moments of the degree distribution, respectively.\n\nThis critical thresholdindicates a finite fraction of random node removal to collapse the largest component structure. In other words, the random removal of afraction of vertices will result in the fragmentation of the network.\n\nTable 9reveals that the FMN exhibits the most robust structure against random failures. In order for the financial multiplex network to fall apart, one would have to remove 84% of its vertices, while to damage the giant component of the stock return network, it is enough to randomly remove 58.6% of the nodes. It should be emphasized that the result robustness of the SRN is consistent with those obtained by [37], where for the MST-based cross-correlation network the critical robustness coefficient isand, respectively, depending on the period. This suggests that the financial market demonstrates resilience to failures in the aftermath of random stock removal.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t009\n\nThe fundamental analysis was conducted through the simplification of a network approach, which entailed the dichotomization of the MSTs obtained using the distance metricand the subsequent construction of an unweighted multiplex network. The robustness test is applied to the relaxation of the network binarization assumption, resulting in the formation of a multiplex network, its corresponding individual layers, and the SRN as a weighted network.Fig 7illustrates the visualization of the multiplex graph (FMN) using a force-directed layout, which was generated with the ForceAtlas2 algorithm (node colors correspond to sector affiliation). In the presented graph, four companies (PRU, MSFT, AMP, ETN) have been highlighted, as their degree centrality in the weighted multiplex network exceeds the threshold value of 0.05 (degree centrality > 0.05). Two of these firms belong to the Financial Services sector, while one represents the Technology sector and another the Industrials sector. Notably, the AMP node stands out due to both its high degree of connectivity and its considerable distance from other vertices.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.g007\n\nIt should be stressed that comparisons of the statistical properties of the networks were omitted, as weighted and unweighted networks inherently differ. The robustness test is applied to the analyses presented in Sections 4.3, 4.4, and 4.5.\n\nTable 10shows the results of the correlations between the weighted networks. The results do not reveal significant differences compared to the basic analyses. It should be pointed out that the assessment of network similarity, as measured by Jaccard similarity, Czekanowski-Sørensen-Dice matching coefficients, and EOR, yields identical values. This is because the evaluation considers only the presence of edges between nodes in the network.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t010\n\nThe results obtained for network regression (Table 11) and the threshold for robustness to failure (Table 12) in weighted networks are similar to those obtained for unweighted networks. This indicates the robustness of the results with respect to the assumption of dichotomization of the networks at the final stage of their construction.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t011\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t012\n\nIn order to assess which financial network has a structure that better represents stock price movements, a regression analysis has been performed employing the ordinary least squares method. The dependent variable is the Sharpe ratio, as proxy for stock performance [34], using out-of-sample data of the stock returns over the 252 days, with a one-year lag from the last data point used to construct the financial networks. The time frame for the out-of-sample data is March 13, 2023, to March 12, 2024. The explanatory variables employed are two centrality measures calculated for the two networks, respectively FMN and SRN (for the in-sample data): 1) degree centrality and 2) eigenvector centrality. Degree centrality is a simple measure that captures connections in the nearest vertex neighborhood in the network. In contrast, eigenvector centrality is a more complex measure that considers the wider context of the structure of the connections in the network. A similar approach was applied by [101], investigating the correlation between the in-sample centrality and the out-of-sample Sharpe ratio. Due to changes in listed shares over the out-of-sample period, the number of observations is 456.Table 13reports the results of a regression analysis of the in-sample centrality measures and their relationship with the out-of-sample Sharpe ratio.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320799.t013\n\nThe first two models are directly comparable and evaluate the impact of the eigenvector centrality of the SRN (Model A) and the FMN (Model B) on the Sharpe ratio realized in a later time period. The results of the standardized regression coefficients indicate a more pronounced effect of the FMN than of the SRN. Furthermore, thevalue for Model B is greater than that of Model A. Model C includes the eigenvector centrality of both networks and confirms a larger regression coefficient for the FMN. In addition, the regression coefficient for the SRN is not statistically significant. The last model (D) includes the degree and eigenvector centrality derived from both networks. The effect of the FMN centrality measures on the Sharpe ratio is more pronounced than that of the SRN centrality measures, as evidenced by the absolute values of the standardized regression coefficients. Additionally, the regression coefficient for the eigenvector centrality_SRN is not statistically significant. Note that, indicating that there is no problem with multicollinearity.\n\nIn this paper, we have proposed the construction of a financial multiplex network, comprising three layers of the US stock market network, that considers interactions between companies. Each network layer is generated from the cross-correlation matrix of the complex financial system using the MST approach. These layers consist of i) the firm-specific stock return premium network, ii) the volatility network, and iii) the trading volume network. The analysis focuses on comparisons of the cross-correlations of the log-return network (SRN), the single-layer networks, and the financial multiplex network.\n\nIn summary, the comparison of the multiplex network, the three layers of the multiplex, and the stock return network reveals similarities and differences in their structures. The results demonstrate that the FMN has a higher density of connections and degree of connectivity, as well as a more compact structure, than the other networks. While all the networks obey a power-law vertex degree distribution, the SRN and each of the three layers exhibits a tree-like structure, a strong community structure, and disassortative behavior. In contrast, the multiplex network has none of the typical structures, has a weaker community structure with fewer modules, and has less pronounced disassortative behavior. Additionally, only the multiplex network displays the small-world property, which results from the nature of its construction. This does not imply that the MLN outperforms the SRN. These observations indicate that different networks can exhibit unique structural and behavioral characteristics and have distinct properties, highlighting the importance of understanding the underlying phenomena they represent.\n\nFrom the similarity measures, one can conclude that each network layer provides a unique part of the information that contributes to the overall structure of the multiplex network. The edge overlapping between the three layers with the multiplex network is approximately 8%. Moreover, significant differences between the three layers of the multiplex network and the commonly analyzed MST-based stock return network are noticeable. The inter-layer mutual information shows that the degree distribution is not strongly correlated between the layers of the financial multiplex network. This provides the basis for an affirmative answer to the first research question: “Is there a significant difference between the FMN and the SRN?”\n\nFurthermore, empirical studies based on the MR-QAP regression reveal that the multiplex network and the stock return network can be significantly explained by the three layers. This supports the conclusion that the distinct layers convey separate information. In other words, the results of this study indicate that the multiplex network and the stock return network are influenced by three distinct channels, with the multiplex network exhibiting a different structure. Specifically, the three network layers only explain about 50% of the variance of the stock return network, while, in an inverse relationship, the stock return network explains only approximately 26% of the variance of the multiplex network. This implies that the two independent networks are different from each other as they consider different information in the financial market. Nevertheless, about 31% of the overlapping edges in both these networks are generated by the relatively more similar layer of the multiplex network based on the firm-specific factor of stock return to the SRN which additionally incorporates a systematic risk premium (common market factor). In other words, the idiosyncratic stock return network layer determines the stock return network to a greater extent than the other two layers of the multiplex network. In general, the low similarity reduces the risk of overfitting and redundancy in multiplex network models. The divergence ensures that each layer contributes distinct structural and relational information, thereby enhancing the robustness and interpretability of the network. This divergence highlights the multiplex network’s ability to capture the multifaceted nature of financial markets by incorporating non-redundant perspectives. It should be pointed out that the observed transitivity, higher density and much smaller fraction of pendant nodes in the FMN compared to the SRN indicate that the proposed multiplex representation has less network fragility to random removal of vertices or edges. This ultimately leads to the fragmentation of the network into two or more distinct components. Moreover, FMN is more robust to the collapse of the largest component due to the removal of randomly selected nodes. The above conclusions legitimize the affirmative answer to the second research question: “Does each layer of the stock network offer unique information within the FMN?”\n\nThe out-of-sample evaluation of the dependency structure representation indicates that the financial multiplex network has a greater impact than the stock return network on the future stock performance under the return-risk ratio in the financial market. This statement provides a clear answer to the third research question: “Which network more accurately reflects the interconnections between financial assets?” Nevertheless, the low values of the determination coefficient () of the proposed regression models indicate the necessity for further research in this area.\n\nThis research has several limitations. Firstly, the OLS estimator was employed to extract the idiosyncratic stock returns, which may exhibit slight limitations in adequacy when applied to long time series. Secondly, the analysis may underestimate the impact of extreme events due to the overall low similarity between the volatility and turnover volume layers. This limitation arises from focusing on the entire distribution rather than explicitly isolating tail dependencies. Furthermore, such extreme events in financial markets have the potential to trigger significant structural breaks in networks. However, the adopted long study period should adequately mitigate their impact.\n\nThis study contributes to the area of complex networks in financial markets. The information space of the multiplex network is much wider than the standard range of information included in the cross-correlation of the stock return network, as the multiplex network contains three layers: firm-specific stock return, volatility, and turnover volume. Reducing data complexity by applying the MST-approach to the construction of each of the three layers of the multiplex network, on the one hand, and the three-layer bonding of a wider context of information in the financial market, on the other hand, makes the concept proposed in this study, that of extracting the backbone of the financial multiplex network, an inspiration for further research analyzing the interconnectedness of the complex financial system using the network approach. Future studies should aim to more deeply analyze the relationships between the financial multiplex network and firm performance, such as stock returns, and the volatility of the stock price. A network dynamic approach could be applied in this area. One promising direction for future research involves exploring the application of simplicial complexes to evolving multilayer networks, particularly in contexts where temporal and higher-order interactions play a crucial role. Simplicial complexes provide a means of capturing both local and global properties of networks, thereby facilitating a more profound analysis of these systems [109]. These mathematical constructs are instrumental in modeling and analyzing complex structures within networks. Moreover, simplicial complexes extend the analytical capabilities of financial multilayer networks, enabling the simultaneous modeling of multilateral interactions both within individual layers and between them. They also facilitate the representation of interactions among multiple entities, capturing relationships that extend beyond pairwise connections. This capability is particularly advantageous in complex systems where higher-order interactions play a significant role [110,111].\n\nThe Supporting Information,S1 File, contains additional tables and graphs for the robustness analysis.\n\nhttps://doi.org/10.1371/journal.pone.0320799.s001\n\n(PDF)",
    "category": "economics"
  },
  {
    "title": "Outdoor recreation’s association with mental health and well-being during the COVID-19 pandemic",
    "authors": "Colby Parkinson, Xiangyou Shen, Megan MacDonald, Samuel W. Logan, Lydia Gorrell, Kreg Lindberg, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321278",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321278",
    "content": "Outdoor recreation provided a crucial way to maintain physical activity, reduce stress, and preserve a sense of normalcy during the COVID-19 pandemic. This study assessed the relationship between outdoor recreation and mental health in the context of COVID-19. Cross-sectional online survey data were collected in early 2021 from a sample (n= 503) representative of the U.S. adult population in age, gender, and race. We observed prevalent engagement in near-home outdoor activities, widespread reductions in outdoor engagement relative to the pre-COVID period, and significant age, financial, and racial differences in engagement patterns. Regression models suggested that reduced outdoor recreation was associated with higher levels of perceived stress and depressive symptoms, whereas more frequent outdoor activities predicted better well-being. The health implications of adaptive engagement versus cumulative exposure during times of significant disruptions are discussed, along with the need to address structural inequities in accessing outdoor recreation as a health behavior.\n\nCitation:Parkinson C, Shen X, MacDonald M, Logan SW, Gorrell L, Lindberg K (2025) Outdoor recreation’s association with mental health and well-being during the COVID-19 pandemic. PLoS ONE 20(4):\n           e0321278.\n        \n        https://doi.org/10.1371/journal.pone.0321278\n\nEditor:Gareth Hagger-Johnson,, UCL: University College London, UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\n\nReceived:May 14, 2023;Accepted:February 28, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Parkinson et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All survey data files in .sav format are available athttps://doi.org/10.5281/zenodo.12668838\n\nFunding:XS received funding to partially support this research by the Hallie E. Ford Center Team Science Seed Grant from the Hallie E. Ford Center for Healthy Children & Families, College of Public Health and Human Sciences, Oregon State University (https://health.oregonstate.edu/hallie-ford). The grant was Oregon State University internal, therefore the grant number is NA. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe COVID-19 pandemic caused a mental health crisis [1], increasing the worldwide prevalence of anxiety and depression by 25% [2]. In the U.S., the beginning lockdown phase witnessed as high as three-fold increases in stress, anxiety, and depression among the general population [3,4], a trend that persisted after COVID-19 vaccine approvals [5–7]. As access to out-of-home indoor spaces instrumental to personal and community functioning drastically declined, people around the world increasingly turned to outdoor natural areas as relatively safe spaces for recreation and restoration [8–13]. While this shift coincided with greater gender, ethnic, age, and financial diversity among new outdoor recreation participants [14], historical inequities that exclude or constrain use of outdoor spaces were exacerbated during the pandemic [15], particularly among women, racial and ethnic minorities, and low income individuals in the U.S. [9,16,17].\n\nUnderstanding nature exposure patterns during COVID-19 is important because, consistent with long-standing research that supports the physical and mental health benefits of nature exposure [18,19], nature contact (e.g., gardening, visiting green or blue spaces) helped mitigate the negative effects of pandemic stressors on numerous mental and physical health outcomes [20,21]. Specifically, more nature contact, whether indicated by cumulative exposure measures (e.g., frequency, duration) or relative changes compared to pre-COVID level, was associated with lower perceived stress [10,22–24], reduced depressive symptoms [25–27], and better overall mental health and well-being [24,28,29]. In this study, we aimed to contextualize outdoor recreation engagement during COVID-19 and develop a better understanding of its potential mechanism for promoting mental health in times of severe disruptions and constraints.\n\nThroughout different phases of the pandemic, significant variations existed in outbreak levels and pandemic responses across countries and locales, shaping diverse outdoor space policies, public health measures and guidance, and individual adherence to preventive measures and perceptions of risk [12,13,30,31]. At a high-level, many countries first implemented legally restrictive measures (e.g., stay-at-home, ban on large gatherings) and public health guidance to reduce the spread of the virus in March 2020, often removing, adjusting, and re-implementing measures depending on the severity of nationwide or local spread through the remainder of 2020 and beyond [32]. Throughout this period, many governments instituted complete or partial lockdowns that inhibited or discouraged the use of public and recreational spaces [12]. In 2021, the approval of vaccines alongside more infectious and deadly local outbreaks from different COVID-19 variants brought greater variability in pandemic response. Wealthy countries rolled out millions of vaccines that protected citizens from more deadly outcomes while broadly ending or reducing restrictive measures, although many poor countries or vulnerability communities continued to suffer [33].\n\nMixed evidence was reported regarding the rate of outdoor recreation and use of outdoor spaces during COVID-19. Compared to pre-pandemic levels, decreased outdoor recreation and facility use were observed in places that implemented park and recreation facility closure or other lockdown measures [23,36,37]. Meanwhile, many regions or recreational facilities that implemented minimal or eased restrictions experienced increased visitation [12,38,39], particularly at facilities with more natural features and those nearest to people’s homes [40,41]. Notably, several studies observed increases in neighborhood walking or jogging [42–44], reliance on at-home nature and gardening [45,46], and many other less specialized outdoor activities [34,47]. These activities are typically excluded from outdoor recreation taxonomies commonly used in outdoor participation surveys and studies examining recreation facility usages. Overall, our literature review revealed largely inconsistent findings about individual-level outdoor recreation participation during the pandemic [10,24,28,42,48,49]. Many factors might have contributed to these inconsistencies: diverse research designs, different outdoor space uses as a result of heterogeneous time- and place-related pandemic responses at both the individual and societal level [20,34,35,50], seasonal variations associated with regional climates [37], and structural inequities and individual differences associated with demographic characteristics [9,16,51].\n\nIn this study, we examine the outdoor recreation rate in the U.S. in early 2021, one of the country’s most deadly and infectious periods [52]. Relative to other countries, the U.S. took a localized approach to managing the pandemic [31] and, at the time of the study, implemented no nationally instituted laws that restricted mobility, the latter often associated with decreased outdoor recreation [53,54]. Some research observed higher-than-pre-pandemic annual participation rate (54%) in outdoor recreation in 2021 [55]. Other studies observed increased [56] or decreased [39] outdoor recreation during later phases of the pandemic. Through this study, we aimed to collect data on the broad patterns of outdoor engagement during a later phase of the pandemic to reveal emergent popular activities and potential demographic differences that are underexamined in existing research. Instead of using a pre-defined set of outdoor recreation activity categories, respondents in our study self-nominated their most frequent outdoor recreation activity. This approach ensures the inclusion of a broader set of activities pursued by people in an outdoor setting for recreational purposes.\n\nOutdoor recreation provides a direct and engaging form of nature contact because it usually involves physical movement and close interactions with the natural environment [19]. However, different measures of outdoor recreation engagement and broader nature exposure have been associated with varied benefits to mental health outcomes during the COVID-19 pandemic [21]. Existing research suggested that increasing or maintaining time spent outside during the pandemic was associated with lower perceived stress and higher positive mental health [23,24,56], whereas decreasing time outside was associated with higher depression [48]. Additionally, people who maintained pre-COVID levels of outdoor recreation experienced smaller decreases in subjective well-being than those who reduced outdoor activities [28], potentially revealing an adaptive effect of outdoor recreation. Compared to indoor space use, outdoor space use during COVID-19 was more strongly associated with well-being [57], reinforcing outdoor space’s contribution to adaptation, especially as people intentionally used these spaces to improve their health outcomes [43,51].\n\nStudies have observed that, regardless of the relative levels of outdoor recreation compared to the pre-COVID period, cumulative exposure as indicated by outdoor recreation frequency was associated with higher well-being [21,29,58] and reduced depression [25–27]. Furthermore, improved well-being was associated with spending any amount of time outdoors relative to non-participation [8]. These behavior-focused findings are consistent with the observations from outdoor space use studies, which found both proximity to green spaces and actual use contributed to improved mental health and engagement in healthy behaviors [59–61].\n\nDespite thorough examination of their independent effects, few studies included both relative and cumulative measures when examining outdoor recreation’s association with mental health during COVID-19 or in other contexts. It remains unclear which measure is a better predictor of mental health in times of major disruption and to what extent one may confound the other. Previous research that examined leisure engagement and mental health during the pandemic revealed that these two types of measures were related but not equivalent, and, in times of significant interruptions, adaptive engagement indicated by relative measures may better predict mental health [62]. In this study, we include both types of measures to enable comparison and examine outdoor recreation’s potentially adaptive role during stressful events.\n\nMost existing literature on outdoor recreation and mental health also focused on early stages of the pandemic, particularly the lockdown phase [24,26,28]. While later-phase studies generally reported consistent evidence in favor of nature’s contribution to health [59], their focus was on different regions or populations than the present study. In general, several studies examined European countries [8,57,59] or specific regions or destinations within the U.S. [29,60,63]. Others sampled only specific groups, such as college students [10,58,64]. In this study, we seek to expand our understanding on the outdoor recreation-mental health relationship beyond early stages of the pandemic using data collected from a diverse nationwide U.S. adult sample.\n\nResearch has identified salient risk factors that might worsen mental health during COVID-19, including higher perceived risk of infection [3,65] and loneliness or social isolation [66,67]. Negative perceptions and beliefs regarding preventive measures have also been associated with poorer mental health [62,68]. On the flip side, positive beliefs about preventive measures might have a protective effect on mental health. Engaging in precautionary behavior intended to reduce the risk of infection (e.g., wearing a mask, washing hands) has been identified as a protective mental health factor [69,70]. Additionally, more positive future outlooks that were measured using optimism [71], hope [70], and anticipation of a better world [72] were associated with better mental health outcomes during the pandemic.\n\nResearchers have identified risk and protective factors in the context of nature exposure and mental health during COVID-19 at the environmental and community levels, such as severity of lockdowns [23,24] and COVID-19 death rate [10], and related to individuals’ lifestyles, such as screen time [64,73] and physical activity [24,48,58]. Findings from different countries and pandemic stages suggested that risk and protective factors might confound the relationship between nature contact and health outcomes [23,27,64].\n\nIn this study, we focus on individual-level risk and protective factors as informed by previous research, including infection risk perceptions, social isolation, beliefs about preventive measures, practices of precautionary behavior, and future outlook about vaccines and a post-pandemic world. These factors are included as covariates to control for their possible confounding effect on the association between outdoor recreation and mental health.\n\nThe current study extends previous literature in five key ways: first, it collected data from a nationwide sample to reveal broad patterns of outdoor recreation among U.S. adults with a focus on an individual’s most frequent outdoor activity, as the latter may provide an anchor and special meaning through a time of turmoil and disruptions. Second, we let participants self-define outdoor recreation to allow for the inclusion of key outdoor activities that became prevalent during the pandemic but would have been excluded from a conventional definition or activity taxonomy [47,74]. Third, this study was conducted during a period that overlapped with one of the largest waves of COVID-19 cases and deaths in the U.S. [52], providing a unique opportunity to examine the outdoor recreation-mental health relationship under severe and sustained stress. Fourth, unlike most existing studies that used either cumulative measures (e.g., frequency, duration) or relative measures of outdoor recreation (e.g., changes relative to pre-COVID level), we included both to enable comparisons and insights on the possibly unique effect of changes in outdoor engagement on mental health independent of the impact of cumulative exposure. Fifth, when analyzing the outdoor recreation-mental health relationship, we minimize biases by controlling for potential confounding COVID-specific risk and protective factors. The latter has been accounted for by only a small number of previous studies [21,48,58,64].\n\nTo address the above gaps, we asked two research questions:\n\nData in this study were collected from a nationwide sample proportionally representative of the U.S. adult population in age, gender, and race (n= 503). Participants were recruited via Prolific, an online crowd-sourcing platform, and screened to meet two inclusion criteria: aged 18 years or older and residing in the U.S. at the time of survey. A Qualtrics survey was administered between February 3 and February 15, 2021. The study was approved by the Institutional Review Board of the authors’ institution (IRB-2020–0927). The research was deemed to pose minimal risk with the only potentially identifiable information collected being zip code. All participants provided written consent that was recorded via the online survey.\n\nThis research was part of a larger study investigating leisure engagement patterns among U.S. adults. We aimed to collect data from a national sample representing diverse backgrounds. A previous cross-sectional study on health during COVID-19 [30] using the same platform demonstrated that a sample size of 500 was sufficient to ensure diverse socio-demographic representations. Power analyses (assuming medium effect size, 95% CI, and α =.05) confirmed this exceeded the minimum required sample size for each planned statistical test. More details about the research design and sampling method are reported in prior published research [62].\n\nPerceived stress was measured using the 7-item stress subscale from the Depression, Anxiety, and Stress Scale (DASS-21) [75,76]. Participants used a 4-point scale (0 = “Not at all” to 3 = “Most of the time”). Participants reported their agreement with how often statements regarding difficulty relaxing and general agitation (e.g., “I found it hard to wind down” and “I tended to over-react to situations”) applied to how they felt over the last two weeks. Responses were summed for final analysis and ranged from 0 to 21 with higher scores signifying higher perceived stress. The scale had excellent internal reliability (Cronbach’s α =.92).\n\nDepressive symptoms were measured using the Patient Health Questionnaire (PHQ-2) [77]. Participants used a 4-point scale (0 = “Not at all” to 3 = “Nearly every day”) to report how often they were bothered by “Little interest or pleasure in doing things” and “Feeling down, depressed, or hopeless” over the last two weeks. Responses were summed and ranged from 0 to 6 with high scores signifying more depressive symptoms. The scale had good internal reliability (Cronbach’s α =.85).\n\nWell-being was measured using the World Health Organization Well-being Index (WHO-5) [78]. Participants used a 5-point scale (0 = “At no time” to 4 = “All of the time”) to report how frequently statements regarding positive mood and vitality (e.g., “I have felt cheerful and in good spirits” and “I have felt calm and relaxed”) applied to how they felt over the past two weeks. Responses were summed and ranged from 0 to 25 with higher scores indicating better well-being. The scale had excellent internal reliability (Cronbach’s α =.92).\n\nParticipants reported their most frequent outdoor recreation activity during COVID-19 through an open-ended question. Two additional questions using 5-point scales covered past-month outdoor recreation frequency (1 = “Less than once a week,” 2 = “Once a week,” 3 = “2-3 times a week,” 4 = “4-5 times a week,” and 5 = “Almost every day”) and changes in outdoor recreation level compared to pre-COVID level (1 = “Much less now than before COVID-19”, 2 = “Slightly less now than before COVID-19”, 3 = “About the same, 4 = “Slightly more now than before COVID-19”, and 5 = “Much more now than before COVID-19”).\n\nSocial isolation was measured using a single item from the UCLA Loneliness Scale Version 3 [79]. Participants indicated how much the statement “I felt isolated” applied to them over the past two weeks using a 4-point scale (1 = “Not at all” to 4 = “Most of the time”).\n\nResponse categories for all subsequent items in this subsection were on a 6-point Likert scale (1 = “Disagree strongly”, 6 = “Agree strongly”). Perceived risk of infection was measured using a single item—participants indicated their agreement with the statement “There is a high likelihood of acquiring COVID-19 in general.” Beliefs about preventive measures were measured by having participants report their agreement with statements that concluded the sentence “COVID-19 preventative measures…,” including two items measuring positive beliefs (“…help lower the risk of infection”, “...help make our environment safer”) and three items measuring negative beliefs (“...are constraining,” “...cause anxiety in me,” and “...make it hard to live a full life”). The positive and negative belief scales showed acceptable internal reliability (Cronbach’s α =.73 and.82, respectively). Average scores were used for both. Precautionary behavior was measured by having participants report their agreement with the statement “I take active precautionary measures to lower the risk of infection.” Future outlook was measured by having participants report their agreement with separate statements measuring two items: vaccine outlook (“Situations are improving with the development of COVID-19 vaccines”) and COVID optimism (“I am optimistic that life will return to normal soon”).\n\nSocio-demographic response options with ten or fewer responses were recoded into theoretically consistent groups or treated as missing. Participants reported the following socio-demographic characteristics: age (years), sex (male or female; with Trans/non-binary treated as missing due to low response rate), race (White, Asian, or Black or African American; with Native Hawaiian or Other Pacific Islander, American Indian or Alaska Native, and other treated as missing), work status (five categories recoded into three: work from home, work in public, and unemployed), parenting (yes or no), subjective financial condition (1 = “I’m behind on my bills”, 2 = “I’m barely making ends meet”, 3 = “I’m just getting by”, 4 = “I’m doing alright”, 5 = “I’m living comfortably”), and household income (measured from “19,999 or less” to “$150,000 or more” in increments of $10,000).\n\nParticipants also reported COVID-related background information, including their pre-existing medical conditions (yes or no) and COVID-19 infection status. “Confirmation via test,” and “Suspicion based on symptoms” were treated as “Infected”; “Neither” was treated as “Not infected”; “Prefer not to disclose” was treated as missing.\n\nTable 1presents sample demographic characteristics. We confirmed sample representativeness using Chi-Square analysis by comparing 2015 American Community Survey data with proportions of key demographic attributes, including sex (χ2= 0.004, df = 1,p=.947), age (in 10-year categories up to 60 years or older; χ2= 5.346, df = 5,p=.375), and race (χ2= 8.776, df = 5,p=.118). The percentage of participants who had been infected (12.1%) was also within 1% of cumulative confirmed infections at the time of the survey closing [52].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321278.t001\n\nSample representativeness verification was conducted using Excel version 16.57. Power analyses for sample size were completed using G*Power version 3.1. All subsequent analyses were conducted using IBM SPSS 27. Complete cases were used for all analyses reflecting low missing rates (< 5% for all variables), which resulted in varied sample sizes. We also assessed linearity, normality, multicollinearity, and homoscedasticity for all regression analyses, with a correlation matrix for all variables used in the regression analysis provided in the supplement (S1 Table).\n\nResponses about “the most frequent outdoor activity” were coded via an iterative process informed by categorization frameworks used in existing studies [19,80]. Unique responses indicating the same activity using different wording were first merged (e.g., “biking” and “riding bike” were coded into “bicycling”). Activity types were then grouped into categories based on shared characteristics in resources, equipment, and level of physical exertion (e.g., hiking, walking). One researcher coded the open-ended responses into the activity categories. Subsequently, a second researcher used a list of those categories to independently code the same responses to determine interrater reliability, which was near-perfect (κ = 0.96, SE = 0.01,p<.001). Lastly, activity categories were grouped into one of two broad domains based on proximity to home and dependence on a natural resource or sport facility: (1) near-home outdoor activities and (2) outdoor sports and nature-based recreation.\n\nWe described outdoor recreation patterns for the full sample using proportions. Reflecting evidence supporting differences in outdoor recreation engagement by age, sex, race, and income [16,55], we analyzed differences in outdoor recreation engagement within these groups using nonparametric tests for categorical variables and Pearson correlation for continuous variables.\n\nOrdinary least squares regression was used to analyze the associations between outdoor recreation engagement and perceived stress and well-being. Weighted least squares regression was used to estimate the depressive symptom model due to non-normality of residuals. For all regression analyses, changes in outdoor recreation engagement level was recoded into three levels (“Much less,” “About same,” and “Much more”) and treated as categorical, with “about same” serving as the reference group. Eight covariates (age, sex, race, work status, parental status, subjective financial condition, pre-existing medical conditions, and infection status) were included based on existing evidence supporting associations between these variables and mental health outcomes during COVID-19 [4,81,82]. All categorical variables (changes in outdoor recreation engagement level, sex, race, work status, parental status, pre-existing medical condition, and COVID-19 infection status) were dummy coded.\n\nParticipants (n= 483) provided 183 unique open-ended responses about their “most frequent outdoor activity” during COVID-19, which were coded into 12 categories (Table 2). Most participants (56.9%) named walking as their most frequent activity, followed by hiking (8.3%), running (7.7%), and gardening (6.8%). Twice as many respondents reported a near-home activity (68.1%) than an outdoor sport or nature-based activity (31.9%).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321278.t002\n\nTable 2shows that over one-third (34%) of the sample recreated outdoors less than once a week, whereas 45% recreated outdoors one-to-three times a week and the remaining 21% recreated four-to-five times a week or more often. Most of the respondents (57%) reported reducing outdoor recreation to some degree during COVID-19, whereas 28% maintained their pre-COVID level and 15% increased engagement.\n\nTable 3presents demographic characteristics of outdoor recreation engagement. Several small but significant effects were observed: First, people who reported a near-home activity as their most frequent outdoor activity were on average almost seven years older than those who engaged in an outdoor sport or nature-based recreation as their most frequent outdoor activity (p<.001, η =.193). Age was positively correlated (p<.001) with outdoor recreation frequency. Second, outdoor recreation engagement relative to pre-COVID levels differed across racial groups (p=.002, Cramer’s V =.134). White participants were more likely to maintain their pre-COVID outdoor recreation level than Black or Asian participants, whereas the latter were more likely to reduce their outdoor engagement during COVID-19. White respondents also reported recreating outside more frequently than Black respondents (p=.025, η =.124). Third, people who perceived themselves as having a better financial condition recreated outside more frequently (r =.12,p=.009). The result also suggested significant differences in outdoor recreation frequency based on household income (p=.015, η =.144), but post-hoc tests did not reveal significant pairwise differences.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321278.t003\n\nTable 4provides regression analysis results for perceived stress, depressive symptoms, and well-being controlling for COVID-specific protective and risk factors, demographics, and COVID-related background (n= 458).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321278.t004\n\nDecreased outdoor recreation engagement predicted higher perceived stress (.85 points higher on a 21-point scale than the maintenance group,p=.046). Neither frequency nor increasing outdoor recreation engagement were significant predictors. Outdoor recreation variables collectively explained 1.3% of the variance in perceived stress.\n\nThree COVID-specific risk factors predicted significantly higher perceived stress, including social isolation (β= 0.41,p<.001), negative beliefs about preventive measures (β= 0.14,p<.001), and perceived risk of infection (β= 0.09,p=.02). Older age (β= -0.33,p<.001) reporting Asian race (relative to White race,β= -0.09,p=.01) and better subjective financial condition (β= -0.07,p=.049) predicted lower perceived stress, while parenting (β= 0.11,p=.004) and having a COVID-19 infection (β= 0.07,p<.036) predicted higher perceived stress. The full model accounted for 46.1% of the total variance in perceived stress.\n\nOutdoor recreation’s effects on depressive symptoms were similar to the effects observed in the perceived stress model. Decreased outdoor engagement was the only significant predictor of depressive symptoms (.35 points higher on a 7-point scale than the maintenance group,p=.007). Frequency and increased outdoor recreation engagement were not significant. Outdoor recreation engagement variables accounted for 4.2% of the variance in depressive symptoms.\n\nStronger social isolation (β= 0.46,p<.001) and negative beliefs about preventive measures (β= 0.12,p=.002) predicted higher depressive symptoms, while a more optimistic outlook about the pandemic (β= -0.08,p=.046) predicted lower depressive symptoms. Older age (β= -0.21,p<.001), better subjective financial condition (β= -0.08,p=.024), and reporting Asian race (relative to White,β= -0.16,p<.001) predicted lower depressive symptoms, while having a pre-existing medical condition (β= 0.13,p=.001) or being unemployed (relative to working from home,β= 0.08,p=.034) predicted higher depressive symptoms. The full model accounted for 48.3% of the total variance in depressive symptoms.\n\nMore frequent outdoor recreation was associated with higher well-being (β= 0.18,p<.001). Changes in engagement levels were not significant predictors. Outdoor recreation engagement variables accounted for 7.7% of the variance in well-being.\n\nHigher social isolation (β= -0.32,p<.001) predicted lower well-being, while COVID optimism (β= 0.20,p<.001) predicted higher well-being. Better subjective financial condition (β= 0.12,p=.004), older age (β= 0.10,p=.027), and reporting Asian race (relative to White, β= 0.09,p=.033) were associated with higher well-being, while having a pre-existing medical condition (β= -.10,p=.018) predicted lower well-being. The whole model accounted for 33.1% of the total variance in well-being.\n\nIn this study, we described patterns of outdoor recreation among U.S. adults during the height of the COVID-19 pandemic and examined how relative and cumulative engagement in outdoor recreation related to mental health and well-being. We observed widespread reductions in outdoor recreation levels relative to the pre-COVID period. Our data also suggested distinct relations between different measures of outdoor engagement and mental health, wherein relative measures were better predictors of negative mental health, while cumulative frequency measures better predicted well-being. Detailed discussions of results and implications follow.\n\nMore than 45% of our sample reported recreating outside at least once a week. While this rate is higher than prior findings [55], it is likely due to the inclusion of a broader set of outdoor activities in this study, including non-nature-based near-home activities and those involving low levels of physical exertion (e.g., walking, sedentary and relaxing activities). Our finding of more frequent near-home activities relative to traditional outdoor sports and nature-based recreation extended similar observations from the lockdown period to a later phase [43], accentuating the role of nearby natural spaces and non-tradition outdoor activities as people continued to adapt to pandemic challenges [47,83,84]. This finding revealed that in the face of disruptions people fell back on low-barrier outdoor activities [83] as they navigated and negotiated various constraints such as travel restrictions, park closures, crowding, and risk of infections [43,85].\n\nOur results also suggested widespread (57%) reductions in outdoor recreation (relative to pre-COVID level) despite a general increase of leisure time [86], relative availability of outdoor space (compared to indoor spaces), and public health guidance that encouraged using outdoor space for physical activity and socialization [87]. Several reasons might have contributed to the observed decreases in outdoor engagement: negative impacts of increasing COVID-19 cases [34], people returning to other activities during later phases of the pandemic [39], and disengagement of racial minorities, possibly due to a lower sense of belonging or access [16,88]. Our data provided empirical evidence aligned with these explanations. Despite mixed evidence in outdoor recreation participation rates during later phases or after the pandemic, recreation managers and public health policymakers should aim to minimize restrictions on and barriers to these spaces to prevent decreased engagement. They should also consider incentives to facilitate engagement, such as lowering costs and improving transportation to facilities, particularly for low-income groups [35,39].\n\nWe observed significant differences in outdoor recreation engagement based on age, race, and subjective financial condition. With respect to cumulative exposure, we observed more frequent outdoor activities among older adults, possibly reflecting the higher levels of free time available to retired adults. However, we observed no age differences in relative changes in outdoor recreation engagement compared to pre-pandemic levels, contrasting findings in Vienna where younger adults were more likely to increase outdoor recreation participation [51]. Consistent with previous studies, we observed a stronger preference in near-home recreation activities among older adults [11,89].\n\nAdditionally, we observed less frequent and reduced outdoor recreation among people of color and those who perceived themselves as being in a poorer financial condition, possibly due to historically greater constraints to nature access [90,91] and heightened barriers to outdoor space use during the pandemic among these groups [92,93]. In light of these findings, we suggest potential increased investment in park-poor areas by municipalities [93]. There are practical measures for implementing standards for park and green space access, such as the 3-30-300 rule, which encourages city designers to ensure that every dwelling has three visible trees from its windows, every neighborhood has 30% tree canopy, and every home is 300 meters to a park or publicly accessible greenspace [94]. Adopting these measures or similar alternatives will facilitate wholistic accounts of health benefits derived from green views and park space, maximizing outdoor recreation and related facilities’ potential as a means to equitably promote healthy behavior and distribute health infrastructure [94].\n\nLower levels of outdoor recreation engagement, especially among younger adults and those who reported poorer financial well-being, is concerning as mounting evidence [4,82] suggested heightened risk for poor mental health and well-being for these groups during the pandemic. Future empirical studies should examine potential constraints at the intrapersonal, interpersonal, and structural levels that may have contributed to the overall decreased engagement in outdoor activities [95,96]. There is also an opportunity to examine causes of inequities in outdoor engagement between people of different races, ethnicities, and income backgrounds during COVID-19 and their enduring impacts on recreation participation as they relate to identity, perception, and experience [88,97] or place-based factors [15,98].\n\nOur result suggested that different measures of outdoor engagement predicted different aspects of mental health. Specifically, while frequency of outdoor recreation predicted well-being, only reduced engagement relative to pre-COVID level was significantly associated with perceived stress and depressive symptoms. Past studies reported similar effects of relative changes in outdoor engagement without controlling for frequency [23,24,48,56]. By including both types of measures, our study illustrated the unique effect of failing to maintain or increase outdoor engagement on mental health. Echoing prior research [62], we suggest that adaptive engagement plays a more prominent role than cumulative exposure in mitigating the adverse effect of negative events on mental health. Combined, these findings provide a nuanced insight into the role of outdoor activity, and nature contact in general, in aiding stress recovery in contexts marked by significant changes and constraints [99–101]. Future research should be more mindful of what types of measures to use when studying context-specific health outcomes of leisure or outdoor recreation.\n\nPrior research has suggested that spending more time outdoors may increase people’s well-being by increasing their connection to nature, which in turn promotes continued engagement and restoration [8,19,22,49]. Our findings supported outdoor recreation’s positive effect on well-being controlling for COVID-specific contextual factors, with frequency emerging as one of the strongest protective factors. Collectively, outdoor recreation variables predicted well-being better than they predicted negative mental health, providing additional support for leisure’s differential associations with positive and negative mental health [62].\n\nOur regression models explained a significant portion (33–48%) of the variance in mental health outcomes, with all statistically significant risk and protective factors exhibiting anticipated effects. As such, they provide a robust framework for future research in similar contexts characterized by marked stressors and disruptions. Notably, among all included variables, social isolation emerged as the strongest predictor of mental health across all three models.\n\nResearchers have suggested that nature-based activities, when engaged in as shared activities, provide opportunities for social connections and relationship building, which in turn accrue social support and reduce loneliness [102,103]. This could be especially true in the context of COVID-19, wherein outdoor space was perceived as relatively safe and instrumental for social interactions [51,104]. However, facilitating outdoor engagement and interactions also requires balancing heightened risk for infections in future similar public health crises [9,87] and other potential negative impacts of crowding on both the recreators and natural resources. Future research may examine the potential mediating effect of social isolation as a mechanism for explaining outdoor recreation’s positive impact on well-being during the pandemic and beyond.\n\nOur results contributed to the growing evidence for outdoor recreation’s role as an important health behavior [20,105]. Parks and other outdoor recreation spaces play a critical role in supporting this health behavior, with the potential to reduce inequalities in wide-ranging negative health outcomes [17]. Corresponding to the increasing perceived importance of parks and outdoor spaces to public health post-pandemic [106,107], we believe it is crucial to maintain or even increase access to outdoor recreation spaces during future crises like the COVID-19 pandemic, especially in park-poor areas or communities where vulnerable groups concentrate. In addition to promoting outdoor recreation as a restorative, relatively low-effort health behavior, governments could systematically invest in green infrastructure as a preventative health measure while addressing broader aims like promoting sustainability [94,107]. However, evidence suggests that individual adaptative strategies during COVID-19, including increasing effort and adjusting the time of recreation, were strong predictors of outdoor recreation above and beyond structural factors like park access [108]. Therefore, land managers, practitioners, and advocates could invest in efforts that facilitate or encourage adaptative outdoor recreation behaviors during future stressful events. The opportunity to help maintain engagement in low-barrier and less specialized outdoor recreation activities (e.g., walking) among new and existing participants also remains important [34,47], as is facilitating reintroduction to outdoor recreation among people who stopped during the pandemic [15,88].\n\nWe collected data through an online survey. While the use of a crowd-sourcing platform enabled quick recruitment and participant screening, it also introduced potential self-selection bias at the platform and survey level as is often the case for other types of digital user-generated data [109]. These biases were partially mitigated by recruiting a sample representative of the general adult population in key demographic variables. Nonetheless, our study sample was not a random sample, and caution should be heeded when generalizing the findings. Furthermore, while our sample size was consistent with related literature [30] and suitable for measuring population-level effects based on power analysis, a larger sample size may have been able to better detect within-group differences and smaller effects.\n\nDue to the cross-sectional nature of our data, causality can only be tentatively inferred based on theory and prior evidence. A longitudinal design would be instrumental in addressing this limitation by tracking the outdoor recreation-mental health relationship through a stressful event while accounting for potential confounders [48]. Specifically, our results may be susceptible to two issues: (1) seasonal effects, as the generally low outdoor recreation participation rates during winter could mask our findings [37], and (2) self-report bias associated with retrospective reports, which may be overcome by measuring real-time engagement.\n\nThe mental health benefits of nature exposure are well established [25,92], particularly as a result of the interplay between psycho-physiological effects from viewing natural features, increased physical activity, and fostered social interactions [18,99,100]. As a primary and direct form of nature contact, outdoor recreation provides an important pathway for maintaining or improving human health and well-being. In the context of COVID-19, outdoor recreation was most frequently performed in the convenience and relative safety of near-home outdoor spaces. This study highlights the critical role of adaptive outdoor engagement in protecting against poor mental health and the importance of frequent outdoor recreation in maintaining well-being. Meanwhile, our observation of a common reduction in outdoor recreation among U.S. adults during the pandemic, particularly among racial minorities, younger adults, and people perceiving worse financial conditions, raises concerns about the persisting effect of structural inequity in people’s ability to engage in outdoor recreation as a health behavior. We urge researchers, policymakers, and land managers to invest in promoting outdoor recreation engagement as vectors for health equity, including facilitating the maintenance of outdoor recreation during future enduring crises or similar events.\n\nCorrelation matrix of all variables included in linear regression models examining mental health. Outdoor recreation was abbreviated to OR. Dichotomous variables were dummy coded. *p-value < 0.05; **p-value < 0.01; ***p-value < 0.001.\n\nhttps://doi.org/10.1371/journal.pone.0321278.s001\n\n(DOCX)",
    "category": "economics"
  },
  {
    "title": "Should I stay or should I go—Medical assistants´ experiences and coping with patient demand and lack of appreciation during the Covid-19 pandemic",
    "authors": "Anastasia Suslow, Kathrin Schlößler, Nino Chikhradze, Romy Lauer, Michael Pentzek, Achim Mortsiefer, Horst Christian Vollmar, Ina Carola Otte, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320953",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320953",
    "content": "This article explores the psychological burden experienced by medical assistants (MAs) in General Practices during the Covid-19 pandemic (Corona virus disease 2019 (SARS-CoV-2)) in Germany. The study aims on demanding patient behavior, increased workload, and the perceived lack of appreciation and discuss their potential impact on the MAs´ well-being and career decisions.\n\nA qualitative approach was utilized. MAs were included via a regional practice network as well as professional associations and newsletters. In total, 21 interviews with MAs from various federal states in Germany were conducted between April and September 2021. The semi-structured interview guideline focused on daily work challenges during the pandemic and its consequences. Interviews were recorded, transcribed, and analyzed using qualitative content analysis according to Kuckartz.\n\nThe findings highlight core challenges, including demanding communication with patients, lack of appreciation in the media, a high workload, resilience versus career migration, and the needs and wishes of MAs in their everyday work. Abusive language, insults, and theft of materials by patients added significant stress. The interviews reveal how important teamwork and a supportive working environment are for overcoming these challenges.\n\nThe study underlines the urgent need for societal and political awareness regarding the challenges faced by MAs, especially during public health crises. The perceived social egoism in patient behavior, coupled with a lack of recognition and appreciation, contributed to a challenging work atmosphere and potential burnout risk. Recommendations include enhancing support for MAs, recognizing their contributions in the media, and fostering collaborative efforts between practitioners and policymakers to address the unique challenges in general practices.\n\nGerman Register of Clinical Studies (DRKS) DRKS00032402;https://drks.de/search/de/trial/DRKS00032402(Registration Date: 14.08.2023)\n\nCitation:Suslow A, Schlößler K, Chikhradze N, Lauer R, Pentzek M, Mortsiefer A, et al.  (2025) Should I stay or should I go—Medical assistants´ experiences and coping with patient demand and lack of appreciation during the Covid-19 pandemic. PLoS ONE 20(4):\n           e0320953.\n        \n        https://doi.org/10.1371/journal.pone.0320953\n\nEditor:Othman A. Alfuqaha, The World Islamic Sciences and Education University, JORDAN\n\nReceived:June 18, 2024;Accepted:February 27, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Suslow et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and itsSupporting Informationfiles.\n\nFunding:This study was financially supported by Ruhr University Bochum in the form of a research grant (F1003-2020), via FoRum (Research Funding of the Medical Faculty of the Ruhr University Bochum), received by the Institute of General Practice and Family Medicine (AM RUB), Ruhr University Bochum. No additional external funding was received for this study. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:I have read the journal's policy and the authors of this manuscript have the following competing interests: Kathrin Schlößler is an employed doctor in a general practitioner's practice from whose practice MA were interviewed for this study. As an employed GP, she also worked as a trial physician in a study under the German Drug Law (sponsored by Lilly). She received her regular salary as an employed doctor and received no compensation or expense allowance from the sponsor. This does not alter our adherence to PLOS ONE policies on sharing data and materials.\n\nAbbreviations:Covid-19,\n            Corona virus disease 2019 (SARS-CoV-2); MA,\n            Medical Assistant; PIPER,\n            Pandemic Management in General Practice - Experience and Reflection.\n\nDuring the Covid-19 pandemic (Corona virus disease 2019 (SARS-CoV-2)), the tasks and workload of all medical professions and facilities increased enormously.\n\nWhile many studies explored the impact of the pandemic on hospitals, nurses and physicians in general, little focus was set regarding medical assistants (MAs) in General Practice and Family Medicine.\n\nIn Germany, MAs have a crucial role in General Practice. Usually, they are the first point of contact for patients [1]. Further tasks, depending on their role in practice, the scope of their vocational training and additional further qualifications, are practice management and patient care such as vaccination, taking blood samples and technical examinations such as electrocardiograms or lung function tests. However, unlike physician assistants who have graduated from university, they do not perform routine-consultations on their own [2].\n\nDuring the peak of the Covid-19 pandemic from spring 2020 to summer 2021, the number of patients in general practices increased. The practices experienced high numbers of infections, and the workload of vaccinations against Covid-19 was added to the regular tasks of MAs. With MAs being figuratively also considered primary caregivers for the many patient concerns, MAs were facing many different stressors such as demanding patients, a high workload and high flexibility [3] and exposition to the risk of infection, specially before the vaccination was available. Indeed, MAs belong to the professions most frequently infected with Covid-19 [4].\n\nThe scope of the present PIPER study (Pandemic Management in General Practice – Experience and Reflection) was MAs’ perception during the peak of Covid-19 in Germany. In another article, we highlighted the challenging organization of Covid-19 vaccinations on behalf of the MAs. In this article, we present partial results of this study on how MAs perceived patients’ challenging behavior, how they dealt with it, and what consequences they drew.\n\nA qualitative approach in the form of interviews was chosen to enquire about all aspects of MAs´ experiences. The individual methodological steps and the researchers’ approach are presented below.\n\nOn April 1st, 2021, we contacted 275 General practices associated with the network of the Institute of General Practice and Family Medicine (AM RUB) at the Ruhr University Bochum, North Rhine Westphalia, Germany. First, we contacted them in written form and then tried to contact them by phone. Because of the poor response rate (probably due to the high workload during the Covid-19 pandemic) we revised our recruitment strategy [5]. In June 2021, we advertised the study via newsletters from professional associations for MA training such as VERAH (Versorgungsassistentin in der Hausarztpraxis/ Supply assistant in general practice) and the General Practitioner Association, as well as via HAFO.NRW, which is a network of General Practitioner research practices [6,7]. In addition, we used snowball recommendations from already interviewed MAs. Inclusion criteria were professional employment in a general practice as a medical assistant (MA) or in practice management and willingness to participate. We planned to conduct approximately 25 interviews before assuming thematic saturation [8,9]. After 21 interviews on September 22nd, 2021, it became apparent that the thematic saturation had already been reached, after the content was repetitive in the last interviews [8,9]. Therefore, the recruitment was concluded at this point.\n\nWe conducted the interviews using a semi-structured interview guideline allowing for natural course of the conversation. The guideline was based on a previous literature review [10] and focused on the daily work tasks of MAs. It was divided into four main topics: situation comparison, pandemic course, support, and outlook. Each topic contained keywords for further discussion (seeTable 1). Additionally, the MAs were asked to fill out a short set of standardized questions from a questionnaire on socio-demographic characteristics (e.g., age, professional experience in years) and return it to the interviewer.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320953.t001\n\nThe interviews were conducted between April and September 2021 exclusively by telephone for reasons of participants’ convenience, safety, and uncomplicated access by AS, a sociologist, with a focus on qualitative research and concise interviewing experience, in a personal conversation between interviewer and interviewee. On average, all interviews lasted 32 minutes with a range of 17 to 50 minutes. Throughout the interviews, the interviewer (AS) followed the semi-structured interview guideline and therefore was guided by the statements of the MAs and adapted the questions and the structure of the interview accordingly, which led to a predominantly open and narrative interview. MAs did not know about the topics of the interview guideline beforehand. The MAs were granted the opportunity to talk about their feelings and experiences, which led to a high density of topics and statements. For this reason, we decided to consider the results in broad categories and to publish them according to focus. [11]. All interviews were audio recorded. An external transcription agency transcribed the interviews verbatim and pseudonymized them. The MAs did not receive any compensation for the interviews.\n\nWe analyzed the interviews according to Kuckartz’ qualitative content analysis [12] with the software MAXQDA [13]. The first three interviews were coded openly, these were then correlated with the results of the literature and discussed with other researchers to develop the subcategories and main categories. This research group met regularly to discuss open questions and finalize the coding process. Initially preliminary categories were derived deductively from the guideline. During the coding-process additional inductive categories emerged resulting in a final coding tree [12,14].\n\nAll interviews were coded using the final coding tree of AS (please see appendix Material); discrepancies were resolved in discussion with ICO, HCV, KS, and NC as supervisors according to a consensual approach. The authors are health scientists, nursing scientists or sociologists, General Practitioners, and medical ethicists with a qualitative focus and/or experience in analyzing interprofessional collaboration. The original quotes were translated from German into English by the authors. Translations were double checked by also translating them back from English into German.\n\nAll participants received and signed an information sheet that included a privacy statement and an informed consent form. In addition, they had the opportunity to ask questions verbally or in writing. Written informed consent was obtained. A positive ethics vote of the Ethics Committee of the Medical Faculty of the Ruhr University Bochum has been obtained for this study (20-7010). All methods were performed in accordance with the relevant guidelines and regulations of this ethics committee. The study was conducted in accordance with the criteria of the Declaration of Helsinki.\n\nA total of 21 MAs were interviewed by telephone over a period of six months.Table 2summarizes sociodemographic and professional characteristics of the participants. Most participants were female covered a broad spectrum of age and professional experience.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320953.t002\n\nDuring the analysis of the interviews, one main category (or focus) quickly evolved: “social egoism”. We defined “social egoism” as a demanding and aggressive attitude among patients. In the following, we were able to identify four main categories in total. On the one hand, as just described above, one of the most significant categories of this manuscript: 1) demanding patients and social egoism, but also 2) (lack of) appreciation and high workload of MAs, 3) resilience vs. migration and 4) needs and wishes in everyday work, which are explained in more detail below. The following results represent the opinions of the MAs in direct quotes in quotation marks. The authors’ interpretations are given before and after the quotes.\n\nDuring the pandemic, it seems that MAs made experiences with demanding patients and social egoism that frightened them and let them question their view of the world and humanity as a whole. Additionally, the MAs only had the current media (television, radio, newspaper, Internet) as a source available, as changes of the hygiene concept and regulations made by the government, or superior institutions were not passed on to them in a timely manner. This meant that they had the same level of information as their patients. Further stress was provoked by the governmental communication strategy. In Germany, stakeholder, e.g., politicians often disseminated their statements regarding regulations such as recommended vaccinations or priority in the media. The MA felt as “the last to know” as they often only had this media statements as a source for current practice recommendation:\n\nMA-11: “We sometimes already didn’t know what to do in the morning. [...] [We had to] check by e-mail to see what new information was available [...]. It was constantly changing, the PCR tests, the rapid tests, how to invoice them, whom and what how to test. Who has to go into quarantine when entering from this country or that country? [...] A colleague of ours often arrived half an hour early and checked first: What’s new today? How should we proceed? Because if the patients come and ask, we should at least know. And I really wish we’d always been given this information in advance so that we didn’t have to deal with it ourselves.”\n\nHowever, statements (e.g., preference for vaccinating younger target groups) could not always be fulfilled, and the regulations were frequently amended and adapted. MAs find themselves in a difficult situation in which it is often difficult to meet patient expectations:\n\nMA-04: “So all these promises that came from the politicians, which then of course also went through the media, that the patients naturally thought ‘Oh, huh? But that’s what they said’, and unfortunately, we now face the situation and have to say ‘I’m sorry, we can’t do it, unfortunately, it doesn’t work the way they said it would’. We’re basically right in the middle, this in-between part, and it’s a bit difficult to deal with, so sometimes people say that they just don’t understand.“\n\nMA-05 expressed concern that the pandemic has led to a change in values and with an increasing social egoism:\n\nMA-05: “There is no respect anymore, this disrespect. It’s just this self-centeredness; people no longer look out for each other. […] I know that humanity is changing, that’s not a thing at all, but in such a short space of time, where everyone is just ‘me, me, me’ and they’re just elbowing and-, I find that enormously frightening. And I don’t think we’re on the right track. I could never have imagined that this human aspect, this thing that makes us human, this talking to each other or treating each other with respect, could fall by the wayside like this.“\n\nIn some cases, MAs have also experienced personal insults. The behavior of some patients was considered inappropriate and difficult to deal with by the MAs:\n\nMA-14: If someone says to me ‘You stupid nut’ or ‘You old sod’; what I have to listen to or what we have to listen to, that is a personal form of address, of course, we take it personally. [...] And- and then you simply can’t stop that. And then you can’t be generous about it either. That’s behavior that’s not appropriate - and that’s it. “\n\nThis was especially the case regarding vaccination. For MAs the perceived pressure regarding vaccinations was high:\n\nMA-01: “So it’s mostly about the vaccinations, people want to be vaccinated as soon as possible, no matter how old they are, or how ill they are. They want to be preferred, [...] sometimes you actually have to reprimand them, i.e., you have to end the conversation if the attitude doesn’t change straight away. So [...] the tension is increasing in that regard. “.\n\nOne MA also reported that disinfectants and protective equipment had been stolen from the surgeries, leading to shortages. This forced the medical staff to take security measures:\n\nMA-05: “And [...] we also had to make sure that we locked it away properly because the patients took disinfectant with them. They took masks with them, they took everything they could possibly need […].“\n\nThe challenging behavior of patients led to enormous psychological stress, which has built up, particularly over the first two coronavirus years 2020-2021.\n\nOverall, the quotes show how communication with patients and increased expectations have become a significant stress factor for MAs.\n\nParticipants stated to not feel sufficiently appreciated. The MAs worked overtime during the pandemic, often far beyond their regular working hours:\n\nMA-07: “None of us managed to say ‘Well, work is over, I’m going home now, it’s my right’. No, the waiting room was packed and the patients had to be looked after. (-) And we also sympathized with some of the patients who were fighting to survive. And when the wife sat there and cried because she thought her husband wouldn’t come back from ICU, you don’t say ‘Well, I’m off to buy toilet paper.’ Yes, of course, you listen to what the poor woman has to say. “\n\nMA-08: “I’ve often said that I do something completely different, my job has become a completely different one, yes. [...] For example, I’ve also increased my job, I used to work 25 hours, now I work full time.”\n\nDuring the interviews it was emphasized that there was an imbalance in the distribution of appreciation and media and public attention:\n\nMA-07: “Everyone was talking about nurses. ‘The poor ones’ and ‘They’re saving the country’ in other words ‘single-handedly’. Nobody thought about the medical assistants in general practices. Nobody said a word about the fact that we sometimes worked 14 hours! Quite the opposite: they said, ‘What, you’re already getting off work? “\n\nAccordingly, MAs expressed the desire for more recognition from politicians. In Germany, many health care professionals received a governmental “corona bonus”- However, this was not the case for MAs. They hoped that politicians will take their commitment into account and appreciate it more in the future:\n\nMA-03: “Yes, somehow more recognition from politicians perhaps, that there would be some kind of […] co-payments or - that’s somehow always the case with politics, that they say, well, it’s not just geriatric nurses, medical assistants have also had a hard time, I would like to see that somehow, in the future, that they are also kept more in mind.“\n\nIt seems that there is a need to recognize other groups within the medical workforce and not just focus on specific professions. Without the appreciation required above, MAs develop strategies to deal with such situations. This can involve resilience but also turning away from the current profession, as shown in the next section.\n\nDuring the Covid-19 pandemic, many MAs have taken the opportunity to reflect on their professions. The challenges and changes coming along with this unforeseen situation led them to reflect on the meaning of their profession and how they perceive their work:\n\nMA-06: “ And during that time, I came to the conclusion that I wanted to do something else. I then started further training and - yes, I’ve now become a freelancer and will soon be working a little less as a medical assistant, I can honestly tell you.“\n\nAnother MA described how patients were often abusive. She emphasized the stress this placed on medical staff and expressed concerns about recommending the medical assisting profession to others due to this stress:\n\nMA-14: “The patients are simply really abusive, both in their choice of words and in the tone of their voice. And these are all things that can’t (-) go on like this. We’ve been listening to this for a year now, and it’s just miserable. I spoke to a few young girls at our sports club, and I said ‘You can be anything, just don’t become a MA. For God’s sake, find something else’. [...] You can’t recommend this job to anyone with a clear conscience. It’s no longer possible.“\n\nAnother MA was concerned about the risk for her own health:\n\nMA-14: “Hm, I thought it was - yes, very, very threatening. And then one of our supervisors said, ‘Well, if you’ve taken on the job as a medical assistant - I learned that 30 years ago - you had to know that you’d get into a situation like this’. No, I couldn’t have known that 30 years ago And I also told him ‘If I would have wanted that, I would have gone to the Congo and cared for Ebola patients there’. But I don’t want that kind of thing.“\n\nWhile supervision might be a means to foster resilience, this MA felt not taken seriously in her sorrows. Contrary, a strong team and informal communication between the colleges were helpful in coping with the situation according to one MA. Despite the extreme situations, some teams were able to come even closer together. Solidarity was mentioned as an important element in difficult times:\n\nMA-07: “And that a good team is important, that you can get along with each other even in difficult situations. Because if you have someone who says ‘Oh come on, we’ll get through it’ when things aren’t going so well, that makes a big difference. It’s not like everyone is a lone fighter and nobody in the team cares how the other person is doing.“\n\nMA-01: “We stick together even more than before. Quite simply, we have become even more united as a result of the whole thing because we absolutely know how we can rely on each other. Even in these extreme situations that have arisen.“\n\nOverall, the quotes show the resilience of MAs in times of stress and uncertainty. At the same time, individual considerations for career changes due to the pressures in the medical field and resentfulness were presented.\n\nIt was highlighted that in uncertain situations, such as the emergence of new vaccines during the pandemic, a point of support would have been important:\n\nMA-06: “[...] having such a support point would have been nice. When things like that happen, there really is someone somewhere who can answer questions explicitly. Because even our doctors couldn’t say ‘This vaccine is for you or that one’, it was all too new and too recent and no one really knew that, right?“\n\nThe MA urged more targeted support and suggested working participatory with practices to gain direct insight. Politicians were encouraged to experience day-to-day practice life to understand the feasible challenges and provide realistic support:\n\nMA-11: “You don’t even see what services the MAs provide at the front, always at the front, they are always - yes, the cannon fodder, to put it bluntly (laughing), right? Every sick person, every patient, whether corona yes/no, arrives here first, right? And to handle all that, to manage it - you had to be very flexible; and I would have wished for a little more recognition from the side - yes, maybe a little more recognition.“\n\nMA-04: “Perhaps they should simply take a look at everyday life (-) in a completely normal, ordinary practice so that they can have a say and so that they know what they are talking about: What does everyday life look like? How is it structured? Can I do that? Can I still get funding, or can I support them in some other way?”\n\nThe quotes show the need of MAs for clear communication, targeted support, and recognition for their daily efforts. It is pointed out that politicians and decision-makers should understand more clearly what everyday life in medical facilities looks like to provide appropriate support.\n\nThe presented qualitative study evaluated the MAs perceptions during the peak of the Covid-19 pandemic in Germany and will be discussed below with already published articles. It gives us deep insights into the MAs-patient relationship during the pandemic and addresses several ethical issues.\n\nIn general, it became apparent that the daily work of MAs has been energy-sapping during the pandemic. The MAs reported on the chaos in the daily organization, the anxieties of all involved and their collective trauma. It was not only the statements not kept by politicians and the unstructured, often equivocal communication by the media that caused demotivation in the everyday work of the MAs, but also the increased expectations and associated frustration when patients’ expectations were not met during the Covid-19 pandemic [15]. Patients demanded more and were more impatient if their expectations could not be met quickly enough [1,15].\n\nThe high expectations of patients were also reflected in their egocentric behavior and disapproval of patients when MAs did not immediately provide all information and could not answer all questions, even if they could also only obtain their information from the media [1]. Furthermore, the MAs also had to deal with demanding attitude from patients and stolen material, so some practices attempted to employ security staff, as reported above. The behavior of the patients put pressure on the MAs, but it should be considered that the patients were also exposed to enormous uncertainties. It must be kept in mind that the patients also showed fear of the emerging virus and often did not demand to be prioritized out of malice [16,17]. The pandemic was a threatening time, and people wanted to protect themselves and their relatives. In addition, patients had to deal with the possible consequences of a Covid-19 infection, which for many were not yet predictable.\n\nThe working conditions of MAs have already been problematic due to their high workload and different tasks with overtime work and low salaries [1,18], but with the onset of the Covid-19 pandemic and especially the vaccination campaign, they worked a lot of overtime that was not compensated [1,15]. Although they represented a significant part of the protective wall that shielded the clinics from being overloaded, they criticized that they were simply not appreciated enough, unlike the nursing staff, who were praised in the media [19–21]. Studies also show that other healthcare workers, such as nurses, doctors and especially primary contact personnel who have first contact with patients, are also affected by stress, an increased workload and difficult patient contacts [22–24]. Nevertheless, the MAs criticized in the interviews that they felt “not seen”.\n\nThe increased workload, which is intensified by a lack of appreciation, is particularly detrimental. Job satisfaction is influenced by working hours and high workload as well as lack of appreciation and insufficient salary [25–28]. In such stressful situations, healthcare staff tend to be absent due to illness more often or are completely overwhelmed with their work, as previous studies on epidemics have shown [29]. At the beginning of the pandemic, 10.9% of healthcare workers (especially doctors and nurses) were already considering changing careers [27,29,30]. It is uncertain what the situation was explicitly like for MAs. However, according to our interviews, MAs are considering career changes due to the challenges of their work during the pandemic.\n\nTo avoid this situation, employers need to recognize stressed employees and offer interventions that at best have been documented previously in a kind of crisis plan. Many practices were able to learn from the past situation and draw up individual recommendations for action. In the future, extraordinary stressful situations may continue to occur, for which employers and MAs should prepare in collaboration. Appreciation from employers and support from the management are also important factors in counteracting work overload [29]. Our study also showed that appreciative interaction between employees and an overall supportive working environment has an encouraging influence and can make a big difference in everyday work. This can create a sense of togetherness and prevent all employees from struggling alone, thus creating resilience and enabling a rapid recovery of mental health [29].\n\nIn crises, centralized information points must be created where patients can obtain information so that their fears and concerns can be allayed. In addition, politicians and the media should only release information as soon as it is considered reliable. Releasing information prematurely, which may have to be revised later, unsettles the population, and can lead to anxiety and frustration, which is later taken out on the MAs. Most recently, the many strikes by MAs under the leadership of the Association of Medical Professions (Verband Medizinischer Fachberufe e.V.) in Germany, showed how important reasonable framework conditions are to MAs within their profession [31]. Many MAs pointing out demanding and aggressive patients in social media also shows how society’s attitude should change so that general practices do not face a flood of layoffs in the future.\n\nRecommendations for future improvements include enhancing support for MAs, recognizing their contributions to the media, and fostering collaborative efforts between practitioners and policymakers to gain insights into the daily challenges of medical facilities. Additionally, creating a more supportive and appreciative work environment, with a focus on teamwork and resilience, can contribute to the well-being of MAs.\n\nThe results of our study shed light on the significant challenges faced by MAs during the Covid-19 pandemic, particularly in general practices.\n\nThe pandemic exacerbated existing difficulties in the daily work of MAs, with increased demands, unstructured communication from the media, and a surge in disrespectful behavior from patients. Patients exhibited more impatience and egocentric behavior, adding to the burdens faced by MAs. Additionally, incidents of abusive behavior and theft of materials further strained the work environment, prompting some practices to consider security measures. Despite their critical role in maintaining healthcare services, MAs felt undervalued and unappreciated, especially in comparison to other healthcare professions. The lack of appreciation, coupled with increased workloads and stress, contributed to concerns about burnout and career changes or participating in retraining measures among MAs.\n\nOur PIPER study highlighted the broader societal shift towards self-centered behavior, with patients displaying increased demands and impatience, often fueled by misinformation from the media. The study underscored the importance of acknowledging and addressing the psychological burden faced by MAs, as their well-being directly influences the quality of patient care.\n\nTo address these challenges, employers and policymakers must recognize the importance of supporting MAs and provide intervention strategies to mitigate stress and workload. Centralized information points for patients and improved communication from politicians and the media can help alleviate uncertainties and reduce tensions in medical settings.\n\nEfforts to promote a supportive and appreciative working environment and initiatives to encourage collaboration between General Practitioners and policy makers are essential to improving the quality of working conditions for MAs. By acknowledging their contributions, providing targeted support, and promoting resilience, we can ensure the continued effectiveness of healthcare systems and the overall well-being of MAs.\n\nThe following three main points could represent concrete measures to address the challenges mentioned in this article:\n\nThe role of practice owners and associations of statutory health insurance physicians should not be underestimated when it comes to shaping the working conditions of medical assistants. Practice owners are directly responsible for determining how the working environment and conditions look on a day-to-day basis. Through fair pay, regular training, and psychological support, they can help to ensure that employees feel valued and do not burn out. At a political level, the associations of statutory health insurance physicians have the task of advocating for the rights and interests of MAs, particularly regarding working hours, overtime pay, and the quality of training opportunities. Close cooperation between practice owners and statutory health insurance physicians’ associations can achieve a sustainable improvement in working conditions that benefits both the MAs and the patients.\n\nA significant strength of this study is the timing of the interviews. Between April and September 2021, the first wave of Covid-19-vaccination was conducted in general practices. This allowed us to learn just in time about the daily work and struggles of MAs as well as their experiences with aggressive patients, which gave us deep insights into MA-Patient relationship during the pandemic. The content of the interviews conducted during this period was extensive and detailed, as the MAs generously shared their experiences and unfiltered emotions despite their increased workload in the practices.\n\nHowever, a limitation of this study relates to the fact that only MAs who volunteered to participate in the study were interviewed. Therefore, it can be assumed that only individuals who had an interest in the thematic content and were willing to talk about it shared their insights.\n\nhttps://doi.org/10.1371/journal.pone.0320953.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0320953.s002\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0320953.s003\n\n(PDF)",
    "category": "economics"
  },
  {
    "title": "The spillover effects of Medicare’s comprehensive care for joint replacement (CJR) model in California",
    "authors": "Narae Kim, Mireille Jacobson, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0319582",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319582",
    "content": "The Comprehensive Care for Joint Replacement (CJR) model, a bundled Medicare payment for lower extremity joint replacement (LEJR), was initially randomized across the United States, providing a unique opportunity to study the broad impact of this alternative payment model. This study aimed to determine the spillover effects of the CJR model on older patients in California covered outside of the traditional Medicare program. The study analyzed hospitalizations for hip and knee joint replacement in California between January 2014 and December 2017 from the California Patient Discharge Dataset. The study used event study and difference-in-differences models to estimate changes in discharge-related outcomes in hospitals in treated and control areas before versus after CJR implementation (April 2016). Main outcomes were hospital length of stay and home discharge rates. All LEJR patients admitted to the treated or control hospitals were included in the study regardless of their primary payers. Of 312,914 analyzed LEJR hospitalizations (mean [SD] age, 68.3 [11.3] years; 189,575 [60.6%] women; 15,374 [4.9%] black), 113,590 (36.3%) were covered by traditional Medicare (TM), 83,277 (26.6%) were covered by Medicare Advantage (MA), and 116,047 (37.1%) were without Medicare coverage. After program implementation, TM and non-Medicare patients in treated hospitals experienced reductions in length of stay (-4.0% & -1.0%, p < 0.05) and TM, MA and non-Medicare patients in treated hospitals experienced increases in home discharge rates (3.4%, 4.7% & 2.3%, p < 0.001) relative to patients in untreated hospitals. CJR affected health care for non-targeted populations. Evaluating the program based on traditional Medicare beneficiaries alone does not capture the entire effect of the program on older adults.\n\nCitation:Kim N, Jacobson M (2025) The spillover effects of Medicare’s comprehensive care for joint replacement (CJR) model in California. PLoS ONE 20(4):\n           e0319582.\n        \n        https://doi.org/10.1371/journal.pone.0319582\n\nEditor:Yu-Chi Tung, National Taiwan University College of Public Health, TAIWAN\n\nReceived:September 26, 2023;Accepted:February 4, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Kim, Jacobson. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:This study analyzed California’s Patient Discharge Data (PDD) provided by the California Department of Health Care Access and Information (HCAI) for all hospitalizations for major hip or knee joint replacement (MS-DRG 469 and 470) from 2014 to 2017. The dataset contains comprehensive information on patients admitted to hospitals in California, such as the admitting hospital, admission and discharge dates, patient’s age, race, and primary diagnosis and discharge disposition (e.g., discharged to home or a skilled nursing facility), irrespective of the payer. To use the dataset, the authors obtained approval from the Committee for the Protection of Human Subjects (CPHS) at the California Health and Human Services. Protocol ID: 2022-205 Protocol Title: The Spillover Effects of Comprehensive Care for Joint Replacement (CJR) Model: A Study from California The authors confirmed that they received approval from CPHS to access the data. To gain access to the data, please follow the steps below: 1) Create a data request from HCAI data request portal (https://datarequest.hcai.ca.gov/csm) 2) Submit a protocol for IRB review from CPHS (https://www.cdii.ca.gov/committees-and-advisory-groups/committee-for-the-protection-of-human-subjects-cphs/) *Contact information for the California Department of Health Care Access and Information: Phone (916) 326-3800 Office 2020 West El Camino Avenue, Suite 800, Sacramento, CA 95833\n\nFunding:This study was supported by a Haynes Lindley doctoral dissertation fellowship from the Haynes Foundation and grant 1R01HS026488-01A1 from the Agency for Healthcare Research and Quality. There was no additional external funding received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nLower Extremity Joint Replacement (LEJR) is one of the most common treatments received by Medicare beneficiaries, accounting annually for about 5% of both admissions and inpatient spending [1]. In April 2016, the Center for Medicare and Medicaid Services (CMS) introduced the Comprehensive Care for Joint Replacement (CJR) model to evaluate whether a bundled payment could reduce the overall cost of care for LEJR in traditional Medicare. In place of fee-for-service payments, the CJR model provides a bundled payment for an episode of care and compensates hospitals that meet target spending and a minimum quality score via a reconciliation payment [2]. Importantly, the bundle includes not only inpatient care but also LEJR-related care received 90 days post-discharge [2].\n\nAnother distinctive feature of CJR is that it was implemented based on a randomization process. CMS randomly selected 67 Metropolitan Statistical Area (MSA) from across the country for mandatory participation in the payment model in 2016. All hospitals in these MSAs, with the exception of those participating in the Bundled Payments for Care Improvement (BPCI) initiative for LEJR treatment, were required to participate in CJR and were reimbursed for total hip and knee replacements based on a bundled payment. The mandatory nature of these bundles was controversial, and in 2018, hospitals in 33 MSAs were given the option to opt out of the program; the 34 MSAs that historically had the highest episode spending had to remain in the program [3].\n\nTo date, multiple studies have examined CJR and demonstrated its success in traditional Medicare. CJR reduced the average cost of an episode of care to Medicare [4–9]. Savings were driven primarily by reduced utilization of institutional long-term care; a larger proportion of patients were discharged to home, with or without services from home health agencies. Hospital readmission rates, ambulatory care utilization, mortality, and markers of the quality of care were unaffected [10,11].\n\nAs one of the largest payers, Medicare has the potential to broadly affect the market for health care. Some work has considered the “spillover” effects, or indirect effects of the policy beyond its intended target, of the CJR model [12,13]. Specifically, past work has analyzed the CJR model’s effect on untargeted insured groups – Medicare Advantage (MA) patients, who are covered by private insurance plans that contract with the Medicare program, and patients with commercial insurance plans outside of Medicare. However, studies of the spillover effects of CJR have come to conflicting conclusions. Some studies have found that the share of MA patients discharged to institutional care after a hip or knee replacement decreased in treated relative to control MSAs [1,14]. A study of hospital discharge data from Florida, one of the highest spending areas in the country, found substantial spillover effects of CJR on home discharge rates for MA and commercially insured LEJR patients as well as for patients who went through non-LEJR procedures [15]. In contrast, two studies using claims data from the Health Care Cost Institute found no evidence of CJR spillovers to MA patients or commercially insured patients receiving LEJR [16,17].\n\nIn this study, we examined both the direct and spillover effects of CJR using hospital discharge data from California. We examined changes in health care service utilization associated with the program on three patient groups: traditional Medicare (TM) patients, who were subject to CJR, as well as Medicare Advantage (MA) and non-Medicare patients, both of whom were not subject to CJR. Since California accounts for over 10% of Medicare beneficiaries in the United States [18] with considerable racial, ethnic, and socioeconomic diversity, understanding the impact of CJR in the state is of direct importance. Given the conflicting literature, the primary goal of this work was to contribute to our understanding of the spillover effects of CJR on untargeted populations.\n\nThis study analyzed California’s Patient Discharge Data (PDD) provided by the California Department of Health Care Access and Information (HCAI) for all hospitalizations for major hip or knee joint replacement (MS-DRG 469 and 470) from 2014 to 2017. The dataset contains comprehensive information on patients admitted to hospitals in California, such as the admitting hospital, admission and discharge dates, patient’s age, race, and primary diagnosis and discharge disposition (e.g., discharged to home or a skilled nursing facility), irrespective of the payer. The authors had no access to information that could identify individual participants during or after data collection.\n\nThe study protocol was approved by the State of California’s Committee for the Protection of Human Subjects (CPHS) and the University of Southern California’s Institutional Review Board. California’s CPHS waived informed consent based on the infeasibility of obtaining consent as well as the minimal risk of causing harm. The results were reported using the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) reporting guideline.\n\nHospitalizations for three different patient groups were studied: traditional Medicare (TM), Medicare Advantage (MA), and non-Medicare patients. We limited Medicare beneficiaries to those ages 65 and over, assuming that those who are under the age of 65 but receive Medicare benefits would have other medical conditions that could bias our estimation. For the non-Medicare patient group, we limited the sample to those ages under 65 to only include non-targeted younger adults for a clearer comparison. In California, three MSAs – San Francisco-Oakland-Hayward, Modesto, and Los Angeles-Long Beach-Anaheim – among 26 MSAs were mandated to participate in the CJR model in 2016 and 2017. Thus, the treated group included LEJRs at hospitals in the three participating MSAs regardless of their primary payer. The control group included those at hospitals in the other 23 MSAs. LEJR hospitalizations from 37 hospitals participating in the BPCI initiatives were excluded from both treated and control groups. In addition, hospitalizations without information on primary payer were excluded.\n\nOur primary outcomes of interest were inpatient length of stay and discharge home, two proxies for LEJR-related healthcare service utilization. Multiple prior studies have investigated these two outcomes as the primary expected sources of Medicare savings from LEJR [4,5,7–9]. Therefore, changes in these outcomes were analyzed to measure direct and indirect effects of the CJR model. For inpatient length of stay, we used the HCAI’s recommended adjusted length of stay variable, which replaced 0 days in the length of stay variable with 1 to give value to patients who were admitted and expected to stay overnight but discharged home on the same day [19]. We further applied a logarithmic transformation to the adjusted length of stay to handle the outcome’s skewed distribution. To analyze discharge status, we created a binary indicator for home discharge (1 = being discharged to home; 0 = otherwise). Home discharge included self-care at home as well as care at home from an organized home health service organization or a hospice [20].\n\nCovariates included both hospital and quarter-year fixed effects to control for time-invariant characteristics of each hospital and general trends in outcomes across California. We also controlled for demographic characteristics of patients that could possibly affect the health outcomes of interest; the demographic characteristics included age and its square, a binary indicator for female (1 = female, 0 =  otherwise), a categorical variable for race/ethnicity and MS-DRG code indicators – an indicator for comorbidities.\n\nWe estimated the impact of the CJR program using event study and difference-in-differences (DID) analysis. Both event study and DID analysis effectively control for time trends in pre-post assessments, a common health care policy evaluation method, by comparing treated and control groups before and after a treatment (i.e., policy implementation) [21]. While an event study shows temporal, relative changes in outcomes, a DID analysis provides an average, summary estimate of the changes the treated group experienced relative to the control group after policy implementation.\n\nWith the event study, we estimated quarter-year patient-level changes in the outcomes of interest – adjusted length of stay or home discharge rate – before and after CJR implementation. In (1), we show the equation for the event study:\n\nwhereis the outcome of interest (log adjusted length of stay or discharge home) for patientitreated in hospitalhin MSAmand quarter-yearq. The regression includes indicators for hospitals,, to control for fixed differences in outcomes across hospitals and indicators for quarter-year, to flexibly control for general time trends as well as a set of patient characteristics included in the discharge dataset. Our interest is inqthe coefficients on the quarter-year fixed-effects interacted with the treatment indicator for whether the MSA where the hospital was located was randomized to the CJR treatment. We omitted the interaction term for the first quarter of 2016 such that estimates are normalized to the quarter before CJR took effect. Consequently, the coefficients show the temporal difference in outcomes between treated and control hospitals relative to the reference period and allow us to assess whether our difference-in-differences estimates capture a change in outcomes that is credibly related to CJR.\n\nIn the DID models, we estimated the differential change in outcomes after relative to before policy implementation in treated relative to control hospitals. In (B), we show the equation for the difference-in-differences analysis:\n\nwhere,,andare as defined above andis an indicator that captures the interaction between the post CJR period (Q2 of 2016 and later) interacted with an indicator for the treated hospitals (i.e., hospitals located in MSAs randomized to CJR). Note that the main post-period effect is subsumed in the quarter indicators and the main MSA effects are subsumed in the hospital indicators. Our key parameter of interest is the coefficientδon, which captures the differential change in outcomes in hospitals randomized to CJR after the program was implemented compared to the change for hospitals not randomized to participate in CJR.\n\nWe conducted several sensitivity analyses to test the validity of our findings. As pre-policy trends for MA patients were generally not parallel, a condition for valid DID interpretation, we conducted analyses that added pre- and post-policy time trends to the event study and DID models for this group. Second, we employed a wild cluster bootstrap to address potential concerns about inference with a treatment (program participation) that was clustered at the MSA level but had only a small number of treated and control clusters. The wild cluster bootstrap offers a procedure based on the wild bootstrap method [22,23] but that takes into account clustering in the dataset with only a small number of clusters [24]. If a discrepancy exists, it suggests that the estimated standard errors from the main analyses may have been understated, a common issue when using clustered standard errors in settings with few treated clusters [24]. Other sensitivity analyses included DID analyses (1) without any age restrictions on the sample, (2) that controlled for admission from an emergency department (ED) to control for unobserved health differences, (3) with an indicator for Medicaid eligibility for non-Medicare patients, a measure of socioeconomic status that could impact health outcomes and (4) that limited to the period between 2015 and 2017 and used propensity score weighting to ensure balance between patients in treatment and control MSAs. Statistical results were considered significant at a confidence level of 95%. We used Stata/MP 16.1 for all analyses. Data were collected and analyzed between December 2022 and July 2023.\n\nThe total number of hospitalizations for LEJR from January 2014 to December 2017 in California was 411,004. Across all LEJR hospitalizations, 146,662 (35.7%) had traditional Medicare as the primary payer (mean [SD] age, 73.7 [8.7] years; 93,249 [63.6%] women; 5,131 [3.5%] black) while 96,411 (23.5%) had Medicare Advantage (MA) (mean [SD] age, 74.2 [8.1] years; 62,210 [64.5%] women; 5,239 [5.4%] black), and 167,905 (40.8%) had non-Medicare sources as the primary payer (mean [SD] age, 59.7 [8.9] years; 91,824 [54.7%] women; 10,782 [6.4%] black) (S1 Table in S1 File).\n\nAfter applying our sample restrictions – only including those ages 65 and over for TM and MA and those under 65 for Non-Medicare and excluding those admitted to hospitals participating in BPCI – the total number of hospitalizations included in the study was 312,914 (mean [SD] age, 68.3 [11.3] years; 189,575 [60.6%] women; 15,374 [4.9%] black). Among them, 113,590 (36.3%) were covered by TM, 83,277 (26.6%) were covered by MA, and 116,047 (37.1%) were without Medicare coverage. Among TM hospitalizations, 59,214 (52.1%) occurred after the program; 51,708 (45.5%) were from treated hospitals. Among MA hospitalizations, 37,757 (45.3%) were after the program; 41,943 (50.4%) were from treated. Among non-Medicare covered hospitalizations, 50,818 (43.8%) were after the program; 57,061 (49.2%) were from treated. Overall demographic characteristics of the patients in treated and control MSAs were not substantially different except by race. The proportion of non-Hispanic white patients was higher in the control MSAs (Table 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319582.t001\n\nPlots of the unadjusted outcomes from January 2014 to December 2017 showed that gaps in outcomes between hospitals in treated and control MSAs generally narrowed after CJR implementation (S1 and S2 Figs in S1 File). Log adjusted length of stay was higher for TM and non-Medicare patients in hospitals in treated relative to control MSAs, but the gap narrowed after CJR implementation (S1 Fig in S1 File). Home discharge rates across all patient groups were higher in control MSAs before CJR implementation, but the gap narrowed and even reversed after CJR implementation (S2 Fig in S1 File).\n\nEvent study analyses showed quarter-year changes in the logged adjusted length of stay and home discharge rates in treated MSAs relative to control MSAs (Figs 1and2). Hospitals in treated MSAs had a relative decrease in logged adjusted length of stay after CJR model implementation among TM and non-Medicare patients (Fig 1). Only MA hospitalizations had a relative increase in the length of stay in the treated MSAs. However, the increase started before the CJR model implementation, suggesting the increase was not caused by CJR policy implementation. To assess this possibility, we conducted a supplemental analysis for MA patients that included separate linear pre- and post-policy trends; adjusting for the linear time trends, the MA-covered hospitalizations in treated MSA showed a relative decrease after policy implementation (S3 Fig in S1 File).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319582.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319582.g002\n\nFig 2showed the relative quarter-year changes in home discharge rates in treated MSAs compared to control MSAs after policy implementation. All types of hospitalizations –TM, MA and Non-Medicare coverage – showed an increase in home discharge rates after program implementation. The supplemental analysis with linear time trends for MA patients showed the same trend (S3 Fig in S1 File).\n\nTable 2, panel A summarized the DID analyses results based on hospitalizations from 2014 to 2017. For the log adjusted length of stay, TM and non-Medicare hospitalizations showed a statistically significant relative decrease after policy implementation. TM patients hospitalized in treated MSAs had 4.0% lower adjusted length of stay compared to those in control MSAs (p < 0.001), and non-Medicare patients in the treated MSAs had 1.0% lower average adjusted length of stay compared to control MSAs after the policy implementation (p < 0.05). In contrast, MA patients in treated MSAs had 2.0% higher average adjusted length of stay compared to control MSAs after the policy implementation (p < 0.05,Table 2, panel A); however, in the supplemental analysis with pre and post-policy time trends, the MA-covered hospitalizations in treated MSAs had 3.0% lower average adjusted length of stay compared to those in control MSAs (p < 0.05, S2 Table in S1 File).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319582.t002\n\nDID results inTable 2, panel B were limited to hospitalizations from 2015 to 2017 as several event study analyses suggested a potential violation of the parallel trend assumption in the year 2014. Panel B also showed a relative decrease in adjusted length of stay among TM and non-Medicare hospitalizations in treated MSAs (-4.0% and -3.0%, respectively); however, the relative decrease in MA-covered hospitalizations was no longer significantly different from zero (p > 0.05,Table 2, panel B).\n\nIrrespective of payer, patients in treated MSAs experienced a relative increase in home discharge rates after policy implementation. InTable 2, panel A, TM patients in treated MSAs had 0.02 or 3.4% higher home discharge rates compared to control MSAs after policy implementation (p < 0.001). MA patients in treated MSAs had 0.03 or 4.7% higher home discharge rates, and non-Medicare patients in treated MSAs had 0.02 or 2.3% higher home discharge rates compared to those in control MSAs (p < 0.001). In supplemental analysis, MA patients hospitalized in treated MSAs showed the same trend; however, the coefficient was not significantly different from zero (p > 0.05, S2 Table in S1 File).Table 2, panel B showed similar relative increases in home discharge rates for traditional Medicare, Medicare and non-Medicare patients as in panel A (3.3%, 4.5% and 2.3%, p < 0.05).\n\nIn a robustness check of inference for the DID analyses, we employed the wild cluster bootstrap method. The results showed that the relative decrease in adjusted length of stay for TM patients and the relative increase in home discharge rates for MA and non-Medicare patients in treated MSAs compared to control MSAs after the policy implementation were still statistically significant after executing 999 replications based on bootstrap samplings with clusters. Changes in adjusted length of stay for MA and non-Medicare patients and home discharge rates for TM became imprecise after clustering (Table 2).\n\nSensitivity analyses that did not exclude patients based on age yielded similar results as our analytic sample (S3 and S4 Tables in S1 File). In addition, controlling for admission from an ED and Medicaid eligibility did not meaningfully affect the original results (S5 and S6 in S1 File). Employing propensity score weighting to achieve better balance between the treatment and control groups also generated similar results to the original findings (S7 Table in S1 File). The details of the weighting method are provided in the supplemental file.\n\nMedicare’s CJR model was designed to reduce costs and improve the quality of care for traditional Medicare patients undergoing total hip and knee replacements. Our study found that the program affected not only traditional Medicare patients but also MA and non-Medicare patients, who were not subject to the payment model. Specifically, the CJR model was associated with a significant decrease in the adjusted length of stay of TM and non-Medicare patients and a significant increase in home discharge rates of TM, MA, and non-Medicare patients. The spillover effects of the CJR policy on untargeted patient populations were supported by multiple sensitivity checks and robustness analyses. Our most robust finding was that home discharge rates increased for both MA and non-Medicare patients in treated relative to control hospitals after relative to before CJR program implementation.\n\nThis study is unique in several ways. First, we used data on all hospitalizations in California and avoided potential bias from datasets that capture only a sample of admissions. Since our dataset included all patients regardless of primary payer, we could examine the spillover effects of the CJR model on all untargeted patients - MA and non-Medicare patients. Second, we estimated both direct and spillover effects of the program in California, which is one of the most diverse states in the United States. Therefore, our study adds to current evidence on the impact of the program, by providing a comprehensive assessment of its effects in a large, varied, and complex healthcare market. Finally, the study contributes to establishing evidence of spillover effects of the program. Our research demonstrates that the program had a positive effect on untargeted patients, particularly on their home discharge rates. The finding of positive spillover effects aligns with and is of similar magnitude to studies that use comprehensive state discharge data [1,11,16] and is inconsistent with studies that rely on only a subset of health care claims data [14,15]. Overall, our study supports the view that value-based traditional Medicare payment models impact health care markets beyond their intended scope.\n\nThere are several limitations to our study. First, CJR policy randomization was conducted at the MSA, not at the individual level. This may have introduced bias due to incomplete randomization. Second, as some patient information, such as underlying health conditions, secondary payer sources (e.g., Medicaid for dual eligible beneficiaries), was not available in the dataset, our analyses may over or under-estimate the policy effect due to unobserved differences between patients admitted to treated or control hospitals. To overcome this limitation, we conducted several sensitivity analyses with more saturated models and confirmed that the results were not significantly different from the main analyses. In addition, the study period was limited to 21 months after policy implementation, as CJR changed program participation rules in February 2018. Thus, we could not consider whether spillover effects of the program persisted for many years. Furthermore, because the dataset did not include follow-up information, we could not study outcomes such as readmissions or mortality. Lastly, our study was only based on hospitalizations in California, and our findings may not generalize to other regions.\n\nIn sum, this study demonstrates that the CJR model had significant spillover effects in California. The CJR program affected not only TM patients but was also associated with a substantial decrease in hospital length of stay and an increase in home discharge rates of untargeted Medicare Advantage and non-Medicare patient groups. This finding lends support to studies showing spillover effects of Medicare’s value-based payment models.\n\nhttps://doi.org/10.1371/journal.pone.0319582.s001\n\n(PDF)",
    "category": "economics"
  },
  {
    "title": "Modeling lifetime and count data using a unified flexible family: Its discrete counterpart, properties, and inference",
    "authors": "Ahmed Z. Afify, Maha M. Helmi, Hassan M. Aljohani, Sara M. A. Alsheikh, Hisham A. Mahran, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0319091",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319091",
    "content": "In this article, two flexible classes called the modified Kavya–Manoharan-G (MKM-G) and discrete modified Kavya–Manoharan-G (DMKM-G) families are investigated. The two proposed families provide more flexibility for modeling real-lifetime and count data from environmental, medical, engineering, and educational fields. Due to the new extra shape parameter of the two proposed families, their special sub-models are capable of modeling monotonic and non-monotonic hazard rates. The basic properties of the MKM-G family are studied. Eight classical approaches of estimation are used for estimating the MKM-exponential (MKME) parameters. The performances of the estimators are explored using simulation results. Additionally, the DMKM-exponential (DMKME) distribution is defined. Finally, the importance and flexibility of the MKME and DMKME distributions are addressed by fitting seven real-lifetime and count data from aforementioned applied fields. The real data analysis shows that the special models of the two classes are good candidates and can provide close fit as compared to well-known competing continuous and discrete distributions.\n\nCitation:Afify AZ, Helmi MM, Aljohani HM, Alsheikh SMA, Mahran HA (2025) Modeling lifetime and count data using a unified flexible family: Its discrete counterpart, properties, and inference. PLoS ONE 20(4):\n           e0319091.\n        \n        https://doi.org/10.1371/journal.pone.0319091\n\nEditor:Shaiful Anuar Abu Bakar,, University of Malaya, MALAYSIA\n\nReceived:July 22, 2024;Accepted:January 27, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Afify et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All data used in this study are included in the article.\n\nFunding:The authors extend their appreciation to Taif University, Saudi Arabia, for supporting this work through project number (TU-DSPP-2024-162).\n\nCompeting interests:The authors of this paper declare no conflict of interest.\n\nRecently, several attempts to develop generalized distributions have been made to model lifetime and count data in different applied fields. These generalized models have several applications including medicine, economics, biological studies, engineering, finance, and environmental sciences, among others. However, there is a clear need for more flexible distributions, which are capable of modeling different shapes of aging and failure criteria.\n\nSome notable families are the Marshall–Olkin-G [1], Kumaraswamy-G [2], Weibull-G [3], Kumaraswamy transmuted-G [4], odd Dagum-G [5], log–logistic tan-G [6], modified generalized-G [7], logarithmic-U [8], Lambert-G [9], new exponential-H [10], and alpha beta-power-F [11], among many others.\n\nOne of the recent classes is called the Kavya–Manoharan-G (KM-G) family [12], which is used to introduce some generalized distributions include the KM Kumaraswamy distribution [13], KM log-logistic distribution [14], KM Kumaraswamy exponential distribution [15], KM Burr X distribution [16], KM power Lomax distribution [17].\n\nIn this article, we propose a flexible extension of the KM-G class by adding an extra shape parameter. The newly constructed class is called the modified Kavya–Manoharan-G (MKM-G) family, which increases the flexibility of the generated models. Furthermore, the discrete counterpart of the new MKM-G family is proposed. The discrete counterpart class is called the discrete modified Kavya–Manoharan-G (DMKM-G) family. The DMKM-G family is derived using the survival discretization (SD) approach.\n\nThe objectives of the current article are five-fold: (i) to propose two new flexible continuous and discrete families; (ii) to present four special lifetime models and a discrete model as special cases of the two proposed classes, with a more detailed analysis of the MKM-exponential (MKME) and DMKM-exponential (DMKME) sub-models; (iii) to address the mathematical characteristics of the MKM-G family; (iv) to discuss the estimation of MKME parameters using eight classical estimation approaches; and (v) to explore the empirical importance of the MKME and DMKME models through analysis of seven real-life datasets, including two count datasets.\n\nWe are motivated to introduce the MKM-G and DMKM-G families for several reasons: (i) The MKM-G special models can represent reversed-J shaped, right-skewed, and unimodal densities, as well as bathtub, increasing, modified bathtub, decreasing, and unimodal hazard rate (HR) shapes; (ii) These sub-models generalize several published lifetime models such as the KM Burr X and KM exponential models; (iii) The DMKME distribution exhibits unimodal, reversed-J, increasing, bathtub, and decreasing discrete HR shapes, making it more versatile than other count distributions, which typically only exhibit increasing or decreasing shapes; (iv) The special sub-models of both proposed classes are well-suited for modeling asymmetric lifetime and count data across various applied fields, including insurance, biology, medicine, engineering, and life testing; and (v) The empirical importance of the MKME and DMKME models is explored using seven real-lifetime and count datasets, showing that the two proposed distributions outperform several well-known lifetime and discrete distributions in modeling real-world data; and (vi) Finally, the new families offer simple analytical forms and exceptional flexibility, which may lead to wider applications in engineering, reliability, environmental sciences, insurance, medicine, and economics.\n\nThe rest of the paper is outlined in the following eight sections. In Section 2, the MKM-G and DMKM-G families are defined. Five special sub-models of the MKM-G and DMKM-G classes are presented in Section 3. In Section 4, some mathematical properties of the MKM-G class are derived. Estimation methods of the MKME parameters are discussed in Section 5. Detailed simulation results are presented in Section 6. Section 7 provides seven applications for real-lifetime and count data to show the flexibility of the MKME and DMKME distributions. Finally, some concluding remarks are explored in Section 8.\n\nIfXis a random variable (RV) following the KM-G family with parametersαandθ(see [12]), then it has the following cumulative distribution function (CDF)\n\nwhereandis the baseline CDF with a vector of parametersϑ.\n\nThe corresponding probability density function (PDF) of (1) reduces to\n\nDefinition 1.ARVXis said to follow the MKM-G family, denoted byMKM-G (), if its CDF has the form\n\nwhereθis a shape parameter.\n\nThe corresponding PDF of Equation (3) has the form\n\nThe HR function (HRF) of the MKM-G family becomes\n\nThe added shape parameterθallows us to explore the tail behavior of the density (4) and provides more flexibility as we can see in Section 3. Additionally, the importance of the MKM-G family follows from its ability to generate new flexible distributions which exhibit monotone and non-monotone failure rates.\n\nRemark:The KM-G class follows as a special case by settingin Equation (3).\n\nThe SD approach is used to discretize the MKM-G family of distributions. The SD technique depends on the survival function (SF), say,and, which can be adopted to define the probability mass function (PMF) as follows\n\nThe SF of the MKM-G family has the form\n\nApplying the SD approach in (5), the PMF of the DMKM-G family is given by\n\nwhere\n\nThe CDF and SF of the DMKM-G family is given by\n\nand\n\nThis section presents four special sub-models of the MKM-G family. These sub-models provide flexible forms of some baseline distributions namely the exponential (E), Burr X (Bx), Burr XII (BXII), and log-logistic (LL) distributions. The special sub-models of the MKM-G class are called the MKME, MKM-Burr X (MKMBX), MKM-Burr XII (MKMBXII), and MKM-log logistic (MKMLL) distributions. The four special distributions provide decreasing, bathtub, reversed J shaped, increasing, unimodal, and modified bathtub shapes. Additionally, their densities provide right-skewed, symmetrical, and reversed-J shapes as displayed in Figs 1-4. Furthermore, the DMKME model is defined in Section 3.5.Figs 5and6display the PMF and HRF plots of the DMKME model for different values of its parametersθandλ. The HRF of the DMKME distribution provides unimodal, bathtub, increasing, reversed-J, and decreasing discrete failure rates.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g004\n\nThe CDF of the MKME distribution follows by setting the E CDF,, in Equation (3). Then, the CDF of the MKME distribution reduces to\n\nThe corresponding PDF and HRF of the MKME distribution have the forms\n\nand\n\nTheRVwith PDF (7) is denoted by. For, the MKME distribution reduces to the KME distribution [12].Fig 1gives some possible shapes of the density and HR functions of the MKME distribution.\n\nBy taking the CDF of the BXII distribution (forand), say,, as a baseline CDF in (3), the MKMBXII CDF follows as\n\nThe PDF of the MKMBXII distribution reduces to\n\nFor, the MKMBXII distribution reduces to the KMBXII distribution.Fig 2gives some shapes of the PDF and HRF of the MKMBXII distribution for different parametric valuesandλ.\n\nConsider the CDF of the Bx distribution (forand), say,. By inserting the Bx CDF in Equation (3), the CDF of the MKMBx distribution follows as\n\nwhere.\n\nThe PDF of the MKMBx model reduces to\n\nBy settingin the above equation, the KMBx distribution [16] follows as a special case. The MKM-Rayleigh distribution is obtained when. The MKMBx model reduces to the KM-Rayleigh distribution forSome shapes of the density and failure rate functions of the MKMBx distribution are given inFig 3, for different values ofηandλ.\n\nConsider the LL CDF (forand), say,. By inserting the LL CDF in Equation (3), we obtain the CDF of the MKMLL distribution (for)\n\nThe MKMLL density takes the form\n\nThe MKMLL distribution reduces to the KMLL model for.Fig 4provides the shapes of the density and hazard functions of the MKMLL distribution.\n\nThe DMKME distribution is derived here by substituting the CDF of the E distribution in Equation (6), then the PMF of the DMKME distribution follows as\n\nwhere. Then, the corresponding SF and CDF of (8) reduce to\n\nand\n\nThe HRF of the DMKME takes the form\n\nThe plots of the PMF and HRF of the DMKME model are presented inFigs 5and6, for some choices of the parametersθandλ. The DMKME HRF can be unimodal, bathtub, increasing and decreasing discrete HRF.\n\nSome general mathematical properties of the MKM-G family are provided in this section.\n\nImportant and simple mixture representations for the CDF and PDF of the MKM-G family in terms of exponentiated-G (Exp-G) density are provided in this section.\n\nConsider the exponential series, which is given by\n\nApplying (9) to Equation (3), we obtain\n\nHence, the MKM-G CDF is expressed as\n\nwhereAndis the Exp-G CDF with power parameter. By differentiating Equation (10), the PDF of the MKM-G family reduces to\n\nwhereandis the Exp-G PDF with. Thus, many mathematical characteristics of the MKM-G family follow simply from those of the Exp-G family.\n\nThe quantile function (QF) of the MKM-G family, say,, follows by inverting (3). Then, the MKM-G QF takes the form\n\nwhereais the baseline QF and.\n\nHereafter, letdenotes the Exp-GRVwith positive power parameterk. Hence, based on Equation (11), therth moment ofXhas the form\n\nSettingin Equation (12) gives the mean ofX().\n\nThe moment generating function (MGF) of theRVXis defined by. Hence, the MGF of the MKM-G family can be derived from (11) in two different forms. The first one follows as\n\nwhereis the MGF of. Then,of the MKM-G family is calculated based on the MGF of the Exp-G class.\n\nThe second formula fortakes the form\n\nwhere.\n\nTheqth incomplete moment ofXis expressed based on (11) as\n\nThe first incomplete moment (FIM), say,, follows from (13) when. It also can be calculated by two formulae. The first formula forfollows from (13) as\n\nwhereis the FIM of the Exp-G class. The second formula forreduces to\n\nwhere, whereis computed numerically andis the baseline QF.\n\nBonferroni () and Lorenzcurves are useful applications forbecause they can be calculated, for a given probabilityτ, byand, whereis the mean ofXandis the QF ofXatτ. The two curves have important applications in demography, economics, insurance, reliability, and medicine. Additionally, the mean deviations about the meanand about the medianofX, whereis the median andis simply evaluated from (3).\n\nThe variation of the uncertainty can be measured by the Rényi entropy, say, which is given by\n\nUsing the MKM-G density (4), we obtain\n\nBy applying the power series in Equation (9), we have\n\nThen,reduces to\n\nHence,follows as\n\nwhere\n\nThen, the Rényi entropy of the MKM-G family reduces to\n\nThe Shannon entropy follows from the Rényi entropy whenϕtends to 1.\n\nThe expected additional life length for a unit, which is alive at agetcan be expressed by the mean residual life (MRL). The MRL of aRVXis defined (for) by. The MRL ofXreduces to\n\nwhereis the CDF of the MKM-G family. Inserting (14) in Equation (15) gives\n\nThe waiting time elapsed since the failure of an item on condition that this failure had occurred inis expressed as the mean inactivity time (MIT). The MIT ofX, sayfollows as\n\nCombining the last equation and Equation (14), the MIT ofXtakes the form\n\nThe expectation of a certain function of aRVwhose mean exists is known as the probability weighted moments (PWMs). Theth PWM ofXhas the form\n\nUsing the CDF and PDF of the MKM-G family, we can write\n\nApplying the exponential and binomial series, the above equation reduces to\n\nEquivalently, we can write\n\nwhere\n\nThen, the PWM of the MKM-G family follows as\n\nLetbe a random sample from the MKM-G family. The density of theith order statistic, say, has the form\n\nwhereis the beta function.\n\nUsing Equations (3) and (4) of the MKM-G family, we obtain\n\nBased on Equation (16), the last equation has the form\n\nwhereis the Exp-G PDF with parameterand\n\nThen, the PDF ofis expressed by\n\nHence, the PDF of the MKM-G order statistic is a linear combination of Exp-G densities. Equation (19) illustrates that the properties ofcan be derived from those properties of.\n\nTherth moment offollows as\n\nThis subsection provides a simple expression for therth moment of the MKME model.\n\nBased on Equation (11), the PDF of the MKME distribution reduces to\n\nApplying the binomial expansion to the last term, the above equation becomes\n\nwhere\n\nandis the PDF of the E model with scale parameter. Then, the MKME PDF is expressed as a single linear combination of E PDFs.\n\nTherth moment of the MKME distribution is obtained from Equation (20) as follows\n\nThe mean ofsay,, follows from (21) withFurthermore, the R software is used to obtain some numerical values for the, variance, skewness, and kurtosismeasures of the MKME distribution. The values of the given measures are reported inTable 1It is noted that that the spread for itsis much larger ranging from 6.6978 to 18.6635, whereas theof the MKME distribution can range in the interval (1.4482, 3.2662).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t001\n\nAdditionally,Table 2provides the numerical values offor the MKME model based on the numerical integration (NUI) and summation (SUM) formula for several values ofλandθat truncatedMterms, whereLis the truncated terms from this summation.Table 2shows that the summation in (21) converges to the NUI offor all values ofλandθwhenLreaches to 50.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t002\n\nThe QF of the MKME distribution is\n\nThis section discusses the estimation of the MKME parameters using some classical methods called the maximum likelihood (ML), least-squares (LS), weighted least-squares (WLS), maximum product of spacing (MPS), percentiles (PC), Cramér–von Mises (CM), Anderson–Darling (AD), and right-tail AD (RTAD) estimators.\n\nLetbe a random sample from the MKME distribution andbe their order statistics. The log-likelihood function, say,l, reduces to\n\nwhere\n\nThe ML estimators (MLEs) ofθandλare determined by maximizing the above equation with respect to the parametersθandλ, or by solving the following two equations\n\nand\n\nThe MLEs are also calculated by using different statistical programs such as Mathematica, Mathcad, and R (optim function), among others.\n\nSwain et al. [18] estimated the parameters of the beta distribution using the LS estimators (LSEs) and WLS estimators (WLSEs). The LSEs and WLSEs of the MKME parametersθandλare determined by minimizing\n\nwherefor the LS approach,for the WLS approach and\n\nFurthermore, the LSEs and WLSEs can be obtained by solving the following nonlinear equations\n\nwhere\n\nand\n\nCheng and Amin [19,20] pioneered the MPS approach as an alternative method to estimate the parameters of different continuous univariate models. The uniform spacings, say, of a random sample of sizenfrom the MKME distribution are defined by\n\nwhereand\n\nThe MPS estimators (MPSEs) of the MKME parameters can be determined by maximizing\n\nwith respect toθandλ.\n\nAdditionally, the MPSEs of the MKME parameters are also calculated by solving\n\nwhereare defined in Equations (22) and (23) for.\n\nThe PC estimators (PCEs) are proposed by [21] to estimate the model parameters by equating the sample PC points with the population PC points. Ifis an unbiased estimator of, then the PCEs of the parameters of the MKME distribution follow by minimizing\n\nwith respect toθandλ.\n\nCramér [22] and Von Mises [23] introduced the CVM estimators (CVMEs) which are obtained as the difference between the estimated CDF and empirical CDF.\n\nThe CVMEs of the MKME parameters can be determined by minimizing\n\nFurthermore, the CVMEs are also obtained by solving the following nonlinear equations\n\nThe AD estimators (ADEs) are an important type of minimum distance estimators.\n\nThe ADEs of the MKME parameters can be determined by minimizing\n\nwith respect toθandλ. The ADEs are also calculated by solving the following equations\n\nThe RTAD estimators (RTADEs) ofθandλare given by minimizing\n\nThis section explores the performance of several estimators of the MKME parameters by using detailed simulation studies. We generate 5000 samples from the MKME distribution based on some sample sizesand some parametric values of the two parametersand. We calculate the average estimates (AEs) of the parameters and mean square errors (MSEs) for each sample size using the eight estimators.\n\nThe performance of the studied estimators is evaluated using MSEs. The AEs and MSEs (in parentheses) for different estimators are presented inTables 3–6. It is observed that as the sample sizenincreases, the AEs converge to the true parameter values, and the MSEs decrease towards zero, demonstrating that the estimators are asymptotically unbiased. Overall, the numerical simulations show that all eight estimation methods perform excellently with respect to the MSEs.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t006\n\nThis section is devoted to showing the empirical flexibility of the special models of the two proposed families using some real-life data, including both continuous and discrete data.\n\nIn this subsection, we analyze five real-life datasets from applied fields including environmental sciences, medicine, and engineering to explore the flexibility of the MKME model. The first dataset refers to waiting times (in minutes) before the service of 100 bank customers. This dataset is studied by [24]. The data observations are: 3.2, 0.8, 4.6, 1.9, 0.8, 3.3, 6.2, 4.7, 6.2, 8, 7.7, 9.7, 12.5, 9.8, 12.9, 18.1, 17.3, 27, 1.3, 31.6, 3.5, 6.2, 4.7, 8.2, 13, 10.7, 18.2, 13, 1.5, 33.1, 1.8, 3.6, 1.9, 4, 2.6, 4.8, 4.1, 4.9, 6.3, 4.9, 6.7, 4.2, 8.6, 11, 6.9, 8.6, 11.2, 10.9, 8.6, 11, 13.7, 11.2, 13.6, 13.3, 18.4, 19, 18.9, 38.5, 2.1, 4.2, 5, 4.3, 5.3, 7.1, 5.5, 7.1, 8.8, 7.1, 8.9, 11.1, 8.8, 13.9, 19.9, 14.1, 20.6, 2.7, 21.3, 4.4, 2.9, 4.3, 3.1, 21.9, 4.4, 5.7, 9.6, 7.1, 6.1, 7.4, 8.9, 7.6, 5.7, 11.5, 9.5, 11.9, 15.4, 12.4, 17.3, 15.4, 23, 21.4.\n\nThe second dataset is discussed [25], and it contains annual maximum flood levels over a 20-year period of the Susquehanna River at Harrisburg, Pennsylvania. These flood levels are measured in millions cubic of feet per second. The data observations are: 0.494, 0.654, 0.315, 0.297, 0.449, 0.379, 0.402, 0.379, 0.423, 0.324, 0.740, 0.269, 0.418, 0.416, 0.412, 0.338, 0.484, 0.392, 0.265, 0.613.\n\nThe third dataset is analyzed by [26], and it refers to remission times (in months) for 128 bladder cancer patients. This dataset contains the following observations: 3.48, 0.08, 2.09, 4.87, 8.66, 6.94, 13.11, 0.20, 23.63, 2.23, 4.98, 3.52, 6.97, 13.29, 9.02, 0.40, 3.57, 2.26, 5.06, 9.22, 7.09, 13.80, 0.50, 25.74, 2.46, 5.09, 3.64, 7.26, 14.24, 9.47, 25.82, 2.54, 0.51, 3.70, 7.28, 5.17, 9.74, 26.31, 14.76, 0.81, 3.82, 2.62, 5.32, 10.06, 7.32, 14.77, 2.64, 32.15, 3.88, 7.39, 5.32, 10.34, 34.26, 14.83, 0.90, 4.18, 2.69, 5.34, 10.66, 7.59, 15.96, 1.05, 36.66, 2.69, 5.41, 4.23, 7.62, 16.62, 10.75, 43.01, 2.75, 1.19, 4.26, 7.63, 5.41, 17.12, 12.63, 1.26, 46.12, 2.83, 5.49, 4.33, 7.66, 17.14, 11.25, 79.05, 2.87, 1.35, 5.62, 11.64, 7.87, 17.36, 3.02, 1.40, 4.34, 7.93, 5.71, 11.79, 1.46, 18.10, 4.40, 8.26, 5.85, 11.98, 1.76, 19.13, 3.25, 6.25, 4.50, 8.37, 2.02, 22.69, 12.02, 3.31, 6.54, 4.51, 8.53, 20.28, 12.03, 2.02, 6.76, 3.36, 12.07, 2.07, 21.73, 3.36, 8.65, 6.93.\n\nThe fourth dataset is studied by [27], and it refers to the number of vehicle fatalities for 39 counties in South Carolina in the year 2012. The data observations are: 50, 22, 13, 17, 26, 4, 9, 27, 9, 48, 31, 20, 6, 12, 5, 9, 14, 16, 33, 9, 68, 3, 20, 51, 4, 13, 17, 2, 16, 52, 6, 48, 12, 23, 10, 8, 13, 1, 15.\n\nThe fifth dataset is considered by [28]. This dataset refers to the time between failures for 30 repairable items, and its observations are: 0.70, 0.11, 1.43, 0.71, 2.63, 0.77, 1.49, 2.46, 3.46, 0.59, 1.23, 0.74, 1.17, 0.94, 0.40, 4.36, 1.74, 2.23, 4.73, 0.45, 1.46, 1.06, 0.30, 2.37, 1.82, 0.63, 1.24, 1.23, 1.86, 1.97.\n\nThe ML method is used to estimate the model parameters from each dataset, and the R program is used to obtain different computations. The fitting performance of the MKME distribution is compared to other competing E models including the generalized E (GE) [29], Marshall–Olkin E (MOE), alpha-power E (APE) [30], generalized DUS E (GDUSE) [31], generalized inverted E (GIE) [32], KME, and E distributions.\n\nThe fitting performance of the proposed MKME model and other competing distributions is explored using some goodness-of-fit measures including the Anderson–DarlingCramér–von Misesand Kolmogorov–Smirnov (KS) statistics with its associatedp-value.\n\nThe values of the four measures,,, and KS as well as thep-value, of the fitted models are given in TablesTables 7–11for the five datasets, respectively. These tables also display the ML estimates and standard errors (SEs) of the parameters of the MKME distribution and other rival models. It is shown that, the MKME distribution has the lowest values of,, and KS statistics and largestp-value, showing its close fit to the five analyzed datasets. Furthermore, the fitting performance of the MKME model is explored visually through the plots of the PDF, CDF, SF, and probability-probability (PP) for all datasets. The plots are presented in FigsFig 8,Fig 9,Fig 10. The plots indicate that the MKME provides the best fit to all datasets.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t009\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t010\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t011\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g009\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g010\n\nIn this subsection, we use two real count datasets to illustrate the flexibility of the DMKME distribution as compared to the existing discrete models including the transmuted record type geometric (TRTG) [33], exponentiated discrete Lindley (EDL) [34], natural discrete Lindley (NDL) [35], discrete Lindley (DL) [36], geometric (Gc), discrete Ramos-Louzada (DRL) [37], and discrete Poisson-Lindley (DPL) [38] distributions.\n\nThe first dataset represents the final marks of mathematics examination for 48 slow space students. This exam was done in the Indian Institute of Technology at Kanpur as discussed in [39]. The data are: 60, 29, 25, 50, 15, 13, 39, 27, 14, 15, 40, 18, 7, 7, 8, 19, 37, 12, 18, 5, 21, 15, 44, 86, 15, 14, 15, 70, 6, 50, 23, 58, 19, 23, 11, 6, 34, 18, 34, 12, 4, 28, 20, 23, 65, 19, 31, 21.\n\nThe second dataset represents the infant mortality rate per 1000 live births for some nations in 2021. The dataset is reported athttps://data.worldbank.org/indicator/SP.DYN.IMRT.IN. The data are: 12, 56, 10, 3, 22, 69, 7, 6, 11, 19, 44, 27, 13, 7, 12, 4, 3, 11, 27, 84, 25, 35, 6, 14, 6, 11.\n\nTable 12shows the ML estimates of the parameters of the discrete models and their corresponding SEs (in parenthesis) for the two count datasets. Furthermore,Table 12provides the goodness-of-fit measures for all discrete models.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.t012\n\nThe values inTable 12indicate that the DMKME distribution outperforms all competing discrete models, with the lowest values for, fand KS measures and the highestp-value, for the two count datasets. The PP plots for the two count datasets are displayed inFigs 11and12, respectively. These plots support the superior fit of the DMKME model, which provides a closer fit for both datasets as compared to other discrete distributions.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g011\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319091.g012\n\nWe proposed two new classes of distributions called the modified Kavya-Manoharan-G (MKM-G) and discrete modified Kavya-Manoharan-G (DMKM-G) families. The MKM-G class extends and improves the flexibility of the Kavya-Manoharan (KM) family. Five special models of the MKM-G and DMKM-G families are provided. These special models have the advantage of being capable of modeling different shapes of aging and failure criteria. Basic mathematical properties of the MKM-G family are explored. We discuss eight approaches for estimating the parameters of the MKM-exponential (MKME) distribution, evaluating their performance through numerical simulations. We demonstrate that the MKME distribution provides a superior fit to five real-life datasets from the fields of reliability, medicine, engineering, and environmental science, outperforming several existing exponential models. Additionally, two count datasets are analyzed to illustrate the flexibility of the DMKM-exponential model. The newly discrete model provides better fits as compared to other important discrete distributions. Overall, the proposed models provide flexible and effective alternatives to existing distributions for modeling both lifetime and count data across diverse applied fields.\n\nFuture work on the MKM-G and DMKM-G families could include extending these models to bivariate and multivariate distributions for modeling dependent data in complex applications, as well as further generalizing them to incorporate more flexible hazard rate functions. Advanced estimation techniques, such as Bayesian or machine learning approaches, could be explored to improve accuracy in large datasets. The families could also be tested on big data from industries like finance, healthcare, and telecommunications. A comparative study with other flexible distribution families, the development of user-friendly software for implementation, and the extension to handle censored or truncated data are additional areas for future research.",
    "category": "economics"
  },
  {
    "title": "Financial inclusion for persons with disabilities: Experiences of providers and users of financial products and services in Kenya.",
    "authors": "Sheru W. Muuo, Bhavisha Virendrakumar, George Okello, Moses Chege, Vibian Angwenyi, Kenneth Gichohi, Hillary Kibet, Sally Nduta, Stevens Bechange, Elena Schmidt, Simon Brown, Emma Jolley, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321493",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321493",
    "content": "Inclusion of persons with disabilities in financial products and services has been identified as an important step on the pathway to achieving the sustainable development goals. Evidence of how people with disabilities are included in financial products and services including strategies to improve their inclusion in low and middle-income countries is limited. We draw on qualitative data to to understand the experiences of providing and using financial products and services from the perspectives of persons with disabilities and representatives of different financial institutions in Nairobi and Migori counties of Kenya.\n\nEighty-one persons with disabilities (49.4% <35 years, 57% female) were purposively sampled to take part in 10 focus group discussions. Additionally, 26 in-depth interviews were conducted with financial institution representatives. Data were collected between July and September 2022 and analysed thematically.\n\nParticipants described a mixed picture, sharing experiences of different levels of inclusion, and examples of exclusion from different types of financial services and products. Despite good intentions, financial institutions lacked the knowledge and skills required to adapt existing financial products and services, and marketing strategies for different needs and to improve the accessibility of products and services for persons with disabilities. The findings highlighted a need for staff training and establishing institutional policies and guidelines to support the inclusion of persons with disabilities. Persons with disabilities reported embracing digital financial services and constitute a large untapped market for the financial institutions who are able to provide accessible products and services.\n\nMulti-stakeholder approaches are needed to increase disability awareness, develop and enforce policies and guidelines as well as collection of disability-disaggregated data to promote financial inclusion for persons with disabilities in Kenya.\n\nCitation:Muuo SW, Virendrakumar B, Okello G, Chege M, Angwenyi V, Gichohi K, et al.  (2025) Financial inclusion for persons with disabilities: Experiences of providers and users of financial products and services in Kenya. PLoS ONE 20(4):\n           e0321493.\n        \n        https://doi.org/10.1371/journal.pone.0321493\n\nEditor:Philipos Petros Gile, Higher Education Partnership / Erasmus University Rotterdam, ETHIOPIA\n\nReceived:January 4, 2025;Accepted:March 6, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Muuo et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data cannot be shared beyond individual quotations in the manuscript because participants did not give consent in terms of publication of full transcripts. The interview data hold potentially attributable sensitive information regarding participants’ experiences and their employing organisations, and it would therefore be unethical to make this public. This would undermine the minimal risk ethical committee agreement and consent process. Please contact the corresponding author atsmuuo@sightsavers.organd the Kenyatta University Centre for Research Ethics and Safety to request anonymised interview data access atdvc-rio@ku.ac.ke.\n\nFunding:This work was funded by the Deutsche Gesellschaft für Internationale Zusammenarbeit (GIZ) GmbH under Agreement Number 81278422. The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist\n\nFinancial inclusion is defined by the World Bank as individuals and businesses having access to useful and affordable financial products and services (financial transactions, payments, savings, credit, and insurance) that meet their needs delivered in a responsible and sustainable way [1]. Financial inclusion is critical for the achievement of the Sustainable Development Goals (SDGs) [2] since it facilitates access to and use of financial products and services by previously excluded groups such as people in low-income households, microenterprises, youth, women, and persons with disabilities [3]. These include SDG1, on eradicating poverty; SDG 2 on ending hunger, achieving food security and promoting sustainable agriculture; SDG 3 on profiting health and well-being; SDG 5 on achieving gender equality and economic empowerment of women; SDG 8 on promoting economic growth and jobs; SDG 9 on supporting industry, innovation, and infrastructure; and SDG 10 on reducing inequality. Additionally, in SDG 17 on strengthening the means of implementation there is an implicit role for greater financial inclusion through greater savings mobilization for investment and consumption that can spur growth [4].\n\nThe Global Findex Database, the world’s most comprehensive database of financial inclusion, estimated that in 2021, worldwide account ownership reached 76% and 71% in developing economies. However, approximately 1.4 billion adults remain unbanked, and it is more common among women, people in rural areas, and those with lower levels of literacy [5]. One group of people that continues being at risk of financial exclusion is persons with disabilities [6].\n\nPersons with disabilities are defined by in the United Nations Convention on the Rights of Persons with Disabilities (CRPD) as those who have long-term physical, mental, intellectual or sensory impairments, which in interaction with various barriers may hinder their full and effective participation in society on an equal basis with others [7]. They account for 16% (1.3 billion people) of the global population and often experience worse outcomes than persons without disabilities in areas such as education, health, and economic opportunities [8].\n\nPersons with disabilities in sub-Saharan Africa have fewer economic opportunities and are more likely to live in poverty due to multiple obstacles in accessing employment [9], finance and public services [10,11]. Studies in this region reported barriers to financial inclusion such as social stigma and prejudices [12], lack of knowledge of disability among staff working in financial institutions [11], poor digital skills [13], the lack of enabling regulatory frameworks and data on disability needs [14,15], inaccessible physical infrastructure [16] and communication materials [6]. Despite this, global estimates suggest that persons with disabilities constitute an emerging market of almost 3.4 billion people (including family members and caregivers) with two trillion US dollars in annual disposable incomes [10]. It is further recognised that persons with disabilities are critical to building stronger economies, and that there is a business case for their inclusion in financial markets [10].\n\nIn Kenya, the most recent 2019 census revealed that out of the total population of 47,564,296, there were approximately 0.9 million persons with disabilities, translating to 2.2% of the total population [17]. The country has made significant strides in recognizing and addressing the rights and needs of persons with disabilities. In 2003, the Persons with Disabilities Act, the principal legislation on disability in Kenya, was enacted. This Act, with a broadly similar definition of disability as the CRPD, provides for the rights and equalization of opportunities for persons with disabilities and for the establishment of the National Council for Persons with Disabilities [18]. In 2006, the country committed to implementing the CRPD [7]. The current Constitution of Kenya, which came into force in 2010, accords persons with disabilities the right to be treated with dignity and respect, and to access institutions and facilities, public transport and information on an equal basis with others [19].\n\nOver the past decade, Kenya’s financial inclusion has improved dramatically with 79% of adults having bank accounts in 2021, up from 42% in 2011. This leap was largely due to mobile money services [5], which use mobile phones to transfer money, pay bills, withdraw cash, save, process microloans and other services [20]. For example, M‑Pesa, a mobile phone-based money transfer service launched in 2007, spread exceptionally fast and by 2012, had 17 million mobile accounts in Kenya alone. It is argued that through access to microfinance schemes, M-PESA lifted 2% of the Kenyan population out of poverty [21]. However, none of these sources of information include data on disability and thus it remains unclear how these recent advancements in financial inclusion targeting the entire population benefitted persons with disabilities and other vulnerable groups.\n\nEvidence on financial inclusion of persons with disabilities across Sub-Saharan Africa and specifically in Kenya is limited [6]. Studies that are available have focused on either financial service providers (supply-side) [11,22] or users (demand-side) [16,23] and often applied quantitative methods to examine the drivers of exclusion [24–26]. To obtain a more comprehensive picture of financial inclusion it is important to interrogate both the supply and demand sides [27] and to supplement quantitative data with qualitative narratives explored from the perspectives of both financial institutions and persons with disabilities.\n\nFor the purpose of this study, we focused on two types of financial products – accounts and loans which are the two most commonly used financial products in Kenya [28]. Financial services were those that related to these two products including account opening, funds deposits, withdrawals and transfers and loan application and repayment. We did not explore other types of financial products available on the market, such as insurance, foreign exchange or investments since these are not commonly used in the low-income areas, where this study took place.\n\nThis study aimed to understand the experiences of providing and using financial products and services from the perspectives of persons with disabilities and representatives of different financial institutions in Kenya.\n\nThis study was part of a larger project that focused on financial inclusion of persons with disabilities which involved a rapid review of literature, a qualitative study and a co-creation exercise to develop prototypes of services for financial inclusion of persons with disabilities in Kenya and similar contexts [14]. This paper presents findings of the qualitative study, which included a range of in-depth interviews (IDIs) with representatives of financial institutions and focus group discussions (FGDs) with a sample of persons with disabilities.\n\nThe study was conducted in two sites, in Kenya’s capital Nairobi, an urban site, and Migori county, a rural site. According to the 2019 national census the number of persons with disabilities was higher in rural areas with 2.6% or 0.7 million people in rural areas and 1.4% or 0.2 million people in urban areas having a disability [29].\n\nNairobi is the largest city and as a financial and commercial hub, it hosts the highest concentration of financial institutions and industries in the country [30]. Migori is situated in South-Western Kenya; the main economic activities in the county are agriculture, fishing, manufacturing and mining. The county faces numerous challenges including high poverty levels, high unemployment rates, droughts and poor infrastructure [31]. Out of the 916,692 persons with disabilities in Kenya’s 47 Counties, the proportion that resided in Nairobi was 4.6% while those who were from Migori were 3.2% [29]. Migori was chosen as the rural area in the study based on convenience because Sightsavers, the iNGO that led this work, has presence there.\n\nFocus group discussions were conducted with persons with different impairments, aged between 18 and 60 years, recruited by purposive sampling [32]. The IDIs targeted financial institution representatives, who worked as senior managers in various capacities including branch, general or business development managers who were knowledgeable about financial products and services offered by their institutions. These financial institution representatives represented 16 microfinance institutions (MFIs) and one bank, all of which were members of the Association for Microfinance Institutions of Kenya.\n\nOut of the 16 MFIs, there were nine deposit-taking microfinance institutions (or microfinance banks) and seven non-deposit or credit-only microfinance institutions. Defined by the 2006 Microfinance Act, microfinance banks are companies that are licensed by the Central Bank of Kenya to carry out microfinance banking services including branches, outlets and any other licensed places of business. They accept deposits, register accounts, accept cheques, provide loans and carry out investments on behalf of their clients. Credit-only microfinance institutions are companies that provide lending services but do not take cash deposits or collateral from their clients [33].\n\nOne hundred and seven participants including 81 FGD and 26 IDI participants took part in the study. Ten FGDs (six in Nairobi and four in Migori) were conducted with 81 persons with disabilities recruited with support from the United Disabled Persons of Kenya (UDPK), the umbrella body for Organisations for Persons with Disabilities (OPDs) in Kenya. The UDPK mobilised study participants through their member OPDs in Nairobi and Migori. Each FGD had six to nine participants.\n\nTwenty-six representatives (17 in Nairobi and 9 in Migori) from 17 financial institutions were also selected purposively with support from the Association for Microfinance Institutions of Kenya. Microfinance Institutions were primarily targeted for this study, as they work more with low-income households and micro, small and medium enterprises (MSMEs) than banks, particularly in rural and peri-urban areas [34].\n\nData were collected between 27thJuly and 23rdSeptember 2022. The FGDs and IDIs were guided by the topic guides developed based on the rapid literature review [14]. Focus groups were used in place of individual interviews for persons with disabilities to allow participants to feel empowered and share their experiences among other persons with disabilities. Two researchers with qualitative research experience conducted IDIs and FGDs in either English or Swahili depending on participants’ preferences.\n\nThe IDI and FGD guides had questions on financial products and services available to clients in general and specifically to persons with disabilities, institutional policies and guidelines, marketing of products and services, accessibility of products and services, staff knowledge and attitudes as well as awareness of disability and client’s additional needs. All IDIs and FGDs were audio-recorded.\n\nAll IDIs and FGDs were transcribed verbatim, and participants identifiers anonymized during this process. Data were analysed thematically and managed using NVivo 12 software [35] in line with the procedures for analysing qualitative data proposed by Braun and Clarke [36]. At the first level of analysis, transcripts were read thoroughly by SM and VA, who developed and agreed on the code book. Using the code book, the remaining data were coded by VA, in consultation with SM and BV. Following the coding, VA with support from SM and BV organised the codes alongside broader themes. A general inductive approach for analysis of qualitative evaluation data was used [37].\n\nA validation workshop was held in October 2022 with representatives of both participant groups to share and validate the study findings, brainstorm and identify key barriers that needed to be prioritised and identify potential solutions and disability-inclusive recommendations for further deliberations during a programmatic co-creation workshop [14].\n\nEthics approvals were obtained from the Kenyatta University Centre for Research Ethics and Safety (PKU/2454/E1585) and the National Commission for Science, Technology and Innovation (NACOSTI/P22/17185). Written informed consent was obtained from all participants prior to data collection. The consent form was read and explained to participants while responding to questions when they arose. After orally consenting to participation, participants signed and dated the form.\n\nSpecial considerations and accommodations were made to facilitate participation of persons with disabilities. For example, the FGDs were held in buildings which were convenient and accessible for participants with mobility limitations. Persons with visual impairments brought along their carers or guides. Sign language interpreters were available for persons with hearing impairments to ensure accessibility of information.\n\nAdditional information regarding the ethical, cultural, and scientific considerations specific to inclusivity in global research is included in the Supporting Information (S1 Checklist)”\n\nOne hundred and seven participants, including 81 persons with disabilities and 26 representatives of financial institutions participated in this study. Among persons with disabilities, half (49.4%) were young people aged 18–35 years, and the other half were aged 36–60 years. There were slightly more women than men at 56.8% and 43.2% respectively. More participants were from Nairobi (59.3%) than Migori (40.7%). The largest proportion of participants had physical disabilities (39.5%) followed by those with visual impairments (13.6%), hearing, speech and language disabilities (12.3%) as well as albinism (4.9%). Approximately 3.7% had mental health disorders, intellectual disabilities and autism spectrum disorders while 2.5% had multiple disabilities. Some participants (23.5%) preferred not to disclose their disability status on paper despite discussions around confidentiality before data collection. Disability categorization was based on the Kenyan 2022 Disability Medical Assessment and Categorization Guidelines [38].\n\nAmong persons with disabilities participating in the study, over half had an account with a formal financial institution. One in five (21%) had experience of taking a loan from a financial institution, while about a third (32.1%) had borrowed money via a digital lending platform.\n\nIn the IDIs with financial institutions representatives, there were more male (69.2%) than female (30.8%) participants. Half of them had work experience of 11 years and above (50.0%) and almost half (46.2%) had been working for their current employer for five years or less.\n\nThe themes rising from the analysed have been grouped under six broad categories presented below.\n\nFinancial institutions representatives described various products and services available to their clients. These included individual, joint and group bank accounts, a range of loan and credit facilities, such as local purchase order (LPO) financing, asset financing, agricultural loans, school fee loans, and small and medium enterprise (SME) investment loans. The majority of representatives from financial institutions reported that their products and services targeted the population as a whole, although they did have products for specific ages (e.g., young people account) or professional groups (e.g., construction financing, agricultural loans). Only one institution aimed at financially empowering persons with disabilities through specific products designed for these clients, as described by their representative:\n\n“Our core business is lending, and our area of specialization is LPO [Local Purchase Order] financing. Our main target customers are youth, women and persons living with disabilities. So, they make the bigger part of our clients in terms of financial services. We lend them, if they are able to do their work, then they pay us back, once they are awarded an LPO or a tender.”(Credit only microfinance, urban)\n\nParticipants with disabilities appeared to be more knowledgeable of banks than MFIs and only a few knew the difference between them. The most common financial products used by these research participants were bank accounts, loan and credit services, particularly asset financing and school fee loans.\n\nSome persons with disabilities had no accounts. The main reason for this was low or irregular income. These participants preferred to store the little cash they had in a safe place in their house, as one participant explained:\n\n“I repair electronics such as radios, TVs, computers… Unfortunately, the income is very little. It’s what we call from hand to mouth sort of work. Therefore, it’s very unlikely for me to put money in a bank.”(Younger participant with account, rural)\n\nMany participants with disabilities showed high levels of awareness of digital platforms for saving and borrowing money. The services most frequently named were M-Pesa (a mobile phone-based system that enables users to deposit, send and withdraw funds), M-Shwari (a savings and loan service), and Fuliza (an overdraft facility) provided by Safaricom, the leading Kenyan telecommunications company. Other digital lenders mentioned included Silicone Valley backed Tala and Branch as well as Zenka, owned by the Norwegian software maker, Opera. A number of participants preferred using these digital services instead of bank or MFI accounts, as one research participant explained:\n\n“I can say that I prefer M-Pesa because I can save my money there and get a loan from there. I can also use it as a fixed account.”(Younger participant with no account, urban)\n\nApproximately third (30%) of the persons with disabilities interviewed were members of Savings and Credit Cooperative Societies (SACCOs) and/orChamas, where members of a community group come together to save and invest for the benefit of all members. For some participants, these schemes were more popular than formal financial services due to their less cumbersome registration processes, lower interest rates, faster loan processing times, flexibility in repayment periods, and the presence of co-guarantee systems where fellow members served as loan guarantors, as one participant pointed out:\n\n“…the interest rate, you will find that it is higher in the banks and lower in the Chama, so some… prefer the Chamas to the banks.” (Older participant with no account, urban)\n\nMost financial institutions interviewed reported having no specific policies or guidelines on disability including the MFI that has a focus on persons with disability as reported below.\n\n“No, I don’t think we have any documented policy. What is noted in our policy is that we focus on that group [persons with disabilities] and then I think it leaves it at that. I know that in the coming days that is where we intend to go back to. We probably need to formulate our policies to address their needs more.”(Credit only microfinance, urban).\n\nResearch participants reported they relied on broader customer service policies and human resource policies on non-discrimination of clients and staff. Only one financial institution mentioned having an operational policy on loan procedures which detailed terms and conditions for working with persons with disabilities. Another financial institution described how they had to adjust their terms of service when one of their clients developed severe physical limitations due to a terminal illness.\n\nA few research participants reported having a disciplinary system to handle any reported cases of discrimination or poor handling of clients. This system included provisions on discrimination of clients on the ground of disability.\n\nMany institutions also pointed out that their marketing and communication strategies targeted the general population, and they did not know whether the printed materials, websites and social media platforms they used were accessible to persons with disabilities:\n\n“...you see as a marketing guy, our business is…visibility and branding outside there.... we are expected that anytime we post in print, it also goes on social media...the question that we need to ask ourselves is…out of the guys that are blind and those …having issues physically, do they have that opportunity of reading it? Can they access these newspapers? Do they have mobile phones?” (Microfinance bank, urban)\n\nSeveral institutions, however, said that they had made specific efforts to reach clients with disabilities. The most common approach was word of mouth to recruit new clients with disabilities. This involved persons with disabilities, who were already product users sharing information with other persons with disabilities that they personally knew. Another approach was to send field agents to the homes and businesses of clients with disabilities. This was particularly common in promoting new financial products and loans. A few institutions reported that where necessary, these agents were accompanied by sign language interpreters:\n\n“Our way of marketing is very personal…we meet with them [persons with disabilities] and talk to them… if there is a need for sign language, I bring in a sign language interpreter.”(Credit only microfinance, urban)\n\nPersons with disabilities reported they needed more information about different products and services available; they wanted more information and training on how to access them and how to use them safely and beneficially. They recommended financial institutions work with persons with disabilities in the design of such products and services and training sessions.\n\nSeveral persons with disabilities reported that the long distances and travel time to get to a financial institution was a major challenge for them. Those who needed aides had to cover costs of travel for themselves and for people accompanying them, which many could not afford:\n\n“For you to have access to the money, you have to tag along your caregiver and maybe the bank is not near; so maybe you have to look for [bus] fare...and sometimes you have to get enough money for a cab to and from [the bank]. And you see, many are not employed and maybe depend on well-wishers and family.”(Younger participant with account, rural)\n\nRepresentatives of financial institutions also described their efforts to make their products and services more accessible to people with additional needs. They specifically mentioned voice-enabled mobile banking applications and screen readers for website content. When persons with visual impairments visited their institutions, staff read documents out loud. For persons with intellectual challenges, discussions were recorded and shared in an audio file. Persons with hearing impairments were provided with information using handwritten notes and text messages; they could also bring in sign language interpreters for communication support.\n\nWhen describing their physical premises, some financial institution representatives said that they tried to make structural adjustments to improve access for persons with disabilities. These included locating offices on the ground floor, installing ramps, having wide corridors, installing lifts with voice-enabled features and Braille imprinted keys, lowering the counters for wheelchair users and installing accessible toilets:\n\n“...we … made our ATMs accessible, banking halls accessible, we have also made sure that there are counters that are sunken to a level that you can …work comfortably from your wheelchair … we have 19 branches, they are all friendly to persons with disabilities.” (Microfinance bank, urban)\n\nHowever, several financial institution representatives acknowledged that their buildings were inaccessible for persons with mobility difficulties. They explained that many offices were rented spaces, which presented challenges with making structural adjustments. Any changes to office layouts required negotiations with landlords and certain structural modifications required special authorisations. This problem was more common among institutions in rural areas, which had limited choices of buildings for rent:\n\n“We prefer most of our branches to be on the ground floor but [in] some places, it is difficult to get good spaces.”(Credit only microfinance, urban)\n\nSome financial institutions argued that the cost of making their premises and products more accessible was a major challenge for them. They specifically mentioned high costs of printing existing forms using large fonts, preparing documents in Braille, hiring sign language interpreters, modifying mobile applications and making accessibility adjustments to the buildings.\n\nOpinions of participants with disabilities on accessibility of financial institutions and their products varied. Many said that inaccessible infrastructure was a major barrier preventing them from more frequent use of financial institutions. They specifically mentioned glass dividers, which separated clients and banking staff and created difficulties in communication for persons with hearing impairments. Many buildings lacked lifts and ramps, and the floors were often slippery. Sometimes counters and Automated Teller Machines (ATMs) were too high for persons with physical impairments or those of short stature.\n\nThe lack of accessible information was also mentioned as a major challenge. Participants with disabilities said that most institutions did not have sign language interpreters and had to exchange information using written notes, which was strenuous for both the clients and the staff. Some said that the staff often could not understand the written notes due to the differences in grammar used by people, who communicated in sign language:\n\n“When you get there, the forms that are supposed to be filled, the English [language] used is not simple and direct because of our grammar structure… sometimes when we write to them, they think we are stupid because we are using incorrect English but that is what our grammar is based on.”(Younger participant with account, urban)\n\nParticipants with visual impairments also said that the documents they had to complete used small font size and there were no forms in Braille for those who were blind. Many had to rely on their guides in reading the documents. Those who had low literacy levels or had intellectual challenges found that the language used in many documents was too technical and difficult to understand.\n\nWhile digital financial services were popular among many participants with disabilities, some experienced difficulties with installation and update of mobile applications due to their inaccessible formats. Major difficulties were experienced by persons with visual impairments with the applications, which did not have audio-enabled features:\n\n“...if we say that somebody is visually impaired then yes, we have a USSD code but they can’t dial it because they can’t see.”(Credit only microfinance, urban)\n\nFinancial institution representatives acknowledged the need for better training of their staff on how to develop and improve digital channels for persons with disabilities.\n\nAnother common concern expressed during the interviews with both persons with disabilities and staff of financial institutions was the security of digital channels, data privacy and third-party access to sensitive information. Persons with visual impairments were concerned that their phones could be used by someone to process loans without their consent. To prevent unauthorized use of mobile services persons with visual impairments had to provide details of their designated aides who would support them in conducting financial transactions which introduced another layer of complexity and prolonged the account registration process. Some participants, who could not use ATM services due to their high position also were concerned about security of their transactions, as they had to share sensitive information with their aides:\n\n“…for some of us to access the ATM…you have to rely on someone else to enter for you the PIN and it is sensitive, sharing a PIN…So...if it [ATM] was placed on a level that I can do my transactions then I wouldn’t need help with PIN.”(Younger participant with no account, urban)\n\nFinancial institution representatives corroborated these concerns. They acknowledged that persons with disabilities were at high risk of fraud, as one interviewee explained:\n\n“I think what they [persons with disabilities] face is the intermediaries that come with them, who would want to take advantage of them. They probably want to get a little something for themselves and they [persons with disabilities] have already trusted them out there, so they come, access funds and after a while they [persons with disabilities] tell you that that the guy [aide] took their money and went away …. So … they [persons with disabilities] are not paid and next time you are not going to lend them because you still have not recovered your money.”(Credit only microfinance, urban)\n\nSome persons with disabilities mentioned the presence of ramps, lower counter tops, designated rooms or desks for clients with disabilities, fast tracking in queues and ATMs and mobile applications with audio-enabled features. But all agreed that more needed to be done:\n\n“…most of the banks nowadays are trying to be considerate of persons with disabilities and especially when it comes to ramps …The deaf and someone …. visually impaired …[can] ask someone to help them.”(Younger participant with account, rural)\n\nMost financial institutions said that their staff was helpful and accommodating to clients with disabilities and their needs. They specifically mentioned security guards, who guided clients with disabilities through their premises. They also said that clients with disabilities were prioritised in queues and staff helped with filling in forms and operating ATMs. Some institutions mentioned that their staff serving at the customer desks were trained in attending to clients with additional needs.\n\nSome interviewees however admitted the existence of stereotyping attitudes where persons with disabilities were perceived to be a high risk, as a borrower or a guarantor, as one interviewee recalled:\n\n“I had a woman [client] who wanted a loan, but the husband was disabled, and he was supposed to be the guarantor. So, questions on whether the guarantor can repay the loan in case she defaults arose… it is not easy to give them [persons with disabilities] loans as compared to others because you wonder if they can conduct … business.”(Microfinance bank, rural)\n\nParticipants with disabilities also pointed out to a widely spread perception that persons with disabilities did not have money to regularly use financial services. Some reported that they often felt ignored or dismissed while others reported being labelled as “sick people” or “thieves”. This is how one research participant recalled their experience in a bank:\n\n“What made me not to open an account is…I went to [this] institution … several years ago…The first thing they asked me was where I would get the money to keep in the account. Then they started attending to people who didn’t have disability. I waited for a while but then got tired of waiting, so I left.”(Older person with disability, rural)\n\nSome participants argued that one of the reasons why they preferred to use mobile money services is that they wanted to avoid physical contact with financial institutions, so that their disability remained secret which then prevented potential stigma and discrimination.\n\nAlmost all financial institutions interviewed reported limited awareness of disability or how to support persons with disability related needs. Most staff did not know how to communicate with persons with disabilities or how to ensure that marketing materials and products met accessibility requirements. Some interviewees were concerned that their focus on clients’ additional needs may be interpreted as patronizing and discriminating. For example, one interviewee recalled a situation when they wanted a client with disability to be served ahead of the queue. The client felt offended and angry, as they did not want to be treated differently from others.\n\nMost financial institution representatives said that they had not received any training on disability. The only training they mentioned was sessions on diversity of clients, which included persons with disabilities, as part of their general on-the-job training. There were, however, two exceptions. One financial institution organised regular fortnight meetings with staff across all their branches to discuss equity and inclusion, which included topics on disability. Another institution conducted two training sessions for their staff on basic sign language, disability awareness and etiquette. The training was done in partnership with a local organization of persons with disabilities (OPD):\n\n“...we have had two training [sessions] where the staff learnt some basic alphabet and communication in sign language. I think now …we will be more exposed…and maybe the management will see the need to incorporate those trainings….”(Credit only microfinance, rural)\n\nAdditionally, the majority of financial institutions interviewed were unaware of the proportion of their clients that had disabilities or accessibility needs, as one participant explained:\n\n“We are not collecting data on who is disabled or not. So, I’m not even sure how many persons with disability we have and what disabilities they have.”(Microfinance bank, urban)\n\nParticipants explained that they mainly discovered their clients’ disabilities when they interacted with them and when difficulties in performing certain activities were either evident through interactions or reported by the client. Only a few institutions said that they tried to systematically record information on disability, when the clients either presented their disability card or their tax exemption certificate during account registration processes. Only a handful of participants interviewed were aware of these documents and proactively asked whether their clients had them.\n\nFinancial institution representatives raised concerns about potential risks arising from inappropriate collection or storage of disability data. Some argued that if the disability status is known to the institution, clients may be stigmatised or discriminated against:\n\n“...we don’t categorise clients like that but if someone has eye problems, some have leg problems and they are involved in business, they get support from us...You know when you collect that [information], discrimination may occur, so we don’t [do] that... We don’t segregate them [persons with disabilities] and that is why we don’t keep such information.”(Credit only microfinance, urban)\n\nOpinions of participants with disabilities on recording their disability status by financial institutions varied. Some thought that this information could ensure better accessibility and more support from the staff. They also argued that this could potentially support the development of products and services specifically for persons with disabilities, for example loans with lower or waived interest rates. Research participants from financial institutions were hesitant about the feasibility of such products, as they could be considered discriminatory. Also, eligibility for such services would be difficult to establish without a formal verification process (e.g., disability cards), which could potentially open avenues for abuse and fraud.\n\n“I don’t think it’s necessary because one might pretend to have a disability… so they be given a loan.”(Younger participant with no account, urban).\n\nThis is one of a few studies which explored the experiences of inclusion of persons with disabilities in financial markets in Kenya. Our data shows that Kenya has made significant progress in increasing access to financial services for the general population and made efforts to facilitate access for vulnerable groups, including persons with disabilities. Among our participants with disabilities, half had access to a financial account, one in five borrowed money from a formal financial institution and one third took loans from a mobile lender. Although not nationally representative, the study showed that many persons with disabilities could access financial products and services available in the market.\n\nOur findings are consistent with the recent data from the World Bank, who reported that Kenya was at the forefront of financial inclusion in sub-Saharan Africa region with 79% of the general population reporting access to financial institution or mobile accounts. However it is important to note that although the World Bank recognises socio-economic inequalities in access to financial services and disaggregates its global data by six individual characteristics (sex, age, residency, education, workforce and income), disaggregation by disability status is lacking and financial inclusion of people with disabilities continues to be a significant knowledge gap [5]. Data from our study suggests that persons with disabilities may be more disadvantaged than their non-disabled counterparts. However, as it was a qualitative study, we cannot quantify the actual access gap. Moreover, the World Bank global database [5] and data specific for Kenya [25] suggest that women, people with lower levels of education, those out of work and those with lower income are less likely to have access to financial services. As all these characteristics are also associated with disability [8], it is possible that people with disabilities experience double or triple disadvantage due to intersection of disability with other vulnerabilities.\n\nFinancial institutions that participated in our study also described their efforts to make their infrastructure and products more accessible for people with disabilities, although there were variations between institutions and research participants. Our study identified a number of barriers faced by financial institutions in improving access to their services by persons with disabilities. These include poor knowledge of disability and clients’ additional needs among staff, the lack of information about disability status of their clients and high costs of structural adjustments to their premises. Similar results were found in other studies in Ghana [15], Uganda [23] and Bangladesh [39,40].\n\nLiterature also describes examples of significant improvements in financial inclusion as a result of implementing more disability inclusive practices. For example, a study in Uganda demonstrated that implementing interventions targeting discriminatory attitudes and behaviours towards persons with disabilities among staff of microfinance institutions significantly increased the number of their clients [41]. These interventions were developed through involving persons with disabilities in the in the product design, marketing approaches and more accessible infrastructure. The interventions showed also their effectiveness in building confidence and increasing self-esteem among persons with disabilities involved [41].\n\nBanks in Kenya have also made progress towards disability inclusion guided by the efforts of the Kenya Bankers’ Association (KBA) which adopted financial inclusion for persons with disabilities as a strategic goal in 2019. Since then, KBA with support from partners developed a roadmap for the banking industry to training for staff on how to support persons with disabilities, recruit more staff with disabilities, improve accessibility in their branches, and improving accessibility of mobile applications, online banking, and printed and electronic documents [11]. However, it was clear from our findings that these strategies had not yet been rolled out by microfinance institutions, who were the primary participants in our research.\n\nAvailable literature is also clear that financial institutions need to work closely with organisations of persons with disabilities to develop and implement guidelines on how to support persons with disabilities (17). These organisations can help financial institutions develop effective and sensitive approaches to marketing, accessible infrastructure, and collecting disability data. It would also be beneficial for financial institutions to work with disability advocacy groups and policymakers to ensure financial products and services are designed with the unique needs of persons with disabilities in mind, thereby promoting greater their economic independence and participation in the financial system for this underserved populations [14]. These partnerships are essential for truly inclusive financial markets based on the principle “Nothing about us without us” and will benefit both financial institutions and their clients [42].\n\nOur research findings highlighted that both financial institutions and persons with disabilities had embraced digital technology. This was encouraging especially since inclusive digital technology has been shown to be an important pathway to financial inclusion for persons with disabilities (7). Evidence from previous studies also showed that the ownership of mobile phones [13] and accessible digital products facilitated access to financial services by clients with additional needs [43]. Financial institutions therefore should work closely with mobile network operators, fintech providers and persons with disabilities in designing digital financial products, their delivery mechanisms and communication strategies [44]. This should be accompanied by training on data security and safety to empower persons with disabilities and prevent them from becoming victims of fraud or other financial crimes.\n\nThis study highlighted the importance of understanding the accessibility needs of clients which requires collection of meaningful disability data at the institutional level. Disaggregation by disability status of financial data collected through global, regional and national surveys should also be improved. This is important for identifying population groups vulnerable to exclusion and for monitoring and evaluating progress towards more equitable financial access. This more granular understanding of the populations at risk of financial exclusion will allow for better planning and budgeting of reasonable accommodation. If persons with disabilities remain invisible in data, they remain unaccounted for [45].\n\nIn Kenya, financial inclusion monitoring is supervised by the Central Bank of Kenya (CBK) [46]. The Central Bank can guide financial institutions in the collecting disability-related data to be able to fulfil its commitment to the Inclusive Data Charter signed in 2018 which included the country’s commitment to promote collection of accurate data on persons with disabilities for use in planning and programming and to ensure no one is left behind [47]. Central Bank can also guide financial institutions in the development of institutional level policies and guidelines on disability inclusive services and to facilitate their enforcement.\n\nWe acknowledge several limitations in our study. First, the study was vulnerable to social desirability bias. Even though financial institution representatives were assured of data confidentiality, it is possible that some research participants provided a more positive picture in the attempt not to discredit their financial institution. This may have been affected by the fact that most of these interviews took place on the premises of these institutions. Second, the study did not include larger and more popular commercial banks or the Central Bank of Kenya despite multiple attempts to involve them, largely due to their lengthy institutional approval processes. We are aware from the literature that some of these institutions have made significant strides towards disability inclusion, but their perspective could not be fully reflected in our research (12). Thirdly, the study involved persons with disabilities from low-income areas in the two counties which was not representative of all persons with disabilities within these counties or in the country. We recommend further research involving persons with disabilities from different settings in Kenya to get a more wholistic picture. Additional quantitative research is also recommended in order to draw further conclusions indicating differences in financial inclusion among people with different types of disabilities, between women and men and other sub-categories. Fourthly, mobilisation of participants with disabilities was done through the national umbrella organisation for persons with disabilities. It is possible that our participants were more knowledgeable about disability and financial services and their views may not have been representative of all people with disability in Kenya.\n\nIn conclusion, our study showed that although a significant progress towards financial inclusion has been made in Kenya in recent years, more needs to be done to ensure access by vulnerable groups, including persons with disabilities. It is envisaged that these insights will inform financial institutions on how to adapt existing financial products and services to better serve persons with disabilities and ensure financial inclusion for all.\n\nhttps://doi.org/10.1371/journal.pone.0321493.s001\n\n(DOCX)\n\nThe authors would like to thank all the research participants who took part in the study. We also thank the Association of Microfinance Institutions Kenya and the United Disabled Persons of Kenya (UDPK) for mobilisation of research participants, supporting for data collection and participating in the follow-up data validation, co-creation, and dissemination workshops.",
    "category": "economics"
  },
  {
    "title": "Informal workers’ perceptions of retirement planning in developing countries",
    "authors": "Navneel Shalendra Prasad, Amit Prakash, Nikeel Nishkar Kumar, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321214",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321214",
    "content": "In this study, we examine the perceptions of informal workers toward retirement planning in developing countries. Specifically, we examine vegetable market vendors’ perceptions of the local superannuation fund, namely the Fiji National Provident Fund (FNPF) in the Western division of Fiji, where agriculture is predominant. The research aims to address the gap in the literature concerning nest egg savings options for the part of the population for whom superannuation contributions are not mandatory. Nest eggs savings are savings and investments for huge financial goals such as retirement. Generally, respondents had a positive outlook on the FNPF, and most responded that they would prefer a tailor-made retirement plan suited to the income and livelihood of market vendors. Specifically, as self-employed people, market vendors are keen for a specialized system of voluntary contributions towards their FNPF accounts that bypasses the mandatory joint-contributions from employers. We also find that age, gender, duration as a market vendor, and other savings avenues are vital for accessibility to financial services offered by the FNPF. We also find that while market vendors are aware of saving and saving benefits with FNPF, there is a lack of intention for them to adopt the current FNPF product. Policymakers must, therefore, develop FNPF products to cater for the needs of market vendors recognizing self-employment and the voluntary nature of contributions.\n\nCitation:Prasad NS, Prakash A, Kumar NN (2025) Informal workers’ perceptions of retirement planning in developing countries. PLoS ONE 20(4):\n           e0321214.\n        \n        https://doi.org/10.1371/journal.pone.0321214\n\nEditor:Zeewan Lee, National University of Singapore, SINGAPORE\n\nReceived:July 10, 2023;Accepted:March 3, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Prasad et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All data are in the paper and supporting information files.\n\nFunding:This research was supported by a grant from the Fiji Higher Education Commission (FHEC) through The University of Fiji. The FHEC ensures quality assurance in Higher Education in Fiji. The University of Fiji approved this funding through the Research Committee on 18 August 2016 (Grant Number: 2016GOVGRT001). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAgricultural sector development is one of the most powerful tools to end extreme poverty, boost shared prosperity, and feed around 10 billion people by 2050. Compared to other sectors, its growth is two to four times more effective in increasing the incomes of the poorest. Agriculture accounts for 4% of the global gross domestic product and more than 25% in the least developing countries [1]. In Fiji, agriculture is largely an informal sector [2]. The most recent statistics by the Fiji Bureau of Statistics indicate that the informal sector in Fiji consistently contributed as much as 23% of Fiji’s GDP in 2011 [2]. The informal sector in Fiji is dominated by agricultural sector workers such as market vendors [2]. However, such workers do not contribute to superannuation schemes such as the Fiji National Provident Fund (FNPF), have no formal contract letters guaranteeing employment, and their employment is often not in compliance with Fijian labour laws [2]. Retirement planning for informal workers such as market vendors is therefore imperative.\n\nA critical first step in assessing the retirement planning of market vendors is ensuring sufficient funds for old age. Market vendors as informal workers are excluded from social safety nets and Government protection schemes [2]. Informal workers in Fiji are excluded from retirement benefits unless they voluntarily contribute towards their FNPF accounts [2]. Superannuation programs such as the FNPF are available to informal workers such as market vendors on a voluntary basis, and not as a mandate. Based on our survey, the majority of the respondents did not save in FNPF despite being aware of FNPF and its purported benefits. This speaks to a plausible lack of financial literacy motivating this study.\n\nA superannuation scheme is a fund where workers regularly contribute towards a future pension and retirement nest egg. Workers from formal sectors have access to superannuation where they and their employers make mandatory contributions. In brief, the private superannuation landscape in Fiji is described as follows. Mandatory members contribute 8% of their income towards their FNPF, with an additional contribution of 10% from employers. During COVID-19, the government reduced these contributions to 5% respectively between 1 April 2020 and 31 December 2021. These contributions were raised to 6% each in 2022 and 7% in 2023. The 10% and 8% contributions were normalised from 1 January 2024 [3].\n\nThe savings benefits with FNPF include retirement and pre-retirement benefits such as housing, medical, education, funeral, and unemployment assistance. The fund allocates members’ contributions to the Preserved Account and General Account. The Preserved Account accumulates 70% of all contributions, while the remaining 30% is accounted for in the General Account. All the pre-retirement benefits are distributed from the General Account except for housing. On a member’s purchase of their first property, they are entitled to all the contributions in the general account and 30% from the Preserved Account. In 2022, there were a total of 398,593 members in FNPF, 214,536 of whom were compulsory members, 12,242 were voluntary members, and the remainder were dormant members. Of all voluntary members, 55% were females, and 45% were males. There were 6,632 voluntary members in 2021 compared to 12,242 in 2022. Voluntary members contributed 4.8 million in 2021 and 20.1 million in 2022 [4].\n\nThose working in the informal sector, self-employed and working overseas can contribute to the fund as voluntary members with a $10 opening deposit and a minimum of $10 deposit per transaction. Payments in the voluntary membership can be made through bank transfers, payments at FNPF outlets, payments at Post Fiji (postal service providers with offices in diverse locations) outlets and mobile payments. Employers of the informal workers, if any, are not required to pay the mandated employer contributions as with the formal sector [5]. Our survey implies that market vendors generally appear to lack technical knowledge on how voluntary contributions can be made despite having an awareness of FNPF and its benefits.\n\nThis study examines the perception of market vendors towards superannuation programs in Fiji. Retirement planning is a crucial part of financial planning to sustain the livelihood of the workers engaged in the agriculture sector. A sound retirement plan such as clearly defined FNPF policies for market vendors may encourage participation in the largely informal agriculture sector. There may be many other methods to foster incentives via government-assisted programs. The Fiji government provides six main social assistance programs. These include the poverty benefit scheme, care and protection allowance, social pension scheme, disability allowance, rural pregnant mother’s food vouchers, and the bus fare scheme [6]. However, these are macroeconomic efforts with little to no effort directed at the welfare effects of the agriculture sector participants at the grassroots level. Notably, the informal economy, such as the market vendors, is characterized by hand-to-mouth behaviour with little financial discipline to save [7].\n\nThe Reserve Bank of Fiji states a need for financial inclusion policies by the government to incentivize financial products and models aimed at financially excluded populations [8], such as farmers who do not have access to superannuation. This may deter people from considering farming as a long-term career because the presence of mandatory employer and employee contributions on top of baseline salary makes formal employment lucrative. There is a need for formal FNPF initiatives in the informal sector because Fiji is a developing country and like other similar countries, is plagued with issues of poverty, rising inequality, and imports of key goods and services. As a starting point, addressing disincentives within the informal sector may encourage people to enter these industries which may have beneficial flow-through economic effects on local agricultural production helping curb imports [2].\n\nAccordingly, in this study, we provide survey-level evidence on the perceptions of market vendors in the western division of Fiji towards the national superannuation fund, Fiji National Provident Fund (FNPF). The scope of the paper is that we look at voluntary pensions and the plausible reliance of market vendors on such schemes for their retirement. The survey design is intended to answer our primary research questions: Is there a savings plan for small market vendors? Do these small market vendors have a mapped retirement plan for old age? Consequently, the two main objectives of this study are (1) what are the determinants of the awareness of FNPF and its benefits by market vendors, and (2) are there tailor-made FNPF programs catering for market vendors in Fiji? The first objective is fulfilled by regression analysis. The second objective is fulfilled by interviews and thematic analysis.\n\nThe study contributes to research on superannuation schemes focusing on the informal sector in developing countries. To the best of our knowledge, prior research has not examined the determinants of FNPF awareness or its benefits in informal sector workers within the specific context of Fiji. Market vendors as informal sector workers are underrepresented in research and outreach by the FNPF. By conducting a study in this setting, we gain primary first-hand information on the ideas and views of market vendors towards superannuation. Financial planning and, specifically, retirement planning in agriculture is important because it is a crucial step that brings economies closer to achieving the United Nations’ sustainable development goals, reducing poverty, providing decent work, and reducing inequalities for informal workers such as farmers. Apart from scholarly interest, the study provides important insights that can help curb social problems by providing plausible solutions for disincentives in agriculture, retirement planning and financial security for the informal sector in Fiji. In this sense, addressing the critical financial disincentive in the agriculture sector for individual farmers may curb the decline in agricultural participation [9].\n\nThe informal sector contributes to providing essential products and services and generating employment [10]. In developing economies, the informal sector increased its size from 37% of the Gross Domestic Product (GDP) in the 1990s to approximately 50% by 2010 [11]. Informal employment accounts for more than half of all jobs in Fiji, Palau, Tonga, and Vanuatu [12]. The review by [13] suggests that research in the informal sector remains underexplored. The authors argue that management scholarship has enormous potential to improve understanding of the informal sector. Van Ginnekan [14] notes that informal workers contribute to a larger and increasing part of the labour force in developing countries. Many of these workers are unable or unwilling to contribute a percentage of their income to utilize formal sector social benefits. Thus, these workers set up their own health and social benefits schemes aligning with their contribution capacity. Special social assistance schemes are required to protect the most vulnerable in this group.\n\nHu and Stewart [15] provide an overview of pension coverage for informal sector workers. Governments use two approaches, means-tested and universal, to provide social assistance to the poorest elderly on a non-contributory basis. In the means-tested approach, only people who are too poor to support themselves are covered, while the universal approach covers all elderly populations, regardless of income level. South Africa and Bangladesh use the means-tested approach. In South Africa, this pension is the primary source of income for 75% of retirees. In China, it is mandatory for informal sector workers to join a pension scheme. However, very few comply with this requirement due to a lack of incentives, high contributions and low enforcement powers of the government. In many local regions in China, restrictions have been eased to encourage participation. There are many voluntary pension schemes in China. It is noted that simplification and flexibility should be the main features of new pension products. In Chile and other countries with a more significant agriculture sector, flexible contributions are allowed. Flexibility of withdrawals should also be a feature in new pension products as the informal sector workers are a vulnerable group. Lee et al. [16] find that the informal sector in Mexico makes retirement decisions mainly based on health and access to health insurance through social security and not based on socioeconomic benefits. Onyango et al. [17] found that informal sector workers in Nairobi, Kenya, recognized the benefits of savings. However, they focused on meeting the needs of their immediate lives and did not consider the future, let alone retirement, as old age was perceived as bleak, dull, restricted and not worth considering. Tran and Jung [18] find that the effect of public pensions is two and a half times larger when accounting for the interaction between private transfers and the elderly’s retirement decisions.\n\nFinancial literacy relates to retirement planning and superannuation. Financial literacy refers to the effective use of various financial planning skills to budget and plan personal finances, as well as being aware of how financial products such as savings accounts work [19]. People’s knowledge of and ability to use fundamental financial concepts in their economic decision-making matters as this often has longer-term repercussions on their lives and livelihood [19]. Having knowledge of financial products is, however, only part of the picture. True financial literacy may relate to having a working knowledge of the mechanics of financial products, such as understanding rates of return and how this relates to inflation rates and general interest rates in the economy [19]. A lack of financial literacy, therefore, underscores that market vendors may not have FNPF accounts because they may not understand how such accounts function.\n\nA lack of financial literacy undermines financial inclusion, especially in developing countries. Financial inclusion ensures that individuals, especially poor people, access essential financial services in the formal financial sector [20,21]. Ozili [22] finds that financial inclusion is influenced by the level of financial innovation, poverty levels, the financial sector’s stability, the state of the economy, financial literacy, and regulatory frameworks, which differ across countries. Financial inclusion has received academic attention for four reasons. First, it is considered a major strategy to achieve the United Nations’ sustainable development goals [23]. Second, it helps to improve social inclusion [24]. Third, it can reduce poverty [25]. Fourth, it brings socio-economic benefits [26]. The government used financial inclusion in Argentina to draw people into the formal banking system. People began to use more debit and credit cards, which led to more consumption in the formal markets, which the government can easily tax [27]. In Bangladesh, financial inclusion was achieved through financial innovations such as SureCash (Mobile Money Transfer), which reached women and the poor [28]. In developing Asia, less than 27% of people have an account in a formal financial institution, and only 33% of enterprises have credit or loans from a financial institution. High costs, geographic access and lack of identification were major barriers to financial inclusion in developing Asia [29]. In Australia, remote Indigenous groups were the most financially and digitally excluded. While many of these communities have mobile phones (half of which are smartphones), mobile phone banking is unpopular [30]. The link between these groupings is that informal sector workers may lack financial literacy. As such, they may have comparatively less knowledge of financial planning, such as superannuation schemes for retirement planning. This is expected to be a severe problem in developing countries where the informal sector is more prevalent. Discussing superannuation schemes in other developing countries helps situate our paper within the broader literature focusing on superannuation schemes in developing countries.\n\nExisting investment opportunities and support for farmers in Fiji come through the Department of Cooperatives. The department, introduced in 1947, focuses on promoting the development and establishment of rural Agri-based production [31]. Sugar cane farmers form cooperatives and buy sugarcane harvesters in many communities across, something impossible to achieve by an individual or small group of farmers [32,33]. Cooperatives alone will be unable to solve Fiji farmers’ retirement issues. Another option for farmers in Fiji to invest is trust funds. Fiji has two trust funds, the Unit Trust of Fiji [34] and the Fijian Holdings Unit Trust [35]. Investing in these trust funds allows you to earn dividends and growth of the price of your units over time. In this study, we enquire about other avenues of savings that market vendors use other than FNPF.\n\nSuperannuation is a form of retirement planning which can be classified as long-term financial planning. A superannuation is the compulsory deduction of a specified amount of labour compensation to accumulate a retirement nest egg. This deduction exists only for those who hold jobs at either private or public institutions. Jefferson and Preston [36] argue that increasing personal savings is an alternative to superannuation that can be considered for those who do not know of superannuation contributions. This is a plausible alternative for those individuals who are informal workers, such as farmers. Although not without drawbacks, individuals may need to withdraw these accumulated savings, which is counterproductive. Altfest [37] presents an overview of the growing field of personal financial planning (PFP) and attributes its origins to prominent economists such as Modigliani, Becker, and Markowitz.\n\nPFP comprises all items of financial interest to an individual. These include tax planning, cash flow planning, investments, risk management, retirement planning and estate planning [37]. Many individuals do not utilize these financial instruments, and a leading explanation for this is that people are not financially literate [38]. This can be extended to market vendors in Fiji. Due to the lack of financial instruments and financial education, market vendors are generally ignored in Fiji regarding superannuation schemes. Thus, we provide first-hand evidence of PFP in Pacific Island countries lacking financial institutions to support the marginalised vendor community. We study the awareness level of market vendors in Fiji of superannuation as a means of saving and the benefits of saving in a superannuation fund.\n\nRetirement planning broadly relates to financial literacy. There are numerous literatures on well-established financial literacy programs. However, most case studies are unique to the USA. The scarcity of basic financial concepts harms retirement planning, participation in stock markets, and borrowing behaviour [39]. Lusardi and Mitchell [40] used their 2004 survey by including the US Health and Retirement Study (HRS) to investigate the rationale for workers’ decision toward retirement savings avenues for collecting relevant financial literacy information and their level of financial literacy. They concluded that older Americans (50 years or older) were more likely to be financially illiterate, which hindered their financial knowledge, a crucial element for financial planning.\n\nFurthermore, individuals are more comfortable using formal methods of collecting financial information like retirement calculators, retirement seminars, and financial experts rather than family, relatives, or co-workers. Similarly, Lusardi and Mitchell [41] used the 2004 HRS study and discovered a strong correlation between financial planning, financial literacy, and housing wealth. They also found that financial planning strongly correlates with financial and political literacy. Following this, Lusardi and Mitchell [42] investigated financial planning using the new Rand American Life Panel (ALP). They found a consistent result with previous evidence from HRS (positive correlation between knowledge of financial matters and retirement planning). Bucher-Koenen and Lusardi [43] explored the relationship between financial literacy and retirement planning in Germany and found that financial literacy had a significant influence on an individual’s retirement planning. Similarly, the importance of financial literacy in retirement planning in the Netherlands using household survey data was justified by Van-Rooij et al. [44]. In the latter research, Van-Rooij et al. [45] used information on smoking and heavy alcohol drinking as a proxy for myopic behaviour, and the results were like previous research. In addition, the studies by Klapper et al. [46] in Russia and Fornero and Monticone [47] in Italy supported the casualty from financial literacy to retirement planning.\n\nAgarwal et al. [38] contributed to financial literacy and financial planning findings by examining the investment behaviour, liability choice, risk tolerance, and insurance usage of program participants in India. The authors found that most respondents were financially literate on interest rates (numeracy), inflation, and risk/diversification but varied across demographic and socioeconomic groups. In a more recent study, Ricci and Caratelli [48] aimed to contribute new insights into Italy’s case by evaluating several indicators of retirement planning and finding that trust positively influences people’s decision to enter private pension schemes and to devote severance pay to a private pension scheme. Kerry [49] reviews that conceptually, retirement planning continues to be poorly delineated and, therefore, narrowly investigated. Empirically, cognitive antecedents of retirement planning remain prominent in workplace and retirement researchers.\n\nAs we discuss financial inclusion in the informal sector and lack of financial planning based on lack of financial literacy, it is also important to review superannuation adoption in other developing countries such as Fiji. In Thailand, Jansuwan and Zander [50] recommend that a pension higher than the available old-age allowance can support farmers in maintaining a better living standard after retiring. The issue, however, is that only a fraction of farmers currently have access to a pension. Older farmers in Thailand may adopt labour-saving farm technologies, and some seek less intense off-farm work. Older farmers also reduce the cultivated land by leasing or selling [51].\n\nIn Indonesia, there is meagre participation of workers in pension fund programs due to inadequate employee pension schemes or occupational pension schemes (OPS), dues that burden employees’ finances [52], and a low level of knowledge about pension schemes [53]. Previous studies indicate that OPS has a positive effect on retirement intentions (RI) [54,55], OPS prevent workers from quitting [56], and the effect of OPS on RI is determined by the structure of the retirement plan [52]. Wang and Zhang [57] studied the impact of the New Rural Society Pension Insurance pensions of China on the mental well-being of the rural elderly and found that pension income improves mental well-being by relieving depression of the rural elderly however, the beneficial effects of pension income are minimal. In China, Eggleston et al. [58] indicate that the Chinese New Rural Pension Scheme (NRPS) income increases the migration of adult children but does not affect elderly living arrangements. Cheng et al. [59] conclude that NRPS leads to adult children living nearby, higher socioeconomic status, and better health status. Liu and Zhuang [60] and Li and Sicular [61] found that pension programs not only provide the older population with additional income but can also improve land use efficiency by shifting the operation of farms away from senior farmers who have been found to be less productive. It also allows them to substitute leisure for work and reduce their dependency on agricultural production. In Sri Lanka, Heenkenda’s [62] study shows that most individuals lack awareness of their Voluntary Pension Scheme (VPS) even if they are active members. The study also indicates that households with many dependents contributed more to dropouts. The study highlights that income, assets, financial inclusion, financial literacy, and social capital significantly influence individuals discontinuing their pension scheme.\n\nThis study complements the literature on retirement planning in the informal sector. While awareness of superannuation funds has not been studied previously, our study shows good awareness of superannuation and superannuation benefits by Fijian market vendors. A distinction that has not been previously made but is vital in studying intentions to use superannuation was studied in this paper. Here, the distinction is made between being aware that there is a superannuation and knowing the benefits that the superannuation offers (we can call this financial literacy). This study suggests that awareness levels do not necessarily lead to the adoption of superannuation. This is mainly because existing superannuation plans are not simple and flexible enough for market vendors and informal workers in particular. Therefore, there is a need for a tailor-made scheme for market vendors and informal workers.\n\nThe methodology collects quantitative and qualitative data from vegetable market vendors in the western division of Fiji via face-to-face interviews. Based on these responses received, commonalities are identified from the responses gathered to derive conclusions about the perceptions of market vendors towards the FNPF savings scheme. Given the difficulties in gathering enough respondents for analysis, the study used a convenience sampling technique, where participants were recruited based on whoever was willing to participate [63].\n\nConvenience sampling was used for data collection as market vendors fall under the administration of local municipal councils whose approval needs to be sought before data collection in their respective markets. Nevertheless, there are drawbacks of convenience sampling such as a potential lack of generalizability or a selection bias where the findings may apply only to the specific group sampled leading to an over-representation of certain groups as well as limiting of the scope of the survey. Nevertheless, convenience sampling is used due to difficulties in obtaining suitable data for analysis such as in developing countries like Fiji.\n\nThis was the case in our research, where approval was not always granted by municipal councils to interview market vendors. As such, we were only given permission to interview three markets in the western division of Fiji and were advised by the market administrators to approach market vendors for interviews only if they were willing to participate. We were also advised by market administrators not to ask questions that could hurt the sentiments of the market vendors, such as their level of education and sexual orientation. Even for markets where we received permission to interview market vendors, market vendors themselves were reluctant to be part of the interviews. For this reason, convenience sampling was adopted.\n\nAn ethics approval was sought from the University of Fiji Research Committee. Verbal consent was sought from market vendors before interviewing them. Nevertheless, we gave our best efforts to ensure a reasonable balance between genders within our sample. 8.4% of market vendors were between the ages of 18 and 30, about 27% between 31 and 40, about 27% between 41 and 50, about 28% between 51 and 60, about 6% between 61 and 70 and 4% above 71. In this study, 31% of the respondents were males, while 69% were females. A major reason for this is that the majority of the market vendors are Females. Vegetable market vendors in this context are full-time market vendors owning a stall at municipal vegetable markets in the western division. The western division in this case study refers to Sigatoka, Rakiraki, and Tavua. Participants were recruited and interviewed between 2017 and 2019. Participants were informed about the research and how data will be utilised. All participants voluntarily participated, and their privacy is fully protected. The authors did not have access to any information that could identify participants during and after data collection.\n\nObjective 1 seeks to identify the determinants of the awareness of FNPF and its benefits. It is fulfilled by regression analysis. Our regression models are specified as follows:\n\nwhere OUTCOME is the dependent variable, which is either FNPF AWARENESS or FNPF BENEFIT, which measures whether market vendors are aware of any savings scheme from FNPF or are aware of the benefits of FNPF. AGE is an ordinal variable that represents age groupings of the survey participants, LTN reflects the location of the survey participants, GNDR is a nominal variable set to 1 for male and 2 for female, SIZE representing the market vendor’s family size, INC represents weekly personal income of the market vendor, DRTN represents duration as a market vendor, SAVNG represents weekly savings, CURRENT SAVNG represents knowledge of current savings products, AVNE represents knowledge of other avenues for savings, and FRMVND measures whether the market vendor is also a farmer or not, and WYRMV measures whether the market vendor would recommend this line of work. AGE, SIZE, INC, DRTN, and SAVNG are ordinal variables with the remainder being nominal variables. Further descriptions are provided inTable 1:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321214.t001\n\nGiven the exploratory nature of our research, we do not make any predictions on the expected signs of the explanatory variables. The variables were drawn from a preliminary literature review, which helped formulate the survey questions [40,43,50,52,53,57,58,62]. Correlation analysis was used to determine whether there are any positive or negative relationships between our variables that could provide us with meaningful relationships. The regression analysis was used to determine factors that determine awareness of savings with FNPF and factors that determine awareness of savings benefits with awareness. They were tested separately to understand whether there are any significant differences between awareness of savings with FNPF and awareness of the benefits of savings with FNPF.\n\nThe Robust Least Squares (RLS) technique using the M-estimation method is used for analysis. This is a powerful statistical technique used to estimate regression models while mitigating the influence of outliers and violations of the assumptions underlying ordinary least squares (OLS) regression. Unlike OLS, which minimizes the sum of squared residuals, M-estimation minimizes a function of the residuals that reduces the weight of outliers, providing more reliable parameter estimates in the presence of heteroscedasticity or non-normal error distributions. This method is implemented to specify different weighting functions (such as Huber, Tukey, or Andrews weights), allowing researchers to tailor the robustness of the estimation to their specific data characteristics. By employing the M-estimation methodology, researchers can achieve accurate and robust inferences, enhancing the reliability of analyses.\n\nObjective 2 is fulfilled by thematic analysis of the interview questions on whether vegetable market vendors prefer tailor-made FNPF programs. The thematic analysis is discussed in the results section. Codes were assigned to the responses to the interview questions. Upon coding all responses, the codes were used to determine underlying themes. The themes were reviewed to check if all codes had been included. The frequency of each of the themes is noted and denotes their importance.\n\nTable 2describes the descriptive statistics of this study. Convenience sampling was used to gather data from 71 respondents composed of: 28 from Sigatoka market, 21 from Rakiraki market and 22 from Tavua market. To observe the measure of central tendency for the dataset, normal distribution is assessed given the possibility of outliers. The values of Skewness, Jarque-Bera and P- Value are considered guided by the rule of thumb If skewness between -0.5 and 0.5 the data is fairly symmetrical, if skewness between -1 and -0.5 or 0.5 and 1 data is moderately skewed and values greater than -1 or 1 signal highly skewed. For notable variables, the distribution ranges from fairly symmetrical to moderately skewed; thus, the mean is discussed.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321214.t002\n\nThe average age of the vegetable market vendor is between 45 and 46 years. This confirms that the vendors are in the later stage of work life and require significant consideration on retirement plans and regular sources of income after retirement. The retirement age in Fiji was revised from 55 to 60 years in 2023. Gender balance was always a priority, the average respondents were females, but the researchers observed that most market vendors willing to be respond were females, and this could also be down to the fact that there were more female vegetable market vendors in the three markets surveyed. On average, the family size of the market vendors were between 4 and 5 members, with median income ranging between $51 and $100.\n\nThe average duration as a market vendor is between 6 years to 10 years. Therefore, the vendors must accumulate sufficient savings in the span of 6 to 10 years or invest wisely into schemes to hedge risks (disruptions in sale activities) and ensure smooth consumption after retirement. The median savings for the vendors is $21 to $40 with preferred savings avenues such as Banks. While banks offer very low returns, market vendors use this avenue based on ease of depositing and ease of withdrawal, especially in the age of SMS and Internet banking. The market vendors are generally aware of savings with FNPF and the benefits of savings with the FNPF. In addition, there was a strong consensus by the market vendors for tailor-made savings schemes from FNPF. Moreover, a moderate number of respondents had reservations in recommending others to work as market vendors given the challenges (low income, disaster risk, price fluctuations and no retirement schemes).\n\nAs stipulated inTable 3below, there were 16 correlations between the 13 variables used for this study. The correlations were identified using Mukaka’s [64] rule of thumb.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321214.t003\n\nAs described inTable 2, the first notable relationship indicates a moderate positive relationship between FNPF benefit and FNPF savings benefit awareness. This indicates that those who benefit from the FNPF are those who are aware of the benefits of savings with FNPF. The second notable relationship indicate a low negative correlation between age and FNPF benefit thus, older market vendors have low awareness on the FPNF benefit savings. As older market vendors are less aware of FNPF benefits, the underlying reason for this could be the lack of financial literacy, as those in this line of work are less educated. The third notable relationship indicates low FNPF Savings awareness and low FNPF Savings benefit awareness in Tavua and Rakiraki. Tavua and Rakiraki can be considered the least economically developed of other towns and cities in this study and this can be attributed to lack of financial literacy attributed to lower education levels. Furthermore, the weekly income earned by the vendor is larger in Sigatoka compared to Tavua and Rakiraki. Sigatoka is considered to be more economically developed of the other two towns. Moreover, higher weekly income restricts market vendors from exploring FNPF benefit. This presents the vendors with the challenges of mitigating risk in times of disaster as earned income will vary based on market conditions.\n\nIt is likely that older people prefer to take up the role of market vendor as the job activity of market vendors is not very demanding giving older vendors’ lot of flexibility (preferred days to sell). On the other hand, market vendors with big family size may look for alternative source of income (quit being a market vendor) as income from vegetable proceeds may not be sufficient. There is low positive relationship between savings and income as vendors attempt to save lower amount of income given the income generated from sale proceeds are not so high. The results also indicate that those market vendors who are aware of savings avenues are also aware of FNPF savings. Being financially literate provides the market vendors the competitive edge in securing a better future.\n\nTable 4presents the results of the FNPF awareness and FNPF benefits model. Among the predictors of the FNPF awareness model, we find statistically significant effects from Age, location, weekly personal income, duration as a market vendor, and whether the market vendor is also a farmer. Age has a negative association on FNPF awareness suggesting that younger market vendors are generally aware of FNPF. Location has a negative association with FNPF awareness. This is not surprising because amongst the western division municipalities considered, Rakiraki and Tavua are generally more less developed than Sigatoka suggesting that the level of local/municipal development may plays a key role in determining whether market vendors are aware of the benefits of FNPF.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321214.t004\n\nSurprisingly, weekly personal income as a negative association with FNPF awareness. Insights on potential reasons are offered by the qualitative interview which suggested that there is a level of distrust on financial institutions in Fiji. There is some weight to this argument given that the market vendors quoted the collapse of the National Bank of Fiji in the 1990’s. The market vendors indicated that they would like to steer clear of financial institutions in Fiji.\n\nMore surprisingly, duration as a market vendor has a positive association with FNPF awareness which appears to conflict with the effect of AGE on FNPF awareness. A closer inspection of the dataset reveals that the duration a person spends as a market vendor appears to be independent of their age given that there is no formal requirement or official retirement age of market vendors.\n\nThe final variable that has a significant effect is whether the market vendor is also a farmer. This has a statistically significant effect suggesting that market vendors who are also farmers are aware of FNPF as a superannuation scheme.\n\nSimilar results are reported in the FNPF benefits model. We find that age and location are negatively related to the awareness of FNPF benefits, duration as a market vendor has a negative association, and other avenues of savings have a positive awareness. Weekly savings and personal income have negative associations, whereas having the dual role of farmer and market vendor has a positive association.\n\nGenerally, about 62% of respondents are aware of savings with FNPF, while about 68% are aware of the benefits of saving with FNPF. This indicates a good level of awareness among market vendors in terms of savings awareness and the benefits of savings awareness with FNPF. This is contrary to the findings of Gough and Hick [52], Loretto et al. [53] and Heenkenda [62].\n\nAs described inTable 5, the models generally satisfy the various diagnostic criteria, such as the residuals being free of autocorrelation based on the Breusch-Godfrey serial correlation LM test, the model having the correct functional form based on Ramsey’s RESET test, and the residuals normally distributed based on the Jarque-Bera test. However, as we expected, both models had the statistical presence of heteroscedastic error variances based on the Breusch-Pagan-Godfrey test. This was corrected using Huber-White standard errors in the main estimates.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321214.t005\n\nObjective 2 of the study is addressed using a thematic analysis of the qualitative question of why vegetable market vendors prefer a tailor-made superannuation plan. From the 71 respondents, only 36 provided reasons for why they preferred or did not prefer a tailor-made superannuation plan for vegetable market vendors. From the 36 participants’ who responded, we coded the responses and identified four themes. These themes included future planning and retirement, financial security, inconsistent income, risks and challenges and economic and social impact. The most common theme was future planning and retirement. Here, respondents provided comments such as, “to have a secured future” (P-40), “for future when we cannot do market vendoring anymore” (P-45), “for our retirement” (P-53), “for our children to benefit once we retire” (P-54) and “it will assist in paying for school fees for my children and grandchildren when I retire” (P-65). The second most common theme identified was financial security with nine responses aligned to this theme. Respondents stated, “I need a tailor-made plan so I can increase my personal savings” (P-6), “...for ease in savings and getting interest” (P-30), “for safe-keeping” (P-57) and “to benefit from interest gained on savings” (P-58). One other theme was inconsistent income, risks and challenges. This theme consisted mainly of respondents who did not prefer a tailor-made plan. They stated, “I do not have consistent income so I cannot contribute regularly” (P-15), “it can be risky” (P-27), “I will have difficulty in withdrawing if I need my savings” (P-33) and “I do not need a tailor-made plan because cannot save” (P-70). The last theme was economic and social impact. Respondents mentioned that “FNPF should visit us to help us contribute as with current system it is too difficult” (P-34), “we need a tailor-made plan for farmers and market vendors so that we can contribute to the economy” (P-37) and “a tailor-made plan will improve the living conditions of farmers” (P-45). The theme of future planning and retirement indicates that vegetable market vendors are concerned about their future and retirement. However, they have no simple and easy means to make contributions to their superannuation. The second theme of financial security describes the vegetable market vendors’ perception of superannuation as a means of financial security in case of emergencies as well as disasters which are common in Fiji [65]. The third theme also highlights some important considerations that the superannuation fund (FNPF) needs to account for when they make a tailor-made plan or for some basic reasons why one is needed. Respondents have highlighted that their inconsistent income is one of the reasons they cannot regularly contribute to superannuation schemes. Additionally, vegetable market vendors cannot regularly withdraw from the fund if needed during disasters and other hardships. These reasons explain why a tailor-made plan is needed for vegetable market vendors and perhaps for agriculture or non-formal sectors. Their inconsistent income should not be a hindrance to contributing, while a mandatory contribution may be required when there is surplus income or savings. The tailor-made plans should also consider that vegetable market vendors and other agriculture and non-formal workers may need to make withdrawals in emergencies, considering the volatile nature of their occupations. This may be the reason why vegetable market vendors prefer to save in a bank and other means over saving in a superannuation fund. Therefore, the tailor-made plan should allow them to make emergency withdrawals in certain circumstances. The final theme of future planning and retirement describes the desire for vegetable market vendors to contribute to superannuation schemes and get annual interest for the future. It will also allow them to contribute to the economy through superannuation fund investments, have emergency funds for emergencies and secure their future upon retirement, just like those in the formal sector.\n\nSuperannuation funds provide a sense of security to members upon retirement and even pre-retirement with benefits such as housing, medical, funeral, and unemployment in the case of FNPF. Therefore, all nationals should have an equal chance to benefit from this scheme. This study attempted to understand vegetable market vendors’ perceptions of the FNPF superannuation savings scheme. This study interviewed 71 vegetable market vendors in Sigatoka, Tavua, and Rakiraki concerning their perceptions of FNPF savings schemes.\n\nThis study generally found that while 95.8% of these vegetable market vendors indicated that they save, 83.1% of them save in banks only, which may indicate that they do not see saving with FNPF as a benefit or option. 62.3% of the respondents know an option to save with FNPF, while 67.6% indicated that they know the benefits of savings with FNPF. While the previous statistics show above-average awareness, it is strange that 83.1% save in banks. The underlying reason is the lack of motivation and intention to adopt FNPF as a savings option. This can be due to the fact that it is easier for vegetable market vendors to save in a bank than with FNPF. Thus, the FNPF needs to make a tailor-made pension contribution scheme for vegetable market vendors, farmers and those in the informal sector.\n\nOur findings have significant policy implications. Firstly, 94.4% of the respondents indicate that they will welcome a tailor-made savings scheme from FNPF. Considering this and other findings, Fiji and FNPF should tailor-make a pension scheme for vegetable market vendors, farmers and those in the informal sector. The current FNPF structure is a pro-formal sector where employees and employers have a portion of their income and contribution by the employer directly deposited into an employee’s FNPF account. This does not suit informal sector workers such as market vendors because their income fluctuates, and there are no other formal avenues in which they can easily and flexibly contribute to their FNPF account like their formal sector counterparts. This tailor-made plan needs to be flexible and easy for informal sector workers to contribute to. One way this can be achieved is through the only formal payment that market vendors make, the market vendor fees that are paid to the municipal council. The respective stakeholders such as FNPF, respective ministries and local municipal councils, can liaise and add an optional or fixed contribution to the market vendor fees market vendors will easily be able to contribute. After collection of the fee, local municipal councils can credit the amount to the FMPF account of respective market vendors. This creates a simple, flexible and easy way for market vendors to make FNPF contributions. This is important because market vendors work Mondays through to Saturdays and are unable to leave their market stalls to deposit FNPF contributions.\n\nThe need for a tailor-made pension scheme for farmers has been recommended in prior studies such as Jansuwan and Zander [50]. While awareness is high in market vendors towards FNPF savings and awareness of savings benefits with FNPF, their intention to save with FNPF is low. The underlying reasons for the lack of intention could be fluctuating income, lack of withdrawal availability and a structure that does not allow market vendors to easily contribute to their FNPF accounts. Therefore, the need for a tailor-made FNPF plan is justified as discussed above. This finding reveals that contrary to the lack of and the need for awareness of pension schemes for farmers by Gough and Hick [52], Loretto et al. [53] and Heenkenda [62], the intention to save in superannuation savings take the centre stage when awareness levels have been attained. Both these implications must be transformed into policies as occupational tailor-made pension schemes will prevent workers from quitting [56], improve the mental well-being of the rural elderly [57], better socio-economic and health status [59], and improve land use efficiency by shifting operations of farms from the elderly farmers who are found to be less productive. The entire spectrum for superannuation funds is to provide retirement benefits to its members. This should not be based on one’s line of work or the amount one earns, and therefore a tailor-made savings scheme for vegetable market vendors, farmers, and those involved in informal sectors should be developed.\n\nConsidering the debate on the role of financial literacy, despite the vast literature on developed economies, it is comprehensible that financial progress cannot be the absence of financial literacy. Our findings showed that the market vendors know the importance of saving. However, the avenues to save are restricted, with 83.1% saving in banks. Fiji needs to maintain its financial literacy programs while also strategizing means to increase an individual’s intention to save, especially in superannuation funds. The Reserve Bank of Fiji has undertaken an active role in setting up the national financial inclusion taskforce together with a financial literacy mascot, ‘Vuli the Vonu’. The policy implication is that we need to move away from a ‘one shoe fits all financial literacy program’ and redefine the financial literacy program to be tailor-made. More importantly, there needs to be a tailor-made savings product that is easy and flexible for informal sector workers such as farmers and market vendors.\n\nSecondly, the policy setup should be redirected from a macro to a micro perspective. That is, instead of policies for the agriculture sector, the policies must focus on managing different industries within the agriculture sector as they have a modus operandi. This would provide a more stable platform to market vendors and deter them from withdrawing from the agriculture sector. Finally, bearing the resource constraint posed on a small nation, the local towns and city councils, through the market master/administrator, can engage in a Memorandum of Understanding with FNPF to facilitate the monthly collection of contributions for FNPF from willing market vendors. These implications can transcend to countries with similar situations, such as Fiji. This ensures that retirement benefits are available to agriculture workers so that the industry retains workers and more people are attracted to boost agricultural output.\n\nNevertheless, a major limitation of this study was that certain municipalities did not permit us to conduct our interviews. This severely limited our ability to gather the necessary data on market vendors from Ba, Nadi, and Lautoka. In municipalities where we were allowed to interview market vendors, market vendors were also reluctant to participate, so convenience sampling had to be utilized. Due to time and budget constraints, we could not extend our survey to include market vendors in the central and northern divisions. As such, it is possible that the sample is subject to selection bias where the views of the observed market vendors are representative of the views of market vendors in the western division of Fiji. Future research should consider a more representative sample. Nevertheless, the lack of access to superannuation packages is a pervasive issue across all major vegetable markets in Fiji. This brings to light another limitation of this study. Specifically, the sample size is a bit small for regression analysis. A power analysis for regression with eight regressors with a moderate effect size of 0.15 and minimum statistical power of 0.8 returns 108 respondents [66]. Future research could overcome this limitation and explore further dimensions, such as the willingness of the FNPF to accommodate the requests of market vendors, namely having a special FNPF employee collect and update the contributions of the market vendors.\n\nhttps://doi.org/10.1371/journal.pone.0321214.s001\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321214.s002\n\n(DOCX)",
    "category": "economics"
  },
  {
    "title": "The distribution of technology induced job loss: Evidence from a population-wide study in Norway",
    "authors": "Bjørn-Atle Reme, Ole Røgeberg, Jonathan Wörn, Bernt Bratsberg, Vegard Fykse Skirbekk, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321072",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321072",
    "content": "Globalization and automation are leading to skill-biased structural changes in the labor market, resulting in the polarization of employment opportunities. These shifts are raising concerns about growing earnings inequality and gender disparities, particularly in occupations characterized by routine cognitive and physical tasks. This study utilizes comprehensive individual-level data from Norway to analyze gender differences in the routine intensity of occupations. The findings reveal significant and growing gender disparities. These disparities are most pronounced among individuals with low socioeconomic status. The analysis further identifies increasing gender differences in educational attainment as the primary contributor to the growing gender differences. Our results highlight the role of educational inequality in driving labor market disparities, emphasizing the need for targeted policy interventions to address these gendered dynamics, particularly among lower socioeconomic groups.\n\nCitation:Reme B-A, Røgeberg O, Wörn J, Bratsberg B, Skirbekk VF (2025) The distribution of technology induced job loss: Evidence from a population-wide study in Norway. PLoS ONE 20(4):\n           e0321072.\n        \n        https://doi.org/10.1371/journal.pone.0321072\n\nEditor:Satabdi Mitra, KPC Medical College and Hospital, INDIA\n\nReceived:August 24, 2023;Accepted:February 28, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Reme et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The data used in this study encompasses educational outcomes, income, employment records, health records and demographic information for entire cohorts of the Norwegian population. These data were made available on loan for research purposes. Other researchers may apply for access to the same sources - see “helsedata.no/en” and “https://www.ssb.no/en/data-til-forskning/utlan-av-data-til-forskere”.\n\nFunding:This work was financed by the Research Council of Norway through its Centres of Excellence funding scheme (project number 262700) and the project DIMJOB (project number 296297). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:We declare no competing interests.\n\nIn recent decades, skill-biased technological change has allowed firms to automate and offshore routine-intensive tasks. This process has resulted in the erosion of low-skilled and mid-level jobs, while simultaneously increasing returns to education [1–4]. These trends are expected to continue. According to a study from the Organisation for Economic Co-operation and Development (OECD) covering 32 member countries, 14% of jobs were classified as highly automatable [5]. The disappearance of routine-intensive occupations may not necessarily result in an increase in long-term unemployment, as it is also expected to generate new opportunities and product markets that could drive labor demand [6]. From a classical economics perspective, labor saving automation frees up labor for new tasks, though the reconfiguration of the economy may involve a slow and painful shift in the labor market structure [7,8]. In fact, a recent OECD policy-brief found that countries with higher investments in robotics experiencedhigheremployment growth [9], but also heightened job instability among workers in roles requiring less formal education. This raises the question of whether a continuation of these trends will serve to amplify or dampen pre-existing inequalities [10,11], such as differences between individuals with low and high education levels.\n\nSeveral studies have identified men in occupations requiring less formal education as a group that has experienced stagnation or declines in both wage level and labor market participation [12,13]. This development has coincided with a decline in marriage rates, fertility, and health outcomes [13–15]. While the reasons behind these developments are largely unknown, it has stirred debates among policy makers and academics as to the role of technological development.\n\nNorway is a small, open economy with a highly educated workforce, extensive social safety net, and a compressed wage structure with centralized wage bargaining and strong labor unions. These factors have been argued to promote the adoption of technological innovations by industry [16]. Over recent decades, Norway has experienced both an increase in employment within high-skill occupations and a rise in automation through the use of industrial robots, reflecting broader trends observed in other developed economies [17]. Recent evidence from Norway’s manufacturing sector, which leverages import data on industrial robots, suggests that occupational groups particularly vulnerable to automation experience a decline in employment share and wages but also show an increase in unionization [18]. This suggests that labor unions may play a role in mitigating some of the negative impacts of automation. While previous studies primarily have focused on the negative impacts of automation on employment or inequality, less is known regarding the distribution of this risk across the population and to what extent we should expect it to dampen or amplify pre-existing socioeconomic differences. In particular, evidence on the development over time within subgroups and its association with other known risk factors of social marginalization, is scarce. We hypothesize that men with lower education, who are more likely to be in routine-based occupations requiring fewer social skills, are at an increasingly higher risk of automation. Such a trend could exacerbate existing social inequalities [19].\n\nThe study aimed to investigate how a widely used indicator of occupational automation risk is associated and aligned at the individual level with measures of socioeconomic status in a register based study of the full population of Norwegian 45-year-olds, and how this differs for men and women. Our specific objectives were to (i) examine and explain the development in gender-specific risk across birth cohorts, and (ii) to estimate the association with other risk factors of social marginalization, including educational attainment, income, family background and health measures.\n\nWe used linked population-wide administrative register data, covering information from several national registries. The registers were linked by Statistics Norway and then deidentified before researchers were allowed access. The acquisition of the data was part of the data structure at the Center for Fertility at the Norwegian Institute of Public Health, where data sets from the different registers were linked and stored at a secure server hosted by the Services for sensitive data (TSD), University of Oslo.\n\nIn this study we used demographic information and family status (national population register), labor market history (employer and employee register), educational attainment (national educational database), and physician visits (Norway Control and Payment of Health Reimbursements database; KUHR). The data were accessed by the researchers on March 1st, 2020.\n\nOur study period covers 2003–2018, as this was the period where we had population wide records of occupational codes. Given the considerable differences in early-career labor market trajectories and the timing of family establishment across education levels, we included individuals at age 45 in each year. This approach, choosing mid-career, minimizes the risk of misleading associations arising from such variations in timing, driven by education. Hence, our sample consisted of the full population of individuals born 1958–1973 who were employed in the year they turned 45 and living in Norway (N =  900,559).\n\nTo measure structural risk of automation at the occupation level, we use the routine task intensity (RTI) index suggested in Acemoglu and Autor (2011) [20]. This approach to measuring routine intensity has been applied extensively in the labor economics literature on the impacts of skill based technological change, starting with the seminal contribution of Autor et al. (2003) [21]. The measure is a theoretically informed indicator of structural economic risk, classifying occupations based on the tasks performed in it. In particular, the index captures the extent to which an occupation is characterized by routine tasks in the cognitive, manual or interpersonal domain. This reflects an economic theory of automation predicting that routine tasks are more easily automated, an assumption that has received extensive empirical support in work employing the RTI index [21]. Measurement of the content of job tasks were retrieved from the O*NET database. This database consists of a highly detailed description of tasks performed in an occupation. From the large set of measurements in O*NET, Acemoglu and Autor (2011) suggests a subset of items which describe these dimensions. To summarize these items to a one-dimensional RTI measure for each occupation, we used the method suggested by Lewandowski et al. (2017) [22]. Last, to ease interpretation, we standardized the RTI score distribution in the sample to be mean zero with a standard deviation of 1 (RTI z-score). For further details on the construction of the Routine Intensity Index (RTI), see Supporting Information (“Constructing the routine intensity index (RTI)” inS1 File).\n\nThe RTI is one of two commonly used measures used to assess the risk of automation, with the other being the Frey-Osborne index (FOI) [21,23]. Although these measures are strongly correlated (seeS1 Table), we based our analysis on the RTI for the following reasons. First, the RTI is task-based – it assesses to what extent a job consists of tasks that could be automated – while the FOI is based on expert assessment of occupations. Hence, the RTI has a more robust theoretical foundation, as it allows for occupational scores to change with their task content [24]. Additionally, the RTI has done comparatively better in predictive tests [25], and has been used in an extensive literature on skill biased technological change [2,21,26–28] (see [29] and [30] for a description and discussion of the difference between these measures, and other alternative measures used in the literature).\n\nThe main analysis in this paper is based on the 2003 version of the RTI – the first year of our study period. However, in the Supplementary material we also present all main results using both the FOI and the RTI based on 2019 O*NET data to assess robustness of our conclusions against changes in task content over time.S1 Tableshows that all these measures of structural change are highly correlated, and our main conclusions are therefore independent of the selected measure.\n\nOther measures used as covariates for stratification in the analysis were the following:\n\nEducation:The highest level of completed education, available from the National Education Database. There are 9 levels within the ISCED classification, where level 9 is “unknown”. In the analysis we either use 4 categories: primary (1–2), secondary (3–5), 1–4-year university education (6) and master and higher university education (7–8), or dichotomize by whether or not the individual had university level education or not, i.e., 1–5 vs 6–8, referred to as “low” and “high” education, respectively.\n\nOwn income:Own income was retrieved from the income tax register. We calculated birthyear- and gender-stratified income quintiles. In the main part of the analysis, we use a binary variable indicating whether the individual belonged to the lowest income quintile.\n\nFather income: Father’s income was retrieved from the income tax register. We calculated the father’s income quintile at age 40, stratified on his birth cohort. In the main part of the analysis, we use a binary variable indicating whether the father belonged to the lowest income quintile.\n\nMarital status: Marital status was retrieved from the official marriage register. This contains complete records of marriages in Norway since 1974. For the analysis we used a binary indicator for whether the individual was registered as married at age 45. Hence, separated couples, or couples that for other reasons did report to the register, were not captured by our measure.\n\nChildlessness: Using the population register we created a binary indicator for whether the individual was childless at age 45.\n\nMusculoskeletal/psychological problems: We used the register of primary care utilization (KUHR) to create a binary indicator for whether the individual had visited primary health care (general practitioner) for musculoskeletal (L-chapter symptoms or diagnoses) and/or psychological (P-chapter symptoms or diagnoses) problems during the year when being 45-years old. These two chapters were chosen, as they are the most common reasons for both health problems and sick leave among 45-year-olds in Norway.\n\nTable 1provides summary statistics across covariates, excluding covariates based on creating groups based on the underlying distribution (quintiles for own income and parental income).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321072.t001\n\nAll analyses were conducted using R, version 4.1.2.\n\nOur sample included all individuals born between 1958 and 1973 who were employed in the year they turned 45 and resided in Norway. The database contains all registered employer-employee relationships in Norway each year, hence covering all employed wage earners. Occupational RTI scores were assigned to individuals based on their main occupation in their employment records at age 45.\n\nOur aim was to examine how the risk of automation at the occupational level was associated with gender and various measures of socioeconomic status. This was achieved by estimating RTI z-score in different bivariate and multivariate regression models, stratified by gender. Hence, with this approach we both estimate RTI z-scores, and assess to what extent RTI z-scores can be explained by our explanatory variables.\n\nFirst, to assess time trends, we estimated the year- and gender-specific average RTI z-scores using regression models. Year and gender were included as binary indicators, hence the approach is equivalent to the conditional means. Since we used binary indicators, the method is semi-parametric, not resting on strict assumptions related to functional form.\n\nSecond, we examined how the structural risk of automation (RTI z-score) was associated with our measures of socioeconomic status and health (see Data and analytical sample). These models also included birth cohort dummies to adjust for potential time trends.\n\nThird, we performed an attribution analysis where we estimated how much of the increase in automation risk gender gap could be explained by the various covariates included in the regression models. This analysis was carried out in two steps. First, the gender-specific change in covariate levels over the period 2003–2018 was calculated. Then, to estimate the contribution, we multiplied these changes by the corresponding covariate regression coefficients from the multivariate model to estimate the relative impact of each risk factor to the evolving gender-specific risk of automation.\n\nFinally, to provide a detailed description of the variation in occupational risk scores in the most current population of 45-year-olds in our data - birth cohort 1973 - we estimated the RTI z-score for each observed combination of covariate values, separately for each gender. The results were plotted, ordered from low to high, in a bubble scatter plot where the bubble size reflects the size of the covariate group. To examine how these patterns have evolved over time, we also reproduced the plot for the first birth cohort in our data (born in 1958).\n\nThe ethical approval for this study was given by The Ethics Committee of South-East Norway (#2018/434). Based on Section 35 of the Health Research Act, participant consent was waived by the Committee. Data from the different registers were linked by certified researchers who only had access to encrypted personal ID-variable. Extensive measures were taken to maintain the security and confidential handling of the research data. Throughout the process of analyzing data and presenting findings, we are committed to preventing stigmatization and to upholding ethical principles of honesty and transparency in reporting our findings. To achieve this, we used neutral language and avoided portraying vulnerable groups in ways that might be perceived as burdensome. Additionally, the study does not report on group sizes that could potentially disclose information about individual statistical units, in accordance with the recommendations outlined in the Handbook on Statistical Disclosure Control [31].\n\nOur data covers the 15-year period 2003–2018. We first examined the development in routine intensity across this period, separately for each gender (Fig 1). In the supplementary materials we also present the development in RTI z-score for different levels of each covariate used in the analysis (S1 Fig).\n\nThe figure shows the yearly average RTI z-score, stratified by year, for 45-year-olds (birth cohorts 1958 to 1973) by gender. The 95% confidence intervals are indicated by the error bars. SeeS2 Tablein the Supplementary Material for a corresponding table.\n\nThe figure shows the yearly average RTI z-score, stratified by year, for 45-year-olds (birth cohorts 1958 to 1973) by gender. The 95% confidence intervals are indicated by the error bars. SeeS2 Tablein the Supplementary Material for a corresponding table.\n\nhttps://doi.org/10.1371/journal.pone.0321072.g001\n\nWhile there already was a substantial gender difference in standardized routine intensity in 2003 - the score was 0.13 [95% CI, 0.12–0.14] for men and -0.13 [95% CI, (-0.14)-(-0.12)] for women - the difference gradually increased up until 2018, to 0.18 [95% CI, 0.17–0.19] for men and -0.20 [95% CI, (-0.21)-(-0.19)] for women. In the Supplementary material we also present the average risk score using the Frey-Osbourne index (S2 Fig), RTI 2019 z-score (S3 Fig), and not z-standardized RTI scores (S4 Fig). It should be noted that when presenting time trends with the FOI or raw RTI-score, the time trend is downward sloping, indicating that the overall risk of automation is falling during the study period. However, the decrease is smaller for men, causing an increasing gender gap.\n\nIn bivariate analyses, RTI z-score was most strongly associated with low education (education below university level) with coefficients of 1.11 (p <  0.001) for women and 0.82 for men (p <  0.001) (Fig 2A). Regarding gender, the association between RTI z-score and socioeconomic risk factors were higher among men for almost all socioeconomic indicators assessed. See the Supplementary material for models using the Frey-Osbourne index (S5 Fig) and RTI 2019 z-score (S6 Fig).\n\nThe figure displays regression coefficients from (A) bivariate and (B) multivariate regression models, with the RTI z-score as the outcome variable for all 45-year-olds between 2003 and 2018, separately by gender. The 95% confidence intervals are indicated by the error bars. Detailed regression tables are provided in the Supplementary Material (S3 Table).\n\nThe figure displays regression coefficients from (A) bivariate and (B) multivariate regression models, with the RTI z-score as the outcome variable for all 45-year-olds between 2003 and 2018, separately by gender. The 95% confidence intervals are indicated by the error bars. Detailed regression tables are provided in the Supplementary Material (S3 Table).\n\nhttps://doi.org/10.1371/journal.pone.0321072.g002\n\nThe gender differences in regression coefficients shown inFig 2could explain a gender gap in the RTI. However, to understand why this gap has increased over time, we also need to consider gender-specific changes in the prevalence of relevant risk factors. To explore this further, we conduct an attribution analysis to assess how the gender-specific development of each risk factor contributes to the overall change in the gap. This analysis was carried out in two steps. First, the gender-specific change in prevalence over the period 2003–2018 was calculated (Fig 3A). Second, to estimate the contribution, we multiplied these changes by the regression coefficients from the multivariate model (seeFig 2B) to estimate the relative impact of each risk factor to the evolving gender-specific risk of automation. These results are shown inFig 3B.\n\n(A) Share of 45-year-olds in 2003 and 2018 exposed to various risk factors. (B) Estimated impact of changes in exposure, calculated by multiplying the change in share (from Panel A) by the corresponding regression coefficient for each characteristic, based on a multivariate regression of the RTI z-score on all risk factors (seeFig 2B).\n\n(A) Share of 45-year-olds in 2003 and 2018 exposed to various risk factors. (B) Estimated impact of changes in exposure, calculated by multiplying the change in share (from Panel A) by the corresponding regression coefficient for each characteristic, based on a multivariate regression of the RTI z-score on all risk factors (seeFig 2B).\n\nhttps://doi.org/10.1371/journal.pone.0321072.g003\n\nThe largest change in risk factor exposure was related to an increase in higher education (and correspondingly a decline in the share with low education;Fig 3A), especially among women (from 33 to 58 percent). There was also a substantial increase in the share of the sample that were unmarried, both among men (from 37 to 49 percent) and women (from 35 to 47 percent). Regarding the impact of the change in exposure on RTI z-score, i.e., when combining the strength of association (Fig 2B) with the change in exposure (Fig 3A), the strongest impact was found for education with an estimated impact on the RTI z-score of -0.117 (95% CI (-0.116)-(-0.118)) for men and -0.197 (95% CI (-0.195)-(-0.198)) for women.\n\nThe estimated RTI z-scores from a multivariate model applied to the 2018 cohort of 45 years old individuals (birth cohort 1973) showed substantial variation across combinations of risk factors (Fig 4). While the predicted RTI z-scores were -0.75 [95% CI (-0.78)-(-0.72)] and -0.80 [95% CI (-0.83)-(-0.77)] among highly educated married men and women with children and from high SES families, the corresponding RTI z-scores were 0.82 [95% CI 0.69–0.95] and 0.37 [95% CI 0.17–0.58] among less educated unmarried men and women without children from low SES families (seeS4 TableandS5 Tablefor corresponding tables). To examine how this distribution has developed over time, we also estimated this model for the 2003 cohort (1958 birth cohort). The comparison across cohorts reveals that while the gender difference in automation risk declined among highly educated individuals, it has remained substantial among those of lower education. Hence, considering the increasing share of women taking higher education, it supports our finding that the increasing gender gap is due to a large shift in the share of women with university education (S7 Fig).\n\nThe figure presents predicted RTI z-scores based on gender-specific models estimated for the 1973 birth cohort (i.e., those aged 45 in 2018). The explanatory variables were indicators for educational level (Primary educ =  primary education; Secondary educ =  secondary education; Low uni =  lower university (Bachelor’s degree); High uni =  higher university (Master’s degree or higher)), indicators for childlessness (Childless), marital status (Married), and whether the father’s average income rank between ages 40 and 50 was within the lowest quintile among men of the same age group (Low parental income). See Supplementary Material (S4 TableandS5 Table) for detailed tables and the average RTI z-scores for each group.\n\nThe figure presents predicted RTI z-scores based on gender-specific models estimated for the 1973 birth cohort (i.e., those aged 45 in 2018). The explanatory variables were indicators for educational level (Primary educ =  primary education; Secondary educ =  secondary education; Low uni =  lower university (Bachelor’s degree); High uni =  higher university (Master’s degree or higher)), indicators for childlessness (Childless), marital status (Married), and whether the father’s average income rank between ages 40 and 50 was within the lowest quintile among men of the same age group (Low parental income). See Supplementary Material (S4 TableandS5 Table) for detailed tables and the average RTI z-scores for each group.\n\nhttps://doi.org/10.1371/journal.pone.0321072.g004\n\nOur study has three main findings. First, the risk of automation was higher among men than women. This difference increased from 2003 to 2018. Second, the risk of automation was higher among individuals with low socioeconomic status and less social support in the form of a partner and children. Third, the main reason for the increasing gender gap was the growing gender differences in educational attainment. In summary, our study suggests that automation may exacerbate existing social inequalities and create a more unstable job market situation for men that may already struggle financially and socially. And, if disparities in economic and social opportunity are allowed to grow without mitigating policies, they have the potential to create social unrest and political polarization. At the same time, the nature of technological development changes rapidly, as evidenced by the introduction of large language models (LLMs) and multimodal models in recent years. These new developments may have further increased the scope of automation, potentially increasing the scope of routine tasks to also cover language-based tasks such as report writing and analysis.\n\nOur study of Norway provides insights into automation risks within advanced economies, characterized by high educational attainment, strong norms of gender equality, and a well-developed technical infrastructure. A recent study covering 47 countries identified technology adoption and workforce skill levels as key factors driving cross-country variation in routine task intensity [32]. Therefore, developing countries, where larger shares of the population lack formal education, training, or work experience with information and communication technologies, were found to be more exposed to automation risks.\n\nGender disparities in automation risk have been examined across various regions, with mixed findings regarding which gender is more vulnerable [30,33–35]. We have found that the growing gender gap in the risk of automation can be attributed, in large part, to the increasing levels of education among women. It is interesting to note that this gap in education continues to widen, and Statistics Norway reported in 2019 that in many municipalities the share of highly educated women is more than twice that of men [36]. The gap found in this study likely reflects the significant rise in educational attainment among women in the Nordic countries over recent decades. However, the trend of increasing gender differences has, to the authors’ knowledge, not yet been shown in population-wide data covering a long time period. As these developments are likely to continue, it is important for policy makers to understand their implications and carefully consider the best ways to address and mitigate the negative impacts.\n\nAutomation risk varies significantly across sectors, depending on the extent to which occupations consist of more routine tasks, or require interpersonal and emotional skills. The recent Future of Jobs Report by the World Economic Forum, finds that jobs within the care economy and technology sector are growing, while clerical secretarial workers are expected to see the largest declines [37]. In short, industries requiring a combination of emotional intelligence, complex problem-solving, and adaptability will remain challenging to automate in the foreseeable future. However, even within sectors assumed to grow over the coming decades, certain tasks (e.g., diagnostic imaging in healthcare or administrative work in education) are increasingly automated. In summary, the structure of the labor markets, educational trajectories chosen by different genders, cultural norms, technological readiness, industrial composition, will together determine how countries and genders, and other subgroups of the population, are differentially affected by technological developments over the coming decades.\n\nThe main strength of our study is that it covers the full population of employed 45-year-old individuals in Norway over a 15-year period across several important characteristics related to health, financial position, education, and family formation. Hence, in contrast to most other studies on this topic which uses survey data, our study does not suffer from selection bias. At the same time, our study has several weaknesses. First, the study has limited generalizability due to its focus on Norway, a country with unique characteristics related to gender roles, institutional environments, and industry structure. For example, Norway has an extensive welfare system that compensates 62.4 percent of the income in the case of job loss. Hence, the external validity of the results is limited, and likely most relevant for Northern European countries with similar institutions and social norms. At the same time, similar gender-based occupational patterns are likely to exist in diverse geographic contexts. Consequently, the widening gender gap in automation risk and its association with social risk factors are likely present in countries also far from Norway. Second, the scope of the study is limited to what can be quantitatively measured in administrative registers and may not capture important experiential aspects related to technological development that could be measured with qualitative methods.\n\nThe gender difference in the risk of automation has been increasing, with a particular high risk among lower educated men with fewer family ties. This potentially has significant and far-reaching negative impacts on individuals and society as it could exacerbate the concentration of economic, social and health exclusion in the coming decades. Given the increasing disparities identified in this study, policy makers should monitor the development in job market opportunities for various subgroups of the working-age population, and evaluate programs aimed at supporting individuals that are particularly negatively affected. For example, given the heightened risk faced by individuals in jobs that require less formal education, policymakers should consider implementing targeted upskilling programs that equip these workers—especially younger individuals—with skills that are in high demand and less likely to be at risk of automation. Last, provided the recent rapid developments in generative AI, future research should also explore how the risk distribution is evolving over time across age-groups, industries and social risk factors.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321072.s002\n\n(DOCX)\n\nThe figure shows the average RTI z-score, stratified by year for 45-year-olds (birth cohorts 1958–1973) by gender. The 95% confidence intervals are indicated by the error bars.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s003\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321072.s004\n\n(DOCX)\n\nThe figure shows the yearly average FOI, for 45-year-olds (birth cohorts 1958–1973) by gender. The 95% confidence intervals are indicated by the error bars.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s005\n\n(TIF)\n\nThe figure shows the yearly average RTI-2019 z-score, for 45-year-olds (birth cohorts 1958–1973) by gender. The 95% confidence intervals are indicated by the error bars.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s006\n\n(TIF)\n\nThe figure shows the yearly average RTI score, for 45-year-olds (birth cohorts 1958–1973) by gender. The 95% confidence intervals are indicated by the error bars.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s007\n\n(TIF)\n\nThe figure displays regression coefficients from (A) bivariate and (B) multivariate regression models, with the FOI as the outcome variable for all 45-year-olds between 2003 and 2018, separately by gender. The 95% confidence intervals are indicated by the error bars.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s008\n\n(TIF)\n\nThe figure displays regression coefficients from (A) bivariate and (B) multivariate regression models, with the RTI-2019 z-score as the outcome variable for all 45-year-olds between 2003 and 2018, separately by gender. The 95% confidence intervals are indicated by the error bars.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s009\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321072.s010\n\n(DOCX)\n\nThe figure shows the predicted RTI-z-score from a model estimated on the 1958 birth cohort (45 years old in 2003) explaining RTI-z-score with four educational levels, a dummy for childless, a dummy for whether married and a dummy for whether father’s income average income rank between ages 40 and 50 was within the lowest quintile of men of similar age.\n\nhttps://doi.org/10.1371/journal.pone.0321072.s011\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321072.s012\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321072.s013\n\n(DOCX)",
    "category": "economics"
  },
  {
    "title": "Preferences of public sector medical doctors, professional nurses and rehabilitation therapists for multiple job holding regulation: A discrete choice experiment",
    "authors": "Busisiwe Precious Matiwane, Laetitia C. Rispel, Duane Blaauw, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0320854",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320854",
    "content": "Regulating multiple job holding (MJH) among health professionals is challenging for many health systems. The effectiveness of different MJH policy reforms depends on the behavioural responses of different groups of health professionals but little is known about their preferences and likely reactions.\n\nInvestigate the preferences of public sector medical doctors, professional nurses, and rehabilitation therapists for different MJH regulations in two South African provinces.\n\nWe developed a novel discrete choice experiment (DCE) to evaluate the preferences of health professionals for jobs with varying MJH policy interventions. The DCE attributes includedrestrictiveregulations (banning MJH) versusreward-orientedpolicies (increased public sector salaries, expanded overtime, improved clinical practice environment, and better hospital management). We produced an unlabelled DCE using an efficient design and administered it to a representative sample of health professionals. Generalized multinomial logit models were used for analysis. We also investigated group heterogeneity, calculated marginal willingness to pay and estimated uptake for different policies.\n\n1387 participants completed the DCE. The doctors, nurses and rehabilitation therapists were strongly opposed to banning MJH, requiring salary increases of 45.7%, 20.0% and 42.8%, respectively, to accept an MJH ban. Increased public sector salaries significantly increased public sector retention. However, non-financial interventions were also influential. Doctors, nurses, and rehabilitation therapists were willing to forgo 57.9%, 54.8%, and 38.9% of their salaries, respectively, for an improved clinical practice environment. Competent hospital management was also important. There was some preference heterogeneity. Nurses had significantly different preferences for certain attributes compared to the other two groups, and professionals currently engaged in MJH were significantly more opposed to banning MJH.\n\nThis study provides new information on health professional preferences for different MJH regulations. It confirms the importance of non-financial policy interventions in addressing MJH and the need to tailor MJH policy design.\n\nCitation:Matiwane BP, Rispel LC, Blaauw D (2025) Preferences of public sector medical doctors, professional nurses and rehabilitation therapists for multiple job holding regulation: A discrete choice experiment. PLoS ONE 20(4):\n           e0320854.\n        \n        https://doi.org/10.1371/journal.pone.0320854\n\nEditor:Francesca Maria Di Muro, University of Salerno - Baronissi, ITALY\n\nReceived:September 10, 2024;Accepted:February 24, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Matiwane et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data is available fromhttps://doi.org/10.71796/wits-figshare.28570073.v1.\n\nFunding:The National Research Foundation in South Africa's South African Research Chair Initiative (SARChI) (#102219), held by LR, funded this project. The Wits Faculty of Health Sciences Research Committee Individual Research Grant 2021 contributed R12,000.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nMultiple job holding (MJH) or dual practice, where individuals engage in more than one paid job simultaneously, has received increasing attention from labour market analysts, policymakers and researchers [1–4]. Variations in MJH across different labour markets are driven by differences in job opportunities, pay differentials, regulatory regimes and individual worker preferences [5,6].\n\nMany public sector health professionals have a second job in the private sector [5]. This phenomenon has been reported in a range of different countries, at least for doctors [6,7] and nurses [8]. Theoretically, MJH by public health professionals could have contradictory effects on the performance of public healthcare systems [7,9]. On the one hand, MJH might increase the retention of skilled health professionals in the public sector, at a lower cost, which would enhance access, quality, efficiency and equity [10–13]. On the other hand, MJH professionals may decrease time and effort in their public jobs, suffer fatigue and burnout, divert profitable patients to their private practices, or appropriate public resources for private use, which would all compromise public system access, quality, efficiency and equity [6,14,15]. However, there is very little empirical evidence on the balance of those potential impacts in different settings, nor on the contextual factors that may promote more positive outcomes [16,17].\n\nDifferent countries have adopted diverse strategies to regulate MJH among health professionals [17–19]. A few countries rely mainly on professional bodies and peers to regulate unprofessional and unethical practice [9].RestrictiveMJH policies include banning MJH completely, limiting it to specific groups of professionals, specifying maximum hours of permitted MJH, or restricting private practice earnings from MJH [18]. Other countries have focused onreward-orientedMJH policies which include raising public sector salaries, using non-financial incentives to encourage retention, offering more lucrative contracts to health professionals who agree to work exclusively in the public sector, or encouraging the development of private practices within public facilities [9,18].\n\nSome researchers have developed theoretical economic models to explore the dynamics of MJH and predict the likely impact of different policy interventions [12,20–23]. There are also some narrative descriptions of individual country experiences with MJH regulation [18,24]. However, there are few rigorous empirical evaluations of the impact of MJH policies in the health sector, probably due to the methodological difficulties of designing such studies [17]. Indeed, the Cochrane systematic review of interventions to manage the MJH of health professionals found not a single eligible study to include in the review [25].\n\nThe likely impact of different MJH policies is determined by the behavioural responses of health professionals to policy changes. Surprisingly, this is an underexplored area in the health MJH literature [26], even though the methodology is less of an obstacle. The model of Gonzalez and Macho-Stadler [21] makes theoretical assumptions about the probable motivations and responses of health professionals to MJH regulation but empirical studies are rare. For example, Jumpaet al’s [27] qualitative interviews with 20 Peruvian doctors included some discussion about their attitudes to MJH regulation. Our study attempts to address this knowledge gap by using a discrete choice experiment (DCE) to investigate the preferences of South African health professionals for different MJH regulatory policies.\n\nThe South African healthcare system continues to grapple with poor health outcomes, persistent health inequalities, and weak public sector management [28,29]. South Africa (SA) has a mixed healthcare system with a well-developed private sector. The private sector accounts for approximately 50% of national health expenditure, and employs over 60% of health professionals, even though it only services the most affluent 17% of the population able to afford private health insurance [30]. In SA, the Public Service Amendment Act and regulations make legal provisions for MJH, known as remunerative work outside of the public sector (RWOPS) [31–33]. The RWOPS policy was introduced to encourage the retention of health professionals in the public sector. It allows public sector employees to engage in additional paid work in the private sector provided that they have written permission from the relevant authority and that such work is performed outside of their public sector working hours [34]. There has been no formal evaluation of the impact of the RWOPS policy although one government investigation found evidence of abuse by doctors and weak monitoring [35]. There is also limited academic literature on RWOPS in SA [36].\n\nDCEs are a quantitative methodology for evaluating the relative importance of different product characteristics on consumer choices [37]. In health, DCEs have mainly been used to assess patient preferences for different models of healthcare delivery [38,39] or health workers’ valuation of different job characteristics affecting their job choices [40–42]. This paper adds to the small number of studies that have used DCEs to investigate aspects of MJH. Scottet al[43], included a baseline job characteristics DCE in their panel study with Australian medical specialists. One of the job attributes was the percentage of time spent in the private sector, which they then used to analyse the general preference for private sector work and its association with risk aversion. More recently, Pestanaet al[44] did a standard job characteristics DCE with doctors in Portugal but compared the preferences of doctors working exclusively in the public sector with those engaged in MJH.\n\nOur application is more novel. We developed a new DCE to investigate the preferences of South African public health professionals for different MJH policy interventions. We evaluate the trade-offs betweenrestrictiveregulations such as banning MJH, andreward-orientedpolicies such as an increase in public sector salaries or introducing other non-financial incentives to improve public sector retention. The study was done with public sector medical doctors, professional nurses, and rehabilitation therapists from two SA provinces. The inclusion of rehabilitation therapists and the comparison between the three professional groups are also novel in the literature. Information about the preferences and choices of health professionals will aid in predicting their likely behavioural responses to policy interventions which can inform the design and implementation of more effective MJH regulation.\n\nThe study was conducted from July 2022 to October 2022 at 29 public hospitals in two South African provinces, Gauteng (GP) and Mpumalanga (MP). The DCE was part of a cross-sectional survey on MJH conducted with medical doctors (generalists and medical specialists), professional nurses, and rehabilitation therapists (occupational therapists, physiotherapists, speech therapists and/or audiologists) in the study hospitals in 2022. The initial calculated sample comprised 552 doctors and 502 nurses, evenly distributed between the two provinces, along with 237 rehabilitation therapists in Gauteng and 152 rehabilitation therapists in Mpumalanga.\n\nWe recruited public sector doctors, nurses, and rehabilitation therapists from 56 hospitals in Gauteng and Mpumalanga using a multi-stage sampling approach. A stratified sample of 11 hospitals per province was selected randomly from four categories (strata) of hospitals (district, regional, tertiary and central) through a proportional-to-size strategy [45]. GP’s sample included five district, two regional, two tertiary, and two central hospitals, while MP’s sample included six district, three regional, and two tertiary hospitals, as it has no central hospitals [46].\n\nWithin selected hospitals, six clinical disciplines anaesthesia, orthopaedics, paediatrics, obstetrics and gynaecology, internal medicine, and surgery were targeted. Wards within these disciplines were randomly chosen, and all doctors and nurses in the selected wards were invited to participate until target numbers were met. Rehabilitation therapists were recruited from 22 hospitals due to their smaller population size. Additional hospitals, four in MP and three in GP were included to meet sample size requirements for rehabilitation therapists [46].\n\nWe followed the recommended standards for conducting a DCE study [47–49]. We used an unlabelled design with two alternatives plus an opt-out in each choice set. Respondents were asked to select between two public sector jobs (Job 1 and Job 2) containing various combinations of incentives and restrictions of MJH practice. The opt-out allowed respondents to refuse both of the choices offered to better reflect real-world labour market choices [49,50].\n\nSeveral steps were involved in selecting the attributes and levels to be included in the design experiment. First, a literature review on MJH and MJH regulation was undertaken. In-depth interviews were then conducted with key stakeholders across South Africa to gather their perspectives on the effectiveness of current MJH policies and identify potential regulatory mechanisms or enhancements to address MJH. In-depth interviews were also conducted with doctors, nurses and rehabilitation therapists who have engaged in MJH, focusing on their motivations for participating in MJH, their views on the current regulatory mechanisms for MJH, and possible new incentives and restrictions related to MJH. Based on the qualitative findings, we designed a DCE to evaluate the preferences of health professionals for different MJH regulations versus different financial and non-financial incentives intended to make public sector jobs more attractive and thereby decrease MJH.\n\nThe final list of attributes and levels is shown inTable 1. Current RWOPS regulations in SA allow MJH after normal hours with restrictions. The DCE evaluated more restrictive (banning MJH) and more permissive (extended MJH hours and MJH permitted during normal hours) regulatory regimes. Salary supplementation is the main reason in the literature for MJH participation among health professionals [11,14–16], and a salary increase would be the main financial incentive to compensate health professionals for accepting MJH restrictions. This was included as a percentage change in current salary levels to allow comparison between the different professional groups, with four levels to be able to evaluate nonlinear effects. This attribute was also used to calculate willingness-to-pay estimates in terms of salary compensation for the other attributes. Four different employment contracts were included in the DCE design because they have financial impacts that may influence MJH and because more flexible arrangements could be useful in the management of MJH. A part-time post would allow more time in the second job and might better reflect the hours currently worked by professionals engaging in MJH. Increased overtime in the primary job would be an alternative form of income supplementation to MJH. Two non-financial interventions that may influence MJH were also included, with two levels each. The clinical practice environment with adequate resources and staffing to enable quality care has been shown to be important in job selection between private and public sectors [11]. The final attribute focused on improved hospital management, particularly in relation to the management of MJH (RWOPS).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320854.t001\n\nThe final DCE design yielded 256 (43x 22) potential combinations. We first used dcreate in Stata [38] to generate an orthogonal experimental design with zero priors. This was used in the pilot study in two unsampled public hospitals to further refine the attributes and levels and to obtain priors to be used in producing the final design [50]. The final experimental design was generated using an efficient design strategy in Ngene with 16 choice sets. To minimise task fatigue the design was split into two blocks [51]. We also repeated one choice set to assess internal consistency and verify that participants actively participated in the task [51]. Thus, each participant answered nine choice sets in the survey. Each block was presented in two versions, with the order of choice tasks reversed in the second version to account for ordering effects. The four versions of the tool were assigned to participants randomly.\n\nConsenting study participants completed the self-administered questionnaire anonymously on tablets using REDCap (Research Electronic Data Capture) [52]. The DCE tool contained an introductory section explaining the task, attributes and levels (Supplemental File 1), and a practice question. An example of the DCE choice task presented to respondents is shown inFig 1. The questionnaire also included questions on socio-demographics and engagement in MJH during the preceding 12 months.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320854.g001\n\nData was analysed in Stata 17. We used Stata’ssvycommands to account for the complex cluster sampling design, as explained previously [46]. Separate DCE analyses were conducted for the three professional groups. The results were weighted to reflect the population distribution of the study health professionals for different hospital types within the two provinces. Ten participants who did not make trade-offs were excluded from the DCE analysis. We compared the conditional logit model (clogit), mixed logit (MIXL) and generalised multinomial logit models (G-MNL). For the MIXL and G-MNL-II models, we used the Statamixlogit[53] andgmnl[54] ado commands, respectively with appropriate weighting. The G-MNL model had the best fit. The G-MNL model accommodates both preference and scale heterogeneity [55]. Accounting for scale heterogeneity is important in comparing groups which may differ in the variance of their error terms [55]. The DCE results presented here are from the uncorrelated G-MNL-II model, using the responses which included the opt-out, with all parameters as random estimated with 500 Halton draws, and gamma equal to zero. We use the mean regression coefficients and confidence intervals to determine the relative importance of attributes, while the standard deviations of the coefficients in the G-MNL models reflect preference heterogeneity within the sample. Categorical attributes were entered as dummy variables for each level. We compared the categorical and numerical treatment of the salary increase attribute. The results presented are for the numerical analysis of a linear 10% salary increment in all models.\n\nBecause individual characteristics do not vary within choice sets, their impact on preferences is evaluated statistically by including interaction terms between individual and design variables in the models [37]. Three different interaction models were used to assess the influence of health professional group, MJH experience and socio-demographic factors on attribute preferences. The socio-demographic characteristics evaluated were gender, marriage status, having dependants, coming from an urban province and having a professional specialisation, which were shown to be influential in our previous analyses [46]. We did not include all possible interactions but developed more parsimonious final models that include effects of the most statistical significance or policy importance. Although preliminary latent class analysis showed consistent findings, it offered no additional insights on the outcomes of interest, so we prioritised the G-MNL model for its parsimony and relevance.\n\nWe estimated the marginal willingness to pay (mWTP) for each attribute in WTP space from the G-MNL model results. We did this using the Statagmnlcommand [54], with the mean of the salary variable constrained to one, a fixed parameter for the opt-out alternative specific constant, and random coefficients for all other variables. The mWTP indicates the percentage of salary participants were prepared to forgo for improvements in other attributes, or the additional salary required to compensate them for attributes that decreased utility. Finally, to aid in the interpretation of the policy relevance of the regression results, we modelled the uptake of different hypothetical jobs with different combinations of attribute levels. The likelihood of choosing different scenarios was predicted using the estimates obtained from the G-MNL model [54]. Alternative scenarios were compared to the current status quo as a baseline, and results are expressed as the change in uptake from the baseline [53].\n\nThe Human Research Ethics Committee (Medical) of the University of the Witwatersrand in Johannesburg provided ethical approval for this study [M210262]. Study permission was also obtained from the relevant authorities in both provinces. All participants provided electronic informed consent by selecting ‘yes’ before completing the survey.\n\nThe survey response rate was 83.9%.Table 2displays the weighted demographic characteristics of the 1387 participants, which comprised 484 doctors (34.9%), 565 nurses (40.7%), and 338 rehabilitation therapists (24.4%). Rehabilitation therapists were the youngest group on average (32.4±8.7 years) while nurses were the oldest (43.7±10.4), with the doctors in between (39.9±9.7 years). Nurses (91.3%) and rehabilitation therapists (81.7%) were mostly female, but women made up only 44.5% of the doctors. Among doctors, 44.3% were specialists, compared to 32.1% of nurses. Rehabilitation therapists had the highest reported MJH participation at 38.9% (95% CI: 31.1% - 47.3%) in the previous 12 months, followed by doctors at 33.8% (95% CI: 26.4% - 42.1%) and nurses at 8.9% (95% CI: 6.8% - 11.6%). The differences in the prevalence of MJH among the three professional categories were statistically significant (X2= 133.4, p<0.001).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320854.t002\n\nTable 3shows the G-MNL DCE results with separate models for each professional group (models 3.1, 3.2, and 3.3) as well as a pooled model (model 3.4) including interaction terms to test for statistically significant differences in group preferences. The G-MNL-II model had a better model fit than the MIXL and clogit models (Supplemental File 2). The signs of statistically significant attributes were in the expected direction. The coefficients for the opt-out alternative-specific constants were negative and significant for doctors and rehabilitation therapists signifying a preference for the offered jobs. The standard deviations in the G-MNL models were statistically significant for many attributes indicating significant preference heterogeneity even within the professional groups, and the significanttaufor most models confirmed the existence of some scale heterogeneity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320854.t003\n\nIn the stratified analyses (models 3.1, 3.2, and 3.3), none of the groups preferred the more permissive RWOPS regimes (16 hours per week after hours or 8 hours per week during work hours) compared to the status quo of 8 hours per week after hours. However, there was a large and statistically significant aversion to jobs that prohibited RWOPS in all three groups. The interaction model (model 3.4) showed that this aversion was stronger among rehabilitation therapists and doctors compared to nurses, although only statistically significant for rehabilitation therapists.\n\nAs an alternative to restricting MJH, the DCE included several attributes to make public sector jobs more attractive. However, the option of moving to a part-time post with fewer hours in the primary job was not appealing, the coefficient was negative for all three groups although only statistically significant for nurses and rehabilitation therapists. The interaction terms for this attribute in the pooled model indicate that nurses were significantly less enthusiastic about a part-time post than both doctors and rehabilitation therapists (model 3.4). In terms of financial incentives, doctors and rehabilitation therapists strongly preferred jobs with additional overtime but nurses did not. All three professional groups derived significantly higher utility from jobs with higher salaries. The coefficient for a 10% salary increase was highest for nurses, but only the difference with doctors was statistically significant in the pooled model. Regarding non-financial incentives, a positive practice environment with available staff and resources was the most important attribute determining the job choices of the three groups. The coefficients for this attribute were significantly larger than those for a 10% salary increase. Although highly influential for all three groups in the separate models, the interaction terms in the pooled model indicate that the practice environment was significantly more valued by nurses than doctors and rehabilitation therapists (model 3.4). Competent management able to manage RWOPS was also a statistically significant determinant of job choices in all three professional groups (models 3.1, 3.2, and 3.3).\n\nTable 4presents the basic DCE results by professional group in terms of marginal willingness to pay (mWTP). A negative mWTP indicates the amount of salary compensation respondents would require on average to accept an unattractive job attribute, whereas a positive mWTP represents the amount of salary that respondents would be prepared to forgo to keep a positive attribute. According to the DCE results, doctors would require a 45.7% salary increase to accept a job that prohibits MJH, whereas rehabilitation therapists would need 42.8%, and nurses 20.0%. At the other extreme, for a job with adequate resources and staffing which enabled them to provide quality care to patients, doctors, nurses, and rehabilitation therapists were willing to forgo 57.9%, 54.8%, and 38.9% of their salaries respectively. Similarly, for competent hospital management able to manage MJH, doctors, nurses, and rehabilitation therapists were ready to trade 13.7%, 7.7%, and 11.6% of their salaries, respectively. In terms of overtime opportunities, doctors equated a job with 16 hours of overtime to a 23.7% increase in salary, while it was 6.7% for rehabilitation therapists (Table 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320854.t004\n\nTable 5uses the G-MNL DCE results to model the impact of different combinations of attributes on job uptake by the different professional groups. This allows us to evaluate the effectiveness of different compensatory interventions which could be used to offset the impact of an MJH ban. The selected baseline job for comparison was a full-time post without overtime and no salary increase, with an inadequate clinical practice environment and sub-optimal hospital management but allowing 8 hours of RWOPS after normal hours. The model estimated the uptake of such a job to be 22.0% for doctors, 28.8% for nurses and 22.7% for rehabilitation therapists.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320854.t005\n\nIf MJH were prohibited this would decrease job uptake by 11.0, 6.8 and 14.0 percentage points for doctors, nurses and rehabilitation therapists, respectively (Scenario 1). The remaining scenarios evaluate the financial and non-financial incentives required to counteract the impact of a ban on MJH. In terms of financial incentives, a salary increase of at least 50% (Scenario 3) would be required before the decrease in job uptake is reversed for all three groups. Allowing overtime in the primary job would moderate the impact of a ban but not compensate completely in any of the groups (Scenarios 4 and 5). The model indicates that non-financial incentives could persuade health professionals to stay in public posts that banned MJH. A positive practice environment that supports quality care would counteract the impact of a ban for doctors, nurses and rehabilitation therapists with increased uptake of 8.0, 35.3 and 3.9 percentage points above baseline respectively (Scenario 7). Competent hospital management would not be sufficient alone (Scenario 8) but would make an effective package when combined with an improved practice environment for doctors, nurses and rehabilitation therapists improving uptake by 13.7, 40.5 and 10.4 percentage points respectively (Scenario 9).\n\nTable 6compares the G-MNL DCE results for health professionals who did not engage in MJH in the previous 12 months with those who did, in separate models for each group (models 6.1 and 6.2) as well as a pooled model including interactions between MJH practice and the DCE attributes (model 6.3). The significance and relative importance of the DCE attributes were comparable to the results inTable 3and similar between the MJH and non-MJH professionals. However, professionals who engaged in MJH were more strongly opposed to jobs which prohibited RWOPS than those who did not engage in MJH, which was confirmed to be statistically significant in model 6.3. Interestingly, the non-MJH professionals placed a significantly higher value on a 10% salary increase, a better clinical practice environment and more competent management than those currently engaged in MJH (model 6.3)\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320854.t006\n\nWe ran a pooled G-MNL model with socio-demographic interactions to evaluate their impact on attribute preferences (Supplemental File 3). There were no significant differences between male and female doctors, nurses, and rehabilitation therapists in avoiding jobs that prohibited MJH. Married nurses did not differ from single nurses in their preference for jobs that prohibited MJH. Furthermore, generalist doctors valued salary increases more than specialists, whereas nurses from Gauteng province (GP) valued salary increases more than those in Mpumalanga province (MP). All sub-groups preferred a supportive clinical environment, but this preference was significantly stronger among female doctors, female rehabilitation therapists, and nurses from GP.\n\nWe presented the results of a novel DCE evaluating the preferences of South African public sector medical doctors, professional nurses and rehabilitation therapists for different MJH regulatory interventions. We found that all three groups were significantly opposed to a ban on MJH (Table 3). They would refuse jobs that did not permit MJH or require a substantial increase in salary to accept them. Interestingly, none of the groups were clearly in favour of doubling the hours of permitted MJH or allowing MJH during working hours.\n\nAll three professional groups valued salary increases highly, and improved basic remuneration would significantly increase the uptake of public sector jobs. Doctors and rehabilitation therapists were prepared to trade higher salaries for increased overtime allowances, but nurses were not. None of the groups were in favour of part-time posts, even though it might be a more accurate representation of the current split between primary and secondary jobs and would allow more official time in their second private jobs. Improving the clinical practice environment, with adequate staffing and resources to ensure quality patient care, would be a powerful non-financial incentive to increase public sector retention. All three professional groups were prepared to forgo a large proportion of their salaries for such improvements. More competent hospital management was slightly less important but still a significant determinant of job choices.\n\nThere is some support from the DCE that a ban on MJH could be offset by improvements in other job characteristics. The respondents accepted posts that did not permit MJH if there was adequate compensation. A significantly increased salary or a well-resourced clinical environment were sufficient alone to overcome the health professional’s aversion to an MJH ban, but additional overtime or better hospital management would need to be combined with other financial or non-financial incentives. The ranking of attributes was similar between the three professional groups but there were some statistically significant differences in the magnitude of their preferences. The coefficients for doctors and rehabilitation therapists were mostly comparable to each other. However, the nurses were significantly less enthusiastic about part-time posts and overtime and valued the salary increase and clinical practice environment more highly, than the other two groups. The preferences of health professionals who had engaged in MJH in the previous year were also qualitatively similar to those that had not (Table 6). However, MJH professionals were significantly more opposed to a MJH ban and valued the salary increase and clinical practice environment less than the non-MJH professionals.\n\nThis research makes an important contribution to the small literature on the opinions of health professionals about MJH regulation. It is the first study to use a DCE to directly quantify the trade-offs between different MJH policy interventions in the health sector. It is also innovative in comparing doctors, nurses and rehabilitation therapists, and achieved a good response rate of 83.9% which limits selection bias. Other methodological strengths were that we used a rigorous G-MNL model for the DCE analysis and statistically tested differences in preferences between groups through interaction models.\n\nThe study also has several limitations. DCEs are often criticised for measuring stated rather than revealed preferences, although there is some recent evidence of their external validity in predicting real choices [56]. Due to both statistical and cognitive constraints, DCEs are always limited in the number of attributes or levels that can be included. We focused on policy interventions relevant to the SA context, as identified by key informants and health professionals in the qualitative interviews. The study was based in only two provinces and may not be generalisable to the entire country, although Gauteng and Mpumalanga were chosen because they are fairly representative of urban and rural provinces respectively.\n\nThe likely effectiveness of different MJH regulations will vary from one context to another. Many authors have proposed that MJH interventions in low- and middle-income countries (LMICs) will need to be different to those in high-income countries (HICs) [5,6,17,18,21,57]. For example, Garcia-Prado & Gonzalez [9] suggest thatreward-orientedMJH policies are more appropriate in HICs, whilerestrictivepolicies are recommended for LMICs.\n\nHealth policymakers and managers frustrated with the absenteeism of public sector employees engaged in MJH, may be supportive of an outright ban of MJH [58], and this has been tried in a few countries [18]. The theoretical models provide inconclusive advice. Brekke and Sørgard [23] found that an MJH ban may be efficient under certain conditions, while Gonzalez & Macho-Stadler [21] conclude that banning MJH is never desirable, even if a ban could be enforced. However, the empirical country case studies suggest that an MJH ban has limited impact because it is difficult to enforce, particularly in LMICs but even in HICs with stronger regulatory capacity [18]. The risk is that a complete MJH ban might lead to an exodus of skilled health professionals from the public sector to the private sector, undermining the objective of such an intervention which would be to increase access and quality of care for public patients. The respondents in our DCE were opposed to an MJH ban, and the model predicts a significant impact on job uptake. However, the size of the shift was perhaps not as large as might have been expected from the threats of professional groups opposed to a ban [59]. There may be sufficient advantages for staying in a public post in South Africa (SA) even if MJH is banned, or it could be that health professionals are not completely convinced that a ban would be enforced. The fact that compliance with current RWOPS regulations in SA is low with seemingly few consequences [35,58], may support the latter reasoning.\n\nPay differentials between the public and private health sectors are a key driver of MJH and increased public sector salaries might make MJH less necessary for health professionals. Unsurprisingly, increased salary levels strongly influenced job choices in our DCE. We also found that doctors, nurses and rehabilitation therapists would require salary increases of 45.7%, 20.0% and 42.8% respectively, to accept a post that did not allow MJH. In Gruenet al’s [60] survey of MJH doctors in Bangladesh, 100% of primary care doctors and 54% of doctors in secondary and tertiary care said they would give up MJH completely if they were paid higher government salaries. However, the amount of the increase required was not specified. Similarly, in Do and Do’s [61] survey of MJH doctors in Vietnam, 65% of doctors said they would give up their private practices under specific conditions. Approximately 29% of those willing to leave private practice desired a higher basic pay, and the proposed increase was 2.7 times their current pay. Unfortunately, fiscal constraints mean that increasing public sector remuneration is seldom affordable, particularly in LMICs where pay differentials between the public and private sectors are large and government revenue is low [9,18]. Even in HICs that have been able to increase public sector salaries, the evidence is mixed. Sæther [Unpublished work] used a discrete choice model to analyse the revealed preferences of Norwegian doctors and found that a 10% increase in public sector salary levels resulted in a statistically significant but small shift in time allocation away from private practices towards public sector work. However, Mossialoset al[24] report that a raise in public doctor salaries had little impact on MJH in Greece. SA has also already experimented with similar reforms. The so-called Occupational Specific Dispensation (OSD) policy was an increase in public sector salaries, implemented for different categories of health professionals from 2007 to 2009, to improve public sector retention. Unfortunately, the policy was not formally evaluated, and the effects on retention and MJH are equivocal [62,63]. Furthermore, the national economic and fiscal climate has been much less favourable in recent years [64], which makes any significant increase in government salaries extremely unlikely in the near future.\n\nAlthough economic motivations are generally the most important, it is widely accepted that other non-financial considerations play a role in the decision of health professionals to engage in MJH [5]. A second job in the private sector may provide job complementarity, diversity, autonomy, the learning of new skills or career development [5,7,8,43]. Our previous descriptive analysis, confirms those motivations for MJH in this sample of health professionals [46]. Institutional factors are also relevant [5,9]. For example, Hooglandet al[6] found that poor working conditions, inadequate facilities and shortages of drugs and equipment in the public sector, were noted as reasons for MJH by doctors in approximately one-third of the 157 countries included in their review, with similar levels of complaints from both LMICs and HICs. However, despite this recognition, non-financial interventions have received much less attention in the literature on possible MJH policies [17,18,21]. Non-financial attributes were as important as financial attributes in this DCE. Improved public sector working conditions and facility management would be effective interventions in increasing public sector retention, even if MJH was banned. However, it must also be recognised that these are not simple problems to address in SA. Declining public health budgets and the deterioration of public health facilities and services have been noted for years [28,29], as has the poor monitoring and regulation of MJH by public health managers [35,65,66].\n\nLastly, our conclusions about the preferences of MJH and non-MJH professionals were comparable to those of Pestanaet al[44]. They also found that the two groups had similar preferences and that professionals working exclusively in the public sector were significantly more concerned about the clinical practice environment. This would support the arguments for targeting non-financial interventions to increase public sector retention and decrease MJH.\n\nOur DCE study provides new insights into the preferences of different groups of health professionals for different MJH regulatory interventions and confirms the importance of non-financial considerations in MJH decision-making. Such information is useful in the design and tailoring of MJH regulation, particularly in LMICs. However, significantly improved government finances, management and regulatory capacity will be required for the successful implementation of any MJH interventions.\n\nhttps://doi.org/10.1371/journal.pone.0320854.s001\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320854.s002\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0320854.s003\n\n(DOCX)\n\nWe thank the participants for taking part in the survey and the hospital management for facilitating the study.",
    "category": "economics"
  },
  {
    "title": "The assessment of physiotherapy practice is a robust measure of entry-level physiotherapy standards: Reliability and validity evidence from a large, representative sample",
    "authors": "Alan Reubenson, Leo Ng, Vidya Lawton, Irmina Nahon, Rebecca Terry, Claire Baldwin, Julia Blackford, Alex Bond, Rosemary Corrigan, Megan Dalton, Amabile Borges Dario, Michael Donovan, Ruth Dunwoodie, Genevieve M. Dwyer, Roma Forbes, Alison Francis-Cracknell, Janelle Gill, Andrea Hams, Anne Jones, Taryn Jones, Belinda Judd, Ewan Kennedy, Prue Morgan, Tanya Palmer, Casey Peiris, Carolyn Taylor, Debra Virtue, Cherie Zischke, Daniel F. Gucciardi, on behalf of the Physiotherapy Clinical Education Research Collaborative (PCERC), (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0321397",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321397",
    "content": "The Assessment of Physiotherapy Practice (APP) is a 20-item assessment instrument used to assess entry-level physiotherapy practice in Australia, New Zealand and other international locations. Initial APP reliability and validity evidence supported a unidimensional or single latent factor as the best representation of entry-level physiotherapy practice performance. However, there remains inconsistency in how the APP is interpreted and operationalised across Australian and New Zealand universities offering entry-level physiotherapy programs. In essence, the presumption that the psychometric integrity of the APP generalises across people, time, and contexts remains largely untested. This multi-site, archival replication study utilised APP assessment data from 8,979 clinical placement assessments, across 19 Australian and New Zealand universities, graduating entry-level physiotherapy students (n=1865) in 2019. Structural representation of APP scores were examined via confirmatory factor analysis and penalised structural equation models. Factor analyses indicated a 2-factor representation, with four items (1–4) for the professional dimension and 16 items (5–20) for the clinical dimension, is the best approximation of entry-level physiotherapy performance. Measurement invariance analyses supported the robustness of this 2-factor representation over time and across diverse practice areas in both penultimate and final years of study. The findings provide strong evidence for the psychometric integrity of the APP, and the 2-factor alternative interpretation and operationalisation is recommended. To meet entry-level standards students should be assessed as competent across both professional and clinical dimensions of physiotherapy practice.\n\nCitation:Reubenson A, Ng L, Lawton V, Nahon I, Terry R, Baldwin C, et al.  (2025) The assessment of physiotherapy practice is a robust measure of entry-level physiotherapy standards: Reliability and validity evidence from a large, representative sample. PLoS ONE 20(4):\n           e0321397.\n        \n        https://doi.org/10.1371/journal.pone.0321397\n\nEditor:Mansour Abdullah Alshehri, Umm Al-Qura University, SAUDI ARABIA\n\nReceived:September 18, 2024;Accepted:March 5, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Reubenson et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The participants of this study did not provide written consent for their data to be shared publicly. Due to the sensitive nature of the data, namely student academic records, supporting data is unavailable. Data are available on request from the Curtin University Human Research Ethics Committee (hrec@curtin.edu.au) for researchers who meet the criteria to gain access to confidential data.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:NO authors have competing interests.\n\nClinical placements are integral to the training pathways of physiotherapists and other healthcare professionals, providing students with opportunities to integrate knowledge and skills obtained from campus-based learning into real-world settings [1]. Scientifically robust assessment of performance is important to ensure graduates demonstrate the required professional standards necessary for safe and effective healthcare [2]. The Assessment of Physiotherapy Practice (APP) was developed as a standardised instrument, within Australia and New Zealand (ANZ), for the assessment and evaluation of physiotherapy student performance against the same entry-level standards across diverse contextual considerations [3–5]. The APP is the preferred student performance assessment instrument among entry-level physiotherapy programs across ANZ, yet its implementation varies around the interpretation of passing criteria [3–11] and psychometric evidence would benefit from continued investigation [7,12]. Specifically, there is limited research regarding the extent to which the psychometric integrity of the APP generalises across people, time, and context. Relatedly, context of physiotherapy practice has diversified considerably since the inception of the APP 15 years ago with expansion in sectors such as disability and aged care [13,14].\n\nPre-registration physiotherapy education programs require students to meet ‘entry-level standards’ for registration as a physiotherapist. By the end of the physiotherapy degree, graduates need to have demonstrated the necessary knowledge, skills, attitudes and attributes to practise as autonomous, safe and ethical physiotherapy practitioners in the country they studied [15,16]. Within ANZ, the respective Physiotherapy Boards have collaborated to define the entry-level competencies and practice thresholds required for registration [17]. These competencies include the ability to operate as primary contact practitioners and cover seven key roles: physiotherapy practitioner; professional and ethical practitioner; communicator; reflective practitioner and self-directed learner; collaborative practitioner; educator; and manager/leader [17]. To meet these standards, pre-registration educational curricula will vary, yet they must include professional practice, in the form of clinical placements, in a range of areas that physiotherapists work [16].\n\nThe workplace learning environment is complex and dynamic, relying on active participation and social interactions to enhance learning and development [18–20]. In these settings, students can test and apply previously acquired skills and knowledge. Under the supervision of registered physiotherapists, students provide care to a diverse range of patients and clients [21]. The authentic workplace environment can be a powerful and transformative learning space for students when all aspects such as practical experience, mentorship, and collaboration are considered holistically and alongside application of academic knowledge with real-world application [22]. The multidimensional nature of workplace learning can be considered using a practice development crucible metaphor, which illustrates how various considerations interact to shape student learning experiences [20]. This metaphor encompasses four key intersecting influences: (1) workplace influences, which include physical resources and workplace culture; (2) engagement in professional practices, highlighting the importance of student interactions with patients and staff; (3) clinical supervisors’ intentions and actions, reflecting how supervisors’ approaches influence student learning; and (4) students’ dispositions and experiences, which encompass students’ confidence and motivation. Understanding these influences is essential for maximising student learning in clinical placements. Students’ dispositions and prior experiences including their knowledge, skills, and self-reflection, as well as characteristics such as confidence and engagement within the multi-disciplinary team play a crucial role in their learning. Nevertheless, these independent influences rarely occur in isolation and should be understood within the broader context of workplace elements, such as the culture and practices of the workplace, as well as the actions and intentions of clinical supervisors, like the quality of feedback they provide and their motivation to support student learning [23]. Therefore, evaluating student performance in these environments requires a comprehensive approach that considers all these interconnected elements.\n\nAssessment of student physiotherapy practice performance is a complex endeavour that has evolved substantially over the past half century [24]. In the health sciences, work-based assessments are now the primary method for evaluating performance in real-world practice settings through direct observation [25,26]. In these contexts, assessment processes are influenced by the social and cultural contexts in which they occur, including interactions between students, supervisors, and the broader healthcare environment, all of which shape feedback and learning experiences. Work-based assessment within this framework relies on both summative and formative feedback processes to determine the achievement of professional standards [24,26]. A multitude of physiotherapy work-based performance assessment tools exist, yet most come with poorly reported psychometric properties, highlighting the need for ongoing psychometric work to improve the rigour of professional practice assessment processes [12]. In the physiotherapy discipline, evaluation of student performance commonly utilises a longitudinal assessment process, whereby student performance is observed repeatedly over a period of 4–6 weeks, by one or more clinical supervisors. This assessment process allows for variation in performance over time and under different circumstances and contexts [26]. It also acknowledges that workplaces and healthcare often vary, particularly regarding considerations like culture, policies, and processes as well as the relational interactions with supervisors and patients [18,26]. It is widely accepted that reliance on psychometric criteria alone fails to capture the complex social, cultural, and environmental interactions occurring in real-world practice settings and that performance-based assessment needs to involve a holistic, whole system approach [24,26–28]. Nevertheless, in a professional discipline like physiotherapy where there are defined threshold and competency standards for entry into the profession, the availability of a user-friendly assessment instrument with sufficient reliability and validity evidence provides a mechanism for fair and credible performance assessment across different placement settings and over time.\n\nReliable assessment depends, in part, on the use of psychometrically robust tools that provide clear and consistent scoring and interpretation guidelines for clinical supervisors. From a systematic review of the literature, the APP was rated equal or higher than all other international physiotherapy clinical performance assessment tools available [12]. The original APP development work provided initial validity (e.g., dimensionality, differential item functioning, discriminant) and reliability (e.g., inter-rater) evidence [3–5]. The APP was designed to provide a unidimensional assessment of entry-level competency, whereby 20 items are aggregated into a single factor or total score representing overall minimal clinical competence to practice [3,4]. However, alternative interpretations suggest that overall physiotherapy entry-level competence could be better represented by two dimensions: professional behaviours (items 1–4) and clinical skills (items 5–20) [7]. The descriptive labelling of these dimensions as ‘professional’ and ‘clinical’ stems from thematic analysis of item content and indicators associated with each factor. Given this evidence, there is an ongoing question of whether entry-level competency is best captured as a global, single-factor or two-dimensional construct comprised of professional and clinical factors.\n\nGeneralisation of evidence is a cornerstone of the scientific process, serving as a litmus test for the validity and applicability of knowledge. There are numerous ways by which generalisation can be addressed, including but not limited to representative sampling, replication, cross-validation, and consideration of social-cultural and temporal considerations [29]. Individual studies, particularly those with small-to-moderately sized samples, that are imprecise representations of the population, often provide insufficient evidence to draw firm conclusions regarding the psychometric integrity of measurement instruments for science and practice [29]. Owing to its success in related areas of the human sciences [30], we took a ‘Big Team’ science approach to maximise inferences regarding the generalisation of evidence, whereby a large group of collaborators worked together to address a common goal [31]. In 2020, approximately 40 university staff and researchers across 23 ANZ universities established the Physiotherapy Clinical Education Research Collaborative (PCERC). This collaboration created a large and broad representative sample of entry-level physiotherapy placement activity across ANZ. In so doing, our representative sample of physiotherapy students undertaking real-world placements maximises generalisation because the findings are applicable to the broader population and breadth of placement environments, and reduces bias, increases external validity, facilitates meaningful comparisons, supports statistical inference, and enhances the overall credibility of the research. We complement this sampling approach to representativeness with a statistical framework that permits direct tests of the extent to which our findings generalise across people, time, and context.\n\nIn this paper, we report our inaugural project; a large, multi-site replication study, where we aimed to provide the physiotherapy profession with strong evidence regarding scoring protocols for assessment of entry-level performance using the APP. Our specific research questions were:\n\nThis multi-site study replicated the methodology of a single-site study [7], by using archival student APP assessment data from ANZ universities offering entry-level physiotherapy programs. We decided on course completion in 2019 as the target cohort because many clinical placements in 2020, and beyond, were disrupted by the COVID-19 pandemic.\n\nCurtin University’s Human Research Ethics Committee approved the study (HRE2021–0333) and provided approval for consent waiver. All participating universities gained reciprocal ethics and other governance approvals as required.\n\nAdditional information regarding the ethical, cultural, and scientific considerations specific to inclusivity in global research is included in the Supporting Information (S1 Checklist).\n\nThe lead author invited all ANZ universities offering entry-level physiotherapy programs in 2020 (n=25) to participate. Of these, 21 universities had graduating students in 2019andutilised the APP to evaluate clinical placement performance. The remaining four were yet to have graduates (n=3) or didn’t utilise the APP (n=1). Participants included entry-level physiotherapy students from eligible ANZ universities and programs who completed their final APP-assessed placement in 2019.\n\nEach eligible physiotherapy program collated data for their site in a standardised Microsoft Excel template. Site custodians extracted deidentified APP data scores from June 2022 to February 2023, representing the clinical supervisors’ assessment of student performance upon completion of each placement in the participants’ penultimate and/or final year, from paper and/or electronic records, and student demographic data from institution databases (seeTable 1for student and placement characteristics). DG managed the data collection and integration process using the secure CloudStor digital platform hosted by Australia’s Academic and Research Network.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321397.t001\n\nThe APP is the primary physiotherapy assessment tool used to evaluate competency to practice in ANZ and has also been adopted in other countries [13,32]. The 20-item instrument covers seven key domains of physiotherapy practice, namely professional behaviour, communication, assessment, analysis and planning, intervention, evidence-based practice, and risk management (seeS1 File) [3–5]. Clinical supervisors score each item, with reference to accompanying performance indicators, using a 5-point Likert scale (0 = infrequently/rarely demonstrates performance criteria to 4 = demonstrates most performance criteria to an excellent standard) to obtain a total score (out of 80), which is then represented as a percentage.\n\nWe examined the research questions using raw item-level data via two independent yet related analytical phases using Mplus8.10 [33]. Our analyses relied on full information maximum likelihood estimation with robust standard errors (MLR) to utilise all data to estimate models, with listwise deletion for analyses where missing data existed on personal or contextual factors. We calculated omega (ω) as an estimate of internal reliability for latent factors of our preferred structural representation [34]. All analysis scripts and outputs are available on the Open Science Framework (https://bit.ly/PCERC-app).\n\nWe examined the structural representation of APP scores via confirmatory factor analysis (CFA) and penalised structural equation models (PSEM) [35] with robust maximum likelihood estimation and cluster-robust standard errors to account for dependence among observations within each program. Both CFA and PSEM permit investigations of structural representations by modelling associations between observed scores (raw item-level data) and latent factors (i.e., professional or clinical) hypothesised to explain patterns in responses, with unexplained or ‘leftover’ variance captured in residual variances. The main difference between CFA and PSEM is the precision with which latent variables and observed scores are structurally linked. As depicted inFig 1, the strict hypothesis in CFA is that item indicators reflect one latent factor only, whereas item indicators can load on their intended factor and cross-load on other latent factors in PSEM [36]. In PSEM, priors are employed to capture assumptions about certain parameters that act like guidelines or weights, influencing the analysis by nudging it towards these initial expectations [35]. However, as actual data comes in, these priors are updated based on how well they match the data. This process helps in managing complex models, especially when dealing with many variables or when the data is sparse or uncertain. Essentially, priors in PSEM blend what you initially think (your prior beliefs) with what the data is telling you, leading to robust conclusions. In all PSEM models, we used the alignment loss function prior (0,1) to approximate zero for item cross-loadings on unintended factors.\n\nElipses (circles) represent latent variables, boxes represent observed variables, single-headed arrows represent a directional effect of a latent variable on an observed variable, double-headed arrows represent correlation among latent factors, solid lines represent target factor loading and dashed lines represent non-target factor loading. APP = Assessment of Physiotherapy Practice item, e = residual variance.\n\nElipses (circles) represent latent variables, boxes represent observed variables, single-headed arrows represent a directional effect of a latent variable on an observed variable, double-headed arrows represent correlation among latent factors, solid lines represent target factor loading and dashed lines represent non-target factor loading. APP = Assessment of Physiotherapy Practice item, e = residual variance.\n\nhttps://doi.org/10.1371/journal.pone.0321397.g001\n\nWe examined 13 possible structural representations across three broad categories: a unidimensional model in which all 20 items are explained by a single latent factor, as per the original protocol [3]; correlated two-factor solutions in which latent factors characterise ‘professional’ and ‘clinical’ domains [6–8]; and bifactor solutions in which a global factor – entry-level competency – occurs alongside specific factors of professional and/or clinical domains which are anchored to a subset of the overall item pool. We assessed the degree of model-data fit via a multifaceted approach, relying primarily on the comparative fit index (CFI), Tucker-Lewis index (TLI), and the root mean square error of approximation (RMSEA), with values of ≥.90 for CFI and TLI and ≤.08 for RMSEA considered to reflect acceptable fit [37]. Regarding model selection, we prioritised model superiority for lower values for the Akaike Information Criteria (AIC), Bayesian Information Criteria (BIC), and sample sized adjusted BIC (ABIC) [38]; and sound intended factor loadings (~ >.40) and small cross-loadings (~ <.20). In so doing, we preferred an approach where meaningful intended factor loadings can be differentiated quantitatively from meaningful cross-loadings, rather than rely on the rule of thumb of ≥.32 for meaningful factor loadings [39]. Said differently, we prioritised an inference framework where the difference in magnitude of loadings for each item on their intended versus unintended factor were approximately .20. Although we monitored model-data fit indices to evaluate the overall model quality, we focused primarily on conceptually informed item retention because purely statistical benchmarks can undermine construct representation (e.g., breadth, depth). Thus, when an item with a statistically borderline loading represented a theoretically essential aspect of the target construct, we prioritised content validity over strict adherence to cutoff values.\n\nMeaningful group comparisons using aggregate test scores rest on the assumption that latent variables are captured via the same origin and scale and therefore share the same operational definition and meaning across (sub)populations [40,41]. Achieving measurement invariance is crucial for comparing scores between groups or over time, as it ensures that observed differences reflect true variations in the construct rather than inconsistencies in measurement. The subpopulations of interest within our sample include repeated assessments and three elements that characterise contextual features of the professional practice landscape within ANZ, namely placement type (cardiorespiratory, musculoskeletal, neurological, other, or some combination of them), setting (hospital-inpatient, hospital-outpatient, hospital-unknown, or other), and the year in which placements occurred (final year only or penultimate and final years). Measurement invariance evidence is essential for inferences regarding the generalisation of concepts and assessment properties. Evidence that supports measurement invariance across time and context provides confidence that assessment instruments function roughly equivalently irrespective of the circumstances in which they are applied.\n\nTesting measurement invariance involves sequentially comparing nested models in which there are increasingly stricter equality constraints. We deployed the widely accepted 3-stage approach to estimate if the (1) number of factors and items per factor (configural), (2) magnitude of factor loadings (metric), and (3) magnitude of factor loadings and item intercepts (scalar) are equivalent over time and across contextual factors. For nested model comparisons, we relied on changes in fit indices rather than�2differences because they are insensitive to sample size and minor misspecifications [42]. Regarding changes in model-data fit indices, we considered a decline of CFI and TLI of 0.01 or less, and an increase in RMSEA of 0.015 or less to support parsimony or invariance between nested models [43].\n\nIn total, 19 of 21 eligible universities (90.5% response rate) obtained the necessary ethics and governance approvals and provided APP data from a minimum of two, APP-assessed placements per student (seeTable 2for overview). Individual data included 1865 students who collectively completed 9387 APP-assessed placements. We retrieved complete APP records for 8979 (95.6%) placements, providing comprehensive coverage of entry-level physiotherapy placements for the graduating students of 2019 across ANZ (seeTable 1for overview).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321397.t002\n\nModel fit statistics for the total sample and each placement individually are presented inS2 File. Information criteria generally supported the superiority of the PSEM bifactor model with four or six items for the professional dimension relative to the other models tested. All models evidenced acceptable model-data fit according to CFI, TLI, and RMSEA values, except for the PSEM bifactor models with four or six items for professional. The next best working models are the PSEM 2-factor (four or six items for professional dimension) and PSEM bifactor (specific factor anchored to four or six items for professional dimension) representations. However, all models except for the PSEM 2-factor (four items for professional) evidenced an inadequate profile of factors as represented by intended factor loadings and cross-loadings (S2 File). As recommended by one reviewer, we compared and contrasted findings between MLR and weighted least square mean and variance adjusted (WLSMV) estimation. Model-data fit and factor loading estimates obtained with WLSMV estimation are provided in the Supporting Information (S1 and S3 Tables inS2 File). Overall, all models evidenced acceptable model-data fit according to CFI, TLI, and RMSEA values, except for the PSEM bifactor (4 items for professional) representation which did not converge as an unidentified model. Regarding our preferred PSEM 2-factor (4 items for professional and 16 items for clinical) solution, differences in factor loadings were minimal (0–0.15) and consistent with interpretations of intended factor loadings and cross-loading benchmarks between MLR and WLSMV estimation.\n\nCollectively, therefore, model selection indices and factor loadings suggest the 2-factor PSEM model with four items for the professional dimension and 16 items for the clinical dimension is the best approximation of reality regarding these APP data. Factor loadings for this model are presented inTable 3. Most APP items loaded meaningfully onto their respective latent factor (>.40), with higher and more consistent loadings observed for the clinical dimension, and few substantial cross-loadings (e.g., items 2 and 20). One reviewer suggested we remove these poorly fitting items according to statistical criteria alone then recalculate the factor model, and do so iteratively until a well-defined model is achieved. In essence, iteratively modifying the model based on observed loadings within the same dataset can capitalise on chance variation, leading to overfitting and compromised generalisability. This approach resemblespost hocmodel specification, where decisions about item retention and factor structure are made after examining the data rather than being guided by a priori theoretical or empirical criteria. The iterative removal of poorly fitting items based on statistical criteria alone, followed by re-estimation of the model with the same sample, can artificially inflate model fit and lead to a final structure that may poorly generalise to other samples. Most importantly, ignoring conceptual considerations for the removal of items would inevitably weaken our confidence in the content validity of the Assessment of Physiotherapy Practice (APP). Removing items with uncertain statistical properties in our analyses – “demonstrates collaborative practice”, “commitment to learning”, “verbal and non-verbal communication”, and “identifies adverse events/near misses and minimises risk associated with assessment and interventions” – would effectively remove essential content that is required for entry-level physiotherapy performance. The latent factor correlation between the professional (ω =.80) and clinical (ω =.96) dimensions was moderately strong.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321397.t003\n\nModel fit statistics for the invariance tests for the PSEM 2-factor representation with four items for professional and 1-factor CFA model are presented inTable 4. We chose to examine and present the findings of the 1-factor model because it is the original operationalisation of APP for student performance [3–5] and commonly implemented among clinical education programs in ANZ. Overall, model-data fit statistics supported scalar invariance for both the 1-factor and 2-factor solutions across time and contextual factors. Convergence issues – likely because of the limited sample size for placements less than 5 weeks (n = 230) or more than 5 weeks (n = 460) in duration relative to those which were around 5 weeks in duration (n = 8289) – meant that we were unable to test measurement invariance of the APP across placement length. Factor analyses (PSEM) supported the structural validity of the 2-factor model with data obtained from placements which were around 5 weeks in duration; currently, there is an absence of evidence for the structural validity for placements which are less or more than 5 weeks in duration.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321397.t004\n\nOur multi-site replication study supported the psychometric integrity of the 1-factor [3–5] and 2-factor [7] representations of entry-level physiotherapy performance utilising the APP. Relatively speaking, model comparison data support the superiority of the 2-factor model with four items within the professional dimension and 16 items within the clinical dimension. This representation remained largely consistent over time and across diverse practice areas in both penultimate and final years of study.\n\nEntry-level physiotherapy performance is a complex, multidimensional concept. Typically, students must demonstrate diverse skills spanning, at a minimum, cognitive (e.g., clinical reasoning), technical/physical (e.g., manual therapy techniques), and interpersonal (e.g., communication with supervisors and patients) components of practice [14,20]. Accurate assessment relies, in part, on the availability of psychometrically sound assessment instruments, with consistent scoring and interpretation guidelines, for clinical supervisors to use [44]. Drawing from a large representative sample of student performances, we provide strong evidence regarding the internal psychometric properties of the APP including measurement validity and reliability which generalises across the ANZ physiotherapy entry-level placement context as well as temporal and contextual considerations that characterise the complexities of real-world settings. We showed that interpretation of entry-level physiotherapy performance is best operationalised via the APP as a 2-factor concept with domains characterised by professional (items 1–4) and clinical (items 5–20) indicators. The 2-factor representation aligns with contemporary practice, whereby healthcare graduates should be professional, ethically, and legally responsible as well as technically-skilled. Delivering physiotherapy care via assessment, analysis, and planning together with high-quality professional behaviours such as patient rights and consent is essential for safe and effective practice, as per contemporary standards for entry-level performance and registration requirements [15,17]. The 2-factor representation also enhances the utility of the APP for educators and supervisors by highlighting practice areas where students may need focussed support or development. In summary, to meet entry-level standards, physiotherapy students should be assessed as competent across both professional and clinical dimensions of physiotherapy practice.\n\nDespite the firm conclusion regarding the dimensionality of entry-level physiotherapy performance, there are important nuances to the data which require consideration for future use. On the surface, the PSEM 2-factor (four items for professional) model provided the best representation of entry-level competence, yet some item level data were less optimal. Specifically, item 4 “demonstrates collaborative practice” had almost identical factor loadings across professional and clinical dimensions (0.375 vs 0.415 respectively), whereas three items (2 – commitment to learning, 5 – verbal and non-verbal communication, and 20 – identifies adverse events/near misses and minimises risk associated with assessment and interventions) loaded higher on their intended factor relative to the unintended factor, but failed to meet one or both criteria (>.40 on intended and <.20 on unintended factor). Performance indicators within item 4 include “works collaboratively & respectfully with support staff” and “collaborates with the health care team & client to achieve optimal outcomes”. At face value, these features likely cut across most, if not all aspects, of entry-level physiotherapy performance. Commitment to learning (item 2) includes some performance indicators that are subjective in nature, such as “takes responsibility for learning…” and “demonstrates self-evaluation…”. Items that require less subjectivity exhibited higher factor loadings, emphasising the need for clarity in APP item indicators, especially considering the dynamic nature of contemporary healthcare settings [20]. Relying solely on statistical criteria to make inferences regarding item selection and retainment would likely mean that we’d need to compromise the content validity of entry-level physiotherapy performance in some way. Rather than throw the baby out with the bathwater, future work is required to refine these ambiguous items to maximise their conceptual clarity and scoring precision. The conceptual feature of ‘demonstrates collaborative practice’, for example, could be partitioned into separate items that specify with precision exactly what this collaborative approach looks like for professional and clinical elements of performance. Item enhancements could also align with item content in the 2023 update in physiotherapy practice standards within ANZ [17]. As reliability and validity are properties of test scores rather than instruments themselves, we advocate for ongoing validation work on the current version of the APP or any item refinements to the conceptual space.\n\nKey strengths of this study include the utilisation of a Big Team science approach with a large, heterogenous, representative sample and minimal missing data points, alongside rigorous statistical analyses. This combination improves efficiency, precision, confidence, and generalisability of study findings within the ANZ entry-level physiotherapy context [29]. Our study addressed one of the key limitations of existing evidence [4,5,7] by supporting the 2-factor representation and item scaling across diverse geographic locations, placement sites and settings, and supervisor demographics. We acknowledge that the availability of a psychometrically supported instrument for assessment of professional competency is only one piece of the puzzle for maximising robust inferences regarding individual performance [24]. Assessment and learning within complex workplaces, requires an integrative and holistic approach that considers performance within a socio-cultural context, where social interactions, and human judgement and bias influence performance and decision-making [26]. This holistic approach underscores the importance of assessors having sufficient understanding of the physiotherapy practice content and assessment literacy, such as expected standards and behaviours, and how to interpret observations [24,26,45]. It also requires a shift away from the assessment instrument and a focus onto supporting and improving human judgement. Finally, our analyses focused on the internal psychometric properties of the APP. Future research is required to gather knowledge on external validity evidence, particularly predictive validity.\n\nThis large multi-site study provides the physiotherapy profession with the necessary evidence to move towards a standardised application of the ANZ-adopted entry-level physiotherapy performance assessment instrument. Our data support the superiority of the 2-factor model with four items for the professional and 16 items for the clinical dimension, yet the original 1-factor is also a viable representation of the APP. Consistency in professional competency assessment will permit improved benchmarking and quality assurances for accreditation and professional registration requirements and, ultimately, high-quality educational models for training and assessing the future generation of physiotherapy professionals. These findings are also important as others adopt or adapt the APP for assessments of entry-level physiotherapy performance globally [13,32,46].\n\nhttps://doi.org/10.1371/journal.pone.0321397.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321397.s002\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321397.s003\n\n(XLSX)\n\nThe authors thank numerous individuals at each university and placement site who supported this project including but not limited to clinical supervisors who completed APP assessments, as well as academic and professional staff who contributed to the operational activities (e.g., data collection, governance).\n\nMembership of the Physiotherapy Clinical Education Research Collaborative includes:Alison Bell, Allied Health and Human Performance, University of South Australia, Adelaide, AustraliaAllyson Calder, Centre for Health, Activity and Rehabilitation Research, School of Physiotherapy, University of Otago, Dunedin, New ZealandJulie Gauchwin, School of Allied Health, Australian Catholic University, Brisbane, AustraliaChris Higgs, School of Physiotherapy, University of Otago, Dunedin, New ZealandLeanne Johnston, School of Health and Rehabilitation Sciences, The University of Queensland, Brisbane, AustraliaChantal Maher, Graduate School of Health, University of Technology Sydney, Sydney, AustraliaNikki Milne, Department of Physiotherapy, Faculty of Health Sciences and Medicine, Bond University, Gold Coast, AustraliaTim Newing, School of Health Sciences, The University of Notre Dame Australia, Fremantle, AustraliaGitte Nielsen, College of Healthcare Sciences, James Cook University, Townsville, AustraliaEmma Richards, Graduate School of Health, University of Technology Sydney, Sydney, AustraliaGisela Van Kessel, UniSA Online, University of South Australia, Adelaide, AustraliaJill Williams, College of Nursing and Health Sciences, Flinders University, Adelaide, Australia",
    "category": "education"
  },
  {
    "title": "Developing policy recommendations for controlling energy drink consumption in secondary school students using social marketing theory, Shiraz, Iran: A study protocol",
    "authors": "Mohammadhassan Rostami, Mina Babashahi, Masoud Karimi, Soheila Khodakarim, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321766",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321766",
    "content": "Energy drink (ED) consumption has risen sharply among children and adolescents, posing health risks such as obesity and overweight, heart problems, mood disorders, and insomnia. Recognizing these concerns, international organizations have issued guidelines discouraging adolescent ED consumption, leading to policy measures in many countries. This study leverages social marketing theory to develop targeted policy recommendations for managing ED consumption in secondary school students.\n\nThis study utilizes a cross-sectional design with a mixed-methods approach to collect data and formulate policy recommendations. A multistage cluster sampling method was employed to randomly select students from 24 schools, serving as the primary data source. Information is gathered through a questionnaire based on the Theory of Planned Behavior (TPB). Additionally, a food environment analysis of the selected schools, a critical factor influencing ED consumption, is conducted using the NEMS-S INFORMAS tool. This tool assesses the availability, pricing, and marketing of EDs. The study further explores stakeholder perspectives through key informant interviews and a systematic literature review, providing valuable insights into existing policy frameworks. The study aims to develop actionable policy recommendations to effectively address ED consumption by synthesizing findings from all these phases.\n\nThe social marketing model focuses on understanding the audience and evaluating outcomes to develop effective policy proposals. It is particularly useful for behavior change policies, offering evidence-based recommendations that often surpass traditional health promotion methods. This study will analyze ED consumption and its influencing factors using the model’s constructs to present informed and practical policy recommendations.\n\nCitation:Rostami M, Babashahi M, Karimi M, Khodakarim S (2025) Developing policy recommendations for controlling energy drink consumption in secondary school students using social marketing theory, Shiraz, Iran: A study protocol. PLoS ONE 20(4):\n           e0321766.\n        \n        https://doi.org/10.1371/journal.pone.0321766\n\nEditor:Hadi Ghasemi,, Shahid Beheshti University of Medical Sciences School of Dentistry, IRAN, ISLAMIC REPUBLIC OF\n\nReceived:September 9, 2024;Accepted:March 11, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Rostami et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:No datasets were generated or analysed during the current study. All relevant data from this study will be made available upon study completion.\n\nFunding:This paper was financially supported by Shiraz University of Medical Sciences (Grant No. 29624). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAbbreviations:EDs,\n            energy drinks; ED,\n            energy drink; TPB,\n            theory of planned behavior\n\nEnergy drinks (EDs) contain high levels of sugar, caffeine, and other stimulants like guarana, taurine, and ginseng [1,2]. These beverages contain substances that act as non-nutritive stimulants and purport to have energizing or performance- and endurance-enhancing effects [3,4]. EDs were first introduced in 1960 and have been marketed to children and adolescents to increase energy, reduce fatigue, improve concentration, and mental alertness, and other uses [3,5]. Studies from Europe and the US found ED consumption in adolescents and young adults to vary between 20% and 50% [6,7]. However, there is a lack of studies examining the prevalence of ED consumption among children and adolescents in Iran.\n\nStudies have found that consumption of EDs can cause serious side effects, particularly in children, adolescents, and young adults [8,9]. These side effects can be classified into three categories: physical, psychological, and educational.\n\nPhysically, frequent use can contribute to obesity, heart abnormalities, seizures, diabetes, insomnia, and caffeine intoxication, posing substantial health risks [6,9,10].\n\nPsychological complications from consuming these drinks include an increased likelihood of mood and behavioral disorders, worsening depression, and even an increased risk of suicide [6,9–12]. In addition, consuming EDs during sensitive childhood and adolescence can lead to long-term negative consequences on mental health and reduce [10,11].\n\nIn the educational sphere, ED use correlates with reduced academic performance, impaired concentration, and declining mental efficiency [9,10]. Furthermore, studies highlight a strong association between frequent ED consumption and engagement in risky behaviors, such as thrill-seeking, delinquency, binge drinking, and substance use, including alcohol and tobacco [7–9].\n\nThese side effects are significant because they occur at a notable prevalence among ED consumers. For instance, around 20–30% are at risk of weight gain and metabolic disorders [13], 10–30% of users experience increased heart rate and blood pressure [5], 30% report sleep disturbances [13], and 15–20% experience anxiety and jitteriness [13], 10–20% face digestive issues [14].\n\nHealth issues like obesity, diabetes, and other non-communicable diseases in youth can have lifelong effects. Raising awareness about the risks of EDs and their impact on children’s and adolescents’ health is essential.\n\nGiven that childhood and adolescence are critical periods for physical and cognitive development, and considering the aggressive marketing targeting these age groups [15], many calls have been made globally to restrict access and sales of EDs [16]. Based on the Nutrient Profile Model for the Marketing of Food and Non-Alcoholic Beverages to Children in the Eastern Mediterranean Region (EMRO), the World Health Organization (WHO) states that the promotion, purchase, and access of EDs to children is prohibited [17]. The International Society of Sports Nutrition (ISSN) also advises that adolescents aged between 12–18 years need to be cautious while consuming EDs, particularly when the consumption exceeds 400mg. Moreover, the ISSN does not recommend the use of EDs for children aged between 2–12 years old [18]. To clarify, a typical 250ml ED can contain between 80–150mg of caffeine, depending on the brand [19].\n\nMoreover, the WHO and the American Academy of Pediatrics (AAP) advise countries to implement strict policies to reduce the consumption of EDs among children and adolescents (under 18 years old) [20,21]. In response, several countries have introduced regulations and policies—such as fiscal measures, access restrictions, and advertising bans—aimed at transforming the food environment into a healthier one to limit ED consumption [16,22,23]. In Iran, regulations require EDs to display warning labels indicating that their consumption is not recommended for individuals with specific health conditions, pregnant or breastfeeding women, children, and those sensitive to caffeine or with high blood pressure. Other measures include prohibiting the sale and advertising of EDs in schools and imposing taxes on these products [24].\n\nHowever, factors such as deficiencies in the design of regulations, conflicts of interest, and resistance from industries have contributed to the continued widespread availability, aggressive marketing, and relatively low cost of EDs. These factors – which as part of an unhealthy food environment can exacerbate its negative impact – have been significant contributors to the increased consumption of these beverages among children and adolescents [24–26], leading to a greater prevalence of their consumption in recent years [3]. This surge in ED consumption in recent years highlights the critical need to address environments where young individuals are most influenced—particularly schools.\n\nRecognizing that schools are key environments where children and adolescents spend the majority of their time, it becomes evident that these institutions play a pivotal role in shaping dietary behaviors. The pervasive availability and aggressive marketing of EDs within and around school settings further reinforce unhealthy consumption patterns among students. Therefore, addressing the school food environment—where EDs may be readily accessible—is essential in the broader strategy to create healthier food environments [27].\n\nThis focus on schools aligns with the broader concept of the food environment, which encompasses physical, economic, political, and sociocultural factors that influence food choices and nutritional status [28,29]. A healthy school food environment, as an integral part of this larger system, not only enables but also encourages students and their families to make healthier food choices as well as nutritional knowledge. This, in turn, contributes to improved well-being and nutritional outcomes, as supported by various studies [30–33]. However, achieving such an environment requires comprehensive, multi-faceted strategies that extend beyond conventional health promotion efforts, integrating policy reforms and community engagement to ensure sustainable improvements.\n\nIn recent years, the social marketing approach has gained traction among policymakers for developing public health policies [34]. This approach is particularly suited to addressing complex issues within the food environment because it systematically identifies problems and their influencing factors. By understanding these dynamics, social marketing enables the development of targeted and actionable solutions. Unlike traditional policy-making, social marketing emphasizes consumer-focused strategies, making it a valuable tool for evaluating, planning, and implementing interventions to improve the food environment [35–37].\n\nOne of the strengths of the social marketing approach is its multi-stage process, which includes audience analysis, channel analysis, and market analysis [37]. There is evidence to suggest that this planning approach may be more effective than traditional approaches used in health promotion. This is due to its multi-stage focus on the consumer, which differs from most planning models in health promotion settings [34].\n\nThe integration of behavior change theories, such as the Theory of Planned Behavior (TPB), can be a key factor in enhancing the effectiveness of audience analysis in social marketing. TPB provides a cognitive framework for understanding and predicting health-related behaviors, focusing on attitudes, subjective norms, and perceived behavioral control [38,39]. This theory has been shown to be effective in predicting healthy eating behaviors in diverse populations and settings [40–42]. This integration strengthens the customer-focused approach of social marketing by merging its strategic planning framework with the theoretical foundations of TPB. By incorporating TPB, social marketing campaigns are not only strategically refined but also achieve a more targeted and impactful method for driving behavior change.\n\nBased on the outlined evidence, it is clear that gathering data on the prevalence and determinants of ED consumption among children and adolescents is crucial. Given the significant influence of the school food environment on students’ dietary choices, this study focuses on examining the consumption patterns of EDs and identifying the factors driving their use among secondary school students. Utilizing the principles of the social marketing approach, the study seeks to provide actionable insights into this pressing issue.\n\nWhile several countries have implemented policies to limit ED consumption among young populations, including restrictions on advertising, labeling requirements, and bans on sales in certain settings, Iran currently lacks specific legislation targeting ED consumption. Although there are broader regulations addressing foods high in sugar, salt, and trans fats, the absence of targeted policies for EDs underscores the need for a tailored approach.\n\nTo address this gap, the study will leverage the principles of the social marketing approach to develop evidence-based policy recommendations. By doing so, it aims to propose new policies or refine existing ones to better regulate ED consumption. Therefore, the purpose of this study is to use social marketing theory to develop policy recommendations for controlling ED consumption in secondary school students of Shiraz City, Iran in 2024.\n\nUsing social marketing theory, this study aims to formulate policy recommendations for managing ED consumption among secondary school students in Shiraz City, Iran in 2024. The study employs a cross-sectional design and utilizes a mixed-methods approach for data collection and analysis. The qualitative component of this study is grounded in the phenomenological paradigm, which focuses on understanding individuals’ lived experiences [43]. This paradigm seeks to explore and describe the essence of a phenomenon by examining it through the perspectives of those who have directly experienced it, aiming to uncover both the nature of the experience and its deeper meaning [44].\n\nThis study was approved by the student research committee at Shiraz University of Medical Sciences and assigned the ethics code IR.SUMS.SCHEANUT.REC.1402.165.\n\nThis study uses the social marketing model to develop evidence-based and targeted strategies to control ED consumption among children and adolescents. The process begins with gathering detailed information on target behaviors, attitudes, and contextual factors to identify key policy objectives, carried out under the framework of audience analysis. Next, the study evaluates existing policies and strategies for their relevance, feasibility, and effectiveness while addressing potential barriers such as costs, stakeholder resistance, and implementation gaps, within the market analysis framework. Finally, it identifies the most effective pathways for policy implementation by analyzing the successes and limitations of existing programs and frameworks, ensuring the proposed recommendations are practical and impactful. Below, the key stages and constructs are detailed:\n\nThe initial step involves conducting a comprehensive assessment of the target population, with a focus on their behaviors and an evaluation of the school food environment as a critical contextual factor influencing those behaviors. This analysis is divided into two main components: Consumer Analysis and Food Environment Analysis.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321766.g001\n\nThis stage evaluates the proposed policy recommendations using the 4Ps of the marketing mix to reduce ED consumption among children and adolescents:\n\nAt this stage, existing laws and experiences from other programs and policies will be analyzed to determine which laws have been successful and in which areas. By examining these cases, the strengths and weaknesses of existing programs and policies will be analyzed to determine which channels can lead to more successful outcomes.\n\nSynthesis: In this study, we will combine all frameworks and models into a single framework, as shown inFig 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321766.g002\n\nThe study is planned to take place in secondary schools located in Shiraz. According to the latest report by the Shiraz Municipality Program and Budget Office, the city is divided into 11 regions, each with varying economic and social statuses. According to the 2016 census, the total population of Shiraz is 1,869,001, with 5.39% of this population consisting of adolescents aged 15–19 [48].\n\nThe study flow chart is briefly shown inFig 3.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321766.g003\n\nThis phase of the study followed the guidelines outlined by the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) during the first phase [49].\n\nPart 1 - Consumer analysis.Participants:In this study, multistage cluster sampling will be used. The sample size will be calculated throughformula. To know the information on the prevalence of ED consumption, the study by Almulla et al. in 2020 will be used [50].\n\nBased on data from the Shiraz Municipality Program and Budget Office and existing studies, Shiraz is classified into 11 municipal regions, divided into three socioeconomic groups: high, medium, and low [51,52]. Within each socioeconomic group, schools are further categorized based on their type (public or private) and the gender of their students, resulting in 12 distinct clusters. From each cluster, two schools will be randomly selected, totaling 24 schools. In each school, 27 students will be selected using simple random sampling to complete informed consent forms and questionnaires, ensuring the target sample size of 618 participants is achieved.\n\nInclusion criteria:The inclusion criteria for this study will include being Iranian, aged 16–18 years, willingness to participate, not following a specific diet, and the absence of specific illnesses or conditions (i.e., conditions managed by a physician or requiring specific medications) in the students.\n\nQuestionnaire design:A questionnaire based on the extended TPB will be developed for consumer analysis. This questionnaire will assess the determinants, frequency, and amount of ED consumption, along with background information related to their use. Furthermore, it will examine ED consumption within the framework of the extended TPB. The design, validity, and reliability of the questionnaire will follow the comprehensive framework proposed by Tsang et al. [53]. To ensure its scientific rigor, feedback will be obtained from an expert panel comprising specialists in nutrition, school health, health education, health promotion, research methodology, and other relevant fields.\n\nThe subject domains of the questionnaire will be identified through the following approaches:\n\nThe subject domains for this study will be derived from the findings of Treloar et al. (2017), Yujia Wang et al. (2016), and Samoggia et al. (2021), which provide valuable insights into students’ intentions, attitudes, subjective norms, perceived behavioral control, and utilitarian drivers associated with ED consumption [45,54,55]. These studies will serve as a foundation for questionnaire development, ensuring alignment with established constructs. To enhance this approach, 3–4 focused group discussions, each lasting approximately 45 minutes, will be conducted to gather insights from students, the primary group in the study. These discussions will explore their views on EDs, including perceived benefits, potential harms, and social influences, such as the impact of peers and family. A comprehensive literature review will also identify additional determinants and contextual factors, ensuring the study captures a holistic understanding of ED consumption behaviors.\n\nData collected will be analyzed systematically using MAXQDA 2020 software. An integrative inductive-deductive approach will be employed, organizing the data into codes based on the study’s objectives. Similar codes will be grouped into overarching primary codes to ensure clarity and coherence in the analysis.\n\nTo enhance coding accuracy and reliability, two independent coders will review the data. Inter-coder reliability will be calculated using Holsti’s formula, and any disagreements will be resolved through discussion. Additionally, intra-coder reliability will be assessed by having a second coder independently code 20% of the focus group data. The intra-coder reliability coefficient will be calculated to ensure consistency in the analysis.\n\nThe iterative coding process will begin immediately after each focus group session. Based on the finalized codes, preliminary questionnaire items will be developed. The questionnaire will undergo face and content validity assessments by a panel of experts. Content validity will be evaluated using the Content Validity Ratio (CVR) and Content Validity Index (CVI), while face validity will be assessed using the Item Impact Score (IIS). Internal consistency of the questionnaire constructs will be confirmed using Cronbach’s alpha values. To ensure the questionnaire is accessible and comprehensible for the target audience, a pilot test will be conducted with a group of students, and their feedback will inform further refinements.\n\nTo confirm reliability, the test-retest method will be applied with a two-week interval on a sample of 30 students. The Intraclass Correlation Coefficient (ICC) will be calculated to ensure consistency over time. After final validation and reliability testing, the finalized version of the questionnaire will be prepared for use in the study.\n\nPart 2 – Food environment analysis.Participants:In this part of the study, EDs will be examined in school healthy nutrition centers as well as in stores and retail outlets located within a 500-meter radius of selected schools in Shiraz City. The sampling method in this stage is consistent with the first stage, involving the evaluation of healthy eating bases of schools, along with stores and retail outlets around 24 pre-selected schools. The exact locations of the stores will be identified and reported using ArcGIS software.\n\nInclusion criteria.Inclusion criteria include filling out an informed consent form and obtaining permission from the retail store owner or general manager of the chain store to collect data.\n\nData collection.Evaluation of the food environment of stores around schools and schools’ healthy eating bases:The food environment will be assessed using the upgraded version of the NEMS-S (Nutrition Environment Measures Survey in Stores), known as NEMS-S INFORMAS. This enhanced tool combines the original NEMS-S survey with the INFORMAS retailer module, offering a more comprehensive examination of the food environment.\n\nThe researcher will visit stores within a 500-meter radius of the selected schools. Before starting the evaluation, store owners or managers will complete a consent form. Once permission is granted, the researcher will assess variables such as the prices of different food groups and items, the availability of specific food products, and the characteristics of food shelves, including their width, depth, and quantity. The evaluation will also cover food advertisements displayed inside and outside the stores and the prominence of food items in various sections of the store.\n\nAll findings will be recorded on a protocol form that outlines the study’s methodology and data collection details. The completed forms will then be immediately entered into the designated software for analysis.\n\nEvaluation of food advertisements around schools:The Food Promotion Module from INFORMAS will be utilized for this evaluation within a 500-meter radius of the selected schools. This module will help assess advertising patterns and ensure they are aligned with existing food marketing policies.\n\nThe researcher will document all advertisements around the schools, including billboards, banners, posters, and other promotional materials. Using the relevant protocol form, the researcher will fill in the associated checklist to gather detailed information. Additionally, all advertisements will be photographed and the images will be attached to the protocol form for further analysis.\n\nThe data will be collected on the same day, and all information, including the photographs, will be entered into the designated software. The photos will be imported into MAXQDA version 2020, where they will be analyzed using the photo-elicitation method for coding and interpretation.\n\nThis phase of the study adhered to the guidelines outlined by the Consolidated Criteria for Reporting Qualitative Research (COREQ) in the second phase [56].\n\nIn this phase, two methods will be used to collect information:\n\nData collection:Key informants will be interviewed face-to-face using the questions outlined inS1 File. These interview questions may be subject to change following the initial pilot phase, which includes conducting a few preliminary interviews to refine the process.\n\nParticipants will be contacted to schedule appointments, and the purpose of the meeting will be explained beforehand. Interviews will proceed only with the informants’ permission.\n\nAn informed consent form will be provided to participants before the interview begins. If participants are unwilling to sign the form or choose to leave the study at any stage, they will be excluded from the study. With the permission of the experts, interviews will be recorded digitally, and key points will also be noted down. If participants refuse audio recording, the interview will be manually documented in a notebook. Each interview will last approximately 45 minutes.\n\nAfter the interviews, the transcriptions will be sent back to participants for their review, correction, and comments. Following each interview, the content will be carefully reviewed and coded. Both explicit content (the transcribed text) and hidden content (researcher interpretations, pauses, body language, etc.) will be analyzed. The researcher will extract relevant insights to achieve the study’s objectives.\n\nThe interview process will continue until data saturation is reached, meaning no new information is emerging from the interviews. At the end of the interview, participants will be invited to suggest any additional relevant information or points they feel should be included. The content of the interviews includes the explanation of the components of the 4Ps, i.e., policy recommendations in this area (product), the costs of changing or adopting new policies (cost), the effective location of policies and programs (location), and how to promote and market these policies and programs (advertisements). Validation of interview data will be done based on the framework proposed by Guba and Lincoln in 4 parts [57]:\n\nTo measure validity and reliability, indexes such as content validity ratio, content validity index, and Item Impact Score will be calculated. Also, Cronbach’s alpha will be used to check the intraclass reliability coefficient (ICC) and to measure internal consistency. Also, the mean, standard deviation, median, and 25th and 75th percentiles will be used to report the descriptive statistics of quantitative variables, and frequency and percentage will be used for qualitative variables. Logistic regression will be used to determine the relationship between consumption of EDs and demographic variables. SPSS version 26 and Excel version 2021 will be used for data analysis. We will use linear regression to compare the desired indicators such as availability, price, and advertising in different economic and social areas. Quantitative variables, such as ED consumption in different socio-economic areas, are evaluated using the same test. In this study, an attempt has been made to consider potential biases in the reporting of variables such as ED consumption. Also, to determine the relationship between the consumption of EDs and the desired indicators, logistic regression will be used. In addition, to check the amount of advertisements of different food groups every 100 meters distance from schools, the Poisson distribution index will be used. SPSS version 26 will be used for data analysis.\n\nPolicies in the macro field should aim to change behavior, and governments need to explore new and effective tools to direct and reinforce these behaviors. While legislation and mandatory laws are commonly used as hard tools to bring about changes in behavior, they can often be ineffective and expensive. For this reason, policymakers should look for effective and less mandatory solutions and tools [34].\n\nSocial marketing is an approach to developing activities to change or stabilize a social behavior for the benefit of society [58]. It is a powerful way to influence attitude and behavior with the help of an interactive approach in providing information and using behavior change tools based on social science studies [59] and helps to facilitate acceptance, rejection, modification, abandonment, or continuation of behavior in a population group [60].\n\nThe social marketing model also can provide a unique opportunity for policymakers related to behavioral change approaches [61]. Social marketing deals with policymaking mainly in the policy formulation stage. What makes social marketing an effective tool is related to helping to analyze the desired problem and providing appropriate solutions, which can ultimately lead to appropriate and acceptable policy recommendations in the field of behavior change [61].\n\nOne of the places for implementing these policies is the food environment surrounding schools. Policies aimed at improving school food environments can positively influence children’s eating habits, ultimately helping to reduce obesity and overweight issues by creating healthier food options [62]. The school environment plays an essential role in students’ dietary patterns. Studies have shown that the variety and quality of food available around schools can influence this population’s health and nutrition outcomes [30,31]. Therefore, the food environment is one of the places that can be targeted by policymakers to control the consumption of these drinks among students by changing access, and pricing, and banning food advertisements, including EDs.\n\nSo far, no study has been conducted on the prevalence of ED consumption among secondary school students in Iran. However, due to the increasing popularity of these drinks among children and teenagers and the awareness of the side effects of consuming these drinks in this age group, it is felt necessary to conduct a study in this field. Considering that the food environment such as access, price, and advertising can play an important role in the food choices of children and teenagers, it is essential to know the state of the food environment of schools in this area. Also, due to the experience that different countries around the world have approved and implemented laws in this field, the need to know and analyze the target audience and factors affecting the choice of EDs is felt more than ever. In this study, an attempt will be made to analyze the current situation in the field of consumption of EDs by using the principles of social marketing as an efficient tool in analyzing the current situation and the potential of this model in providing evidence-informed policy recommendations and to recommend suggestions to change, Reinforce and improve existing policies or even recommend new policies.\n\nThe purpose of this study is to collect information about the state of the food environment in and around schools, as well as to analyze information related to the constructs of the extended TPB among students that can help the policymakers of this area by drawing a perspective of the current food environment of children and teenagers to improve the food environment of this vulnerable group. It is also an effort to collect information and data, relying on the principles of social marketing, to make policy recommendations to improve the health of children and adolescents and reduce healthcare costs related to the complications of consuming EDs in this group to make it available to the policymakers of this field to adopt new policies by further improving the existing policies.\n\nThis study has utilized established and recognized frameworks such as social marketing theory, the extended TPB, and other analytical frameworks to assess consumer behavior and the food environment. This approach has enhanced the credibility of the methodology and the study’s findings. Additionally, the use of a mixed-methods methodology, combining qualitative and quantitative approaches, has allowed for the collection of more comprehensive data. By employing tools such as interviews, questionnaires, and food environment analysis, the study has gathered richer data, contributing to a more thorough analysis of the topic. Moreover, the analysis of consumer behavior and the food environment in this study has identified factors influencing the consumption of EDs in a detailed manner. These analyses could be especially useful in shaping future policies. The use of a multi-stage sampling method, which considers the economic and social diversity of different areas of the city, has facilitated the collection of representative data that can be generalized to the target population.\n\nThe limitations of this study include several aspects. First, the use of self-reported data through questionnaires and interviews may lead to response biases. Participants may inaccurately report their behavior due to social expectations or a desire to present themselves in a more favorable light. Additionally, the evaluation of the food environment faces challenges such as the lack of cooperation from vendors and limited access to accurate data. Assessing the impact of advertisements and physical environments can also be time-consuming and complex. Furthermore, this study only evaluates the food environment around schools, while children and adolescents are also present in the home and neighborhood food environments. These environments, which can significantly affect children’s food choices, were not investigated in this study. These limitations may impact the comprehensiveness of the results and could influence future policy-making.\n\nhttps://doi.org/10.1371/journal.pone.0321766.s001\n\n(DOCX)\n\nWe extend our gratitude to the Shiraz University of Medical Sciences.",
    "category": "education"
  },
  {
    "title": "Effectiveness of theory-based breast self-examination intervention for breast cancer prevention among female college teachers in Pakistan: A cluster randomized controlled trial study protocol",
    "authors": "Benazir Mahar, Malina Binti Osman, Fatimah Binti Ahmad Fauzi, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321634",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321634",
    "content": "Breast cancer poses a significant health challenge in Pakistan, with a disproportionately high number of cases diagnosed at advanced stages. Despite the rising incidence, preventative measures like regular screening remain not commonly practiced among Pakistani women. While extensive research exists on breast cancer globally, there is a critical gap in studies specifically designed and evaluated to enhance breast self-examination practices within the Pakistani context.\n\nThe primary goal of this study is to design and implement an educational intervention on breast self-examination and evaluate its effectiveness among college teachers in Pakistan. This protocol outlines a single-blind, parallel cluster randomized controlled trial (CRCT) with an intervention period of three months. Clusters will be randomly assigned to either the control or intervention groups,and baseline data will be gathered from both groups. An intervention based on the health belief model will be executed for the intervention group to improve women’s knowledge and behaviors about breast self-examination (BSE). Data will be collected at two follow-up intervals for both groups post-intervention. The modified questionnaires include constructs such as breast cancer symptoms, risk factors, detection techniques, frequency and practices of breast self-examination, and perceptions of breast cancer. The control group will get the intervention once the trial concludes. The primary outcome of this study is breast self-examination (BSE) practice, whereas secondary outcomes encompass knowledge and beliefs related to breast cancer and BSE.\n\nThis cluster randomized controlled trial is aimed to improve the efficacy and legitimacy of theory-based intervention by increasing women’s knowledge of breast self-examination and breast cancer and changing their attitudes to encourage early breast cancer detection by practicing breast self-examination. This might significantly allow an improved detection rate; therefore, earlier treatment can be offered. Therefore, lower the death rate from breast cancer and guide health promotion initiatives in other comparable settings. Furthermore, less aggressive therapies are frequently possible with early detection, which enhances healthcare cost-effectiveness while also improving patient outcomes and treatment burdens.\n\nThis study protocol is registered with the Thai Clinical Trial Registry (TCTR),TCTR20240703005(https://www.thaiclinicaltrials.org/show/TCTR20240703005). The following study protocol complied with the Standard Protocol Items Recommendations for Interventional Trials (SPIRIT) checklist. (S1 file).\n\nCitation:Mahar B, Osman MB, Ahmad Fauzi FB (2025) Effectiveness of theory-based breast self-examination intervention for breast cancer prevention among female college teachers in Pakistan: A cluster randomized controlled trial study protocol. PLoS ONE 20(4):\n           e0321634.\n        \n        https://doi.org/10.1371/journal.pone.0321634\n\nEditor:Mc Rollyn Daquiado Vallespin, Far Eastern University - Manila, Philippines\n\nReceived:August 9, 2024;Accepted:March 1, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Mahar et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:No datasets were generated or analysed during the current study. All relevant data from this study will be made available upon study completion.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interest exist.\n\nBreast cancer accounts for approximately one-third of all new cancer diagnoses in women [1]. Breast cancer (BC) is the most prevalent form of cancer in women globally, posing a serious threat to their health in both developed and developing countries [2].Despite significant efforts and advancements in medical care, breast cancer (BC) is still one of the most serious illnesses for women [3].\n\nThe incidence of breast cancer is increasing in emerging countries because of longer life expectancies, increased urbanization, and alterations in lifestyle and reproductive patterns [4]; however, early diagnosis because of early presentation is notably responsible for the recent decline in breast cancer deaths in Western countries [5].\n\nThe situation has significantly changed in developing countries; Pakistan’s incidence is lower than that of other Asian countries, but its fatality rate is much greater. Pakistan ranks fourth in Asia in incidence but ranks third in mortality due to breast cancer [6]. Early detection of breast cancer (BC) increases the likelihood of early discovery of BC and successful treatment, saving thousands of lives each year [7]. In Pakistan, particularly among women, the society is not very receptive or open to discussing sexually transmitted diseases or problems related to breast/sexual health [8] The reason why late-stage breast cancer is the common clinical presentation in Pakistan is easily understood [9]. Females in Pakistan in general has lack of awareness about breast cancer and screening methods. Previous studies [10,11] have shown that the main barriers to breast cancer screening for Pakistani women are a lack of awareness about and false health attitudes about breast cancer. A study conducted in one of the major cities in Pakistan reported the same trend only 5.4% of females in Pakistan engage in breast self-examination [12].\n\nReducing cancer mortality requires preventive measures, and screening as a secondary preventive measure is a wise choice [13]. A necessary predisposing factor for changing behavior is knowledge of the importance of breast cancer screening itself. Improved health-seeking behavior is also a result of knowledge [14]. Moreover, education might significantly alter attitudes, misconceptions, and beliefs, enhancing screening procedures [15]. Several models and ideas have been theoretically employed to understand early BC detection. One such educational intervention to promote awareness is based on the health belief model (HBM), which serves as the theoretical foundation [16]. HBM has demonstrated effectiveness in addressing issues influencing BCS behaviors. Perceived susceptibility,, severity, benefits, barriers, self-efficacy and cues to action are some of the model’s dimensions [17]. According to this paradigm, the person must be persuaded that the sickness or condition may still exist despite the lack of symptoms; consequently, females are more likely to engage in healthy behaviors when they perceive themselves to be at risk for the disease (perceived susceptibility), understand that there may be serious consequences (perceived severity ), think that taking preventive action will have positive results (perceived benefits) and that the benefits could outweigh the risks (barriers) [18].\n\nAlthough extensive international research has been conducted on breast cancer knowledge, awareness and behaviors of females in the educational sector have received very little attention  when recruiting participants from diverse backgrounds.\n\nIn Pakistan, very few cross-sectional studies have been conducted to assess the knowledge and practices of females, and most of these studies were conducted through online surveys [19]. Very little importance is given to interventional studies. Among previously conducted cross-sectional studies, most were among university/college students [20–21], medical staff/nurses in hospitals [22,23] not among females working in the educational sector. Teaching is the highest among all other professions with female employees in Pakistan, and a large number of women practice teaching in this profession, constituting about 60% of the total 1.89 million teachers appointed in private and public educational institutions in Pakistan [24]. In this current research context, studying teachers is important because they are thought to be responsible, knowledgeable, and good sources of knowledge and motivation for their female students. It can be assumed that they can also transfer the extracted information in an effective way in the community. In short, there is a significant knowledge and awareness gap regarding breast cancer and breast self-examination practices among Pakistani women. This study aims to develop, validate, implement, and evaluate the effectiveness of health education intervention grounded in the Health Belief Model to enhance breast self-examination practices among college teachers.\n\nThis study obtained permission and ethical clearance from the College Education Department, Government of Sindh letter no.DCEHRH(INS)2023–24/423, Pakistan, and from the local Institutional Review Committee of Mekan Medical College, reference no. MMC/ERC/1/6/2024.\n\nInformed consentWritten informed consent will be obtained by the study researcher from all participants who will be willing to the part of the study. An informed consent form is attached as a Supporting file (S3).\n\nThis study will start recruiting participants for the baseline data collection point on September 4th, 2024, and complete data collection for 2ndpost-intervention data point on 20thJanuary 2025. The events of this study are illustrated inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321634.g001\n\nA single-blind, clusterrandomized controlled trial (RCT) will be conducted among female college teachers working in government girls’ colleges in the district of Hyderabad. Blindness is achieved by informing all participants that they are part of a study on breast self-examination without revealing the nature or presence of the intervention in certain colleges. Participants in each college will not be informed whether their college is part of the intervention group or the control group. The colleges will serve as randomization units (clusters). The study will be executed in three phases as shown inFig 2.\n\n25].\n\n25].\n\nhttps://doi.org/10.1371/journal.pone.0321634.g002\n\nThe same questionnaire will be used to collect data from both the control and intervention groups at each phase. The key difference lies in the timing of the intervention module: it will be administered to the intervention group during the study, while the control group will receive the same module after the study’s completion.\n\nThe sample size was determined based on a comparison of BSE practice proportions between an intervention and a control group. A baseline BSE practice proportion of 86.5% was established for the intervention group, while 26% was used for the control group, as per the literature [26] The statistical testing method used to achieve 80% power in this sample size calculation is a two-sample z-test for the difference between two proportions. Considering, a significance level of 0.05, and a design effect of 1.9 to account for clustering, a sample size of 42 participants per group was calculated. To accommodate potential attrition (20%) and eligibility criteria (90%), the final sample size was adjusted to 57 participants per group.\n\nThis study will take place in the Hyderabad region located in Sindh Province. The study sites will be the government colleges for girls located in the Hyderabad region.\n\nThe criteria for including clusters were Government Girls’ colleges located in Hyderabad willing to participate in the study and respondents who were appointed to government colleges in Hyderabad district, aged between 25–59 years and willing to participate in the study.\n\nThe criteria for excluding clusters were that colleges that refused to participate in the trial, that they had already participated in a study conducted for the pretesting of questionnaires, pilot studies, and cross-sectional studies conducted before this CRCT, and that the exclusion criteria for participants were breast cancer patients/survivors, pregnant and lactating mothers, and females who did not like to participate or who were on sabbatical leave during the data collection period.\n\nConfidentiality: To ensure the confidentiality of participant information, we will implement secure measures before, during, and after the trial. Each participant will be assigned a unique code to separate identifiers from research data. Only authorized study researchers will have access to this information, and data will be shared only in anonymized form.\n\nThis study’s sampling strategy comprised many carefully planned stages to ensure a representative and balanced sample of college teachers. The initial step is an assessment of eligibility criteria, in which colleges will be assessed on factors such as the necessary infrastructure, required number of teachers, and consent to participate. This step is important to ensure that included colleges are appropriate, which increases the reliability of the study. There are a total of ten eligible colleges in Hyderabad; three of them were randomly selected for the pilot and pretesting of instruments. Later, three more colleges were randomly selected for the cross-sectional phase, and finally, four colleges were left to include in the main study CRCT phase, as shown inFig 3.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321634.g003\n\nThe next stage is the blocking of colleges, in which included colleges are grouped into two blocks almost balanced in size, based on the total number of teachers. This strategy is used to ensure comparability between the intervention and control groups by achieving balance and minimizing possible biases that may result from variations in college size. The blocks of our study included Block 1: 200 teachers (College A=112, College B=88) and Block 2: 198 teachers (College A=117, College B=81). The third stage is” randomization” within blocks. Using the flipping-a-coin approach, each block is randomly allocated to either the intervention group or the control group. This step is included to ensure that the allocation to treatment groups is completely by chance, thus minimizing selection bias. Given that the researchers are aware of the group allocation (intervention and control colleges) but the participants are not, the study employs a single-blind design. The next step is the proportionate distribution of sample size, where the target sample size is distributed among the colleges in accordance with the number of faculty members at each college. This is a crucial step in ensuring that every college participates equitably in the sample size and that the study remains balanced. The sample is then stratified by faculty (arts, science, and commerce/ business) within each college within the proportionate stratified sampling phase. The required number of participants from each faculty is calculated proportionally. This stratification is critical to ensure adequate representation of all faculties in the sample, which improves the generalizability of research findings. Lastly, individuals within each stratum are chosen at random using a random number generator during the random sampling step. After discussing the inclusion and exclusion criteria and obtaining written consent, the individuals selected will be asked to participate in the study. Those who provide their assent will have their baseline data gathered. This step maintains ethical norms and improves the quality of the data gathered by guaranteeing an impartial selection procedure and complete participant disclosure. By going through these steps, the study intends to obtain a representative and balanced sample, which will improve the overall validity and reliability of the research findings,Fig 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321634.g004\n\nFollowed by proportional stratified sampling participants will be randomly selected from each stratum using a random number generator from the list provided by the education department. Selected participants will be invited to participate in the study. The researcher provides a brief overview of the study and explains its benefits and potential risks to those who meet the participation criteria. Those who meet the criteria will be asked for written informed consent. After completing the consent forms, participants can withdraw from the study at any time without penalty or loss of benefits and are not asked to provide a reason in advance. Finally, baseline data will be collected from the participants who provide consent.\n\nAfter baseline data collection, colleges assigned to the intervention group will be exposed to the educational intervention. After the intervention, the teachers who were randomly selected in intervention and control groups will be contacted for a follow-up evaluation. These follow-ups will be conducted one month and three months after the intervention to assess the ongoing impact of the training program on participants’ knowledge, beliefs, and practices. Follow-up assessment involves collecting data on the same variables measured at baseline, which allows for comparisons of changes over time. A systematic follow-up process ensures that studies can accurately track the effectiveness of an intervention and provide insight into its long-term benefits.\n\nParticipants will be strongly encouraged to attend both the intervention and post-intervention follow-up sessions. However, participants retain the absolute right to withdraw from the study at any point without providing a reason. To minimize attrition, various strategies will be implemented to foster participant retention. Participants will be asked to provide their contact information to facilitate communication and potential creation of a study-related group. All participant information will be handled with strict confidentiality.\n\nUpon joining the study, each participant receives a unique study ID. Participants will be identified by this number in all study-related documents during the intervention and data analysis. All study data are properly protected to meet administrative requirements related to the collection of personal data.\n\nThe TIDieR checklist was used to describe the elements of the intervention [27]. The TIDieR (Template for Intervention Description and Replication) checklist is designed to help research projects report more thoroughly, especially when it comes to effectively describing treatments. By using this checklist, the intervention is reported in a way that makes it possible for other researchers to replicate it. (S2 Checklist).\n\nThis study implements a program titled “Breast Cancer Awareness and BSE Practices Educational Intervention Trial.” The intervention, grounded in the Health Belief Model (HBM), aims to improve knowledge and self-reported practices of breast self-examination (BSE) among female college teachers. The HBM framework suggests that individuals are more likely to adopt preventive health behaviors when they perceive a susceptibility to a health threat (breast cancer in this case), believe in the seriousness of the condition, and have confidence in the effectiveness of the recommended behavior (BSE for early detection).\n\nThe program is designed based on educational materials and skills training, aiming to address these core HBM constructs. The development involved a review of existing educational resources and consultation with college staff to ensure feasibility and content appropriateness. The intervention consists of several components delivered to the intervention group:\n\nA one-day educational program on breast self-examination (BSE) will be held for a total of 57 teachers across two colleges . A focused one-hour session will be held at each college, facilitated by a qualified nursing assistant and a study researcher. The assistant will lead participants through a practical training session to make sure they understand the correct method, while the researcher will present multimedia on breast cancer and the significance of BSE. The researcher will visit both colleges in advance to verify that the required multimedia materials are available to guarantee a seamless presentation.\n\nAn educational session lasting an hour will cover topics such as breast anatomy, cancer awareness, screening strategies, and a brief film on appropriate BSE techniques. The risk factors for breast cancer, the possible repercussions of a delayed diagnosis, and the advantages of early identification by BSE will all be highlighted in this section. A skills training session using a breast model to demonstrate palpation techniques and signs of concern. This will enhance participants’ confidence in performing BSE effectively. The take-home materials included a leaflet summarizing key points, a short educational film on BSE sent via WhatsApp, a wall hanging, a writing pad, pen, and keychain with a breast cancer awareness logo, and monthly BSE reminder messages delivered through WhatsApp.These materials serve as ongoing prompts and resources, reinforcing the importance of BSE. Souvenirs with a breast cancer awareness message serve as reminders for regular BSE practice.\n\nThe control group will receive the same educational materials and training after the final data collection from both groups. The timeline of enrolment, intervention, and assessment is provided inFig 5.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321634.g005\n\nSeveral strategies will be used to support the validity of educational interventions. They include a strategy to maintain the continuity of the intervention, motivate participants to commit to the intervention, and strengthen their commitment. To maintain intervention consistency,\n\nThe same researcher implements the educational intervention for each college.\n\nThe researcher undertakes to implement a uniform training intervention protocol to ensure standardized delivery in both intervention colleges. The BSE training is designed and delivered by an expert nursing assistant. The researcher observes the sessions and provides feedback to the study participants wherever required. Additional approaches used to enhance fidelity will be sending brief reminders to participants and their WhatsApp groups monthly, as well as providing merchandise featuring the BC logo, such as pens, keychains, writing pads, and stickers. They are primarily used to encourage participants and act as a reminder for them to practice BSE regularly.\n\nTo evaluate the gathered data, IBM SPSS Software 29.0 will be used. Data capturing will be performed using Microsoft Excel, which allows for efficient entry and organization of data before analysis in SPSS. At baseline, participants’ characteristics and study variables of both arms will be measured, and the clusters will be compared at the baseline level for any differences among their characteristics, knowledge level, beliefs and practices. The normality of continuous variables will be checked before analysis. A value of 0.05 will be chosen as the alpha level of significance. The data at baseline will be described using descriptive analysis., The chi-square test will be used to examine the differences in observed proportions of categorical data between the intervention and control groups, when comparing within-group comparisons, in a 2×2 table including a cell with an anticipated count below 5,Fisher’s exact test will be employed to assess the association between the two groups To compare the mean difference in continuous data between the intervention group and the control group, the independent-sample t-test will be used between normally distributed variables, where as the Mann-Whitney U test will be employed to compare continuous data that are not normally distributed.\n\nAt the end of the study, the pre- and post-intervention scores of the participants will be compared within the groups and between groups. Cochran’s Q test will be used to assess changes in the proportions of categorical data over time within the study groups. This analysis will determine whether there are significant differences in the proportion of successes between the intervention and control groups. To determine the mean difference for continuous variables across time within the study groups, one-way repeated-measures ANOVA will be used.\n\nLastly, a generalized estimating equation (GEE) will be performed to assess overall impact of the intervention, The GEE is a robust and widely used type of analysis employed for analysing clustered, longitudinal data. It will help to assess the overall impacts of group, time, and group–time interaction effects on the primary and secondary outcome variables. Additionally, baseline covariates demonstrating significant differences between the intervention and control groups will be adjusted during analysis. The confidence interval (CI) for mean estimations is set at 95%, and the significance threshold, alpha (α), is set at 0.05. Intention-to-treat analysis, which accounts for any loss to follow-up or dropout instances, will be utilized in comparison to per-protocol analysis.\n\nThe ITT strategy will be used in the follow-up data analysis. To incorporate an ITT strategy, all participants randomized to the intervention and control groups will be included in the follow-up data analysis, regardless of their participation or dropout. If a participant does not complete the follow-up assessment, their last available data point is used to impute missing data. This method called the last observation carried forward (LOCF)[28], helps maintain the integrity of the ITT analysis and reduces the potential bias of missing data.\n\nThe current study will include one primary outcome and two secondary outcomes, which are represented inTable I.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321634.t001\n\nBSEpractices:The percentage of participants who consistently and proficiently performed breast self-examinations. A self-report answer instrument, which consists of the following questions on breast self-examination, will be used to gauge BSE practice and performance frequency. Any other response will be labeled nonpracticing (irregular BSE), while a woman who performs BSE once a month will be regarded as practicing (regular BSE).\n\nKnowledge of breast cancer and BSE:Knowledge of breast cancer, risk factors, sign symptoms, and knowledge associated with breast self-examination will be measured by using a self-report questionnaire. The questionnaires consisted of 36 items. The questions asked about breast cancer risk factors, signs and symptoms, breast health awareness (BSE), and breast cancer screening techniques. Beliefs about breast cancer and BSE. The modified Urdu version of the Champions Health Belief Model Scale (CHBMS), which was developed by V. Lee Champion and translated and validated by the researchers of this study, will be utilized to measure the beliefs of participants. The scale comprises 32 questions divided into six subscales covering all six health domains: perceived severity and seriousness of breast cancer, benefits and barriers of breast self-examination, self-efficacy in performing self-examination, and cues to action.\n\nThe questionnaire used for this cRCT is a validated and reliable tool; the validity and reliability of this instrument are tested by the study researchers before conducting the current controlled trial. The Cronbach alpha value for all 6 belief constructs of the health belief model ranged between 0.8–0.9.\n\nThe data-collecting tool for this study is generally tailored to the study’s context and derived from a variety of previous research, which enhances the measures’ reliability. The reliability is evaluated with Cronbach’s alpha, and necessary corrections are made based on the test results. The cut-off value used for the Cronbach’s alpha test is 0.70 or higher. Additionally, the same data collectors will be employed to evaluate research participants at baseline and after the survey as an additional measure to guarantee the instrument’s reliability.\n\nBest-practice recommendations will guide the dissemination process. The goal is to disseminate the results of the present study to teachers, young females, public health experts, and policyholders. To reach academic and clinical audiences, the findings will be presented at national and international conferences and published in peer-reviewed publications.\n\nThe authorship will be done in accordance with the guidelines provided by the International Committee of Medical Journal Editors (ICMJE).\n\nThe goal of this study is to investigate the effects of a theory-based intervention to increase breast self-examination knowledge and the intention to promote health behavior related to the timely screening of breast cancer patients. To the best of our knowledge, this study is the first interventional study at the community level to assess and create a strategy for promoting breast self-examination practices in Pakistan. At the completion of the current project, we will rigorously evaluate the effectiveness of a novel intervention addressing breast cancer awareness about symptoms and risk factors and improving knowledge, beliefs, and regular practices related to breast self-examination, particularly timely screening.\n\nPatients and their families are thought to bear particularly heavy pressure because of late-stage BC [29]. Additionally, it places financial constraints on healthcare systems, communities, and economies [30].By including an under-represented community, our educational program acts as a strategy for BC prevention.\n\nThe goal is to improve BCS results and lessen inequalities. This study aimed to support the efficacy and legitimacy of using a theory-based intervention designed to inform women about BCS The anticipated results provide a deeper understanding of the role of knowledge and beliefs in encouraging BCS adoption. This research not only immediately benefits educators, their pupils, families, and friends but also educates researchers and healthcare professionals who seek to develop interventions for women.\n\nThe information from this study could be used to design suitable BCS programs for other women in various settings. To disseminate relevant information extensively throughout communities, these programs boost health systems. They could be used to ensure that specific groups are known at both the individual and society levels.\n\nTo the best of the researcher’s knowledge, this study is the first to implement breast self-examination educational intervention among teachers using a theoretical framework. The effectiveness of this educational intervention will be assessed, and it will be put into practice in a variety of venues where health education interventions for women are offered.\n\nThe current study aims to bridge a significant gap in knowledge by assessing the efficacy of a theory-based intervention designed to increase breast self-examination practices among Pakistani teachers. By targeting a previously unexplored population and employing a rigorous methodology, this research contributes valuable insights into breast cancer prevention strategies. Successful implementation of the intervention holds the potential to improve breast cancer outcomes through early detection, reduce health disparities, and inform the development of tailored interventions for diverse populations. The findings of this study are expected to have far-reaching implications for public health policies, educational programs, and future research endeavors in the field of breast cancer prevention.\n\nhttps://doi.org/10.1371/journal.pone.0321634.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321634.s002\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321634.s003\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321634.s004\n\n(DOCX)\n\nWe would like to acknowledge Mekran Medical College for granting ethical clearance for this research in the local context of Pakistan. We would like to thank the colleges that participated in this study.",
    "category": "education"
  },
  {
    "title": "Job satisfaction mediates the effect of self-efficacy on work engagement among physical education teachers in economically disadvantaged areas",
    "authors": "Hongping Zhou, Shi Qi Xu, Dong-Hwa Chung, De Xin Dang, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321055",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321055",
    "content": "The unequal distribution of educational resources across regions with varying levels of socioeconomic development remains a global issue. Teachers in economically disadvantaged areas often exhibit lower levels of work engagement due to constraints in resources and limited opportunities for professional growth. This issue is particularly pronounced among physical education (PE) teachers, as PE is frequently regarded as a marginal subject. As a result, PE teachers receive less recognition from administrators and parents, encounter greater professional challenges, and experience diminished work engagement. Enhancing self-efficacy and job satisfaction has been identified as a critical strategy for improving work engagement. However, these relationships among PE teachers in underdeveloped regions remain insufficiently explored. To address this gap, this survey collected 472 questionnaire responses from rural primary school teachers, using a 5-point Likert scale survey. A path analysis model was employed to examine the direct and indirect effects of self-efficacy and job satisfaction on work engagement. The findings reveal that self-efficacy exerts an indirect influence on work engagement, with job satisfaction serving as a key mediating factor. These results suggest that fostering self-efficacy among PE teachers in economically disadvantaged areas can enhance job satisfaction, thereby leading to increased work engagement.\n\nCitation:Zhou H, Xu SQ, Chung D-H, Dang DX (2025) Job satisfaction mediates the effect of self-efficacy on work engagement among physical education teachers in economically disadvantaged areas. PLoS ONE 20(4):\n           e0321055.\n        \n        https://doi.org/10.1371/journal.pone.0321055\n\nEditor:Mc Rollyn Daquiado Vallespin, Far Eastern University—Manila, PHILIPPINES\n\nReceived:October 25, 2024;Accepted:March 1, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Zhou et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All data used for this survey are available at figshare athttps://doi.org/10.6084/m9.figshare.28365692.v1\n\nFunding:This survey was supported by a grant from the National Social Science Fund of China (Research on the Occupational Ecological Dilemma and Collaborative Governance of Rural Physical Education Teachers in the New Era; agreement number 21BTY101).\n\nCompeting interests:All the authors declare that they have no conflict of interest.\n\nThe imbalance in educational resources between regions of varying development levels is a global issue, especially in developing countries and regions [1]. Teachers in economically disadvantaged areas often face a lack of educational resources and professional development opportunities, which negatively impacts their quality of life and leads to negative and perfunctory attitudes [2]. This is particularly evident among physical education (PE) teachers, due to the marginal status of their subject, struggle to develop a strong professional identity, enthusiasm, and investment [3,4]. Consequently, enhancing the work engagement of PE teachers in economically disadvantaged areas has become a focal point for many scholars [5].\n\nResearch has shown that enhancing self-efficacy and job satisfaction can significantly improve work engagement. Self-efficacy refers to teachers’ confidence in their teaching abilities [6], while job satisfaction reflects the fulfillment derived from their work [7]. Both factors are positively associated with work engagement, fostering a more motivated and productive teaching environment [8–13].\n\nDespite these findings, there remains a lack of research exploring the specific roles that self-efficacy and job satisfaction play in enhancing work engagement among PE teachers in economically disadvantaged areas. Improving the work engagement of PE teachers in economically disadvantaged areas will have significant implications for the development of PE education in these areas. Therefore, this survey aims to understand the impact of self-efficacy and job satisfaction on work engagement among PE teachers in economically disadvantaged areas, offering new strategies for the development of PE education in these areas.\n\nThe theory of self-efficacy was first proposed by Bandura in 1982, emphasizing that motivation and behavior are influenced not only by external factors but also by individuals’ confidence [14]. In educational settings, self-efficacy refers to teachers’ confidence in successfully fulfilling their educational roles and overcoming challenges [15,16]. It is essential for achieving satisfactory educational outcomes [17,18].\n\nIndividuals with high self-efficacy proactively seek challenging roles, invest more time and effort to achieve their goals, and persevere even in the face of setbacks [19]. In educational environments, teachers with high self-efficacy demonstrate better mental health, experience lower levels of burnout and fatigue [20,21], collaborate effectively with colleagues to achieve common educational goals [22], and, importantly, report higher job satisfaction [23]. Ultimately, this leads to improved student academic performance [6,24].\n\nSelf-efficacy consists of three key dimensions: instructional strategies, classroom management, and student engagement [25].\n\nInstructional strategies refer to teachers’ confidence in selecting and implementing effective teaching methods to achieve educational objectives, impart knowledge, and foster student understanding. These strategies involve creating engaging and interactive classroom environments that stimulate student interest, cater to individual learning needs, and facilitate deeper comprehension [26]. Effective instructional strategies are closely linked to student academic performance, as interactive and student-centered teaching approaches enhance engagement and adaptability to diverse educational settings [27,28].\n\nClassroom management is critical for the effective delivery of educational activities [25,29]. Teachers’ confidence in their ability to establish and enforce classroom rules, manage student behavior, and create a conducive learning environment helps maintain focus on educational content [30]. Strong classroom management also increases student engagement [31], reduces teacher stress and fatigue, and enhances job satisfaction [32,33].\n\nStudent engagement reflects teachers’ ability and confidence in fostering and maintaining student involvement in learning [25]. By designing engaging lesson content, implementing interactive teaching methods, and cultivating positive teacher-student relationships, teachers can enhance student motivation and promote a deeper understanding of the subject matter [34].\n\nJob satisfaction reflects an individual’s overall attitude and emotional response towards various aspects of their work, such as salary, promotion opportunities, colleagues, supervision, and work content [35–38]. In educational environments, job satisfaction is a critical factor influencing teachers’ attitudes and performance [39]. Decreased job satisfaction among teachers can lead to increased burnout and turnover intentions, which directly impact students’ academic performance [40,41]. Moreover, it can contribute to psychological issues such as depression, anxiety, and loneliness among teachers [42–46]. Measures aimed at enhancing teachers’ job satisfaction can optimize their educational performance [47,48], help establish effective educational environments, improve educational quality [44], foster collaborative relationships among colleagues [43], and ultimately enhance students’ academic performance and learning experience [41].\n\nTeachers’ job satisfaction is influenced by various factors, including extrinsic rewards from teaching (such as job recognition and social status), intrinsic rewards related to course teaching, and school-based factors (such as work environment and welfare benefits) [49,50].\n\nCourse teaching involves the time, effort, and resources invested in designing, implementing, and evaluating educational activities. Higher satisfaction with course teaching indicates that teachers are content with the preparation and implementation processes. Teachers who are satisfied with course teaching can design appropriate educational content that aligns with educational objectives and student needs, structure effective classroom environments, facilitate organized educational delivery, and stimulate student interest and active learning [34,51].\n\nWelfare treatment encompasses teachers’ overall economic, security, and career development benefits, including salary, insurance, retirement benefits, paid vacation, professional training, and promotion opportunities [52]. These benefits directly affect teachers’ economic stability, professional security, and career advancement. Teachers satisfied with their welfare benefits typically demonstrate higher efficacy in classroom management, which correlates with improved academic performance among students [53]. Conversely, inadequate welfare can impair teachers’ educational performance [54].\n\nWork environment refers to teachers’ perceptions and evaluations of school culture, educational resources, and administrative conditions [55]. A supportive work environment provides necessary resources and support, enhances teachers’ sense of belonging and professional identity [40,56], fosters respect and recognition for their work, and motivates continuous improvement in professional skills and educational abilities [57].\n\nJob recognition refers to how much teachers feel valued, respected, and supported by school leaders and colleagues. This includes leaders’ appreciation for teachers’ efforts, collegial relationships, and recognition of professional competence. Feeling supported by school leaders increases teachers’ sense of pride and accomplishment, positively influencing their performance and job satisfaction [58]. Similarly, recognition from colleagues boosts teachers’ confidence, fosters a positive work environment, and encourages teachers to excel in their teaching roles [59].\n\nSocial status measures the level of respect and recognition teachers receive for their professional contributions from various societal sectors, including parents, government agencies, media, community organizations, and the public. This recognition encompasses appreciation for teachers’ professional skills, educational achievements, and their role in society and the community [60]. Studies indicate that positive social status in teaching careers correlates with increased work engagement, educational outcomes, professional self-esteem, and feelings of accomplishment [40,61]. When teachers feel recognized socially, they gain confidence and a sense of purpose in their work. Social status not only enhances teachers’ enthusiasm for their work but also motivates them to invest time and effort into implementing innovative teaching methods to improve educational quality [62].\n\nWork engagement encompasses commitment to work roles, the pursuit of work objectives, and emotional attachment and identification with one’s work. High work engagement reflects wholehearted dedication to work tasks, intense focus, and reduced fatigue, all of which contribute to greater personal happiness [63,64]. It is a persistent cognitive state that is not tied to specific events, individuals, behaviors, or goals [65].\n\nAs a positive work attitude, work engagement comprises three dimensions: vigor, dedication, and absorption [65,66].\n\nVigor refers to viewing one’s career as an important goal and pursuing it with abundant energy and psychological resilience, even in the face of challenges [67]. Vigor is not only a positive physiological state that enhances work performance [68] but also increases professional happiness [69,70]. Individuals with high vigor are better able to collaborate with colleagues, overcome challenges collectively, and achieve organizational objectives [71].\n\nDedication is an emotional state characterized by enthusiasm, wholeheartedness, and perceiving work as both important and challenging [72]. Research indicates that individuals high in dedication typically exhibit high work performance [67], job satisfaction [73], organizational loyalty [74], and teamwork [75]. They invest significant time and effort into their work, derive satisfaction and a sense of accomplishment from it, and their enthusiasm positively influences colleagues, fostering teamwork and improving the overall work atmosphere.\n\nAbsorption is a heightened state of focus where individuals become fully engrossed in their work roles, experiencing happiness and entering a flow state where time seems to fly by unnoticed [67,72]. Those with high absorption are deeply immersed in their tasks, maintaining high concentration and productivity, which enhances work efficiency and quality [76]. This absorption leads to a sense of accomplishment and satisfaction [77].\n\nSelf-efficacy for teachers refers to their confidence in achieving positive educational outcomes within their own teaching environments [6]. Teachers who trust in their educational abilities and influence are better equipped to handle various roles and challenges in the educational process. This belief motivates them to invest time and effort into improving their teaching methods, actively participating in educational activities, and persistently enhancing their professional skills and educational performance, ultimately increasing their work engagement. Therefore, self-efficacy is a crucial prerequisite for work engagement [78].\n\nTeachers with high self-efficacy are more likely to implement innovative educational practices, possess better classroom management skills, and engage more effectively in professional development [79,80]. They maintain a positive attitude when facing pressure and challenges in education, devising effective strategies to manage stress and minimize its negative impact on their work, thus sustaining higher levels of work engagement [8]. Research indicates that teachers with high self-efficacy are more motivated, investing greater emotional and mental energy into their work, which results in higher work engagement [81]. Therefore, higher self-efficacy among teachers contributes to increased work engagement [8–10], creating a more positive learning environment [11].\n\nThus, we hypothesize that an increase in self-efficacy will lead to greater work engagement among PE teachers in economically disadvantaged areas (Hypothesis 1). If Hypothesis 1 is supported, it would suggest that self-efficacy directly influences work engagement among PE teachers in economically disadvantaged areas.\n\nSelf-efficacy among teachers is closely linked to job satisfaction [82–84]. As discussed earlier, self-efficacy refers to teachers’ confidence in their ability to plan, organize, and achieve educational objectives within their teaching contexts. Teachers with higher self-efficacy believe in their educational capabilities, enabling them to adapt to diverse educational environments and meet students’ needs. This further fosters a sense of accomplishment and satisfaction, which enhances job satisfaction. Research shows that teachers with high self-efficacy derive greater satisfaction from their educational activities [85,86] and report lower levels of burnout [87].\n\nTeachers with higher self-efficacy feel more in control of their work environment and outcomes, improving their ability to manage stress and minimize its negative effects. In contrast, teachers with low self-efficacy may struggle with classroom management and meeting student demands, which can lead to disruptions and persistent challenges. These difficulties can increase stress and hinder their ability to solve problems effectively [88].\n\nTherefore, we hypothesize that job satisfaction among PE teachers in economically disadvantaged areas will increase with higher levels of self-efficacy (Hypothesis 2a).\n\nJob satisfaction also plays a significant role in influencing work engagement [89,90]. Teachers who experience high job satisfaction are more likely to feel enthusiastic about their work, investing greater time and effort into teaching and supporting students [91]. Numerous studies have consistently shown a positive relationship between job satisfaction and work engagement among teachers [92–99]. Teachers with high job satisfaction derive internal motivation and purpose from their work, which drives their engagement [87].\n\nTherefore, we hypothesize that work engagement among PE teachers in economically disadvantaged areas will increase with higher levels of job satisfaction (Hypothesis 2b). If both Hypothesis 2a and 2b are supported, it would suggest that self-efficacy indirectly influences work engagement among PE teachers in these areas, with job satisfaction serving as a crucial mediator (Hypothesis 2).\n\nThe aim of this survey is to examine the roles of job satisfaction and self-efficacy in enhancing work engagement among PE teachers in economically disadvantaged areas. Based on the theoretical assumptions outlined, this survey has developed a research model (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321055.g001\n\nFitting degree of model: Minimum discrepancy of confirmatory factor analysis/degrees of freedom, 2.175; goodness of fit index, 0.969; Adjusted goodness of fit index, 0.950; Root mean standard error of approximation, 0.050; Tucker-Lewis index, 0.956; Normed fit index, 0.941; Incremental fit index, 0.967; Comparative fit index, 0.967; Standardized root mean square residual, 0.036\n\nThe procedures and protocols employed in this survey were approved by the Ethics Committee of Hubei University of Arts and Science (Xiangyang, China).\n\nThe questionnaire used in this survey was administered and web-programmed by Wen Juan Xing (Changsha Ranxing IT Ltd.) and distributed via WeChat and email. It consisted of closed-ended questions divided into four sections (S1 Table).\n\nSection 1 comprised 7 questions aimed at collecting socio-demographic information from respondents, including age, gender, educational background, professional title, contract type, weekly teaching hours, and monthly salary.\n\nSection 2 included 24 questions derived from the Teachers’ Sense of Efficacy Scale by Tschannen-Moran and Hoy [25] to assess self-efficacy across three variables: instructional strategies (8 questions), classroom management (8 questions), and student engagement (8 questions). Responses were recorded on a 5-point scale.\n\nSection 3 consisted of 19 questions, referencing the questionnaires developed by Chen and Sun [100], Bian [101], and Huang [102] to evaluate job satisfaction across five variables: course teaching (6 questions), welfare treatment (3 questions), work environment (3 questions), job recognition (4 questions), and social status (3 questions). Responses were similarly measured on a 5-point scale.\n\nSection 4 included 17 questions adapted from the Utrecht Work Engagement Scale proposed by Schaufeli et al. [65,72] to assess work engagement across three variables: vigor (6 questions), dedication (5 questions), and absorption (6 questions). Responses were assessed using a 5-point scale.\n\nThe questionnaire was distributed to frontline rural PE teachers from 138 primary schools in Hubei Province, China, through convenience sampling [103]. During the survey period, we visited the above schools and invited the respondents face-to-face. Inclusion criteria required participants to have at least one year of teaching experience and be willing to participate in the survey. Exclusion criteria included dissatisfaction with participation, non-teaching staff, administrators, and incomplete or unreliable responses. Out of 526 responses received, 54 were deemed unusable, leaving 472 valid questionnaires for further analysis.\n\nBefore participation, all respondents were informed about the survey’s purpose and provided written informed consent. Data collection occurred from 21 March 2022 to 28 May 2023. The sample size was determined using PASS software (version 15.0.5) with a two-sided confidence interval method. A confidence interval width of 0.1, a confidence level of 0.95, an acceptance rate of 50%, and a dropout rate of 10% were used, indicating that at least 428 valid questionnaires were needed. The 472 valid responses exceeded the required sample size [104,105].\n\nData were analyzed using SPSS (version 26.0). Frequency analysis was employed to examine the general characteristics of respondents. The validity and reliability of the questionnaire were assessed through confirmatory factor analysis and Cronbach’s α [106]. Convergent validity was deemed satisfactory for multi-item scales if the average variance extracted value exceeded 0.5 and composite reliability exceeded 0.8 [107].\n\nResearch hypotheses were tested using structural equation modeling conducted with AMOS. We followed the two-stage approach proposed by Anderson and Gerbing [108], where the first stage involved confirmatory factor analysis to estimate the model’s items, and the second stage examined structural relationships among constructs to test the research hypotheses. Statistical significance was set atP<  0.05. Model fit indices, including minimum discrepancy of confirmatory factor analysis/degrees of freedom (CMIN/DF), standardized root mean square residual (SRMR), goodness of fit index (GFI), adjusted goodness of fit index (AGFI), normed fit index (NFI), incremental fit index (IFI), Tucker-Lewis index (TLI), comparative fit index (CFI), and root mean square error of approximation (RMSEA) were assessed against the following thresholds: < 3, < 0.05, > 0.9, > 0.9, > 0.9, > 0.9, > 0.9, > 0.9, and < 0.08, respectively, to evaluate model adequacy [109].\n\nA total of 472 respondents participated in this survey, of which 37.92% were male and 62.08% were female. The majority were on full-time contracts (98.52%), with only 1.48% on part-time contracts. Regarding age distribution, 19.49% were aged 20–30, 26.91% were aged 31–40, 38.35% were aged 41–50, and 15.25% were over 51 years old. The highest proportion of respondents held a bachelor’s degree (88.35%), followed by those with a college degree (9.32%) and a master’s degree (2.33%). In terms of professional title, 56.78% held a medium-level title, 14.62% held a junior-level title, and 28.60% held a senior-level title. For teaching workload, 7.42% reported having fewer than 10 lessons per week, 31.14% had 10–15 lessons per week, 41.10% had 16-20 lessons per week, and 20.34% had more than 21 lessons per week. In terms of salary, 3.39% earned 2000–3000 yuan per month, 31.35% earned 3001–4000 yuan per month, 48.10% earned 4001–5000 yuan per month, and 17.16% earned more than 5000 yuan per month (Fig 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321055.g002\n\nFactor analysis of self-efficacy (S1 Fig), job satisfaction (S2 Fig), and work engagement (S3 Fig) revealed no questions with low factor loading values, confirming the adequacy of the measurement items. The Cronbach’s α coefficients for all factors supported the internal consistency of the scales. Additionally, the convergent and discriminant validity statistics showed that the average variance extracted and composite reliability values for all multi-item scales exceeded the thresholds of 0.5 and 0.8, respectively, indicating satisfactory convergent validity for the measurement model.\n\nThe results of the model fit indices confirmed that the proposed measurement model adequately fit the data. The following values were observed: CMIN/DF =  2.175, SRMR =  0.036, GFI =  0.969, AGFI =  0.950, NFI =  0.941, IFI =  0.967, TLI =  0.956, CFI =  0.967, and RMSEA =  0.050 (Fig 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321055.g003\n\nStructural equation modeling indicated that self-efficacy has an indirect effect on work engagement, with job satisfaction serving as a significant mediator in this relationship (Fig 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321055.g004\n\nThe hypothesis testing results showed that self-efficacy significantly influenced job satisfaction (self-efficacy →  job satisfaction =  0.654,P<  0.001), and job satisfaction significantly affected work engagement (job satisfaction →  work engagement =  0.390,P<  0.001). These findings supported hypotheses 2a and 2b. However, self-efficacy did not directly affect work engagement, leading to the rejection of hypothesis 1 (Fig 1).\n\nThis survey explores the role of job satisfaction and self-efficacy in enhancing work engagement among PE teachers in economically disadvantaged areas. Our findings reveal that self-efficacy indirectly influences work engagement, with job satisfaction serving as a crucial mediating factor.\n\nOur results support the notion that self-efficacy has a significant impact on job satisfaction among PE teachers in economically disadvantaged areas. Similarly, Ortan et al. [110] found that increasing teachers’ self-efficacy enhances job satisfaction, while Türkoglu et al. [111] identified a strong positive correlation between these two factors. Self-efficacy reflects teachers’ confidence in overcoming challenges during the educational process [24]. Teachers with high self-efficacy are more likely to approach educational tasks with a problem-solving mindset, perceiving challenges as manageable [25]. Consequently, they are less prone to frustration or disappointment, leading to greater job satisfaction. Therefore, improving self-efficacy among PE teachers in economically disadvantaged areas can enhance their job satisfaction, validating Hypothesis 2a.\n\nAdditionally, our findings confirm that job satisfaction significantly predicts work engagement. Higher job satisfaction fosters a positive impact on work engagement [12]. Oubibi et al. [13] also reported a significant positive correlation between job satisfaction and work engagement in educational settings. Teachers who experience greater job satisfaction tend to invest more time and effort in their professional roles [38,112], exhibiting higher levels of key components of work engagement, including vigor, dedication, and absorption [65]. Thus, enhancing job satisfaction of PE teachers in economically disadvantaged areas is crucial for improving their work engagement, validating Hypothesis 2b.\n\nThe validation of Hypotheses 2a and 2b underscores that self-efficacy indirectly influences work engagement, with job satisfaction playing a pivotal mediating role. Strengthening self-efficacy among PE teachers in economically disadvantaged areas can boost their job satisfaction, ultimately leading to higher work engagement. Specifically, increased self-efficacy enables PE teachers in economically disadvantaged areas to approach their work with confidence, fostering positive attitudes and behaviors in the classroom. However, our findings suggest that confidence alone, as proposed in Hypothesis 1, may not be sufficient to enhance work engagement. While self-efficacy positively impacts work engagement, job satisfaction is a necessary condition for achieving this outcome. As noted by Fathi and Derakhshan [20], teachers with high self-efficacy maintain a positive emotional outlook towards their work, which enhances job satisfaction and further facilitates work engagement. Bandura [88] previously emphasized that self-efficacy shapes behavior and performance in multiple ways, with job satisfaction being significant. Similarly, Wang et al. [113] highlight the critical role of job satisfaction in fostering work engagement among teachers.\n\nWhen teachers feel confident in their abilities, they are more likely to derive satisfaction from their professional roles and work environment, exhibiting higher self-efficacy and further enhancing their work engagement. Therefore, job satisfaction serves as a direct expression of teachers’ self-efficacy. Confident teachers gain recognition and fulfillment from their efforts, reinforcing their self-efficacy and ultimately increasing their work engagement. Thus, our findings substantiate Hypothesis 2, emphasizing the essential role of job satisfaction in shaping work engagement.\n\nThis survey highlights self-efficacy as a significant indirect predictor of work engagement among PE teachers in economically disadvantaged areas, with job satisfaction serving as a crucial mediating factor. The findings support the notion that enhancing self-efficacy can effectively increase job satisfaction and further improve overall work engagement. Therefore, fostering both self-efficacy and job satisfaction is essential for promoting work engagement among PE teachers in economically disadvantaged areas.\n\nDespite its contributions, this survey has several limitations.\n\nFirst, the sample was limited to PE teachers in economically disadvantaged areas of Hubei Province, China, which restricts the generalizability of the findings to PE teachers in economically disadvantaged areas worldwide. Future research should include a more diverse and geographically representative sample to enhance external validity.\n\nSecond, this survey relied solely on a quantitative questionnaire survey. Incorporating qualitative methods, such as interviews or focus groups, would provide deeper insights into teachers’ experiences and help formulate more targeted intervention strategies.\n\nThird, the survey employed a cross-sectional design, which limits the ability to establish causal relationships among self-efficacy, job satisfaction, and work engagement. While structural equation modeling provides valuable insights into these associations, longitudinal studies are needed to examine causal effects over time.\n\nFourth, this survey focused specifically on self-efficacy, job satisfaction, and work engagement, without considering other influential factors, such as school management, peer support, and family background. These variables may also play a crucial role in shaping teachers’ professional experiences and should be explored in future research.\n\nTo our knowledge, this is the first survey to examine the role of job satisfaction and self-efficacy in improving work engagement among PE teachers in economically disadvantaged areas. By providing empirical evidence on this relationship, our survey offers a foundation for developing strategies to enhance PE teacher engagement and reduce educational disparities between developed and underdeveloped regions. Future survey should incorporate qualitative approaches and explore additional contextual factors to gain a more comprehensive understanding of the determinants of work engagement among PE teachers in these settings.\n\nThis survey underscores the importance of recognizing PE teachers in economically disadvantaged areas as key stakeholders whose self-efficacy and job satisfaction significantly impact their work engagement. Educational administrators and policymakers should prioritize initiatives that enhance these teachers’ self-efficacy, equipping them with the confidence and resilience needed to navigate professional challenges while maintaining job satisfaction. Additionally, fostering a supportive work environment that promotes job satisfaction is crucial for sustaining these teachers’ engagement and long-term commitment to their roles. By investing in strategies that strengthen self-efficacy and job satisfaction, educational institutions can cultivate a more engaged and effective teaching workforce, ultimately improving educational outcomes in economically disadvantaged areas.\n\nhttps://doi.org/10.1371/journal.pone.0321055.s001\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321055.s002\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321055.s003\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321055.s004\n\n(DOCX)",
    "category": "education"
  },
  {
    "title": "Association between advanced lung cancer inflammation index and gallstone prevalence among U.S. adults: A population-based study",
    "authors": "Chaofeng Gao, Miaoyan Liu, Yuan Sun, Zekun Zhao, Fengxian Wei, Xiaodong Xu, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321733",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321733",
    "content": "Gallstones are a common digestive disorder, with a global prevalence of 10%–15%, posing a significant economic burden on public health. The formation of gallstones is closely associated with inflammation and nutritional status. The Advanced Lung Cancer Inflammation Index (ALI) is a composite measure for assessing inflammation and nutritional status; however, its relationship with gallstone risk remains unclear. This study aims to investigate the association between ALI and gallstone prevalence among U.S. adults.\n\nThis study is based on data from the 2017–2020 National Health and Nutrition Examination Survey (NHANES) and includes 5,826 adults aged 20 years and older. The Advanced Lung Cancer Inflammation Index (ALI) was calculated using body mass index (BMI), serum albumin levels, and the neutrophil-to-lymphocyte ratio (NLR). The prevalence of gallstones was determined through questionnaire surveys. Multivariable logistic regression models were employed to analyze the relationship between ALI and the risk of gallstones. Additionally, trend analysis, smooth curve fitting, and subgroup analyses were conducted.\n\nThe study results showed a significant positive correlation between ALI levels and the risk of gallstone disease. After fully adjusting for covariates, each unit increase in lnALI was associated with a 42% increase in the risk of gallstone disease (OR =  1.42, 95% CI: 1.12–1.80). Trend analysis indicated a significant dose-response relationship between ALI and gallstone risk (P for trend <  0.01). Subgroup analysis further revealed that the correlation between ALI and gallstone risk was more pronounced in females, non-diabetic patients, individuals with higher education levels, those with insufficient physical activity, and non-drinkers, with gender showing a significant interaction effect (interaction P <  0.05). Smooth curve fitting further validated the linear relationship between ALI and gallstone risk, and this association was particularly prominent in the female population.\n\nThis study demonstrates that ALI is significantly associated with the risk of gallstones, particularly among women. As a simple and readily accessible indicator, ALI may help identify high-risk populations and provide a new clinical tool for the prevention and management of gallstones. Future longitudinal studies should further validate these findings and evaluate the predictive value of ALI across different populations.\n\nCitation:Gao C, Liu M, Sun Y, Zhao Z, Wei F, Xu X (2025) Association between advanced lung cancer inflammation index and gallstone prevalence among U.S. adults: A population-based study. PLoS ONE 20(4):\n           e0321733.\n        \n        https://doi.org/10.1371/journal.pone.0321733\n\nEditor:Li Yang, Sichuan University, CHINA\n\nReceived:September 17, 2024;Accepted:March 11, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Gao et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All NHANES files are available from the NHANES database (https://www.cdc.gov/nchs/nhanes/) for the years 2017–2020.\n\nFunding:The authors declare that this research and the publication of the article were supported by the Natural Science Foundation of Gansu Province (21JR11RA103) and the Gansu Provincial Youth Science and Technology Fund (21JR1RA161). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nGallstones are a common digestive disorder with a global prevalence of 10%–15%, posing a significant health risk to the population [1]. Surgical intervention remains the cornerstone of gallstone management, with approximately 700,000–1,000,000 cholecystectomies performed annually in the United States alone, imposing a considerable economic burden on healthcare systems worldwide [2]. Gallstones are anatomically classified into two main types: those developing in the gallbladder and those forming in the bile ducts. While the majority of gallstone carriers remain asymptomatic, a subset of patients may present with clinical manifestations including abdominal pain, nausea, and vomiting [3]. However, delayed diagnosis in certain cases can precipitate serious complications such as acute pancreatitis, acute cholangitis, obstructive jaundice, and even gallbladder perforation [4,5]. Furthermore, chronic gallstone disease has been associated with an elevated risk of gallbladder carcinoma [6].Therefore, early assessment of gallstone risk is crucial.\n\nThe formation of gallstones is primarily due to dysfunction in the gallbladder or bile secretion. Current evidence indicates that gallstones are associated with various factors, including age, gender, obesity, cardiovascular diseases, microbiota, glucose metabolism, and environmental exposures [7]. Recently, studies have shown a close link between inflammation, oxidative stress, and gallstone formation [8,9]. Elevated levels of circulating inflammatory proteins, such as IL-6, IL-10, IL-12, and IL-13, have been found to increase the risk of gallstones [10]. Additionally, overnutrition is also considered a significant factor in increasing the risk of gallstones, as it affects lipid metabolism and bile cholesterol supersaturation, thereby promoting gallstone formation [11]. Hence, it is essential to explore the role of inflammation and nutritional status in gallstone formation further.\n\nThe advanced lung cancer inflammation index (ALI) is a novel composite measure utilized to evaluate inflammation and nutritional status, first proposed by Jafri et al. in 2013, and has since been established as an independent prognostic marker in patients with non-small cell lung cancer [12]. Subsequently, Song et al. compared various nutrition- and inflammation-related indicators and found that ALI significantly outperforms other markers in evaluating the prognosis of lung cancer patients [13]. ALI is calculated based on routine clinical tests, including body mass index (BMI), serum albumin level, and the neutrophil-to-lymphocyte ratio (NLR) [14]. These parameters are easily obtainable and simple to calculate, making ALI a practical and widely applicable risk assessment tool. With further research, ALI has gradually been applied to the prognosis of other types of tumors, particularly digestive system tumors. Studies have shown that ALI is an independent prognostic factor for gastric cancer, colorectal cancer, and liver cancer, with lower ALI levels associated with poorer outcomes [15–17]. Additionally, research has revealed that ALI is closely related to the prognosis of various cardiovascular and cerebrovascular diseases, such as hypertension, heart failure, and stroke [18–20]. It is also significantly linked to the long-term prognosis of patients with diabetes [21]. This growing body of evidence suggests that ALI can serve as a versatile tool for disease management and risk stratification.\n\nGiven the crucial role of inflammation and nutritional status in the formation of gallstones, ALI holds potential as a predictive tool in this context. ALI integrates BMI, serum albumin level, and NLR—three key factors that are independently associated with gallstone risk—offering a comprehensive evaluation of the influence of inflammation and nutrition. Although previous studies have explored the effects of inflammation or nutritional status on gallstone formation, none have considered the combined effects of these factors. Thus, the potential connection between ALI and gallstone risk remains unclear. This study aims to evaluate the relationship between ALI and the risk of gallstones by analyzing data collected from the National Health and Nutrition Examination Survey (NHANES) from 2017 to March 2020, providing new clinical perspectives and guidance for the prevention and treatment of gallstones.\n\nOur study employed a population-based, retrospective, cross-sectional design to analyze secondary data from the National Health and Nutrition Examination Survey (NHANES) database. NHANES is designed to evaluate the health and nutritional status of residents across the United States through a comprehensive, multi-stage sampling strategy, ensuring national representativeness. Participants underwent extensive evaluations, including household interviews and assessments at Mobile Examination Centers (MECs), which included physical measurements, clinical examinations, and laboratory tests.\n\nOur study focused on data from the NHANES cycle spanning 2017 to March 2020, as gallstone-related questionnaires were exclusively available during this period. Participants were excluded according to the following criteria: (1) those with incomplete gallstone information; (2) individuals lacking data on albumin, neutrophils, lymphocytes, or BMI; (3) participants with missing covariate data; and (4) those who declined to answer or responded with “don’t know.” Given that the education level covariate was collected only from participants aged 20 and above, this study was restricted to adults aged 20 years or older. The final analysis included a total of 5,826 participants. The detailed screening process is illustrated inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321733.g001\n\nThe study protocol of NHANES was approved by the National Center for Health Statistics (NCHS) Research Ethics Review Board, and written informed consent was obtained from all participants. Consequently, no additional ethical approval or participant consent was required for subsequent data analysis.\n\nALI serves as an indicator of participants’ inflammation and nutritional status, and we utilized it to evaluate its association with gallstone risk. ALI is calculated using the formula: ALI =  BMI (kg/m2) ×  albumin level (g/dL)/ NLR, where NLR is derived by dividing the neutrophil count by the lymphocyte count. These parameters were measured at the Mobile Examination Center (MEC). The NHANES Laboratory Manual provides detailed standard methods for assessing serum and plasma markers, discusses potential biases, and offers additional information at the CDC NHANES Biosamples website. Given the skewed distribution of ALI, we applied a logarithmic transformation, using ln(ALI) in our statistical analyses. Gallstone status was determined based on the questionnaire item, “Has a doctor or other health professional ever told you that you have gallstones?” Participants responding “yes” were classified as having gallstones.\n\nBased on clinical expertise and established guidelines, we included the following covariates: age, gender, race, education level, poverty-income ratio (PIR), smoking status, physical activity, alcohol consumption, diabetes, and hypertension. Demographic variables encompassed age, gender, race, education level, and PIR. Health-related behavioral factors included smoking status, physical activity, and alcohol consumption. Chronic disease variables comprised diabetes and hypertension. All data were analyzed using the weighting methodology recommended by NHANES. Education level was categorized as above or below a high school diploma. Smoking status was classified into non-smokers, former smokers, and current smokers, defined as individuals who have smoked fewer than 100 cigarettes in their lifetime, those who have smoked more than 100 cigarettes but are not currently smoking, and those who have smoked more than 100 cigarettes and are currently smoking, respectively. Physical activity was determined based on whether participants engaged in any activity that increased breathing or heart rate during a typical week. Alcohol consumption was defined as consuming any type of alcoholic beverage at least once per month on average over the past year. Diabetes was defined as having an HbA1c level of at least 6.5%, a fasting blood glucose level of 126 mg/dL or higher [22], a self-reported diagnosis by a healthcare professional, or current insulin use. Hypertension was determined by whether a participant had ever been informed by a doctor or other health professional that they had high blood pressure.\n\nIn accordance with the guidelines provided on the official NHANES website, a complex sampling design and corresponding sample weights were utilized to generate nationally representative estimates. Continuous variables were expressed as weighted means ±  standard error, while categorical variables were reported as unweighted counts (with weighted proportions). To compare baseline characteristics between participants with and without gallstones, weighted t-tests were employed for continuous variables, and weighted chi-squared tests were used for categorical variables to assess group differences. The relationship between ALI and gallstones was examined using multivariable logistic regression models. Three distinct models were constructed: Model 1 was unadjusted; Model 2 was adjusted for age, gender, and race; and Model 3 was adjusted for all covariates. The results of each model were presented as odds ratios (OR) with 95% confidence intervals (CI). Given the skewed distribution of ALI, a logarithmic transformation (ln(ALI)) was applied. For a more granular analysis, ALI was categorized into quartiles, and trend tests were conducted to evaluate the dose-response relationship between ALI quartiles and gallstone risk. Subgroup analyses were performed to investigate potential effect modifications by gender, diabetes status, age, education level, physical activity, alcohol consumption, and hypertension. Interaction terms between ALI and these variables were incorporated into the regression models to determine their statistical significance. A smoothing curve fitting method was applied to visualize the association between ALI and gallstones, with stratification by gender to assess potential differential effects. Statistical significance was defined as a p-value <  0.05. All data analyses were conducted using R Studio (version 4.3.3) and Empower software (version 4.2).\n\nThis study ultimately included 5,826 participants, with a mean age of 48 ±  17 years. Among them, 49% were male and 51% were female, with 67% identified as Non-Hispanic White. The mean ln(ALI) value was 4.14 ±  0.49. Participants were stratified into two groups based on the presence of gallstones, with 11% of the cohort diagnosed with gallstones. Significant differences (P <  0.05) were observed between the two groups for age, gender, BMI, physical activity, smoking status, diabetes, poverty-income ratio (PIR), alcohol consumption, and hypertension. Participants with gallstones were more likely to be female, older, have a higher BMI, a history of smoking, diabetes, or hypertension, abstain from alcohol, engage in less physical activity, and have lower economic status (Table 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321733.t001\n\nTo ensure the robustness of our model, we evaluated multicollinearity and correlations among the variables. The calculated Generalized Variance Inflation Factor (GVIF) values (S1 Table in S1 File) were all below 10, indicating no significant multicollinearity. The Spearman correlation heatmap (S1 Fig in S1 File) revealed that most variables exhibited weak correlations (|ρ| <  0.5), suggesting minimal overlap among them. Based on these preliminary assessments, we proceeded to examine the relationship between ALI and gallstones using three multivariable regression models, as presented inTable 2. A positive association was observed between ALI and gallstone presence. In Model 1, which did not adjust for any covariates, the relationship between log-transformed ALI and gallstones was not statistically significant. However, in Model 2, after adjusting for age, gender, and race, a significant correlation emerged between ln ALI and gallstone risk (OR: 1.46, 95% CI: 1.10–1.94). In Model 3, which further adjusted for education level, smoking status, physical activity, alcohol consumption, hypertension, PIR, and diabetes, the association between ln ALI and gallstones remained significant (OR: 1.42, 95% CI: 1.05–1.92). Each one-unit increase in ln ALI was associated with a 42% higher likelihood of developing gallstones. To further explore the complex relationship between ln ALI and gallstone risk, we stratified ln ALI into quartiles for analysis. The results demonstrated that in both Model 2 and Model 3, higher quartiles of ln ALI (particularly Q4) were strongly associated with an increased risk of gallstones (Model 2: OR for Q4: 1.69, 95% CI: 1.14–2.52; Model 3: OR for Q4: 1.61, 95% CI: 1.04–2.50). The trend test revealed a significant linear relationship between ln ALI quartiles and gallstone risk (Model 3: p for trend =  0.032).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321733.t002\n\nTo further evaluate the robustness and heterogeneity of the association between ALI and gallstones, we performed subgroup analyses stratified by gender, diabetes status, age, education level, physical activity, alcohol consumption, and hypertension, with appropriate adjustments for confounding factors. The results revealed that the association between ALI and gallstones was significant in females (OR =  1.70, 95% CI: 1.27–2.27), non-diabetic individuals (OR =  1.42, 95% CI: 1.02–1.97), those with higher education levels (OR =  1.50, 95% CI: 1.09–2.05), individuals with insufficient physical activity (OR =  1.65, 95% CI: 1.16–2.35), and non-drinkers (OR =  1.72, 95% CI: 1.26–2.35). Interaction tests indicated that gender significantly moderated the relationship between ALI and gallstones (P =  0.011), whereas diabetes, age, education level, physical activity, alcohol consumption, and hypertension did not exhibit significant interaction effects on this positive association (Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321733.t003\n\nTo further investigate and visualize the relationship between ALI and gallstones, we utilized smoothing curve fitting to depict the association between ALI and gallstones (Fig 2). The results revealed a linear positive relationship between ALI and gallstones, consistent with the trend analysis findings presented inTable 2. When stratified by gender, the smoothing curve analysis (Fig 3) demonstrated a linear positive correlation between ALI and gallstones in females, whereas no significant correlation was observed in males. This result is consistent with the gender-stratified analysis outcomes shown inTable 3.\n\nThe solid red line represents the smooth curve fit between variables. Blue bands represent the 95% confidence interval from the fit.\n\nThe solid red line represents the smooth curve fit between variables. Blue bands represent the 95% confidence interval from the fit.\n\nhttps://doi.org/10.1371/journal.pone.0321733.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321733.g003\n\nThis study explored the relationship between ALI and the gallstones risk. Based on the review of data from 5,826 participants, we found that higher ALI levels were significantly linked to a higher likelihood of developing gallstones, even after accounting for multiple covariates. Trend analysis indicated a linear increase in gallstone risk with rising ALI levels, and this finding was further supported by smoothing curve fitting. Subgroup analysis revealed that the link between ALI and gallstone was stronger among females, non-diabetic individuals, individuals possessing at least a high school diploma, those who were physically inactive, and non-drinkers. Additionally, gender played a significant moderating role in the relationship between ALI and gallstones, suggesting that ALI may be a stronger predictor of gallstone risk in women.\n\nThe formation of gallstones is a complex, multifactorial process in which inflammation is considered a key pathological mechanism. Localized inflammatory responses can promote gallstone formation through various pathways [23]. First, chronic inflammation can cause thickening of the gallbladder wall and dysfunction of the biliary system, leading to impaired bile flow, which in turn allows cholesterol to precipitate more easily, thereby increasing the risk of gallstone formation [24]. Additionally, the supersaturation of cholesterol in bile is a critical factor in cholesterol stone formation. Inflammation can alter the composition of bile, particularly by disrupting the balance of cholesterol, phospholipids, and bile acids, which collectively accelerate the crystallization of cholesterol [25]. Studies have also shown that chronic inflammation in the gallbladder and bile ducts may shorten the nucleation time of cholesterol crystals (i.e., the initial stage of crystal formation in bile), further accelerating gallstone formation [26]. Neutrophils, a crucial element in innate immunity, are often elevated in bacterial infections, acute inflammation, and certain inflammatory diseases [27]. Lymphocytes, which play a crucial role in adaptive immunity, are also linked to inflammatory diseases, whether their levels are elevated or reduced [28]. Consequently, the Neutrophil-to-Lymphocyte Ratio (NLR) can reflect the body’s immune response and inflammatory state. Previous studies have indicated that the Systemic Immune-Inflammation Index (SII), calculated from platelet, neutrophil, and lymphocyte counts, serves as a marker of inflammatory status, with higher SII levels being closely associated with a higher prevalence of gallstones in individuals under 50 years of age [29]. Beyond inflammation, nutritional status also plays a significant role in gallstone formation. BMI and serum albumin levels are two key indicators of nutritional status [30]. A large cohort study by Unalp-Arida et al. demonstrated a strong link between elevated BMI and the development of gallstones [31]. Zhang et al.’s study found that obesity is associated with the occurrence of gallstones even in metabolically healthy adults [32]. Additionally, recent research indicates that visceral fat accumulation is closely linked to the risk of gallstones [33]. In our study, we similarly found that patients with a BMI greater than 30 had a higher prevalence of gallstones. This is likely because the livers of obese individuals tend to synthesize and secrete more cholesterol into bile, increasing bile cholesterol saturation and promoting stone formation [34]. Moreover, obese individuals often have poor gallbladder contractility, leading to delayed gallbladder emptying, which prolongs bile retention and further increases the risk of stone formation [35]. Additionally, obesity is closely linked to insulin resistance and metabolic syndrome, which can further elevate the risk of gallstone formation [36]. In summary, inflammation and nutritional status play crucial roles in the development of gallstones, and their interaction further amplifies this risk.\n\nNumerous studies have confirmed the critical role of inflammation and nutritional status in the formation of gallstones. Liu et al., analyzing data from 95,319 participants, found that increased levels of high-sensitivity C-reactive protein (hs-CRP) independently contribute to the risk of new-onset gallstones in the Chinese population [37]. Another study demonstrated that the monocyte-to-high-density lipoprotein cholesterol ratio (MHR), a combined marker reflecting inflammation and oxidative stress, is positively correlated with the prevalence of gallstones [38]. Cheng et al.‘s cross-sectional study, which analyzed data from 7,334 participants, showed that a high dietary inflammatory index, linked to pro-inflammatory diets, significantly increases the risk of gallstones [39]. Furthermore, recent studies have found that various BMI-related indices effectively reflect nutritional status and are closely associated with gallstones. Zhang et al. reported that an elevated visceral adiposity index is strongly linked to the prevalence of gallstones [40], while the weight-adjusted waist index is also positively correlated with the prevalence of cholelithiasis [41]. Although numerous studies have established the close relationship between inflammation or nutritional condition and gallstones, most have focused on single factors, lacking systematic analysis of the combined effects of multiple factors. S2 Table in S1 File provides a summary of ongoing and completed clinical trials related to inflammation, nutrition, and gallstone risk. These trials highlight the growing clinical interest in exploring the combined influence of these factors, reinforcing the importance of a comprehensive approach. The ALI, composed of BMI, serum albumin levels, and NLR, can comprehensively reflect the role of inflammation and nutrition on gallstones. Our study found that higher ALI levels were strongly linked to a higher likelihood of developing gallstones.\n\nMoreover, our analysis revealed that gender plays a notable moderating role in the relationship between ALI and gallstone risk, with the association being more pronounced in females. This occurrence could be due to the physiological and immune system differences unique to women. Hormonal fluctuations during physiological processes such as pregnancy and menopause significantly affect cholesterol metabolism and bile composition, especially post-menopause, where women have a higher cholesterol burden than men [42]. Research indicates that women are twice as likely as men to develop cholesterol gallstones, as estrogen promotes cholesterol secretion into bile via the estrogen receptor (ER) α pathway, leading to bile becoming more prone to cholesterol supersaturation, thus increasing the risk of gallstone formation [43]. Furthermore, literature suggests that women’s immune systems are generally more active than men’s, exhibiting elevated neutrophil levels and heightened sensitivity to pro-inflammatory signals [44]. Therefore, when ALI levels increase, women might be more vulnerable to nutritional status and inflammatory responses, thereby increasing the risk of gallstones. Liu et al.’s study similarly found that women are more affected by inflammatory markers such as MHR, leading to an increased risk of gallstones [38]. This finding aligns with our study’s results. In our research, we also observed that the correlation between ALI and gallstone risk was significantly enhanced in non-diabetic patients, those with a high school education or higher, those who were physically inactive, and non-drinkers. These results suggest that the impact of ALI may vary across different populations. For instance, diabetic patients have been shown to have a significant causal relationship with gallstones, with their likelihood of developing gallstones being considerably higher due to metabolic dysfunction [45]. In contrast, non-diabetic patients, with relatively stable metabolism, may be more directly impacted by changes in ALI. Similarly, individuals with higher education levels may be more focused on health management, making the association between ALI fluctuations and gallstone risk more apparent. Physically inactive individuals may experience the effects of ALI more prominently due to metabolic and gallbladder function issues [46]. Alcohol, in certain cases, is a protective factor against gallstones, likely due to its influence on cholesterol metabolism [47]. Our study found that non-drinkers exhibited a greater prevalence of gallstones than drinkers. Therefore, in non-drinkers, elevated ALI levels may more directly reflect an increased risk of gallstones. These findings suggest that ALI could serve as a valuable instrument in clinical settings for evaluating gallstone risk in specific high-risk populations. Particularly in women, non-diabetic patients, individuals with higher education levels, those who are physically inactive, and non-drinkers, early monitoring and intervention based on ALI levels could help reduce the incidence of gallstones. Future research should further explore the characteristics of these subgroups to develop more precise prevention and treatment strategies.\n\nThis study possesses several strengths. First, it leverages the large-scale NHANES database, which is nationally representative and has been weighted to ensure external validity and nationwide representativeness of the results. Second, by comprehensively adjusting for confounding factors like age, gender, race, and education level, the findings of the study become more accurate and reliable. Additionally, detailed subgroup analyses were conducted, revealing heterogeneity in the relationship between ALI and gallstone risk across different populations, thereby providing scientific evidence for personalized prevention and treatment strategies. The study also employed the innovative ALI index, which integrates multiple factors related to inflammation and nutritional status, offering a more comprehensive assessment of overall health. Lastly, trend analysis and smooth curve fitting further validated the linear relationship between ALI and gallstone risk, enhancing the robustness of the study’s findings.\n\nThis study also has some limitations that should be considered. First, since the study is based on a retrospective and cross-sectional design, we are unable to establish causality. Although we observed an association between ALI and gallstone risk, it is unclear whether an increase in ALI leads to gallstone formation or whether the presence of gallstones causes an increase in ALI. Therefore, prospective longitudinal studies are needed in the future to further confirm this causal relationship. Second, this research relies on pre-existing data from the NHANES database, which includes self-reported information. This introduces the potential for recall bias and subjective error, particularly regarding health status and lifestyle factors. Although NHANES is managed by the CDC with rigorous protocols to ensure data quality and national representativeness, these limitations are inherent to retrospective surveys. Additionally, while we controlled for multiple confounding factors, some unmeasured confounders may still influence the results. Third, this study is limited by the lack of detailed information on the types of gallstones (e.g., cholesterol stones, brown pigment stones, and black pigment stones). These types have distinct etiologies and pathogenesis, which could affect the association between ALI and gallstone risk. Unfortunately, the NHANES dataset does not provide such classification, limiting our ability to explore these potential differences. Future research incorporating datasets with detailed gallstone classifications would help further validate and refine these findings. Lastly, this study is based solely on data from the U.S. population, which may introduce geographical and cultural limitations. Differences in lifestyle, healthcare systems, and genetic backgrounds in other regions may affect the relationship between ALI and gallstone risk. Future research should validate these findings using datasets from other countries and cultural contexts to ensure broader applicability and improve generalizability.\n\nThis study is the first to reveal a significant association between ALI and the risk of gallstones, particularly among women. This finding lays a critical foundation for future research and clinical applications, suggesting that incorporating ALI into routine clinical risk assessment tools could facilitate the early identification of high-risk individuals and the development of targeted prevention strategies, such as lifestyle interventions or medical monitoring, to reduce the occurrence of gallstones. Additionally, since ALI is calculated using easily accessible parameters—BMI, serum albumin, and NLR—it is both simple and cost-effective, making it suitable not only for clinical practice but also for community screening programs, thereby helping to alleviate healthcare burdens. Future research could further explore the value of ALI in personalized management and validate its predictive capability across different populations.\n\nThis file includes the variance inflation factors for variables (S1 Table), heatmap of Spearman’s rank correlation coefficients (S1 Fig), summary of clinical trials related to inflammation, nutrition, and gallstone risk (S2 Table), and data processing and modeling methods (S3 Table).\n\nhttps://doi.org/10.1371/journal.pone.0321733.s001\n\n(DOCX).",
    "category": "education"
  },
  {
    "title": "Change is never easy: Exploring the transition from undergraduate to dental student in a U.S.-based program",
    "authors": "Taiana C. Leite, Christine R. Wankiiri-Hale, Nilesh H. Shah, Camille S. Vasquez, Emily M. Pavlowski, Sarah E. Koury, Jia Kim, Kristina M. Ceravolo, Seth M. Weinberg, Zsuzsa Horvath, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321494",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321494",
    "content": "The goal of this study was to gain student-centered insights to better understand the challenges of transitioning from undergraduate to dental education. To this end, questionnaires were designed and distributed to incoming dental students, as well as second-, third-, and fourth-year students in the same year for a cross-sectional assessment in 2015/2016. The same questionnaires were also distributed to those same incoming students when they were in their second, third, and fourth years for a longitudinal assessment (2015–2019). There were both open-ended and Likert scale-type questions about expectations (incoming students) and experiences (years 2–4) in dental school compared to undergraduate education. Accordingly, data analysis involved a combination of qualitative and quantitative statistical approaches. Cross-sectional and longitudinal analyses showed that incoming students expected an increased workload in dental school, but also more attention, support, and access to faculty than they received as undergraduates (i.e., they expected a stronger academic support system). All students also reported experiencing more stress and greater difficulty managing their time than expected when compared to their undergraduate experiences. Thus, our study highlights areas of discrepancy between dental students’ initial expectations and their lived experience. Importantly, dental schools can take measures to address these discrepancies, foster a better learning environment, and improve students’ overall experience to help pave a smooth path for students to become successful and well-prepared oral health care providers.\n\nCitation:Leite TC, Wankiiri-Hale CR, Shah NH, Vasquez CS, Pavlowski EM, Koury SE, et al.  (2025) Change is never easy: Exploring the transition from undergraduate to dental student in a U.S.-based program. PLoS ONE 20(4):\n           e0321494.\n        \n        https://doi.org/10.1371/journal.pone.0321494\n\nEditor:Leona Cilar Budler, University of Maribor, SLOVENIA\n\nReceived:June 7, 2024;Accepted:March 6, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Leite et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe transition from an undergraduate to a graduate/professional program – such as the transition to dental school – can be a challenging time for incoming students [1]. Students often have pre-conceived notions regarding their upcoming dental school experience and these may be influenced by several sources, including information from current and former dental students and their own experiences in previous programs. One longitudinal study comparing dental students’ expectations to their lived experiences revealed an overall negative shift, suggesting that students initially expected more from their educational environment than what they experienced [2]. This kind of mismatch between expectations and reality can be frustrating, potentially leading to academic and personal struggles, and even mental health issues [3]. This is particularly true for dental students. Several studies report that stress is very prominent among dental students and its sources are mainly related to academic and clinical aspects of dental training [3–5]. If stress levels remain high, they may significantly impact students’ academic performance, physical health, and psychological well-being [4]. An important long-term consequence of stress is burnout. A cross-sectional study showed an alarming figure of 40% of dental students suffering from burnout at an American dental school and reported that prolonged burnout is not sustainable and can lead to depression, self-isolation, and in severe cases, suicidal ideation [6].\n\nBecause dental education is inherently challenging and potentially stressful to students, we believe that if incoming students can set realistic expectations, they may be better prepared for the challenges they will face in their education. That preparation may, in turn, reduce potential negative impacts on their education, mental health, and overall wellbeing. For this reason, it is important to evaluate the degree to which incoming dental students’ expectations about dental school match their reality. Thus, the goal of this study was to compare students’ perceptions of their experiences in undergraduate education to expectations and experiences in dental school. To this end, we conducted observational cross-sectional and longitudinal studies comparing expectations and experiences from students in a US-based dental program. By focusing on student-centered insights, we hope to better understand the specific aspects involved in these challenges, help shape preventative strategies, and inform the kinds of resources needed in dental schools to address these issues.\n\nDental students from the four-year predoctoral program at the University of Pittsburgh School of Dental Medicine (UPSDM) were invited to voluntarily complete surveys for two cohorts – a cross-sectional study and a longitudinal study. In all questionnaires, student identity remained anonymous, and each respondent provided an anonymous unique identifier, consisting of the first two letters of their mother’s maiden name and the two digits corresponding to the day of the student’s birth month.\n\nTable 1shows a schematic for the study outline and response rates. For thecross-sectionalstudy, all students in all four years (D1, D2, D3, and D4) in the 2015–16 academic year who were present at the time of distribution of questionnaires were invited to participate. Enrolled D1 students were invited to answer the questionnaire during orientation early in the fall semester of 2015. In that same school year, D2, D3, and D4 students were invited to participate during class. For thelongitudinalstudy, the students from the class of 2019 were surveyed four times, once every year during their education, also during class. Recruitment took place between August 19, 2015, and April 1, 2019.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321494.t001\n\nStudents were invited to complete paper questionnaires in person. These questionnaires were distributed to all students present in the classroom at all time points. The purpose of the survey was explained to students and that their participation was completely voluntary. At that point, completion of the survey was taken as informed consent. This study was approved as exempt by the University of Pittsburgh Human Research Protection Office (PRO15070414).\n\nThe questionnaires contained two sections. Thefirst sectionincluded questions about undergraduate and current (when applicable) academic achievements, such as GPA and undergraduate institution. Thesecond sectionincluded the bulk of the survey, with eight questions comparing expectations or experiences between undergraduate and dental school. Three of these questions were open-ended and addressed differences between undergraduate and dental school instructors, classes, and experiences outside the classroom. The remaining five were Likert scale-type questions regarding differences between undergraduate and dental school overall preparedness, time management, workload, stress, and academic support. Questions were carefully chosen by a panel of experts (CWH and ZH) based on their experience in the areas of teaching, clinical education, admissions, and student affairs, and on Appleby’s 2014 study [7], which examined the expectations and differences between high school and college. Open-ended questions were deliberately used to allow students to respond with spontaneity.\n\nThree different questionnaires were distributed, depending on the study group (Table 1). Thefirst questionnaire, henceforth referred to asbaseline questionnaire, was distributed to incoming D1 students, who were included in both cross-sectional and longitudinal cohorts, asking questions of both sections. Specifically, its second-section questions asked students to compare theirexperiencesas undergraduates to theirexpectationsin their upcoming dental school education. Thesecond questionnairewas distributed to the cross-sectional cohort, i.e., D2, D3, D4 students, at the same time point as the first questionnaire, and also included questions of both sections. Specifically, its second-section questions asked students to compare theirexperiencesas undergraduates to theirexperiencesas dental students. Thethird questionnaire, henceforth referred to asfollow-up questionnairewas utilized only for the longitudinal cohort including only second-section questions comparing theirexperiencesas undergraduates to theirexperiencesas dental students.\n\nThe complete study questionnaires are provided as the supplemental materials (S1–S3 File).\n\nWritten responses were transformed to electronic versions using Qualtrics™ and exported into Excel spreadsheets for subsequent analyses. For open-ended questions in both cross-sectional and longitudinal cohorts, a coding system was created to group common themes (the five most common themes are listed and explained inTable 2). Two calibrated, independent coders (CV, EP) analyzed each response separately and later reconvened to create a final combined dataset. The categorized open-ended question responses were displayed in percentages and summarized with descriptive statistics. Less frequently mentioned themes included frequency of exams, responsibility and professionalism, and social environment of learning (classes); less access to faculty and professionalism (instructors); developing interpersonal skills, activities related to dentistry, and independence (non-classroom experiences). These scarcely mentioned themes were not included in our subsequent analyses.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321494.t002\n\nAs for Likert score-like questions, students of both cross-sectional and longitudinal cohorts responded to expected/experienced differences between dental school and undergraduate pertaining to preparedness for dental school, workload, ability to manage time, stress level, and rate of academic support, using Likert scale-like scores. For the cross-sectional study, these data were analyzed using Stata™ (v.17) software. The Shapiro-Wilk test for normality showed that many responses did not follow normal distribution. We, therefore, utilized the Kruskal-Wallis test to analyze cross-sectional cohort responses, followed by the Wilcoxon Rank-Sum test for paired comparisons, when a significant difference was found. To test for potential confounders for the Likert scale-type responses, we ran a multiple linear regression model, using students’ responses for the questionnaires’ first sections, regarding academic performance. These covariates included undergraduate/graduate GPA, having held a job as an undergraduate/graduate, undergraduate/graduate research experience, age upon entrance at dental school, and Barron’s college ranking [8] based on name of college attended for undergraduate education. Mixed-effects regression modeling was utilized to analyze the longitudinal cohort. We modeled each Likert scale-type response longitudinally and examined the impact of year while adjusting for potential confounding variables related to academic performance – undergraduate/graduate GPA, having held a job as an undergraduate/graduate, and undergraduate/graduate research experience (age and college rankings were not included, as they did not change, because the same students were analyzed).\n\nA complete case analysis was performed for these longitudinal data, excluding responses from students who were absent from one or more questionnaires, and those with duplicate anonymous unique identifiers. Because the questionnaires were anonymous, it was not possible to track down the cause of absence for each individual case; possible causes include: students chose not to complete the questionnaire, were absent from school that day, or did not use consistent unique identifiers throughout the years. Whichever the case, we are comfortable assuming that these data were missing completely at random. Significance was considered for p-values lower than 0.05 for Kruskal-Wallis tests and regression models, and 0.008 for Wilcoxon Rank-Sum tests, using Bonferroni correction for multiple paired comparisons (0.05 divided by 6 comparisons, resulting in 0.008).\n\nThe response rate varied depending on the different groups, because each questionnaire was administered to different classes (Table 1). The response rate was calculated by the dividing number of questionnaires filled-out by the number of students in the class roster. After accounting for missing data, there were 46 participants with non-duplicated responses available across the four time points for the longitudinal dataset. The raw questionnaire datasets used in our analysis are provided as supplemental materials (S4–S12 File).\n\nOpen-ended question responses were grouped into categories and the five most common categories mentioned by the incoming D1 class (Table 2) were selected for comparisons among different classes in our descriptive analyses (Fig 1).\n\nD1 (class of 2019), D2 (class of 2018), D3 (class of 2017), and D4 (class of 2016) students’ responses to expected/experienced differences between(A)undergraduate classes and dental school classes,(B)undergraduate instructors and dental school instructors, and(C)undergraduate non-classroom experiences and non-classroom experiences in dental school surveyed in 2015.\n\nD1 (class of 2019), D2 (class of 2018), D3 (class of 2017), and D4 (class of 2016) students’ responses to expected/experienced differences between(A)undergraduate classes and dental school classes,(B)undergraduate instructors and dental school instructors, and(C)undergraduate non-classroom experiences and non-classroom experiences in dental school surveyed in 2015.\n\nhttps://doi.org/10.1371/journal.pone.0321494.g001\n\nRegarding responses to differences betweenclassesin dental school versus undergraduate, most D1 students (64%) expected there to be increased workload in dental school (Fig 1A). Proportions remained high but dropped more than 10% in D2 through D4 reflecting their lived experience with increased workload in dental school. For the other four categories, a common pattern emerged with a greater number of D1 students expecting increased depth and difficulty, a faster pace, more relevance to dentistry, and a more difficultly with time management compared to the experiences of their D2, D3, and D4 colleagues.\n\nThe gap between D1 students’ expectations and more senior students’ lived experience also extended toinstructors(Fig 1B). The most jarring discrepancy related to expectations of more personalized attention and more support, with a 31% difference between D1 expectations and D2 experience.\n\nResponse relating tonon-classroom-related experienceswere more complex (Fig 1C). While expectations around professionalism and having close relationships with classmates showed the same pattern of gross discrepancy with lived experience as those reported above, the gap narrowed considerably for time management and time for social life. Notably, responses concerning increased stress levels and expectations was initially low in D1 students but continued to rise each year through D4.\n\nThe linear regression model did not reveal any potential confounders impacting students’ responses when accounting for academic performance.\n\nOf the five Likert scale-type questions, Kruskal-Wallis tests showed a statistically significant difference fortime-management(p < 0.0001) andacademic support(p < 0.0001), but no significant differences between responses for overallpreparednessfor dental school, theworkloadthey will face, and the level ofstressthey will endure. Upon further investigation, Wilcoxon Rank-Sum tests showed these differences were present between D1 students and all other classes (D2, D3, and D4) (Fig 2), with D1 students expecting to have a significantly greater ability to manage time (Fig 2C) and, notably, expecting to have a higher level of academic support (Fig 2E).\n\nD1 (class of 2019), D2 (class of 2018), D3 (class of 2017), and D4 (class of 2016) students’ responses to expected/experienced differences between dental school and undergraduate regarding(A)preparedness for dental school,(B)workload,(C)ability to manage time,(D)stress level, and(E)rate of academic support. Forpreparedness, 0 = Very inadequate, 1 = Somewhat inadequate, 2 = Somewhat adequate, and 3 = Very adequate. Forworkload, 0 = Much less, 1 = Less, 2 = About the same, 3 = More, and 4 = Much more. Fortime management, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. Forstress level, 0 = Much lower, 1 = Lower, 2 = About the same, 3 = Higher, and 4 = Much higher. Foracademic support system, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. Data displayed as mean and standard deviation. **P-value < 0.008 and ***p-value < 0.0001 of D2, D3, and D4 in comparison to D1, as determined by Wilcoxon Rank-Sum test.\n\nD1 (class of 2019), D2 (class of 2018), D3 (class of 2017), and D4 (class of 2016) students’ responses to expected/experienced differences between dental school and undergraduate regarding(A)preparedness for dental school,(B)workload,(C)ability to manage time,(D)stress level, and(E)rate of academic support. Forpreparedness, 0 = Very inadequate, 1 = Somewhat inadequate, 2 = Somewhat adequate, and 3 = Very adequate. Forworkload, 0 = Much less, 1 = Less, 2 = About the same, 3 = More, and 4 = Much more. Fortime management, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. Forstress level, 0 = Much lower, 1 = Lower, 2 = About the same, 3 = Higher, and 4 = Much higher. Foracademic support system, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. Data displayed as mean and standard deviation. **P-value < 0.008 and ***p-value < 0.0001 of D2, D3, and D4 in comparison to D1, as determined by Wilcoxon Rank-Sum test.\n\nhttps://doi.org/10.1371/journal.pone.0321494.g002\n\nAgain, the five most common categories mentioned by the D1 class were selected for comparison among different classes in our descriptive analyses (Fig 3).\n\nClass of 2019 (D1, D2, D3, and D4) students’ responses to expected/experienced differences between(A)undergraduate classes and dental school classes,(B)undergraduate instructors and dental school instructors, and(C)undergraduate non-classroom experiences and non-classroom experiences in dental school throughout all four years of dental school.\n\nClass of 2019 (D1, D2, D3, and D4) students’ responses to expected/experienced differences between(A)undergraduate classes and dental school classes,(B)undergraduate instructors and dental school instructors, and(C)undergraduate non-classroom experiences and non-classroom experiences in dental school throughout all four years of dental school.\n\nhttps://doi.org/10.1371/journal.pone.0321494.g003\n\nRegarding the class of 2019’s expectations aboutclassesin dental school compared to what they experienced as undergraduates, responses expressing concern for increased workload dropped as their education progressed (from 64% to 47%) (Fig 3A). A similar pattern of reduction was observed for concerns about increased depth/difficulty and faster pace. In contrast, D1 expectations and D2-D4 experiences concerning relevance to dentistry and time management concerns were more similar.\n\nAs for questions aboutinstructors, the pattern of responses was variable across the four years. While fewer students mentioned receiving more personalized attention and support in their D2-D4 years compared to their initial D1 year expectations, the discrepancy was less evident than in the cross-sectional study (Fig 3B). D1 expectations regarding more access to faculty fluctuated from having similar percentages at the D2 and D3 stage, to having a higher percentage of responses by D4. Responses indicating that faculty would be more knowledgeable and experienced were higher at D2 than initially expected at D1, but then fell gradually during the D3 and D4 years. Lastly, responses referencing teaching styles being different and faster-paced had somewhat similar proportions across the four years (around 12%).\n\nExpectations aboutnon-classroom-related experiencesin dental school compared to undergraduate were mostly similar to those observed for the cross-sectional study, with a few exceptions. Responses regarding having more professionalism and dental-related experiences showed a drop between D1 and later years (Fig 3C), similar but less drastic than we observed for the cross-sectional study. Notably, we observed the same drop between D1 and D2/3 concerning being closer with classmates, but this pattern was then reversed in D4.\n\nSimilar to what was observed in the cross-sectional Likert scale-type results, in the longitudinal cohort there were also no significant differences between responses for overallpreparedness,workload, andstress levels. Also mirroring the cross-sectional results, there were significant differences between D1 expectations and what they report in years 2, 3, and 4 fortime management(p < 0.0001) and level ofacademic support(p < 0.0001) (Fig 4andTable 3). Responses indicated expectation of less difficulty in managing time compared to their time as undergraduates (Fig 4C). The same went for expectations regarding academic support versus what they received throughout their dental education (Fig 4E). Interestingly, when analyzing for potential confounders regarding academic performance, the statistical significance was not impacted for academic support, but disappeared for time management (Table 4).\n\nD1, D2, D3, and D4 (class of 2019) students’ responses to expected/experienced differences between dental school and undergraduate regarding(A)preparedness for dental school,(B)workload,(C)ability to manage time,(D)stress level, and(E)rate of academic support. Forpreparedness, 0 = Very inadequate, 1 = Somewhat inadequate, 2 = Somewhat adequate, and 3 = Very adequate. Forworkload, 0 = Much less, 1 = Less, 2 = About the same, 3 = More, and 4 = Much more. Fortime management, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. For stress level, 0 = Much lower, 1 = Lower, 2 = About the same, 3 = Higher, and 4 = Much higher. Foracademic support system, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. Data displayed as mean and standard deviation. *p-value < 0.05, ** p-value < 0.008 and ***p-value < 0.0001 of D2, D3, and D4 in comparison to D1, as determined by the mixed-effects regression modeling.\n\nD1, D2, D3, and D4 (class of 2019) students’ responses to expected/experienced differences between dental school and undergraduate regarding(A)preparedness for dental school,(B)workload,(C)ability to manage time,(D)stress level, and(E)rate of academic support. Forpreparedness, 0 = Very inadequate, 1 = Somewhat inadequate, 2 = Somewhat adequate, and 3 = Very adequate. Forworkload, 0 = Much less, 1 = Less, 2 = About the same, 3 = More, and 4 = Much more. Fortime management, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. For stress level, 0 = Much lower, 1 = Lower, 2 = About the same, 3 = Higher, and 4 = Much higher. Foracademic support system, 0 = Much worse, 1 = Worse, 2 = About the same, 3 = Better, and 4 = Much better. Data displayed as mean and standard deviation. *p-value < 0.05, ** p-value < 0.008 and ***p-value < 0.0001 of D2, D3, and D4 in comparison to D1, as determined by the mixed-effects regression modeling.\n\nhttps://doi.org/10.1371/journal.pone.0321494.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321494.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321494.t004\n\nThe main purpose of this study was to investigate pre-doctoral students’ expectations and experiences throughout the dental program in comparison to their undergraduate experiences. The cross-sectional cohort was intended to give a snapshot of expectations and experiences across the classes for a given year, whereas the longitudinal cohort was intended to allow observation of the same group of students over time. Both cohorts had similar differences between what incoming students expected and what was experienced in later years during their education. Of note, D1 students based their expectations solely on what they had heard about dental school, as they hadn’t had any dental curricular experience at the time when questionnaires were distributed.\n\nOpen-ended question results for both cohorts showed that D1 students expected increased workload, paralleling their more senior peers’ reports. Another study also found that dental students reported a heavier workload when compared to their undergraduate experience [9]. However, in our study, other D1 expectations regarding classes were reported in lower proportions by D2, D3, and D4 students, including more depth and more difficulty, faster pace, relevance to dentistry, and more difficulty in managing time. The decrease in these proportions is possibly due to students’ ability to adjust during their education and could also be attributed to the fact that clinic time increases throughout the curriculum and students have significantly fewer (or no) didactic classes by the time they reach their fourth year. As a result, they report encountering fewer class-related issues in these final years. The decrease may also be related to the culture of dental education being known as inherently challenging [4]. In other words, students may have an expectation that their education will be difficult, but once they are enrolled, they face fewer challenges than initially expected.\n\nThe cross-sectional open-ended responses also showed that incoming students expected more attention, support, and access to faculty than they received as undergraduates, whereas their senior peers mentioned these themes in smaller proportions. The longitudinal data showed similar overall trends, though the disparity was less evident. Previous studies indicate comparable trends, with dental students perceiving that faculty were less helpful and supportive than anticipated, with antiquated teaching methodologies and rigid hierarchical relationships offered as a possible explanation [10,11]. Even today, traditional teaching methods are still widely prevalent in dental education; however, students’ prior educational experience may have changed to include more up-to-date instructional strategies, priming them for potential disappointment when entering dental education. Additionally, students’ rationale for expecting more attention may be due to the apprenticeship model characteristic of health professional education. Moreover, depending on their undergraduate experience (possibly at a larger institution), students may expect increased faculty attention due to a more favorable student-faculty ratio. Conversely, from the faculty’s perspective, dental students may be viewed as adults, and more mature than undergraduate students, therefore not requiring as much attention.\n\nAnother noteworthy finding from our qualitative data is that D1 students’ expectations regarding having more professionalism and dental-related experiences outside the classroom had a higher percentage of responses compared to their senior peers’. A possible explanation for this discrepancy could be that D2, D3, and D4 students have an implicit understanding that opportunities for profession-related exposures as dental students will take place outside of the curriculum, and therefore, do not consider including this aspect in their responses when asked about their non-classroom-related experiences.\n\nStudents’ responses mentioning being closer to classmates showed different patterns in the cross-sectional and longitudinal studies. In our cross-sectional data, student’s initial expectations were higher compared to the reported experiences of D2-D4 classes. This could be due to intrinsic difference among the different classes, and we do not know how the experience of any single class might have changed over time. We can glean some additional insights, however, from our longitudinal data. Here we saw a similar pattern in higher expectations for the incoming D1 class compared to their experiences in their D2 and D3 years, but this changed dramatically in their D4 year, rising even higher than their initial expectations at the start of dental school. A possible explanation could be that the initial camaraderie expected in D1 was negatively impacted due to stressors and the high degree of competitiveness characterizing their D2 and D3 years. In contrast, the D4 year represents a new stage of their dental education marked by less competition as most students have fulfilled the majority of their requirements and placed into a residency program or secured their first job. Another recent study from the University of Hong Kong reported overall high rates of dental students having “a positive relationship with their classmates” [12], but it is difficult to compare our results due to cultural and curricular differences and the fact that their study did not present these data broken down by class year or assess attitudes longitudinally.\n\nFor open-ended questions, most students also reported more stress than anticipated, although the high stress level aligns with the expectation reported in the Likert scale-type questions. Though far from ideal, this is expected and has been previously reported as an inherent component of dental or health profession educations [3,4,13,14].\n\nAs for Likert scale-type questions, both cohorts reported having more difficulty managing time than expected when compared to their undergraduate experiences. However, for the longitudinal group, the effect was attenuated when factoring in academic performance confounders. Considering that the longitudinal group is more uniform, it could be interpreted that more adept students would be able to manage their time more efficiently and would therefore have more realistic expectations. On the other hand, it could also be that this result was impacted by sample size, which was limited to students who were present in all four time points, and model complexity, rather than the impact of confounders. Regardless, a good management of time is desirable not only because the workload requires it, but also because it has been shown to help with coping with stress [14] and maintaining adequate work-life balance [13].\n\nImportantly, recurring responses in both cohorts indicated that students expected to have a stronger academic support system than they did as undergraduates, but that D2-D4 experiences fall below these expectations. The lack of academic support was also pointed out by dental students in other studies, including a recent cross-sectional investigation [10]. It should, however, be pointed out that this study was conducted prior to the COVID-19 pandemic. During and after the pandemic, many institutions, including the UPSDM, implemented a number of measures to improve students’ experience, with special focus on support and mental health [15,16].\n\nSeveral such measures can be taken to address the results discussed above, foster a better learning environment, and improve students’ overall experience in a dental school [12,14]. Dental schools may use the data collected to better curate their curriculum, extra-curricular offerings, and faculty training (which would address some of the recurring responses by students) to create a more supportive environment [11,13]. To prevent frustration, stress (which was also mentioned in students’ responses), and burnout, dental schools may consider offering early detection/prevention programs and interventions to foster psychological safety amongst students [17–19]. In this regard, one study found that medical and dental students thought early psychological assessment and counseling to be very important for students [20]. With the popularity of social media, virtual group therapy may provide students with an alternative source of help [6]. Examples of such measures have already been implemented or enhanced at the UPSDM after this study was conducted, and include peer tutoring programs, hiring of a full-time Licensed Professional Counselor, identifying an ombudsperson, a meditation room, earlier extended onboarding, student focus groups, among many others. Finally, to avoid overwhelming students, it is key to properly curate all resources and communicate to students their availability, and to clarify how they can properly be used to their best advantage [12].\n\nAs a future direction, it may be worthwhile to redistribute questionnaires to students to measure effects of implemented actions, gauge future changes, and assess whether the discrepancy between expectations and experiences will be significantly reduced. Similar to other health professions, transitions at other time points in dental education, e.g., from predoctoral to residency education, may also be worth investigating [21].\n\nOur study only included responses from a single institution, which poses a limitation, because it might have introduced possible biases pertaining to geographical location, philosophical aspects of the university, and cultural background of students. However, it should be noted that our students have a similar profile when compared to the national data of the same period, so it is reasonable to assume that our findings are generalizable [22]. Nonetheless, single classes may have individual characteristics that set them apart from other classes, which might also have introduced bias to the cross-sectional study. We were also limited by sample size, as there is a restricted number of students enrolled in each year, as well as uncontrollable issues, such as absences and duplicate unique identifiers. Repeating similar studies in other institutions could potentially provide more reliable conclusions and more broadly applicable recommendations. Another limitation was the fact that our questionnaires were not validated prior to distribution. However, we considered them robust, as they were based on the literature [7] and were revised by a panel of experts. Furthermore, while open-ended questions were intentionally included because they offer rich data and allow the participants to include any relevant experience, they limit conclusions, because students were not specifically prompted to report their experiences in specific themes, such as those mentioned in D1 responses.\n\nThis study provides student-centered insights to better understand specific challenges when transitioning from undergraduate to dental education by documenting dental students’ expectations and experiences in a professional health education environment. We found that some of the students’ initial expectations at the start of their first year differed from the experiences of students in later years. Some of these discrepancies were in key areas, related to managing workloads or the degree of academic support available. Dental schools should consider implementing measures to address these issues and help pave a smoother path from admission to graduation.\n\nhttps://doi.org/10.1371/journal.pone.0321494.s001\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s002\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s003\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s004\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s005\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s006\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s007\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s008\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s009\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s010\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s011\n\n(S11)\n\nhttps://doi.org/10.1371/journal.pone.0321494.s012\n\n(XLSX)\n\nThe authors would like to express their gratitude to the 2019 UPSDM Dean’s Summer Research Scholars Program for supporting Camille Vasquez’s involvement in the project. We would also like to thank Rebecca Abromitis and Rachel Suppok, Reference Librarians at the University of Pittsburgh Health Sciences Library System, for their help with the literature review. We would also like to express our gratitude to Theodore Vincent Kondrich, undergraduate student worker at the University of Pittsburgh, and Nishali Bera, graduate student at the UPSDM, for their help organizing references, and Nicholas Joseph Habib, undergraduate student worker at the University of Pittsburgh, for entering surveys into QualtricsTM. Lastly, the authors would like to thank Giuseppe Intini, for supporting Taiana Leite’s interest in educational research.",
    "category": "education"
  },
  {
    "title": "Leveraging agent-based modeling and a randomized intervention to advance childhood physical activity: A study protocol",
    "authors": "Matt Kasman, Adam B. Sedlak, Lydia Reader, William J. Heerman, Russell R. Pate, Amelie G. Ramirez, Evan C. Sommer, Shari L. Barkin, Ross A. Hammond, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321301",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321301",
    "content": "This study (1R01HD107002-01A1) protocol describes the planned creation and use of an agent-based model (ABM) of early childhood physical activity (PA). Successful early childhood PA interventions can potentially play an important role in both increasing overall population health as well as closing health disparities across subpopulations. At present, effective strategies for doing so are currently unknown. In large part, this is because PA determinants operate across levels dynamically, interact with one another, and can differ substantially across children. A complex systems approach—specifically, ABM—can be used to provide important insights about effect pathways driving child PA. Design of the proposed ABM will be based on high-quality extant research on childhood physical activity while allowing for the testing of hypotheses that extend beyond this body of literature. Its primary source of input data will be participants in GROW (NCT01316653), a completed cohort-based randomized controlled trial (RCT) that includes extensive longitudinal PA data collected from accelerometer observations of children from ages 3–9. We will iteratively test and improve upon an etiologic ABM of childhood PA, ensuring that it can satisfactorily reproduce micro- and macro-level influences and trends comparable to those seen in GROW. The tested ABM will then be used to extrapolate beyond the context of the GROW RCT, experimentally identifying potentially efficacious intervention strategies to improve childhood physical activity through program implementation or changes in policies and practices. We will use expert input to identify promising intervention approaches. We will use the model to systematically experiment with a wide array of different hypothetical combinations of intervention specifications and combinations. At the end of the model experimentation step, we expect to generate insights of broad applicability to the field of PA science regarding what might work, and for whom, in promoting PA and reducing disparities in these behaviors.\n\nCitation:Kasman M, Sedlak AB, Reader L, Heerman WJ, Pate RR, Ramirez AG, et al.  (2025) Leveraging agent-based modeling and a randomized intervention to advance childhood physical activity: A study protocol. PLoS ONE 20(4):\n           e0321301.\n        \n        https://doi.org/10.1371/journal.pone.0321301\n\nEditor:Jennifer Tucker, PLOS: Public Library of Science, UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\n\nReceived:February 27, 2025;Accepted:March 3, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Kasman et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:This study protocol describes the planned creation and use of an agent-based model (ABM). Data collected during this study will be solely comprised of model parameter sets (i.e., model inputs) and output from model runs during testing and experimentation. Following best practices, these will be made available upon completion of the ongoing study.\n\nFunding:Financial support was received for the research, authorship, and publication of this article. Award R01HD107002 received from the National Institute of Child Health and Human Development. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAlmost half of U.S. adults have a preventable chronic disease, most of which could be improved with regular physical activity (PA) [1]. Numerous studies demonstrate a relationship between greater PA and favorable health outcomes for children and adults including metabolic, skeletal, psychosocial, cognitive, and cardiovascular health [2–10]. PA is a promising potential lever for addressing racial and ethnic health disparities due to both the high prevalence of negative health outcomes and low levels of PA within specific subpopulations; for example, on average, Hispanic women experience higher incidences of negative health outcomes and engage in less PA than other groups [11–17]. Significant health benefits accrue in adults who have been physically active throughout their lives [2–4,18,19]. Physical activity behaviors in childhood are associated with those same behaviors in adolescence and adulthood, meaning that even a moderate amount of PA in childhood can have immediate and long-term health benefits. Because PA behavior patterns are established at a young age, successful early childhood PA interventions can potentially play an important role in both increasing overall population health as well as closing health disparities across subpopulations [20–30].\n\nUnderstanding the relative contributions of potentially modifiable determinants of childhood PA behaviors could lead to a better understanding of long-term health promotion strategies. While there are many programs and policies that seek to support sustainable patterns of health PA in early childhood, the most efficacious approaches are currently unknown, to the best of our knowledge. In large part, this is due to the vast number of factors that contribute to physical activity behaviors throughout childhood. Cross-sectional studies suggest a multilevel framework with influences at the macro-level (e.g., the built environment) [31–33], the meso-level (e.g., social environment) [34–37], and the micro-level (e.g., cognitive processes) [38–40]. That is, PA determinants operating across levels dynamically interact with one another, and can substantially shape the PA behaviors and development of children based on individual circumstances and experiences. These interrelated dynamics strongly suggest that childhood PA can be productively thought of as the result of acomplex adaptive system. A complex adaptive system is one in which elements interact and change over time, generating system-level patterns that are often not linear, uniform, or intuitive [41]. Complex adaptive systems are characterized by the substantial presence of interdependence, adaptation, and heterogeneity [42]. In combination, these present serious challenges for traditional quantitative analytic techniques that rely on strict assumptions about the independence of observations [41–44].\n\nAgent-based models (ABMs) have widely been used across fields of science to study complex adaptive systems, and members of our research team have successfully applied ABMs to study myriad public health topics [45–62]. ABMs are “bottom-up” computation simulation models, explicitly representing the actions of simulated “agents” (typically but not always individuals) over time, with system-level patterns emerging from an accumulation of micro-level behaviors [42–44]. These models are inherently dynamic and heterogeneous, allowing individuals with different attributes and behavioral traits to interact with one another and their environment, and to adapt their decision-making in response to interactions or changes in environment. While preliminary studies have demonstrated the potential application of ABM to PA behaviors in adults, only a few have examined PA in older children, and none have explored the interrelated mix of determinants that drive early childhood PA [63–69].\n\nA key barrier to the development of ABMs of early childhood PA to date has been the need for sufficiently longitudinal, high-quality individual-level data. The Agent-based Computational Testing to Increase Vigorous Exercise (ACTIVE) project will develop the first data-driven, complex adaptive systems approach for modeling both PA behaviors in children (aged 3–9) and potential interventions to reduce PA disparities by leveraging the rich, high-quality data from the Growing Right Onto Wellness (GROW) RCT (NCT01316653) [70]. What follows is a description of the ACTIVE study protocol.\n\nWe will use ABM to pursue two primary research goals:\n\nOn 12/17/2024 the Emory IRB reviewed this study by expedited process. Due to the nature of this study, a complete waiver of HIPAA authorization and informed consent has been granted by the IRB.\n\nWe will use extensive data collected during a completed RCT focusing on childhood obesity prevention and objective observation of childhood physical activity to develop and test an ABM of childhood physical activity. Classical statistical approaches typically make implicit assumptions (e.g., about independence between entities) that are incompatible with phenomena such as childhood PA. For example, children’s decisions to engage in PA are clearly intertwined as they observe one another, copy behaviors, and choose to play physically active games with one another. ABM is an appropriate methodological approach that can address some of these limitations to study childhood PA. ABM is a powerful analytical approach in which complex dynamic and spatial systems are studied “from the bottom up.” In an ABM, each individual actor in the system (i.e., each child) is explicitly represented as an autonomous computer software “agent.” This allows for substantial individual heterogeneity among agent attributes such as age, sex and environments such as parental physical activity and social settings experienced both inside and outside of the home. The agents are also given a set of hypothesized adaptive rules that govern their interactions with each other and with their environments (e.g., rules about how parental attitudes and activities affect children’s behaviors), allowing ABMs to effectively represent multiple simultaneous and potentially interdependent effect pathways. ABM is valued for the ability to capture: 1) feedback between multiple analytic levels; 2) direct and indirect effects on behaviors based on when and how individuals interact with each other 3) co-adaptation of individuals, groups, and the environments; 4) heterogeneity in both agent attributes and effect pathways; and 5) the possible impact of putative interventions via experimental manipulation of counterfactuals [43,44,71,72].\n\nFrom the outset, our ABM will be designed to test hypotheses about heterogeneous effects, specifically whether, and in what ways, effect pathways differ throughout early childhood and across genders. Model relationships are anticipated to change over the course of childhood development, as will the influencing domains themselves (e.g., the built or social environments that children experience can change over time). The model will cover a time-period from early childhood (from age 3) to school-age (through age 8). The design of our model will be able to capture dynamic influences on PA, with some factors potentially becoming weaker or stronger during the course of early childhood development and socialization. We will also explore potential sources of heterogeneity in influence pathways across child characteristics. For example, the ways in which the built and home social environments combine may, on average, affect determinants of physical activity differently between girls and boys.\n\nThe nature of ABM is well-aligned with our goal of testing hypotheses about the etiology of early childhood PA. Because ABMs are computational, mechanistic models, the functional forms corresponding to every model element must befully specified.Details of the model design such as which attributes are static or dynamic and how dynamic properties change over time need complete and logical and mathematical specifications [43,44]. Based on previous, successful ABM projects, we will use relevant empirical literature and guided collaborative discussions between content experts and modelers on our research team to translate research, experience, observation, and intuition into mathematical expressions [52,54,60,61,73].\n\nThe design of our model will be based on high-quality extant research on childhood physical activity while allowing for the testing of hypotheses that extend beyond this body of literature. Our planned initial model design reflects the best currently available empirical evidence, theory, and expert guidance. The ABM will be designed to represent factors that research suggests have the strongest influence on childhood PA, as well as how these factors interact with one another, change over time, and can differ across children (Fig 1).\n\nThe interconnected systems of factors that drive physical activity patterns can change as children age and can differ substantially between children. Child-level influences change over time, with changes potentially interacting with child characteristics over the course of childhood development.\n\nThe interconnected systems of factors that drive physical activity patterns can change as children age and can differ substantially between children. Child-level influences change over time, with changes potentially interacting with child characteristics over the course of childhood development.\n\nhttps://doi.org/10.1371/journal.pone.0321301.g001\n\nThe model will simulate a cohort of young children with heterogeneous attributes interacting across heterogeneous social and physical environments. During the course of each simulation run, these simulated children can engage in varying degrees of physical activity. Levels of physical activity at any given point in time will be driven by:\n\nOur hypothesized model will incorporate two forms of feedback stemming from PA. The first is that physical activity can increase a child’s executive functioning; this contribution to development of cognitive processes increases a child’s capacity for engaging in future PA. The second is that engaging in physical activity in turn affects children’s social environments. For example, children enjoying PA could cause their peers to be more physically active or their parents to become more supportive of behaviors conducive to childhood PA. Our model will allow for effect pathways that display substantial heterogeneity across children. This is important because the makeup, strength, and characterization of effect pathways (alone or in combination) that influence PA can be expected to differ during childhood development and across characteristics such as age and gender [12,25,26,28,29,32,70,87,101–111]. Although informed by existing literature and preliminary studies, the process of operationalizing the ABM will by necessity entail testing many fine-grained hypotheses about the causal mechanisms that drive childhood PA that extend beyond existing literature.\n\nAfter initial model design, we will engage in model parameterization. During this process, we will assign values to each of the terms that appear in the model design. Data from the GROW RCT will be the primary source of input into parameter values. The GROW RTC was a childhood obesity prevention study that built on previous research with an emphasis on methodological rigor. It included multiple intervention components across disparate settings, had an unprecedented 3-year intervention window, and targeted children of underserved racial/ethnic groups and low socio-economic status [112]. GROW followed a cohort 610 children and parents or guardians from preschool to school-age while measuring a diverse set of phenotypes (i.e., anthropometrics, physiological, psychological, behavioral, socio-demographical, and environmental). Participants were enrolled between August 2012 and May 2014, with guardians providing informed, written consent for participation. Throughout the 3-year trial, attendance to all intervention sessions was high (>80%) and the overall retention rate was very high (>90%). Data on parent-child dyads were collected for 3 years on a rolling basis from 2012 to 2017 and included assessments of anthropometry, accelerometry, social network connections between parents, environmental conditions, and executive functioning. The study consisted of two-thirds preschool aged children who were high normal weight (BMI % ≥ 50% and <85%) and one-third who were overweight (≥85% and <95%). By study design, none were obese at the time of enrollment. Enrolled children and families were 90% Hispanic and 10% non-Hispanic Black. Children enrolled in the study from ages 3–6 years and were followed for 3 years (i.e., from ages 6–9 years). The GROW intervention provided 12 weekly skills-building group classes at community centers; followed by 9 months of phone call coaching and 24 months of cues to action to use the built environment for family health. The comparator condition provided school readiness and literacy promotion through a series of six workshops over 3 years.\n\nGROW collected triaxial accelerometry at baseline and annually for 3 years from both children and parents using GT3X+ accelerometers with required minimum wear time of 360 minutes per day for at least four days including one weekend day. Sedentary, light, and moderate to vigorous physical activity (MVPA) data were defined using validated cut points for children and adults [28,113–115]. This allows us to examine physical activity objectively and in a granular way, distinguishing sedentary behavior from light, moderate, and vigorous physical activity. We also developed an algorithm to distinguish rest or sleep from sedentary behavior [116]. At baseline, GROW participants on average wore their accelerometers for 15 hours per day; wear time remained high throughout the study, providing unprecedentedly high-quality data on PA patterns.\n\nAlthough we will rely primarily on GROW data for model input, these data are insufficient to fully characterize all of the model elements that we anticipate including in the final ABM design. In order for the model to represent the GROW cohort context as best as possible, we will supplement GROW data with other data sources hierarchically as follows:\n\nA summary of our expected model input strategy is outlined inTable 1. Following best practices, we will share model input values derived from the above sources during dissemination of findings to ensure transparency and replicability.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321301.t001\n\nAfter initial parameterization, the model will be instantiated in software architecture. Following established best practices from ABM and computer science, we will implement the ABM in Python, ensuring key functionality for computational modeling; extensibility with a wide array of pre-existing packages; and compatibility with standard statistical, GIS, and visualization software., including versioning and software testing [43,44,120–122]. In addition, conceptual testing via boundary adequacy tests, dimensional consistency, partial model testing, and extreme condition tests will be woven into the modeling process to ensure structural validity and internal consistency [123–126]. At the end of instantiation, we expect to have a well-specified, fully operationalized computational representation of the key pathways that drive physical activity in young children. This implementation will include structures to allow for heterogeneous impact of pathways across individuals and a data output structure that will be used to facilitate rigorous empirical testing.\n\nFollowing model development, we will engage in rigorous and multifaceted model testing to assess its ability to produce expected output patterns. By comparing output from the completed model against empirically observed patterns of PA from GROW, we will be able to test the explanatory power of the model, and then explore how each component, independently and collectively, influences physical activity for different children across time and space within the context of GROW. These efforts will explicitly include the identification and incorporation of sources of substantial pathway heterogeneity. During this phase, we will explicate assumptions that underlie model design and subsequently subject these assumptions to sensitivity analyses to understand whether and to what extent they drive key findings. Following ABM best practices, the testing procedure will focus on assessing and improving upon the ability of the models to reproduce patterns and trends taken from GROW data [12,70,101–104,111]. Assessment of “fit” to GROW data will follow standard statistical tests appropriate to the type of data (e.g., time series, cross-sectional, associative). Specifically, data patterns that we will use to assess the model will include:\n\nIn addition to quantitative testing of the model, we will subject model design and behavior to qualitative assessment throughout the process to ensure consistent face validity. We will draw upon evidence from the GROW RCT and literature, alongside the extensive expertise of our research team and external Community Advisory Board to verify that the model meaningfully represents real-world fact patterns and dynamics as understood by researchers, intervention experts, practitioners, and community stakeholders, including parents of young children.\n\nThe ABM will be used as a “virtual laboratory” to extrapolate beyond the context of the GROW RCT, experimentally identifying potentially efficacious intervention strategies to improve childhood physical activity through program implementation or changes in policies and practices. We will apply the tested model to counterfactual settings and interventions beyond those observed during the GROW RCT so that insights can be generalized and provide guidance for future intervention efforts. A “counterfactual” setting refers to what would happen to a population’s health/behavior in alternative exposure scenarios [127,128]. ABMs provide a valuable opportunity to gain insight into potential policies and interventions through “in silico” experimentation (i.e., in the computer, via simulation) that goes well beyond any existing trial or dataset. We will have a valuable opportunity to gain insights that are relevant for the development of novel policies and interventions.\n\nWe will use expert input to identify promising intervention approaches. We will use the model to systematically experiment with a wide array of different hypothetical combinations of intervention effect magnitudes (i.e., “dose”), targeted recipients, and timing. In our previous work, we have found that policy interventions can have important synergies that make multiple small-dose intervention elements “supra-additive” in their impact—that is, effects that are greater than the sum of their effects individually [50,54,62]. We will explore the potential for such synergies here, exploring combinations of intervention approaches and leveraging the model’s ability to interact multiple pathways that drive PA across different childhood developmental stages. At the end of the model experimentation step, we expect to generate insights of broad applicability to the field of PA science regarding what might work, and for whom, in promoting PA and reducing disparities in these behaviors. These findings can suggest effective strategies for intervention selection and implementation.\n\nIterative model design, development, and testing are underway. Experimentation is in the planning phase. Data collected during this study will be solely comprised of output from model runs during testing and experimentation. Data collection is expected to be complete by June 2025. Results (comprised of analyses of model output) will be available shortly thereafter, with dissemination activities described below expected to begin in July 2025.\n\nThe initial conceptual model of childhood PA was selected to parsimoniously reflect both key influences theorized and observed in extant literature as well as data collected during GROW. However, the components included are not exhaustive. If the model design described above does not achieve explanatory power (i.e., ability to satisfactorily reproduce patterns observed in GROW data), the assumptions made during design and parameterization will be systematically revisited and revised as we iteratively improve upon our model’s ability to reproduce expected patterns. We allow for the possibility that this might necessitate expansion of the model to include additional elements not described here or removal of elements that do not contribute to explanatory power. Members of our research team have encountered similar situations and have successfully navigated these challenges through a combination of substantial, ongoing literature review and model exploration, model testing, solicitation of stakeholder and expert input, and iterative adjustment [52].\n\nThe research described here entails combining data sources—including ones that represent expert estimates—and quantifying hypotheses about the specific characterization of dynamics that underlie childhood PA. All of this requires making many assumptions. Systematic exploration of model behavior will be undertaken as these assumptions are varied. The robustness of explanatory hypotheses from our etiologic exploration and of the findings from our experimentation with counterfactual scenarios will be quantitatively assessed (e.g., through the testing of model fit to data described above). This is a standard and essential best practice for all computational models, defending against over-specification and assumptions or parameters that may not be correct. This step will also provide additional important information to guide future data collection (by identifying the most important unknowns) and intervention development (by identifying targets that provide maximum impact on dynamics or are robust against contextual factors) [43,44,58,129,130].\n\nThe nature of this research means that dissemination efforts should extend to multiple audiences. Findings that provide insight into the interrelated factors that underlie foundational early child PA are expected to be of interest to researchers and policy makers. The results of application of the model to counterfactual scenarios that shed light on policies and practices that can effectively increase child PA overall or reduce key disparities, and how successful intervention characteristics might differ across community contexts, should be made accessible to intervention experts, policymakers, and community stakeholders. Organizations that might be able to take effective action based on our findings include (but are not limited to) the Centers for Disease Control and Prevention; federal, state, or local departments of public health and education, the American Academy of Pediatrics, the National Institutes of Health, the Council of Governors, the United States Conference of Mayors, parks and recreation departments, and private or public community centers.\n\nFinally, the nature of this research is highly innovative. To the best of our knowledge, theex postextension of RCT data into the development and testing of an ABM is a novel approach to addressing research questions in public health. We believe that the use of a multidisciplinary research team including those involved with designing, fielding, and analyzing results from the RCT and those with extensive practice expertise in ABM can serve as a template for future synergistic combinations of RCT and complex adaptive systems research [131].",
    "category": "education"
  },
  {
    "title": "Effect of knowledge of sulfadoxine-pyrimethamine (SP) as prophylaxis for malaria on its uptake for intermittent preventive treatment of malaria in pregnancy (IPTp): Application of inverse probability weighted regression adjustment (IPWRA) technique",
    "authors": "Charles Natuhamya, Edson Mwebesa, Nazarius Mbona Tumwesigye, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0320893",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320893",
    "content": "Malaria still remains a global health issue. In response, the World Health Organisation has continuously recommended the use of Sulfadoxine-Pyrimethamine (SP) for Intermittent Preventive Treatment of Malaria in Pregnancy (IPTp) as a malaria preventive measure for the mother and fetus, which has been implemented by the Ugandan government. In collaboration with partners, the government has created awareness of using SP for IPTp (SP-IPTp) among women mainly through media. Studies have investigated the effect of a woman’s education attainment on SP-IPTp. However, the effect of knowledge of SP as prophylaxis for malaria on SP-IPTp has not been studied. Notably, education does not necessarily have an effect on knowledge of SP for malaria prevention, and knowledge of SP as prophylaxis may not result in its significant uptake for IPTp. The purpose of this study, therefore, was to ensure baseline covariate balance and determine the effect of knowledge of SP as preventive chemotherapy on its uptake for IPTp.\n\nThe study utilised the Ugandan Malaria Indicator Survey dataset of 2018–19. Women aged 15–49 years who indicated their uptake status of SP during their last pregnancy formed the sample of this study. The inverse Probability Weighted Regression Adjustment technique was applied to assess the study objective.\n\nThe findings revealed a positive and significant effect of knowledge of SP as malaria prophylaxis on its uptake for IPTp (Average Treatment Effect of the Treated or ATET =  0.163; 95% CI =  0.138–0.188).\n\nEnsuring covariate balance while applying IPWRA resulted in more precise estimates of treatment effects. Programmes and policies that create awareness of using SP as malaria prophylaxis may serve as effective interventions towards SP-IPTp in Uganda.\n\nCitation:Natuhamya C, Mwebesa E, Tumwesigye NM (2025) Effect of knowledge of sulfadoxine-pyrimethamine (SP) as prophylaxis for malaria on its uptake for intermittent preventive treatment of malaria in pregnancy (IPTp): Application of inverse probability weighted regression adjustment (IPWRA) technique. PLoS ONE 20(4):\n           e0320893.\n        \n        https://doi.org/10.1371/journal.pone.0320893\n\nEditor:José Luiz Fernandes Vieira, Para Federal University, BRAZIL\n\nReceived:January 13, 2024;Accepted:February 25, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Natuhamya et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The datasets analyzed during the current study are publicly available in the Demographic Health Survey repository,https://dhsprogram.com/data/dataset/Uganda_MIS_2018.cfm.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAbbreviations:ATET,\n            average treatment effect on the treated; EA,\n            enumeration area; IPTp,\n            intermittent preventive treatment of malaria in pregnancy; IPW,\n            inverse probability weighting; IPWRA,\n            inverse probability weighted regression adjustment; ITN,\n            insecticide-treated net; MIS,\n            malaria indicator survey; NPHC,\n            National Population and Housing Census; POM,\n            predicted outcomes mean; RCT,\n            randomized controlled trial; SMS,\n            short message service; SP,\n            sulfadoxine-pyrimethamine; SP-IPTp,\n            sulfadoxine-pyrimethamine for intermittent preventive treatment of malaria in pregnancy; TX,\n            Texas; WHO,\n            World Health Organization.\n\nMalaria, caused by the mosquito-transmitted parasite Plasmodium falciparum, is globally a major cause of mortality and morbidity every year [1] and a serious illness [2] that significantly varies at both individual and area levels [3]. The morbidity and mortality caused by malaria are continually increasing [4]. Pregnant women who are uniquely susceptible to malaria infection [5] form part of the disadvantaged groups of individuals besides children, with the highest morbidity and mortality [6], and malaria in pregnancy is associated with a high economic burden on households and the health system [7].\n\nThe World Health Organization (WHO) strongly recommended the use of SP-IPTp in areas of moderate to high Plasmodium falciparum malaria transmission like Uganda for all pregnant women irrespective of the number of pregnancies [8] which in response, has been implemented by the Ugandan government [9]. SP is an affordable IPTp option among pregnant women as it is widely available [10] and its benefits for IPTp in malaria-endemic areas of Africa have been well documented [11]. Besides being prophylaxis for malaria, among other benefits of SP-IPTp is that its uptake in higher doses may lead to delivery at term and normal birth weight babies [12]. In Africa, however, average knowledge of SP-IPTp exists among majority of the mothers [13]. In addition, data from 33 countries in the WHO African region showed that only 35% of pregnant women had received the recommended doses of SP-IPTp [8] while in Uganda, still less than half of the women take the recommended dosage [14].\n\nTo assess the study objective, IPWRA was applied. Unlike other methods that control for confounding like multivariable regression, IPWRA is justified in case of several confounders or a small number of events. It also retains most individuals in the analysis that otherwise would have been dropped if propensity score matching was applied, resulting in an increased effective sample size [15]. Inverse Probability Weighting (IPW) is useful for adjusting for bias due to confounding or selection in observational studies by weighting [16]. In IPWRA, a logistic regression model is applied to estimate the probability of exposure, and the predicted probability is used for weighting in the subsequent analyses. The inclusion of weights in the analysis achieves covariate balance, a fundamental concept in Randomized Controlled Trials (RCTs) upon which precise causal evidence is based.\n\nAlthough the use of the technique is rapidly increasing in literature, several published studies have not considered the vital step of assessing the comparability of the treated and control groups in the weighted sample [17]. This study addressed this omission by assessing the balance of baseline covariates between the treated group (women knowledgeable of SP) and the control group (women without knowledge of SP) in the sample weighted by the inverse probability of treatment.\n\nThough some studies have investigated the association of women’s education attainment with SP-IPTp [17,18], they haven’t determined the influence of knowledge of SP on its uptake for IPTp. Since formal education does not necessarily have an effect on knowledge of SP-IPTp [13], it is critical to ascertain the effect of knowledge of SP on SP-IPTp. Hence this study aimed to assess the balance of baseline covariates between women knowledgeable about SP (treated group) and those without such knowledge (control group) using inverse probability of treatment weighting and to determine the effect of SP knowledge on its uptake for IPTp.\n\nThis study utilized secondary data from the Ugandan Malaria Indicator Survey (MIS) of 2018–19, which was the most recent Ugandan MIS at the time of this study. The MIS was based on a two-stage cluster and stratified sampling technique where, at the first sampling stage, a total of 320 clusters were selected with probability proportional to size from the enumeration areas (EAs) covered in the 2014 National Population and Housing Census (NPHC) and 28 households were systematically selected from each EA at the second sampling stage, resulting into a total sample size of 8,878 households [9]. The MIS collected information on vector control interventions such as mosquito nets, indoor residual spraying of insecticides, intermittent preventive treatment of malaria in pregnant women, and malaria knowledge, behaviour, and practices, among others. Women aged 15 to 49 years who were either permanent residents of the selected households or visitors that stayed in the household the night preceding the survey were eligible to be interviewed [9]. The study population consisted of 4,718 women aged 15 to 49 years who indicated their uptake status of SP during their last pregnancy.\n\nUptake of SP-IPTp was the dependent variable for this study, and it was measured during the last Ugandan MIS by asking women whether they had taken any dose of SP/Fansidar for malaria prevention during pregnancy. Women who disclosed to have done so were categorized as SP-IPTp users and coded as 1 while their counterparts were categorized otherwise and coded as 0.\n\nThe main independent variable was knowledge of SP as prophylaxis for malaria, the treatment variable in this study upon which treatment effects are based. During the last Ugandan MIS, knowledge of SP was measured by asking women whether they were aware of SP/Fansidar as malaria preventive medicine during pregnancy. Responses to this were recorded as No (coded 0) and Yes (coded 1). The outcome model included; education level, number of antenatal care visits, malaria messages, and type of place of residence while the treatment model included variables in the outcome model in addition to wealth index and age group, but excluded the number of antenatal care visits and type of place of residence for correct specification of the model.\n\nTo control for variability among variables, the household’s wealth index was re-categorized; ‘poorer’ and ‘poorest’ were grouped as low, ‘richer’ and ‘richest’ as high while ‘middle’ was maintained. For education level, ‘secondary’ and ‘higher’ were combined into secondary or higher while the rest were maintained. For age group, the four highest 5-year age groups were combined into 35 and above, and the rest were maintained. The ‘number of antenatal care visits’ was grouped into less than 4 and 4 or more visits as previously recommended [19].\n\nAll statistical analyses were conducted in Stata 15.0 (StataCorp, College Station, TX). Both the treatment and outcome models were first specified before conducting inverse probability-weighted regression adjustments. In the process of model specifications, bivariate analyses were conducted, and later multivariable models fitted on the outcome variables. The backward-step elimination criteria were used while selecting variables for the final outcome and treatment multivariable models.\n\nThe author was granted permission to use the datasets for the aim of this study. Upon request for the permission, the data were made available for download and use for free. In addition, the 2018–19 Ugandan MIS had received approval from the Uganda National Council for Science and Technology (UNCST), the Ethics Committee of the School of Medicine Research and Ethics Committee (SOMREC) of the Makerere University as well as the institutional review board of the ICF.\n\nRCTs are necessary to establish the highest causal evidence. Through randomization, observed and unobserved participants’ characteristics are typically balanced across groups. But because of some of their limitations like being costly and time-consuming, and ethical limitations, they are rarely carried out. IPWRA is an adjustment technique in observational research that adjusts for baseline characteristics imbalances between treated and non-treated groups [15]. The technique uses propensity score, a conditional probability to a particular treatment vector of baseline individual’s characteristics [20]. Propensity scores can be applied in observational studies in a way analogous to randomized experimental studies [21]. Having carefully considered covariates to be included in the propensity score model, and the appropriate treatment of any extreme weights, IPWRA offers a fairly straightforward analysis approach in observational studies that is analogous to Randomized Controlled Trials (RCTs) [15]. In this study, ATET of knowledge of SP on its use for IPTp was estimated.\n\nATET was computed as:\n\nPredicted outcomes mean (POM) for treatment levelwas calculated as:\n\nEach individual’s potential outcomes areandwhere,is the outcome that would be obtained ifis not knowledgeable of SP for IPTp (not treated), andis the outcome that would be obtained ifis knowledgeable of the same (treated).andare realizations of the random variablesandThe unobservable individual-level treatment effect is,denotes a random treatment,denotes the treatment received by individual,is the treatment level, andis the control level.\n\nCovariate balance is the degree to which the distribution of covariates is similar across levels of the treatment which is the benefit of randomization in RCTs. While matching, covariate balance was useful for assessing the quality of resulting matches and providing evidence that the estimated treatment effect was close to the true effect.\n\nStandardized differences assessed covariate balance in measured baseline covariates between treated and control subjects in the sample that was weighted using inverse probability of treatment [17]. It was expected that baseline covariates in the treatment model would be balanced between the treated and untreated groups [22]. Balance across covariates was numerically checked using standardized differences (Tables 1and2) and a standardized difference value greater than 0.1 was considered as a sign of imbalance [23]. The standardized difference,was computed as [24]:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.t002\n\n\n\nWhereanddenote the prevalence of dichotomous variables in the treated (women knowledgeable about SP) and control (women not knowledgeable about SP) group, respectively.\n\nThis is the ratio of the variance of a covariate in one treatment group to the variance of the same covariate in the other group. Covariate balance was also demonstrated by the variance ratio where a good matching procedure reduced bias by increasing the balance and decreasing the variance [25]. Hence, a variance ratio value close to 1 was considered to demonstrate a good matching [22], indicating that the variances of the groups were similar. The variance ratio,was computed as:\n\nWhereandrepresent the variance of dichotomous variables in the treated and control groups, respectively.\n\nThe balance of covariates was further graphically presented using Kernel density plots with Epanechnikov Kernel function. The over-identification test was conducted as the overall test for balance based on the hypothesis that; the covariates were balanced. Treatment effects were therefore considered accurate if the null hypothesis of the over-identification test was not rejected.\n\nThis section presents selected characteristics of women aged 15 to 49 years and the treatment effects of knowledge of SP as malaria preventive medicine on its uptake for IPTp.\n\nMost women were young; aged between 15 and 24 years 1,577 (33.5%), had attained utmost primary level of education 2,673 (56.7%), had visited health facilities for antenatal care at least 4 times 2,757 (58.4%), had not seen/heard malaria messages 2,804 (59.4%) and were not or unsure of being pregnant by the time of the survey 4,246 (90.0%). Most of these women dwelled in households with low wealth index (poor and poorer) 2,643 (56.0%), resided in rural areas 3,401 (72.1%), and were from the northern region 1,663 (35.3%). The rest of the results are presented inTable 3.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.t003\n\nTable 1indicates a significant balance between the treated and control observations after weighting as opposed to before weighting. The weighted standardized differences values across the covariates were less than 0.1 indicating balance in the covariates after matching (seeTable 2). After weighting, the variance ratio values of all covariates were approximately 1, which is also an indication of covariate balance (Table 2).\n\nIn addition to the standardized differences and variance ratio, the Kernel density graphs evaluating covariate balance in the treatment model among women who were knowledgeable about SP as malaria preventive medicine and those who were not knowledgeable of the same show similar distributions after weighting. This indicates a balance among covariates (seeFigs 1–4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.g004\n\nResults from the treatment model show that the probability of using SP for IPTp was 16% (ATET =  0.163; 95% CI =  0.138–0.188) higher among women who were knowledgeable about SP as malaria prophylaxis compared to 79% (POM =  0.794; 95% CI =  0.770–0.817) if none of these mothers were knowledgeable about the same. This indicates women’s awareness of SP as prophylaxis for malaria increases the likelihood of using it for IPTp by 16% compared to when women are unaware of it.\n\nFurther, after converting ATET as a percentage, results inTable 4indicate that the probability of using SP for IPTp increased by an estimated 21% (ATET =  0.205; 955 CI =  0.168–0.242) when every mother was knowledgeable about SP as malaria prophylaxis relative to the case when no mothers was knowledgeable of the same.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320893.t004\n\nResults from the over-identification test inTable 4indicate that the null hypothesis was not rejected. This showed that the treatment model balanced the covariates, proving accuracy of the treatment effects.\n\nThe study ensured covariate balance while applying IPWRA to assess the effect of knowledge of SP on SP-IPTp among pregnant women. The study utilised data from a nationally representative sample to make inferences about the Ugandan population.\n\nResults from this study indicate relatively small standard errors and different parameter estimates in a model devoid of weighting (with unbalanced covariates) compared to one with balanced covariates. These findings are consistent with previous findings where covariate imbalance resulted in parameter bias and small standard error bias [26].\n\nEven in RCTs, it is difficult to adjust for all prognostic covariates at the design level since some of them may be unknown or unmeasurable [27]. This study adds to the existing literature by demonstrating the importance of adjusting for covariate balance during analysis. Previous findings [28] indicate that properly adjusting for covariate imbalance during analysis annuls the undesirable effect of imbalance. This shows that even though observational studies suffer from drawbacks that experimental studies address during the design stage, ensuring covariate balance contributes to unbiased estimates in observational studies which is useful for estimating results from studies based on experimental designs. Hence, leveraging the baseline information to achieve balanced covariates during analysis [29] can significantly increase the study power [30].\n\nThis study found that women’s awareness of SP as prophylaxis for malaria increases the likelihood of using it for IPTp by 16% compared to when women are unaware of it. Although a previous study demonstrated that knowledge about malaria preventive measures did not essentially lead to enhanced malaria prevention practices [31], a recent study found that enhanced women’s knowledge of such measures was significantly associated with their use [32]. Relatedly, the likelihood of using antimalarial drugs by pregnant women was lower among those who did not receive malaria knowledge on the radio compared with those who did [33].\n\nSince mothers’ level of formal education is not necessarily associated with knowledge and use of SP-IPTp [13], targeted educational programs to enhance attitudes and practices regarding malaria control [31] may serve as a better alternative because it was recently found out that although mothers had sufficient knowledge on malaria preventive methods, most of them were adamant in using them [34]. In addition, sensitization targeted towards the use of known preventive measures should be intensified [34] as well as rigorous behavioural communication intervention to improve the knowledge of malaria regarding malaria prevention measures [35] through proper community channels [36], to bridge the existing knowledge gap.\n\nOther studies indicated enhanced use of malaria prevention methods as a result of malaria knowledge through messaging for example, messages to the public about insecticide-treated nets (ITNs) were very useful in increasing the use of the mosquito nets [37], mobile phone short message service (SMS) was effective in malaria control [38], strengthening topic-specific malaria messages was vital for effective malaria communication [39], and utilization of the two peak hours for broadcasting malaria radio interventions was helpful in practicing malaria prevention methods [40].\n\nHowever, it is worth noting that IPTW does not control for unmeasured or unknown confounding. Hence in case of unmeasured confounding, this may still impact the validity of the effects of knowledge of SP as preventive chemotherapy on uptake of IPTp in this study.\n\nThe strength of this study was the national representativeness of the survey data. The study limitations included; the possibility of recall bias since information was purely based on self-report by the survey respondents. However, this was minimal since most responses were only required about events from the most recent past. Also, some variables deemed important may not have been collected however, the variables available in these data sufficiently addressed the study objective.\n\nEnsuring covariate balance while applying IPWRA resulted in unbiased estimates of treatment effects. Hence malaria researchers can use the technique to estimate causal parameters in settings where RCTs are not feasible. The results from this study indicate a significant and positive effect of knowledge of SP as preventive chemotherapy on its uptake for Intermittent Preventive Treatment of Malaria in Pregnancy among mothers in Uganda. Programmes and policies that create awareness of the use of SP as malaria preventive medicine may serve as effective interventions towards its use in Uganda for malaria prevention and control. Identifying the most effective channels for disseminating knowledge of SP may contribute to closing the knowledge gap among pregnant women.",
    "category": "education"
  },
  {
    "title": "Assessing factors that influence graduate student burnout in health professions education and identifying recommendations to support their well-being",
    "authors": "Jacqueline M. Zeeman, Emili B. Anderson, Isabel C. Matt, Michael B. Jarstfer, Suzanne C. Harris, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0319857",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319857",
    "content": "While well-being has become increasingly important in graduate education, limited information exists regarding factors contributing towards burnout and well-being in Pharmaceutical Sciences Doctor of Philosophy (PhD) students. This exploratory story aimed to identify factors influencing well-being and burnout in these students as well as identify recommendations to support their well-being.\n\nA two-stage sampling approach was used: (1) purpose sample of Pharmaceutical Sciences PhD students at a public university were invited to participate in a semi-structured focus group or interview to explore factors contributing to PhD student burnout and well-being as well as solicit suggestions for strategies to improve their well-being; (2) Stratified sampling was used to assign participants into focus groups by All-But-Dissertation (ABD) status (i.e., pre-ABD candidates, ABD candidates) to explore experiences that may be unique to these students. Inductive coding and thematic analysis were used.\n\nSix PhD candidates participated in three sessions: three Pre-ABD candidates in one focus group, two ABD candidates in one focus group, and one ABD candidate in one interview. Participants identified relationships and aspects of curriculum and research (i.e., program design, completing milestones) as factors influencing their well-being. Factors influencing participants’ burnout included curriculum and research stressors (e.g., cumulative exams, competing academic and research responsibilities), working overtime, unrealistic expectations, lack of work life balance, and financial burden. While relationships and curriculum and research were factors in both subgroups, unique aspects within these themes emerged between Pre-ABD and ABD participants. Participant recommendations to foster PhD student well-being included improving financial support and encouraging PhD connections.\n\nThis study advances knowledge on factors influencing PhD student well-being and burnout, providing suggestions to improve their well-being. Findings highlight curriculum and research factors as well as relationship dynamics influence graduate student burnout and well-being. Findings contribute to broader conversations aimed to support student wellness and reduce burnout in higher education, informing the academy of focused areas and strategies to improve PhD student well-being.\n\nCitation:Zeeman JM, Anderson EB, Matt IC, Jarstfer MB, Harris SC (2025) Assessing factors that influence graduate student burnout in health professions education and identifying recommendations to support their well-being. PLoS ONE 20(4):\n           e0319857.\n        \n        https://doi.org/10.1371/journal.pone.0319857\n\nEditor:Supaprawat Siripipatthanakul,, Bangkok Thonburi University: Bangkokthonburi University, THAILAND\n\nReceived:August 8, 2024;Accepted:February 11, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Zeeman et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the article and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nWhile well-being initiatives have become increasingly important in graduate education to prevent burnout, research on specific factors influencing well-being in Doctor of Philosophy (PhD) students is limited. The Substance Abuse and Mental Health Services Administration (SAMHSA) defines well-being it in eight dimensions: emotional, spiritual, intellectual, physical, environmental, financial, occupational, and social [1]. Well-being encompasses many areas of our lives that are often interconnected; however, low levels of well-being may correlate with increased burnout [2]. Burnout is defined as a syndrome that involves prolonged response to chronic stressors and includes three dimensions [3,4]. The consequences of burnout have been associated with negative personal well-being outcomes as well as negative social and organizational outcomes, including dysfunctional relationships, worsened health, increased substance abuse, higher incidence of depression/suicidal ideation, increased error, and higher turnover rates [4–5].\n\nOriginally, burnout was classified as an occupational phenomenon that was most prevalent in careers with intense people interactions, such as healthcare [6]. However, burnout has also been linked to academic training. The risk of burnout within the academic setting has been accompanied by a growing cry from students struggling with mental health concerns. Specifically, PhD students experience higher levels of anxiety, sleep disturbances, depressive symptoms, burnout, and a lower level of well-being compared with students who do not pursue post-graduate education [7,8]. This interconnection is important as burnout can be a cause of a mental health disorder, but mental health conditions can also cause burnout [9]. One study in graduate students found they were six times more likely to experience anxiety and depression compared to the general population [10]. In 2015, the University of Arizona reported that a majority of doctoral students’ experience “more than average stress” or “tremendous stress” [11]. The COVID-19 pandemic has only further exacerbated mental health concerns for this population and research on the well-being of graduate students has greatly increased over recent years potentially due to the pandemic and remote learning [12–14]. This evidence supports a call to action for more research to understand the causes of and to develop strategies and resources to decrease risks of burnout and improve the well-being of graduate students.\n\nDespite literature indicating high levels of stress, mental health, and burnout concerns in PhD students, only more recently has research on factors that affect graduate students’ well-being been reported [15–18]. Surveys in PhD students in medicine and biomedical sciences have identified lack of sleep and basic psychological needs, having at least one current psychiatric disorder, mental health impairment, thoughts of dropping out, challenges in research, pressure to publish, perceived challenges with employment opportunities, limitations in resources, lack of value and poor relationships as stressors or predicters for burnout [8,19,20]. However, resources, supervision, feelings of autonomy and good relationships were seen as factors that influenced resiliency [8,19,20]. One longitudinal survey study indicated that effective mentoring, confidence in the selection of their PhD program, academic development, and sense of belonging were associated with higher mental well-being [21]. Further research confirmed sleep quality and duration, as well as supervisor and peer support, to be positively associated with well-being in graduate students [22,23]. El-Ghoroury et al. [24] found that stressors in psychology graduate students included academic responsibilities, finances/debt, anxiety, and poor work/school-life balance. Whereas coping strategies that improve wellness included support from friends, family, classmates, regular exercise, and hobbies [24]. Barriers to practicing well-being strategies include lack of time and cost [24].\n\nWhile there has been a growth of studies in graduate student well-being broadly, the research on factors that affect well-being and the influence of unique stressors in graduate training in health professions programs are primarily survey-based. While survey strategies are beneficial for exploring larger audiences, they are limited in their ability to explore detailed subtleties and nuances that provide important context. This is a distinctive population that ultimately represents the future of academia and industry in the United States of America (USA) and beyond; thus, supporting the well-being of this group is warranted and qualitative methods would allow investigators to derive salient themes to identify unique stressors doctoral students face [8]. The research objective of this qualitative study is to address this literature gap by exploring factors that positively and negatively influence well-being and identify recommendations for improving the well-being of Pharmaceutical Science Doctor of Philosophy (PhD) students. Specifically, this study sought to answer the following research questions: (1) what factors positively affect PhD student well-being, (2) what factors negatively affect PhD student well-being and/or cause burnout, (3) what are recommended strategies to improve PhD student well-being, and (4) what other thoughts or suggestions are important to this study? For the purposes of this study, burnout is characterized by prolonged or repeated periods of stress, where a person begins to feel mentally exhausted by their tasks [25]; well-being is characterized as a state of being happy, healthy, and prosperous [26]; and recommended strategies are ideas for action solicited from participants.\n\nA two-stage sampling approach was used in this exploratory study: (1) purpose sampling of a public university in the USA (i.e., UNC Eshelman School of Pharmacy) that had previously conducted a quantitative well-being baseline assessment. Results from the baseline assessment indicated that nearly half of the School community was at risk for decreased well-being and burnout – findings similar to many other institutions and disciplines [27–29]. PhD students from this purpose sample were recruited via email from September 19, 2022 to September 30, 2022 to participate in a 60-minute focus group in Fall 2022. Participants provided electronic informed consent through QualtricsXM prior to completing the focus groups. (2) Stratified sampling of PhD students was used to assign participants into focus groups stratified by dissertation status (i.e., All-but-Dissertation (ABD), pre-ABD) to explore experiences that may be similar or unique within these groups. Participants self-identified their status (i.e., ABD, pre-ABD) during focus group signups. Focus groups were led by a doctoral student from a different degree program who was trained in focus group methodology to reduce relational bias (e.g., student-faculty relationship, peer relationship) and to promote a free-exchange of ideas among participants about the PhD student experience.\n\nA semi-structured focus group script was reviewed by faculty and students for refinement to ensure validity and reliability prior to implementation (S1 Appendix). The semi-structured approach allowed for real-time clarification of responses and probing to further understand factors influencing PhD student burnout and well-being, as well as recommendations for strategies to improve PhD student well-being [8,19–24]. Upon completion of focus groups, participants had the opportunity to provide additional thoughts and feedback through an optional, anonymous single-item post-focus group survey. Focus groups were audio recorded and transcribed via Zoom (Version 5.3.11), and transcripts were reviewed for accuracy and de-identified by non-faculty research team members prior to analysis. Transcripts were analyzed using inductive coding. Initial coding and codebook generation was completed by one author. A second researcher coded each transcript independently using the developed codebook. Coded transcripts were compiled and analyzed for agreement. Researchers reviewed all applied codes, discussing any new emerging codes identified and any discrepancies until consensus was reached and data saturation was achieved. Inter-coder agreement was above the accepted 80% threshold for qualitative data [30]. This process ensured validity of code interpretation and richer data analysis. Teams Microsoft Excel (Version 1.6.00.4464) was used to conduct thematic analyses. Theme generation involved grouping codes into overarching patterns or ideas, with subthemes developed for further categorization. Thematic analysis supported relative frequency analysis of themes and subthemes without direct quantification [31]. Ethical consideration by The University of North Carolina at Chapel Hill Institutional Review Board deemed this study exempt on 7 July 2022. (IRB # 21-1629, IRB approval letter is attached). The IRB application specifies no identifiable information (e.g., gender, age, race/ethnicity) will be linked with participant responses. Exploring demographic identifiers, such as gender and age, as factors affecting well-being or burnout was beyond the scope of this study.\n\nSix PhD candidates participated in three sessions: three Pre-ABD candidates in one focus group (S2 File), two ABD candidates in one focus group (S3 File), and one ABD candidate in one interview (S4 File). There were no responses submitted to the optional, anonymous post-focus group survey. Participants’ duration in the program was well distributed as evidenced by anticipated graduation year: 33.3% expected to graduate in 2023 and 16.7% in each subsequent year through 2027 (i.e., 16.7% in 2024, 16.7% in 2025, etc.) Of the participants, 83.3% identified as White or Caucasian and the majority (83.3%) identified as female.\n\nParticipants across both Pre-ABD and ABD groups expressed relationships and elements of the curriculum and research as the most prominent factors influencing their well-being (Table 1). Specifically, both groups identified peer relationships as positively influencing their well-being. One participant shared, “not only relationships with other students in [their department] but also the PhD Program more broadly are important for establishing a sense of well-being.”(ABD participant A2.2, 10/12/22)When another participant expressed stress associated with the program, they shared “I could only imagine how even more jarring it was for people who didn’t talk to senior students.”(pre-ABD participant P1.3, 10/13/22)Participants also discussed having a support dissertation committee as positively influencing their well-being: “My dissertation committee is very supportive, very polite, and always constructive with their feedback, even if they have things they want me to improve. I really like how they’re a source of knowledge and expertise to help guide you. They also help rein it in – like, whoa! This is gonna take way too much time. Or have you thought this? For me, it has been very helpful.”(ABD participant A1.1, 10/6/22).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319857.t001\n\nIn addition to relationships, themes regarding aspects of curriculum or research in the PhD program were identified as positively influencing PhD well-being for all participants, although unique elements of the curriculum and research surfaced as prominent themes for each subgroup (Table 1). The first-year program design, specifically the balance and pacing of coursework and research experience, was an aspect of the curriculum and research theme that influenced pre-ABD student well-being, with one participant sharing: “I do think the first-year experience is well-run. It was a good balance between the course work and the research work and everything. I definitely appreciated that.”(pre-ABD participant P1.1, 10/13/22).ABD participants discussed how completing tasks or milestones were elements in their curriculum and research that influenced their well-being, along with a degree of certainty with reaching ABD status: “I feel like I have a path, a plan. I’ve got all my specific aims written out. My dissertation committee approved them. I just need to do it. I feel worlds better. I was so stressed going into [preliminary exams] and it’s not that I don’t feel stress now, but I have more clarity.”(ABD participant A1.1, 10/6/22).\n\nAdditionally, ABD students emphasized the impact of peers and the concept of a shared understanding and support from others who understand the PhD experience as factors positively influencing their well-being (Table 1). One ABD participant shared that “peers are people that understand the most because they’re most likely experiencing the same stressors…so we can empathize with each other and share emotional and mental support for overcoming challenges.”(ABD participant A2.2, 10/12/22).Meaningful work was also a theme commonly expressed among ABD participants, with participants emphasizing specifically the impact of positive feedback: “words of affirmation from a PI or lab mate do go a really long way.”(ABD participant A1.1, 10/6/22).\n\nWhile elements of curriculum, research, and relationships were noted as factors influencing PhD student well-being, elements across these same domains (i.e., curriculum and research, relationships) were identified as factors influencing PhD student burnout (Table 2). Specific to curriculum and research stressors, participants discussed multiple elements – including balancing curriculum and research responsibilities, cumulative exams, and unrealistic expectations – as specific factors that contributed towards their burnout. One participant shared, “next thing you know you’re starting your first project, taking your [cumulative exams], preparing for your oral [defense]. You really just take off suddenly, and I feel like I wasn’t as prepared as I expected to be.”(pre-ABD participant P1.3, 10/13/22).Participants also expressed how the workload often resulted in a need to work more than 40 hours/week. One participant shared: “[students] feel like they have to work significant overtime, or they have to work through their vacation. No one says you have to do this but that’s kind of the unspoken expectation.”(ABD participant A1.1, 10/6/22).Participants also discussed how unrealistic expectations within the curriculum and research contributed towards this workload stressor with one participant sharing: “in my first year, no one expected me to really accomplish anything in research because I’m only basically half-time since classes take up the rest of the time. So it’s very bizarre that once you get to [cumulative exams], they’re like ‘oh, now you have to do all of it.”(pre-ABD participant P1.1, 10/13/22).Further, inconsistency between mentors or PI expectations was an additional element within curriculum and research stressors that influenced their burnout. One participant elaborated, “there are different expectations [between mentors] and I don’t think that is addressed. For example, there are pretty much no rules [for taking time off]. So, you’re really at the mercy of your PI and how nice they’re feeling or how hard they want to make your life. That’s something I found frustrating.”(pre-ABD participant P1.1, 10/13/22).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319857.t002\n\nIn addition to curriculum and research factors, participants across both groups discussed how having a lack of work life balance and financial burden contributed towards their burnout (Table 2). One participant stated, “if my [experiment] doesn’t work, I feel it and it keeps me up at night. Even when I leave the school, I’m still thinking about it and it’s hard to stop.”(pre-ABD participant P1.2, 10/13/22).Another participant reflected on the financial burden, sharing: “even though we’ve seen a small raise [it is] so far below the amount that would be necessary to provide the same, albeit low, quality life that was provided a couple of years ago in this program [before inflation]. This is something that is causing incredible financial stress to any student who does not have a partner who is making more than them.”(ABD participant A2.1, 10/12/22).The stress of a financial burden was discussed further and its significance noted: “it affected people to the point of increasing their willingness to drop out of the program with a master’s or nothing.”(ABD participant A2.1, 10/12/22).\n\nIn addition to the factors mentioned above, Pre-ABD students noted limited and/or expensive parking as well as stipend inequity between departments as prominent factors affecting their burnout (Table 2). One Pre-ABD student noted that “the student parking pass is the lottery…which is outrageously expensive... then we have to pay an additional fee to get a parking pass for the summer.”(pre-ABD participant P1.3, 10/13/22).The Pre-ABD student further explained that the alternative, the park-n-ride, is unrealistic because “you have to plan for two hours for transfers and [travel time]” which is a “big frustration and financial impact”(pre-ABD participant P1.3, 10/13/22).Stipend inequity between departments was also specifically noted by Pre-ABD participants, with one explaining: “the stipend is not even the same level as other students in our labs, which is very strange to me. If I had gone through [a different program] and joined the same exact lab, I’d be paid a lot more.”(pre-ABD participant P1.1, 10/13/22).\n\nIn contrast to the Pre-ABD experience, ABD students emphasized uncertainties in program requirements and expectations around the timeline for program completion as specific elements of curriculum and research that contributed towards their burnout (Table 2). One ABD participant shared, “A big one for me is the lack of transparency and confusion on whether or not you're on the right path or if you were meeting the markers you need to meet…it has a really big negative impact on my well-being.”(ABD participant A1.1, 10/6/22).This uncertainty in program requirements, including research progress, translates into feeling burnout given the degree program duration: “You’re constantly worried about [if you’re doing enough because] spending time on one is taking away from time on the other”(ABD participant A1.1, 10/6/22).and another sharing “It always feels like you're gonna pay for your time somehow. Because we have requirements to graduate, going slower is maybe better for your day-to-day work-life balance. But then, if you're here for another year or two, that might not be great for your financial well-being, and that can be a stressor that will get you on the other side. So in some ways it can feel like a zero sum game.”(ABD participant A2.1, 10/12/22).Additionally, challenges with the supervisor/PI relationship, poor communication with their PI, and others lack of understanding of student stress and/or dismissing the student perspective were relational elements that contributed towards ABD student burnout. One participant described this experience “as a graduate student, you’re immediately shot down, despite multiple students independently having this experience…it makes you feel like you’re not taken seriously and that your experiences aren’t valued”.(ABD participant A2.1, 10/12/22).\n\nParticipant recommendations for strategies to promote PhD student well-being centered on three primary themes: curriculum and research, financial support, and supportive relationships (Table 3). More specifically, respecting days off was a consistent theme seen across both groups as was ensuring financial compensation was increased to align with minimum living expenses. One participant shared, “look at the cost of living, and make sure the salary offered is aligned – the current stipend does not meet the cost of living for most students.”(ABD participant A1.1, 10/6/22).Participants also recommended strategies to improve relationships, including creating more opportunities that encourage PhD connections. For example, one participant recommended “encouraging more cohesion across [departments] – I couldn’t name a single student from [a different department than their own] which is a shame since they’re part of an important research pipeline and we should have an understanding of what they do and I’m sure they would love to understand what we do.”(pre-ABD participant P1.3, 10/13/22).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319857.t003\n\nPre-ABD students, in addition to the suggestions above, specifically recommended improving insurance coverage and parking access to help reduce financial burden (Table 3). For example, one participant suggested “adding dental and vision coverage to the health care plan”(pre-ABD participant P1.1, 10/13/22),which was echoed by multiple students, with one emphasizing, “I completely agree with that. As someone who needs glasses…I hope I don’t break them anytime soon, because I definitely can’t do much about it.”(pre-ABD participant P1.3, 10/13/22).Pre-ABD participants also recommended improving parking access as a strategy to reduce the financial burden experienced by PhD students: “have parking available for everyone that’s affordable would help.”(pre-ABD participant P1.2, 10/13/22).\n\nABD participant recommendations emphasized an opportunity to create and implement actionable change, reduce uncertainties and communicate expectations regarding the curriculum and research requirements, and encourage connections within the School community (Table 3). ABD students often recommended a concept deemed actionable change, such as a change that goes beyond providing resources or emails and creates change that gets at the root problem. For example, one ABD participant reflected on mental health resources, specifically a recent death by suicide in the undergraduate student population, sharing: “it was just awful and all I ever heard about it was an email. I think we need to take time to recognize that that’s a sign things are not good.”(ABD participant A1.1, 10/6/22).Reducing uncertainties within the curriculum and research was also recommended by ABD students, specifically, recommending improved communication about curriculum and research requirements. One ABD participant shared: “sometimes I feel like there’s a list of requirements, and someone somewhere has that list, but I don’t have the list, even though I’m the one supposed to be meeting those requirements.”(ABD participant A2.2, 10/12/22).Although peer relationships were identified as a prominent factor improving student well-being, ABD students expressed a desire to also connect with the larger school community. One ABD participant suggested “encouraging connection within the school so that students don’t feel alone because PhD students can feel kind of siloed in what they’re doing and feel disconnected from other students and faculty.”(ABD participant A1.1, 10/6/22).\n\nThis study adds to the growing literature exploring factors that influence well-being of PhD students. This is an understudied population that has been mostly limited to quantitative data collection, with a few survey studies beginning to explore factors influencing burnout in a broader graduate student population. This research aligns with call to actions for institutional approaches to support well-being and facilitate climates where graduate students can thrive in their intellectual and personal growth [32,33]. Through the utilization of semi-structured interviews and focus groups, participants provided rich insights through descriptions of their experiences related to the well-being of PhD students. This discussion aims to synthesize the factors identified through thematic analysis to provide insight into elements of the PhD student experience that influence their well-being, burnout, and/or both, and thus ultimately inform strategies and recommendations to support PhD student well-being. Insights uncovered through this study fills an existing literature gap by expanding on factors that contribute positively and negatively towards PhD student burnout. Findings can inform actionable recommendations to improve the PhD student well-being and reduce factors influencing their burnout.\n\nAcross both Pre-ABD and ABD groups, themes relating to curriculum and research, relationships, and finances were found to positively impact student well-being (Table 1) as well as contribute towards their burnout (Table 2) and thus were a primary focus area of participants’ recommendations (Table 3). Consistent with the results of this study, previous literature has identified academic responsibilities and challenges in researchers as common stressors for PhD students [19,21,24]. However, this study expands upon this, such that themes associated with curriculum and research not only influence burnout (Table 2) but can also positively influence well-being (Table 1).\n\nFurther, while Zhang et al. [21] studied graduate students by class year (i.e., first year, second year, etc.), this study advances prior work by exploring how factors impact PhD students at different stages in their program by dissertation status (i.e., Pre-ABD and ABD). The curriculum and research themes that affected well-being were generally related to the program structure and balance of curriculum and research as they progressed (Table 1). For example, Pre-ABD students noted the structure of the first-year program helped them acclimate to a graduate program, therefore supporting their overall well-being. Furthermore, ABD students shared how progression through the program (e.g., achieving ABD status) provided them greater clarity and confidence, which supported their well-being. However, aspects of the curriculum and research also led to increased levels of burnout (Table 2). Burnout themes relating to balancing curricular and research responsibilities (e.g., cumulative exams and curriculum and research stressors), as well as themes related to individualized experiences within the PhD program, including feelings of uncertainty around program expectations or research progress and working overtime, are consistent with previous studies [19,20,24]. Unique to this study were sentiments of inconsistencies between mentor expectations and how some of aspects of curriculum and research – such as cumulative exams, working overtime, and unrealistic expectations – compounded on each other to influence burnout (Table 2). More research is needed to further explore these emerging themes of positive and negative effects of curriculum, research, and mentorship expectations, and how compounded responsibilities influence burnout in PhD students in health professions programs. Future research should continue to evaluate stressors of PhD students at different stages (e.g., class year, ABD status).\n\nRelationships were also found to influence both well-being (Table 1), burnout (Table 2), and recommendations (Table 3), with unique relationship factors and associated recommendations for well-being emerging in this study that are not reflected in prior studies. Notably, while a positive relationship with a dissertation chair was noted to predict positive well-being in early years of the program [21], this study found a positive relationship between dissertation committees and well-being within ABD students, highlighting the impact of positive relationships from the broader mentorship network (Table 1). Additionally, our study results suggest a connection between relationships and the curriculum and research themes. For example, participants expressed that positive relationships with supervisors, dissertation committees, and peers helped students feel supported through curriculum and research stressors (Table 1). Whereas lack of supporting relationships led to students to feel isolated, dismissed, and uncertain in their research and the curriculum, and thus influenced their burnout (Table 2). In addition to these emerging themes, other findings related to supervisor, peer, and family relationships are consistent with previous literature. Specifically, prior studies [21,23] found that the quality of supervisor support was a significant predictor for PhD student satisfaction, and peer support was also an important predictor for PhD satisfaction [23]. Furthermore, El-Ghoroury et al. [24] found support from friends, family, and classmates were common coping strategies for stress among psychology graduate students. Kusurkar et al. [19] also identified supervision and good relationships as energizers and poor relationships as perceived stressors in PhD work.\n\nFurther emphasizing the impact of positive relationships, our study found that PhD students, specifically ABD students who spend most of their time in their research lab, recommended increasing opportunities to form connections with other PhD students outside of their lab or department, as well as members of the broader school community, to improve their well-being (Table 3). It is important that other programs are aware of the impact of positive relationships on PhD student well-being in order to create more opportunities for networking both within and outside their research teams in order to promote a sense of connection and belonging to the full school community.\n\nAlthough previous literature has identified work-life balance as a predictor for burnout in graduate students, results from this study expands upon this factor to include the connection between supervisor and work-life balance [20,24]. When participants described the impact their supervisor or PI had on their well-being, it was often mentioned in relation to their ability to support work-life balance. Participants shared their well-being was impacted positively when their supervisor promoted work-life balance (Table 1) and negatively when they felt their supervisor did not value it (Table 2). Furthermore, this concept connects to the curriculum and research theme of inconsistencies in mentors’ expectations and working overtime influencing burnout (Table 2). These connections support the Pre-ABD students’ recommendation to respect days off, specifically with University endorsed Well-Being Days (i.e., no classes) (Table 3). The theme of supportive supervisor relationships on improvements in work-life balance (Table 1) is worthy of further exploration across PhD programs at other institutions.\n\nThe financial burden PhD students face was a frequent theme that appeared during focus group discussion relating to burnout (Table 2). This theme is consistent with previous literature that identified finances and debt as a common stressor for PhD students [24,33]. All focus group participants expressed that the current stipend for PhD students was inconsistent with the cost of current living, thus influencing their burnout, and this was especially challenging for students without dual income partners. Improving financial support was a notable recommended strategy to better support PhD student well-being (Table 3). Considering financial stress is one of the strongest correlates with graduate student mental health [33], institutions should critically assess stipend amounts in relation to levels of inflation and PhD student needs. Programs should consider regular reevaluation of the stipend amount to assess if it is a livable wage in the current economic climate.\n\nParticipants also identified a number of recommended strategies to foster PhD well-being, which aligns with national calls to action to promote graduate student well-being through cultural, organizational, and environmental strategies [8,33]. Participants in this study emphasized the importance of relationships for improving student well-being and identified recommended strategies to enhance these relationships (Table 3). Findings suggest institutions should provide opportunities for PhD students to connect with each other, regardless of department or research group. Further, institutions should promote opportunities to build relationships across all communities (i.e., professional students, graduate students, faculty, and staff), such as informal social events [33] that allow community building outside of the academic setting. Other ideas include more formal networking events and opportunities to present research to larger audiences (e.g., PhD students in other departments, professional students, faculty, and staff).\n\nAs curriculum and research themes were found to both increase well-being (Table 1) and influence burnout (Table 2), recommendations to improve the curriculum and research environment were common (Table 3). For example, respecting days-off as a break from the curriculum [33], reducing uncertainties, and communicating expectations [33] were suggested to help improve PhD well-being (Table 3). To help address the recommendations for clarity in expectations, programs could consider focusing energy on creating clear expectations for program requirements and completion. [33] For example, posting expectations on the institution’s website [33] and explicitly reviewing student progress in completing requirements at biannual evaluations with supervisors and reinforcing the graduate student handbook as a guide. However, to reduce uncertainties, ensuring that what is on the website is up to date with current requirements [33].\n\nStrategies that have been implemented through our institution’s leadership or well-being action plans that align with broader calls to action in PhD students [33] and address many of the participants’ recommendations that other programs could adopt include: providing resources to promote and facilitate mental health [33]; hiring an embedded mental health counselor as an unbiased outlet; identifying and promoting alternative, less cost-prohibitive resources available on the School’s well-being website; and implementing a University-wide increase in the minimum PhD student stipend to better match rates of inflation and living expenses [34]. Across the University, Wellness Days [33] have also been established to create opportunities for protected well-being time in the curriculum (e.g., no class), including for PhD programs. For students that are primarily in labs and which University Wellness Days do not apply, the Pharmaceutical Sciences PhD program now includes a newly added vacation policy [33] outlined in the Student Handbook. While these are positive steps to support PhD well-being, more research and exploration is needed to discover the impact of the stipend increase and strategies to better close the gap between the initiative and implementation of Wellness Days for PhD students (e.g., consistency within PIs to uphold protected time).\n\nTo promote connection and build relationships, institutional interventions include: guidance around best practices for the student-advisor relationship [33] outlined in the graduate student Expectations Document; peer-mentors [33] for incoming students and regular wellness and simple social events [33] (e.g., Bagel Mondays) that provide opportunities to leave lab, grab a snack midday and socialize with peers, faculty, and administrators; robust mentor training programs to foster the student-advisor relationship [35]; a pilot “homes’ model across years and sub-disciplines to facilitate a sense of belonging, and support social engagements with a small stipend [33]. These are a select example of strategies that other PhD programs could consider to facilitate mental health access, promote true breaks and work-life balance, cultivate relationships and mentorship, and improve financial support [33,35].\n\nWhile this exploratory study addresses a critical literature gap, it is limited to one institution and future research should explore the PhD student experience at other institutions. Additionally, focus group participation was voluntary, introducing the possibility of participant bias. To reduce relational bias introduced by a faculty or peer focus group moderator, a student researcher in a different doctoral program moderated the PhD student focus groups to help participants feel comfortable sharing their honest experiences and recommendations without concern or fear of repercussions from individuals who may be viewed as authoritative (e.g., faculty, administration). Lastly, the focus groups were conducted during a two-week period in October, which may not be fully representative of the PhD student experience during other times of the year. Future opportunities exist to conduct longitudinal studies of this population with future research. Additionally, the impacts of COVID-19 on participant well-being was beyond the scope of this study.\n\nThis study advances knowledge on factors that influence PhD student burnout and well-being as well as provides suggested recommendations for strategies to improve their well-being. Participants identified several factors that contribute to PhD student burnout – including curriculum and research stressors, work-life balance, and financial burden – and described positive relationships and aspects of the curriculum and research program structure as factors contributing towards PhD student well-being. Participant recommendations focused on reducing uncertainties and providing clarity on curriculum and research requirements, enhancing financial support including increasing stipend/compensation, and encouraging relational connections with other students and faculty as specific strategies to promote PhD student well-being. This study provides critical insight into factors that influence PhD student well-being and burnout and may inform other programs and guide graduate education more broadly on strategies to support PhD student well-being. Further research should explore how the identified factors influence PhD student burnout and well-being at other programs.\n\nhttps://doi.org/10.1371/journal.pone.0319857.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0319857.s002\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0319857.s003\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0319857.s004\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0319857.s005\n\n(XLSX)\n\nThe authors acknowledge Sara Wasserman, PhD candidate, Robert Hubal, PhD and members of the Research and Scholarship in Pharmacy (RASP) Program at the UNC Eshelman School of Pharmacy for feedback and support throughout this project.",
    "category": "education"
  },
  {
    "title": "Unveiling perceptions on academic leadership effectiveness: PLS-SEM, FSQCA, and NCA approaches",
    "authors": "S. M. Mahbubur Rahman, Ummah Tafsirun, Md. Faisal-E-Alam, Paulo Ferreira, Luís Loures, Rui Alexandre Castanho, (PLOS)",
    "publish_date": "2025-04-14",
    "doi": "https://doi.org/10.1371/journal.pone.0320723",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320723",
    "content": "Academic leadership plays a critical role in fulfilling higher education institutions’ missions, fostering a competent workforce, and becoming a key driver in unlocking the potential to achieve sustainability goals. Within this context, the leadership effectiveness of academic deans is particularly significant. This study aims to identify the factors influencing the academic leadership effectiveness in public universities in Bangladesh. The study collected data from 318 faculty members of public universities. A combined methodology consisting of Partial Least Squares-Structural Equation Modeling (PLS-SEM), Fuzzy-Set Qualitative Comparative Analysis (fsQCA), and Necessary Condition Analysis (NCA) was utilized to analyze the collected data. The PLS-SEM results indicated that vision and goal setting (VG), management of the unit (MU), interpersonal relationships (IR), communication skills (CS), research/professional endeavors (PE), and quality of education in the unit (QEU) significantly influence deans’ leadership effectiveness. Further, five necessary and six sufficient conditions were discovered by fsQCA results, which also demonstrated the nonlinear and intricate interaction effects of the factors leading to leadership effectiveness (LE). Importantly, NCA findings revealed that all factors are essential for LE and have meaningful and substantial impact. Also, a minimum of 14.78% VG, 20.75% MU, 23.27% IR, 33.96% CS, 16.98% PE, and 10.06% QEU must be met to accomplish an 80% LE. Therefore, the findings provide useful insights for the higher education sector, university top management, potential academic leaders, and relevant stakeholders to improve leadership effectiveness at the tertiary education level. Moreover, this study is the first to explain the effectiveness of deans’ leadership through an expanded methodology that integrates both symmetric and asymmetric methods.\n\nCitation:Rahman SMM, Tafsirun U, Faisal-E-Alam M, Ferreira P, Loures L, Castanho RA (2025) Unveiling perceptions on academic leadership effectiveness: PLS-SEM, FSQCA, and NCA approaches. PLoS ONE 20(4):\n           e0320723.\n        \n        https://doi.org/10.1371/journal.pone.0320723\n\nEditor:Chengliang Wang, East China Normal University, CHINA\n\nReceived:September 11, 2024;Accepted:February 24, 2025;Published:April 14, 2025\n\nCopyright:© 2025 Rahman et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Uploaded assupporting information.\n\nFunding:The authors would like to acknowledge the financial support of the National Funds provided by FCT—Foundation for Science and Technology to VALORIZA—Research Center for Endogenous Resource Valorization (project UIDB/05064/2020).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nIn this contemporary world, leadership at the tertiary education level has assumed a crucial role in advancing the quality of higher education [1]. The overarching goals of higher education institutions—academic excellence, innovation, and positive societal impact—are guided by their leaders [2]. As the diversity of universities continues to rise and the policy reforms in numerous countries reinforce the strategic role of academic leaders, academic leadership is rising rapidly to the forefront of scholarly attention [3]. In recent years, effective academic leadership has become increasingly critical in higher education. This is especially true in developing nations like Bangladesh, where challenges such as resource constraints, global competition, and policy reforms significantly impact institutional success [4].\n\nThe recent World University Rankings 2024, published by Times Higher Education (THE) [5], recognized only four Bangladeshi universities that placed in the 800-1000 category, of which only two are public universities. In terms of Asia rankings for 2024, three public universities in Bangladesh are ranked between 300 and 400. When considering the other emerging SAARC countries, 43 Indian universities and 19 Pakistani universities have secured positions in the 1000 range in this global ranking list. Furthermore, 18 Indian universities and 3 Pakistani universities were ranked in the top 200 in Asia. The disparity in rankings between Bangladeshi universities and their regional counterparts emphasizes the urgent need for strong leadership to improve the country’s educational quality and reputation [6]. Effective academic leadership can ensure academic quality [7]. Research on effective leadership in higher education also shows that leaders and leadership sharpen higher education institutions’ performance, governance, learning, and teaching [8–10].\n\nEarlier research investigated academic leadership effectiveness from multiple viewpoints. Mishra et al. [11] investigated the essential components of academic leadership development and the qualities of effective academic leadership. Yasin et al. [12] examined the expected qualities of an effective academic leader and the perceived effective academic leadership and concluded that an effective academic leader should possess IQ and EQ, visionary power, and the ability to unite their team. Ambag et al. [13] found that academic leaders are transformational and demonstrate strong communication and visioning skills. While academic leadership has been extensively studied, most research has focused on institutions in Western or economically developed nations [14–16].\n\nTo date, research on academic leadership effectiveness in developing nations, particularly in the context of Bangladesh’s public universities, is limited. Few studies have specifically examined the distribution and inequality of gender in academic leadership positions in university settings [17,18]. This study aims to fill this gap by exploring academic leadership effectiveness in Bangladeshi public universities. The main aim of this study is to examine the factors that shape the perceptions of deans’ leadership effectiveness in public universities in Bangladesh. The research question is: What factors contribute to deans’ leadership effectiveness in public universities in Bangladesh?\n\nUndertaking this research provides knowledge that can help policymakers and university leaders develop strategies to enhance academic leadership. Understanding these perceptions is vital for creating and encouraging a productive academic environment. In addition, this research employs a hybrid methodology that has been overlooked in prior research. To the best of the authors’ knowledge, this is the first study to use a hybrid methodology combining PLS-SEM, fsQCA, and NCA in the domain of academic leadership. The remaining sections of the paper are organized as follows: Section 2 provides a literature review to support hypothesis development and presents the conceptual framework. Section 3 explains the study’s methodology. Section 4 shows the results of the PLS-SEM, fsQCA, and NCA. Section 5 discusses the main results and theoretical and managerial implications of the findings. Finally, Section 6 covers the conclusions and limitations of this study, as well as future research scopes.\n\nYukl [19] defines leadership as “the process that involves guiding individual and collective efforts to understand and influence people, helping them recognize what needs to be done and how to achieve shared objectives.” Academic leadership is gaining prominence as universities become increasingly complex. Policy reforms in many countries are also reinforcing the strategic role of university leaders. A challenge in the definition of academic leadership is the recognition of the variations in roles and titles that exist among institutions [20]. According to the literature, academic leaders can assume formal leadership roles, such as directors, supervisors, and deans, or informal roles, such as faculty members [21]. With their own unique challenges, there is a growing recognition of the significance of leadership across all levels of an organization, including deans, department chairs, and curriculum and course directors [3]. Conventional knowledge about academic leadership concentrates on the number of responsibilities or actions executed by each individual [22]. In this regard, academic leadership is defined as a collection of duties that include visionary planning, research, and teaching [22]. However, several scholars argue that this particular conceptual framework is unsuitable for the present-day context of higher education. This is primarily because leadership in the contemporary academic arena is not an outcome or responsibility of an individual but rather a group effort [23].\n\nWolverton and Gmelch [24] offered a comprehensive examination of the leadership exhibited by college deans. Following an extensive review of the relevant literature, they defined academic leadership in American higher education as empowering faculty and staff to establish a community of scholars to achieve common objectives and set direction. Recent years have witnessed an explosion of studies about leadership in academic context, which has led to a diverse view of academic leadership. Siddique [25] posits academic leadership as the leadership type needed in the higher education institution. This term is usually used to describe leadership inside an academic organization and interactions with academic personnel [3]. It differs from professional managers and administrators within universities, who are responsible for numerous non or semi-academic areas of student and research activities. Academic leadership is also referred to as leading academic professionals in teaching, research, and service. Therefore, Dopson [26] urged for additional investigations to establish a thorough definition of leadership in academic environment, encompassing leadership processes more autonomously and contextually while expanding the scope of individual leaders.\n\nThe roles of deans and directors are crucial to the success of their respective institutions as academic leaders. According to Morris [27], an academic dean acts as the head of a college or school at a university, whether public or private. The dean administers the university’s faculty and serves as the institution’s leader. They are deemed exceptional due to their more challenging, deliberate, sophisticated, and managerial duties [28]. Tahsildar [29] reported a strong positive correlation between the deans and the faculty members’ levels of efficacy in leadership, teaching, and scholarly work. A study by Hunde et al. [30] aimed to examine the effectiveness of deanship and identify that instructors with different educational qualifications and work experiences had similar views on the effectiveness of deanship in their colleges. Akbulut et al. [31] identified the faculty perceptions of department chairs’ leadership effectiveness and found that the most influential factor was establishing leadership functions, including roles as motivator, visionary, and innovator.\n\nRosser et al. [32] looked at the leadership of academic deans and directors from both personal and institutional perspectives, focusing on seven key leadership duties. This encompasses (a) vision and goal setting, (b) management of the unit, (c) interpersonal relationships, (d) communication skills, (e) quality of unit’s education, (f) research, professional, and community endeavors, and (g) support for institutional diversity. In empirical research, academic leadership has received limited attention beyond theoretical investigations [33]. Heck et al. [34] identified seven deans’ leadership domains based on past studies and concepts. Rosser et al. [32] used those parameters to evaluate deans and directors. The relevance of these domains has been validated in scholarly investigations concerning leadership in the administration of higher education [35–38]. Hunde et al. [30] also assessed deans’ leadership using these dimensions. Hence, this study adopts these validated leadership dimensions to accurately assess leadership effectiveness in the context of higher education in emerging country.\n\nAcademic leadership effectiveness has increasingly been examined through well-established theories in organizational and educational leadership, including transformational, relational, situational, contingency leadership theories, and agile leadership theory. Transformational leadership theory, developed by Burns [39] and later expanded by Bass [40], emphasizes leaders’ abilities to inspire a shared vision, set strategic goals, and motivate followers toward organizational objectives. This approach highlights the importance of constructs such as Vision and Goal Setting, Interpersonal Relationships, and Research/Professional Endeavors in measuring leadership effectiveness, as these traits foster organizational alignment, commitment, and a culture of scholarly excellence.\n\nRelational leadership theory, established by Uhl-Bien [41], further supports the significance of Interpersonal Relationships and Communication Skills by emphasizing the role of interpersonal dynamics and open communication in fostering collaboration and cohesion within academic institutions. Effective relational leadership in academia helps build a supportive environment, enhancing both faculty satisfaction and organizational commitment.\n\nSituational Leadership Theory provides a foundation for Management of the Unit by suggesting that effective leaders adapt their management style according to the needs of their team and context, balancing direction with support based on situational demands [42]. In academic settings, leaders who effectively manage resources, delegate tasks, and respond to departmental challenges create a stable and productive environment essential for meeting both faculty and administrative needs.\n\nContingency Theory, introduced by Fiedler [43], supports both Management of the Unit and Quality of Education in the Unit by proposing that a leader’s effectiveness is contingent on how well their management approach aligns with organizational needs and goals. Academic leaders who excel in unit management and emphasize educational quality are better positioned to align resources, faculty, and educational objectives. This alignment directly supports curriculum development, program accreditation, and student success, which are critical to the institution’s overall reputation and performance.\n\nAgile Leadership Theory, as an approach to leadership, emphasizes flexibility, collaboration, and continuous improvement, which are crucial for academic leadership effectiveness [44]. By fostering an adaptive leadership style, agile leaders can dynamically adjust their strategies in response to the changing needs of their teams and the academic environment [45]. This theory supports the development of Vision and Goal Setting, Management of the Unit, and Interpersonal Relationships by prioritizing responsiveness and teamwork. Academic leaders who adopt agile principles are better positioned to create a high-performing, innovative environment that enhances faculty engagement and student success, thereby driving overall leadership effectiveness in academic settings.\n\nIn our study, Vision and Goal Setting, Management of the Unit, Interpersonal Relationships, Communication Skills, Research/Professional Endeavors, and Quality of Education in the Unit represent key dimensions validated in previous research on academic leadership effectiveness. These constructs were selected based on their demonstrated relevance in enhancing educational quality, faculty engagement, and organizational governance.\n\nComplexity theory, originally conceptualized by Warren Weaver [46], provides a foundational framework for this study, addressing the need to understand how interconnected elements interact dynamically in complex systems like academic leadership. In academic environments, leadership effectiveness depends on various interdependent factors—such as vision, resource management, and interpersonal relationships—that interact in non-linear ways. Complexity Theory supports the use of Partial Least Squares-Structural Equation Modeling (PLS-SEM), which is ideal for analyzing these interrelationships among latent variables, offering insights into both direct and indirect effects that simpler models cannot capture [47,48]. Recent studies demonstrate the efficacy of Complexity Theory and PLS-SEM in capturing the multifaceted nature of academic and organizational systems, particularly where multiple factors collectively contribute to outcomes [49].\n\nIn line with Complexity Theory’s principles, Fuzzy-Set Qualitative Comparative Analysis (fsQCA) and Necessary Condition Analysis (NCA) enable this study to explore diverse combinations and baseline conditions within academic leadership. fsQCA aligns with the concept of equifinality, where different pathways lead to effective outcomes. This approach is essential in academic settings, where diverse leadership approaches may all lead to similar success based on contextual factors [50]. NCA complements this by identifying conditions that are necessary but not sufficient alone, highlighting the foundational elements that must be in place for leadership effectiveness. Together, these methods reveal both the configurations and essential conditions required for success in complex academic systems, advancing a nuanced understanding of leadership through Complexity Theory [51].\n\nHaving a vision and direction to be effective as an academic leader is proven by prior researchers [8,52,53]. Without exception, articulating a clear and compelling vision is a crucial competency for academic deans to become successful leaders. Successful coordination of followers’ endeavors toward fulfilling organizational objectives is contingent upon leaders’ ability to communicate their visions. By articulating a compelling vision and establishing specific goals that are consistent with the changing requirements of students, faculty, and stakeholders, effective leaders in this domain provide strategic guidance [54]. From this point of view, an effective leader must explicitly link a vision to members and stakeholders to gain their support. Scott et al. [33] delineated three primary characteristics that exemplify the essence of effective academic leadership: (a) the act of engaging people in the change process, (b) a specific set of traits or skills, and (c) a particular group of individuals responsible for running a university or unit. Based on these characteristics, academic leadership involves creating a supportive environment for academic success, fostering a shared academic identity and values, and representing collaborative efforts for cross-border partnerships. Thus, the following hypothesis can be drawn from the earlier argument:\n\nWhen a unit is well-managed, it ensures that resources are properly allocated, goals are clearly defined, and team members are aligned with the academic mission. This creates an environment where academic leaders can focus on strategic initiatives, foster collaboration, and drive innovation. As a result, strong management practices contribute to the overall effectiveness of academic leadership, enabling leaders to successfully guide their institutions toward achieving educational excellence. Jones and Rudd [55] emphasized that the sustainability and effectiveness of change management in higher education institutions greatly rely on leadership. This perspective by Zhu et al. [53] implied that possessing excellent management skills is essential for demonstrating quality leadership. Academic leadership involves a variety of positions and designations within higher education institutions. It spans from task-oriented administrative management to visionary leadership with transformative potential. Additionally, it includes tactical management centered on achieving specific objectives [56]. Based on the arguments presented above, we can derive the next hypothesis:\n\nAcademic leaders must act as coalition builders, negotiators, and facilitators [32]. In terms of interpersonal relationships, academic leaders play a vital role in creating a positive and welcoming atmosphere for both faculty and students within the organization. Researchers evaluated leadership effectiveness based on the impact of leaders on individuals, groups, or organizations [57]. Leaders with strong interpersonal skills can enhance their effectiveness by improving communication and resolving conflicts, which is critical in academic leadership [58,59]. Thus, the effectiveness of an academic leader, according to Avolio and Bass [60], is assessed based on the degree to which leaders fulfill the requirements and anticipations of personnel, including supervisors, followers, and peers. This entails their commitment to implementing their vision and guidance, as well as how much they are liked, respected, and admired by their subordinates. Evans [61] discussed that effective academic leadership necessitates three qualities, with interpersonal relationships being the most significant. Therefore, the hypothesis can be stated as follows:\n\nIt is well-known that strong communication skills are essential for effective leadership in many fields, including academia. Academic leaders must effectively communicate in public forums, such as meetings, conferences, and university events, to represent the institution and advocate for its interests. Many studies have examined academic leaders’ abilities and effective qualities. Spendlove [62] suggested that effective institutional-level leadership requires scientific credibility, university experience, administrative abilities, communication, and negotiation skills. Consequently, effective communication skills are crucial for academic leaders, enabling them to lead more effectively and achieve better outcomes in their institutions. Considering the earlier literature and studies [32,34], the following hypothesis can be taken:\n\nAcademic leaders who are committed to research engage in a variety of scholarly endeavors, such as publishing, conducting research, obtaining grants, and contributing to the intellectual discussion in their respective disciplines. Research has shown that academic leaders who uphold rigorous research agendas enjoy greater visibility, influence, and credibility within their respective institutions [63]. Additionally, professional networks also give members access to resources, support, and best practices, all of which make leadership more effective [64]. Involvement in research and professional networks positively impacts leadership effectiveness by providing leaders with essential resources, knowledge, and collaborative opportunities, thereby enhancing their ability to lead and innovate [32,34]. As a result, the following hypothesis can be suggested:\n\nA faculty’s quality of education is determined by a multitude of components, such as instructional methodologies, curriculum development, student support services, and academic achievements. An effective approach, stimulating curricula, knowledgeable faculty, and nurturing learning environments that promote student achievement are all the components of a high-quality education [65]. According to Shahmandi et al. [66], the effectiveness of academic leadership would decline if leaders lacked the necessary knowledge, skills, and behaviors essential for guiding their institutions effectively. Consequently, Hoppe [67] emphasized the importance of defining an effective academic leader profile to help current leaders enhance their abilities, prevent unsuitable selections, and develop future leaders. The quality of education provided by faculty and the effectiveness of the dean’s leadership are closely connected. Faculty members often enhance the quality of education within their departments through their effective leadership [8]. Thus, the preceding discussion leads to the following hypothesis:\n\nBased on the earlier reviews,Fig 1illustrates the study’s conceptual framework, which includes six independent variables and one dependent variable.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.g001\n\nThe current study used a survey questionnaire to validate the conceptual framework. According to Yukl [68], how followers perceive and feel about their leaders is a standard measure of a leader’s effectiveness. Faculty members from all public universities in Bangladesh were targeted as participants. Data collection was conducted from March 1, 2023, to June 30, 2023, at eight purposively selected universities—four general universities and four science and technology universities—to ensure diversity in educational contexts.\n\nA stratified random sampling technique was used, where universities were first categorized by type (general and science/technology), and then faculty members were randomly selected from faculty lists obtained from the universities’ official websites. Participants received an email with a study summary and a link to a Google Form. A total of 318 valid responses were collected, with all participants providing voluntary consent to participate in the study.Table 1presents the demographic details of the study participants.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t001\n\nTable 1demonstrates that the majority of respondents, representing 65.1% of the total, were male, while 34.9% were female. Most respondents, 153 (48.1%), were aged between 25 and 30 years, with 105 (33%) falling between the 31 to 36 age categories, while 13.5% belonged to the 36 to 40 years category, and 5.3% were beyond 40 years old. When considering the educational level of the samples, there were 227 Master’s degree holders (71.4%), 44 MPhil holders (13.8%), 37 PhD holders (11.6%), and 9 Postdoc holders (2.8%). Almost half of the participants (50%) identified themselves as lecturers, whereas only 4.4% were professors. Over half of the participants (55%) reported 1 to 5 years of job experience at that university, while 29.6% reported having 6 to 10 years of work experience.\n\nThe research adopted instruments drawn from existing literature in this domain, and content validity assessed through a pilot study. A structured questionnaire was then developed to collect data from the participants. The study instrument was adapted from Heck et al. [34]. Deans’ effectiveness was assessed using six dimensions, including vision and goal setting, management of the unit, interpersonal relationships, communication skills, research/professional endeavors, and quality of the unit’s education. There were 43 items covering these six independent constructs. Leadership effectiveness construct was evaluated with five items from Hooijberg et al. [69]. All 48 items were rated on a 5-point Likert scale, where a rating of “1” reflected as very unsatisfactory, while a rating of “5” denoted an outstanding level of performance.\n\nThe study used three statistical techniques to analyze the collected data. First, Partial Least Squares Structural Equation Modeling (PLS-SEM) was employed as the primary analysis technique using SmartPLS (V. 4.1). PLS-SEM has advanced more rapidly than Covariance-Based SEM (CB-SEM) in recent years and is particularly well-suited for analyzing complex interactions between observed and latent variables. Furthermore, without making any assumptions about distributions, PLS-SEM can estimate complicated models with several constructs, measures, and structural paths. The analysis was conducted in two stages: evaluating the measurement model and the structural model [70].\n\nSecond, Fuzzy-set Qualitative Comparative Analysis (fsQCA) is used to augment the results of PLS-SEM and offer a more sophisticated insight into the factors that influence academics’ leadership effectiveness. The investigation of complex causal configurations is facilitated by fsQCA, which is particularly appropriate for samples that are small to medium in size [71]. In addition to providing a qualitative magnitude that outperforms conventional regression-based method, it assists in the identification of necessary and sufficient conditions for an outcome. However, fsQCA advances the investigation by unveiling configurational patterns that conventional linear model may fail to detect [72].\n\nThe final method applied is Necessary Condition Analysis (NCA), which adds to the fsQCA approach. NCA proves especially beneficial in better understanding of the configurations that result in high or low level of outcome, as it is linked to the identification of necessary condition for an outcome [73]. By implementing NCA, this study attempts to identify the crucial conditions that must exist for the anticipated results to be achieved. This approach offers additional insights into the complexities of the relationships being examined [74].\n\nIn the PLS-SEM findings, it is crucial to determine whether the measurement model is reflective or formative [75]. In this study, the measurement model is reflective which consists of three key components that need to be considered to ensure reliability and validity during evaluation. First, internal consistency reliability is confirmed by using metrics like Cronbach’s Alpha, Composite Reliability (CR), and rho A. Second, convergent validity was checked with loadings and average variance extracted (AVE) values. Thirdly, discriminant validity was verified [76,77]. The internal consistency reliability measures must meet a minimum threshold of 0.7 [78,76]. It is also recommended that the loadings and AVE values should be greater than 0.5 [79,80]. Fornell-Larcker criterion is a conservative and frequently used metric in the evaluation of discriminant validity [75]. In addition, Heterotrait-monotrait ratio (HTMT) was recommended by Henseler et al. [81] as a way to ensure more robustness of discriminant validity. For the HTMT confidence interval, 1 must not be the threshold. A lower, more conservative threshold value of 0.85 seems justified [81]. In the Fornell-Larcker criterion, the square root of each construct’s AVE should exceed its maximum correlation with every other construct in the same model [82].\n\nThe measurement model initially failed due to low Average Variance Extracted (AVE) values. To improve model fit, several low-loading indicators—specifically, VG1, VG3, VG7, VG8, VG11 (from Vision and Goal Setting), MU1, MU2, MU7, MU8 (from Management of the Unit), IR1, IR4, IR5, and IR9 (from Interpersonal Relationships)—were removed. This strategic removal of low-loading items increased the AVE values for the constructs, thereby achieving convergent validity. As shown inTable 2andFig 2, all constructs exceeded the minimum AVE threshold of 0.5, confirming convergent validity. Additionally, internal consistency reliability was assured with both Cronbach’s alpha and Composite Reliability (CR) values surpassing the 0.7 threshold. This methodological refinement aligns with best practices in scale validation, ensuring that the measurement model is both reliable and valid.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.g002\n\nConcerning discriminant validity, the HTMT assessment results indicated that no construct had an HTMT value exceeding the 0.85 threshold (Table 3).Table 4presents the Fornell-Larcker results, as recommended. Thus, the HTMT and Fornell-Larcker criteria verified the measurement model’s discriminant validity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t004\n\nThe structural model is examined in the second phase of assessing the PLS-SEM findings [75]. The essential components that constitute the standard evaluation parameters for evaluating the structural model are standardized root mean square residual (SRMR), the Normed Fit Index (NFI), predictive relevance (Q2), collinearity assessment, coefficient of determination (R2), effect size (f2), and structural model path coefficients [77].\n\nIt is recommended that the SRMR value falls between 0.08 and 0.10, and the NFI value ranges from 0.70 to 0.90 to be considered acceptable [83]. The model’s SRMR and NFI were 0.066 and 0.711. So, the model fit was overall good. Since the scores were satisfactory, the model could be investigated further.\n\nThe subsequent analysis of the assessment model for predicting accuracy [84] was derived from the Q2values [85]. Q2values integrate in-explanatory power and out-of-sample prediction characteristics [86]. The prediction accuracy of the structural model depends on Q2values greater than 0 for a dependent construct. Q² values indicate predictive relevance, with values exceeding 0, 0.25, and 0.50 representing small, medium, and large predictive relevance, respectively [76]. The Q2value for leadership effectiveness is 0.667, which suggests a large predictive relevance.\n\nThe structural model uses OLS regressions for path coefficients. Hence, collinearity must be rigorously assessed to prevent bias in the regression results [77]. The construct’s variance inflation factor (VIF) value indicates collinearity. To avoid collinearity, the VIF value should be greater than 0.20 and less than 5 [87]. The data inTable 5specifies that all VIF values fall within the recommended threshold.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t005\n\nNext, the coefficient of determination (R2) is a widely used measure for assessing structural models. It represents the percentage of variance in the endogenous constructs explained by the correlated exogenous constructs [70]. Additionally, the R2value measures the explanatory and sample predictive power of the model’s constructs [88,89]. R2values are between 0 and 1, with higher values indicating stronger explanatory power. An R2value of 0.75 indicates substantial explanatory power, 0.50 indicates moderate power, and 0.25 represents weak explanatory power [76,90]. The R2coefficient is 0.689, as shown inTable 6. This indicates a satisfactory level of explanatory power, with the six exogenous constructs accounting for 68.9% of the variance in the endogenous construct.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t006\n\nFurthermore, effect size, commonly represented as f2, measures the relative impact of exogenous constructs on endogenous construct. The f2values of 0.02, 0.15, and 0.35 represent the small, medium, and large effects of an exogenous constructs on an endogenous construct [70,77]. As shown inTable 6, vision and goal setting, management of the unit, interpersonal relationships, communication skills, and research/professional endeavors exhibit small but statistically significant effect sizes, while the quality of the unit’s education shows a medium and significant effect size, reinforcing its importance in the model.\n\nStructural model evaluation uses the stated hypothesis to examine the path between constructs. Following [70], we calculated the sample’s standard error and t-statistics and assessed the path coefficients using bootstrapping with 5000 subsamples, a two-tailed approach, and a significance level of 0.05. The statistical significance of all hypothesized relationships is shown inTable 7andFig 3. However, vision and goal setting (β =  0.145, t =  3.135, p =  0.002), management of the unit (β =  0.104, t =  2.091, p =  0.037), and interpersonal relationships (β =  0.119, t =  2.200, p =  0.028) have a positive and significant effect on academic leadership effectiveness supporting H1, H2,and H3, respectively. Similarly, hypotheses H4, H5, and H6 are supported by the strong positive impacts of communication skills (β =  0.189, t =  3.182, p =  0.001), research/professional endeavors (β =  0.211, t =  3.176, p =  0.002), and quality of the unit’s education (β =  0.259, t =  4.453, p =  0.000) on leadership effectiveness.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.g003\n\nFurther analysis was conducted using the fsQCA tool to determine how the various components combined to get a certain outcome. This study’s antecedent conditions were six independent variables: VG, MU, IR, CS, PE, and QEU, while the outcome variable was LE. The three key phases in the data analysis are data calibration, constructing a truth table, and causal conditions analysis [91].\n\nThe calibration process in fsQCA converts raw scores into a 0-1 scale. The present study used latent variable scores for calibration because they more accurately represent unobservable constructs [73,92], therefore improving the accuracy of further fsQCA evaluations. This was accomplished by taking an average of the associated indicators and using it to generate an index for each construct. Fuzzy sets must be created from ordinary data by setting Likert scale values to full membership (fuzzy score =  0.95), crossover point (fuzzy score =  0.5), and full non-membership (fuzzy score =  0.05).\n\nVariables were converted into calibrated sets, with 4 representing complete membership, 3 representing the crossover point, and 2 representing full non-membership [77]. As recommended by Fiss [93], this study adds 0.001 to scores exactly equal to 0.50 to ensure reliability and prevent complications. This prevents cases close to the crossover point from being excluded from analysis. In fsQCA V. 4.1, the calibration procedure was automated.Table 8illustrates the outcomes of this transformation together with descriptive statistics of the variables, which serve as the fundamental fuzzy sets for further assessment of causal conditions and outcomes.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t008\n\nA crucial part of fsQCA is the examination of sufficient conditions, but before looking into that, it is required to determine the necessary conditions [91]. The necessary conditions analysis in fsQCA is employed to confirm whether the antecedent conditions are necessary for the outcome. This study inspects all conditions, both present and absent, with a focus on the presence or absence of LE as the outcome variable. It identifies six preconditions - VG, MU, IR, CS, PE, and QEU - affecting LE. According to Ragin [91], a variable is usually deemed “necessary” for the outcome if its consistency is greater than 0.9.\n\nIt is evident fromTable 9that all the conditions have sufficient consistency scores except VG, leading to impacting high leadership effectiveness since their scores for consistency are above the threshold level. Hence, the result reveals that MU, IR, CS, PE, and QEU are considered essential to ensure the deans’ high leadership effectiveness. Additionally, necessary conditions in fsQCA offer a vital understanding of the fundamental mechanisms of causal relationships. The interrelated nature of these conditions implies that their combined impact should be explored in more detail.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t009\n\nAfter the analysis of necessity, the analysis of sufficient conditions was conducted to find the various causal configurations that result in leadership effectiveness. For the examination of sufficient conditions, a truth table with 2krows was constructed. Each row represents a combination of six factors, along with the frequency and consistency of each combination, and k represents the number of outcome factors [91]. To ensure that 75% of the reserved samples are remained and that the study’s sample size is considered to be large (>150 cases), a minimum frequency threshold of 3 was established [94,95]. The raw consistency standard was set at 0.8 to delineate the minimum impact of the antecedent conditions on the outcome [96].\n\nComplex, intermediate, and parsimonious solutions were reported in the standard analyses generated by the fsQCA truth table [91]. The complex solution lacked explanatory value, while the parsimonious and intermediate solutions successfully made a distinction between the core and peripheral conditions [94].Table 10presents the results of the fsQCA findings, which identify six unique solutions that contribute to high leadership effectiveness (LE) in the context of Bangladeshi public universities.Table 10also demonstrates that the consistency and coverage of all configurations are above 0.8 and 0.2, respectively [92].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t010\n\nThe result indicates that all six solutions were sufficient for leadership effectiveness, as the consistency values exceeded 0.8. The solutions are: Solution-1: VG *  MU *  IR; Solution-2: VG *  IR *  CS *  PE; Solution-3: VG *  IR *  CS *  QEU; Solution-4: MU *  IR *  CS *  QEU; Solution-5: MU *  IR *  PE *  QEU; and Solution-6: VG *  MU *  CS *  PE *  QEU. Findings from Solutions 1 indicate that leadership effectiveness can be achieved through a combination of VG, MU, and IR and CS, PE, and QEU are irrelevant. According to solution 2, Leadership effectiveness can be attained by combining VG, IR, CS, and PE, while MU and QEU have insignificant roles. These findings from solution 1 and 2 emphasize the crucial role of VG and IR in attaining high LE (core conditions). The sufficient configurations ensure high LE with a raw coverage of 82.2% and 77.4% of the cases, respectively. Also, these solutions exhibit a high level of consistency with scores of 0.910 and 0.949. Next, a high level of LE can be attained with a combined recipe of VG, IR, CS, and QEU, as reported by 77.9% of the cases in Solutions 3 where MU and PE are not important.\n\nThis solution has a high consistency score of 0.947. Solution 4 further proposes that MU and IR, when combined with CS and QEU, are sufficient to achieve a high level of LE while VG and PE are inconsequential according to 79.5% of the cases. This solution has a high consistency score of 0.937. Solution 5 then highlights the significant role of IR and QEU in achieving high LE combined with MU and PE. Lastly, solution 6 underscores that the combination of VG and QEU can still achieve high LE even with a low MU, CS, and PE level. Notably, Solution 1 is the most effective solution for achieving high LE, as evidenced by its high raw coverage of 0.822. This implies that it applies to a wide range of cases. In addition, the combinations of solutions associated with high leadership effectiveness accounted for a significant portion of the overall solution coverage, which is 89%. The six configurations could likely explain 92% of the cases with adequate explanatory power, as the overall solution consistency was 0.920.\n\nNecessary Condition Analysis (NCA) was performed to supplement the PLS-SEM further to examine the relationships between predictor variables and the outcome. Three main criteria used to determine the necessary conditions [97]. Firstly, the predictor-outcome variable relationship needs to be theoretically justified. Secondly, the necessary condition’s effect size should exceed zero to be significant [98]. Thirdly, evaluation of the conditions against the null hypotheses to avoid making Type 1 errors and giving false results. To accomplish this, a bootstrapping approach can be implemented, which involves employing a permutation test to evaluate the necessary conditions against the outcome. If the relationship is to be considered significant, it must have a low p-value, such as p < .05. The Cartesian coordinate system was used to initiate NCA, with the latent variable scores from the PLS-SEM analysis serving as the starting point. Different ceiling lines can be selected. The proposed Ceiling Regression-Free Disposal Hull (CR-FDH) line was performed in this study (Fig 4), which is ideal for continuous or discrete data with numerous levels [99].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.g004\n\nAfter that, the effect sizes (d) of the latent variable scores were subsequently evaluated, and a recommended random sample size of 10,000 was used to figure out if the results were statistically significant [97,100]. InTable 11, the findings revealed that each condition was necessary for leadership effectiveness, as they demonstrated effect sizes that exceeded zero. The effect size of communication skills was the most significant (d =  0.290, p < .05), followed by research/professional endeavors (d =  0.240, p < .05). This suggests a medium effect size range (0.1 ≤  d ≤  0.3) [96]. Likewise, interpersonal relationships (d =  0.207, p < .05), quality of the unit’s education (d =  0.164, p < .05), vision and goal setting (d =  0.152, p < .05) and management of the unit (d =  0.121, p < .05) were also determined as necessary conditions having medium effect sizes.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t011\n\nA bottleneck table (Table 13) was developed at the final stage to obtain a more in-depth understanding of the essential predictors’ levels for ensuring leadership effectiveness.Table 12demonstrates the minimum values (in percentage) needed for predictor variables (VG, MU, IR, CS, PE, and QEU) in the subsequent columns, corresponding to each desired level of the outcome variable (LE) listed in the first column. As articulated, the minimum requirements for achieving leadership effectiveness of 80% were: 14.78% for VG, 20.75% for MU, 23.27% for IR, 33.96% for CS, 16.98% for PE, and 10.6% for QEU. However, as the level of LE (100%) increases, the required percentages of predictor variables also increase. These values imply that deans are unlikely to exhibit high leadership effectiveness unless the specified threshold values are not attained. More importantly, this finding consistently conforms to the results obtained from both PLS-SEM and fsQCA analyses.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t012\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320723.t013\n\nThis study conducted an empirical investigation into faculty members’ perceptions regarding the effectiveness of deans’ leadership in public universities in Bangladesh. This study developed and examined a model in which vision and goal setting, management of the unit, interpersonal relationships, communication skills, research/professional endeavors, and quality of education in the unit are examined as contributors to leadership effectiveness. A combined approach of the PLS-SEM, fsQCA, and NCA methods is utilized in this research.\n\nThe PLS-SEM results indicated that VG, MU, IR, CS, PE, and QEU positively influence the dean’s leadership effectiveness (Table 7). This aligns with the findings of Sehgal et al. [101] which suggests that these are likely to enhance leadership effectiveness significantly. Furthermore, the findings are compatible with previous research that presents a framework for evaluating the academic’s leadership effectiveness according to these six leadership domains or roles [102]. Academic leadership effectiveness is not just about identifying organizational elements but also ensuring all staff, regardless of position, are engaged and aligned with elements like VG, MU, and CS [103]. Nevertheless, there is a strong connection between positive interpersonal relationships and pedagogical leadership, which can enhance the educational environment and improve teacher performance and student outcomes [104]. However, one study does not directly support the connection between professional endeavor (PE) and leadership effectiveness of teachers. The study suggests that principal leadership, emphasizing values like integrity and trustworthiness, plays a key role in developing teachers and staff, ultimately influencing academic leadership, as found in this paper [105]. This study found a significant connection between quality education and academic leadership, which is further emphasized by another study, underlining that improving academic leadership effectiveness cannot be achieved without including quality education (SDG-4) [106,107].\n\nWhile the findings from the PLS-SEM provide insights into the overall impact of antecedents on outcomes, fsQCA offers various particular combinations of antecedent conditions that are sufficient. Thus, fsQCA indicated six primary configurations which can significantly influence high LE (Table 11). The findings validated the conditions as necessary and sufficient for achieving high LE. According to solutions 1 and 2, the combination of VG and IR (core requirements), along with MU or with CS and PE, could result in achieving high leadership effectiveness. Solution 3 demonstrated that when VG and IR are aligned with CS and QEU, it could lead to a high level of LE. Based on solutions 4 and 5, it was found that combining MU, IR, and QEU with CS or PE might result in high LE. Additionally, solution 6 showed that the combination of VG, MU, CS, PE, and QEU could also lead to high LE. Core conditions for high LE are VG, IR, and QEU, as evidenced by the fsQCA results.\n\nIn addition, the PLS-SEM findings (H1) are consistent with the fact that VG is a condition in four of the six configurations (solutions 1, 2, 3, and 6). Likewise, the PLS-SEM results (H3) are also consistent with the fact that IR is an essential prerequisite in five of the six solutions. Moreover, the PLS-SEM result (H6) is validated by the core condition of QEU in solutions 3-6, which results in a high LE. Apart from these, the PLS-SEM results (H2, H4, and H5) are further supported by the identification of MU, CS, and PE as significant factors (peripheral conditions) that ensure high LE.\n\nAlthough fsQCA evaluated the empirical value of sufficient combinations of conditions for high LE, NCA offered a better comprehension of how the predictor variables confined the outcome variable. NCA results confirmed that all six conditions are essential for achieving the desired outcome, which is consistent with the PLS-SEM and fsQCA findings. Notably, VG was found to be unnecessary according to necessity results in fsQCA but it is necessary according to NCA results. Additionally, they have medium-size influences on LE. In particular, LE is most significantly influenced by communication skills. Furthermore, the NCA bottleneck analysis (Table 12) illustrated the minimum level of predictors necessary to achieve a high level of outcome. For a minimum of 80% of LE to be achieved, the required percentages of VG, MU, IR, CS, PE, and QEU must be 14.78%, 20.75%, 23.27%, 33.96%, 16.98%, and 10.06%, respectively. It has also been discovered that the minimum required percentages of the predictor variables increase as the level of LE increases.\n\nTable 13shows the combined results of the three analytical approaches, which offer an outline for comparing the results of each method and deriving the final insights. This framework helps identify significant links between hypothesized predictors and the outcome, ascertain the presence of necessary conditions, and evaluate cases with alternative causal configurations. It allows for the classification and description of complexities, illustrates variations, and enhances the explanatory power of the examined phenomenon.\n\nThis study contributes to leadership theory by utilizing a combination of PLS-SEM, fsQCA, and NCA methods, demonstrating that a multi-method approach can provide a more comprehensive understanding of leadership effectiveness. By integrating these methods, the study highlights the existence of multiple pathways (or configurations) that can lead to effective leadership, thereby supporting the concept of equifinality—where different combinations of factors can achieve the same outcome. This finding encourages future research to move beyond single-method studies, suggesting that employing diverse analytical techniques can capture the complexities of leadership dynamics more effectively.\n\nThe present study also extends existing leadership theories to new cultural and institutional contexts by investigating academic leadership in public universities in Bangladesh. This contextualized insight enriches the global discourse on leadership by highlighting the need for theories that are adaptable to diverse environments. The study also provides clarity on the roles of necessary and sufficient conditions for leadership success, offering theoretical frameworks for identifying which elements must always be present and which combinations can effectively achieve desired outcomes. This distinction is vital for refining theoretical models and guiding future research to focus on the critical factors that drive leadership effectiveness.\n\nFrom a managerial perspective, this study gives perceptions of university leaders and policymakers who seek to enhance leadership effectiveness in academic settings. Universities should recognize that multiple combinations of attributes can lead to effective leadership. This insight calls for the design of flexible and customized training programs that address the diverse needs of academic leaders. These programs should incorporate various methods to develop a broad range of competencies, including VG, MU, IR, CS, PE, and QUE, ensuring that leaders are well-rounded and adaptable to different challenges.\n\nMoreover, institutions should strategically allocate resources to strengthen both core and supporting leadership factors identified in the study. This could involve investing in professional development opportunities. The study also suggests implementing a comprehensive evaluation framework that integrates multiple methods to gain a deeper understanding of leadership effectiveness. Such an approach would allow university administrators to more accurately assess leadership performance, guiding more effective decision-making and policy development. The data-driven insights provided by this research emphasize the importance of continuous monitoring and adaptation of leadership strategies.\n\nBy leveraging empirical evidence, institutions can refine their leadership approaches to better meet their unique needs. This practice helps ensure that leadership strategies remain aligned with institutional goals and are responsive to evolving challenges, fostering a more effective and resilient academic leadership environment.\n\nThis study provides a comprehensive examination of the perceptions of leadership effectiveness among deans in public universities in Bangladesh, focusing on six key leadership constructs: VG, MU, IR, CS, PE, and QEU. By employing a combined approach of PLS-SEM, fsQCA, and NCA methods, the study offers a nuanced understanding of how these factors contribute to effective leadership. The PLS-SEM analysis demonstrates that all six constructs significantly impact leadership effectiveness, while fsQCA uncovers six distinct configurations of these variables that can lead to high effectiveness, with combinations involving VG, MU, and IR proving particularly effective (Based on raw coverage). Additionally, the NCA method highlights the necessity of all six factors and identifies specific bottlenecks that must be addressed to achieve high leadership effectiveness. The integrated approach of these three methods confirms the existence of complex, asymmetric relationships among the variables, providing deeper insights into the mechanisms of effective leadership in academic settings.\n\nWhile the study offers valuable insights, it also has certain limitations that suggest avenues for future research. The focus on faculty members from eight public universities in Bangladesh limits the generalizability of the findings. Future studies could expand the sample size and include a broader range of universities to enhance the applicability of the results. The cross-sectional design also restricts the ability to capture the dynamic nature of leadership over time, pointing to the need for longitudinal studies. Additionally, relying solely on faculty perceptions of leadership effectiveness presents a limited perspective; future research could incorporate self-assessments from deans as well as evaluations from their superiors, subordinates, and students. Exploring leadership effectiveness in different contexts, such as comparing public and private universities, and using alternative instruments like the Multifactor Leadership Questionnaire (MLQ), could provide further insights. Despite its methodological rigor, this study recognizes that there are other analytical methods that may offer deeper explanations of the research phenomena, encouraging future researchers to consider diverse approaches.Top of Form\n\nhttps://doi.org/10.1371/journal.pone.0320723.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0320723.s002\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0320723.s003\n\n(CSV)",
    "category": "education"
  },
  {
    "title": "The influence of resonant leadership on teachers’ innovative behavior: The mediating mechanism of information processing models",
    "authors": "Yuangen Bao, (PLOS)",
    "publish_date": "2025-04-11",
    "doi": "https://doi.org/10.1371/journal.pone.0321763",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321763",
    "content": "Teacher innovation is crucial for adapting education to contemporary societal needs. While the benefits of resonant leadership have been extensively studied, its influence on teachers’ innovative behavior and associated cognitive-affective processes remains underexplored. This study employs the information processing theory to investigate the influence of resonant leadership on innovative behavior among primary and junior teachers in mainland China, while examining the intricate mediating roles of perceived insider status and affective commitment. Using structural equation modeling and bootstrapping techniques, data analysis was conducted on a sample comprising 4,769 teachers from 16 provinces in China. The findings confirm a positive correlation between resonant leadership and teachers’ innovative behavior. Perceived insider status and affective commitment not only independently mediate this relationship but also act as sequential and interactive mediators. Furthermore, the distinct mediating effect of interactive mediation is the most important. This research enhances our understanding of resonant leadership’s impact on basic education while providing novel insights into fostering teacher innovation through comprehensive cognitive-affective pathway analysis.\n\nCitation:Bao Y (2025) The influence of resonant leadership on teachers’ innovative behavior: The mediating mechanism of information processing models. PLoS ONE 20(4):\n           e0321763.\n        \n        https://doi.org/10.1371/journal.pone.0321763\n\nEditor:Amal Diab Ghanem Atalla, Alexandria University Faculty of Nursing, EGYPT\n\nReceived:September 5, 2024;Accepted:March 11, 2025;Published:April 11, 2025\n\nCopyright:© 2025 Yuangen Bao. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data cannot be shared publicly because of commercial and privacy reasons. Data are available from the Longgang District Institute of Educational Sciences, Shenzhen, China, Institutional Data Access / Ethics Committee (contact viajsfzzxzhwq@lg.gov.cn) for researchers who meet the criteria for access to confidential data.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe development of innovative behavior is pivotal for organizational success in today’s technologically dynamic and globally connected world[1]. Within education, teachers’ innovative behavior is equally critical; as the system’s backbone, they play an irreplaceable role in navigating challenges from technological shifts and globalization [2]. By demonstrating adaptability through innovation, educators ensure institutions remain responsive to evolving demands [3], making the cultivation of such behavior essential for sustained educational advancement.\n\nLeadership styles are widely recognized as key drivers of teacher innovation. Studies demonstrate the impacts of transformational [4], distributed [5], and empowering leadership [6] on teachers’ innovative behavior. However, existing research predominantly examines unidirectional effects, overlooking the reciprocal emotional resonance between leaders and teachers.\n\nResonant leadership, conceptualized by Goleman [7], counters organizational dissonance by fostering empathetic leader-subordinate relationships [8]. This involves leaders transmitting positive emotions and values to subordinates while also encouraging subordinates to express their emotions and perceptions, facilitating an interactive two-way transmission of emotions. Resonant leaders provide emotional support through empathy, compassion, and mindfulness to help combat stress and burnout among their subordinates [9]. They also identify opportunities within challenges and inspire hope amidst fear and despair for both their organizations and communities [8]. Nevertheless, how resonant leadership specifically drives teacher innovation remains underexplored.\n\nPrior mechanistic studies have relied on isolated frameworks like social cognitive [10], social exchange theory [4], or self-determination theory [6]. Yet integrated analyses of cognitive-affective interactions in teacher innovation remain scarce, prompting calls for multidimensional approaches[11].\n\nInformation processing theory suggests organizational contexts activate cognitive-affective systems to shape behavior [12]. The leader behavior style in an organization is a key situational factor that impacts employee cognition, emotion, and ultimately their behavior. We thus propose a dual-path model where resonant leadership drives innovation via cognitive (insider status perception) and affective (emotional commitment) pathways.\n\nFurthermore, based on information processing theory, individual cognitive units can influence behavior by sequentially activating or concurrently interacting with affective units [13]. Moreover, research demonstrates that a high-quality interactive relationship between employees who perceive a strong insider identity and the organization results in higher levels of emotional commitment [14]. Consequently, resonant leadership can impact the interaction between teachers’ perceived insider status and affective commitment, ultimately influencing their innovative behavior. This study also investigates how resonant leadership affects teachers’ innovative behavior through both chain mediation and interactive mediation models.\n\nThe information processing model serves as a guiding principle or framework for evaluating the decision-making process of behavioral conduct and constitutes a crucial theoretical foundation for elucidating teachers’ innovative decision-making behavior. This theory has evolved through three key mechanisms, elucidating the evolving roles of affect within cognitive frameworks. According to traditional perspectives, emotions are believed to emerge after cognitive representations. Sensory inputs are encoded and interpreted cognitively before triggering emotional reactions [15]. This suggests that emotions are secondary and depend on pre-existing cognitive structures, emphasizing the primacy of cognition in information processing. For instance, a teacher might first think about the potential benefits and drawbacks of a new method before feeling enthusiastic or anxious about it.\n\nChallenging linear models, Berlyne, et al [16] and Estes, et al [17] proposed that emotions can operate independently from cognitive processing. Zajonc further emphasized the direct influence of emotions on behavior as a distinct pathway in human response systems [18]. For example, a teacher might feel a strong sense of excitement (emotion) that directly motivates them to try a new method, without needing to think through all the details first (cognition). Building upon these foundations, Mischel, et al integrated emotion into social-cognitive processing through their CAPS theory[12]. They proposed Cognitive-Affective Units (CAUs) within personality systems, suggesting that cognitive and emotional units dynamically interact within an individual’s psychological architecture to shape choices and actions collectively. Metcalfe, et al enriched the CAPS model by introducing ‘hot’ (emotion-driven) and ‘cold’ (cognition-driven) systems, providing a nuanced understanding of control dynamics[13]. For example, a ‘hot’ system might drive a teacher to act on a gut feeling to try a new method, while a ‘cold’ system might involve careful planning and analysis before making a decision. Their addition illustrates the bidirectional nature of cognitive-affective interactions guiding human behavior. For instance, a teacher might start with a gut feeling (emotion) to try a new method, then use logical reasoning (cognition) to plan it out, and finally, the excitement (emotion) of seeing positive results reinforces the decision.\n\nIn summary, based on the research process of information processing mode in existing literature, the impact of external information on individual behavior primarily occurs through distinct pathways: cognitive system, affective system, cognitive-affective system, and cognitive-affective interaction system. Consequently, within the context of resonant leadership, this study posits that teachers’ decision-making regarding innovative behavior is influenced by their internal cognitive and emotional systems as well as these interrelated systems w1hich operate successively and synchronously; importantly, these four systems are autonomous from one another.\n\nIn recent decades, there has been an increasing interest in educational leadership because of the growing responsibilities of school principals [19]. The emerging leadership theory of Resonant Leadership was proposed by Western scholars [7]. Goleman and his colleagues believe that leaders, being at the core of a team or organization, are observed and emulated by employees, making them susceptible to negative states that lead to discord in management. Consequently, leaders need to achieve emotional resonance with their employees, conveying positive emotions and adapting to subordinates’ emotions through empathy, making them feel understood and cared for, thus leading to voluntary fellowship. Boyatzis, et al further pointed out that resonant leadership is based on emotional intelligence, encompassing three dimensions: mindfulness, hope, and compassion, which can inspire positive emotions and healthy relationships [20]. Scholars have defined resonant leadership from various perspectives: for instance, Mckee, et al believe that resonant leaders are in sync with those around them [21], Squires and others define resonant leaders as those with high emotional intelligence, and Bawafaa, et al point out that resonant leadership is a positive relational leadership style that empowers team members by instilling confidence and trust [22]. Integrating these perspectives, the essence of resonant leadership lies in three key dimensions: the resonance process between leaders and their team and environment, the manifestation of high emotional intelligence, and the goal of achieving harmony. Leaders should maintain consistency with those around them and the environment, demonstrate individual characteristics such as mindfulness, hope, and compassion, and achieve a harmonious state with themselves, others, and the environment through emotional resonance with their subordinates.\n\nResonant Leadership, a unique form of leadership, shares similarities with Relational and Emotional Leadership but also exhibits distinct differences. While all three emphasize emotional intelligence in leadership, Resonant Leadership particularly highlights the emotional resonance and deep connections between leaders and team members. Compared to Relational Leadership, which values interpersonal relationships within the team, Resonant Leadership achieves deeper emotional and psychological synchronization with employees through resonance [20]. This synchronization promotes individual harmony as well as harmonious teamwork and organizational state. In contrast to Emotional Leadership’s focus on influencing subordinates’ psychological states through emotional transmission for goal achievement, Resonant Leadership places greater emphasis on emotional resonance and connection between leaders and subordinates, achieving team harmony through mutual adjustment of attitudes and behaviors [23]. Therefore, Resonant Leadership brings positive impacts and long-term development to teams and organizations by stimulating a broader and more profound resonance effect.\n\nAlthough resonant leadership plays a crucial role in reducing employee anxiety and promoting organizational development, its research is still in the early stages within academic circles [22,24], with limited empirical studies available. This study will focus on the impact of resonant leadership on the innovative behavior of primary and secondary school teachers in mainland China.\n\nFirstly, resonant leaders can achieve the same frequency resonance with employees by transferring emotional energy, to convey their optimism, enthusiasm, and other positive emotions to employees [7]. According to the Extension-Construction principle, teachers with positive emotions such as optimism and enthusiasm can promote their innovative behavior [25]. Secondly, resonant leaders exhibit high levels of emotional intelligence and can manage their emotions effectively and in tune with those of those around them, building strong, trusting relationships and creating an optimistic atmosphere that inspires commitment [24]. This kind of relationship and atmosphere can stimulate the intrinsic motivation of teachers to carry out innovative teaching. Thirdly, resonant leadership is based on emotional intelligence and includes the three dimensions of Mindfulness, Hope, and Compassion, which are the sources of personal renewal [20]. These can not only stimulate teachers’ positive emotions and healthy interpersonal relationships, but also allow teachers to maintain resilience and work efficiently in the face of innovation failures. Therefore, this study proposes the following hypothesis.\n\nH1: Resonant leadership is positively related to teacher innovative behavior.\n\nThe early conventional information processing model suggests that when exposed to external stimuli, an individual goes through sensory input, followed by physical and advanced encoding of the information, ultimately leading to the formation of cognitive representation. This type of cognitive representation, known as a “cold system” can directly influence an individual’s final judgment and decision-making process without eliciting emotional reactions [13,15,18]. As an important cognitive factor, insider identity perception may play a conductive role between resonant leadership and teachers’ innovative behavior.\n\nThe perception of insider identity refers to the self-perception that an individual, as a member of an organization, has won personal space, status, and acceptance in the organization, that is, the degree to which an individual can perceive himself as an “insider” in a particular organization [26]. Leaders are “important others” of employees and possess certain authority [27]. Therefore, employees tend to judge their status in the organization and the extent to which they are accepted by the organization according to the way they treat themselves [28]. When employees perceive the support of their leaders, they tend to judge themselves as “insiders” of the organization [29]. Resonant leadership achieves emotional resonance with teachers by transmitting emotional energy, thereby conveying its own positive emotions such as optimism and enthusiasm to the teachers. This emotional support may foster the teachers’ perception of their sense of belonging. Resonant leadership is when leaders demonstrate a high level of emotional intelligence and can effectively manage their emotions and align with those of those around them, thereby building strong, trusting relationships [24]. This close relationship between leaders and members is an important reason for promoting the perception of employees’ insider status [30].\n\nAt the same time, employees’ insider identity cognition also has a significant impact on their work attitude and behavior [26]. Specifically, this study speculated that insider identity cognition would positively affect teacher innovative behavior. According to the social exchange theory, when employees with a high level of insider identity cognition realize the recognition and respect of the organization and meet their needs for emotional connection and belonging, employees will take the initiative to act in a way that is beneficial to the interests of the organization and are more willing to make efforts beyond the work requirements as a return to the organization and positive feedback to the recognition and respect of the organization. In fact, previous studies have shown that employees with a high level of insider identity recognition are more likely to implement innovative behaviors that contribute to the interests of the organization. Based on the above analysis, the following hypothesis is proposed.\n\nH2a: Resonant leadership is positively related to teacher perceived inside status.\n\nH2b: Teacher perceived inside status is positively related to teachers’ innovative behavior.\n\nH2: Teacher perceived inside status play a mediating role between resonant leadership and teacher innovative behavior.\n\nAccording to the information processing model, the emotional system can react to external stimuli without intricate reasoning and analysis, functioning as a “thermal system” that directly elicits behavioral responses [12,18]. Innovation process is challenging and risky for the employees [31], so it requires not only the knowledge and skills of employees, but also the intrinsic motivation and emotional support of employees. Affective commitment, the core part of organizational commitment [32], provides a powerful perspective for explaining the mechanisms between resonant leadership and teacher innovative behavior. On one hand, resonant leadership serves as an important information source for shaping teacher affective commitment. Resonant leadership is particularly effective in fostering employees’ sense of organizational emotional support [33], which is rooted in affective commitment [34]. Squires et al. argue that employees are more likely to engage in high quality LMX when they perceive a relationship with their leaders who demonstrate a high level of emotional intelligence [24]. Numerous studies have provided empirical evidence of the positive relationship between LMX and subordinate affective commitment [35].\n\nOn the other hand, teacher affective commitment to the school can stimulate their innovative teaching behavior. The extension-construction principle suggests that positive emotions expand employees’ cognition and action, promoting them to generate innovative ideas and adopt creative thinking for problem-solving [25]. Teachers who deeply care about the school closely align their own development with the school goals, prioritizing organizational objectives over personal interests. Such emotionally committed teachers strive to exceed expectations in their work and contribute to the organization’s growth. When conventional methods fail to achieve desired outcomes, these passionate teachers proactively seek new ways and approaches that better suit the organization through active learning. Although there is limited empirical research on the effect of teacher affective commitment on innovative behavior, it is possible to promote innovation based on the above theoretical analysis.\n\nH3a: Resonant leadership is positively related to teacher affective commitment.\n\nH3b: Teacher affective commitment is positively related to teachers’ innovative behavior.\n\nH3: Teachers’ affective commitment plays a mediating role between resonant leadership and teacher innovative behavior.\n\nEarly information processing theory suggests that individual cognitive units activated by situational stimuli can eventually act on individual behavior by activating affective units [15]. Therefore, the relationship between teacher insider perception of identity and affective commitment is not completely independent. As a kind of teacher’s perception of teacher-school relationship, insider perception of identity should positively affect teacher affective commitment. Specifically, employees with a higher level of insider identity perception are recognized and accepted by the organization, have a strong sense of belonging and responsibility to the organization, and show a higher level of affective commitment [36]. Relevant empirical studies also show that when employees have a strong perception level of insider identity, they will incorporate the concept of “in-group” members into their self-concept, forming the overall self-cognition, and thus generating higher emotional commitment [37]. To sum up, this paper constructs a chain mediation model of “resonant leadership-internal personal perception-affective commitment-teacher innovative behavior “. Therefore, this paper makes the following assumptions:\n\nH4: Perceived inside status and affective commitment play a chain-mediating role between resonant leadership and teacher innovative behavior.\n\nAccording to Mischel (1995) theory of cognitive-affective system, the cognitive-emotion unit (CAUs) in personality system will have interactive influence after being stimulated by external environment information, and then determine people’s decision-making and behavior [12]. Therefore, it can be speculated that after primary and secondary school teachers experience resonant leadership behaviors, their internal cognitive factors (insider identity) and emotional factors (affective commitment) may interact and jointly promote their innovative behaviors.\n\nThe perception of insider identity refers to an employee’s sense of belonging to the organization, including their cognitive and emotional relationship with it [38]. This relationship also forms the basis for employees’ affective commitment. Therefore, employees’ cognition and emotions towards their organization are internal elements that are closely related to both insider identity perception and affective commitment. In other words, both concepts focus on employees’ cognitive and affective connection with their work organization, suggesting that neither insider identity nor affective commitment alone can fully maximize the effects of employees’ psychological cognition and emotion (e.g., stimulating innovative behavior). They complement each other and together have a more powerful effect than either one alone. Therefore, exploring employee innovative behavior should consider not only the individual impact of perceived inside status and affective commitment but also their interaction. Based on this logic, I expect that:\n\nH5a: Resonant leadership is positively related to interaction between perceived inside status and affective commitment.\n\nH5b: Interaction between perceived inside status and affective commitment is positively related to teachers’ innovative behavior.\n\nH5: The interaction between perceived inside status and affective commitment plays a mediating role between resonant leadership and teacher innovative behavior.\n\nBased on the above analysis, the proposed hypothesized theoretical model is illustrated inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321763.g001\n\nThis study targeted primary and junior high school teachers across mainland China, where regional disparities in educational resources and leadership practices provide a critical context for examining innovation dynamics. We employed stratified random sampling to ensure representation from 16 provinces (50% of China’s 32 provincial units), covering eastern (high-resource urban areas), central (transitional zones), and western (under-resourced rural regions) areas.\n\nThe data collection process spanned 14 weeks (February 5 to May 13, 2024) through a self-administered electronic questionnaire distributed via provincial education bureaus’ official platforms, structured into three phases. During the initial two-week preparation phase, we developed the questionnaire using Sojump and conducted a pilot test with 120 teachers to refine clarity and reliability (Cronbach’s α > 0.80 for all scales), collaborating with provincial authorities to secure permissions and coordinate logistics. Subsequently, over eight weeks, invitations were systematically emailed to 5,328 teachers across 16 Chinese provinces (50% of mainland China’s administrative regions) using stratified sampling to ensure regional representation (eastern, central, western). Participants accessed surveys through unique links requiring approximately 15 minutes to complete, with biweekly reminders and ethical safeguards including digital consent forms and anonymized randomized IDs. To ensure data quality, we implemented dual validity checks: automated detection via Sojump filtered 312 responses with duplicates/blank patterns, while manual review eliminated 247 responses exhibiting patterned answers (e.g., straight-lining), aligning with predefined criteria (≤50% missing items, ≤90% response duplication via Qualtrics XM’s fraud detection). This rigorous process yielded 4,769 valid submissions (89.5% validity rate).\n\nThe study used a five-point Likert scale (ranging from 1 to 5) to measure resonant leadership, teachers’ innovative behavior, perceived inside status, and affective commitment. The scales for resonant leadership, affective commitment, and perceived inside status were translated into Chinese and then back-translated into English by three bilingual graduate students [39]. In this section, we analyzed the reliability and validity of the four questionnaires. For confirmatory factor analysis (CFA), we adopted the model fit criteria recommended by Wen, et al: chi-square model fit criterion (χ2)/degree of freedom(DF)≤3, comparative fit index (CFI≥0.90), standardized root mean square residual (SRMR≤0.08), and root mean square error of approximation (RMSEA≤0.08) [40].\n\nThe scale used to measure principal resonant leadership comprised 10 items divided into four dimensions [41]: (a) self-awareness, (b) social consciousness, (c) self-management, and (d) relationship management. The scale demonstrated high internal consistency with a coefficient α of 0.91. The CFA yielded satisfactory results, indicating good validity: χ2/DF =1.93, RMSEA= 0.07, CFI= 0.99, SRMR= 0.02, and RMSEA=0.06.\n\nWe assessed teachers’ innovative behavior using a 23-item scale adapted from Li [42]. This scale, developed within the Chinese context, demonstrated strong reliability and validity. It encompassed two dimensions: innovative idea generation, innovative idea implementation. The scale exhibited high internal consistency, with a coefficient α of 0.88. The CFA yielded satisfactory results, indicating good validity: χ2/DF = 1.79, RMSEA= 0.01, CFI= 0.89, and SRMR= 0.02.\n\nIn this study, we employed the affective commitment scale developed by Meyer, et al [43]. The scale comprises 5 items, with higher scores indicating a greater prevalence of affective commitment among teachers. The internal consistency of the scale in our study was strong, with a coefficient α of 0.90.\n\nIn this study, we employed the perceived inside status scale developed by Stamper, et al [26]. The scale comprises 6 items, with higher scores indicating a greater prevalence of perceived inside status among teachers. The internal consistency of the scale in our study was strong, with a coefficient α of 0.839.\n\nPrevious research found that demographic characteristics, such as teachers’ gender, education, tenure, can influence teachers’ innovative behavior [44]. To ensure a comprehensive analysis, this study treated gender (as a binary variable), tenure (as a nominal variable), and education level (also as a nominal variable) as control variables. Dummy variables were created for each of these factors, with “female” “≤ 3” and “Undergraduate” serving as the reference groups respectively.\n\nThis study adheres to the principles outlined in the Declaration of Helsinki and obtained approval from the Human Research Ethics Committee of Longgang Institute of Education Sciences, Shenzhen (Approval No.: 202312280039). All participants, who were K-12 teachers, provided written informed consent before completing the survey. The consent forms outlined the purpose of the study, the rights of the participants, the confidentiality of the data, and how the data would be used. All consent forms are on file and were witnessed by an independent third party. Participants had the option to withdraw from the study at any time. Additionally, our data underwent rigorous anonymization procedures to ensure the utmost participant privacy.\n\nDescriptive statistics, including numbers and percentage distributions, were utilized to characterize the demographic features. For measurement data that followed a normal distribution, the mean ± standard deviation [M (SD)] was employed. Common method bias was assessed via Harman’s single-factor test [45], with a threshold of 40% variance explained. Confirmatory factor analysis (CFA) was conducted to evaluate discriminant validity. Pearson correlation analysis was applied for normally distributed variables, while Spearman correlation analysis was used otherwise. Structural equation modeling (SEM) was employed to test hypothesized relationships among resonant leadership (RL), teachers’ affective commitment (TAC), perceived inside status (PIS), and innovative behavior (TIB) using AMOS 28.0. PROCESS plug-in mediation effect analysis [46] was used to test mediation effects, with statistical significance set at p<0.05 (two-tailed).\n\nThe final sample comprised 4,769 teachers. Most respondents came from eastern China (52.02%), while others were from central China (29.89%) and western China (19.09%). These proportions reflect the population distribution across different regions in China. The sample predominantly comprised female teachers (n=3,923) compared to male teachers (n=846), mirroring the gender distribution among primary school educators nationwide. Most teachers possessed at least a bachelor’s degree (86.4%). More than half of the participants had teaching experience exceeding ten years (52.2%).\n\nBefore initiating the analysis of structural equation modeling (SEM), it is imperative to consider several data-related issues.\n\nFirstly, the issue of common method biases (CMBs) often arises when utilizing questionnaires for data collection. To address CMB, this study implemented rigorous procedural controls during the data collection process. Furthermore, Harman’s single-factor test was conducted as a means of validation [45]. The results of the unroasted exploratory factor analysis revealed the extraction of 8 factors with eigenvalues exceeding 1.0. However, it is noteworthy that the maximum factor accounted for only 31.69% of the variance, falling below the established threshold of 40%. Therefore, it can be concluded that CMBs did not exert a significant confounding influence on the empirical findings obtained in this study.\n\nSecondly, a confirmatory factor analysis (CFA) was conducted to ensure the distinctiveness of the four variables in this study. The model fit was evaluated using the indices recommended by Wen et al. [40]. As shown inTable 1, the baseline model (four-factor model) demonstrated a satisfactory fit for the four-factor structure (χ2/DF=1.73, RMSEA=0.03, CFI=0.91, IFI=0.94, NFI=0.95), outperforming alternative models and indicating good discriminant validity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321763.t001\n\nFurthermore, the sample size in this study met the minimum requirement (n=200) for SEM as suggested by Hu et al. [47] and Kline [48]. We used a probability–probability (PP) plot to assess our data’s conformity to a normal distribution. The detruded PP plot showed that the deviations in our data samples for the four variables were within the range of −0.15 to 0.05, indicating their basic conformity to the normal distribution.\n\nThe means and standard deviations of the four main variables in this study are presented inTable 2, along with their respective correlations. These correlation coefficients provide empirical support for further hypothesis testing.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321763.t002\n\nTo test the hypotheses, SEM and bootstrapping tests were conducted following Preacher et al. [49] recommendations. The standardized effect sizes produced by these estimates were comparable to those produced by SEM. The bootstrapping test involved calculating the indirect effects of the independent variables using resampling estimation technique to generate confidence intervals (CIs). In this test, point estimates of total, indirect, and direct effects represented the mean of a bootstrap sample of 5,000 [50].\n\nThe SEM model fitting indices for the impact of resonant leadership on teachers’ innovative behavior, with perceived internal status and affective commitment as mediating variables, were χ2=1793.86, RMSEA= 0.06, CFI= 0.93, SRMR= 0.04. These indices indicate that the model meets the criteria and is suitable for further interpretation based on recommended values.\n\nThe results indicate a significant positive correlation between resonant leadership and teacher’s innovative behavior (γ= 0.39, p<0.01), supporting H1. Resonant leadership also correlates positively with perceived inside status (γ= 0.49, p<0.001), supporting H2a. Perceived inside status is significantly correlated with teacher’s innovative behavior (γ= 0.58, p<0.001), supporting H2b.Resonant leadership further shows a significant positive correlation with affective commitment (γ=0.42, p<0.001), providing support for H3a. Affective commitment is significantly correlated with teacher’s innovative behavior (γ= 0.44, p < 0.001), supporting H3b.\n\nIn order to examine the mediating role of resonant leadership in teachers’ innovative behavior, we utilized the mediation analysis method proposed by Wen et al. [40]. The Process program was used for analysis, specifically Model 4 and Model 6, to determine the specific mediating effects of each variable. Bootstrap resampling with 5000 samples was employed, while a confidence interval of 95% was set. The combined analysis results using model4 and model6 are shown inTable 3.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321763.t003\n\nThe confidence interval for the main effect of resonant leadership on teachers’ innovative behavior does not include 0, indicating a significant impact. Hypothesis H1 is supported once again. When considering intermediary variables such as perceived inside status, affective commitment, and their interaction terms, the confidence interval for the total indirect effect also excludes 0, suggesting a significant indirect effect. Specifically, the indirect effect 1 had a significant effect value of 0.07, as the bias-corrected 95% CI interval did not include 0, confirming the significance of H2. The indirect effect 2 also showed significance with an effect value of 0.09 and a bias-corrected 95% CI interval that did not include 0, confirming H3. Similarly, the indirect effect 3 had an effect value of 0.12 and a bias-corrected 95% CI interval that did not include zero, supporting the significance of H5. Lastly, the indirect effect 4 had an effect value of only 0.03 but still demonstrated significance as its bias-corrected confidence interval excluded zero. Furthermore, based on difference testing and standardization coefficients associated with each mediator variable, it can be concluded that the interaction between perceived inside status and affective commitment exerts the most substantial influence.\n\nOur study uncovered a robust positive relationship between resonant leadership and teachers’ innovative behavior, indicating that the demonstration of resonant leadership by principals significantly promotes and nurtures such behavior. This finding is consistent with relevant research conducted in diverse cultural contexts [51,52], thereby enhancing the credibility and reliability of the findings. By fostering a supportive and emotionally engaging environment, resonant leaders can directly encourage teachers to adopt more innovative practices, contributing to a more dynamic and adaptive educational setting. This direct effect highlights the critical role of leadership in driving innovation within schools, emphasizing the potential of resonant leadership as a powerful tool for educational transformation.\n\nWe have identified a mechanism by which resonant leadership influences teachers’ innovative behavior. The perception of internal status and affective commitment independently mediate the relationship between resonant leadership and teachers’ innovative behavior, playing both a chain-mediated and interactive-mediated role. Collectively, these four mediated paths account for 59.61% of the total impact effect with the interactive mediation being the most significant. This finding aligns with the predictions and theories of information processing [12]. Unlike much of the existing literature, which primarily focuses on the personality and psychological characteristics of employees, our study delves into the psychological processes, specifically the interaction between cognitive and emotional factors. By applying the information processing theory, we provide a deeper understanding of how resonant leadership influences teachers’ innovative behavior. This research not only advances the systematic study of leadership’s impact on employee innovation but also extends the application of information processing theory to the field of education, enriching its scope and practical relevance.\n\nThe innovative finding of this study highlights the significant mediating role of the synchronic interaction between insider identity and affective commitment, which is the most impactful among the four mediating paths, accounting for 38.71% of the total effect. This finding is crucial as it deepens our understanding of the mechanisms through which resonant leadership influences teachers’ innovative behavior within the school context. Our results provide robust empirical support for the information processing theoretical framework proposed by Mischel, et al. [12], which posits that cognitive and emotional units dynamically interact within an individual’s psychological structure, jointly influencing decision-making and behaviors. The synchronic interaction between insider identity and affective commitment reveals a unique and powerful pathway, underscoring the importance of both cognitive and emotional processes in shaping teachers’ innovative behavior. These findings contribute to the broader literature on leadership and innovation by demonstrating the critical role of a holistic cognitive-affective approach in fostering a supportive and innovative educational environment. Resonant leaders, through their empathetic and emotionally intelligent leadership, create a context that leverages both cognitive and emotional factors, leading to increased teacher innovation and organizational success.\n\nFirstly, our study establishes a solid foundation for principals’ self-improvement and development, enabling them to engage in reflective practices regarding their resonant leadership and strive for continuous improvement. Through an analysis of the four empathic ways in which leaders’ cognition and emotion interact, this paper validates the positive impact of resonant leadership on enhancing teachers’ innovative behavior. Consequently, education administration departments could implement graded and classified resonant training programs, such as monthly reflection sessions and role-playing exercises, to standardize the process and provide comprehensive content guidance. This will foster school leaders who possess both exceptional talent and emotional intelligence, thereby better serving the innovative development of teachers’ profession. In promoting principals, attention could be given not only to their management skills but also to their emotional intelligence and proficiency in handling organizational conflicts.\n\nSecondly, our study provides valuable insights for principals on how to foster teachers’ innovative behavior. Principals could prioritize enhancing teachers’ internal identity perception and affective commitment, as well as motivating them to engage in innovative practices. In the context of China’s relationship-oriented culture, teachers place great importance on their connection with the school. The notion of being an “insider” within the school community can stimulate teachers’ sense of responsibility towards the institution, strengthen their identification and emotional attachment to it, and encourage behaviors that benefit the organization. For example, principals can organize regular team-building activities, such as workshops and social events, and set up a teacher lounge with amenities like coffee machines and comfortable seating. On one hand, schools can enhance recruitment, training, promotion, reward and punishment mechanisms by implementing appropriate and effective human resource management practices. They can also create a cooperative, open-minded, harmonious, and inclusive environment that supports teacher development while fostering their internal identity perception and emotional attachment to the school. On the other hand, principals could attend to both material and spiritual needs of teachers by continuously improving their well-being. Recognizing and valuing teachers’ contributions through annual awards and public recognition can enhance their sense of belongingness and attachment to the school.\n\nFinally, our study highlights the significance of synchronic interaction between insider identity and affective commitment as a crucial link between resonant leadership and teachers’ innovative behavior. Therefore, in terms of school management, principals need to strengthen the internal governance structure of schools, encourage teachers to participate in decision-making and school management, and adopt various effective measures to comprehensively cultivate teachers’ perception of insider identity and affective commitment to the school. For example, principals can establish a Teacher Advisory Board to involve teachers in key decisions, hold regular school hall meetings to gather feedback, and provide opportunities for teachers to lead professional development sessions.\n\nWhile this study provides valuable insights into the mechanisms through which resonant leadership influences teachers’ innovative behavior, several limitations should be acknowledged. First, the sample was drawn from a single country, which may limit the generalizability of the findings. Cultural factors, such as the degree of collectivism versus individualism, can significantly influence the effectiveness of leadership styles and the nature of workplace relationships. For example, in collectivist cultures, where group harmony and interdependence are highly valued, the impact of resonant leadership on teachers’ sense of insider identity and affective commitment might be more pronounced. Conversely, in individualistic cultures, where personal achievement and independence are emphasized, the effects of resonant leadership might manifest differently. To address this limitation, future research should include schools in different countries and cultural contexts. This would provide a broader perspective and allow for a more comprehensive understanding of how resonant leadership operates in various educational environments. Additionally, future studies could explore the specific cultural dimensions that moderate the relationship between resonant leadership and teachers’ innovative behavior, such as power distance, uncertainty avoidance, and long-term orientation. By examining these cross-cultural differences, researchers can develop more nuanced and culturally sensitive strategies for fostering innovation in schools.\n\nFurthermore, this study relied on self-reported data, which may be subject to response biases. Future research could incorporate multiple data sources, such as peer evaluations and observational data, to provide a more robust and multi-faceted understanding of the phenomena under investigation. Finally, longitudinal designs could be employed to examine the long-term effects of resonant leadership on teachers’ innovative behavior and to track changes over time.",
    "category": "education"
  },
  {
    "title": "Community health systems and priority setting for elderly healthcare services in rural Tanzania: Experience from Nzega and Igunga districts",
    "authors": "Malale Tungu, Nathanael Sirili, Amani Anaeli, Gasto Frumence, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321482",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321482",
    "content": "In the 1990s, Tanzania adopted health sector reforms with the aim of engaging the local communities in priority setting and decision-making for effective and efficient use of resources. Community engagement aims to enhance community voice and efficiently allocate available resources according to the citizen’s demands to achieve the targeted health outcomes. The Community Health Systems (CHS) aim to strengthen Primary Health Care (PHC) services by empowering all community actors close to and serving community members. This study explored the role of the CHS during priority setting process in improving health services for the elderly in rural Tanzania.\n\nAn exploratory case study design was employed to collect data using Key Informants Interviews (KIIs) in Nzega and Igunga districts. Purposeful sampling was used to select participants from the two districts. Twenty-four (12 from each district) interviews were conducted with community representative members of the Health Facility Governing Committee (HFGC), social welfare, Council Health Management Team (CHMT), District medical officers, Medical Officers in-charge (MOI), planning officers and health system information focal person. All audio recorded interviews were transcribed verbatim. The transcribed interviews were translated from Kiswahili to English. The data were analyzed using the content analysis approach. The transcribed data, field notes, and documents were reviewed and read to identify broad areas in which to form initial codes and codes. Similar codes with related concepts were grouped to form initial categories and categories.\n\nThe findings of this study demonstrated the importance of CHS in strengthening community participation in identifying the elderly who are in need in the community and been involved in elderly matters during priority setting of the elderly health services through the health facility governing committee. This means that there was community participation in elderly matters especially to help the elderly reach health facilities and during priority setting, positive and negative perceptions among community members about the elderly agenda during priority setting. In addition, the findings show that there is poor awareness among community members including family members who perceive that the government is responsible for providing health services to the elderly and not the community or family members.\n\nThe findings of this study indicate the importance of community during the priority setting process which plays a great role in identifying the elderly who are in need and the most needed health services for the elderly in their communities. Therefore, the Local government authority should fully involve CHWs in collaboration with all community actors to address elderly matters in rural areas and improve elderly healthcare services. The community members have to be educated and raise awareness about elderly health matters through different platforms such as during world elderly day, village meetings and at the health facility level.\n\nCitation:Tungu M, Sirili N, Anaeli A, Frumence G (2025) Community health systems and priority setting for elderly healthcare services in rural Tanzania: Experience from Nzega and Igunga districts. PLoS ONE 20(4):\n           e0321482.\n        \n        https://doi.org/10.1371/journal.pone.0321482\n\nEditor:Kanchan Thapa, Noble Shivapuri Research Institute, NEPAL\n\nReceived:August 5, 2024;Accepted:March 5, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Tungu et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors declare that they have no competing interests exist.\n\nGlobally, community participation in health systems during priority setting has a crucial role, especially in less developed countries where most of the governments fail to provide adequate and quality healthcare services for their people [1–3]. Community health systems have been a central theme in most world health-related discussions which is in the World Health Organization (WHO) constitution, confirmed in the Alma-Ata Declaration whereby people are urged to participate individually and collectively in the planning and implementation of their healthcare services [4–6]. Tanzania and other developing nations adopted health sector reforms in the early 1990s. Among other aspects, the reforms aimed to engage the local community in the priority setting and decision-making for effective and efficient use of resources [7,8]. The community participation is aimed at enhancing community voice, empowering marginalized groups including the elderly, efficient allocation of the available resources as per citizen’s demand, improving health service and subsequently improving the quality of healthcare at the lower levels [1]. Part of these reforms was decentralization by devolution whereby the districts were regarded as the focal point for the planning and implementation of all health programs which combine all local levels including the health facility level, community level, village and ward level [9,10]. Decentralization by devolution focused on improving community-level health services as a key component of overall health systems strengthening [8,10,11]. The current idea of CHS aims to strengthen Primary Health Care PHC) services by empowering Community Health Workers (CHWs) towards Universal Health Coverage (UHC) [12].\n\nIn Tanzania, community participation is considered a significant dimension in healthcare planning and priority setting for decision-making within CHS under decentralized healthcare systems across the country. The government of Tanzania is pushing accountability for the planning and distribution of health services closer to the communities. Civil Society Organizations (CSOs) and community actors are being asked to play a greater participatory role in these processes of priority setting and planning by considering vulnerable groups including the elderly [13]. The country extended PHC services at the grassroots level by expanding frontline health facilities and training CHWs to conduct community outreach [14].\n\nEvidence from previous studies have presented empirical evidence on the importance of priority setting in local governments through community participation. Decentralization has the reputation of building a relationship between policy-makers at the district level and the local levels through the prioritization process that starts from the community level. The Local Government Authorities (LGAs) aimed at increasing the participation of the community including representatives of special groups such as the elderly, women, youth, disabled, and other stakeholders in setting priorities for healthcare services. Studies show that there is no full participation of the community and other stakeholders in priority setting at the district level [13,15]. In principle, the priority setting process should be based on the guiding principles and criteria including the burden of diseases, magnitude and severity of the problem for equitable distribution of the available scarce resources. However, the process of priority setting is sometimes driven by the historical allocation of mobilized resources at the district level, which lacks appeals mechanisms [15]. This implies that the allocation of resources is based on what was allocated in the previous financial years regardless of the reality of the contemporary dynamics.\n\nDistrict councils identify the priorities and plan how the mobilized scarce health resources can be allocated for health services to meet local health needs [16]. The Council Health Management Team (CHMT) is responsible for planning, implementing, monitoring, and evaluating healthcare services at the council level. The teams perform their responsibilities, by involving different stakeholders at every stage of planning, and budgeting. This ensures that various priorities from the community are incorporated into the planning process and subsequently included in the budget. Decentralized health governance aims to engage communities (through representatives) in council health planning, budgeting, and monitoring processes.\n\nThe CHS is a set of different local actors and processes engaged in producing, advocating for, and supporting health in communities and households outside the formal health system [17,18].Community Participation is a function of different groups including public health officials, local organizations, community health leaders, private sector providers, civil society, and frontline workers who are central in identifying and addressing healthcare issues within their areas [19].\n\nTanzania is among developing nations in which priority setting in healthcare delivery systems is important in ensuring the proper allocation of scarce resources for the provision of responsive health services. Priority setting is the process of formulating systematic rules to decide on the distribution of limited healthcare resources among competing programs or patients [20]. Priority setting focuses on either health or utility depending on whether the decision-maker believes that resource allocation should depend only on the utility obtained by individual people (i.e., welfarism) or depend on factors other than a utility like health (i.e., extra-welfarism) [21].\n\nIn priority setting, welfarists explain that the goodness of any state should be judged based on the utility level attained by individuals. Extra-welfarists believe that health outcomes should be more relevant than utility in assessing policies in the health sector [22]. This means that the priority setting process should not consider only the individual demand, but the need for health systems for the allocation of resources in the health sector by considering different criteria [23–26]. The stated criteria include the magnitude of the problem (proportion of people affected by a problem), severity or danger of the problem (how serious the condition is), vulnerability to intervention, equity issues, acceptability by the targeted consumers, the cost of the intervention compared to the health outcomes and political will of the intervention.\n\nProper priority setting is compelled to ensure financial protection for vulnerable groups including the elderly population. In Tanzania, most of the elderly live in rural areas with poor health services, high rates of chronic diseases and poor economic conditions. It is therefore imperative that the process of priority setting is obliged to take into consideration community members with special attention to the elderly group. Studies on the role of CHS during priority setting process at the district level are scanty and not specific to the improved healthcare services of the elderly in rural areas. Most of them are based on the priority setting process regarding accountability for reasonableness from the experience of the CHMT and decision-makers at the district level [15], actors and contextual factors for healthcare priority setting at local levels [27], priority setting process for family planning, maternal, new-born and child health at the decentralised health system [16]. Other studies on elderly health status but not specific for the role of CHS in priority setting process to improve the health services for the elderly [28–30]. This study therefore aimed at exploring the role of the CHS during the priority setting process in improving health services for the elderly population in rural Tanzania.\n\nAn exploratory case study design using Key Informants Interviews (KIIs) was employed in this study. A case study using two districts of Nzega and Igunga was found appropriate in understanding how the community is being involved in setting priorities regarding health services, particularly for the vulnerable population including elderly people. In other words, this design enabled the research team to explore contextual issues regarding priority setting at the community level. Additionally, considering that priority setting is a complex phenomenon involving social processes, the case study approach was found relevant for this study [31].\n\nThis study was conducted in Nzega and Igunga Districts located in Tabora region. The two districts were the relevant districts for a case study in Tanzania since they have most of the rural settings with scattered households. According to NBS [32,33], the total population in Nzega District was 502,252 in 2012 and 699,691 in 2022 while in Igunga was 399,727 in 2012 and 546,204 in 2022. Among these populations, about 6 per cent and 5 per cent of the total population are the elderly above 60 years and above in Nzega and Igunga districts, respectively which is almost the same as the nation of 5.7 per cent. Among the elderly population in Nzega and Igunga districts, about 72 per cent live in rural areas [34]. The elderly in rural areas are characterized with poor health and limited resources to meet healthcare costs. This was among other factors considered in this study, which was conducted in Nzega and Igunga districts to explore the role of the CHS during priority setting, especially in the rural areas where the majority of elderly people are living.\n\nThe study adopted purposive sampling in selecting participants for data collection. We purposively selected Key informants who were responsible for the priority setting process from the community to the council level. The study population were purposefully selected based on their day-to-day roles in the priority setting process for elderly health services in the community. If the cadre had more than one participant, the one who was in charge was selected to represent the others in the department. For each district, the following participants were selected: 1 District Planning Officer (DPLO), 1 District Medical Officer (DMO), 1 Medical Officer In-charge (MOI), from the District Hospital 1 Health Management Information System (HMIS) focal person, 1 District Social Welfare Officer (DSWO), 2 Health Facility Governing Committee (HFGCo) members, 1 District Health Secretary (DHS), 1 Hospital Secretary (HS), 1 Council Health Service Board (CHSB), and 2 members from Council Health Management Team (CHMT). This makes 12 participants from each district with an overall total of 24 participants from the two districts. Among the 24 participants, 7 were female and 17 were male, all of whom had experience in the role of CHS during the priority setting to improve health services among the elderly. The community representatives from HFGCo and CHSB represented the CHS.\n\nThis study used the Key Informant Interview (KII) guide to explore information on the role of the CHS in the planning process and priority setting to have improved health services for the elderly in rural areas from the study participants. We started by reviewing the documents to familiarize ourselves with the decision-makers on the role of CHS in priority setting and planning. The participants were asked about their experience with the role of the CHS during the priority setting process in improving health services for the elderly in rural Tanzania. The topics covered included the participation of the community in the priority setting related to elderly matters, community perceptions and awareness about the elderly, and the role of CHWs in addressing elderly matters within the community. Key informant interviews were conducted between July and August 2020. Four researchers (whereby two were faculties and two were Master’s Graduates) conducted the interviews. The faculties facilitated the interview while others facilitated the audio recording of the interviews, taking notes on the key themes, asking additional questions and monitoring any interaction. After attaining information saturation of the categories since there was no new information that was coming and thus stopped data collection at 24 respondents, 12 from each district. Study participants were purposively selected based on their experience and role in priority setting from the community to the district level. The key informant interviews with participants working in district councils were conducted in their offices, while others were conducted in selected offices suitable for the interview. All KII were conducted in the Kiswahili language which is widely understood by the majority of ordinary Tanzanians. All KII were audio-recorded using a digital voice recorder and the duration of the interview ranges from 50 to 74 minutes. The research team included a moderator and assisted by a note taker who recorded in the notebook all important issues that emerged during the interview. Debriefing sessions were conducted after every interview for consistency, quality control and capturing new information. In addition, to ensure the trustworthiness of the findings, the study included many participants including members of the different committees, whereby most of them are part of the community based on their experience in the priority setting process at the local level. This study is transferable due to the detailed background data and in-depth methods description to ensure the reliability of the study for further researchers to replicate the study.\n\nAll audio recorded interviews were transcribed verbatim. The transcribed interviews were translated from Kiswahili to English. Data were analyzed using the content analysis approach. This approach is used to determine the presence of concepts within texts or a set of texts which limit bias. The approach helped to develop categories from the text data inductively for capturing the experiences of the participants. In addition, this approach entails the interpretation of the content of text data through a systematic classification process of coding and identifying themes or patterns [35,36]. Using the NVivo software, the transcribed data, field notes and documents were carefully reviewed and read to identify broad areas to form initial codes and codes. Similar codes with related concepts were grouped to form initial categories and categories.\n\nEthical clearance was obtained from the Muhimbili University of Health and Allied Sciences (MUHAS research review board) in June 2020 (MUHAS-REC-6-2020-288). Permission for data collection in Tabora region was granted by the Regional Administrative Secretary. Permission for data collection was granted by the District Executive Directors of the Igunga and Nzega districts. Participants were duly informed of the purpose of the study and their rights. Written informed consent for this study that includes data collection and consents to participate was requested and obtained from the participants and they were assured of their anonymity in publications.\n\nThe summary of the study findings is presented inTable 1which indicates the content analysis process for the categories. The findings are structured into five categories, namely; community participation in elderly healthcare matters, community participation in the priority setting on elderly healthcare matters, community perceptions about the elderly agenda, community awareness about the elderly and less involvement of the CHWs in the elderly healthcare services in the community. This study involved 24 (7 female and 17 male) respondents who are involved in making decisions and setting priorities at the district level.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321482.t001\n\nThe findings of this study show that community members are involved in various issues concerning elderly healthcare matters. These include helping the elderly to reach the health facility where necessary, providing information about the elderly who are in need, and sometimes contributing an amount of money especially for the elderly who are poor to cover some basic expenses for their health.\n\n“At the village or community level, some elderly individuals are being assisted by their neighbors to reach the health facilities …sometimes the neighbors or community take the responsibility to cover some costs to buy medicines or transport, especially to the elderly who are in need” –(KI#12).\n\nCommunity members play a vital role in the priority setting process during planning for the health services at the lower level including elderly healthcare services through the health facility governing committee. This includes the identification of the elderly who are supposed to be prioritized, providing data on the common problems which affect the elderly in their localities and providing information about the availability of the elderly who are living with difficulties in their localities. Further, the community helps to promote democracy and transparency during identifying the elderly since the process is done at different gatherings and meetings at their localities.\n\n“The community plays a crucial role in the priority setting process, as it initiates at the community level and progresses through the village to the district level. Therefore, the community play a significant role in identifying the elderly individuals eligible for waivers and exemptions, as well as providing information on health problems affecting the elderly in their community…therefore, the elderly matters are recognized at the community level since the elderly are the community…” -(KI#9).\n\nThe participants reported that there is the existence of different perceptions about the elderly agenda during the priority setting process which may affect positively or negatively the provision of health services to the elderly. Some of the community members recognize the importance of the elderly in the community for their vision and wisdom. On the other hand, some of the community and family members perceive the elderly as not an important group to be prioritized over other groups like under 5 years children and pregnant women. In many cases, some of the community members perceive that most of the elderly people are witches. In addition, sometimes the community including family members perceive that the government is responsible for helping the elderly and not the community or family members.\n\n“…It is true that the elderly group needs to be considered and supported by the community and other decision - making levels. However, it is a group that is not prioritized starting from the family level through community, village and up to the council level. At the community and family level, elderly have been perceived as witches, which may affect the prioritization process…. during the reallocation of funds, it is rare to consider elderly matters, as there are other groups also in need of attention for their health…”- (KI#7).\n\nThe results of this study show that community members are not well aware about the government’s responsibility for elderly healthcare services. This brings some confusion on the responsibilities of the family and community members for the elderly in accessing free healthcare services. This low awareness of the community members about elderly health services makes it difficult for them to understand when it comes to the elderly missing some of the services at the health facilities. For example, when the elderly miss access to medicines while the elderly with NHIF access. At the same time, the central government insists the LGAs supervise the free health services to the elderly without specific funds for the elderly. The community and some of the family members think that the government is responsible for taking care of all the elderly.\n\n“…sometimes it becomes difficult for the community to contribute to the elderly healthcare services because they know that healthcare services for the elderly are free and the government is responsible for taking care of the elderly...” (KI#16).\n\nThe participants also reported that the CHWs were supposed to play a great role in the community to help with outreach programs which may include helping the elderly with health problems who need immediate help. The challenge with the CHWs are temporarily engaged by partners on a contract basis in the specific programs in which they are not dealing with elderly healthcare services. This led to less involvement of the CHWs in the elderly matters.\n\n“...during outreach programs and other community programs implementation, most of the CHWs focus on programs related to pregnant women, HIV, vaccinations, mothers and children. CHWs are less involved in elderly matters due to budget constraints from the government. Another challenge is the scarcity of CHWs in the community, coupled with numerous activities”- (KI#3).\n\nThis study explored the role of CHS on priority setting process to improve health services among the elderly. It highlighted the main findings including community participation on elderly matters, community participation on priority setting of the elderly health services, community perception of the elderly agenda, community awareness about elderly matters and the role of the CHWs on the elderly matters in the community. This study indicate that community members are involved in helping the elderly matters including helping the elderly reach the health facility where necessary, providing information about the elderly who are in need and covering some basic expenses for their health. These results are supported by other studies which indicated that the poor elderly can be helped by the community members where necessary to improve their health [17,19,37–39].\n\nAnother finding of this study indicates the importance of CHS during the priority setting process, which plays a significant role in identifying the elderly in need and determining the most necessary health services for them in their communities. This is due to the fact that most of the elderly live in communities where can be identified easily with their health problems and their ability to pay for healthcare services. The Community play a role in identifying these elderly and suggesting the best solutions according to their localities. The findings are consistent with previous studies [13,17,19,40] which indicates the importance of the community in the priority setting process which suggests reasonable measures for the community and simplifies the monitoring and evaluation process according to the community needs especially for the vulnerable people in the community like the elderly.\n\nFurthermore, the study also indicated the community’s perception of the elderly agenda as a challenge. Although there are some community members who perceive that the elderly are important in the community of their wisdom, however, there are some community members who perceive that elderly matters/agenda are not very important to the community since there are so many other health needs to be improved like children’s health programs who are considered to be the next generation and pregnant women. These findings corroborate other studies [41] that indicates the same perceptions from the community that the elderly are not productive in the community.\n\nAnother finding of this study revealed that there was community awareness about elderly matters. Most of the community and family members are not well aware of their responsibilities and the government’s responsibilities to the elderly. Most of the community members think that there is only one organ which is responsible for the elderly matters. These findings are supported by other studies [39,42–44] which indicated the same results that family members and community members think that they are not responsible with the elderly healthcare services.\n\nLastly, the study found that CHWs are less involved. The main challenge with CHWs is that most CHWs are responsible for other health services than elderly matters. This is due to the fact that CHWs are temporarily engaged in specific programs on a contract basis. If they were to be utilized efficiently, they could be very important people in the community who can help with elderly matters and improve the provision of elderly healthcare services. The results corroborate with other studies which indicate the importance of CHWs in a community and how they could be beneficial to the elderly health services [42,45–47]. Most of the studies indicate that CHWs are not well involved in elderly matters due to financial problems at the lower levels with no specific budget to cover their daily expenses since they are not permanently employed [48–51].\n\nIn this study, we acknowledge the fact that some efforts have been made by the government to engage the community in improving the health services for the elderly, including the involvement of CHWs at local levels. Despite all these efforts by the government, there still exist challenges facing the CHS during priority setting process for the improvement of health services for the elderly. One of the challenges is that although some community members perceive that the elderly are important in the community for their wisdom, however, some community members perceive that elderly matters/agenda are not important to the community due to competing with other health needs like children’s health programs. Another challenge was community awareness about elderly matters whereby most of the community and family members are not well aware of their responsibilities and the government’s responsibilities to the elderly. In addition, there is less involvement of the CHWs who are responsible for other temporary health services than elderly matters. The government should improve community engagement, especially CHWs during the priority setting process who are close and aware of the health needs in the community. This can be improved by employing a few CHWs in each village with permanent employment to improve CHS at lower levels. This will help to improve CHS with early identification of the health problems of the vulnerable groups including the elderly for further access to health services. Also, these CHWs will help to provide awareness among community platforms.\n\nOne of the strengths of this study is that it has provided valuable information that will contribute toward improved community participation during the priority setting process to have improved health services for the elderly in rural areas. The study also revealed several challenges facing the CHS including negative perceptions among community members on the elderly agenda, low community awareness of elderly matters in terms of their responsibilities on improving health services of the elderly and low involvement of the CHWs on improving health services of the elderly. The respondents of this study were among people who are responsible for policymaking at the district level which may act as a limitation of the study since such respondents are likely to be defending the ways they run things. They may describe the role of the CHS during priority setting in improving health services for the elderly. However, the findings of the study provided an understanding of the role of CHS during priority setting to have improved healthcare services for the elderly. To address the limitations the study included many participants including members of the different committees, whereby most of them are part of the community.\n\nThis study highlighted the role of CHS during the priority setting process to improve health services among the elderly including community participation on elderly matters, community participation on priority setting of the elderly health services, community perception of the elderly agenda, community awareness about elderly matters and the role of the CHWs on the elderly matters in the community. This indicates that the CHS plays a great role during the priority setting process on elderly matters to have improved health services for the elderly including suggesting the best solutions according to their localities. Therefore, the government should involve fully the CHWs to strengthen the CHS which may help the elderly healthcare matters in rural areas to improve elderly healthcare services. In addition, the community have to be educated in order tocreate awareness and positive perception about the elderly agenda and matters through different platforms such as during world elderly day, village meetings, posters, brochures and at the health facility.\n\nhttps://doi.org/10.1371/journal.pone.0321482.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321482.s002\n\n(DOCX)\n\nWe are grateful for the support of the District Executive Directors and Health Managers from Nzega and Igunga Districts in Tanzania.",
    "category": "geography"
  },
  {
    "title": "Geographical and disciplinary coverage of open access journals: OpenAlex, Scopus, and WoS",
    "authors": "Abdelghani Maddi, Marion Maisonobe, Chérifa Boukacem-Zeghmouri, (PLOS)",
    "publish_date": "2025-04-14",
    "doi": "https://doi.org/10.1371/journal.pone.0320347",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320347",
    "content": "This study aims to compare the geographical and disciplinary coverage of OA journals in three databases: OpenAlex, Scopus and the Web of Science (WoS). We used the Directory of Open Access Scholarly Resources (ROAD), provided by the ISSN International Centre, as a reference to identify OA active journals (as of May 2024). Among the 62,701 active OA journals listed in ROAD, the WoS indexes 6,157 journals, Scopus indexes 7,351, while OpenAlex indexes 34,217. A striking observation is the presence of 24,976 OA journals exclusively in OpenAlex, whereas only 182 journals are exclusively present in the WoS and 373 in Scopus. The geographical analysis focuses on two levels: continents and countries. As for disciplinary comparison, we use the ten disciplinary levels of the ROAD database. Moreover, our findings reveal a similarity in OA journal coverage between the WoS and Scopus. However, while OpenAlex offers better inclusivity and indexing, it is not without biases. The WoS and Scopus predictably favor journals from Europe, North America and Oceania. Although OpenAlex presents a much more balanced indexing, certain regions and countries remain relatively underrepresented. Typically, Africa is proportionally as under-represented in OpenAlex as it is in Scopus, and some emerging countries are proportionally less represented in OpenAlex than in the WoS and Scopus. These results underscore a marked similarity in OA journal indexing between WoS and Scopus, while OpenAlex aligns more closely with the distribution observed in the ROAD database, although it also exhibits some representational biases.\n\nCitation:Maddi A, Maisonobe M, Boukacem-Zeghmouri C (2025) Geographical and disciplinary coverage of open access journals: OpenAlex, Scopus, and WoS. PLoS ONE 20(4):\n           e0320347.\n        \n        https://doi.org/10.1371/journal.pone.0320347\n\nEditor:Alberto Baccini, University of Siena, ITALY\n\nReceived:October 21, 2024;Accepted:February 8, 2025;Published:April 14, 2025\n\nCopyright:© 2025 Maddi et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The data are publicly available on Zenodo and can be accessed at the following link:https://zenodo.org/records/14389358.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe academic publishing landscape is experiencing a seismic shift as more researchers, institutions, and funding bodies embrace open access (OA) publishing models [1]. This transition is driven by a multifaceted set of factors, including policy mandates, institutional initiatives, changing attitudes towards scholarly communication, as well as economic and philosophical considerations that influence the support for and adoption of open access practices [2]. From an economic perspective, the rising costs of subscription-based models have prompted universities and research institutions to seek more sustainable alternatives that allow wider access to research outputs without the financial burden. Open Access is based on the philosophical and democratic principles that rely on greater transparency, equity, and accessibility in scholarly publishing, with many arguing that publicly funded research should be freely accessible to all. OA goals seek to democratize knowledge, reduce barriers to information, and promote the free flow of research across disciplines and borders. Governments, research funders, and academic institutions worldwide are increasingly recognizing the benefits of making research outputs freely accessible to all, without barriers such as subscription fees or paywalls [3].\n\nIn response to these incentives, there has been a proliferation of OA journals and platforms, facilitated by various funding models [4,5]. One notable development is the emergence of the Diamond model, characterized by journals that are both OA for readers and free of publication charges for authors [6,7]. Traditional bibliographic databases like Web of Science (WoS) and Scopus were developed on the basis of the subscription-based journals, and their coverage did not fully take into account the development of the growing prevalence of OA publishing [8]. While these databases have made efforts to incorporate OA content, they often lag behind in terms of coverage and inclusivity [9]. This discrepancy is particularly evident when comparing their journal coverage to that of the Directory of OA Scholarly Resources (ROAD), which exclusively indexes OA journals. Indeed, the traditional databases do not take openness as a criterion among their indexing criteria. WoS and Scopus both have a list of indexing criteria including “quality” criteria (i.e., the presence of a peer review policy, article titles and article abstracts in English, timeliness, international Editorial Boards) and “impact” criteria, which somehow means that the published articles must receive citations from journals already indexed in these databases. As of December 2024, the WoS indexing criteria are summarized here:https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/web-of-science-core-collection/editorial-selection-process/journal-evaluation-process-selection-criteria/. Scopus indexing criteria (less numerous and precise than WoS criteria) are summarized here:https://www.elsevier.com/products/scopus/content/content-policy-and-selection. Because of this last dimension, the indexing closely depends on the current content of the databases, reinforcing their initial biases. By adhering to these restrictive standards, these databases fail to fully represent the breadth of open access publishing, which has grown substantially in recent years. As a result, the traditional databases are limited in their ability to reflect the diversity and evolution of scholarly publishing, leading to a skewed representation that overlooks a significant portion of the academic literature.\n\nEnter OpenAlex, a new player in the field of bibliographic databases, heralded at least in France and some European countries, as a potential game-changer in the realm of OA publishing [10]. OpenAlex’s agenda is to address the limitations of traditional databases by providing a more comprehensive and inclusive index of scholarly journals [11]. By leveraging advanced data harvesting techniques and partnerships with academic institutions, OA repositories, and publishers, OpenAlex aims to offer a broader and more diverse representation of scholarly outputs from around the world [12]. The current key question surrounding OpenAlex is whether it can effectively address the historical biases and limitations of traditional databases. While OpenAlex holds promise as a potential solution to these long-standing issues, its effectiveness has yet to be fully evaluated. Ongoing research and analysis will be essential to assess the impact of OpenAlex on the visibility, accessibility, and diversity of scholarly publications. As the academic publishing landscape continues to evolve, OpenAlex represents a significant development in the ongoing quest for a more open, inclusive, and equitable scholarly communication ecosystem. Aiming to contribute to this topic, our research questions are:\n\nIn this study, our objective is to conduct a comparative analysis of the geographical and disciplinary coverage of OA journals across three prominent databases: the WoS, Scopus, and OpenAlex. Through this approach, we aim to shed light on the differences and nuances in OA journal coverage across the three databases. For this purpose, we employ the ROAD database as a coverage reference as it provides a comprehensive catalogue of 62,701 indexed OA journals. Our analysis focuses on two key dimensions: geographical representation and disciplinary diversity. Geographically, we examine coverage across continents, income groups and countries. Additionally, we conduct a disciplinary comparison using the ten disciplinary levels outlined in the ROAD database. The article is structured as follows: we start with a review of the literature on recent papers comparing the three databases. Then, we present the data collected and method used aligned on the study objectives. The results encompass an analysis of the overall coverage of OA journals and a comparison of their geographical and disciplinary structure, including an examination at the country, income group and continent levels. Finally, we provide a discussion of the findings and their implications.\n\nWhile there is a growing number of studies using OpenAlex as a data source, few have focused specifically on OpenAlex’s OA coverage and limitations discussed in this paper. This is why our literature review focuses solely on comparative studies involving OpenAlex alongside other sources, a choice aligned with our research questions.\n\nA recent study by Alperin et al. [12] observed a growing trend in using OpenAlex as a data source. They compared OpenAlex and Scopus data, finding more publications in OpenAlex, particularly from regions and languages under-represented in Scopus. However, they identified areas for improvement in metadata accuracy (e.g., affiliations, document types, open access status) and completeness in OpenAlex. Another study by Culbert et al. [13] explored OpenAlex as a promising open source of scholarly metadata, comparing it with WoS and Scopus (whose metadata are not error-free either). They assessed reference and metadata coverage, demonstrating OpenAlex’s comparability in reference numbers but mixed results in other metadata. Their study highlighted the importance of addressing data and metadata trustworthiness in rapidly evolving sources like OpenAlex.\n\nJiao et al. [14] investigated the indexing of data papers in scholarly databases to understand how research data is published and reused. They examined 18 data journals across WoS, Scopus, Dimensions, and OpenAlex to evaluate coverage and document type information consistency. Their findings revealed highly inconsistent coverage of data papers and their document types across databases, posing challenges for quantitative analysis. Jiao et al. [14] showed that, while newer databases like Dimensions and OpenAlex cover all data journals, they classify data papers as regular research articles, making their retrieval challenging. In contrast, although Scopus and the WoS cover fewer data journals, they distinguish data papers with a ‘Data paper’ document type. However, inconsistencies persist, indicating a need for improved communication to enhance database quality.\n\nOrtega and Delgado-Quirós [15] analysed retractions and withdrawals in scholarly databases, highlighting differences between traditional citation indexes like the WoS and newer hybrid databases like OpenAlex. Their findings underscored the impact of database selection on coverage of retractions and withdrawals. Ortega and Delgado-Quirós [15] highlighted that the differences primarily stem from how withdrawals are indexed by newer hybrid databases like Dimensions, OpenAlex, Scilit, and The Lens. Excluding withdrawal data, OpenAlex and The Lens collect the most retractions, while Scilit, Scopus, and Dimensions include the highest number of retracted articles. This suggests a distinction between traditional citation indexes such as WoS, PubMed, and Scopus, which are journal-based and do not index withdrawals, and newer hybrid databases relying on external sources like Crossref and Microsoft Academic. Since September 2023, Crossref, the leading DOI registration agency, acquired the RetractionWatch database, making it freely accessible [16]. Consequently, OpenAlex now directly incorporates RetractionWatch data to enrich its retraction field (seehttps://docs.openalex.org/api-entities/works/work-object). More recently, Delgado-Quirós and Ortega [17] aimed to compare metadata completeness across academic databases. They found that third-party databases like OpenAlex had higher metadata quality and completeness compared to academic search engines like Google Scholar. Their study emphasized the need for reliable descriptive data retrieval, especially in third-party databases.\n\nMoreover, other studies pointed out that the metadata quality of OpenAlex has significant room for improvement to be usable in bibliometric studies. For example, Zhang et al. [18] investigated missing institutional information in journal article metadata in OpenAlex. They identified significant gaps, particularly in early years and social sciences and humanities disciplines. Their study emphasized the importance of data quality improvements in open resources like OpenAlex. Similarly, Bordignon [19] discussed the growing adoption of OpenAlex, citing institutions’ decisions to transition from proprietary bibliometric products, notably the decision of Sorbonne Université in France to unsubscribe from WoS (seehttps://urls.fr/_8o4s2), and CNRS (French National Centre for Scientific Research) unsubscribing from Scopus (seehttps://urls.fr/PtYcj_) but keeping WoS subscription. She highlighted the importance of assessing the relevance of OpenAlex for bibliometric analysis, presenting tests to evaluate its effectiveness at an institutional level. Bordignon [19] came out with similar conclusions to Zhang et al. [18] regarding the quality of institutional metadata, based on a case study of publications from École des Ponts (a French engineering school). More recently, Céspedes et al. [20] assessed the linguistic coverage of OpenAlex and the accuracy of its metadata compared to the WoS. Through an in-depth manual validation of 6,836 articles, the study found that OpenAlex offers a more balanced representation of non-English languages than the WoS. However, the language metadata was not always accurate, leading to an overestimation of English and an underestimation of other languages. This research underlined the need for infrastructural improvements to ensure accurate metadata, despite OpenAlex’s potential for comprehensive linguistic analysis in scholarly publishing.\n\nAnother study from Alonso-Alvarez and van Eck [21] examined the coverage and metadata availability of African publications in OpenAlex, comparing it with Scopus, WoS, and African Journals Online (AJOL). Their findings revealed that OpenAlex offers the most extensive coverage of African-based publications, but still lags in providing detailed metadata, particularly regarding affiliations, references, and funder information. Interestingly, metadata completeness was found to be better for publications indexed in both OpenAlex and the proprietary databases, highlighting areas for improvement in OpenAlex to better serve research from the Global South.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g001\n\nData collected for the study was primarily sourced from the Directory of OA Scholarly Resources (ROAD) (https://www.issn.org/services/online-services/road-the-directory-of-open-access-scholarly-resources/), kindly provided to us by the ISSN International Centre (https://www.issn.org/) in XML format. We extracted information for each of the 62,701 indexed sources (ISSN), including country (across 163 countries) and disciplines (10 levels). It is noteworthy that some journals lacked information regarding their discipline (3.6%—2,263 journals out of 62,701).\n\nThe ROAD database primarily indexes OA journals, but also includes other types of OA resources, such as monographic series, which are considered part of the broader open access publishing landscape. As shown inFig 1, the major share of resources in ROAD are journals: 90.45% of the resources in ROAD are journals, representing 56,714 out of 62,701 entries. For consistency and clarity, the term ‘journal’ is used throughout the paper to refer to all types of resources indexed in ROAD, as they follow the same editorial standards and article publication processes.\n\nLaunched in late 2013, ROAD offers free access to a subset of bibliographic records from the ISSN Portal, describing scholarly resources available in OA identified by an ISSN/eISSN. These resources include Journals, Monographic series, Conference proceedings, Scholarly blogs, and Academic repositories. Metadata for these records, created by the ISSN network comprising 93 national centres and the ISSN International Centre, are enriched with data from indexing services, directories (such as DOAJ, Latindex, The Keepers Registry), and performance indicators (Scopus). ROAD is aligned with UNESCO’s efforts to promote OA to scholarly resources and complements the Global Open Access Portal (GOAP) (https://www.goap.info/) developed by UNESCO, which provides an overview of OA to scholarly information worldwide.\n\nROAD applies specific inclusion criteria to list resources in its directory. To be included, a resource needs several requirements, including being freely accessible without registration, providing a clear description of its OA policy and licensing terms, and presenting scholarly content across various fields. The resource must also have clear editorial responsibility, academic affiliation, publishing entity, and adhere to ethical guidelines and indexing standards.\n\nFor the purpose of this study, ROAD was used as the gold standard for comparing the coverage of OpenAlex, Scopus, and WoS in OA journals. ROAD includes exclusively OA journals and provides comprehensive metadata for each journal, including ISSN, eISSN, country, and discipline. We included all journals from ROAD with complete metadata, without applying any additional filters. The data extraction from ROAD was conducted in October 2023, yielding 253,200 identifiers (ISSN and/or eISSN) for 183,158 distinct journals.\n\nFor our analysis, we focused on active OA journals in OpenAlex that had more than five publications. From the total of 183,158 journals in OpenAlex, 6,632 journals with no more than five publications were excluded from the analysis. Consequently, we considered 176,526 active journals from OpenAlex. Additionally, we included 29,262 “active” journals from Scopus and 23,189 ‘active’ journals from the WoS Core Collection (covering AHCI, SSCI, SCIE, and ESCI). For these two databases (WoS and Scopus), we used the information they provide on the status of their indexed journals.\n\nIn addressing classification differences, we used the metadata provided by ROAD for the country and discipline classification, as ROAD’s classifications are considered reliable, being provided by the ISSN Centre. This approach allowed us to bypass the issue of reconciling different classification systems between the databases. Our comparison therefore focused on the indexing of OA journals listed in ROAD across the other databases (OpenAlex, WoS, and Scopus).\n\nIt is important to note here that our methodology was specifically designed to avoid potential biases related to metadata inaccuracies in OpenAlex. By relying on ROAD as the gold standard, which provides comprehensive and reliable metadata for OA journals, we limited our analysis to verifying whether the journals listed in ROAD were indexed in OpenAlex. We did not use OpenAlex’s metadata for journal classification or other characteristics. As a result, any potential inaccuracies in OpenAlex’s metadata, such as issues with document types or open access status, did not affect our results. This approach ensured that the quality of OpenAlex’s metadata did not influence our analysis, as the focus was solely on checking the presence or absence of ROAD-listed OA journals in OpenAlex. For income data by country, we used the R package ‘tmap’ [22], which provides this information. Additionally, we enriched the metadata for 13 territories that were not listed in the ’World’ dataset of tmap. Namely the territories with the following ISO3 codes: BHR (Bahrain), BRB (Barbados), MLT (Malta), MUS (Mauritius), SGP (Singapore), SYC (Seychelles), GLP (Guadeloupe), GUF (French Guiana), REU (Réunion), MTQ (Martinique), GUM (Guam), MAC (Macau), HKG (Hong Kong).\n\nThe study has a dual objective: (1) to analyse the overall coverage of OA journals in the three databases and (2) to investigate the geographical and disciplinary distribution to assess the extent to which disciplines, countries, and regions are represented in each database. For the analysis of overall coverage, we employed an UpSet graph to visualize the coverage and intersections among the three databases. This graphical representation allows for a comprehensive examination of the shared and unique journals indexed by each database. Regarding the distribution analysis, an indicator (the Coverage Index) was calculated to assess the representation of various entities (such as countries, continents, or disciplines) in each of the three databases (WoS, Scopus, and OpenAlex), relative to their representation in the entire ROAD database.\n\nwhereithe entity (continent, discipline, etc.) andjthe database (WoS, Scopus and OpenAlex). Specifically, this indicator compares the proportion of a given entity (e.g., a country) within the journals indexed by a particular database (e.g., OpenAlex) to the proportion of that entity within the entire ROAD database. For example, to calculate the indicator for Italy in OpenAlex, the proportion of Italy within the journals indexed by OpenAlex (1.6%) is divided by the proportion of Italy within the entire ROAD database (7%). The neutral value of this indicator is 1. Therefore, if a given country has an indicator of 1.30 in WoS, it would indicate that it is overrepresented by 30% in this database compared to the global structure of OA journals distribution within ROAD. This method allows for a refined assessment of the representation biases within each database, highlighting any discrepancies in the geographical and disciplinary distribution of OA journals across the three platforms.\n\nAs shown inFig 2, among the journals indexed in the ROAD database, the WoS indexes 6,157 journals, while Scopus indexes 7,351, and OpenAlex indexes 34,217. A striking observation is the presence of 24,976 OA journals exclusively in OpenAlex, whereas only 182 journals are exclusively present in WoS and 373 in Scopus. Additionally, 4,094 OA journals are simultaneously indexed in all three databases, while 145 journals are indexed simultaneously in WoS and Scopus but not in OpenAlex.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g003\n\nThe examination of continent representation in Scopus, the WoS, and OpenAlex reveals distinct trends, highlighting disparities in journal coverage on a global scale. As represented inFig 3below, all databases exhibit significant differences in continent representation. While Scopus and WoS generally show similar patterns, OpenAlex stands out with different representation trends. Scopus and WoS, despite minor variations in their continental indices, demonstrate a tendency towards over-representation of Oceania, North America and Europe, along with a relative under-representation of Africa and Asia. These databases seem to favor journal coverage from hegemonic regions, raising questions about equity and inclusivity in their indexing practices.\n\nConversely, OpenAlex presents more diverse representation patterns, with a trend towards better geographical equity. Although some disparities persist, such as the underrepresentation of Africa and Asia, OpenAlex appears to offer more inclusive coverage of journals from various regions worldwide.\n\nThe high values of Oceania in Scopus (3.39) and WoS (4.30) indicate that the region’s presence in these databases is more than three and four times higher than the global average, respectively. This high representation is primarily driven by the significant contribution of Australia and New Zealand, both of which have robust research output and strong academic infrastructures. Their focus on publishing in high-impact, English-language journals aligns well with the indexing criteria of Scopus and WoS, leading to their disproportionate visibility. This imbalance may reflect a linguistic and systemic bias, where English-speaking countries with well-established research ecosystems are more prominently featured. Australia, in particular, largely benefited from the Regional Expansion of the WoS in 2006–2008 [23]. However, this is less the case in OpenAlex (1.46), which offers a more balanced representation of global research by including a broader range of OA sources, including those in multiple languages and from less prominent regions. Interestingly, Scopus and OpenAlex exhibit a common over-representation pattern regarding the coverage of South American OA journals, whereas OA journals from this continent are under-represented in the WoS.\n\nThe comparison of economic income groups (Fig 4) across Scopus, WoS, and OpenAlex databases reveals also notable disparities in representation. High-income economies, whether part of The Organisation for Economic Co-operation and Development (OECD) or not, are consistently over-represented in Scopus and WoS, reflecting historical biases. Unlike the WoS and Scopus, OpenAlex operates under a fundamentally different paradigm, prioritizing an open and inclusive indexing strategy. While the WoS and Scopus often rely on selective curation processes that may favour established publishers and higher-income regions, OpenAlex harvesting strategy embraces a broader, more decentralized approach. This allows for a wider representation of research outputs across various economic contexts, not necessarily through targeted efforts but rather through a strategic commitment to openness and accessibility that contrasts with the more traditional, restrictive models of other platforms. Middle-income economies show varying levels of representation, with indicators fluctuating across databases.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g004\n\nLower middle-income economies are particularly underrepresented in Scopus and WoS, highlighting systemic biases within these databases. OpenAlex presents a more equitable representation across middle-income categories. Low-income economies face consistent under-representation in Scopus and WoS, indicative of broader challenges in access to scholarly resources. Analysing the representation of disciplines across Scopus, WoS, and OpenAlex databases provides insights into the distribution of scholarly knowledge and potential biases within each database.Fig 5comparing disciplinary representation across these databases reveals notable variations in coverage, reflecting broader trends in academic publishing and bibliographic indexing practices.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g005\n\nScopus and WoS demonstrate unsurprising consistent biases towards certain disciplines, particularly within STEM fields such as Physics and Natural Sciences. International databases often use journal impact factors as a key criterion for inclusion, which may influence the prominence of quantitative research and publications from highly ranked institutions [24]. Consequently, disciplines within the humanities and social sciences may be under-represented in Scopus and WoS, reflecting historical publishing and citation biases. Conversely, OpenAlex presents a more inclusive approach to indexing, aiming to encompass a diverse range of scholarly outputs across disciplines. While OpenAlex exhibits slightly lower representation in some disciplines compared to Scopus and WoS, such as Applied Sciences, Medicine, and Technology, it offers a more balanced representation overall. This suggests that OpenAlex’s indexing practices may be more reflective of the diverse disciplinary landscape and less influenced by traditional biases prevalent in academic publishing. Notably, academic subjects such as ‘Social sciences’ demonstrate higher representation in OpenAlex compared to Scopus and WoS, highlighting potential differences in indexing criteria and inclusivity across databases. This variation underscores the crucial importance of considering multiple databases to ensure comprehensive coverage across diverse disciplinary areas.\n\nFigs 6–11highlight the differences in the coverage of OA journals between the WoS, Scopus, and OpenAlex databases at the country level. The world maps (Figs 6,Fig 8, andFig 10) represent the geographical distribution of the Coverage index for each database (described in the Methods section), showcasing well-represented regions and countries as well as underrepresented ones. The circle packings (Fig 7,Fig 9, andFig 11) show the share of ROAD journals covered by each database (colour gradient) whereas the size of the circles depend on the absolute number of ROAD journals per country. These representations allow us to highlight how significant the similarities between WoS, Scopus, and OpenAlex are.\n\nUpon examiningFigs 6–11, it becomes evident that certain regions, such as Western Europe and North America, are well represented in all three databases, with high Coverage index values. However, significant disparities emerge for other parts of the world. For instance, some areas in Africa, Asia, and Latin America exhibit relatively low coverage indices in the WoS and Scopus but better representation in OpenAlex. This difference can be attributed to OpenAlex’s more inclusive indexing policy, which covers a broader range of OA journals from diverse regions around the world. In contrast, the WoS and Scopus may exhibit geographic biases, often favouring journals published in specific countries or regions, and applying selection processes that emphasize certain quality standards, which can further limit the diversity of represented sources. OpenAlex provides a more inclusive and balanced indexing of OA journals compared to both WoS and Scopus, which show similar coverage indices and comparable geographic biases. At the same time, it is worth noting that each database has its own strengths and weaknesses, and the choice depends on the specific needs of each research endeavour.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g007\n\nOur analysis also reveals two outliers we can interestingly focus on. In Europe, the case of France stands out as a notable exception. Despite its status as a high income country with a substantial scholarly output, French OA journals are consistently underrepresented across all three databases. This discrepancy raises questions about the systemic factors contributing to the exclusion of French journals from mainstream bibliographic databases. However, there is a possibility of French journals being disproportionately represented in the ROAD database, the reference database used for comparison. This potential over-representation in ROAD could skew perceptions of under-representation in Scopus, WoS, and OpenAlex. Further investigation into this discrepancy is necessary to understand the underlying factors contributing to the exclusion or under-representation of French OA journals.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g009\n\nThe case of Indonesia also raises similar questions. Specifically, both OpenAlex and ROAD exhibit a notable pattern for this country. Indonesia emerges as the top contributor to the ROAD database (it represents the biggest circle on the circle packing plots). One possible explanation is that, since 2019, the Indonesian government has mandated through legislation that universities must create OA journals [25]. This policy has significantly increased the number of Indonesian journals in ROAD, potentially leading to an apparent over-representation in this database. As for France, this scenario necessitates further investigation to understand the impact of such policies on the visibility and representation of Indonesian journals in bibliographic databases like OpenAlex.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g010\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320347.g011\n\nTo sum up, this study presents a comprehensive assessment of the coverage of OA journals across three major scholarly databases: the WoS, Scopus, and OpenAlex. The analysis reveals significant variations in representation across different countries, regions, continents, and income groups, highlighting the importance of database selection when it comes to scholarly research and outputs. These results underscore the important role of OpenAlex in expanding the coverage of OA journals, with a significant proportion of journals exclusive to this database. However, it is crucial to acknowledge that some journals may publish a small number of publications, as evidenced by a recent study focusing on Diamond journals [26,27].\n\nThe examination of coverage indices highlights notable differences in the representation of countries and regions and disciplines across the three databases. While certain areas, such as Western Europe and North America, enjoy robust coverage across all platforms, disparities are evident in other regions. OpenAlex confirms its agenda and exhibits a more inclusive approach, capturing a broader range of OA journals from diverse geographic locations compared to WoS and Scopus. This suggests that OpenAlex serves as a valuable resource for researchers seeking comprehensive coverage, especially for studies focusing on under-represented regions (as soon as the outliers are known, i.e., the case of Indonesia).\n\nFurthermore, the analysis points out disparities in coverage based on certain regions. In particular, Africa and parts of Asia tend to have lower coverage indices in WoS and Scopus compared to OpenAlex. This latter demonstrates a more equitable representation of journals from these regions, offering researchers access to a wider array of scholarly content. Likewise, analysis based on income groups further highlights disparities in database coverage. Low and middle-income countries often experience lower representation in WoS and Scopus compared to high-income countries. OpenAlex demonstrates a more equitable distribution of journals across income groups. Moreover, our findings underscore the importance of database selection in shaping scholarly research and knowledge dissemination. OpenAlex emerges as a new and valuable source for researchers seeking a more comprehensive coverage of OA journals, particularly from underrepresented regions, continents, development levels, and income groups.\n\nIn addition to the observed disparities in geographic, and income-based representation, the differences in database coverage can largely be attributed to the distinct criteria used by traditional databases such as WoS and Scopus for indexing journals. These databases often employ strict editorial and publishing standards, which, although ensuring a certain level of quality, may inadvertently exclude many open access journals, especially those from emerging or less-established regions. As a result, the WoS and Scopus are less inclusive in representing the full scope of scholarly output, particularly from non-Western countries or lower-income regions where open access models are rapidly growing. This exclusion is compounded by the fact that these traditional databases were initially designed around subscription-based journals, which have long dominated academic publishing. On the other hand, OpenAlex’s inclusive approach to indexing OA journals, with fewer restrictions, enables it to better capture the diverse and evolving landscape of global scholarly communication, offering a more representative picture of the global research ecosystem. Thus, the selection and indexing practices of databases like WoS and Scopus can significantly shape the accessibility and visibility of research from underrepresented regions, highlighting the critical role of database choice in academic research.\n\nIn discussing the notable cases of France and Indonesia in terms of OA journals and their respective under-representation in databases, it is essential to understand the factors that contribute to the high number of OA journals in these countries. Both France and Indonesia show notable differences in their representation of OA journals, and these discrepancies are influenced by various national and cultural factors. In France, the prominence of OA journals can be traced to several factors that have shaped the country’s scholarly publishing landscape. One significant element is the long-standing tradition of ‘revues de laboratoire’ (journals issued from a specific research unit or a locally-based group), which are often founded, launched and managed by specific research laboratories, academic institutions, or specialized scientific communities mainly in Humanities and social sciences (HSS). These journals, mainly managed on a crafted and small-scale basis, although they may not always meet the standards required for indexing in Scopus or the WoS, represent a vital part of the French scholarly communication ecosystem. They contribute significantly to the high number of OA journals in France, as many are supported by strong institutional backing and public funding. These journals provide an avenue for disseminating research and fostering open science within local or specialized communities. In addition, OpenEdition [28,29], a major French platform dedicated to scholarly publishing in the HSS, plays an important role in the French OA journal landscape and in the promotion of the Diamond OA. OpenEdition hosts a substantial number of French-language OA journals, especially in fields that are underrepresented in major international databases. It serves as a key infrastructure for the dissemination of scholarly knowledge in these fields. OpenEdition has helped increase the visibility and accessibility of French academic work, ensuring that journals, even if they are not indexed in large databases, contribute to the growing body of OA literature. This platform, combined with the French tradition of local journals, underscores the country’s strong commitment to making academic research freely accessible.\n\nIn contrast, Indonesia has seen significant growth in OA journal production, driven largely by national policies and institutional efforts to increase the accessibility of research outputs. Government-led initiatives have encouraged universities and research institutions to embrace OA as part of their commitment to global academic visibility and knowledge sharing. Local OA journals have proliferated, supported by efforts to enhance the quality of Indonesian research and its international impact. Despite these advances, some challenges remain, such as limited resources for high-quality editorial management and insufficient international recognition, which may hinder these journals from meeting the criteria for indexing in global databases.\n\nBoth countries’ OA journal landscapes reflect a combination of local initiatives and national policies. France benefits from a well-established tradition of ‘revues de laboratoire’ and platforms like OpenEdition, which contribute significantly to the country’s OA journal vitality. Indonesia, while benefiting from more recent surges in OA journal production, has made significant progress through government support and institutional initiatives, though it faces challenges in establishing international recognition. These country-specific dynamics emphasize the importance of considering both national and regional factors when analyzing OA journals representation, as they play a significant role in shaping the openness, accessibility, and inclusivity of academic publishing.\n\nOur study highlights the role of database selection in shaping the landscape of scholarly research and knowledge dissemination. The disparities in coverage across the WoS, Scopus, and OpenAlex underscore the varying degrees of inclusion and representation of OA journals from different countries, continents, and income groups. OpenAlex, with its broader and more inclusive approach, emerges as a valuable resource for researchers, particularly those focusing on underrepresented regions or countries with lower income levels. This platform mitigates some of the biases inherent in traditional databases like WoS and Scopus, offering a more equitable distribution of OA journals.\n\nTo better understand our results on France under-representation in the WoS, Scopus and OpenAlex, a closer and more longitudinal examination is needed. Together with Indonesia, France is the country with the highest number of OA journals indexed in ROAD. Interestingly, the role of OA national policies has been important in the two countries, but OpenAlex unequally covers these countries (coverage index of 1.19 for Indonesia and 0.22 for France). Further investigations are needed to explore these differences.\n\nWhile this study provides a comprehensive analysis of OA journal coverage across OpenAlex, WoS, and Scopus, it is essential to discuss certain limitations that may influence the interpretation of the results. First, metadata issues are a known challenge in OpenAlex, as well as in traditional databases like WoS and Scopus to a lesser extent. However, in this study, we minimized the impact of these potential biases by relying primarily on the metadata provided by the ROAD database, which is curated independently of OpenAlex. This approach allowed us to avoid many of the inaccuracies that could arise from OpenAlex’s metadata, such as issues with the disciplinary classification or geographical indexation. Second, while ROAD is a robust resource for identifying OA venues, it is not without limitations too. Notably, over 2,000 journals in ROAD lacked disciplinary classifications, which may have affected the results presented inFig 5(disciplinary coverage by database). This could result in an incomplete representation of certain disciplines. Enhancing the metadata coverage for these journals would be an important step for future research aiming to refine the analysis. Finally, the absence of publication volume data for ROAD and the restricted availability of such data for WoS and Scopus limited our ability to analyze the impact of journal size on database representation. While publication thresholds could be explored using OpenAlex data, a more comprehensive investigation across all databases was beyond the scope of this study. Future work could address the identified gaps and further enhance the robustness of comparative analyses.\n\nThe authors would like to thank ISSN International Centre for providing the ROAD data. We would like to express our heartfelt gratitude to Dr. Gaëlle BEQUET, Director of the ISSN International Centre, for reviewing the initial draft of this paper. Her insightful comments and constructive feedback have been invaluable in enhancing the quality and depth of our work. We sincerely appreciate her time and effort, which have significantly contributed to the improvement of this article.",
    "category": "geography"
  },
  {
    "title": "Interlinkage between health workforce availability and socioeconomic status in rural and remote Australia",
    "authors": "Ellen McDonald, Ross Bailie, Peter Radchenko, K. Shuvo Bakar, (PLOS)",
    "publish_date": "2025-04-11",
    "doi": "https://doi.org/10.1371/journal.pone.0321198",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321198",
    "content": "Australians living in rural and remote areas experience a higher burden of disease compared to their urban counterparts, whilst having poorer access to essential health services. Socioeconomic status and health workforce shortages are important influences on health status and access to care in these areas. This research aims to provide a local-level analysis of the association between local government area (LGA) indicators of socio-economic status and health workforce availability to enhance understanding of rural and remote workforce distribution patterns.\n\nData were extracted from the Australian Bureau of Statistics and the Department of Health and Aged care, which encompassed demographic factors, socioeconomic indicators and counts for medical practitioners, allied health workers and nurses and midwives within non-metropolitan local government areas. Generalised Additive Models with Generalised Estimating Equations (GEE-GAMs) were used to test for an association between socioeconomic status (SES) and the World Health Organisation’s definition of health workforce deficit.\n\nThe odds of being in deficit of nurses and midwives increased with increasing SES. No significant association between SES and medical practitioners or allied healthcare workers was found. Very remote areas were less likely to have a deficit of allied health professionals than inner regional areas, and the same was true for nurses and midwives in both remote and very remote areas.\n\nThe findings suggest that health workforce policies that target areas of need based on SES, may have contributed to better availability of nurses and midwives in these locations, but not significantly so for medical practitioners or allied health professionals. Further research is required to investigate the relative success of workforce policies in addressing health need in relation to SES and remoteness.\n\nCitation:McDonald E, Bailie R, Radchenko P, Bakar KS (2025) Interlinkage between health workforce availability and socioeconomic status in rural and remote Australia. PLoS ONE 20(4):\n           e0321198.\n        \n        https://doi.org/10.1371/journal.pone.0321198\n\nEditor:Marwa Ramadan, The World Bank Group, Canada\n\nReceived:July 18, 2024;Accepted:March 3, 2025;Published:April 11, 2025\n\nCopyright:© 2025 McDonald et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All data sources used in the study are publicly available. The data can be accessed from ABS: (https://www.abs.gov.au/statistics/people/people-and-communities/socio-economic-indexes-areas-seifa-australia/latest-releaseandhttps://explore.data.abs.gov.au/), Australian Government Department of Health and Aged Care - Health Workforce Data Tool (https://hwd.health.gov.au/datatool/).\n\nFunding:The authors would like to acknowledge funding support from FMH-Business (Grant ID. 223039) and note that RB’s contribution to this paper is through his role as co-lead of the Rural and Remote Research Theme of the HEAL Network, which is supported by the National Health and Medical Research Council (NHMRC, Grant No. 2008937). There was no additional external funding received for this study.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nGlobally, those living in rural and remote areas tend to suffer from poorer health outcomes when compared to their urban counterparts and have relatively unfavourable social determinants of health [1]. Australia is no exception to this phenomenon, with rural and remote areas having higher rates of hospitalisation, death and injury when compared to major cities, and lower rates of education and employment [2]. National statistics show that burden of disease from conditions such as coronary heart disease, type 2 diabetes and lung conditions increases with location remoteness [2], and subsequently rural and remote populations have been identified as a priority in Australia’s National Preventative Health Strategy [3]. In this paper, we refer to rural and remote areas as those outside of major cities, as defined by the Australian Bureau of Statistics (ABS).\n\nDespite the national prioritisation of rural and remote health, access to healthcare in these areas continue to be limited [4]. Consistent with global trends [1], those living in rural and remote areas of Australia have poorer access to health services compared to those living in major cities [2]. While rural and remote areas face unique socio-economic and geographical challenges that contribute to health service limitations, a deficit of trained health professionals is central to the inadequate availability of health services in these areas [1]. In Australia, the number of full-time equivalent (FTE) healthcare workers per head decreases with increasing location remoteness [4], demonstrating that the health workforce is being inversely distributed in relation to relative need [5]. While various programs and incentives exist to attract healthcare workers to rural and remote areas in Australia [6], evidence of effectiveness is limited [7,8], and the health workforce remains unevenly distributed. Research into the determinants of health workforce availability in rural and remote Australia is needed to guide evidence-based policy and address the imbalanced distribution of the health workforce.\n\nThe current literature base surrounding the determinants of health workforce availability in rural and remote Australia mainly describes factors that influence retention and recruitment.\n\nCurrent studies suggest that personal factors such as a rural background or extended training in rural areas increases the likelihood of healthcare professionals working rurally [8,9,10,11,12]. The Rural Health Multidisciplinary Training program in Australia facilitates rural training and recruitment of rural students, and has been shown to be an important contributor to addressing rural and remote health workforce shortages [13].\n\nOther determinants of rural and remote health workforce retention and recruitment in Australia include place-based and workplace factors. Ineffective management, poor work environments and lack of career progression in rural and remote settings is detrimental to healthcare worker retention [7,12,14,15]. Place based factors such as increased remoteness, community deprivation, lack of facilities and social isolation are also detrimental to rural and remote health workforce retention [11,14,15]. Determinants associated with increased retention include community engagement and having access to family support, childcare and appropriate housing [7,14,16,17]. However, the link between these determinants and effective intervention is not strong [7,8], and primary sources of evidence are mostly restricted to local settings, which limits the generalisability of this evidence.\n\nIn 2023, Yisma et al. analysed the distribution of occupational therapists, physiotherapists and podiatrists across Australia by socioeconomic status (SES) of areas [18]. SES was represented by index of relative socioeconomic advantage and disadvantage (IRSAD), and the density of occupational therapists, physiotherapists and podiatrists was found to decrease with decreasing IRSAD quintile (which equates to decreasing SES) [18]. No other literature within Australia could be identified that investigates the relationship between healthcare worker availability and local area-level SES, with studies that consider local area-level SES focusing on health service utilisation [19,20], rather than health workforce availability.\n\nTurning to the international context, studies in England found a “pro-rich” relationship between general practitioner density and socioeconomic status after adjusting for need [21,22,23]. In one study, this relationship also held true for paramedics, while the opposite was true for nursing staff [21]. Looking even more broadly, Cookson et al. found that health workforce availability is inversely associated with area socioeconomic disadvantage in most low and middle-income countries (i.e., health workforce availability decreases with increasing socioeconomic disadvantage), however in high income countries the same is true only after adjustment for need [24].\n\nImportant geographical and socio-economic differences exist between Australia and other parts of the world, particularly in non-metropolitan settings, meaning the transferability of results from international studies to Australia may be limited. The findings from Yisma et al. are limited in transferability and generalisability due to inclusion of only three allied health professions, and the analysis not being specific to the rural and remote setting [18]. While the current evidence base suggests there is an association between the availability of specific healthcare workers and the socioeconomic status of areas [18,21–23], this association needs to be examined in the rural and remote Australian setting, across a broader range of health professions.\n\nInvestigating the relationship between local area-level SES and health workforce availability should improve understanding of the distribution of Australia’s rural and remote health workforce, and provide insight into the extent to which health workforce policies have been effective in improving availability of different types of health professionals in areas higher need as reflected by SES and rurality. Those living in areas of lower SES in the rural and remote setting may face intersecting disadvantage and will likely have higher demands for health services, given the well-known association between low SES and poor health [25,26], and increased rurality and poor health [2]. Knowledge relating to the current relationship between local area-level SES and rural and remote health workforce availability may inform policy and health workforce planning that aims to distribute healthcare professionals to areas of highest need.\n\nThis paper explores the association between local area-level SES and a 2016 WHO definition of health workforce deficit (see details in the methods section below) in areas outside of major cities, per the Australian statistical geography standard remoteness structure. The influence of area remoteness is explored and adjusted for in the statistical analysis. We focus on three categories of health workers: medical practitioners, allied health workers and nurses and midwives, as these professionals make up an essential portion of the health workforce [1,27]. For this paper, areas outside of major cities including inner regional, outer regional, remote and very remote areas (per the Australian statistical geography standard remoteness structure) will be referred to as rural and remote areas.\n\nThe Australian Bureau of statistics (ABS) census data was used to extract socio-economic indicators for areas (SEIFA) from 2013 to 2021, at local government area (LGA) level across rural and remote Australia [28]. SEIFA scores rank areas by socio-economic advantage and disadvantage through variables measured in census data [29]. Age distributions for rural and remote LGAs were also sourced from the ABS, using data-explorer [30]. The proportion of residents aged over 85 years old and aged under 5 years old in each LGA were calculated. The following data were collected from the Health Workforce Data Tool [31], provided by the Australian Government Department of Health and Aged Care for the same time periods (2013–2021) and by LGA:\n\nThe outcome variable is binary, with each LGA being coded as either being in deficit or not being in deficit of the categories of health care worker of interest, i.e., “medical practitioners”, “nurses and midwives”, and “allied health professionals”. Thresholds to define a “deficit” were extracted from WHO’s 2016 report on health workforce requirements. This report concluded that 4.45 medical practitioners, and 4.45 nurses and midwives are required per 1,000 people to achieve health related sustainable development goals [32]. Therefore, under 4.45 FTE workers per 1,000 people was defined as a deficit for medical practitioners and nurses and midwives.\n\nThe WHO health workforce requirements report recognised the importance of allied health professionals but did not define a minimum workforce requirement for this profession due to difficulty centralising data [32]. Due to a lack of other literature surrounding the required quantity of allied health professionals, the 2020 Australian national average of allied health professionals per 1,000 population was used to define a deficit in this category, which is 5.94 FTE allied health professionals per 1,000 people [4].\n\nIndex of relative socioeconomic advantage and disadvantage (IRSAD) was the SEIFA score chosen to represent SES in this analysis, as it considers elements of both advantage and disadvantage, and encompasses the broadest range of variables [29]. IRSAD will be measured in quintiles, as is consistent with national [18,33], and international literature [22,23] examining the socioeconomic status of areas in a similar context. A higher IRSAD quintile represents higher SES.\n\nThe following variables were included as covariates:\n\nThese covariates were included based on the assumptions illustrated inFig 1, which were guided by current literature. National statistics demonstrate that the remoteness of an area is independently associated with both SES [1,2] and health workforce availability [4], making RA an important covariate to adjust for to avoid possible confounding. Year was also included as a covariate, as time may influence both health workforce availability and IRSAD scores through events such as the covid-19 pandemic. Age distributions from two extreme tails of the LGA population, i.e., less than 5 and over 85 years old were also included as covariates, due to possible relationships between age and local area-level SES [26], which may influence health workforce availability through workforce retention factors such as availability of childcare services [16] and community engagement [14].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321198.g001\n\nData were examined using summary statistics, and repeated observations were deleted. Examination of diagnostic plots showed a non-linear relationship between the continuous variables and the binary outcome variable, which prompted the development of a non-linear additive structure in our model for the continuous variables. More specifically, we used Generalised Additive Models (GAMs), which allow for inclusion of non-linear continuous variables by use of cubic regression splines [34]. GAMs were created for each healthcare profession.\n\nDue to the clustering effects in the data, generalised estimating equation (GEE) estimation was also implemented. The data were considered to be clustered on the basis that separate observations from a single LGA are likely to be more correlated than observations from different LGAs [35]. This clustering violates the independence assumption of GAMs, making GEEs a necessary addition to address this violation [36]. This decision was supported by the large intra-cluster correlation values within each GEE model. GEEs address clustering by assuming a correlation structure within the dataset, which allows for calculation of robust standard errors [36]. GEEs are robust to misspecification of correlation structures [37], and were selected as the most appropriate method to account for clustering as they allow for population averaged estimations.\n\nTo create the GEE-GAM models, the splines of the continuous variables were extracted from the GAMs and applied to GEE-GLMs. Similar techniques of developing GEE-GAMs have been shown to be successful in literature [38]. The QIC (quasi-likelihood under the independence model criterion) was used to identify the best and final GEE-GAM for all workforce categories. Age distribution variables were considered for removal from the final GEE-GAM models if they did not cause an increase in the QIC value or a significant change in the IRSAD quintile coefficients after removal. RA and year variables were not considered for removal due to their strong contextual relevance to the model.\n\nThe model selection process was completed with both exchangeable and autoregressive correlation structures for each GEE-GAM, and the correlation structure for each final model was selected based on the lowest QIC value. Effect modification between year and age distribution variables was also tested in the final model and considered for inclusion if interaction terms were significant. QIC values were compared between the initial GEE-GLMs and the final GEE-GAMs to ensure the best model was selected.\n\nWe used R programming language to implement the models [36,39], and used “glm”, “mgcv” [34,40] and “geepack” [41] packages to get model-based results. Table B and C inS1 Fileincludes model-based output for crude and adjusted GLMs for the health professional categories considered in this paper.\n\nA total of 3,294 observations were collected from 368 rural and remote LGAs across Australia, over nine years. There were no missing data. IRSAD quintile 5 (most advantages quintile) contained the smallest proportion (8.4%) of observations, while quintiles one to four each contained between 20% to 24% of the remaining observations. The highest proportion of observations were from inner regional Australia (41.6%), and the lowest proportion were from remote Australia (11.3%).\n\nThere was an overall 15.5% relative decrease in the proportion of LGA’s in deficit of allied health professionals between 2013 and 2021 (Table 1). The proportion of LGAs in deficit of medical practitioners in 2013 had decreased by 3% in 2021, which is the smallest relative change amongst all health profession categories. Nurses and midwives had a 9.6% relative decrease in the proportion of LGAs in deficit between 2013 and 2021.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321198.t001\n\nAll GEE-GAMs had lower QIC values than their corresponding GEE-GLMs, and were therefore selected as final models. The final GEE-GAM for allied health professionals included all the covariates, as listed inTable 2. All continuous covariates were observed to have a non-linear relationship with the logit of the outcome variable, and were therefore included as smoothed variables, which are plotted inFig 2. Age distribution variables remained in the final model as their exclusion increased the QIC score. There was no evidence of effect modification between year and age distribution variables. The C-statistic for this model is 0.77, which is greater than the null model (0.5). The QIC value for this model (1652) is lower than that of the null model (1824). Table A in S1 File provides the model-based results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321198.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321198.g002\n\nThe estimated odds ratios calculated for each IRSAD quintile (Table 2) have large robust standard errors, and there is no statistical evidence (p>0.1) of association between IRSAD quintile and allied health professional deficit. However, there is strong evidence (p<0.01) that LGAs in very remote areas have on average 70% lower odds of being in deficit of allied health professionals compared to LGAs in inner regional areas, after adjusting for the covariates listed inTable 2.\n\nThe GEE-GAM model for medical practitioners included all covariables, and all continuous variables were included as smoothed functions (Fig 2) due to non-linearity. The age distribution variables increased the QIC value when removed from the model and were therefore included. There was no evidence of effect modification between the age distribution variables and year. The C-statistic for this model was 0.73 which is higher than that of the null model (0.5). The QIC for the final model (2016) was also lower than that of the null model (2140). The model showed no statistical evidence of association between IRSAD quintile and medical practitioner deficit, due to large robust standard errors. There was also no statistical association between area remoteness and medical practitioner deficit.\n\nThe GEE-GAM model for nurses and midwives also included all variables, with both age distribution variables being included as smoothed terms (Fig 2). Year was included as a linear term in the model after graphical inspection. The age distribution variables were not removed from the model, as their presence lowered the model’s QIC value. There was no evidence of effect modification between either of the age distribution variables and year.\n\nThis model showed a significant association between nurse and midwife deficit and IRSAD quintile. Strong statistical evidence (p<0.01) demonstrated that on average, LGAs in quintile 5 had 2.54 times the odds being in deficit of nurses and midwives compared to LGAs in quintile 1. There was also evidence (p<0.05) to show that LGAs in IRSAD quintile 4 had on average 1.65 times the odds of being in deficit of nurses and midwives compared to LGAs in IRSAD quintile 1. Additionally, there is weak evidence (p<0.1) to show that on average LGAs in IRSAD quintile 2 and 3 had respectively 1.34 and 1.43 times the odds of being in deficit of nurses and midwives when compared to LGAs in IRSAD quintile 1. All conclusions were after adjustment for the covariates listed inTable 2, and after accounting for clustering.\n\nAdditionally, strong evidence shows that LGAs in remote areas have on average 88% lower odds of being in deficit of nurses and midwives than LGAs in inner regional areas, and that LGAs in very remote areas have 72% lower odds of being in deficit of nurses and midwives than LGAs in inner regional areas, after adjusting for the included covariates.\n\nOur findings illustrate a large overall deficit of both medical practitioners and allied health professionals in rural and remote areas, which is consistent with national statistics [4]. Conversely, a much smaller deficit of nurses and midwives exists, suggesting that nurses and midwives are more adequately distributed within rural and remote areas than medical practitioners and allied health professionals. All three categories of health professionals have an overall relative decrease in deficit of health professionals between 2013 and 2021, however the magnitude of the relative reduction in deficit varies between health professions. Medical practitioners have a very small relative decrease in deficit over time, while allied health professionals and nurses and midwives had a much larger relative decrease in deficit. This may indicate that health workforce distribution policies have been more effective for allied health professionals and nurses and midwives than for medical practitioners over the period 2013–2021.\n\nOur findings indicate that in the rural and remote Australian setting, the availability of both medical practitioners and allied health workers is not associated with local area-level SES. This is inconsistent with findings from international and national sources, which show that decreased local area-level SES is associated with decreasing density of general practitioners [21,23] and various allied health professionals [18,21]. Unlike these sources, our findings are specific to the rural and remote setting, which may suggest that the influence of local area-level SES on retention and recruitment for these professions differs between non-metropolitan and metropolitan areas. The lack of association found in this paper may indicate that in the rural and remote setting, medical practitioners and allied health workers are not deterred by socioeconomic factors relating to their area of practice, or that existing health workforce policies are to some extent addressing the higher level of need in areas of lower SES. Alternatively, the widespread deficits among these health professions across rural and remote Australia could be overshadowing the association between SES and deficit, and perhaps an association would emerge if rural and remote areas had lower overall levels of deficit.\n\nThe difference between our findings and that of existing literature may also be due to differences in analysis. Nussbaum et al. [21], Fisher et al. [23], and Yisma et al. [18] examined density of healthcare professionals rather than deficit, and their findings were specific to individual professions. The grouping of professions in this analysis may have masked profession specific associations, with the lack of association found possibly being indicative of heterogeneity within different specific allied health and medical professions. Nussbaum et al., and Fisher et al. also adjusted for need in their analyses, with Fisher et al. finding no association between general practitioner density and area disadvantage prior to adjusting for need. This may also explain differences in results.\n\nOur findings relating to the association between SES and nurse and midwife deficit differs from that found among medical practitioners and allied health workers. Our results show that SES is associated with nurse and midwife deficit, and that areas of lower SES are less likely to be in deficit of nurses and midwives when compared to areas of higher SES. These results are supported by the literature in England, which found an increased proportion of nurses per 10,000 patients in areas of higher disadvantage [21]. Our results also show that remote and very remote areas were significantly less likely to have a deficit of nurses and midwives compared to inner regional areas [21]. This phenomenon was mirrored among allied health professionals, with very remote areas being less likely to be in deficit of allied health workers compared to inner regional areas.\n\nLower SES and increased remoteness being associated with lower odds of nurse/midwife deficit suggests that nurses and midwives are present in areas of relatively higher need, and that current health workforce policies may have been more effective for these professions. However, this is concurrent with a widespread deficit of medical practitioners and allied health professionals in rural and remote areas. An adequate supply of nurses and midwives in the absence of medical practitioners and allied health professionals is not necessarily indicative of adequate health service availability [42]. These results may be illustrating an increased reliance on nurses and midwives in rural and remote areas and areas of lower SES (due to a shortage of medical practitioners and allied health professionals), with nurses and midwives filling a wider range of health professional roles in these locations [23,32].\n\nThe use of IRSAD as a proxy for SES is a limitation of the models created. While IRSAD is a widely used measure of SES that undergoes validation by the ABS [28], socioeconomic status remains a difficult concept to quantify. IRSAD ranks relative socioeconomic advantage and disadvantage, meaning LGAs in lower IRSAD quintiles are not necessarily of low socioeconomic status, but are of lower SES compared to LGAs in higher quintiles [29]. Hence, the conclusions of this study cannot be equated to actual SES, but relative SES.\n\nAnother key limitation of the study is the lack of detailed data on the breakdown of health workforce professions. For example, nursing and midwifery data are combined by AHPRA, despite their distinct scopes of practice. These professions often have separate roles and are frequently the first point of contact for providing essential services in health and primary care, health promotion, and disease prevention. Therefore, analysing these two professions separately would provide a more meaningful perspective for policy implications.\n\nAnalysing health workforce deficit as a binary outcome rather than as a continuous measure also introduces model limitations. The use of a binary outcome variable means that the magnitude to which an observation is above or below the deficit threshold is not accounted for, and more detailed associations cannot be uncovered. The efficacy of the final models is also dependent on the accuracy of the deficit thresholds defined. The lack of evidence surrounding the minimum requirements for allied health professionals means deficit in this category was based on the national average of FTE allied health workers in 2020, which may be an inaccurate representation of deficit. The minimum health workforce requirements estimated by the World Health Organisation are not specific to the rural and remote Australian setting, and therefore may decrease accuracy of the thresholds defined for medical practitioners and nurses and midwives.\n\nAdditionally, areas of greater remoteness with more sparsely distributed populations may require an increased number of health professionals to account for the potentially larger distances of travel required. This means a single population to health practitioner ratio may not be appropriate for all levels of remoteness, which may also decrease the accuracy of the models created. However, to our knowledge more accurate minimum thresholds are not available, and the estimations supplied by the World Health Organisation are widely used.\n\nAnother limitation of this study was the inability to adjust for an LGA’s level of need. Areas of lower SES are likely to have increased burden of disease [25], and therefore may require more healthcare workers per head. Hence LGAs in lower IRSAD quintiles may be in deficit of healthcare workers due to increased demand, but in this analysis would not be classified as such if they are above the minimum threshold. This may bias the results towards the null, as was evident in findings from Fisher et al [23]. Further research into the association between SES and health workforce availability with adjustment for need may be valuable, and uncover associations that this paper was unable to.\n\nIt must also be noted that this analysis examines healthcare worker availability, and does not account for quality, acceptability, or accessibility of care. The number of FTE healthcare staff available is only a precondition to adequate care [32], with aspects of quality, acceptability and accessibility being equally important to the delivery of essential health care services [22,32].\n\nOur findings suggest that local area-level SES is a determinant of workforce deficit among nurses and midwives, with the odds of being in deficit of nurses and midwives decreasing with decreasing SES. Additionally, we found that remote and very remote areas have decreased odds of being in deficit of nurses and midwives compared to inner regional areas. These findings suggest that current health workforce planning and policy relating to nurses and midwives may have been effective over the period of this study, as areas of higher need are less likely to be in deficit of these staff. Conversely, no association was found between local area-level SES and health workforce deficit among medical practitioners or allied health workers. However, it must be noted that this analysis does not account for increased need in areas of lower SES and in remote areas with geographical challenges.\n\nhttps://doi.org/10.1371/journal.pone.0321198.s001\n\n(DOCX)",
    "category": "geography"
  },
  {
    "title": "A quantitative evaluation study of China’s Long-Term Care insurance policies based on the PMC index model: A case study of 16 pilot policy texts",
    "authors": "Yuzi Wang, Weizheng Wang, Yujie Zhang, Yuan Zeng, (PLOS)",
    "publish_date": "2025-04-11",
    "doi": "https://doi.org/10.1371/journal.pone.0321057",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321057",
    "content": "China’s Long-Term Care Insurance (LTCI) system is designed to address the caregiving needs of elderly individuals with disabilities and dementia, focusing on long-term care to ensure adequate survival and quality of life for disabled individuals. This study employs the PMC index model to evaluate LTCI policies in 16 pilot cities, including Changchun and Qingdao, using keyword extraction and social network analysis on the latest policy documents from these cities. The study revealed the following findings: (1) Among the 16 cities, only Qingdao’s policy achieved a “perfect” rating, with two policies rated as “excellent,” 11 as “acceptable,” and two as “poor.” (2) While most cities allow the involvement of commercial insurance in LTCI administration, there is a lack of clear policy direction for the assessment and service provision by commercial insurers. (3) Dementia care receives significantly less attention compared to physical disabilities. (4) Most cities have underdeveloped financing mechanisms, and family caregiving services are undervalued. Moreover, an analysis of representative policies based on the PMC surface indicates substantial differences between the pilot cities, with Qingdao’s “perfect” policy serving as a model for future LTCI development. The study offers several recommendations: (1) Improve caregiver support policies to enhance family caregiving services. (2) Expand funding sources to increase the equity of LTCI financing. (3) Allocate insurance policy resources more effectively to gradually eliminate policy barriers. (4) Increase the focus on dementia care and clarify the criteria for assessing disability. (5) Strengthen the preventive function of LTCI and progressively expand its coverage. This research provides critical insights into the ongoing development of China’s LTCI system and proposes viable strategies for promoting equity and sustainable growth.\n\nCitation:Wang Y, Wang W, Zhang Y, Zeng Y (2025) A quantitative evaluation study of China’s Long-Term Care insurance policies based on the PMC index model: A case study of 16 pilot policy texts. PLoS ONE 20(4):\n           e0321057.\n        \n        https://doi.org/10.1371/journal.pone.0321057\n\nEditor:Robbert Huijsman, Erasmus University Rotterdam, NETHERLANDS, KINGDOM OF THE\n\nReceived:October 23, 2024;Accepted:March 1, 2025;Published:April 11, 2025\n\nCopyright:© 2025 Wang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and its Supporting Information files.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAccording to the results of the fourth sample survey on the living conditions of elderly people in urban and rural China, 18.3% of the elderly population in 2015, approximately 40.63 million people, were either fully or partially disabled. The predicts that from 2020 to 2050, the number of elderly individuals with disabilities will continue to rise due to the ongoing expansion of the elderly population [1]. In response to the increasing burden of caregiving for severely disabled elderly individuals, the gradual establishment of a long-term care insurance (LTCI) system and the improvement of an integrated medical and elderly care service system have become crucial components of China’s proactive strategy to address population aging. The LTCI system is designed to meet the caregiving needs of elderly individuals with disabilities and dementia, focusing on the provision of long-term care to ensure better survival security and quality of life for disabled individuals. The establishment of the LTCI system also helps to address the non-professional nature of elderly care, alleviating the economic burden on families and caregivers. At the same time, it facilitates the downward transfer of high-quality medical resources, optimizes the allocation of caregiving resources, and promotes the development of an intelligent and healthy elderly care industry [2].\n\nIn 2016, the Office of the Ministry of Human Resources and Social Security issued the “Guiding Opinions on Conducting Pilot Programs for the Long-Term Care Insurance System” (Document No. 80 [2016] of the Ministry), selecting 15 cities to initiate national-level LTCI pilot programs. In September 2020, the National Healthcare Security Administration, in collaboration with the Ministry of Finance, released the “Guiding Opinions on Expanding the Pilot Programs for the Long-Term Care Insurance System” (Document No. 37 [2020] of the Healthcare Security Administration), adding 14 additional pilot cities. This expansion aims to explore a framework for an LTCI system suited to China’s national context on a broader scale. The pilot cities have actively implemented LTCI policy trial plans, achieving some success in practice. However, challenges such as limited service content, underdeveloped financing mechanisms, and immature management models have emerged. At the same time, there are significant differences in the implementation effectiveness of the policies across the pilot cities. Are these issues related to the design of the LTCI system? What differences exist in the policy schemes among the pilot cities? Are the outcomes of LTCI policy implementation influenced by other factors? Based on these questions, this paper applies the Policy Modeling Consistency (PMC) index model to establish an LTCI policy evaluation index system. Through PMC surface diagrams and a comparative analysis of LTCI development in countries with more advanced systems, this study critically examines the strengths and limitations of LTCI policy design, providing scientific references for the sustainable development of the LTCI system.\n\nLong-Term Care Insurance (LTCI) is a system designed to provide long-term care services for individuals who are unable to manage daily living activities due to age, illness, or functional disabilities [3]. The core of LTCI lies in providing financial support for long-term care services through social or commercial insurance mechanisms. As global aging trends intensify, the demand for long-term care is steadily increasing, leading many countries to design and implement various forms of LTCI systems according to their specific national contexts. Summarizing and comparing these international experiences offers valuable insights into the design and effectiveness of LTCI systems.\n\nGermany was the first country in the world to introduce a long-term care insurance system, officially implemented in 1995 as part of its social security system. A key feature of Germany’s LTCI is its mandatory and intergenerational solidarity principle, requiring all residents covered by statutory health insurance to participate in LTCI, with premiums shared between employers and employees [4]. The system is built on the principle of “intergenerational support,” where the contributions of current workers fund care services for those in need. Germany’s LTCI covers a wide range of services, including home care, institutional care, and community-based care. Notably, the system prioritizes home care to reduce pressure on public care institutions and encourages family members to be actively involved in caregiving. The government provides cash benefits to individuals requiring long-term care, allowing beneficiaries to choose between using the funds for family-based care or purchasing professional care services [5]. Furthermore, the care needs assessment mechanism within Germany’s LTCI system is highly regulated, with care services only provided following evaluation by professional assessment bodies to ensure that recipients are genuinely unable to care for themselves, whether elderly or disabled. Care services are categorized into different levels based on the degree of need, ensuring that those with higher needs receive greater support. Germany’s LTCI system not only alleviates the burden of caregiving in an aging society but also significantly shares the financial burden of care, reducing the economic strain on families [6].\n\nJapan’s Long-Term Care Insurance (LTCI) system was officially implemented in 2000, drawing from Germany’s model but with distinct features in its policy design. Unlike Germany, Japan’s LTCI covers all residents aged 40 and above, rather than being limited to insured individuals. The premiums are jointly funded by residents over 40, local governments, and the central government, ensuring a diversified funding source and the sustainability of the system [7]. A key feature of Japan’s LTCI is its mandatory and universal nature, requiring all residents aged 40 and above to pay LTCI premiums, which gives the system broad coverage. Japan’s long-term care service system emphasizes the integration of community services with home care, striving to keep the elderly out of institutional care facilities. The government provides financial and policy support to promote the development of community-based elderly care services, enhancing the accessibility and quality of home care. Similar to Germany, Japan has established a standardized care needs assessment system, which assigns different levels of services and financial support based on the degree of care needed by the insured. Additionally, the Japanese government places great emphasis on the training and management of care service workers, ensuring service quality through a stringent certification system [8]. In terms of policy design, Japan’s LTCI is government-led, with a strong emphasis on public financial support to ensure that all elderly individuals requiring care receive basic services [9].\n\nIn contrast to the social insurance models of Germany and Japan, the long-term care system in the United States of America primarily relies on private long-term care insurance and the public Medicaid program. Private long-term care insurance is mainly targeted at high-income individuals, and its market-driven nature has resulted in low enrollment rates, with only a small portion of middle- and upper-income families able to afford the high premiums of private insurance [10]. Furthermore, the coverage provided by private long-term care insurance is often limited, typically covering only a portion of care costs, leaving many elderly individuals’ care needs unmet. In contrast, Medicaid, as a federal public medical assistance program, covers a large portion of long-term care costs for low-income elderly individuals. However, Medicaid’s coverage is limited to individuals who meet specific financial eligibility criteria [11]. The U.S. long-term care system faces challenges such as insufficient funding, inadequate service provision, and a fragmented system. Although the government provides some level of support for long-term care, the lack of a unified national system leads to significant variations in care quality and coverage across states. Compared to the more cohesive systems in Germany and Japan, the U.S. LTCI system is more fragmented and underdeveloped, which contributes to greater financial pressure and resource shortages in the field of long-term care in the United States [12].\n\nA comparison reveals that the long-term care insurance systems of different countries exhibit significant differences in terms of funding sources, coverage, and service models. The social insurance models in Germany and Japan are characterized by universal coverage and broad-based social solidarity [13], whereas the United States of America relies more on market-driven mechanisms [14]. These international experiences offer valuable insights for the design and optimization of LTCI systems globally, including lessons on funding mechanisms, coverage, and service delivery models.\n\nFrom the perspective of long-term care insurance (LTCI) policy, research based on the social welfare policy analysis framework has examined China’s LTCI system in major pilot cities through the lens of four key elements: social distribution, types of service provision, delivery systems, and financial models. Findings indicate that issues such as evaluation tools and service supply accuracy have been persistent [15–17]. He [18] conducted a comprehensive study on the financing mechanism through literature review and in-depth interviews, proposing a multi-channel independent financing mechanism. Other innovative studies have also gained attention, such as those exploring the role of social forces as important sources of LTCI funding and service provision [19–20] and new models like the “gradual coverage of insured individuals” and “fixed financial responsibility” exemplified by Jinjiang’s LTCI pilot program [21].\n\nIn terms of covered populations, Germany and other countries generally have broader coverage in both the insured and the beneficiaries compared to China [22–24]. For example, in the LTCI trial in Shanghai, researchers found that the citywide six-level elderly needs assessment system had issues with overly detailed classifications [25]. Furthermore, China is actively exploring flexible LTCI mechanisms tailored to its own context. Wang [26] conducted theoretical and empirical studies, suggesting that the design of the LTCI system should take into account the characteristics of demand that influence service needs. In addition, scholars have used descriptive statistics and ordinal logistic regression to analyze satisfaction and influencing factors among LTCI beneficiaries in Shangrao, Jiangxi Province, showing a generally high level of satisfaction [27].\n\nIn terms of operational models, Germany and Japan’s “independent insurance” models represent a shift from China’s pilot LTCI, which was initially attached to the medical insurance model [28–30]. Additionally, studies have affirmed the unique local practices of integrating medical and elderly care and the “mutual assistance” model of LTCI that features the interplay between family and community care [31,32]. However, operational outcomes have revealed various problems in China’s LTCI system, including financing sources, the identification of beneficiaries, and the supply of care resources and services [33,34]. Yang [35] studied the operational effectiveness of the pilot in Chengdu, employing interviews and data analysis, and found inefficiencies such as wasted resources and underutilization of services on both the supply and demand sides.\n\nMany scholars have applied content analysis methods to study service models in LTCI pilot programs. For example, researchers using deductive content analysis have examined the characteristics of LTCI pilot programs in 14 cities across China and found that all cities covered institutional care, while most (except for Changchun, Chengde, and Ningbo) also included home-based care [36–40]. Subsequently, researchers expanded the scope to include both the first 15 pilot cities and the 13 new pilot cities, comparing service models and categorizing them into institutional care, home care, and non-conventional models tailored to local conditions [41]. In terms of service progress, some scholars have analyzed the current state of professional care personnel, disability assessment, care ratings, and service projects, with the aim of establishing standards for personnel qualifications, work processes, and service quality [42]. Huang [43] conducted a quantitative analysis of care resources in Chengdu, one of the first pilot cities, using Lorenz curves, Gini coefficients, and Theil indices to evaluate equity.\n\nIn terms of LTCI policy evaluation, various studies have employed quantitative methods. Zheng [44] developed a multi-tier evaluation framework for LTCI in Qingdao, Chengdu, and Shijingshan District in Beijing, incorporating core policies, management, and supporting linkages into 3 primary indicators, 10 secondary indicators, and 20 tertiary indicators. However, studies utilizing specialized policy tools for comprehensive evaluation of LTCI policies remain limited, with only a few researchers employing the Policy Modeling Consistency (PMC) index model for a thorough exploration of LTCI policy[45–48].\n\nIn summary, previous studies have largely focused on qualitative methods such as interviews, though some have utilized quantitative models and text analysis, yet no systematic framework has emerged. Much research has concentrated on mechanism construction, operational development, and service models, but systematic analysis of LTCI policy texts is lacking. Similarly, while some studies have applied the PMC index model to analyze LTCI policies, an academic framework has not yet been fully developed. This study, therefore, utilizes the PMC index model to scientifically evaluate China’s LTCI policies and mechanisms, aiming to provide new insights for the improvement of the LTCI system.\n\nThe Policy Modeling Consistency (PMC) index model is a policy evaluation tool that includes both economic and non-economic variables. It can be used to analyze the internal characteristics of any policy and scientifically quantify the advantages and disadvantages of different policies. In this study, binary values were assigned to all variables, and the PMC index was calculated to evaluate the institutional design of the policies.\n\nIn June 2016, the Office of the Ministry of Human Resources and Social Security of China issued the “Guiding Opinions on Conducting Pilot Programs for the Long-Term Care Insurance System,” which identified 15 cities as the first batch of LTCI pilot cities, while Jilin and Shandong provinces were designated as key liaison provinces. To further advance the development of the LTCI system and establish an independent insurance type, the National Healthcare Security Administration, together with the Ministry of Finance, issued the “Guiding Opinions on Expanding the Pilot Programs for the Long-Term Care Insurance System” in 2019. This expanded the number of pilot cities from the original 15 to a total of 49 cities, including the two key liaison provinces of Jilin and Shandong (Fig 1), aiming to create a social insurance system that funds long-term care for disabled individuals through mutual aid, covering basic daily living care and medical services.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g001\n\nBased on this, the selection of samples for this study follows China’s division of seven major geographical regions. A representative city from each region was selected for policy analysis: Northeast China, with Jilin Province as a key liaison province, selected Changchun as a representative of the first batch of pilot cities; in North China, Qingdao was chosen as it was the first to establish an LTCI pilot; East China selected Shanghai, a city with the dual status of the highest economic development level and a direct-controlled municipality; and Shijingshan District in Beijing, the only district-level pilot nationwide, was chosen as it holds significance for the broader rollout of the LTCI system. Additionally, to ensure a balance between the two batches of pilot cities and considering factors such as regional per capita GDP, aging rates, and the development of LTCI, 16 cities were selected for analysis, including Shihezi, Hanzhong, and Jingmen (Fig 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g002\n\nDuring the collection of long-term care insurance (LTCI) policies, the following retrieval strategies were employed to ensure the authority and comprehensiveness of the policy texts. First, policy documents were retrieved from the official websites of municipal governments, healthcare security departments, and human resources and social security departments in cities such as Changchun, Chengdu, Beijing, and Shanghai. Second, supplementary searches and verification of related policy documents were conducted through specialized databases such as “PKULaw” and the “China Long-Term Care Insurance Pilot Policy Database (CLIP).” After excluding notices, public announcements, news reports, and response letters, 66 valid policy documents were obtained. Given that the focus of this study is on the evaluation of LTCI policy design, 16 of the most recently issued special policy documents from each city were selected for analysis, as shown inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t001\n\nKeyword Extraction and Social Network Analysis of Long-Term Care Insurance PoliciesUsing ROST CM software, keyword extraction and social network analysis were conducted on 16 long-term care insurance policy documents. The results are shown inFig 3.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g003\n\nSocial network analysis provides important references for the design of variables in the construction of the PMC index model. In the social network analysis map, high-frequency keywords from the long-term care insurance policies are organized into a node network, visually reflecting the structural relationships between these high-frequency terms. High-frequency words are represented as nodes, with the size of each node indicating its centrality strength. The more connections a node has with other nodes, the stronger its degree of centrality, indicating the greater importance of that node [49].\n\nFromFig 3, it can be observed that: (1) “care,” “personnel,” “insurance,” and “medical” occupy central positions with the highest degree of centrality and the most connections to other keywords. These core themes indicate that the policy texts of long-term care insurance in various pilot cities focus on care, insurance content, medical services, and personnel. (2) Peripheral keywords include “services,” “funds,” and “enrollment,” which reflect the current focus of long-term care insurance policies on service content, fund operations, and the scope of enrollment. (3) Terms such as “payment,” “administration,” and “standards” indicate that long-term care insurance policies also address payment standards and the management of administrative agencies.\n\nFollowing the modeling principles of the PMC index model, which emphasize multi-dimensional data processing through the use of multiple input-output matrices, this model requires consideration of the interaction between various factors and variables to assess the full impact of policies [50]. Additionally, the model is systematic and structured, with variables classified and parameters identified to emphasize the role and interrelations of each element, ensuring a clear and organized framework. The quantification and evaluation principle of the PMC index ensures that the model includes measurable standards for evaluating consistency and effectiveness, providing a scientific basis for decision-making. Finally, visualization and communication are integral, with the PMC surface (graphical representation) allowing for easier interpretation and understanding of model results, ensuring that policy recommendations are accessible to policymakers [50].\n\nIn line with these principles, variables X1 to X10 were established to construct the PMC index model for evaluating pilot policies of long-term care insurance. The secondary variables for the insured population (X1), covered groups (X2), payment standards (X4), involvement of commercial insurance (X5), financing channels (X7), financing methods (X8), and fund operation (X9) were defined based on the research by Wang [47]. The X3 variable was adjusted to include family caregiving services, which play a key role in long-term care insurance by offering flexible care options that reduce the burden on medical institutions and provide more personalized care in home settings. This adjustment is aligned with findings by Brendan,who emphasized that family health care is a critical component of long-term care insurance, addressing diverse needs such as daily living assistance, medical care, and psychological support for the elderly and disabled. However, it also faces challenges in terms of service quality, workforce training, and financial sustainability. The inclusion of this variable is based on the specific content of the pilot policy texts that highlight the growing importance of family caregiving services in providing cost-effective, quality care to individuals in home environments.\n\nAdditionally, service management (X6) and executive department (X10) variables were defined according to the social network analysis map of long-term care insurance policies. These variables reflect the core elements of long-term care insurance in China as outlined by Wang [47], who identified four key components that define the actual characteristics of LTCI: Capital (funding resources), Object (beneficiaries), Standard (quality evaluation criteria), and Supply (service provision). Regarding payment standards, the transparency and clarity of these standards are critical to ensuring the fairness and effectiveness of the LTCI system. As highlighted by Peng et al. [48], clear and transparent payment standards enable policymakers and the public to understand the coverage and conditions of insurance, which enhances the trust in the system and supports its long-term sustainability. The clarity of payment mechanisms is essential to avoid confusion and disputes, ensuring that beneficiaries can accurately assess their insurance entitlements and benefits. These components form the foundation for assessing the practical implementation and sustainability of LTCI policies.Ultimately, this includes 10 primary variables and 40 secondary variables, as detailed inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t002\n\nRuiz Estrada [50] outlined the specific steps for calculating the PMC index as follows:\n\nConstruct variables based on the policy texts, including primary and secondary variables, as shown in Equation(1):\n\nEstablish a multi-input-output table, and assign specific values to the secondary variables based on the binary method, as shown in Equation(2):\n\nCalculate the values of the primary variables using the values assigned to the secondary variables in the previous step, as shown in Equation(3):\n\nIn the equation, t represents the primary variable, and j represents the secondary variable.\n\nSum the values based on the above equations to calculate the PMC score for each policy, as shown in Equation(4).\n\nThe classification standards for policy evaluation results are set according to the method proposed by Estrada et al. (Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t003\n\nFrom this, the PMC index and policy grades for each digital economy policy are derived, as shown inTable 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t004\n\nThe PMC index of long-term care insurance policies from the 16 pilot cities indicates (Table 4) that one policy text achieved a “perfect” rating, two were rated as “excellent,” 11 were rated as “acceptable,” and two were rated as “poor.” The proportion of policies rated as “perfect” and “excellent” is 18.75%.\n\nRegarding the local policies across various dimensions,Table 4shows that the PMC values for commercial insurance participation (X5), financing methods (X8), and covered population (X2) exhibit the highest degree of variation, indicating significant differences in policy design across these dimensions. In terms of commercial insurance participation (X5), most cities allow commercial insurers to participate in the administration of long-term care insurance, but there is still no clear policy direction regarding the assessment of commercial insurance involvement and the provision of service products (Fig 4). This lack of clarity hinders the activation of private capital and the expansion of service diversity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g004\n\nIn May 2020, the National Healthcare Security Administration officially released the ‘Guiding Opinions on Expanding the Pilot Programs for the Long-Term Care Insurance System’ (Healthcare Security Administration Document [2020] No. 37) [National Healthcare Security Administration, Ministry of Finance, May 2020]. This document provided important guidance on the involvement of social forces in the administration of long-term care insurance and the role of commercial insurance, aiming to establish a multi-tiered long-term care security system that meets the diverse needs of the public. Specifically, it clarified that administrative management fees can be covered by the medical insurance fund, thereby creating opportunities for commercial insurance companies to participate in long-term care insurance. This encourages commercial insurance to play a role in addressing regional and demand differences, thus reducing the fiscal burden on the government.\n\nThe Guiding Opinions not only emphasize multi-tiered coverage and the integration of social forces into the long-term care system but also introduce a framework for shared responsibility in funding and service provision. These principles align with the PMC index model by ensuring that financial sustainability and system equity are at the heart of policy development. This document served as a critical foundation for the PMC index model by influencing the establishment of variables related to financing channels (X7), financing methods (X8), and fund operation (X9), which are crucial for evaluating the economic sustainability of LTCI systems.\n\nFurthermore, the Guiding Opinions align with international best practices by promoting the integration of commercial insurance into the social insurance system, which is a concept also advocated in Germany’s long-term care insurance system. The PMC index model incorporates these insights, reflecting a hybrid financing model that combines public and private resources, ensuring the flexibility and scalability of LTCI systems to meet diverse population needs. By considering both local policy context and international experiences, the PMC index model is adapted to evaluate China’s LTCI pilot policies more effectively, taking into account both the institutional design and financial mechanisms that will support the system’s long-term sustainability.\n\nFinancing Channels (X7) and Financing Methods (X8) reflect the design of the financing mechanism.From the analysis of financing channels (X7), Jingmen, Chengde, and Nanning scored significantly lower (Fig 4). The vast majority of pilot regions rely on financial subsidies, contributions from employers and individuals, followed by the transfer of surplus from the medical insurance fund and social donations. However, consolidating a diversified financing mechanism does not mean accumulating as much capital as possible; instead, the focus should be on enhancing the efficiency of fund utilization, improving the protection of the insured, and maximizing the social benefits of the system. If expenditures are insufficient, it may increase the burden of fund management and operations.\n\nIn terms of financing methods (X8), the financing models for long-term care insurance can be divided into three types: proportional financing, fixed-amount financing, and mixed financing. Proportional financing refers to a system where different payers in the pilot regions contribute according to a set proportion based on a designated payment base. Pilot regions that have adopted proportional financing include Chengde, Kunming, Jincheng, Shanghai, Guangzhou, Fuzhou, and Panjin. Unlike proportional financing, fixed-amount financing stipulates that all payers must contribute a specific amount of premiums within a given period. Nanning and Shihezi are examples of pilot regions that use fixed-amount financing. Mixed financing combines both proportional and fixed-amount methods, tailored to different insured groups. Pilot regions using mixed financing include Chengdu, Jingmen, Changchun, Shanghai, Kaifeng, Qingdao, Hanzhong, and Beijing (Shijingshan District).\n\nFixed-amount financing does not vary according to personal income or economic status, making it simple to implement and resulting in lower administrative costs. Proportional financing, on the other hand, adjusts the contribution base according to economic growth and increases in personal income. Under equal benefits, higher-income individuals contribute more, thereby reflecting the social insurance function of income redistribution.\n\nAs shown inTable 4, the scores for service content (X3) and coverage (X1) are relatively concentrated across regions. In terms of service content, the services provided are fairly consistent among regions. However, it is worth noting that leading cities in the PMC index, such as Qingdao and Shanghai, lack a focus on family caregiving services in their policy texts. Family caregiving services refer to a model where relatives of the insured receive training and, upon certification, provide care to the insured, for which they are paid a monthly fee. By utilizing the care resources within the families of insured individuals and relieving them of the unpaid “caregiving role,” this approach extends the reach of services.\n\nRegarding coverage (X1), the ratio of policies covering both employees and residents in the “perfect” and “excellent” categories is 1:1. For the other two secondary variables, the number of policies with assigned values is relatively low. Since the PMC index assumes equal weights for all primary variables, these differences did not affect the overall PMC index results.\n\nA comparison of the long-term care insurance policy texts between the first and second batches of pilot cities reveals the following (as shown inTable 5): First, the scores for X2 and X7 are the same in both batches of cities, indicating that the expansion of the coverage groups was minimal and the financing channels were clearly defined. Second, the first batch of pilot cities scored higher on X1, X3, X4, X5, X6, X8, and X9 compared to the second batch. This is because the first batch of cities started their pilots earlier—Qingdao, for example, has had long-term care insurance policies for over 10 years. Additionally, the first batch includes two direct-controlled municipalities and two key liaison provinces, and Sichuan Province has also issued provincial-level guidance for the long-term care insurance pilots. As a result, the policy designs in the first batch pay more attention to detailed provisions regarding protection, administration, financing, and operations, which are comparatively more comprehensive than those in the second batch. In terms of coverage (X1), 87.5% of the first batch of pilot cities achieved universal coverage, while only 37.5% of the second batch included both urban and rural residents.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t005\n\nThird, the second batch of pilot cities scored higher on X10 (executive departments) than the first batch. The most notable difference is the involvement of tax departments in the second batch. In contrast, cities in the first batch, such as Shihezi and Changchun, only mentioned the healthcare departments in their policy texts, lacking coordinated issuance and integrated institutional arrangements. This fragmentation, with policies and funds spread across multiple sectors such as civil affairs, health, and disability organizations, often results in a lack of unified efforts, with each department acting independently. However, the “Guiding Opinions on Expanding the Pilot Programs for the Long-Term Care Insurance System” (Healthcare Security Administration Document [2020] No. 37) has brought about significant improvements in coordination among relevant departments and strengthened top-level design.\n\nTo more intuitively present policy scores, as well as their strengths and limitations, a PMC surface can be constructed based on the PMC index. The PMC index model for long-term care insurance policies contains 10 primary variables. Since most long-term care insurance policies cover urban employees, rural and urban residents, flexibly employed individuals, and people over the age of 60, variable X1 was excluded, and a 3 * 3 matrix was constructed as follows:\n\nTo clearly and intuitively reflect the strengths and limitations of policy design in both batches of pilot cities and to showcase the results of the quantitative evaluation, representative policies were selected and their PMC surfaces were plotted. PMC surfaces are typically uneven 3D graphs, with different color blocks representing varying indicator scores. As shown inFigs 5–9, the raised areas in the surface graph indicate higher scores for the primary variables, while the recessed areas indicate lower scores.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.g009\n\nThe PMC index model selected 10 primary variables and 40 secondary variables, and the values of the primary variables were calculated using the PMC index model formulas. By calculating the standard deviations and variances of these primary variables, the PMC values for 16 cities were obtained. Four cities were selected as representative policies, based on the PMC index criteria and the actual situations of the pilot cities. The representative policies include: (1) Qingdao (P9), from the “perfect” category, (2) Kaifeng (P5), from the “excellent” category, (3) Guangzhou (P12), from the “acceptable” category, and (4) Panjin (P15), from the “poor” category.\n\nAdditionally, to provide an overall impression of the 16 sample cities and facilitate better comparisons, a virtual policy (P17) was constructed based on the average values of the primary variables from the 16 selected policies in the sample cities, as shown inFig 5.\n\nThe average PMC index value calculated for the 16 prefecture-level cities is 6.217, which falls within the “acceptable” range and approaches the “good” category. From the shape ofFig 5, despite the overall average evaluation being “good,” the surface is relatively smooth, indicating that, on average, the internal consistency of long-term care insurance policies across the 16 pilot cities is high, with balanced development across various aspects of the policy, leading to a reasonably structured system.\n\nCompared toFig 6, the values for Qingdao’s 9 primary variables are significantly higher than the average of the 16 cities. Six variables—covered population (X2), payment standards (X4), commercial insurance participation (X5), service management (X6), financing channels (X7), and fund operations (X8)—all scored full marks. Especially for the covered population (X2) variable, which scored full marks, analysis of Qingdao’s policy shows that although the 2012 version of Qingdao’s long-term care insurance (1.0) did not explicitly define the categories of disabled and cognitively impaired elderly, it proposed two relatively vague concepts: (1) Insured individuals who, due to old age, illness, or disability, have lost some or all bodily functions, are bedridden for long periods, and are unable to care for themselves, requiring long-term medical care in designated care institutions; (2) Insured individuals who, due to old age, illness, or disability, have lost some or all bodily functions, are bedridden for long periods, and require medical care to be provided at home due to changes in their condition. These concepts have gradually evolved over time, with individualized service requirements emerging for disabled and cognitively impaired elderly. In response, Qingdao’s 2018 version (2.0) of the long-term care insurance policy made detailed distinctions between these two groups to ensure more precise services.\n\nCompared to other sample cities, Qingdao’s financing channels (X7) reflect a diversified funding model. Not only does it rely on the medical insurance fund pool, but it also balances payment standards (X4) and financing methods (X8), reflecting a well-coordinated approach to fund operations. This allows Qingdao to provide higher quality and more refined services, indirectly improving the quality of long-term care services (X3) in the region. Furthermore, Qingdao has established detailed regulations on fund evaluation and supervision, which have contributed to a perfect score in the fund operations (X9) variable. Among all the sample cities, Qingdao is the only one with a perfect score in this variable. In addition to maintaining separate accounts and audits, Qingdao has also made detailed plans for funding the prevention of disability and cognitive decline. The “Notice on Issuing the Qingdao Long-Term Care Insurance Plan” in 2021 [Qingdao Municipal Government Office, March 2021, “Notice on Issuing the Qingdao Long-Term Care Insurance Plan” stipulates, “A prevention and delay fund for disability and cognitive decline shall be established, with up to 3% of the annual long-term care insurance funds for employees and residents allocated for this purpose.” This demonstrates that Qingdao not only excels in differentiating services for disabled and cognitively impaired elderly, but also places great emphasis on preventive measures for these conditions.However, it should be noted that although Qingdao has differentiated payment ratios for different contribution levels, it has not yet implemented a “longer contribution, higher benefits” system, which may represent a limitation in the policy.\n\nBased on the above analysis, it is evident that Qingdao’s long-term care insurance policy is relatively well-developed and reasonable, with a well-established service mechanism. According to available policy documents and other materials, Qingdao, as one of the key pilot cities in the first batch of long-term care insurance trials, launched its long-term medical care insurance system (referred to as “long-term medical care system”) in 2012, ahead of the rest of the country. Prior to this, in response to the central government’s call to streamline administration and delegate power, Qingdao established community-based medical insurance fund management offices in 2005 and began developing community healthcare institutions and home care beds. In 2006, elderly medical care was incorporated into the community medical insurance system, and nursing homes and elderly care institutions with qualified medical care services were included in the medical insurance network. With the increasing pressure of health service demand and medical care resources brought by the aging population, Qingdao’s approach—aimed at both improving the efficiency of medical resources and funds, and providing more targeted and adaptable basic medical care services—was formulated after multiple rounds of calculation and coordination with various departments. Ultimately, the city proposed the establishment of a long-term medical care insurance system within the framework of the urban basic medical insurance system, starting a pilot program in July 2012. Qingdao’s policy has evolved over nearly a decade, continuously improving and adapting based on practical implementation, with a goal of achieving diversified, personalized, and humanized services. This analysis shows that Qingdao provides a relatively complete and practical blueprint for long-term care insurance system design, offering valuable lessons for other cities.\n\nKaifeng ranks second among the policies classified as ‘excellent,’ just behind the economically developed city of Shanghai, with a PMC index value of 7.50, nearly one point higher than the average, placing it in the ‘excellent’ category (Fig 7). As a second-batch pilot city, Kaifeng officially introduced its long-term care insurance policy in 2021. According to the Kaifeng municipal government’s website, relevant departments involved in the formulation of Kaifeng’s long-term care insurance policy conducted multiple field visits to first-batch cities such as Shanghai and Nantong in 2020 to learn from their advanced experiences. Based on this research, Kaifeng issued the ‘Trial Measures for the Long-Term Care Insurance System of Kaifeng’ on December 29, 2020.\n\nCompared toFig 5, the policy design in Kaifeng is relatively reasonable. Except for the covered population (X2) and financing channels (X7), which are below the average, the other seven primary variables are above the average, with four primary variables scoring full marks. The average score for the covered population (X2) is only 0.25. Among the 16 sample cities, only Qingdao, Hanzhong, and Shanghai include the cognitively impaired population, while the other 13 pilot cities only address the physically disabled, which may lead to a lack of targeted services and measures in the future, affecting the precision and quality of long-term care services.\n\nIn terms of financing channels (X7), Kaifeng has not established clear regulations for converting the medical insurance fund into the long-term care insurance fund, which could increase the financial burden on individuals participating in long-term care insurance and hinder the long-term sustainability of the policy. However, on the other hand, not relying heavily on medical insurance funds reduces the risks associated with the financing mechanism. Meanwhile, Kaifeng scored full marks for the financing methods (X8), as it balances both fixed-amount and proportional financing, addressing both fairness and efficiency, and facilitating easier management and calculations.\n\nRegarding service content (X3), Kaifeng’s policy specifies, ‘Home-based autonomous care refers to the form of care where a family member of the insured, after receiving qualified training, provides care for the insured. The maximum monthly payment from the long-term care insurance fund is 900 yuan per person’ [Kaifeng Municipal Government Office, December 2020, ‘Trial Measures for the Long-Term Care Insurance System of Kaifeng’]. This inclusion of family caregiving services innovates the service content and also specifies that ‘during the period of receiving benefits, the insured may choose one form of care service, and the service type can be changed,’ which further reflects the humanization and flexibility of the policy.\n\nIt is undeniable that Kaifeng’s high PMC index score, surpassing that of more developed regions, is due to strong government support. The Kaifeng municipal government has played a pivotal role in ensuring the successful implementation of the long-term care insurance system through effective policy framework and system building. The local government introduced a comprehensive set of policies and regulations, including the issuance of 19 policy documents, such as the Trial Measures for the Long-Term Care Insurance System of Kaifeng. Additionally, Kaifeng’s financing model, incorporating multiple funding sources like unit and individual contributions and fiscal subsidies, has contributed to the program’s financial sustainability.\n\nFurthermore, Kaifeng has taken significant steps to raise public awareness and promote participation in the program. According to the Kaifeng Medical Security Bureau’s survey, 9388 residents benefiting from the long-term care insurance expressed satisfaction with the policy, citing improvements in their quality of life and reduced financial burden. As of September 2023, 420,000 people were enrolled, and 18,307 people were receiving benefits, with a total payout amounting to 145 million yuan. The program has not only reduced the financial burden on families of disabled individuals but also significantly improved their living standards, which has led to increased public approval and positive feedback. The introduction of a positive policy feedback mechanism has further enhanced resident satisfaction, demonstrating the government’s commitment to providing sustainable and effective care for its citizens.\n\nCompared toFig 5, Guangzhou scores (Fig 8) below the average on two primary variables: commercial insurance participation (X5) and financing methods (X8), while its service content (X3) matches the average. The other six primary variables score above the average. Guangzhou’s PMC index value is 6.97, slightly above the average. As one of the first-batch pilot cities, Guangzhou officially launched its long-term care insurance program in 2017 and has gone through three stages: initiation, development, and deepening. In 2021, Guangzhou fully reformed its long-term care insurance system based on the Guiding Opinions on Expanding the Pilot Programs for the Long-Term Care Insurance System.Regarding commercial insurance participation (X5), Guangzhou’s policy lacks detailed provisions. The policy only mentions commercial insurers’ involvement in administration but does not provide specific guidelines for operations or service provision. There is limited regulation on the role of commercial insurance in providing services, assessing disability, and managing funds. This insufficient involvement of commercial insurance results in a single source of funding, inadequate risk-sharing, and a lack of service diversity. The core issue lies in the fact that Guangzhou’s policy remains heavily government-driven, with a tendency toward risk control. As a result, it relies more on the medical insurance fund and fiscal support, while avoiding the potential uncertainties of involving commercial insurers, such as management issues, increased regulatory costs, or conflicts of interest.\n\nIn terms of financing methods (X8), Guangzhou adopts proportional financing, which ensures fairness but poses challenges in regulation. There is a gap between income and expenditure, and the lack of a hybrid financing model (combining fixed-amount and proportional financing) reduces the policy’s flexibility and makes it difficult to cater to insured individuals with different economic backgrounds. Guangzhou’s financing mechanism heavily depends on the transfer of surplus from the medical insurance fund, neglecting fiscal appropriations and social donations. This increases the burden on the medical insurance fund, with no flexible financing mechanism in place. Moreover, the policy does not set differentiated financing standards for groups with different income levels, leading to lower participation rates among low-income groups.\n\nOverall, the weaknesses in commercial insurance participation and financing methods result in Guangzhou’s long-term care insurance policy scoring lower than excellent examples like Qingdao. The main issues in Guangzhou’s policy are the lack of market involvement and a single financing mechanism. Guangzhou should learn from the perfect and excellent pilot cities by focusing on improving policy stability, enhancing disability assessment accuracy, and encouraging commercial insurers to develop long-term care products. Future improvements should target expanding commercial insurance participation, introducing a hybrid financing model, and strengthening support for family caregiving services. Specific measures could include enhancing administration, diversifying care services, and expanding product offerings.\n\nFig 9shows that Panjin’s PMC index ranks at the lower end of the sample, placing it in the “poor” policy category. The surface chart reveals significant depressions, with only two primary variables—payment standards (X4) and executive departments (X10)—scoring above the average, while the rest are below average. Particularly for commercial insurance participation (X5), Panjin scores 0, indicating that its policy did not consider the importance of commercial insurance participation or, due to local circumstances, was unable to implement it. The lack of involvement from commercial insurance and other third parties may affect service quality and the orderly operation and improvement of the long-term care insurance system. Panjin has a weaker economic foundation, and the smaller scale of its economy limits its ability to attract commercial insurers. Additionally, local governments may be concerned that commercial insurance participation could lead to higher premiums and unstable service quality. Combined with conservative policy design, Panjin’s long-term care insurance remains government-dominated, with minimal risk-taking.\n\nFinancing channels (X7) also show certain limitations. Panjin’s policy relies heavily on the surplus of the medical insurance fund and does not fully utilize diversified financing channels such as fiscal appropriations, social donations, and charitable funds. As a small to medium-sized city, Panjin faces significant pressure on its medical insurance fund, and over-reliance on surplus funds could lead to financial strain, affecting the normal operation of the medical insurance system. Additionally, local fiscal resources are limited, and the lack of sufficient local fiscal investment makes it difficult to support long-term care insurance on a larger scale. Panjin’s financing structure limits the sustainability of its policy and leads to financial stress. This issue aligns with a common challenge in China’s long-term care insurance pilots—single-source financing that fails to introduce more market forces or social donations to alleviate financial pressure.\n\nFor small to medium-sized cities, two key issues are insufficient fiscal support and limited financial resources, as well as the lack of family caregiving support and community care models. The service content remains relatively singular, unable to meet diverse needs. This also leads to lower scores in covered population (X2), as the policy does not clearly differentiate among the covered groups. This is similar to the difficulties faced by many small to medium-sized pilot cities nationwide, where most resources are concentrated on institutional care, while more cost-effective home-based care models are overlooked. The underlying reason is that smaller local governments lack sufficient resources to develop diverse care services, particularly family caregiving. Additionally, their limited experience in promoting home-based and community care has resulted in incomplete policies and insufficient execution capabilities.\n\nThe low PMC index scores in poor-performing cities are partly due to the late implementation of long-term care insurance and limited development experience, and partly due to lower levels of economic development.\n\nFrom the analysis of the four representative policies, we can conclude that Qingdao, which falls under the “perfect” category, scores near full marks for all variables except for the absence of specific provisions on family caregiving services. Kaifeng, in the “excellent” category, has shortcomings in covered population, as it does not include the cognitively impaired elderly, and its disability assessment is not sufficiently detailed. Additionally, its financing channels are limited, and it has not fully utilized the medical insurance fund during its initial stages of operation. Guangzhou, in the “acceptable” category, lacks detailed provisions on commercial insurance participation, which could lead to unclear responsibilities and gaps in service content. Finally, Panjin, in the “poor” category, faces numerous challenges, with the most significant being the lack of commercial insurance participation in the operation of long-term care insurance, which needs continuous improvement.\n\nFundamentally, the differences in policy content between pilot cities reflect variations in local governments’ understanding of long-term care insurance and their capacity to provide protection. The design of institutional plans also reflects the practical direction of local decision-makers. Cities with lower PMC index scores should tailor policy improvements based on their specific development context and indicator performance, in order to better guide the practice of long-term care services.\n\nIn reviewing the entire process of establishing the long-term care insurance policy evaluation index system and PMC surface using the PMC index model, the analysis was divided into two parts: an analysis of the ten policy evaluation dimensions and an analysis of the degree of improvement in representative policies from both batches of pilot cities. The study also ranked the policies of the 16 pilot cities comprehensively. Finally, it identified the essential problems in specific indicators of long-term care insurance policies and highlighted areas for broader implementation. The practice of long-term care services requires policy support and protection, and the PMC index clearly reveals the practical functioning of the long-term care insurance system. Based on the model construction, five recommendations were identified as having a positive effect on improving the long-term care insurance system.\n\nAlthough the analysis results of the PMC index model showed that Shanghai did not meet the family caregiving service policy standards, as early as 2005, Shanghai proposed the “9073” elderly care service model. This model emphasizes that 90% of elderly care is provided by the family, 7% through community home care services, and 3% through institutional care services. This approach takes into account both the adaptability of the elderly to their environment and the issue of economic burden, and it remains a widely advocated model in long-term care insurance systems. However, the PMC index model revealed several issues with family caregiving services within the broader range of care services, including institutional care, home-based care, hospital medical care, community day care, and family caregiving services.\n\nFrom the analysis of the relationship between commercial insurance participation and family caregiving services across the 16 pilot cities, it was found that most cities have linked family caregiving services to commercial insurance participation [51–53]. Since commercial long-term care insurance is fully voluntary, where both the insured and the financing entity are individuals, the role of family decision-making becomes particularly important.\n\nAmong the five cities that comply with family caregiving service policies—Chengdu, Kaifeng, Kunming, Jincheng, and Beijing—each requires professional caregiver training as a prerequisite. In this regard, developed countries such as Germany, Japan, and the United States have promoted family caregiving through different systems: broad mandatory public long-term care insurance, mandatory public long-term care insurance for specific groups, and voluntary commercial long-term care insurance. Scholars have compared these systems and highlighted their distinctions (seeTable 6). Among the three, the U.S. long-term care insurance system was found to be the most effective, followed by Germany, with Japan ranking third [54].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t006\n\nBased on these insights, this study draws on the experience of the U.S. voluntary commercial long-term care insurance system, supplemented by Germany and Japan’s mandatory public long-term care insurance models. It emphasizes the role of national policy in guiding long-term care insurance and suggests that China could benefit from integrating more flexible commercial insurance options to better support family caregiving services. Additionally, it is crucial to coordinate the flexibility of commercial insurance with the mutual assistance of public insurance, establish a comprehensive third-party review agency, implement strict disability assessment standards, and actively leverage market mechanisms.\n\nThe results of the PMC index model indicate that the policies of Nanning, Chengde, and Jingmen perform poorly in terms of financing channels, with structural imbalances between conventional and unconventional financing methods. Additionally, Nanning’s overall policy is weak in terms of financing methods, where internal structural inconsistencies are evident.\n\nA review of long-term care insurance financing mechanisms abroad reveals that Germany, Japan, and South Korea primarily adopt social insurance, commercial insurance, allowance-based, or mixed models, forming stable long-term care insurance financing systems involving individuals, employers, and the government [11]. In contrast, China’s long-term care insurance financing mechanism has evolved from the cooperative medical system of the 1950s to the urban and rural residents’ basic medical insurance, a system that merged the new rural cooperative medical system and the urban residents’ basic medical insurance [55]. This merged system retained the basic model of the earlier medical financing systems, where each person pays a fixed amount of medical insurance. According to statistics from the National Healthcare Security Administration, from 2016 to 2021, individual contributions to China’s urban and rural residents’ medical insurance increased from 150 yuan per person per year to 320 yuan per person per year, with an average annual increase of about 30 yuan. Although this fixed-amount financing method is equal in contributions and easy to implement, it essentially mirrors the financing model of commercial insurance in a market-based system [11]. Commercial insurance is a market transaction between the insurer and the insured, governed by market economic principles. It does not account for the varying payment capacities of policyholders and charges fixed premiums based on individual risk and insurance needs [13].\n\nChina’s urban and rural residents’ basic medical insurance is a government-led social basic medical insurance system targeting all non-employed residents, and adopting the commercial insurance financing model would be inappropriate. Fixed-amount financing results in unequal payment burdens for different income groups, creating a reverse adjustment effect where low-income groups “subsidize” higher-income groups, violating the principle of fairness in “ability-to-pay” financing.\n\nThe core value of modern social security is fairness, and promoting social equity is a fundamental goal of social security. As an essential aspect of social security, social insurance should ensure fairness at the starting point, maintain fairness in the process, and strive to reduce inequalities in outcomes among social members. Social insurance funds not only provide economic protection for society’s members but also help regulate income distribution. Thus, social insurance should be financed based on individuals’ capacities, with higher-income earners paying more and lower-income earners paying less. The principle of “contributing based on ability and receiving based on need” can effectively adjust income distribution, reduce income disparities between different groups, and promote social equity.\n\nIn principle, proportional financing should be calculated based on household disposable income per capita, with a specific percentage of that income set for contributions. Furthermore, support should be provided to low-income families, such as lowering their contribution rates or increasing fiscal subsidies, to promote equity in financing and fairness in the system.\n\nThe PMC index analysis of the coverage and executive departments of long-term care insurance reveals several issues, including uneven distribution of resources between urban and rural elderly, resource waste, and discrepancies in medical insurance benefits between different parts of the same city. Specifically, among the 16 pilot cities examined in this study, only Changchun and Guangzhou had relatively balanced policy resource allocation, while the others exhibited varying degrees of imbalance [56,57].\n\nFor urban employees, the policies of all 16 pilot cities addressed the issue, clearly specifying that those covered by social medical insurance should also participate in either employee or resident long-term care insurance. Comparing Germany’s coverage and protection of insured individuals, the German long-term care insurance system achieves universal coverage (Table 7) [57], and the range of beneficiaries is gradually expanding, with both the number and proportion of beneficiaries increasing. In contrast, China’s long-term care insurance covers a smaller population (seeTable 8), with the main beneficiaries being severely disabled elderly individuals. Most regions do not extend coverage to moderately or mildly disabled individuals, nor to those with cognitive impairments.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t008\n\nCurrently, as the long-term care insurance system is still in the pilot stage in the 16 regions, the government can address the issue of geographical inequity in care resources by coordinating the overall layout and providing policy incentives for the strategic placement of long-term care service institutions. Based on the care service needs of insured individuals in different areas, the government can integrate internal care resources, promote the integration of care institutions within each region, and encourage collaboration and communication between institutions. This would facilitate resource sharing and information exchange. At the same time, insufficient overall resources remain a major constraint on the utilization of long-term care services, and increasing resource investment is the primary way to resolve this issue. Thus, it is crucial to encourage qualified institutions to participate, reasonably set entry standards, and provide policy incentives such as tax reductions to alleviate financial burdens.\n\nAn analysis of the PMC index for the covered population indicates that many policy documents focus on elderly individuals with disabilities, particularly those with severe disabilities, while attention to the cognitively impaired elderly remains limited, regardless of the severity of their condition. Furthermore, while policies involving medical insurance departments, civil affairs departments, and finance departments are relatively well-developed, those from human resources and social security departments, as well as health departments, require further improvement. Although current long-term care insurance policies emphasize elderly individuals with disabilities, there is an urgent need to increase focus on cognitively impaired individuals and develop corresponding measures.\n\nAt the same time, the potential for the reversal of “disability” in elderly individuals and the flexible transition between severe and mild disability highlight the lack of a reasonable standard for determining “disability” in current policies. This leads to procedural issues in policy formulation. Additionally, the relatively low attention given to cognitively impaired individuals further complicates the practical aspects of developing long-term care insurance policies for this group.\n\nGermany’s care levels are divided into three categories: moderate, severe, and very severe care needs [7]. In comparison, China’s long-term care insurance primarily covers only those with severe disabilities. In Germany, after submitting a claim, the insured is assessed through an in-home care evaluation conducted by the medical insurance review agency, which determines the appropriate care level based on the results. Germany’s approach can help address the issue of defining disability in China, especially given the flexibility in how disability is assessed. Germany’s long-term care insurance also follows the principle that home care takes precedence over institutional care (Table 9), with home care receiving more policy support than institutional care.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321057.t009\n\nTherefore, based on the German experience, China’s long-term care insurance system should consider expanding benefit eligibility to include individuals with moderate disabilities, aiming to achieve broad coverage. At the same time, regarding the issue of disability standards, China could draw lessons from Germany’s experience. For cognitively impaired individuals, Germany’s principle of prioritizing home care over institutional care could offer valuable insights [7].\n\nIn terms of the service content of long-term care insurance, from family caregiving services, institutional care, hospital medical care, to community day care and finally home-based care, the scope of services and delivery methods are continually expanding. Regarding service management, the system plays a preventive role by standardizing the management of service institutions, strengthening the training of caregivers, promoting the digitalization of insurance management, encouraging third-party participation, and implementing re-evaluation of disability assessments. These measures influence the various stakeholders—both service providers and beneficiaries—within different fields. Regarding fund operations, dedicated accounts, the establishment of a disability and cognitive impairment prevention fund, and a long-term care insurance reserve fund (risk contingency fund) continue to expand their inherent functions.\n\nFor the pilot cities, long-term care insurance is still in the experimental phase, where the approach has been described as “crossing the river by feeling the stones.” In Qingdao, the first pilot city, the system initially covered only medical care. However, as the pilot reforms deepened, coverage expanded to include both medical care and daily living assistance. Medical care primarily focuses on health management and maintenance treatments, while daily living assistance includes long-term care, rehabilitation training, palliative care, end-of-life care, and emotional support, covering a total of 61 different services.\n\nFrom the experiences of Japan and Germany, which have established sustainable long-term care insurance systems, both countries have developed relatively mature operational models in terms of financing mechanisms and service provision [11]. Specifically, Japan’s long-term care insurance is funded by a combination of government taxes, long-term care insurance contributions, and individual payments. From the supply-side perspective, Japan has divided care services into health promotion, care prevention, rehabilitation, home care, and institutional care. In Germany, social long-term care insurance is financed through a pay-as-you-go system, with the principle of home care taking precedence over institutional care in terms of service provision. These countries have thus reached a relatively advanced stage in both financing and service provision.\n\nThe rich experiences of Japan and Germany in terms of financing mechanisms and service provision can serve as excellent models for establishing and improving China’s long-term care insurance system [10]. However, it should also be noted that both countries face issues such as insufficient insurance reserves, a shortage of caregivers, and complex administrative processes in their long-term care insurance systems. Therefore, while China can learn from international experience, it must also adapt these lessons to its national context and continue to adopt a “crossing the river by feeling the stones” approach.\n\nGiven the deepening aging of China’s population, the rate of funding growth for commercial long-term care insurance may slow. At the same time, upon reflection, it becomes clear that there are numerous issues with family caregiving services. In this context, commercial insurance participation can play a positive role by helping manage operations and providing products and evaluations [7]. This can effectively alleviate the current pressures on public long-term care insurance and further expand the scope of coverage.",
    "category": "geography"
  },
  {
    "title": "Association between hyperlipidemia and nephrolithiasis: A comprehensive bioinformatics analysis deciphering the potential common denominator pathogenesis",
    "authors": "Zhikai Su, Zhenjie Ling, Haoqiang Chen, Lei Hu, Songtao Xiang, Qian Li, Jianfu Zhou, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321734",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321734",
    "content": "Evidence suggests that nephrolithiasis and hyperlipidemia are linked. The study is designed to identify diagnostic biomarkers for nephrolithiasis in conjunction with hyperlipidemia using bioinformatics analysis, while exploring the potential common denominator pathogenesis.\n\nThe NCBI Gene Expression Omnibus (GEO) database provided separate datasets for nephrolithiasis and hyperlipidemia. We employed the R limma package to detect differentially expressed genes (DEGs), which were subsequently analyzed for enrichment using Gene Set Enrichment Analysis (GSEA), Gene Ontology (GO), and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways. Immune cell infiltration was analyzed by the CIBERSORT method. The WGCNA-R package clustered genes with similar expression profiles, followed by an analysis of the associations between the modules and specific traits or phenotypes. The STRING database was utilized to establish a protein-protein interaction (PPI) network and key functional modules, which were then analyzed using Cytoscape software. Diagnostic genes for both diseases were screened from core hub genes using least absolute shrinkage and selection operator (Lasso) regression. Subsequently, we generated receiver operating characteristic (ROC) curves to validate the predictive ability of these diagnostic genes for diagnosing nephrolithiasis in combination with hyperlipidemia. Lastly, the Network Analyst platform facilitated the construction of transcription factor-gene (TF-gene) and TF-miRNA regulatory networks.\n\nBased on datasets of nephrolithiasis and hyperlipidemia, we identified 167 DEGs and 74 hub genes through WGCNA. Using PPI networks and machine learning techniques, we recognized three frequently diagnostic genes (HSP90AB1, HSPA5, and STUB1), which demonstrated high diagnostic validity. The functional enrichment of these three diagnostic genes primarily involved pathways related to cellular metabolism.\n\nOur study identified three candidate diagnostic genes that can predict nephrolithiasis in conjunction with hyperlipidemia, providing a solid foundation for further exploration into the pathogenesis of nephrolithiasis and hyperlipidemia.\n\nCitation:Su Z, Ling Z, Chen H, Hu L, Xiang S, Li Q, et al.  (2025) Association between hyperlipidemia and nephrolithiasis: A comprehensive bioinformatics analysis deciphering the potential common denominator pathogenesis. PLoS ONE 20(4):\n           e0321734.\n        \n        https://doi.org/10.1371/journal.pone.0321734\n\nEditor:Li Shen, University of Helsinki: Helsingin Yliopisto, FINLAND\n\nReceived:November 27, 2024;Accepted:March 11, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Su et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and its Supporting information files.\n\nFunding:This work was supported in part by the Scientific Research Project Funded by Traditional Chinese Medicine Bureau of Guangdong Province (No. 20221170), Major Innovation Technology Construction Project of Synergistic Chinese Medicine and Western Medicine of Guangzhou (No.2023-2318), and College Students' Innovation and Entrepreneurship Training Plan Program of Guangdong Province (No.202410572186).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nUrolithiasis is a highly prevalent condition and a leading cause of hospitalization in urology worldwide. A cross-sectional study using ultrasound revealed a prevalence rate of renal stones at 6.4%, with an age- and sex-adjusted rate of 5.8%. Specifically, the prevalence rate is 6.5% for males and 5.1% for females [1]. A meta-analysis of nephrolithiasis subgroups indicated that the highest prevalence rates in Guangdong (12.7%) and Guangxi (10.3%). Additionally, prevalence rates were higher in the developed eastern regions compared to the western regions, showing significant regional and provincial distinctions [2]. Despite a decline in the age-adjusted prevalence of urolithiasis among Chinese men and women over the past three decades, the crude prevalence in Chinese women has been increasing [3]. Worldwide prevalence of kidney stones is increasing. Despite successful therapeutic options such as percutaneous nephrolithotomy (PCNL), ureteroscopy and extracorporeal shock wave lithotripsy (ESWL) [4,5], the recurrence rate of renal calculus remains high, reaching up to 50% within 5–10 years after the first episode [6]. This imposes a significant burden on healthcare systems and socioeconomic factors [7]. Therefore, clarifying the key factors and molecular mechanisms underlying the formation and recurrence of nephrolithiasis holds great clinical significance and research value.\n\nHyperlipidemia, characterized by dysregulated lipid profiles, remains a major global health concern, contributing to metabolic syndrome and associated comorbidities [8]. Despite the significant decline in total cholesterol levels among populations of many developed countries [9], the overall prevalence of dyslipidemia in China remains relatively high, at 35.6% [10].A national cross-sectional study among adult males revealed an upward trend in total cholesterol and LDL cholesterol levels, along with low awareness, treatment, and control of hyperlipidemia [11]. Research has shown a positive association between unhealthy lifestyles, high-protein, high-fat diet intake, and the development of hyperlipidemia [12]. Additionally, hyperlipidemia acts as a key contributor to the risk of numerous diseases.\n\nRecently, growing attention has been given to the link between lipid metabolism disorders and the prevalence of urolithiasis, suggesting a possible connection between circulating lipids and urolithiasis development [13,14]. A longitudinal study conducted in Taiwan found that individuals with hypertriglyceridemia (67–93 mg/dL) had a 1.463-fold increased risk of kidney stone disease, whereas low HDL-C could prevent kidney stone disease. Furthermore, Chol/HDL-C ratio exceeding 3.64 was linked to a 1.381-fold increased likelihood of developing kidney stones [15]. An animal experiment conducted by Chan Jung Liu [16] demonstrated that statins reduced the number of stones in rats with hydroxyproline water-induced formation of hyperoxic calcium oxalate renal calculi by ameliorating hyperlipidemia in rats. Moreover, statins facilitated the conversion of calcium oxalate to Calcium phosphate There is substantial evidence indicating a direct link between high serum triglyceride levels and an increased likelihood of developing urolithiasis [17,18]. However, there is a lack of relevant studies both domestically and abroad regarding the biological processes through which lipid metabolism disorders promote the development of nephrolithiasis. Therefore, exploring the intrinsic mechanisms linking lipid metabolism disorders and nephrolithiasis may present fresh perspectives on the prevention, therapy, and management of nephrolithiasis recurrence.\n\nGiven the current challenges in treating kidney stones and preventing their recurrence, along with the strong correlation between lipid metabolism disorders and kidney stone occurrence, this research seeks to explore the transcriptomics and proteomics associated with nephrolithiasis and hyperlipidemia. The objective is to identify diagnostic biomarkers related to the disease through a series of biosignature analyses, elucidate the biological processes underlying the disease, and construct the TF-gene regulatory network of pivotal genes as well as the TF-miRNA regulatory network of hub genes.\n\nWe downloaded gene expression data for nephrolithiasis and hyperlipidemia from the GEO database (https://www.ncbi.nlm.nih.gov/geo). The GSE73680 dataset, based on the GPL17077 platform, contains renal papillary tissue from 36 subjects who underwent endoscopic procedures (29 with the disease and 7 healthy controls). To assess diagnostic efficiency, we downloaded the GSE117518 dataset based on GPL21827, which includes renal papillary tissue from 6 patients (3 with the disease and 3 healthy controls). Randall’s plaque tissue was collected from patients undergoing percutaneous nephrolithotomy for renal calculus, while normal renal papillary tissue was obtained from patients with kidney neoplasms who underwent nephrectomy as well as from renal papillary tissue not invaded by the tumor. For hyperlipidemia, we utilized the GSE6054 dataset, based on the GPL570 platform, which consisted of 23 samples, of which 10 represented patients diagnosed with hyperlipidemia and 13 were healthy controls. The samples were obtained from blood, and gene expression profiles of isolated monocytes were detected using Affymetrix microarrays. The GSE13985 dataset (based on the GPL570 platform) including 5 hyperlipidemia samples and 5 healthy controls was additionally downloaded to assess diagnostic performance.\n\nThe raw expression matrix was standardized using R software (4.3.0). The “limma” R package [19] was employed to detect differentially expressed genes (DEGs) in the GSE73680 and GSE6054 datasets by comparing healthy control samples with disease groups. Statistically significant DEGs were identified based on the following criteria: p-value < 0.05, |log FC| ≥ 0.9. The R packages heatmap and ggplot2 were used to generate volcano plots of the Statistically significant DEGs and heat maps of the top 150 genes. The Bioladder Bioinformatics Online Analysis Platform (https://www.bioladder.cn/web/#/chart/17) was used to identify common DEGs between the two training datasets.\n\nTo achieve a more comprehensive understanding into the possible functions of the overlapping DEGs between the two training datasets, the Metascape database [20] (www.metascape.org) was utilized to conduct pathway analyses for Gene Ontology (GO) [21] and Kyoto Encyclopedia of Genomes (KEGG) [22]. The results of the enrichment analyses were uploaded to the Bioinformatics Cloud Platform (http://www.bioinformatics.com.cn) for visualization.\n\nGSEA [23] (version 4.3.3) was employed to conduct functional enrichment analysis for KEGG. The gene set parameters were configured as follows: gene names were chosen as the expression dataset, and ‘c2.cp.kegg_medicus.v2023.2.Hs.symbols.gmt’ was selected as the gene set database. The alignment value for calculating the Normalized Enrichment Score (NES) was set to the default of 1000. The maximum and minimum sizes for excluding larger and smaller gene sets were kept at the default values of 500 and 15, respectively. Signaling pathways with a p-value < 0.05 were considered enriched.\n\nBased on the overlapping DEGs between the two training datasets, the immune cell composition in tissue samples was assessed using the CIBERSORT algorithm [24]. The analysis utilized the LM22 leukocyte signature matrix, which includes 22 immune cell subtypes. To ensure robust results, 1,000 permutations were performed. Only results with a CIBERSORT p-value below 0.05 were deemed significant and included in the analysis. A matrix of immune cell fractions was generated, and correlations between the 22 immune cell types were visualized using the R package “corrplot”. The “vioplot” package in R was used to visualize differences in immune cell infiltration between the experimental and control groups.\n\nTo explore the immune mechanism involved in nephrolithiasis and hyperlipidemia development, we utilized the R software to run Spearman’s rank correlation analysis of the overlapping DEGs and immune cells. Besides the results were visualized with the “ggplot2” package.\n\nWGCNA [25] is a method in bioinformatics aimed at defining gene association patterns across multiple samples. It organizes genes with similar expression patterns and assesses the association between modules and distinct traits or phenotypes. The WGCNA-R package was employed to build co-expression networks for all genes in the dataset, and the algorithm identified the 10,000 genes exhibiting the highest variability for subsequent analysis. To estimate the network connectivity, the Weighted Neighborjoint matrix was converted to Topology Overlaymatrix (TOM), and hierarchical clustering was employed to construct its cluster tree structure. The branches of the clustering dendrogram correspond to distinct gene modules, with each color indicating a different module. Genes exhibiting comparable functions were clustered into a single module, with numerous genes being divided into various modules based on their weighted correlation coefficients. Many modules were closely related to nephrolithiasis or hyperlipidemia. Consequently, we proceeded with gene screening based on gene significance (GS) and module membership (MM). We used |MM| >0.8 and |GS| >0.5 as criteria to select key expressed genes in the hub module.\n\nThe PPI network plays a vital role in functional biology research by mapping candidate genes (CGs) to publicly available PPI data to uncover pathways involving these genes [26]. Cytoscape [27], a tool available for the visualization, analysis, and construction of biological networks, was utilized to construct a PPI network of overlapping DEGs using the STRING database [28] (version 12.0,https://string-db.org). Co-expression networks were generated with Cytoscape (version 3.9.1), and Cytoscape’s MCODE plugin was utilized with its default parameters (Degree Cutoff: 2, Node Score Cutoff: 0.2, K-Core: 2, Max Depth: 100) to identify sub-networks of PPIs among the common CGs. Using the CytoHubba plugin algorithm [29], crucial genes within the PPI network were identified by applying six topology analysis methods (MCC, MNC, Degree, Closeness, Radiality, and EPC), with visualization achieved through upsetR. Bioladder Bioinformatics Online Analysis Platform (https://www.bioladder.cn/web/#/chart/17) was utilized to identify core hub-genes from the candidate genes derived through CytoHubba and MCODE. Four core hub genes were then input into GeneMANIA--an online tool) [30] (http://genemania.org) for analyzing gene co-expression networks, exploring interactions with core hub genes related to nephrolithiasis and hyperlipidemia, and predicting and visualizing gene set functions.\n\nLasso is a widely-used regression technique that employs an ℓ1 penalty to obtain a sparse solution [31]. The “glmnet” package [32] in R was utilized to conduct least absolute shrinkage and selection operator (LASSO) regression, aiming to identify the most effective predictors for nephrolithiasis and hyperlipidemia.\n\nTo validate the precision of these diagnostic genes, we retrieved GSE117518 for nephrolithiasis and GSE13985 for hyperlipidemia for external validation purposes. We obtained the raw data for both datasets from the GEO database and proceeded with normalization. For GSE117518, we used 2 healthy control samples and 3 nephrolithiasis patient samples. Validation was performed on 5 healthy controls and 5 patients with hyperlipidemia for GSE13985. Box-and-whisker plots and area under the ROC curve (AUC) were calculated for the diagnostic gene expression patterns of the validation cohort.\n\nTo explore potential transcription factors (TFs) that might regulate diagnostic genes, the Network Analyst 3.0 online tool [33] from Homo sapiens (https://www.networkanalyst.ca) was employed to predict transcription factors (TFs) utilizing the ENCODE database, which holds microarray sequence data for numerous TFs. Cytoscape was used to complete the mapping of the TF-gene regulatory network.\n\nThis study did not involve human participants, interventions, or data collection directly from individuals. All data used in this study were obtained from publicly available online databases ‘GEO (Gene Expression Omnibus)’. GEO database provide fully anonymized datasets and ensure compliance with ethical standards, including obtaining necessary approvals and consents from original participants, as specified in their data usage policies. As the analysis involved secondary use of de-identified and publicly accessible data, ethical approval and informed consent were not required for this study.\n\nBased on our inclusion criteria, four datasets were screened for exploratory analyses: GSE73680, GSE117518, GSE6054, and GSE13985. GSE73680 served as the discovery cohort for nephrolithiasis, while GSE6054 was designated as the discovery cohort for hyperlipidemia. Additionally, GSE117518 and GSE13985 were the validation cohorts for nephrolithiasis and hyperlipidemia respectively. The following is the complete research workflow (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321734.g001\n\nIn the nephrolithiasis dataset GSE73680, we identified 5,610 DEGs. 1,543 DEGs were upregulated, while 4,067 DEGs were downregulated (Fig 2A). For GSE6054, 3,173 DEGs were identified, of which 1,312 were up-regulated and 1,861 were down-regulated (Fig 2B). The differential genes in these two groups were visualized using heatmaps (Fig 2Cand2D). Venn diagrams indicated that there were 82 overlapping co-upregulated genes (DEGs-up) and 85 co-downregulated genes (DEGs-down) between the nephrolithiasis and hyperlipidemia cohorts (Fig 2Eand2F).\n\n(B) Volcano map: DEGs in GSE6054, with red for up-regulated, blue for down-regulated, and black for unchanged genes. (C) Heatmap: Top 150 DEGs in GSE73680. (D) Heatmap: Top 150 DEGs in GSE6054. (E) Venn diagram: Overlap of up-regulated DEGs between GSE73680 and GSE6054. (F) Venn diagram: Overlap of down-regulated DEGs between the two dataset.\n\n(B) Volcano map: DEGs in GSE6054, with red for up-regulated, blue for down-regulated, and black for unchanged genes. (C) Heatmap: Top 150 DEGs in GSE73680. (D) Heatmap: Top 150 DEGs in GSE6054. (E) Venn diagram: Overlap of up-regulated DEGs between GSE73680 and GSE6054. (F) Venn diagram: Overlap of down-regulated DEGs between the two dataset.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g002\n\nMany of the enrichment pathways in Gene Ontology (GO) are associated with the regulation of the internal environment. The top 10 enriched GO pathways are shown inFig 3A. Molecular Function (MF) analysis indicated that DEGs were primarily involved in ribosomal structural components (GO:0003735) and kinase binding (GO:0019900). For Cellular Component (CC) ontology, these genes are largely located in focal adhesion (GO:0005925) and the actin cytoskeleton (GO:0015629). As for the Biological Process (BP) category, genes were mainly enriched in cytoplasmic translation (GO:0002181), response to hormone (GO:0009725), regulation of Wnt signaling pathway (GO:0030111), actin filament-based process (GO:0030029), and intracellular protein transport (GO:0006886). KEGG enrichment analysis confirmed that the pathways of DEGs were enriched in the Hippo signaling pathway, protein processing in the endoplasmic reticulum, and ribosome signaling pathways (Fig 3B).\n\n(A) GO enrichment analysis. (B) KEGG enrichment analysis.\n\n(A) GO enrichment analysis. (B) KEGG enrichment analysis.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g003\n\nThe metabolic patterns of nephrolithiasis and hyperlipidemia appear distinct yet interconnected. GSEA was conducted to evaluate the signaling pathways involved in DEGs. The results showed that pathways associated with kidney stones were significantly downregulated, including olfactory transduction, neuroactive ligand-receptor interactions, maturity-onset diabetes of the young, and linoleic acid metabolism (Fig 4A). Conversely, pathways associated with hyperlipidemia were significantly upregulated, including endocytosis, fatty acid metabolism, glycolytic gluconeogenesis, and steroid biosynthesis (Fig 4B). These results indicate that DEGs in the GSE73680 and GSE6054 are engaged in the regulation of metabolic functions in nephrolithiasis and hyperlipidemia.\n\n(B) GSEA plots showing the top four significantly enriched KEGG pathways in GSE6054 dataset (p-value < 0.05). Screening criteria: Biological functions with a p-value < 0.05.\n\n(B) GSEA plots showing the top four significantly enriched KEGG pathways in GSE6054 dataset (p-value < 0.05). Screening criteria: Biological functions with a p-value < 0.05.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g004\n\nDifferences in immune cell composition were examined between nephrolithiasis and normal control tissues. There were significant differences in immune cell composition between groups. Compared to the control group, the nephrolithiasis group exhibited a lower proportion of plasma cells (p < 0.01), while the proportions of regulatory T cells (p=0.02), monocytes (p=0.04), M1 macrophages (p<0.01), and eosinophils (p=0.02) were significantly higher (Fig 5Aand5C). In the hyperlipidemia group (Fig 5Band5D), the proportions of resting NK cells (p=0.02) and monocytes (p<0.0001) were elevated, with monocytes showing the most pronounced increase. Nephrolithiasis and hyperlipidemia exhibited similar differential trends in comparison to normal samples, according to the differential expression analysis. Compared to healthy human samples, monocytes were notably increased in nephrolithiasis and hyperlipidemia. This indicates that nephrolithiasis and hyperlipidemia may involve inflammatory responses, immune dysregulation, and metabolic disorders.\n\n(A, B) Histogram showing the proportions of 22 immune cell subpopulations in the nephrolithiasis-GSE73680 cohort and the hyperlipidemia-GSE6054 cohort. (C, D) Immune cell infiltration patterns were visualized using boxplots for the nephrolithiasis-GSE73680 and hyperlipidemia-GSE6054 cohorts, with red indicating nephrolithiasis/hyperlipidemia patients and blue indicating healthy controls. (E, F) Immune cell fraction correlations were visualized in a matrix, with red for positive, white for neutral, and blue for negative correlations. The size of the circle also directly reflects the degree of correlation. * p-value < 0.05, ** p-value < 0.01, *** p-value < 0.001, **** p-value <0.0001, ns, no significance.\n\n(A, B) Histogram showing the proportions of 22 immune cell subpopulations in the nephrolithiasis-GSE73680 cohort and the hyperlipidemia-GSE6054 cohort. (C, D) Immune cell infiltration patterns were visualized using boxplots for the nephrolithiasis-GSE73680 and hyperlipidemia-GSE6054 cohorts, with red indicating nephrolithiasis/hyperlipidemia patients and blue indicating healthy controls. (E, F) Immune cell fraction correlations were visualized in a matrix, with red for positive, white for neutral, and blue for negative correlations. The size of the circle also directly reflects the degree of correlation. * p-value < 0.05, ** p-value < 0.01, *** p-value < 0.001, **** p-value <0.0001, ns, no significance.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g005\n\nThe correlation analysis of 22 immune cell types used red for positive correlations, blue for negative correlations, and circle size to represent correlation strength. The results inFig 5Eindicate significant synergistic interactions in nephrolithiasis between T cells gamma delta and plasma cells, activated mast cells and T cells follicular helper, and M2 macrophages and activated NK cells. Conversely, the strongest competitive effect was observed between memory B cells and naive B cells. In hyperlipidemia (Fig 5F), regulatory T cells and naive B cells, resting dendritic cells and CD8 T cells, and activated NK cells and T cells follicular helper exhibited pronounced synergistic interactions. In contrast, the strongest competitive effect was observed between resting mast cells and naive CD4 T cells.\n\nTo more thoroughly investigate the link between the disease and overlapping DEGs, we employed WGCNA with differential expression analysis across the two groups. We constructed a co-expression network by applying a soft-threshold method. Maintaining a scale-free topology within the co-expression network depends heavily on the parameter β. For the nephrolithiasis group, a fit index over 0.9 indicated a scale-free topology, and the β parameter was fixed at 16 (Fig 6A). The adjacency function was employed to generated an adjacency matrix, followed by the construction of hierarchical clustering using the TOM difference metric (Fig 6C). In total, 17 co-expression modules were recognized, with modules showing a P-value under 0.05 classified as essential. The turquoise module displayed a strong positive correlation, while the green, yellow, and brown modules exhibited significant negative correlations (Fig 6E). Within these four key modules in the nephrolithiasis group, 9,380 genes that matched |MM| > 0.8 and |GS| > 0.5 were further selected. Similarly, WGCNA was also conducted on the hyperlipidemia group, with β = 10 determined to be the optimal soft power value (Fig 6B). 19 modules were identified, with the blue and green modules demonstrating significant positive correlations, while the yellow module showed a strong negative correlation (Fig 6Dand6F). Using MM |>0.8 and | GS |>0.5 as standards, we further screened 955 genes from the genes of these three key modules in the hyperlipidemia group. These genes from the two sets of key modules may serve as candidate cell-specific markers. To investigate the common pathogenesis of nephrolithiasis and hyperlipidemia, we examined the intersection of the overlapping co-regulated genes and the genes identified through WGCNA.Fig 6Gshows the key modular genes common to WGCNA for nephrolithiasis and hyperlipidemia, totaling 817. The common key modular genes in DEGs (GSE73680 and GSE6054) and WGCNA overlapped with 74 genes (Fig 6H).\n\n(C, D) Gene dendrograms: Module assignments based on dynamic tree cut clustering. (E, F) Module-trait relationships: Heatmap showing correlations between module eigengenes (MEs) and clinical traits with p-values. (G) Key module genes: Shared modules identified in both GSE73680 and GSE6054 datasets through WGCNA. (H) Common key module genes: Genes found in common DEGs and WGCNA.\n\n(C, D) Gene dendrograms: Module assignments based on dynamic tree cut clustering. (E, F) Module-trait relationships: Heatmap showing correlations between module eigengenes (MEs) and clinical traits with p-values. (G) Key module genes: Shared modules identified in both GSE73680 and GSE6054 datasets through WGCNA. (H) Common key module genes: Genes found in common DEGs and WGCNA.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g006\n\nSeventy-four hub genes were imported into STRING, and unrelated genes were removed to derive a PPI network graph. This PPI comprised 37 nodes and 43 edges, with an interaction score above 0.4 (Fig 7A). The MCODE plugin in Cytoscape was used to identify hub gene modules, resulting in a core module containing 4 hub genes (Fig 7B). For topology analysis, we used the CytoHubba plugin within Cytoscape to pinpoint shared genes by applying six algorithms. The upsetR plot displayed seven intersecting genes from CytoHubba, namely HSP90AB1, PABPC1, HSPA5, STUB1, RPL10, PRKCSH, and BRD4(Fig 7C). By intersecting these 7 genes obtained from the CytoHubba plugin with the 4 genes obtained from the MCODE plugin, we identified 4 core hub genes, which were visualized using a Venn diagram (Fig 7D). GeneMANIA biofunctional analysis was used to explore genes with shared attributes and similar functions with the four core hub genes, illustrating the interactive functional association network among them. 20 molecules were found to be most closely related to the 4 overlapping DEGs, showing gene co-expression (8.01%), physical interaction (77.64%), predictive value (5.37%), co-localization (3.63%), genetic interaction (2.87%), and pathway involvement (1.88%) (Fig 7E). These genes are mainly functioned in peptidyl-serine modifications, cellular response to unfolded proteins, cellular response to heat, endoplasmic reticulum unfolded protein response, endoplasmic reticulum stress response, regulation of endoplasmic reticulum stress response, and protein folding.\n\n(B) Identification of key gene module through MCODE plug-in in cytoscape. (C) Identifies hub genes using six Cytohubba algorithms (MCC, MNC, Degree, EPC, Closeness, Radiality). (D) Venn diagram highlighting four core hub genes common to CytoHubba and MCODE. (E) The GeneMANIA diagram displaying co-expression of core hub genes and their neighbors, with colors representing shared functions.\n\n(B) Identification of key gene module through MCODE plug-in in cytoscape. (C) Identifies hub genes using six Cytohubba algorithms (MCC, MNC, Degree, EPC, Closeness, Radiality). (D) Venn diagram highlighting four core hub genes common to CytoHubba and MCODE. (E) The GeneMANIA diagram displaying co-expression of core hub genes and their neighbors, with colors representing shared functions.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g007\n\nPotential common diagnostic genes were identified using the LASSO regression algorithm. In GSE73680, 7 out of 37 core crossover genes were selected by LASSO with the optimal λ value set at 0.011 (Fig 8Aand8C). In the GSE6054 dataset, LASSO analysis pinpointed four out of the 37 core crossover genes with the optimal λ value of 0.011 (Fig 8Band8D). Ultimately, the best common diagnostic biomarkers for nephrolithiasis and hyperlipidemia were identified as 3 diagnostic genes (HSP90AB1, HSPA5 and STUB1) (Fig 8E).\n\n(B) LASSO coefficient profiles for hyperlipidemia. (C, D) Ten-fold cross-validation was used to optimize (λ) in both nephrolithiasis and hyperlipidemia. (E) LASSO identified 6 core genes in nephrolithiasis, 4 in hyperlipidemia, and 3 diagnostic genes after intersection analysis.\n\n(B) LASSO coefficient profiles for hyperlipidemia. (C, D) Ten-fold cross-validation was used to optimize (λ) in both nephrolithiasis and hyperlipidemia. (E) LASSO identified 6 core genes in nephrolithiasis, 4 in hyperlipidemia, and 3 diagnostic genes after intersection analysis.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g008\n\nTo further explore the diagnostic value of these biomarkers, we evaluated the predictive accuracy and discriminatory strength of the common diagnostic genes by analyzing the expression patterns of the three genes and their ROC curves. First, we examined the expression levels in nephrolithiasis and hyperlipidemia within the two discovery cohorts. The expression of HSP90AB1 was lower in both the nephrolithiasis group (P<0.01) and the hyperlipidemia group (P<0.0001) (Fig 9A). HSPA5 expression was higher in both the nephrolithiasis (P<0.001) and hyperlipidemia (P<0.01) groups compared to controls (Fig 9E). Similarly, STUB1 expression was elevated in the experimental group (P<0.01) (Fig 9I). Next, ROC analysis was performed to assess the specificity and sensitivity of the three diagnostic genes in diagnosing both diseases. For nephrolithiasis biomarkers, the three pivotal genes, HSP90AB1 (AUC=0.857), HSPA5 (AUC=0.845), and STUB1 (AUC=0.872), showed strong predictive performance. The same ROC analysis was performed for the hyperlipidemia group, with HSP90AB1 (AUC=0.777), HSPA5 (AUC=0.838), and STUB1 (AUC=0.877) also showing robust predictive performance (Fig 9B,9Fand9J). In addition, we validated the reliability of HSP90AB1, HSPA5, and STUB1 as diagnostic genes for nephrolithiasis and hyperlipidemia through external validation. In both validation groups, the expression levels of these three diagnostic genes were consistent with those in the discovery cohortFig 9C,9Gand9K). HSP90AB1 showed low expressed in the validation set GSE117518 for nephrolithiasis, while the other two diagnostic genes were highly expressed, although the p values were not significant. Similar expression profiles were also observed in the hyperlipidemia validation set GSE13985. HSP90AB1 demonstrated good diagnostic accuracy in the nephrolithiasis validation cohort (AUC = 1.000) and in the hyperlipidemia validation cohort (AUC = 0.880) (Fig 9D). HSPA5 exhibited strong diagnostic potential in nephrolithiasis (AUC=1.000) and hyperlipidemia (AUC=0.920) (Fig 9H). Similarly, STUB1 correctly diagnosed nephrolithiasis (AUC=0.889) and hyperlipidemia (AUC=0.800) (Fig 9L). These findings confirm their potential as key diagnostic biomarkers for nephrolithiasis and hyperlipidemia.\n\n(A, C) HSP90AB1 gene boxplot for diagnosis and efficacy validation. (B, D) HSP90AB1 ROC curve for diagnostic performance. (E, G) HSPA5 gene boxplot for diagnosis and efficacy testing. (F, H) HSPA5 ROC curve for diagnostic accuracy. (I, K) STUB1 gene boxplot for diagnosis and efficacy analysis. (J, L) STUB1 ROC curve for diagnostic validation.\n\n(A, C) HSP90AB1 gene boxplot for diagnosis and efficacy validation. (B, D) HSP90AB1 ROC curve for diagnostic performance. (E, G) HSPA5 gene boxplot for diagnosis and efficacy testing. (F, H) HSPA5 ROC curve for diagnostic accuracy. (I, K) STUB1 gene boxplot for diagnosis and efficacy analysis. (J, L) STUB1 ROC curve for diagnostic validation.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g009\n\nIt is helpful to reveal the biological processes underlying the pathogenesis of diseases through analyzing the interactions between transcription factors (TFs), miRNAs, and diagnostic genes. We constructed a TF-gene interaction network and a TF-miRNA co-regulatory network in our study, which were then imported them into Cytoscape for visualization and further analysis. The TF-gene network comprised 86 transcription factors, 3 diagnostic genes and 180 linkages (Fig 10A). The TF-miRNA co-regulatory network consisted of 98 connections involving 25 miRNAs, and 54 transcription factor genes interacting with the 3 diagnostic genes (Fig 10B).\n\n(B) TF-gene-MiRNA co-regulatory network. Diagnostic genes are represented by red nodes, TFs by blue nodes, and miRNAs by green nodes.\n\n(B) TF-gene-MiRNA co-regulatory network. Diagnostic genes are represented by red nodes, TFs by blue nodes, and miRNAs by green nodes.\n\nhttps://doi.org/10.1371/journal.pone.0321734.g010\n\nA Polish study on obese children aged 3–18 years indicates that those with hypercholesterolemia and hypertriglyceridemia exhibit reduced urinary citrate excretion, elevated ionic calcium levels, and a greater propensity for developing kidney stones [34]. Additionally, multiple clinical studies have found a positive association between hyperlipidemia and nephrolithiasis [35–37] These findings suggest that hyperlipidemia significantly impacts the occurrence of nephrolithiasis. Another study confirmed that patients without a history of urolithiasis who received statin therapy had lower lipid parameters (LDL, TG, cholesterol) and a significantly reduced risk of developing new urolithiasis compared to those who did not receive statin therapy [38]. The potential mechanism may involve statins reducing autophagy-ERS responses, renal injury, and crystal deposition levels, thereby decreasing the formation of calcium oxalate kidney stone formation and protecting the kidneys [39]. Meanwhile, Kaisaier Aji et al. identified KLK1 and MMP10 as key genes associated with kidney stone formation using WGCNA and machine learning. While these genes have been implicated in metabolic pathways related to kidney stones, their potential connection to hyperlipidemia remains unexplored [40].\n\nDespite these findings, as far as we know, transcriptomic data have not yet been utilized to evaluate potential diagnostic biomarkers among healthy controls, nephrolithiasis, and hyperlipidemia. Therefore, to explore the connection between nephrolithiasis and hyperlipidemia, we conducted bioinformatics and enrichment analyses by merging independent datasets for both diseases, leading to the identification of three diagnostic genes (HSP90AB1, HSPA5, and STUB1), offering new insights and potential directions for future research. The following sections will elaborate on the relationships between these three genes, nephrolithiasis and hyperlipidemia.\n\nHSP90AB1, commonly known as HSP90β, is a heat shock protein family member with molecular chaperone activity. Chaperone proteins aid in correct protein folding and maintain protein stability by binding to client proteins, especially during cellular stress [41]. Our study suggests that HSP90AB1 is a potential diagnostic target for patients with hyperlipidemia and kidney stones, a conclusion that is partially supported by previous research. Nilubon Singhto et al. found that lower levels of HSP90β were positively correlated with kidney stone occurrence, indicating a possible association between HSP90AB1 and kidney stones. Additionally, HSP90 has been shown to promote nitric oxide production by endothelial nitric oxide synthase (eNOS), regulating renal vascular tension, sodium excretion, and urine concentration, which may affect the excretion of stone forming substances in urine and then indirectly participating in the formation of kidney stones [42]. Furthermore, Victoria Ramírez et al. applied the HSP90 inhibitor Radicicol to male Wistar rats and observed a decrease in renal blood flow and glomerular filtration rate, creating an environment conducive to calcium oxalate stone formation in the renal pelvis [43], further supporting our findings. Based on the research results, we speculate that the abnormal expression or function of HSP90β may lead to the dysfunction of renal tubular epithelial cells and increase the risk of crystal deposition. Similarly, Hsp90β may affect the survival and repair of renal tubular epithelial cells by regulating the expression of apoptosis related proteins. Increased apoptosis may lead to renal tubular injury and promote crystal nucleation and growth.\n\nHSP90AB1 is also associated with hyperlipidemia. A reduction in HSP90AB1 levels can have a preventive effect on hyperlipidemia by maintaining the stability and activity of sterol regulatory element-binding proteins (SREBP), which play a crucial role in de novo lipogenesis (DNL) [44,45]. Based on the results of immune infiltration, we speculate that HSP90AB1 may contribute to hyperlipidemia by modulating monocyte activation and inflammatory responses. In hyperlipidemia, monocytes activated by oxidized low-density lipoprotein (oxLDL) differentiate into pro-inflammatory macrophages and release inflammatory cytokines. Additionally, it has also been shown that the knockout of HSP90AB1 in mice facilitates the degradation of mature sterol regulatory element-binding proteins (mSREBPs) via the Akt-GSK3β-FBW7 pathway. This significantly reduces neutral lipids and cholesterol levels, thereby decreasing de novo lipogenesis in hepatocytes [45].\n\nHeat shock protein A5 (HSPA5), also known as glucose-regulated protein 78 (GRP78) is primarily responsible for refolding or degrading misfolded proteins in the endoplasmic reticulum to maintain low levels of unfolded proteins [46–48]. Although the direct link between HSPA5 and kidney stones and hyperlipidemia are not yet fully confirmed, several researches propose that HSPA5 may play a role in the pathogenesis of these diseases. Crystalline binding sites provide the foundation for crystallization, facilitating crystal deposition and kidney stone formation possible [49].Calcium serves as an essential component in the development of calcium oxalate stones, and endoplasmic reticulum stress-induced upregulation of GRP78 may lead to increased urinary calcium ion concentration, promoting kidney stone formation. The primary binding site for calcium ions is in the endoplasmic reticulum, and elevated cytosolic Ca2+can disrupt the function of endoplasmic reticulum chaperones, inducing endoplasmic reticulum stress, activating the unfolded protein response (UPR), and subsequently upregulating GRP78 [50]. Several studies have shown that increased oxalate can stimulate the expression of GRP78, a marker of endoplasmic reticulum stress, leading to increased crystal deposition in the kidneys and creating a favorable environment for kidney stone formation [39,51,52]. Additionally, GRP78 may be involved in the oxidative stress process, creating conditions conducive to kidney stone formation. Rishi Bhardwaj et al. found that increased expression of the GRP78 marker indicates endoplasmic reticulum stress under hyperoxic conditions, accompanied by the appearance of calcium oxalate crystals [53].\n\nSome attention has also been given to the relationship between HSPA5 and hyperlipidemia. In a cross-sectional analysis, serum GRP78/BiP levels were positively correlated with LDL cholesterol, non-LDL cholesterol, and triglycerides, suggesting that GRP78 may be associated with the occurrence of hyperlipidemia [54]. Additionally, reticulon 3 (RTN3) regulates triglyceride biosynthesis and storage through its interaction with heat shock protein family A (HSP70) member 5, which may be a mechanism for hyperlipidemia occurrence [55]. In conclusion, HSPA5 may play a shared role in the pathogenesis of nephrolithiasis and hyperlipidemia by regulating endoplasmic reticulum stress, oxidative stress, and inflammatory responses. In nephrolithiasis, HSPA5 may mediate renal tubular epithelial cell injury through endoplasmic reticulum stress, promoting calcium oxalate crystal deposition, while also exacerbating stone formation by modulating oxidative stress and the release of inflammatory cytokines. In hyperlipidemia, HSPA5 would contribute to lipid accumulation and metabolic dysregulation by influencing lipid metabolism-related signaling pathways including NF-κB and AMPK, as well as inflammatory responses. Both diseases involve the crosstalk of HSPA5-mediated endoplasmic reticulum stress-inflammatory axis and oxidative stress, suggesting that HSPA5 serves as a key molecular link between nephrolithiasis and hyperlipidemia.\n\nSTUB1 is a newly identified co-chaperone with ubiquitin ligase functio, involved in facilitating the degradation of misfolded proteins within cells. It encodes CHIP (C-terminal of Hsc70 Interacting Protein), an essential E3 ubiquitin-protein ligase that contributes to protein quality control and cellular homeostasis [56]. Studies have shown that overexpression of cystic fibrosis transmembrane conductance regulator (CFTR) can alleviate renal tissue damage and calcium oxalate deposition in mice, while STUB1 exacerbates calcium oxalate-induced renal damage by regulating CFTR ubiquitination and reactive oxygen species-mediated autophagy [57]. Calcium oxalate deposition and kidney injury would create favorable conditions for kidney stone formation. Additionally, STUB1 can indirectly influence kidney stone formation by influencing affecting aquaporin 2 (AQP2), which regulates urine volume and osmolality. The expression and regulation of AQP2 are primarily controlled by vasopressin-dependent proteins, whose half-life and abundance are influenced by AQP2 ubiquitination [58]. Animal experiments have found that CHIP gene knockout mice or CRISPR/Cas9-modified mice lacking CHIP E3 ligase function experience increased AQP2 levels, which affect kidney water regulation, decrease water intake and urine volume, and elevate urine osmolality [59]. Moreover, STUB1 cooperates with arginine vasopressin (AVP) to induce water reabsorption through principal cells of the collecting duct [60]. Based on existing reports, we hypothesize that STUB1 may promote kidney stone formation by increasing tubular reabsorption, urinary osmolality, and the accumulation of oxalate and calcium ions in the kidney. Although the relationship between STUB1 and hyperlipidemia has not been confirmed, research has indicated that upregulation of STUB1 may alleviate lipid droplet accumulation and steatosis in the liver of mice, improving non-alcoholic fatty liver disease [61].Jie Luoet al found that upregulation of SREBP1 expression in chronic kidney disease models drives increased cholesterol synthesis [62]. Accordingly, we speculate that STUB1 may inhibit this process through ubiquitin-mediated degradation of SREBP1. If STUB1 function is impaired, it may not be able to effectively degrade SREBP, resulting in hyperactivation of the cholesterol synthesis pathway, thereby promoting lipid accumulation.\n\nIt is necessary to acknowledge the inherent limitations in our study. First, the currently available datasets related to nephrolithiasis and hyperlipidemia are indeed limited in size. Although these datasets represent the publicly available data in this field and have been used in prior literature, the limitations of the datasets have had a certain impact on the results of the research. Specially in the validation of diagnostic genes, the result may reflect dataset-specific characteristics or overfitting. Therefore, it is necessary for future studies to utilize larger datasets to enhance the statistical power and generalizability of our findings. Second, this experiment has not been validated at the cellular and animal levels, and prospective studies are required to confirm our results.\n\nIn conclusion, this study identifies new diagnostic biomarkers for nephrolithiasis and hyperlipidemia using bioinformatics approaches and elucidates the potential common denominator pathogenesis. The identified biomarkers not only offer potential diagnostic tools but also provide a foundation for future therapeutic strategies targeting shared metabolic pathways in nephrolithiasis and hyperlipidemia. Prospective studies, including clinical trials and animal models, are warranted to validate these findings.\n\nWe sincerely acknowledge the researchers who deposited datasets in GEO database for enabling this investigation through data sharing.",
    "category": "immunology"
  },
  {
    "title": "Exploring the association between dietary indices and metabolic dysfunction-associated steatotic liver disease: Mediation analysis and evidence from NHANES",
    "authors": "Qiang Wang, Rude Chen, Shaohua Chen, Bowen Wei, Chunlan Liu, Zongxing Jiang, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321251",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321251",
    "content": "The association between dietary indices and metabolic dysfunction-associated steatotic liver disease (MASLD) has shown inconsistent results in previous studies. Additionally, the potential mediating variables linking dietary quality to MASLD have not been adequately explored.\n\nWe analyzed data from 6,369 participants in the National Health and Nutrition Examination Survey (NHANES) 2007–2018. Three dietary indices—Healthy Eating Index (HEI), Energy-adjusted Dietary Inflammatory Index (EDII), and Composite Dietary Antioxidant Index (CDAI)—were evaluated for their associations with MASLD using logistic regression models adjusted for a comprehensive range of covariates. Mediation analysis was performed to evaluate the roles of potential mediators from four domains: insulin resistance (homeostatic model assessment of insulin resistance, HOMA-IR; metabolic score for insulin resistance, METS-IR), systemic inflammation (systemic inflammatory response index, SIRI; systemic immune-inflammation index, SII), obesity or visceral fat distribution (a body shape index, ABSI; body roundness index, BRI), and oxidative stress (Gamma-Glutamyltransferase, GGT; Bilirubin; Uric Acid).\n\nAfter adjusting for all covariates, only HEI showed a consistent inverse association with MASLD, while EDII and CDAI showed no significant associations. Mediation analysis identified METS-IR, HOMA-IR, BRI, and ABSI as significant mediators in the relationship between HEI and MASLD, with mediation proportion accounting for 47.16%, 48.84%, 52.69%, and 13.84%, respectively.\n\nHigher HEI is associated with a reduced risk of MASLD. The findings suggest that insulin resistance and visceral fat distribution partially mediate the relationship between HEI and MASLD, providing insights into potential mechanisms linking diet and liver health.\n\nCitation:Wang Q, Chen R, Chen S, Wei B, Liu C, Jiang Z (2025) Exploring the association between dietary indices and metabolic dysfunction-associated steatotic liver disease: Mediation analysis and evidence from NHANES. PLoS ONE 20(4):\n           e0321251.\n        \n        https://doi.org/10.1371/journal.pone.0321251\n\nEditor:Samuel O. Antwi, Mayo Clinic Florida: Mayo Clinic's Campus in Florida, UNITED STATES OF AMERICA\n\nReceived:January 15, 2025;Accepted:February 27, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Wang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The NHANES dataset is publicly available online, accessible athttps://wwwn.cdc.gov/Nchs/Nhanes/Search/default.aspx. The physical activity questionnaire is publicly available online, accessible athttps://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/PAQ_J.htm. Analyzed data are available from the figshare repository (DOI:https://doi.org/10.6084/m9.figshare.28210793.v1).\n\nFunding:The research was supported by 2023 Chengdu Health Commission Research Project (202304013629). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nMetabolic dysfunction-associated steatotic liver disease (MASLD), previously known as non-alcoholic fatty liver disease (NAFLD), is now recognized as a significant global health concern [1]. It is defined by abnormal fat deposition in liver cells in the absence of substantial alcohol intake or other identifiable liver disease causes [2]. MASLD is intricately linked to metabolic abnormalities, including insulin resistance, type 2 diabetes mellitus, obesity, dyslipidemia, and hypertension [3,4]. The rising prevalence of MASLD reflects the worldwide increase in obesity and metabolic health challenges, making it a pressing concern for healthcare systems worldwide [5]. Understanding the modifiable factors that influence MASLD risk is critical for developing effective prevention and intervention strategies.\n\nDietary patterns and nutritional quality are key modifiable factors in the prevention and management of MASLD [6]. High-quality diets have been associated with improved metabolic health outcomes, whereas diets rich in saturated fats, processed foods, and added sugars are linked to increased risk of metabolic dysfunction [6,7]. Dietary indices, such as the Healthy Eating Index (HEI), Energy-adjusted Dietary Inflammatory Index (EDII), and Composite Dietary Antioxidant Index (CDAI), have been developed to quantify various dimensions of diet quality, including overall adherence to dietary guidelines, inflammatory potential, and antioxidant capacity [8,9]. The HEI evaluates adherence to the Dietary Guidelines for Americans (DGA), while EDII estimates the pro-inflammatory effects of diet. CDAI, on the other hand, measures the antioxidant properties of dietary intake based on the consumption of vitamins, minerals, and other compounds known to reduce oxidative stress.\n\nDespite the potential importance of these dietary indices, existing evidence on their associations with MASLD is inconsistent. Some studies have reported a protective role of high diet quality, as measured by CDAI, in reducing the risk of MASLD, while others have found no significant associations [9–11]. Similarly, past studies have explored the relationships between HEI, EDII, and MASLD, but many of these studies lacked comprehensive control for important covariates, such as physical activity (PA), poverty income ratio (PIR), and alcohol consumption [12,13]. These inconsistencies may be attributed to differences in methodologies, study populations, and the extent of covariate adjustments. Consequently, it is essential to revisit the relationship between dietary indices and MASLD using a robust methodological framework that accounts for a comprehensive set of confounding factors.\n\nBeyond direct associations, the mechanisms underlying the relationship between dietary quality and MASLD remain inadequately explored. Insulin resistance, systemic inflammation, obesity or visceral fat distribution, and oxidative stress are well-established pathways in the pathogenesis of MASLD and may serve as mediators linking dietary quality to liver health [14–17]. For instance, diets rich in anti-inflammatory or antioxidant components may reduce insulin resistance and inflammation, thereby mitigating the risk of MASLD. However, few studies have systematically examined these pathways in the context of dietary indices and MASLD, leaving a significant gap in understanding.\n\nThis study aims to address these gaps by evaluating the associations between three dietary indices (HEI, EDII, and CDAI) and MASLD using data from the nationally representative National Health and Nutrition Examination Survey (NHANES) 2007–2018. We employed rigorous statistical models to control for a wide range of covariates, including sociodemographic factors, lifestyle behaviors, and metabolic health markers. Furthermore, we conducted a comprehensive mediation analysis to investigate the roles of potential mediators across four domains: insulin resistance (homeostatic model assessment of insulin resistance, HOMA-IR; metabolic score for insulin resistance, METS-IR), systemic inflammation (systemic inflammatory response index, SIRI; systemic immune-inflammation index, SII), obesity or visceral fat distribution (a body shape index, ABSI; body roundness index, BRI), and oxidative stress (Gamma-Glutamyltransferase, GGT; Bilirubin; Uric Acid). By examining these mediating pathways, this study seeks to provide novel insights into the mechanisms linking dietary quality to MASLD risk.\n\nThis study utilizes data from the NHANES, a nationally representative, cross-sectional survey organized by the National Center for Health Statistics (NCHS). NHANES assesses the health and nutritional status of the noninstitutionalized population in the United States. The survey employs a precise stratified, multistage probability sampling design to ensure sample representativeness and reliability.\n\nThe present study uses data from the NHANES 2007–2018 cycles, including participants aged 18 years and older. The study was designed to evaluate the impact of the HEI on MASLD, while also investigating potential mediating variables. Participants with missing variables were excluded. A flowchart of participant inclusion and exclusion is shown inFig 1. The final study sample consisted of 6,369 participants, with data representing a weighted population of 113,302,410 individuals.\n\n* “Excluded missing data with MASLD” refers to individuals with missing values for variables involved in the MASLD definitions and its related inclusion and exclusion criteria. **Other steatosis liver disease (SLD) refers to cryptogenic SLD, metabolic associated alcoholic liver disease (MetALD) or other combination aetiology SLD, and other specific aetiology SLD.\n\n* “Excluded missing data with MASLD” refers to individuals with missing values for variables involved in the MASLD definitions and its related inclusion and exclusion criteria. **Other steatosis liver disease (SLD) refers to cryptogenic SLD, metabolic associated alcoholic liver disease (MetALD) or other combination aetiology SLD, and other specific aetiology SLD.\n\nhttps://doi.org/10.1371/journal.pone.0321251.g001\n\nThe selection of the 2007–2018 cycles was made because these years provide the most comprehensive details on the United States Fatty Liver Index (USFLI) and Fatty Liver Index (FLI), which are crucial for the accurate diagnosis of MASLD. Additionally, the reason we did not combine the 2019–2020 cycles is due to the significant disruptions caused by the COVID-19 pandemic, which led to changes in the study’s methodology and sample collection protocols, making it unsuitable to combine these cycles with others. The FLI and USFLI have been proven reliable for diagnosing MASLD. Specifically, FLI has an area under the receiver operating characteristic curve of 0.78 (95% CI: 0.74–0.81), and the USFLI is 0.80 (95% CI: 0.77–0.83) [18,19]. Thus, based on these factors, the 2007–2018 cycles were selected for this study.\n\nThis study was conducted under the auspices of the National Center for Health Statistics (NCHS), with comprehensive ethical oversight provided by the NCHS Institutional Review Board (IRB). Prior to data collection and health examinations, comprehensive informed consent was meticulously obtained from all eligible participants, ensuring full compliance with ethical research standards.\n\nFor the dietary data, NHANES includes two 24-hour dietary recall interviews. In this study, we used the average of two 24-hour dietary recalls to obtain a more accurate representation of participants’ dietary intake\n\nIn this study, HEI specifically refers to the HEI-2015. It is designed to measure how closely an individual’s diet aligns with the DGA. A higher HEI score (ranging from 0 to 100) signifies better adherence to the DGA, indicating a more balanced and health-promoting dietary pattern.\n\nThe EDII is a dietary scoring system developed to assess the inflammatory potential of an individual’s diet. It is derived from a comprehensive review of the literature, analyzing over 1,900 peer-reviewed studies on the relationship between various dietary factors and inflammation. The score is adjusted for total energy intake, ensuring that the impact of diet-related inflammation is assessed independently of overall calorie consumption. An elevated EDII score reflects a diet that is more likely to promote inflammation.\n\nThe CDAI is an index used to quantify the antioxidant potential of an individual’s diet. It is based on the intake of key dietary antioxidants, including vitamins A, C, and E, carotenoids, as well as minerals such as zinc and selenium, which have been shown to have protective effects against oxidative stress and inflammation. A higher CDAI score indicates a diet with a higher antioxidant capacity.\n\nFor further details on the algorithms used to calculate HEI, EDII, and CDAI, please refer to previous studies [8,9].\n\nHepatic steatosis was identified using the USFLI or FLI. Specifically, hepatic steatosis was defined as an a USFLI score ≥  30 or FLI score ≥  60. The FLI and USFLI are both composite indices. For both indices, a higher score indicates a greater likelihood of hepatic steatosis. The calculation formulas for USFLI and FLI are as follows:\n\nThe ethnicity factor assigns a value of 1 for participants identified as Mexican American or Non-Hispanic Black, and 0 for those not belonging to these groups.\n\nMASLD was diagnosed in cases where hepatic steatosis was observed in the absence of the following conditions: (1) Alcohol consumption exceeding one drink per day for women or two drinks per day for men [15]; To define the status of alcohol consumption, we used the relevant “alq130” variable from the NHANES database. This variable specifically assesses the average number of alcoholic drinks consumed on days when participants reported drinking in the past 12 months. (2) Infection with Hepatitis B or C virus; (3) Use of pharmacological agents known to induce steatosis, including tamoxifen, amiodarone, nucleoside reverse transcriptase inhibitors, methotrexate, aspirin, ibuprofen, valproic acid, protease inhibitors, carbamazepine, fluorouracil, glucocorticoids and irinotecan [20]; (4) Iron overload, defined as a transferrin saturation of 45% or higher, combined with ferritin levels of at least 400 µg/L in women and 500 µg/L in men.\n\nIn accordance with the Delphi consensus definition, individuals with MASLD must have at least one of the five cardiometabolic risk factors. The specific cardiometabolic risk factors can be found in the referenced literature [12,21].\n\nIn this study, nine potential mediators were identified to represent four key biological aspects: IR (HOMA-IR, homeostatic model assessment of insulin resistance; METS-IR, metabolic score for insulin resistance), systemic inflammatory (SIRI, systemic inflammatory response index; SII, systemic immune-inflammation index), obesity or visceral fat distribution (ABSI, a body shape index; BRI, body roundness index), and oxidative stress (GGT, Gamma-Glutamyltransferase; Bilirubin; Uric Acid). Each mediator is described below:\n\nHOMA-IR is a widely used index for assessing insulin resistance. It reflects the efficiency of insulin in regulating glucose homeostasis [22]. HOMA-IR was calculated using the formula FPG (mmol/L) × FINS (mIU/L)/22.5. METS-IR is a surrogate marker of insulin resistance. It has been validated as a reliable indicator of metabolic dysfunction associated with insulin resistance [22]. METS-IR =  Ln [2 × glycemia (mg/dL) +  triglycerides (mg/dL)] ×  BMI/Ln HDL-C (mg/dL).\n\nSIRI and SII are both markers of systemic inflammation [23]. SIRI =  (neutrophil count ×  monocyte count)/ lymphocyte count, and SII =  (platelet count ×  neutrophil count)/ lymphocyte count.\n\nBRI is a measure of body shape and visceral fat distribution.\n\nABSI is another anthropometric index, offering a more nuanced evaluation of abdominal fat distribution and its associated health risks [24].\n\nGGT is an enzyme primarily involved in liver function and oxidative stress [25]. Bilirubin, a byproduct of hemoglobin breakdown, serves as an antioxidant and a marker of liver health. Altered bilirubin levels are linked to oxidative stress and metabolic disorders [25]. Uric acid, a byproduct of purine metabolism, is widely recognized as an indicator of metabolic health. Elevated levels of uric acid are associated with oxidative stress, systemic inflammation, and increased risk of metabolic syndrome [26].\n\nDue to missing data in potential mediators and abnormalities in blood cell counts, the final number of participants included in the mediation analysis was 6,617.S1 Figpresents box plots illustrating the distribution of lymphocyte, monocyte, neutrophil, and platelet data, along with the identification and exclusion of outliers in blood cell count data to ensure the accuracy of the analysis.\n\nThese covariates include sociodemographic characteristics, physical measurements, lifestyle behaviors, prevalent health conditions and metabolic health markers, as outlined inTable 1. The methods used to collect and classify data on hyperlipidemia, hypertension, and diabetes mellitus (DM) are detailed inS1 Table. In the NHANES program, serum samples were obtained during laboratory assessments, including measurements of high-density lipoprotein (HDL) and triglycerides (TG), both of which are reported in units of mmol/L. Each participant completed a PA questionnaire covering activities performed in the past 30 days. The questionnaire recorded the type, frequency, and intensity of activities, categorized as moderate or vigorous [27,28]. Moderate activities involved slight increases in breathing or heart rate, while vigorous activities caused substantial increases. The weekly total PA volume (PA total MET) was calculated as the sum of MET scores from work, recreational, and transportation-related activities. Further details on the definition of covariates can be found in previously published studies [23].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321251.t001\n\nFor this study, we focused on data from the 2007–2018 survey cycles, combining six consecutive cycles. Dietary day one sample weight (WTSAF2YR*1/6) were applied to account for the combined survey cycles and ensure accurate population estimates. Descriptive statistics summarized participant characteristics, with continuous variables reported as means and standard deviations (SD) and categorical variables as frequencies and percentages. Differences between groups stratified by MASLD status were analyzed using Chi-square tests for categorical variables and ANOVA for continuous variables. Collinearity diagnostics were performed for all covariates, with variance inflation factors (VIF) calculated. All covariates had a VIF less than 2.3, indicating no multicollinearity. Statistical analyses were conducted using R Studio (version 4.3.1) with the nhanesR package (version 0.9.4.3), following the principles outlined in the STROBE Guidelines.\n\nThe HEI, EDII and CDAI were divided into quartiles, from the lowest group (Q1) to the highest group (Q4), as outlined inS2 Table. Weighted logistic regression was employed to assess the association between dietary indices and MASLD. Three regression models were developed: an unadjusted model with no covariate adjustments; Model 1 adjusted for sex, age, and race; and Model 2 further adjusted for BMI, PIR, education level, marital status, alcohol consumption, smoking status, hypertension, hyperlipidemia, DM, TG, HDL, and PA total MET. Associations between dietary indices and MASLD were assessed using odds ratios (OR) with corresponding 95% confidence intervals (CI). To ensure the assumptions of logistic regression were satisfied, we examined the linear relationship between continuous independent variables and the logit(p) transformation.\n\nSubgroup analyses were performed to examine whether covariates potentially modified the relationship between dietary indices and MASLD. This approach enabled the association to be assessed within specific subgroups, such as age, sex, and BMI, ensuring the consistency of results across different population strata. Sensitivity analyses were conducted to address potential biases arising from missing data on key covariates. Notably, a substantial proportion of data was missing for PIR (N =  950), alcohol consumption (N =  1095) and PA total MET (N =  2056). A sensitivity analysis was conducted to test the robustness of the findings by excluding participants with missing data on PIR, alcohol consumption and PA total MET, resulting in a final sample of 10,083 participants.\n\nWe used histograms to assess the distribution of HEI (Fig 2A). Restricted cubic spline (RCS) analysis was utilized to examine potential nonlinear associations between dietary indices and MASLD. NonlinearP-values were calculated to evaluate the significance.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321251.g002\n\nThe “Mediation” package was employed to perform mediation analysis to evaluate the mediating effects of potential mediators. The analysis followed a two-step approach, as shown inFig 3A. First, regression models were applied to evaluate the influence of dietary indices on mediators (path a). Next, after adjusting for mediators, the effect of the mediators on MASLD (path b) and the effect of dietary indices on MASLD (path c’) were evaluated. The indirect effect was calculated as the product of path a and path b, and the mediation proportion was determined by dividing the indirect effect by the total effect. The total effect of dietary indices on MASLD was estimated without controlling for mediators (path c). Bootstrapping with 500 iterations was performed to calculate 95% confidence intervals for the mediation proportion.\n\nNotes: Adjust for age, sex, race, body mass index, poverty income ratio, education levels, marital status, smoking status, alcohol consumption, hyperlipidemia, hypertension, diabetes mellitus, triglyceride, high density lipoprotein and PA total MET. Abbreviations: HEI, healthy eating index; METS-IR, metabolic score for insulin resistance; HOMA-IR, homeostatic model assessment of insulin resistance; BRI, body roundness index; ABSI, a body shape index; ACME, average causal mediation effects (indirect effect); ADE, average direct effects. *P<  0.05, **P<  0.01, and ***P<  0.001.\n\nNotes: Adjust for age, sex, race, body mass index, poverty income ratio, education levels, marital status, smoking status, alcohol consumption, hyperlipidemia, hypertension, diabetes mellitus, triglyceride, high density lipoprotein and PA total MET. Abbreviations: HEI, healthy eating index; METS-IR, metabolic score for insulin resistance; HOMA-IR, homeostatic model assessment of insulin resistance; BRI, body roundness index; ABSI, a body shape index; ACME, average causal mediation effects (indirect effect); ADE, average direct effects. *P<  0.05, **P<  0.01, and ***P<  0.001.\n\nhttps://doi.org/10.1371/journal.pone.0321251.g003\n\nA total of 6,369 participants were included in this study (Fig 1).Table 1summarizes the characteristics of the study population, stratified by MASLD status. The prevalence of MASLD increased significantly with age (P<  0.001), with the highest prevalence observed in participants aged ≥ 60 years (42.79%). Among the participants, 3,102 (49.19%) were female, and 3,267 (50.81%) were male. The prevalence of MASLD was significantly higher in males compared to females (P<  0.001). Regarding BMI categories, 2,350 (38.32%) participants were under weight or normal weight, 2,275 (35.74%) were overweight, and 1,744 (25.94%) were obese. The prevalence of MASLD increased significantly with BMI, with 82.01% of obese participants having MASLD (P<  0.001). Other race had the lowest prevalence of MASLD (23.42%), while Hispanics had the highest prevalence (33.43%). Notable variations in MASLD prevalence were identified among racial/ethnic groups (P<  0.001). Participants with a PIR 1.3–3.5 had the highest prevalence of MASLD (31.55%), although the differences among PIR categories were not significant (P=  0.550). The prevalence of MASLD was highest among participants who had not completed high school (38.42%,P<  0.001). Other factors significantly associated with higher MASLD prevalence included being married/living with partner, being a former smoker, having hyperlipidemia, hypertension, or DM (P<  0.001 for all).\n\nMASLD participants had significantly lower HEI scores (52.11 ±  0.38 vs 55.30 ±  0.36,P<  0.001) and CDAI scores (0.90 ±  0.12 vs 1.41 ±  0.11,P<  0.001) compared to non-MASLD participants, whereas EDII had significantly higher scores (0.94 ±  0.05 vs 0.79 ±  0.03,P=  0.009). Additionally, participants with MASLD had significantly higher TG levels and lower HDL and PA total MET values compared to those without MASLD (P<  0.01 for all).\n\nBinary logistic regression was utilized to examine the associations between dietary indices and MASLD, with results detailed inTable 2. In the unadjusted model, HEI (continuous) demonstrated a significant inverse association with MASLD (OR: 0.98, 95% CI: 0.98–0.99,P<  0.001). This association persisted after adjusting for sex, age, and race in Model 1 (OR: 0.97, 95% CI: 0.97–0.98,P<  0.001) and remained significant in Model 2, which included all covariates (OR: 0.98, 95% CI: 0.97–0.99,P<  0.001).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321251.t002\n\nWhen HEI was analyzed as quartiles (Q1–Q4), consistent and significant associations were observed after full adjustment (Model 2). Participants in the highest quartile (Q4) exhibited substantially lower odds of MASLD compared to those in the lowest quartile (Q1) (OR: 0.46, 95% CI: 0.33–0.64,P<  0.001). The OR for Q2 and Q3 were 0.83 (95% CI: 0.61–1.12,P=  0.210) and 0.66 (95% CI: 0.49–0.89,P=  0.010), respectively. ThePfor trend in all models was also highly significant (P<  0.001).\n\nIn contrast, no significant associations were identified between MASLD and either EDII or CDAI after adjusting for all covariates in Model 2. This indicates that HEI was the only dietary index consistently and significantly associated with MASLD following comprehensive adjustment. Given the consistent and significant association between HEI and MASLD across all models, HEI was selected for subsequent analyses.\n\nThe results of the subgroup analysis are shown inTable 3. After controlling for all covariates, no significant interactions were observed in subgroups stratified by sex, age, BMI, race, smoking status, hyperlipidemia, hypertension, and DM, as allP-values for interaction exceeded 0.05. This suggests that the association between HEI and MASLD was consistent across these groups. To assess the robustness of these results, sensitivity analyses were performed (S3 Table). The outcomes were aligned with those inTable 2, confirming that HEI remained significantly associated with MASLD across all models.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321251.t003\n\nIn summary, the subgroup and sensitivity analyses consistently demonstrated that HEI was significantly associated with MASLD across different population strata and analytical approaches, confirming the reliability and robustness of the primary results.\n\nTo explore the potential nonlinear association between HEI and MASLD, we applied an RCS model with 4 strategically positioned knots, as illustrated inFig 2B. After adjusting for all covariates, the analysis indicated no statistically significant nonlinear relationship between HEI and MASLD risk (nonlinearityP=  0.399). This result aligns with the statistically significantPfor trend observed inTable 2, suggesting a linear association.\n\nAs shown inS4 Table, we conducted sensitivity analyses by varying the number of knots from 3 to 8. Regardless of the number of knots used in the RCS model, the nonlinearityP-values were consistently greater than 0.05, indicating no evidence of a nonlinear relationship between HEI and MASLD across different knot selections. These findings further support the robustness of the observed linear relationship.\n\nIn the mediation analysis, HEI, potential mediators, and MASLD were treated as the independent variable, mediator variables, and dependent variable, respectively. The relationship between HEI (continuous) and potential mediators was explored. As shown inS5 Table, in Model 2, METS-IR, HOMA-IR, SII, SIRI, ABSI, BRI, and bilirubin were significantly associated with HEI, indicating that the path a was significant for these mediators.\n\nNext, the relationship between potential mediators and MASLD was examined. As shown inS6 Table, after controlling all covariates and HEI, METS-IR, HOMA-IR, BRI, ABSI, and GGT were significantly associated with MASLD in Model 2, indicating that the path b was significant for these mediators.\n\nTo satisfy the prerequisites for mediation analysis, mediators must exhibit significant associations in both the paths a and b. Among the potential mediators, METS-IR, HOMA-IR, BRI, and ABSI met this criterion. These four mediators were selected for mediation analysis (Fig 3). The mediation analysis revealed significant indirect effects of HEI on MASLD through all four mediators. For METS-IR, the mediation proportion was 47.16% (95% CI: 28.47%–79.13%,P<  0.001). For HOMA-IR, the mediation proportion was 48.84% (95% CI: 7.38%–78.36%,P<  0.05). For BRI, the mediation proportion was 52.69% (95% CI: 35.22%–94.21%,P<  0.001). For ABSI, the mediation proportion was 13.84% (95% CI: 5.17%–28.13%,P<  0.001). These findings indicate that a portion of the relationship between HEI and MASLD is mediated by these factors, as shown inFig 3.\n\nThis study highlights the association between dietary quality, reflected by the HEI, and MASLD risk. HEI demonstrated a significant inverse association with MASLD, whereas the EDII and CDAI showed no significant associations. Mediation analysis revealed that insulin resistance (METS-IR, HOMA-IR) and visceral fat distribution (BRI, ABSI) partially mediated the relationship between HEI and MASLD, underscoring the importance of metabolic pathways in linking diet to liver health.\n\nOur analysis identified distinct patterns in MASLD prevalence across socio-demographic groups. Younger individuals, females, those with underweight/normal weight, and greater educational attainment were found to have lower MASLD prevalence. These results are broadly consistent with prior studies analyzing national datasets, which have underscored the influence of social factors on liver health [12,29]. These findings emphasize the importance of considering these covariates when studying the relationship between HEI and MASLD. Moreover, our findings show that MASLD is more prevalent in individuals with hyperlipidemia, hypertension or DM, conditions that are strongly implicated in metabolic dysfunction [30–32]. Hyperlipidemia is strongly associated with MASLD, with studies showing that moderate and severe hyperlipidemia significantly increase the prevalence of MASLD [33]. Hypertension is recognized as an independent risk factor for MASLD, with studies indicating that early-stage hypertension may promote MASLD development even without other metabolic abnormalities [34]. Additionally, managing blood pressure may help in preventing or slowing the progression of MASLD [34]. Similarly, DM contributes to insulin resistance and lipid dysregulation, creating conditions favorable for MASLD development [35]. Previous studies have highlighted these connections, and our findings support these established relationships while reinforcing the need for integrated metabolic risk management in MASLD prevention.\n\nThe relationship between iron overload and MASLD is complex. Recent studies have indicated that elevated serum ferritin levels are closely associated with the occurrence and severity of MASLD. However, iron overload is not merely a characteristic of MASLD; it may also reflect systemic inflammation or other metabolic abnormalities [36]. Research suggests that iron overload, particularly hyperferritinemia, may contribute to hepatic fat deposition and exacerbate liver fibrosis [37]. Nonetheless, some MASLD patients may present with concomitant hereditary hemochromatosis or other secondary causes of iron overload, which could independently impact liver health rather than being a direct component of MASLD [38,39]. To ensure the homogeneity of our study population and exclude potential liver diseases primarily driven by iron metabolism disorders, we excluded individuals with significant iron overload.\n\nPrior studies examining dietary indices and MASLD have reported conflicting results, likely due to differences in population characteristics, study design, and the extent of covariate adjustments. While some studies have highlighted the protective effects of CDAI on MASLD, others found no association [9–11]. Our findings strengthen the evidence supporting CDAI not a key dietary index associated with MASLD risk, leveraging a large, nationally representative dataset and rigorous analytical methods. Similarly, EDII did not exhibit significant associations with MASLD in this study. While these indices capture specific dietary components, such as antioxidant properties and inflammatory potential, they may not fully reflect the broader dietary patterns encompassed by HEI. This suggests that overall dietary quality, rather than individual dietary properties, may play a more critical role in MASLD prevention.\n\nA novel contribution of this study is the identification of insulin resistance and visceral fat distribution as mediators in the HEI-MASLD relationship. Insulin resistance is a hallmark of MASLD pathogenesis, promoting hepatic lipid accumulation and impairing metabolic regulation [40]. HEI, characterized by higher consumption of nutrient-dense foods, may enhance insulin sensitivity and reduce insulin resistance, thereby mitigating MASLD risk [14]. Similarly, visceral fat distribution, reflected by BRI and ABSI, is strongly linked to MASLD [41]. Visceral adiposity contributes to systemic inflammation, and metabolic syndrome, both of which exacerbate MASLD progression [41,42]. The inverse association between diet quality and visceral fat suggests that HEI may influence MASLD through visceral fat pathway [43]. These findings expand the understanding of how dietary patterns influence liver health and highlight the need for interventions targeting these mediating pathways.\n\nOxidative stress plays a critical role in the pathogenesis and progression of MASLD [44]. Diet has been widely recognized as a key factor influencing oxidative stress levels, with dietary patterns either exacerbating or mitigating oxidative damage [45]. Given the well-established link between oxidative stress and MASLD, we included oxidative stress as one of the potential mediators in our analysis to explore whether it contributes to the association between dietary indices and MASLD risk. To assess oxidative stress, we selected GGT, Bilirubin, and Uric Acid as biomarkers, as they are commonly used indicators of systemic oxidative stress in epidemiological and clinical studies [46]. By incorporating these oxidative stress markers into our mediation analysis, we aimed to determine whether oxidative stress acts as a biological link between dietary quality and MASLD risk.\n\nThe results of this study carry important implications for the prevention and management of MASLD. First, promoting adherence to dietary guidelines, as reflected by higher HEI scores, represents a practical and effective strategy for reducing MASLD prevalence. Public health campaigns emphasizing the benefits of high-quality diets rich in vegetables, fruits, lean proteins, and whole grains could play a pivotal role in addressing the growing burden of MASLD. The relationship between dietary composition and MASLD is well documented. A Western-style dietary pattern, characterized by high intake of red and processed meats, refined sugars, and saturated fats, along with low consumption of fiber-rich foods, has been associated with an increased risk of hepatic steatosis and liver fibrosis [47]. Conversely, adherence to healthier dietary patterns, such as the Mediterranean diet, has been shown to reduce liver fat accumulation, improve insulin sensitivity, and lower inflammation, thereby exerting protective effects against MASLD [48]. The observed lower HEI scores in MASLD patients in our study, reinforcing the need for dietary interventions targeting specific nutrient imbalances rather than focusing solely on total caloric intake. Additionally, integrating dietary assessments into clinical practice may help identify at-risk individuals and guide personalized nutritional interventions. Second, targeting mediating factors such as insulin resistance and visceral fat distribution may enhance the effectiveness of MASLD prevention efforts. Interventions aimed at improving metabolic health through diet and lifestyle modifications could reduce the burden of MASLD. These findings also underscore the need for multidisciplinary approaches combining dietary counseling, metabolic management, and lifestyle interventions in MASLD care.\n\nThis study has several methodological strengths that enhance the reliability and generalizability of its findings. The use of a large, nationally representative sample from NHANES (2007–2018) ensures that the results are applicable to diverse populations in the United States. The rigorous analytical framework, including comprehensive covariate adjustments and mediation analysis, provides robust insights into the complex relationships between dietary quality, metabolic mediators, and MASLD. Additionally, the inclusion of multiple dietary indices and mediators spanning four domains—insulin resistance, systemic inflammation, visceral fat distribution, and oxidative stress—offers a comprehensive evaluation of the pathways linking diet to MASLD.\n\nDespite its strengths, several limitations should be considered when interpreting these findings. The cross-sectional design of NHANES data limits the ability to draw causal conclusions, and longitudinal studies are needed to confirm the observed associations and mediation effects. Furthermore, dietary intake was evaluated using self-reported 24-hour recalls, which are prone to recall bias and potential underreporting. While HEI demonstrated strong associations with MASLD, the lack of significant findings for EDII and CDAI warrants further investigation. Future studies should explore whether these indices may have stronger associations with specific subgroups or stages of MASLD. Another limitation is the reliance on surrogate markers, such as FLI and USFLI, to define MASLD. While these indices are validated and widely used, direct imaging or biopsy-based measures of liver fat would provide more definitive assessments. Moreover, the mediators examined in this study do not capture all potential pathways, such as gut microbiota alterations, which may also play critical roles in the diet-MASLD relationship.\n\nIn conclusion, this study establishes HEI as a key dietary factor associated with reduced MASLD risk, with insulin resistance and visceral fat distribution playing mediating roles. These findings provide actionable insights into the mechanisms linking diet to liver health and underscore the importance of promoting high-quality diets in MASLD prevention.\n\nOutliers are highlighted within the black rectangular boxes.\n\nhttps://doi.org/10.1371/journal.pone.0321251.s001\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321251.s002\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321251.s003\n\n(DOCX)\n\nUnadjusted model: non-adjusted model. Adjust 1: Adjust for age, sex, race. Adjust 2: Adjust for age, sex, race, body mass index, education levels, marital status, e density lipoprotein. Abbreviations: HEI, healthy eating index; CI, confidence interval.\n\nhttps://doi.org/10.1371/journal.pone.0321251.s004\n\n(DOCX)\n\nAbbreviations: HEI, healthy eating index; CI, confidence interval.\n\nhttps://doi.org/10.1371/journal.pone.0321251.s005\n\n(DOCX)\n\nUnadjusted model: non-adjusted model. Adjust 1: Adjust for age, sex, race. Adjust 2: Adjust for age, sex, race, body mass index, poverty income ratio, education levels, marital status, smoking status, alcohol consumption, hyperlipidemia, hypertension, diabetes mellitus, triglyceride, high density lipoprotein and PA total MET. Abbreviations: HEI, healthy eating index; METS-IR, metabolic score for insulin resistance; HOMA-IR, homeostatic model assessment of insulin resistance; SII, systemic immune-inflammation index; SIRI, systemic inflammation response index; BRI, body roundness index; ABSI, a body shape index; GGT, serum gamma- glutamyltransferase; CI, confidence interval.\n\nhttps://doi.org/10.1371/journal.pone.0321251.s006\n\n(DOCX)\n\nUnadjusted model: non-adjusted model. Adjust 1: Adjust for age, sex, race. Adjust 2: Adjust for age, sex, race, body mass index, poverty income ratio, education levels, marital status, smoking status, alcohol consumption, hyperlipidemia, hypertension, diabetes mellitus, triglyceride, high density lipoprotein and PA total MET. Abbreviations: HEI, healthy eating index; METS-IR, metabolic score for insulin resistance; HOMA-IR, homeostatic model assessment of insulin resistance; SII, systemic immune-inflammation index; SIRI, systemic inflammation response index; BRI, body roundness index; ABSI, a body shape index; GGT, serum gamma- glutamyltransferase; CI, confidence interval. * To address the extreme OR values observed during the initial analysis, we scaled the ABSI values by multiplying them by 100. This transformation ensured that the variable was within a more interpretable and computationally stable range, without affecting the underlying associations. After this adjustment, the logistic regression model yielded reasonable and reliable OR estimates.\n\nhttps://doi.org/10.1371/journal.pone.0321251.s007\n\n(DOCX)\n\nWe extend our profound gratitude to the dedicated staff and principal investigators of the NHANES. Our deepest appreciation is reserved for the study participants whose invaluable contributions have been instrumental in advancing scientific knowledge and public health understanding.",
    "category": "immunology"
  },
  {
    "title": "Resveratrol decreases extracellular traps (ETs) in acute promyelocytic leukemia (NB4) cells",
    "authors": "Mahshid Vafajoo, Minoo Shahidi, Fahimeh Shahriyary, Mohammad Reza Amirzargar, Ahmad Kooshari, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321221",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321221",
    "content": "Activated neutrophils can create structures known as neutrophil extracellular traps (NETs/ETs) consisting of nuclear components and granules. The ETOsis phenomenon leads to activating the platelets and coagulation factors. Accordingly, coagulation and fibrinolysis can be promoted. Resveratrol (RSV) is a botanical antioxidant with anti-inflammatory and anti-leukemia effects. The present study was conducted to assess the effect of RSV on the occurrence of ETOsis in the NB4 cell line.\n\nHuman acute promyelocytic leukemia cell line (NB4) were stimulated and treated by lipopolysaccharides (LPS) and RSV, respectively. Sytox green and a fluorescent microscope were used to assess the ETOsis in NB4 cells. Furthermore, the expression level of peptidylarginine deiminase 4 (PAD4) gene and the occurrence of ETOsis in NB4 cells were evaluated by real-time PCR and flow cytometry, respectively. Moreover, an enzyme-linked immunosorbent assay (ELISA) kit was utilized to measure tumor necrosis factor-α (TNF-α) cytokine.\n\nFollowing treatment with RSV, a significant decrease in PAD4 gene expression and TNF-α cytokine concentration in the supernatant of NB4 cell line culture medium was observed. Besides, the amount of ETOsis in the NB4 cells treated with LPS and RSV decreased.\n\nThe findings demonstrated that RSV can inhibit the process of ETOsis in NB4 cells. By inhibiting the process of ETOsis, RSV may be able to reduce the bleeding and, consequently, the failure after treatment in acute promyelocytic leukemia (APL) patients.\n\nCitation:Vafajoo M, Shahidi M, Shahriyary F, Amirzargar MR, Kooshari A (2025) Resveratrol decreases extracellular traps (ETs) in acute promyelocytic leukemia (NB4) cells. PLoS ONE 20(4):\n           e0321221.\n        \n        https://doi.org/10.1371/journal.pone.0321221\n\nEditor:Mehmet Baysal, Tekirdag Namik Kemal University: Tekirdag Namik Kemal Universitesi, TÜRKIYE\n\nReceived:August 11, 2023;Accepted:March 3, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Vafajoo et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and itsSupporting Informationfiles.\n\nFunding:This study was supported by grants from Iran University of Medical Sciences, Tehran, Iran (Cod number: 16493).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nNeutrophils have a killing function by engulfing and degrading bacteria through antimicrobial cytoplasmic granules [1]. In addition, activated neutrophils have the ability to destroy extracellular pathogens through forming neutrophil extracellular traps (NETs/ETs), consisting of nuclear components and granules. Interleukin 8, phorbol myristate acetate (PMA), and lipopolysaccharides (LPS) are factors that could stimulate neutrophils for NETs formation [2].\n\nDuring NET formation, peptidylarginine deiminase 4 (PAD4) is activated by increasing the intracellular calcium level. Active PAD4 converts arginine in histones to citrulline after translocation into the nucleus. Finally, the chromatin is decondensed as a result of the lack of the positive charge of histones [3]. Therefore, a particular marker for ETosis could be citrullinated histone. Given the observed relationship between ETosis and thrombosis in diseases such as cancer-associated thrombosis, the risk of thrombosis can be evaluated by the specific markers of ETosis [4]. Moreover, increasing the level of DNA in the blood circulation can be considered one of the molecular mechanisms of blood clotting and thrombosis in cancers [5].\n\nAcute promyelocytic leukemia (APL) is a kind of blood cancer which occurs as the result of the t (15,17) chromosomal translocation. In this disease, some cellular processes, including the division, differentiation, and death of promyelocytes, are disrupted [6]. These patients are involved in thrombotic and bleeding coagulation problems, which are life-threatening [7]. All-transretinoic acid (ATRA) and arsenic trioxide (ATO) drugs are used to treat APL, which induce both apoptosis and cell differentiation. But unfortunately, in some cases, due to patients becoming resistant to these drugs, the disease will recur after a while [8]. ATO has shown a dose-dependent effect on ETOsis and apoptosis processes, with its medium and high concentrations stimulating ETOsis and apoptosis in APL cells, respectively [9]. Moreover, ATRA can induce and increase the ETOsis process in promyelocytic cells by increasing cytokines such as TNF-α and IL-6 [6]. Promyelocyte extracellular chromatin induced by ATRA causes excessive use of coagulation factors, thrombin production, and fibrin deposition. Ultimately, these factors cause disruption of clot lysis and endothelial cell damage [7]. In addition, ETs results in the activation of platelets, whereby the secretion of active platelet factors, the stimulation of endothelial retraction, and the creation of gaps between endothelial cells happen. Consequently, the leakage of red blood cells (RBCs) from the vessels leads to bleeding. Therefore, it seems useful to find a solution to reduce the occurrence of ETOsis and, subsequently, the bleeding burden and more effective treatment in APL patients [10].\n\nResveratrol (RSV) (3,5,4 -trihydroxy-trans-stilbene) is a small polyphenol, which is found in sources such as red grapes and various berries. It is considered a strong antioxidant that reduces the cytokines and pro-inflammatory mediators such as IL-6 and TNF-α in immune cells by destroying reactive oxygen species (ROS) and inhibiting nuclear factor-kappa B (NF-κB) [11,12]. As studies revealed, RSV and ATO have a synergistic pro-apoptotic effect and anti-leukemia activity on NB4 cells [13]. Moreover, RSV induces apoptosis and differentiation of APL cells. The findings state that the simultaneous use of RSV and ATRA increases differentiation in NB4 cells, so further investigation of RSV as a therapeutic agent for APL can be beneficial [14].\n\nOne of the main problems in patients with APL is disseminated intravascular coagulation (DIC), a tendency to thrombosis and bleeding [15]. Additionally, the use of ATRA, by increasing the occurrence of ETOsis in APL cells, can aggravate thrombosis and bleeding in these patients [7]. Given the anti-inflammatory effect of RSV, it seems interesting to investigate its effect on the process of ETOsis in these patients. Due to these reasons, this study assessed whether RSV inhibits ETOsis in acute promyelocytic leukemia (NB4) cells stimulated by LPS or not.\n\nThis research was conducted on the NB4 cell line gifted by Dr. Majid Safa at the Hematology Research Center of Iran University of Medical Sciences.\n\nHuman acute promyelocytic leukemia cell line (NB4) was cultured in RPMI-1640 with L-Glutamine (Gibco) medium containing 10% fetal bovine serum (FBS) (Cegrogen Biotech) and 1% penicillin-streptomycin (Penicillin 100 U/ml-Streptomycin 100 µg/ml) (Gibco) at a 5% CO2 humidified atmosphere and 37°C. The cells in the log phase were subjected to experiments.\n\nSeeded NB4 cells in 6-well plates at 105cells/well were stimulated with LPS (500 ng/mL, Sigma Aldrich). Then, they were treated with different concentrations (0, 5, 10 μM) of RSV (Sigma Aldrich) for 2:30 h. The drug concentrations were selected regarding the obtained results in the MTT assay. In the control well, cells were only incubated with RPMI-1640 supplemented medium.\n\nAfter harvesting NB4 cells treated with certain concentrations of RSV (Sigma Aldrich) and control cells (media alone), they were incubated for 3 hours at 37°C. Approximately 7 ×  104of these cells were cultured in 94-well plates. Then, thiazolyl blue tetrazolium bromide (MTT) solution (Sigma Aldrich) with a concentration of 0.5 mg/ml was added to the cells. After 3 hours, the cells were centrifuged at 1000 g for 10 minutes. In order to dissolve the formazan, 100 μl of dimethyl sulfoxide (DMSO) solution was added to the wells and mixed on a shaker for 15 minutes. Then, the optical density (OD) was read by an ELISA reader at wavelengths 570–630. It should be noted that the OD of the control sample is considered 100% viability. Moreover, all tests were performed in triplicate.\n\nNB4 cells (15 × 104) were resuspended in RPMI-1640 supplemented with 10% FBS, seeded in 24-well plates, and subjected to stimulation [LPS (500 ng/mL)] along with different concentrations (0, 5, 10 μM) of RSV. They were incubated for 2:30 hours at 37◦C in a CO2incubator. After the drug treatment step, SYTOX green (10 nM, Biolegend, USA) was added to each well. One well is unstained. The chromatin released by NB4 cells is bindable by SYTOX green, a cell impermeable dye that binds to extracellular DNA. The ETs process was quantified using SYTOX green by FACS Calibur flow cytometry (Becton Dickinson). Then, the results were analyzed with FlowJo_V10 software (BD Biosciences, USA).\n\nAfter the drug treatment step, the ETs were stained with SYTOX green (1 µ M, Biolegend, USA), and Images were taken on a fluorescent microscope (NIKON ECLIPSE Ts2R), and the results were analyzed by Image J (NIH, USA).\n\nIn order to assess the changes in PAD4 gene expression in NB4 cells stimulated with LPS and treated with the RSV drug, the qRT-PCR technique was performed. After the treatment step, the cell sediment was isolated, and total RNA was extracted using RNX-Plus Solution (EX6101, Sinaclon). Then, cDNA was synthesized according to the manufacturer’s instructions for the cDNA Synthesis Kit (Ana cell). To perform the qRT-PCR, SYBR Green RT-PCR Master Mix (Ampliqon), forward primer, reverse primer, cDNA sample, and double-distilled water were used. After that, the samples were subjected to 40 cycles as follows: each cycle including 15 seconds at 95°C and 60 seconds at 60°C. Each reaction was repeated three times. It should be noted that GAPDH gene was used as an internal control. Finally, the results were calculated using the ∆∆Ct method.\n\nPAD4 primer was designed using the websitehttp://www.ncbi.nlm.nih.gov/blast/and Oligo 7 software. The primers sequences were listed inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321221.t001\n\nThe cell supernatant was separated through centrifuging at 2500 RPM for 10 minutes at 4°C. Finally, TNFα was quantified in cells supernatant according to the ELISA Kit (IBL, Hamburg, Germany) manufacturer’s instructions.\n\nThe data was analyzed by GraphPad prism 8.2.1 software (GraphPad Software, Inc., San Diego, CA, USA). The mean ±  SD was calculated to describe quantitative variables. In order to compare quantitative variables between two and more than two independent groups, student’sttest or one-way ANOVA were used, respectively.pvalue less than 0.05 was regarded as significant.\n\nIn the presence of different concentrations of RSV, viability was detected in NB4 cells. The MTT results considered a dose of 5 µ M as the best-selected dose.\n\nThe results of flow-cytometric analysis showed significant changes between treated groups with RSV 5 and 10 µ M and LPS-stimulated NB4 cells. Both concentrations of RSV significantly decreased the rate of ETosis. However, RSV 5 µ M demonstrated a higher effect compared with 10 µ M (Fig 1; A1 and A2 p = 0.002,Fig 1; A1 and A3 p = 0.002).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321221.g001\n\nInFig 2, we showed the results of NB4 cells treated with SYTOX green, which was detected by a fluorescent microscope (Fig 2A). The results were analyzed using Image J after counting cells in ten fields for each condition (Fig 2B). In agreement with flow cytometry analysis, results demonstrated a significant decrease in ETOsis formation when compared with RSV-treated NB4 cells (Fig 2; 1A and 2A p < 0.001,Fig 2; 1A and 3A p < 0.001).\n\nA: LPS stimulated NB4 cells with the SYTOX green concentrations (1). NB4 cells treated with RSV (5 µ M) (2). NB4 cells treated with RSV (10 µ M) (3). All images are 10x,***p < 0.001. Resveratrol (RSV) B: Results of microscopy analysis. In cells treated with resveratrol at both concentrations of 5 and 10 μM, ETOsis incidences were lower than in cells treated with LPS alone.\n\nA: LPS stimulated NB4 cells with the SYTOX green concentrations (1). NB4 cells treated with RSV (5 µ M) (2). NB4 cells treated with RSV (10 µ M) (3). All images are 10x,***p < 0.001. Resveratrol (RSV) B: Results of microscopy analysis. In cells treated with resveratrol at both concentrations of 5 and 10 μM, ETOsis incidences were lower than in cells treated with LPS alone.\n\nhttps://doi.org/10.1371/journal.pone.0321221.g002\n\nThe mRNA levels of PAD4 were assessed as one of the key factors to determine the status of ETOsis. As shown inFig 3, PAD4 expression level in NB4 cells has significantly decreased in cells treated with both concentrations of RSV 5 M (p < 0.001) and 10 M (p < 0.001) compared to the control group.\n\n***p < 0.001, ****p < 0.0001. PAD4 expression was increased in NB4 cells treated with LPS stimulus, whereas it was decreased when cells were treated with 5 or 10 μM resveratrol.\n\n***p < 0.001, ****p < 0.0001. PAD4 expression was increased in NB4 cells treated with LPS stimulus, whereas it was decreased when cells were treated with 5 or 10 μM resveratrol.\n\nhttps://doi.org/10.1371/journal.pone.0321221.g003\n\nThe measurement of TNF-α by ELISA indicated a significant decline in the level of cytokine in the RSV treatment groups with concentrations 5 µ M (p =  0.014) and 10 µ M (p =  0.012) rather than control group (Fig 4,Table 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321221.t002\n\nαin RSV-treated groups and the control.The level of TNFα in RSV-treated groups is significantly lower than control (LPS). Individual data are presented as mean ±  SD (t test), **p < 0.01.\n\nαin RSV-treated groups and the control.The level of TNFα in RSV-treated groups is significantly lower than control (LPS). Individual data are presented as mean ±  SD (t test), **p < 0.01.\n\nhttps://doi.org/10.1371/journal.pone.0321221.g004\n\nThe incidence of ETOsis increased in the control state when the cells were treated with LPS alone in all assays, while ETOsis decreased when resveratrol was added to the medium at both doses. Additionally, in cells treated with LPS stimulant only, expression of the PAD4 gene, a key marker of ETOsis, increased, while in cells treated with resveratrol, it decreased. Compared to the control condition, TNF-α decreased in cells treated with resveratrol. Thus, resveratrol inhibited ETOsis in NB4 cells.\n\nThe present study investigated the effect of RSV on the occurrence of ETOsis in the NB4 cell line. The findings of flow cytometry and microscopy demonstrated that the RSV reduces ETosis in NB4 cells. Moreover, a decrease in ETOsis was observed in NB4 cells treated with LPS stimulus and RSV. For the first time, in 2016, it was demonstrated that APL cells were affected by ETOsis through the release of extracellular DNA traps (ET). It was also found that ATRA accelerated ET formation by increasing the levels of TNF-α, interleukin-6 and autophagosome formation [6]. Researchers suggest that autophagy in APL cells is induced by ATO through rapamycin-dependent autophagy and reactive oxygen species. Leukaemia-initiating cells (LICs) are reduced by increased ETosis caused by ATO. Through ETosis, ATO exerts anti-leukaemic effects and targets LICs as the key component of the treatment and relapse prevention protocol. Therefore, increasing ETosis induced by ATO seems like a potential strategy for eradicating LICs[9]. This theory, however, has been contradicted by other studies; observations have demonstrated that ATRA causes ETosis, which results in extracellular chromatin that produces excessive amounts of thrombin and fibrin, increases plasmin, and damages endothelium. Extracellular promyelocytic chromatin exacerbates the coagulation and fibrinolysis of acute promyelocytic leukemia and may cause induction failure in high-risk patients with APL [7]. A study published in 2022 demonstrated that ATRA and ATO drugs induce and increase ETOsis in mature neutrophils. Moreover, platelet-derived factor 4 stimulates ETOsis, causing ETs to stimulate platelets and secrete platelet derivatives, resulting in a positive feedback loop. ETs lead to endothelial contraction and gap formation in APL, which result in RBC leakage and increased bleeding. Therefore, an ETOsis inhibitor may reduce bleeding in APL and protect endothelial cells from damage [10].\n\nRSV is a botanical ingredient with anti-inflammatory, anti-tumor, and anti-leukemia effects [16]. Considering the previous studies, RSV can inhibit cell proliferation in NB4 cells through apoptosis. Certainly, further studies on this drug as an effective therapeutic agent in APL patients is useful [13,14]. Our results demonstrated the occurrence of ETOsis in the NB4 cells in the presence and absence of RSV. In order to quantitatively investigate the occurrence of ETOsis, the PAD4 gene expression change was measured using the real-time PCR technique. The results of our study revealed that the expression of the PAD4 gene decreased significantly after treatment of cells with RSV compared to LPS stimulation alone. The highest decrease was observed in 10 µ M concentration. Therefore, compared to the findings of flow cytometry and microscopy, it is quite obvious that the RSV reduces the occurrence of ETosis in NB4 cell line. However, to find the most suitable concentration of RSV, more investigation is needed.\n\nThere is still a lack of understanding of how resveratrol reduces ETOsis. Future research may help to resolve this question. Resveratrol, this phenolic molecule, has been shown to inhibit the reactive oxygen species (ROS) cycle (COX) in previous studies. Additionally, it activates anti-inflammatory pathways, such as SIRT1, which reduces the production of inflammatory factors such as TNF-α. And activates many anti-inflammatory pathways, including SIRT1, to reduce the production of inflammatory factors like TNF, IL-1, IL-6, MMP-1 and COX-2 by inhibiting nuclear factor-kappa-B (NF-KB) [11]. Finally, considering that the ETOsis process requires ROS from the NADPH oxidase pathway and inflammatory cytokines such as TNF-α, IL-6, resveratrol may inhibit the ETOsis process by reducing these products.\n\nIn a previous study, it was shown that in NB4 cells treated with ATRA drug, the concentration of cytokines IL-6 and TNF-α increased in a time-dependent manner. The increase of these cytokines causes the stimulation of NB4 cells and the release of ETs (Extracellular Traps) by these cells [6]. Moreover, the RSV drug in combination with ATRA induces both apoptosis and differentiation in NB4 cells [14] and it shows a synergistic anti-leukemia effect when used in conjunction with ATO [13]. Furthermore, we observed that resveratrol significantly decreased VWF, t-PA-1, and IL-8 levels in our previous study of the effects of resveratrol on human umbilical vein endothelial cell expression and secretion of coagulation, fibrinolytic, and inflammatory markers. Additionally, resveratrol reduced VWF and t-PA-1 mRNA expression as well as factor VIII activity. In cell culture (in vitro), resveratrol demonstrated anti-inflammatory, anticoagulant, and anti-fibrinolytic effects [17].\n\nIn the present study, the amount of TNF-α cytokine in the supernatant of the NB4 cell line culture medium stimulated with LPS increased. The amount of this cytokine in the supernatant of NB4 cell line culture medium treated with LPS in the presence of RSV at both 5 and 10 μM concentrations has decreased compared to the control state (treatment with stimulant alone). In another study on the RSV, it has been suggested that the simultaneous use of RSV and ATO can reduce the hepatotoxicity resulting from ATO [18]. In addition, recent findings on animal models revealed that the RSV with its strong antioxidant potential prevents the accumulation of arsenic in the liver and kidneys in rats exposed to ATO [19]. Furthermore, APL cells in patients treated with ATO undergo autophagy-induced ETOsis [9]. Recent studies have also shown that there is a significant positive correlation between plasma ATO concentration and cfDNA concentration in elderly APL patients treated with ATO and found that cfDNA in these patients is caused by the ETOsis process [20]. Moreover, RSV can inhibit PI3K/AKT pathway activity in NB4 and HL-60 cells by upregulating the expression of phosphatase and tensin homologue (PTEN), whereby the proliferation of leukemic cells is suppressed, and apoptosis is induced in these cells. Therefore, it has been claimed that RSV has an anti-leukemia effect [21]. Since RSV has recently been suggested to be an agent inducing apoptosis and modulating autophagy in APL cells, it can be considered as an efficient chemotherapy agent [22].\n\nAlthough ATRA and ATO are used to treat patients with APL, the development of thrombosis and embolism is regarded as the main problem after treatment [10]. For the first time, the current study has investigated the effect of RSV on ETOsis of APL (NB4) cells, which is one of the causes of thrombosis. It could be a turning point to find a less complicated treatment in the future.\n\nThe limitations of this research should be considered. The first limitation is the use of NB4 cells instead of bone marrow (BM) cells and plasma from APL patients, which would yield more accurate results. However, due to the difficulty of preparing BM samples and maintaining and cultivating them, NB4 cell line was used in this study. Moreover, if ATRA and ATO are used in combination with RSV, the results will be more reliable for use in clinical settings where patients are treated with these drugs.\n\nIn conclusion, RSV causes a decrease in PAD4 gene expression and TNF-α cytokine concentration in the supernatant of NB4 cell line culture medium. Furthermore, the amount of ETOsis in the NB4 cell line treated with LPS and in the presence of RSV, decreased. Therefore, the RSV, in addition to being an effective therapeutic agent in APL patients, may be able to reduce burden of bleeding by inhibiting the process of ETOsis and subsequently reduce failure after treatment in APL patients. It is suggested to use RSV in combination with ATRA in future studies and investigate the effect of RSV on the ETOsis process in NB4 cell line treated with ATRA, so that a more efficient treatment for APL patients can be approached. Additionally, it is suggested that animal samples be used in future studies to investigate the effect of RSV on the ETOsis process in APL cells in order to obtain clinically relevant results.\n\nhttps://doi.org/10.1371/journal.pone.0321221.s001\n\n(RAR)\n\nWe would like to express our sincere gratitude to our colleagues who contributed to this research for their guidance and support.",
    "category": "immunology"
  },
  {
    "title": "Quantitative risk assessment and interventional recommendations for preventing canine distemper virus infection in captive tigers at selected wildlife stations in Thailand",
    "authors": "Kanittha Tonchiangsai, Anuwat Wiratsudakul, Suwicha Kasemsuwan, Ruangrat Buddhirongawatr, Weerapong Thanapongtharm, Kan Kledmanee, Tatiyanuch Chamsai, Nareerat Sangkachai, Bencharong Sangkharak, Pakpoom Aramsirirujiwet, Sarin Suwanpakdee, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320657",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320657",
    "content": "Canine distemper virus (CDV) can cause high morbidity and mortality in large felids and pose a significant threat to the conservation of captive and non-captive tiger (Panthera tigris). This study conducted in Thailand’s wildlife stations aimed to assess the risks of CDV introduction to captive tiger populations. A stochastic quantitative risk assessment model was employed to determine the pathways and estimate the risk probabilities through humans, animal reservoirs, and fomites. The final risk probability of entry, obtained from a combination of six entry pathways, indicated that the absence of measures resulted in a relatively high risk at 0.858. The sensitivity analysis identified CDV-contaminated human hands, followed by other CDV-infected wild animals, and CDV-contaminated equipment, as the most influential pathways of CDV spread. Risk probabilities were compared among those without intervention, with routine intervention at wildlife stations, and with full intervention implementation. Implementing all interventions at the captive wildlife stations significantly reduced the risk of CDV introduction. These interventions included control measures such as quarantining and isolating infected animals and providing treatment to reduce infectiousness. Preventive measures included screening tests for healthy individuals for early detection of asymptomatic or pre-symptomatic cases, preventing further spread or complications, CDV vaccination campaigns, and promoting hand hygiene among staff and visitors. Environmental interventions involve restricting dogs and cats from accessing tiger enclosures, disinfecting animal transport vehicles, using separate equipment for each cage, etc. Together, these interventions lowered the median risk of CDV introduction to 0.089, representing an 89.6% risk reduction. This approach assessed CDV infection risks and adapted interventions to specific situations at wildlife stations. Consistent implementation of these measures is essential to minimize CDV spread. Wildlife stations must strictly implement these interventions as standard procedures to protect the health of captive tigers.\n\nCitation:Tonchiangsai K, Wiratsudakul A, Kasemsuwan S, Buddhirongawatr R, Thanapongtharm W, Kledmanee K, et al.  (2025) Quantitative risk assessment and interventional recommendations for preventing canine distemper virus infection in captive tigers at selected wildlife stations in Thailand. PLoS ONE 20(4):\n           e0320657.\n        \n        https://doi.org/10.1371/journal.pone.0320657\n\nEditor:Julian Ruiz-Saenz, Universidad Cooperativa de Colombia, COLOMBIA\n\nReceived:September 14, 2024;Accepted:February 23, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Tonchiangsai et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nCanine distemper virus (CDV) is an enveloped single-stranded RNA virus of the familyParamyxoviridaein the genusMorbillivirus[1]. Distemper is a highly contagious and potentially fatal disease that attacks a dog’s respiratory, gastrointestinal, and nervous systems. CDV is spread through the air by infected coughs or sneezes and could be transmitted through contact with bodily fluids [2]. Although puppies and unvaccinated dogs are most at risk, all dogs are susceptible to the virus [2]. It can also infect other animals within the order Carnivora, including foxes (Vulpes vulpes), raccoons (Procyon lotor), bears (Ursusspp.), and large felids (Pantheraspp.) and species outside this order, such as the rhesus monkey (Macaca mulata), collared anteater (Tamandua tetradactyla), and Asian elephant (Elephas maximus) [2]. Clinical symptoms in infected tigers and other carnivores range from asymptomatic to nasal discharge, conjunctivitis, hyperkeratosis at footpads and nasal planum, diarrhea, melena, vomiting, seizure, opisthotonos, and myoclonus [3–6]. Laryngeal paralysis and stridor sounds were also observed in infected tigers [5].\n\nTigers (Panthera tigris) are an endangered species [7]. Thailand has approximately 190-250 wild tigers, mainly found in western forests [8]. Meanwhile, captive tigers are housed in wildlife stations and zoos and by private owners [9–11]. The government has implemented strict laws to protect tigers in Thailand [12]. The Department of National Parks, Wildlife, and Plant Conservation (DNP) oversees wildlife breeding and rescue centers (referred to as wildlife stations in this study), and the Zoological Park Organization of Thailand (ZPOT) manages governmental zoos. As of 2021, Thailand has a total of 164 captive tigers: 119 in DNP wildlife stations (S1 Table inS1 File) and 45 in ZPOT zoos [10]. Tigers are kept in legal captivity for conservation. Wildlife stations participate in captive rescues as part of ex situ conservation efforts. Health and disease prevention management is crucial to maintain the health of captive tigers.\n\nIn tropical and subtropical ecosystems, tigers serve as an umbrella and iconic species, and their conservation supports broader biodiversity by maintaining ecological balance and protecting coexisting species [13]. As apex predators, they regulate prey populations, contributing to their ecosystem health [14]. However, wild tigers are facing an additional threat from CDV, which is associated with illness and death in large felids [15]. CDV poses a potential threat to the extinction of Amur tigers (Panthera tigris altaica) with small populations, particularly those in Russia. A significant CDV outbreak affected Amur tigers in 2004 and 2010 within the Sikhote-Alin Biosphere Reserve in Russia, leading to a dramatic population decline from 25 individuals in 2008 to only 9 in 2012. Infected tigers exhibited abnormal behaviors, such as fearlessness and neurological symptoms, which caused human wildlife conflicts and fatalities. This outbreak highlighted the susceptibility of small tiger populations to diseases introduced from reservoirs of more abundant species, such as domestic dogs and wild carnivores [16].\n\nIn 2011, 12 captive tigers at a Japanese zoo contracted respiratory and gastrointestinal diseases. A tiger died from neurological complications, and CDV was found in its fecal samples and lungs. This outbreak may have been spread by wildlife around the zoo [4]. In 2021, a CDV outbreak resulted in the death of seven captive tigers and one lion in an exotic feline rescue center in the USA. It was linked to being near or sharing enclosures with infected animals of the same species [17]. In 2016, two captive wildlife stations in Thailand experienced a major CDV outbreak. Most of the 156 affected tigers were Siberian tigers taken from private collectors. A total of 88 tigers died; the majority of deaths were suspected to be caused by CDV infection, with 31.88% (22 out of 69 dead tested tigers) primarily attributed to CDV infection. Neurological signs were observed after the systemic infection had developed. Other animals, including bears, monkeys, and leopard cats, also tested positive for CDV during this outbreak [5].\n\nTherefore, risk estimation of CDV infection is needed in captive large felids to recommend the best practices for disease prevention. The risk assessment results help in the management of quarantined and sick animals and the prevention of the spread of viral particles into the environment. In this study, stochastic risk assessment of CDV infection for captive tigers in the wildlife stations was used. It is a protocol for determining the risk groups and defining the risk level. Finally, the effectiveness of risk-reducing interventions was assessed by entering them into the risk estimation models. This study aimed to present best practices to mitigate the risk of CDV introduction to captive wildlife stations.\n\nCaptive tigers are found in 10 of 26 Thailand’s DNP wildlife stations, including wildlife rescues and breeding stations. This study focused on 7 stations located in different regions in Thailand, which have more than 2 tigers. Three stations with only 1-2 tigers and potentially different husbandry and management practices were excluded (Fig 1). This figure was generated by the authors using QGIS version 3.30.3-’s-Hertogenbosch, with base map data obtained from the Thai Land Development Department (accessible athttps://tswc.ldd.go.th/DownloadGIS/Index_Lu.html, accessed on [May 30, 2024]).\n\nYellow circles show the included stations, whereas pink circles show the excluded ones. The sizes of the circles represent the number of tigers. Red stars indicate wild tiger habitats, and green areas represent forests.\n\nYellow circles show the included stations, whereas pink circles show the excluded ones. The sizes of the circles represent the number of tigers. Red stars indicate wild tiger habitats, and green areas represent forests.\n\nhttps://doi.org/10.1371/journal.pone.0320657.g001\n\nData were collected from 2016 to 2021 through interviews using semi-structured questionnaires. These questionnaires contained a mix of predefined questions with specific response options (structured parts) alongside open-ended questions that allowed respondents to provide more detailed responses. The interviews were conducted on-site and online. The plan was to interview one director or veterinarian per wildlife station and approximately three animal keepers per station, or as many as were available. Across seven wildlife stations, a total of interviews was conducted. This included interviews with directors from four stations and veterinarians from three stations using questionnaire number 1 (QN1). In addition, due to variations in the number of staff at different stations, a total of 18 interviews with keepers were conducted. These comprised 15 tiger keepers, 2 keepers of other susceptible wild animals (1 bear keeper and 1 monkey keeper), and 1 animal husbandry staff member. All keeper interviews were conducted using QN2. Both QN1 and QN2 are provided in the supporting information (S9 inS1 File). Nevertheless, information from various other sources, such as health and husbandry records of wildlife stations, laboratory databases, published literature, public databases, relevant websites, and standard guidelines, were used as input parameters and probabilities incorporated into the quantitative stochastic models employed in this study. Subsequently, the backbone pathways of CDV entry to wildlife stations were developed based on the collected data.\n\nThe quantitative risk assessment model was developed, and calculations were made using the R Program Version 4.3.0 within the interface R-studio Program Version 2023.03.1. Probability distributions were selected with the Monte Carlo sampling method from the package “mc2d” to run entry scenarios with 1,000 iterations. Median probabilities with 5thand 95thpercentile values were determined. The sensitivity analysis was conducted to identify the most influential parameters on the model outputs. Risk-mitigated interventions were chosen to analyze risk reduction after identifying the most potential entry pathways.\n\nRoutes or physical pathways of CDV entry to CDV-free wildlife stations were identified without any interventions (Fig 2). The entry boundaries for all animal infections and fomite contaminations began at the entrance of tiger housing areas within the wildlife stations.\n\nThe arrowheads show the directions of entry, and the crosses in circles show conditions without entry in those routes.\n\nThe arrowheads show the directions of entry, and the crosses in circles show conditions without entry in those routes.\n\nhttps://doi.org/10.1371/journal.pone.0320657.g002\n\nGiven that not all transmission routes can infect tigers in the housing areas, CDV can enter wildlife stations through infected tigers, other wild animals, domestic dog or cat reservoirs, human contamination (hands, bodies, and feet), animal-transported vehicles, equipment, and tigers’ food. The Australian guideline for importing non-domestic Felidae requires diagnostic tests, treatment efficacy information, vaccinations, and appropriate quarantine durations [18]. Following this guideline, tigers and other wild animals need to be tested for CDV to ascertain their disease status before transportation, quarantined for 30 days after arrival to observe symptoms, and tested again for CDV. After testing, sick animals are isolated, treated, and/or given CDV vaccination. The presence of domestic dogs and cats near wildlife stations and their ability to access housing areas of tigers or other wild animals were also considered in the entry pathway because CDV aerosol transmission between animals can occur.\n\nHumans in close contact with tigers, such as staff members, can transmit CDV to tigers or other animals. This occurs when humans touch equipment used in tigers’ cages, tigers’ food, animal transport vehicles, or their pets at home. Visitors who do not have direct contact with tigers can also contribute to contamination by touching food tongs with their hands. Therefore, human hand contamination was included in the entry pathway. However, human bodies and contaminated footwear were omitted from the entry pathway because visitors are prohibited from entering tiger cages. In addition, staff members responsible for tiger care do not enter the tiger cages directly, as tigers are wild animals with instinctive aggression. Staff members do not make physical contact with the tigers. Cleaning tasks, such as washing floors or cleaning water ponds, are generally performed only after the tigers have been moved to another cage. During the survey of wildlife stations, no tiger cubs were present; thus, contamination through external human body contact, such as hugging or holding them, was not possible.\n\nWildlife stations have animal transport vehicles, which can be accessed near the tiger cages. CDV can contaminate vehicles carrying infected animals; thus, this study focused only on exterior surfaces such as wheels or mudguards. In addition, equipment was shared among tiger and other animal cages, such as floor-cleaning brushes used between tiger and small wild cat cages, and cages used to transport tigers were also used to transport monkeys. Domestic dogs could not enter tiger cages or pantries in wildlife stations; thus, the risk of contamination through tigers’ food from infected dogs was eliminated. CDV contamination via food handlers or outsiders was also excluded, as food preparation staff members work only in designated areas with strict hygiene protocols, and outsiders never handle the feed. In instances where feeding activities occur at certain wildlife stations, tools are utilized to avoid direct contact.\n\nThus, the physical pathways of CDV introduction to wildlife stations inFig 2contained six biological pathways, namely, i) CDV-infected tigers, ii) other CDV-infected wild animals, iii) dog or cat reservoirs, iv) CDV-contaminated human hands, v) wheels or mudguards of animal transport vehicles, and vi) CDV-contaminated equipment. The biological pathways and sub-equations for transmission through tigers, other wild or domestic animals, human hands, animal transport vehicles, and equipment are presented in S2–S5 Figs inS1 File.\n\nTo estimate the annual probabilities of CDV introduction to captive tigers within Thailand’s DNP captive wildlife stations through animal infections and fomite contaminations, six quantitative stochastic risk assessment models were developed. Each probability of entry (PRi) of six pathways through which CDV can infect or contaminate from the outer to destined wildlife stations annually was modeled as the products of various conditional probabilities as follows:\n\nPRireferred to the probability that CDV use the entry pathway to wildlife stations from the outside for each introduction pathway. It represented six scenario trees of the entry pathway probabilities through i) CDV-infected tigers (PRt), ii) other CDV-infected wild animals (PRa), iii) domestic dog or cat reservoirs (PRd), iv) contaminated human hands (PRh), v) contaminated animal transport vehicles (PRv), and vi) contaminated equipment (PRe).Rirepresents at-risk entry sub-pathways, andNjrepresents non risk entry sub-pathways (S2–S5 Figs inS1 File).PiandPjwere the probabilities of each node in all entry pathways (S6 Tables inS1 File). Each probability of entry pathway (PRi) was estimated, and all six entry pathways were combined to quantify the risks of having all entry pathways of CDV infection and contamination pathways annually at the final step.\n\nThe aforementioned model was subjected to sensitivity analysis using Spearman’s rank correlation to assess the effect of uncertainty on the model and identify the most influential parameters. The correlation coefficients (ρs) between each entry pathway and the final entry probability of CDV introductions to captive tigers were calculated. A tornado graph was used to rank all inputs according to their contributions to the variance of the output. Sensitivity analysis can also help identify appropriate interventions to reduce CDV infection risk.\n\nAfter identifying the entry pathway with the most significant effect on the final probability, interventions to reduce the overall risk can be determined. Feasible interventions were incorporated into the biological pathways to assess the reduction in entry risk probabilities. By implementing these interventions and noting the reduction in CDV infection risk, efforts to minimize the risk effectively can be prioritized. The probability of entry with interventions (PRj) for CDV infection or external contamination to tigers in wildlife stations was modeled as follows:\n\nThe following are the probabilities of CDV introduction to captive tigers in wildlife stations with integrated risk-mitigated interventions (PRj) via six scenarios:PRt,PRa,PRd,PRh,PRv, andPRe.PRjrrepresented the routine intervention practices, andPRjfdescribed 100% or implementations of all interventions. The interventions implemented in all scenarios were as follows: i) screening or reverse-transcription polymerase chain reaction (RT-PCR) tests from feces, sick tiger isolation and treatment, and CDV vaccine efficacy and coverage (PRtrandPRtf) for the probability of entry via CDV-infected tigers; ii) screening or RT-PCR tests from feces, sick animals isolation and treatment, CDV vaccine efficacy, and coverage for the probability of entry via other CDV-infected wild animals (PRarandPRaf); iii) preventing dogs or cats from entering near tiger cages for the probability of entry via domestic dog or cat reservoirs (PRdrandPRdf); iv) thorough hand washing for the probability of entry via contaminated human hands (PRhrandPRhf); v) effective disinfection for the probability of entry via contaminated animal transport vehicles (PRvrandPRvf); and vi) not sharing equipment between animal cages for probability of entry via contaminated equipment (PRerandPRef).RIirepresents at-risk entry sub-pathway with interventions, andNIjrepresents a non-risk one with interventions (S2–S5 Figs inS1 File).PIiandPIjindicated the probabilities in each node in all entry pathways with the implementation of integrated risk-mitigated interventions (S6 Tables inS1 File). Regarding vaccination, the term “efficacy” refers to the reduction rate in disease incidence among vaccinated individuals compared with unvaccinated individuals, calculated as follows: VE =  ((ARU-ARV)/ARU) *  100, where ARU is the attack rate in the unvaccinated population, and ARV is the attack rate in the vaccinated population [19]. “Coverage” refers to the proportion of the target population that has been vaccinated. In this study, vaccine coverage was calculated based on questionnaire data collected from wildlife stations, detailing the number of vaccinated tigers and other wildlife species.\n\nThe relative risk reduction of the risk probability in each entry pathway (ΔPR) was calculated by the risk probabilities with (PRj) and without (PRi) interventions using the following formula:\n\nThe effect of implementing a single intervention on the probability of CDV entry to captive tigers in each pathway was also analyzed. The input probabilities of CDV entry pathways with interventions varied from 0% to 100%, and the output risk probabilities of CDV entry were recorded in each scenario.\n\nMany patterns of the risk-mitigated interventions were assessed for risk reductions on entry routes I and II. The interventions of sick tiger isolation and treatment (PRtiso), CDV tests performed at original stations (PRttor), destined stations (PRttst), and both original and destined wildlife stations (PRttos) and effective vaccinations (PRtvac) were added in the risk probability of entry of the tiger (PRt). The interventions for isolating and treating other sick wild animals (PRaiso); performing CDV tests at original stations (PRator), destined stations (PRatst), and both original and destined wildlife stations (PRatos); and giving effective vaccinations (PRavac) were added in the risk probability of entry of other wild animals (PRa).\n\nInformation on captive tigers and other wild animals infected with CDV annually was derived from questionnaires and the health and husbandry records of DNP wildlife stations, which were integrated with the laboratory database of the Monitoring and Surveillance Center for Zoonotic Diseases in Wildlife and Exotic Animals of Mahidol University. Information on dog or cat reservoirs, contaminations through human hands, wheels or mudguards of animal transport vehicles, and equipment was derived from questionnaires and literature reviews (S6 Tables inS1 File).\n\nThe risk probability in each entry node was assessed, six stochastic quantitative risk assessment models were calculated, and probabilities were combined to estimate the final risk probability of CDV introduction to captive tigers in Thailand’s wildlife stations, with and without interventions annually.PRfinwas the final entry probability of CDV introduction to captive tigers in wildlife stations without interventions.PRfinrreferred to the final entry probability of CDV introduction to captive tigers in wildlife stations with all routine interventions.PRfinfindicated the final entry probability of CDV introduction to captive tigers in wildlife stations with the implementation of all interventions (100%). The annual probabilities of CDV introduction from six entry pathways were independent events and were not mutually exclusive. Therefore, the combined probabilities of all CDV entry pathways with and without interventions were estimated as follows:\n\nThe relative risk reduction of the risk probabilities of all entry pathways, when integrated with all routine interventions (ΔPRfinr), was calculated by the risk probabilities with (PRfinr) and without (PRfin) routine interventions using the following formula:\n\nThe relative risk reduction of the risk probabilities of all entry pathways, when integrated with the implementation of all interventions (100%) (ΔPRfinf), was calculated by the risk probabilities with (PRfinf) and without (PRfin) the implementation of all interventions (100%) using the following formula:\n\nThis study obtained approval for ethical considerations involving human subjects from the Mahidol University - Central Institutional Review Board (COE No. MU-CIRB 2022/130.2308). In addition, permission was secured from the Department of National Parks, Wildlife, and Plant Conservation (DNP) to conduct research at captive wildlife stations in Thailand from 2022 to 2023.\n\nThe questionnaire interviews involved 25 respondents, including 3 veterinarians (12%), 4 wildlife station directors (16%), 15 tiger keepers (60%), and 3 other keepers of other susceptible wild animals (12%). All had over 1 year of work experience and aged < 30 (8%), 30-50 (76%), and > 50 years (16%). The male-to-female ratio was 4:1. Two stations had full-time veterinarians, and five had veterinary care consultants from regional veterinarians of DNP.\n\nFour out of seven wildlife stations are located near tiger habitats in the forest, and six are near the village (within 1-5 km). The wildlife stations obtained tigers and other wild animals from other DNP wildlife stations (100%) and other sources, e.g., confiscated wild animals from illegal trades or private collections, abandoned or injured wild animals (86%), and wild animals transported to other DNP wildlife stations (57%). Besides tigers, wildlife stations also contained species susceptible to CDV, i.e., wild cats (Asiatic golden cats,Catopuma temminckii; fishing cats,Prionailurus viverrinus; leopard cats,Prionailurus bengalensis; clouded leopards,Neofelis nebulosa; leopards,Panthera pardus; marbled cats,Pardofelis marmorata; and jungle cats,Felis chaus), wild dogs (Asiatic jackals,Canis aureus; and dholes,Cuon alpinus), civets (small Indian civet,Viverricula indica; large Indian civet,Viverra zibetha; large-spotted civet,Viverra megaspila; common palm civet,Paradoxurus hermaphroditus; and masked palm civet,Paguma larvata), binturongs (Arctictis binturong), bears (Asiatic black bear,Ursus thibetanus; Malayan sun bear,Helarctos malayanus), and monkeys (crab-eating macaque,Macaca fascicularis; pig-tailed macaque,Macaca nemestrina; rhesus macaque,Macaca mulatta; and stump-tailed macaque,Macaca arctoides). All wildlife stations allowed the entry of outsiders, and the respondents observed the presence of domestic dogs or cats around these wildlife stations.\n\nIn this study, the median probabilities of six entry pathways that can introduce CDV to captive wildlife stations without any interventions for risk mitigation were assessed (Fig 3). The pathway with the highest probability of introducing CDV was through CDV-contaminated human hands (PRh), with a median probability of 0.534 (range, 0.372-0.719, 5th-95thpercentiles). The second and third highest probabilities were not much different through CDV-contaminated equipment (PRe), with a median probability of 0.379 (range, 0.196-0.619, 5th-95thpercentiles), and CDV-infected wild animals (PRa), with a median probability of 0.376 (range, 0.181-0.622, 5th-95thpercentiles). Other pathways, in descending order of probability, were the entry of CDV-infected tigers (PRt) (median probability, 0.111; range, 0.070-0.164, 5th-95thpercentiles), entry of dog or cat reservoirs (PRd) (median probability, 0.045; range, 0.018-0.090, 5th-95thpercentiles), and entry of CDV-contaminated vehicles (PRv) (median probability, 0.005; range, 0.001-0.011, 5th-95thpercentiles), respectively. The probability estimations in each node of all entry pathways are shown in S7 Table inS1 File.\n\nBox plots of each probability of entry (PRt, CDV-infected tigers;PRa, other CDV-infected wild animals;PRd, dog or cat reservoirs of CDV;PRh, CDV-contaminated human hands;PRv, CDV-contaminated animal transport vehicles;PRe, CDV-contaminated equipment; andPRfin, final probability of entry without any interventions).\n\nBox plots of each probability of entry (PRt, CDV-infected tigers;PRa, other CDV-infected wild animals;PRd, dog or cat reservoirs of CDV;PRh, CDV-contaminated human hands;PRv, CDV-contaminated animal transport vehicles;PRe, CDV-contaminated equipment; andPRfin, final probability of entry without any interventions).\n\nhttps://doi.org/10.1371/journal.pone.0320657.g003\n\nThe tornado graph (Fig 4A) illustrates the results of the sensitivity analyses. The correlation coefficients were assessed using Spearman’s rank correlation. The most influential input for the final probability of CDV introduction to captive wildlife stations was the probability of entry via CDV-contaminated human hands (PRh), followed by other CDV-infected wild animals (PRa), CDV-contaminated equipment (PRe), and CDV-infected tigers (PRt). The entry pathway with the smallest effect on the final probability of CDV introduction to captive wildlife stations was the probability of dog or cat reservoirs (PRd) and CDV-contaminated animal transport vehicles (PRv). Most of the inputs demonstrated a positive correlation, and only CDV-contaminated animal transport vehicles exhibited a negative correlation, with p-values < 0.05. Therefore, interventions consistent with the sensitivity analysis were selected, which mitigated the risk probabilities of entry (Fig 4B).\n\n(4A) Tornado graph depicting the sensitivity analysis of CDV risk introduction through infections and contaminations without interventions. Spearman’s correlation coefficients ranked all input parameters according to their contributions to the output variance. (PRh, CDV-contaminated human hands;PRa, other CDV-infected wild animals;PRe, CDV-contaminated equipment;PRt, CDV-infected tigers;PRv, CDV-contaminated animal transport vehicles; andPRd, dog or cat reservoirs of CDV). (4B) Physical pathways of humans, animals, and fomites entering wildlife stations with the selected interventions.\n\n(4A) Tornado graph depicting the sensitivity analysis of CDV risk introduction through infections and contaminations without interventions. Spearman’s correlation coefficients ranked all input parameters according to their contributions to the output variance. (PRh, CDV-contaminated human hands;PRa, other CDV-infected wild animals;PRe, CDV-contaminated equipment;PRt, CDV-infected tigers;PRv, CDV-contaminated animal transport vehicles; andPRd, dog or cat reservoirs of CDV). (4B) Physical pathways of humans, animals, and fomites entering wildlife stations with the selected interventions.\n\nhttps://doi.org/10.1371/journal.pone.0320657.g004\n\nFig 5depicts the results of the effect of a single intervention on each scenario. The interventions were found to reduce the risk probabilities of each entry route in all pathways. The higher the percentage of interventions implemented, the higher the risk reductions. The implemented interventions were as follows: not allowing the entry of dogs or cats to wildlife stations, not sharing equipment between cages of tigers and other wild animals, performing CDV tests to tigers and other wild animals at both original and destined stations, hand washing, and disinfecting animal transport vehicles, which could relatively highly reduce the risk of entry in each pathway by 80-99%. Vaccinating animals without CDV testing slightly reduced the risk of entry in both tigers and other wild animals. Increasing CDV vaccine coverage in tigers and other wild animals reduced the risk more than increasing CDV vaccine efficacy.\n\n(a) Vaccine coverage and efficacy in other wild animals. (b) CDV tests in other wild animals. (c) Hand washing of contaminated human hands. (d) No sharing equipment between tiger and wild animal cages. (e) Vaccine coverage and efficacy in tigers. (f) CDV tests in tigers. (g) Dogs or cats not entering areas near tiger cages. (h) Animal transport vehicle disinfection.\n\n(a) Vaccine coverage and efficacy in other wild animals. (b) CDV tests in other wild animals. (c) Hand washing of contaminated human hands. (d) No sharing equipment between tiger and wild animal cages. (e) Vaccine coverage and efficacy in tigers. (f) CDV tests in tigers. (g) Dogs or cats not entering areas near tiger cages. (h) Animal transport vehicle disinfection.\n\nhttps://doi.org/10.1371/journal.pone.0320657.g005\n\nFig 6illustrates probabilities of entry and risk reductions when employing various patterns of risk-mitigated interventions in all six entry scenarios. InFig 6A, routine (yellow box plots) testing of tigers for CDV before entry reduced the infection risk more than testing at their destination (median probability of 0.097 from 0.104).Fig 6Bshows similar results for wild animals (median probability of 0.370 from 0.374). In both situations, the best way to minimize the risk is to perform CDV tests at the beginning and end of their transportation (0.091, tigers; 0.368, wild animals). Testing at the origin is crucial. Animals that are tested positive should not be transported. Follow-up testing at the destination offers additional benefits, particularly if the animal was asymptomatic or a carrier during transport. This two-staged testing approach significantly enhanced the ability to identify and manage CDV risks effectively. A combination of testing, isolating, treating infected animals, and vaccinating healthy ones at entry points effectively reduced CDV spread in tigers and other wild animals. These routine combined interventions mainly reduced the risk of CDV transmission compared with other intervention patterns:PRtrfor tigers (0.060, reduced risk by 45.98%) andPRarfor wild animals (0.262, reduced risk by 30.37%). After fully implementing (100%) (green box plot) all interventions in tigers (PRtf), the risk was reduced from 0.111 to 2.420e-03(97.81%) compared with the initial risk (PRt). Similarly, when the same interventions were implemented in other wild animals (PRaf), the risk was reduced from 0.376 to 0.009 (97.59%) (Fig 6Aand6B).\n\nThe red box plots indicate the conditions without interventions, yellow box plots with various patterns of routine interventions, and green box plots with 100% implementation of all interventions. (A) Entry probability through CDV-infected tigers. (B) Entry probability through other CDV-infected wild animals. (C) Entry probability through CDV-contaminated human hands and equipment. (D) Entry probability through dog or cat reservoirs and vehicles. (E) Final probability of CDV entry to wildlife stations.\n\nThe red box plots indicate the conditions without interventions, yellow box plots with various patterns of routine interventions, and green box plots with 100% implementation of all interventions. (A) Entry probability through CDV-infected tigers. (B) Entry probability through other CDV-infected wild animals. (C) Entry probability through CDV-contaminated human hands and equipment. (D) Entry probability through dog or cat reservoirs and vehicles. (E) Final probability of CDV entry to wildlife stations.\n\nhttps://doi.org/10.1371/journal.pone.0320657.g006\n\nThe risk reduction for contaminated human hands was achieved through routine thorough hand washing (PRhr), reducing the probability of CDV-contaminated human hands (PRh) from 0.534 to 0.169 (68.34%) (Fig 6C). When all humans in close contact with tigers thoroughly wash their hands (100%) (PRhf), the initial risk (PRh) decreased from 0.534 to 0.059, indicating a reduction of 88.96%. The risk of CDV-contaminated equipment (PRe) was reduced by 41.54% (from 0.379 to 0.222) when equipment was not shared between tiger and other wild animal cages in routine practice (PRer) and by 97.02% (from 0.379 to 0.011) when all equipment (100%) was not shared (PRef) (Fig 6C).\n\nInFig 6D, routine practice intervention reduced the risk associated with dog or cat reservoirs entering areas near tiger cages (PRdr) and wheels or mudguards of CDV-contaminated animal transport vehicles (PRvr), resulting in reductions of 66.88% (from 0.045 to 0.015) and 41.85% (from 0.005 to 0.003), respectively. When the entry of dog or cat reservoirs is avoided 100% (PRdf) and 100% of vehicles are disinfected (PRvf), the risk reduction rate is 99.42% (from 0.045 to 2.622e-04) and 84.25% (from 0.005 to 7.957e-04), respectively.\n\nAs shown inFig 6E, the final probability of entry of CDV introduction to the tigers in captive wildlife stations through animal infections and fomite contaminations, without any interventions (PRfin), was calculated from the entry probabilities of six pathways (PRi) inFig 3, with a median probability of 0.858 (range, 0.716-0.950, 5th-95thpercentiles). When utilizing routine or regular interventions, the final probability of entry of CDV introduction to the tigers in captive wildlife stations through animal infections and fomite contaminations (PRfinr) was indicated by a median probability of 0.578 (range, 0.416-0.746, 5th-95thpercentiles). When implementing all integrated interventions (100%) in six scenarios, the final probability of CDV introduction to tigers in captive wildlife stations through animal infections and fomite contaminations (PRfinf) was reduced, with a median probability of 0.089 (range, 0.053-0.154, 5th-95thpercentiles). Implementing routine practices for all interventions at entry points will result in a 32.60% reduction (ΔPRfinr) in the risk of CDV entering a wildlife station. Fully implementing a comprehensive set of all interventions at entry points will result in an 89.57% reduction (ΔPRfinf) in the risk of CDV entering a wildlife station.\n\nThe risks were reduced when routine practice and 100% implementation of all risk-mitigated interventions were employed (S8 Fig inS1 File). The probabilities of risks were compared between the entry pathways of implementing routine interventions in wildlife stations (yellow histogram), 100% of all interventions implemented (green histogram), and without any interventions (red histogram).\n\nThe entry of CDV-contaminated human hands poses the highest risk probability to captive tigers. Hand contamination can occur through direct contact with CDV-infected tigers, dog or cat reservoirs, contaminated equipment, or contaminated animal transport vehicles. Human hands can serve as contaminated fomites that transmit the virus by contact with body fluids and feces [20]. Routine thorough hand washing is important for preventing the spread of germs and can reduce the risk of CDV contamination by 68.34%. Washing hands thoroughly can reduce the risk of CDV contamination by 88.96%. This value is consistent with the results of a study reporting that 80% of germs can be transferred to hands during contact and can potentially contaminate objects or surfaces [21]. The use of plain or antiseptic soap effectively eliminates germs; even the use of plain soap and water alone can reduce bacteria by up to 92% [22–25]. Handwashing with soap and water or using alcohol-based hand rubs reduces the number of H1N1 virus particles to levels undetectable in cultures and approximately 100 virus copies/mL in PCR tests, achieving a reduction rate of > 99.99% in virus particles on hands [26]. H1N1 and CDV are negative-sense RNA viruses that share structural similarities, including lipid envelopes and surface proteins that are essential for entering host cells. They also have similar modes of transmission, including respiratory droplets, direct contact, and fomites [26]. These similarities make them highly susceptible to disinfectants that target lipid envelopes, such as soap. Hand-washing facilities at farm entry and exit points reduced the likelihood of CDV outbreaks on Danish mink farms in 2012-2013 [27]. Handwashing can reduce respiratory illness risk by 6%-44% and prevent viral transmission, such as the measles virus, which is similar to CDV [24,28]. Alcohol-based hand rubs with 60% alcohol content are effective for hand hygiene when hands are not visibly dirty [28]. Campaigns should target staff and visitors entering wildlife stations to promote handwashing with plain soap. In addition, disposable gloves should be worn when handling tigers.\n\nThe introduction of other CDV-infected wild animals exhibited the second highest risk of CDV entry to captive tigers. Sensitivity analysis revealed that this pathway is more than twice as likely to contribute to CDV entry compared with contaminated equipment. Various interventions have been implemented to mitigate this risk, including CDV testing, isolating and treating sick animals, and ensuring effective vaccination protocols. Stress during animal transportation between stations can suppress the immune system, potentially triggering latent diseases such as CDV infection [29]. Performing CDV tests before entry to wildlife stations significantly reduces this risk compared with testing after entry. However, the best practice is to perform CDV testing both before and after entry. In addition, sourcing protocols for animals from exporting stations should include ensuring the absence of distemper in terrestrial carnivores within the previous 12 months and enforcing a 1-month pre-export and post-arrival quarantine at the importing station [18]. These measures, combined with ongoing CDV testing, are effective in monitoring and minimizing disease transmission risks [30].\n\nThe entry of CDV-contaminated equipment poses the third highest risk to captive tigers. Sharing equipment, such as floor-cleaning brushes or transport cages, can lead to the spread of CDV through contaminated surfaces. Strict protocols should be followed to reduce this risk, including avoiding the sharing of equipment between tiger and wild animal enclosures. Implementing such measures has decreased the risk of CDV contamination by 97.02%. This precaution aligns with earlier CDV outbreaks in farmed rhesus monkeys, captive African wild dogs, and farmed civets, where contaminated equipment or human handlers were recognized as potential indirect contact pathways of transmission [31–33]. Strict biosecurity measures are essential to mitigate this risk and safeguard the health of captive tigers.\n\nThe entry probability of CDV-infected tigers is the fourth highest risk for captive tigers and has less effect on the final probability of entry, following contaminated human hands, other CDV-infected wild animals, and contaminated equipment. This lower probability of entry and effect may be due to the relatively low prevalence of CDV in the healthy tiger populations in Thailand. If a tiger is infected with CDV at its place of origin, it must be treated until fully recovered before transport, which is already routine practice in normal situations. Although it is considered a lower priority, the strategies for mitigating this risk aligned closely with those employed in managing the entry of other CDV-infected wild animals. These strategies include performing CDV tests before and after entry, isolating and treating infected tigers, and administering effective vaccines. Quarantine at the importing station is crucial to mitigate the spread of CDV, a complex disease that affects large felines, often causing neurological symptoms and death. Clinical outcomes in infected tigers vary depending on their age and immune status, ranging from full recovery to persistent disease or fatality [34]. Isolating and treating symptomatic animals can significantly reduce CDV transmission risk [5,35,36]. Additionally, post-recovery viral shedding in dogs, which can occur in urine for 60–90 days [2,37] and in other secretions for up to 120 days, highlights the importance of extended quarantine and monitoring for complete resolution of the infection [38].\n\nImplementing routine CDV vaccination if no CDV tests were performed in tigers and other wild animals slightly reduced the risk of entry. In contrast, routine CDV vaccination with previous CDV tests resulted in higher risk reduction. Moreover, CDV tests and isolation and treatment of sick animals resulted in higher risk reduction than CDV testing with vaccination. These are attributed to the low efficacy and coverage of vaccines routinely used in wildlife stations. The vaccine efficacy was 20% in tigers compared with 88% in civets or other wild animals, and the vaccine coverage was 7% in tigers and 0% in other wild animals used in the models. Vaccine coverage is low because it is currently part of a trial aimed at determining whether the antibody titer can provide protection against CDV infection in tigers. Conversely, achieving 99% CDV vaccine efficacy and coverage in tigers and other wild animals, alongside previous CDV testing and isolation and treatment of sick animals, led to the highest risk reduction. In Thailand, tigers received recombinant CDV vaccines [5]. Recombinant vaccines are considered safer because they employ a canarypox vector to deliver antigens; however, multiple doses may be needed to establish lifelong immunity because they induce weaker immune responses [16]. Compared with recombinant vaccines, modified live or live-attenuated vaccines utilize either canine or avian kidney cell lines and elicit a significantly higher and extended humoral immune response [6]. However, vaccination with attenuated CDV strains was associated with an increased risk of post-vaccination CDV infection in untested species, highlighting the importance of thorough safety evaluations before administration [16,39]. Implementing test-based surveillance for infections in animals is a crucial strategy to minimize these risks. To ensure herd immunity, a percentage of the population must be vaccinated, which typically ranges from 60% to 90%; these figures are influenced by various population-specific factors [40–41]. The following factors must be considered in tiger or other wild animal vaccinations: population density, tigers’ distance from other wild animals, prevalence of CDV infection, and host susceptibility. Vaccine efficacy is affected by the infectious properties of the pathogen, vaccine type, dose, administration route, host-specific factors (age, genetics, and immune health), and degree of similarity between the vaccine and the current circulating virus [30,42]. The most effective approach for preventing CDV transmission between domestic dogs and wild animals is to regularly vaccinate dogs and limit their contact with wild animals [34].\n\nThe entry of dog or cat reservoirs into wildlife stations poses a low risk of introducing CDV to captive tigers. This concern is heightened by the CDV situation in nearby villages. Wildlife stations close to these villages often have high populations of domestic dogs, which can exacerbate the virus spread. Increased domestic dog populations correlate with the likelihood of CDV transmission. Domestic dogs serve as the main reservoirs of CDV among wild animals, contributing to a decline in wild carnivore populations worldwide [1,43]. Implementing mass vaccination programs for dog populations near wildlife areas is recommended [1,44]. However, studies conducted in Africa have indicated that dog populations adjacent to wildlife areas may be inadequate to sustain the virus [1,45]. The ability of species to act as reservoirs depends on susceptibility, population size, turnover, and interaction frequency [16]. Although cats can become infected, they are generally asymptomatic. The virus spreads from dogs to cats but not vice versa or among cats [46]. In addition, no substantial evidence supports that CDV can be transmitted from cats to other animal species or wild animals. To restrict the entry of dogs and cats into wildlife stations and near tiger cages (within 6 m of aerosol transmission) [47], restrictions can be enforced, such as installing fencing, banning visitors from bringing pets, and relocating waste ponds away from the housing areas of wild animals.\n\nAlthough the risk of entry of CDV-contaminated animal transport vehicles was very low to negligible, it still poses a risk. The duration of transportation is determined by distance. CDV can survive for extended periods at lower temperatures, such as up to 14 days at 5°C and 48 h at 25°C [20,48]. In a CDV culture study, the virus remained viable for up to 125 min at 25°C, but died faster at higher temperatures, lasting only 75 min at 35°C and 65 min at 37°C [25]. In Thailand, where temperatures fluctuate between 28 and 33°C in cooler months and between 30 and 37°C in the summer [49], the virus may survive during animal transport between nearby wildlife stations, which typically takes 1-2 h. The negative correlation between the entry of animal transport vehicles and the overall probability of CDV entry may stem from the fact that the distance over which animals are transported is inversely related to the ability of the virus to survive. However, factors such as heat, dry conditions, and disinfectants can effectively inactivate CDV [36]. Therefore, appropriate disinfection of animal transport vehicles is essential.\n\nLastly, the overall probability of CDV entry was calculated by integrating six scenarios. When no standard procedures or risk-mitigated interventions were implemented, the probability of CDV entry was relatively high. However, implementing all interventions across all pathways significantly reduced the risk of CDV entry and is recommended as a standard practice.\n\nIn addition, wildlife stations are situated near forests that are natural habitats of wild tigers and are mostly protected areas, including the Western Forest Complex, Kaeng Krachan Forest Complex, and the Eastern Forest [50]. This proximity poses a potential risk for the spread of CDV into the wild. Furthermore, the endangered Amur tiger faces extinction because of CDV infection [51]. Past CDV outbreaks have devastated various wildlife species, including silver-backed jackals (Canis mesomelas), bat-eared foxes (Otocyon megalotis), African wild dogs (Lycaon pictus), and Tanzania’s lion (Panthera leo) in East Africa [52]. The presence of numerous susceptible species, disease reservoirs, and dense populations increases the risk of CDV transmission among nearby species.\n\nOur processes are applicable to situations such as in our study setting. Conceptual and biological pathways must be reassessed for wildlife stations with varying animal husbandry and management practices. Nevertheless, this study has some potential limitations. For example, data’s uncertainty may be caused by overestimating disease probabilities during all introductions. Specifically, the hand transmission rate of CDV was overestimated because of insufficient data regarding virus survival and transmission rate via hands. Conducting observational studies and research on mathematical models can help estimate relevant factors and unknown parameters, such as the probability of transmission, recovery, number of reservoirs, and vectors. In this study, the information was cross-checked with wildlife station records and animal test laboratory data to minimize recall bias of past events or behaviors during questionnaire interviews.\n\nIn this study, the risk assessment models have identified critical points that need attention for captive wildlife conservation. We recommend implementing biosecurity measures, performing screening tests, providing appropriate vaccinations, and restricting human and animal movements into wildlife stations to prevent CDV outbreaks. Wildlife stations can utilize the results of quantitative risk assessments to improve their management and biosecurity protocols. Conducting an annual risk assessment is essential to monitor improvements in risk reductions and guide effective management practices. The health and well-being of tigers are crucial in species preservation and maintenance of ecological balance, whether they are in captivity or the wild.\n\nS1 Table 1. Captive tiger population number in Department of National Parks wildlife stations in 2021. S2 Figs 3A. Scenario trees depicting the biological pathways of CDV introductions into captive wildlife stations through infected tigers with and without interventions.(3A) Scenario tree without any interventions. (3.1A) With the intervention of isolation and treatment of sick tigers. (3.2.1A) With CDV testing at the place of origin. (3.2.2A) With CDV testing at the destined wildlife station. (3.2.3A) With CDV testing in both original and destined stations. (3.3A) With CDV vaccinations. (3.4A) With all combined interventions. (3.5A) With CDV testing in both stations and vaccinations. (3.6A) With CDV testing in both stations and isolation and treatment of sick tigers. (3.7A) With isolation and treatment of sick tigers and vaccinations.S3 Figs 3B. Scenario trees depicting the biological pathways of CDV introductions into captive wildlife stations through other infected wild animals with and without interventions.(3B) Scenario tree without any interventions. (3.1B) With isolation and treatment of sick wild animals. (3.2.1B) With CDV testing at the place of origin. (3.2.2B) With CDV testing at the destined wildlife station. (3.2.3B) With CDV testing in both original and destined stations. (3.3B) With CDV vaccinations. (3.4B) With all interventions. (3.5B) With CDV testing in both stations and vaccinations. (3.6B) With CDV testing in both stations and isolation and treatment of sick wild animals. (3.7B) With isolation and treatment of sick wild animals and vaccinations.S4 Figs 3C. Scenario tree depicting the biological pathway of CDV introductions into captive wildlife stations through dog or cat reservoirs with and without interventions.(3C) Scenario tree without interventions. (3.1C) With intervention of not allowing dogs or cats enter areas near tiger cages.S5 Figs 3D-3F. Scenario trees depicting the biological pathways of CDV introductions into captive wildlife stations through contaminations of human hands, wheels or mudguards of animal transport vehicles, and equipment.(3D) Scenario tree via contaminated human hands without interventions. (3.1D) With the intervention of thorough hand washing. (3E) Scenario tree via contaminated wheels or mudguards of animal transport vehicles without intervention. (3.1E) With the intervention of effective disinfection of vehicles. (3F) Scenario tree via contaminated equipment without intervention. (3.1F) With the intervention of not sharing equipment between tiger and other wild animal cages.S6 Tables 2-4. Description of input parameters and probabilities utilized in the quantitative stochastic models for the entry assessment of the risk of CDV introduction into wildlife stations through tiger and other wild animal infections (Tables 2 and 3), dog or cat reservoirs, and contaminated hands, animal transport vehicles, and equipment (Table 4). S7 Table 5. Probability estimations in each node of all six entry pathways (number of iterations = 1,000). S8 Fig 7. Histograms showing risk reductions using interventions in different risk pathways.The left red histograms show the condition without interventions, middle yellow histograms with routine interventions, and right green histograms with the implementation of all interventions (100%). Entry probabilities through (7a) CDV-infected tigers, (7b) CDV-infected wild animals, (7c) dog or cat reservoirs, (7d) CDV-contaminated human hands, (7e) CDV-contaminated animal transport vehicles, and (7f) CDV-contaminated equipment and (7g) final entry probabilities through all animal infection and fomite contamination routes.S9. Questionnaires for interviews.Questionnaire number 1 (QN1) was used for interviewing directors or veterinarians of wildlife stations. Questionnaire number 2 (QN2) was used for interviewing animal keepers of wildlife stations.\n\nhttps://doi.org/10.1371/journal.pone.0320657.s001\n\n(PDF)\n\nWe thank the Department of National Parks, Wildlife and Plant Conservation, Ministry of Natural Resources and Environment, Thailand, for allowing us to conduct research within their areas and providing the necessary information concerning both captive and non-captive tigers. We thank the Monitoring and Surveillance Center for Zoonotic Diseases in Wildlife and Exotic Animals, Faculty of Veterinary Science, Mahidol University, Thailand, for providing the laboratory data on CDV in tigers and other wild animals and necessary information on CDV outbreak among captive tigers and allowing our study to proceed. We are grateful to the contributors for their kind cooperation during our questionnaire interviews and conducting the qualitative pathway assessment.",
    "category": "immunology"
  },
  {
    "title": "Variations in de novo donor-specific antibody development among HLA-DQ mismatches in kidney transplant recipients",
    "authors": "Peenida Skulratanasak, Thidarat Luxsananun, Nuttasith Larpparisuth, Nalinee Premasathian, Attapong Vongwiwatana, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321629",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321629",
    "content": "HLA-DQ antibodies are the most prevalent de novo donor-specific antibodies (dnDSAs) after kidney transplantation (KT). The immunogenicity and impact of each HLA-DQ mismatch on graft outcomes can vary considerably.\n\nThis retrospective cohort study investigated the prevalence and risk factors for dnDSA development in patients who underwent KT at Siriraj Hospital between 2006 and 2020 and had HLA-DQB1 mismatches. Our center employed a protocol for post-KT dnDSA surveillance. The impact of dnDSAs on late rejection and graft survival was evaluated.\n\nIn our cohort of 491 KT recipients, 59 (12.02%) developed dnDSAs to HLA-DQB1 at a median time of 4.2 years after KT. The risk of dnDSA occurrence was significantly higher among recipients with HLA-DQ7 mismatch (HR: 2.8; 95% CI: 1.21–6.52;P= 0.017) and HLA-DQ9 mismatch (HR: 2.63; 95% CI: 1.11–6.27;P= 0.028). Recipients who developed dnDSAs were younger (P= 0.009), had higher rates of medication nonadherence (P= 0.031), had pre-KT panel reactive antibody levels above 20% (P= 0.044), and received non-tacrolimus immunosuppression (P< 0.001) compared to those without. Recipients who developed dnDSAs to HLA-DQ exhibited a significantly higher incidence of late graft rejection (HR: 7.76; 95% CI: 5–12.03;P< 0.0001) and inferior death-censored graft survival than those without dnDSAs (log rankP< 0.001).\n\nThe patients with HLA-DQ7 and HLA-DQ9 mismatches exhibit the highest risk of developing dnDSAs. Individualized immunosuppression adjustment and kidney allocation based on specific HLA-DQ mismatch may enhance long-term graft survival.\n\nCitation:Skulratanasak P, Luxsananun T, Larpparisuth N, Premasathian N, Vongwiwatana A (2025) Variations in de novo donor-specific antibody development among HLA-DQ mismatches in kidney transplant recipients. PLoS ONE 20(4):\n           e0321629.\n        \n        https://doi.org/10.1371/journal.pone.0321629\n\nEditor:Paolo Fiorina, Children's Hospital Boston, UNITED STATES OF AMERICA\n\nReceived:May 31, 2024;Accepted:March 10, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Skulratanasak et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript. The datasets that support the findings of this study are attached along with manuscript.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nKidney transplantation (KT) offers superior survival and quality of life to other kidney replacement therapies. However, antibody-mediated rejection (AMR) remains a primary cause of late allograft failure, even with advancements in immunosuppressive therapy. KT recipients who are medication nonadherent or underimmunosuppressed may be at higher risk of developing de novo donor-specific antibodies (dnDSAs) and subsequent late AMR, particularly in cases of high numbers of human leukocyte antigen (HLA) mismatches (MM) [1]. Greater compatibility of HLA between donors and recipients is associated with better outcomes in KT.\n\nThe most prevalent type of dnDSA detected in cases of late AMR is the anti-HLA-DQB1 antibody. The presence of dnDSAs targeting HLA-DQB1 is associated with the lowest graft survival compared to other types of dnDSA [2,3]. Several studies have reported a significant increase in the risk of graft loss for both living and deceased donor KTs with HLA-DQ MM [4,5]. Moreover, numerous studies have demonstrated a strong association between HLA-DQ MMs and late AMR, leading to subsequently graft failure [5–7]. These findings underscore the high immunogenicity of HLA-DQ over the long term. However, it is noteworthy that most countries do not include HLA-DQ MM in their kidney allocation systems.\n\nPrevious studies investigating the influence of HLA/epitope MM on transplant outcomes have predominantly focused on the number of MM. However, each HLA-DQ has demonstrated varying immunogenicity in triggering antibody production and subsequent long-term graft outcomes. A study on heart and lung transplant recipients in Canada found that the epitope MM identified in donor HLA-DQB1*02/HLA-DQB1*03:01 was associated with a higher risk of dnDSA development [8]. We observed an increased frequency of dnDSA against certain HLA-DQ MM compared to others in our center, which has conducted posttransplant dnDSA surveillance for an extended period. Nevertheless, the immunogenic differences among HLA-DQ MMs in KT recipients still require full understanding. Therefore, we conducted this study to identify the specific HLA-DQ MMs associated with dnDSA occurrence and their impact on graft survival. Understanding the differing immunoreactivities among HLA-DQB MM could assist in developing individualized immunosuppression and DSA monitoring for KT recipients.\n\nA retrospective cohort study was conducted among adult patients who underwent KT at our center between January 2006 and December 2020. We included recipients with at least one HLA-DQB1 MM. Patients were excluded if they underwent repeat KT, combined transplantation, had pretransplant donor-specific antibodies, experienced primary allograft failure, or lacked post-transplantation data on HLA antibody results. The study was approved by the Ethics Committee of the Faculty of Medicine Siriraj Hospital, Mahidol University, Bangkok, Thailand (COA No. Si 791/2021), with a waiver of informed consent. The study was performed in accordance with international guidelines for human research protection. Patient identifiers were used for data collection but then de-identified after completion of the collection.\n\nData were obtained from our institutional database and included baseline demographic information, donor profiles, donor and recipient HLA typing, immunosuppressive regimens, self-reported medical nonadherence, development of dnDSAs, and episodes of graft rejections. The database was accessed between November 15, 2021 and March 15, 2022. Depending on the immunologic risk, induction with basiliximab or antithymocyte globulin was prescribed. However, prior to 2012, most patients did not receive antibody induction due to reimbursement limitations. The initial immunosuppressive regimen at our center consisted of mycophenolic acid, prednisolone, and either cyclosporine or tacrolimus during the earlier period, with tacrolimus becoming the standard during the later phase. Calcineurin inhibitors (CNI) or mycophenolate mofetil were substituted with mTOR inhibitors in cases of infections (e.g., BK viruria/viremia, persistent CMV viremia, or mycobacterial infections), CNI nephrotoxicity, or malignancy. Changes to immunosuppressive regimens were made based on the clinical judgment of the treating physician.\n\nIn our center, HLA typing was assessed using intermediate-resolution molecular methods before 2014 and high-resolution typing thereafter. We conducted surveillance for dnDSA at 6 months and 1 year after KT and annually thereafter. HLA antibodies were evaluated using the solid-phase method with a Luminex microbead assay (One Lambda Inc, Canoga Park, CA, USA). The presence of dnDSAs was determined at the antigen level and confirmed using the Luminex LABScreen single antigen method with a mean fluorescence intensity (MFI) cutoff of 1000. The maximal MFI was determined from the bead with the highest MFI in cases where multiple beads for the same antigen were positive. While protocol biopsy is not part of our routine practice, allograft biopsies were performed in KT recipients who experienced unexplained increases in serum creatinine from baseline, persistent proteinuria, or persistently elevated MFI of dnDSA > 5,000 despite adjustments to immunosuppression. Diagnosis of AMR was determined by reviewing pathological scores, DSA results, and C4d staining in accordance with the Banff classification 2019 criteria [9].\n\nThe primary outcome was to compare the prevalence of dnDSAs against each HLA-DQ. We defined HLA antibodies as dnDSAs if no such antibodies were detected during the pretransplant or early post-KT period (< 6 months). The prevalence of dnDSAs against each HLA-DQ was determined based on the number of MM. In cases where patients had duplicate DQ MM (e.g., both donor HLA-DQ antigens are DQ5, which mismatches the recipient), such MM were counted as a single dnDSA. The risk factors for dnDSA development and transplant outcomes of KT recipients with dnDSAs against HLA-DQ, including late rejection and allograft failure, were also of interest. Transplant outcomes were assessed at the end of December 2021.\n\nBaseline characteristics are presented as percentages (%), numbers and percentages, or means ± standard deviations for normally distributed data and as medians and interquartile ranges (IQRs) for nonnormally distributed data. Enumerated variables were compared using Chi-squared or Fisher’s exact tests, while continuous variables were compared using one-way ANOVA or Kruskal–Wallis H tests, depending on the data distribution. Two-tailed probability (P) values < 0.05 were considered statistically significant.\n\nCox proportional-hazard regression analyses adjusted for mode of KT, donor age, sex, HLA antigen, diabetes, hypertension, death from cerebrovascular accident (CVA), recipient age, sex, diabetes, duration of dialysis, panel reactive antibody (PRA), recipient HLA antigen, other HLA MM, cold ischemic time, and induction and maintenance immunosuppression, were employed to identify factors associated with dnDSA development. Additionally, a Cox model was applied to assess graft outcomes, incorporating the same covariates along with the presence of anti-DQ DSA and class I DSA. The results are reported as hazard ratios (HRs) with 95% confidence intervals. Kaplan–Meier analysis was used to compare the probability of allograft failure after KT. All statistical analyses were performed using IBM SPSS Statistics for Windows, version 21.0 (IBM Corp, Armonk, NY, USA).\n\nOut of 978 adult patients who underwent KT between January 2006 and December 2020, 451 recipients had no HLA-DQB1 MM. Among the eligible 527 recipients, 17 were excluded due to repeated KT, 13 due to the presence of preformed donor-specific antibodies, 4 due to combined transplantation, and 2 due to primary allograft failure. Consequently, the analysis encompassed 491 KT recipients with a median follow-up period of 6.35 years (IQR: 3.54–10.22) (Figure 1). All KT had negative complement-dependent cytotoxicity (CDC) and antihuman globulin (AHG) crossmatches. Virtual crossmatch was also performed in patients with high PRA levels, most of whom had single antigen bead testing results. All KT had negative complement dependent cytotoxicity (CDC), antihuman globulin (AHG) and virtual crossmatch. Among them, 75 recipients had 2 HLA-DQB1 MM, bringing the total number of DQB1 MM in this study to 566. Details of the distribution of HLA-DQB1 MM are provided inS1 Table. The mean age of recipients was 41.3 ± 12 years, and 295 patients (60.1%) were male. The majority (96.1%) had pre-transplant PRA levels of < 20%.Table 1details the baseline characteristics of the enrolled patients stratified by the presence of dnDSAs to HLA-DQB1, irrespective of the development of HLA-nonDQ antibodies. The presence of dnDSAs against HLA-DQB1 was detected in 59 patients (12%) at a median of 4.23 years (IQR: 1.97–5.56) after KT. The mean MFI of the first maximum dnDSA was 9,274 ± 6,405. The incidence of HLA-DQ DSA development was 11.1% and 17.3% in patients with single and double MM, respectively. When compared to patients without anti-DQ dnDSAs, recipients with anti-DQ dnDSAs were significantly younger (35.1 ± 13 vs 42.14 ± 12 years;P< 0.001), had PRA class II levels ≥ 20% (10.16% vs 3%;P= 0.01), received living donor KT (61% vs 47%;P= 0.04), had a lower incidence of delayed graft function (27.1% vs 41.9%;P= 0.03), did not receive tacrolimus-based immunosuppression either immediately after KT (55.9% vs 79.6%;P< 0.001) or at the time of dnDSA detection (45.8% vs 78.7%;P< 0.001) and were more medication nonadherent (6.8% vs 1.9%;P= 0.04). There was no significant difference in the prevalence of HLA-nonDQ antibody between the presence and absence of anti-DQ antibody.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321629.t001\n\nKT = kidney transplantation.\n\nKT = kidney transplantation.\n\nhttps://doi.org/10.1371/journal.pone.0321629.g001\n\nRisk factors for developing dnDSAs against HLA-DQ were determined using Cox proportional hazard model. Univariate analysis revealed significant risk factors, including recipient age under 35 years (HR 3.06; 95%CI 1.34–6.99;p= 0.008), pre-transplant PRA class II levels of 20% or higher (HR 2.58; 95%CI 1.11–6.01;p= 0.028), non-tacrolimus-based immunosuppression early after KT (HR 1.79; 95%CI 1.06–3.03;p= 0.03) and at the time of dnDSA detection (HR 1.83; 95%CI 1.42–2.37;p= < 0.001), and medication nonadherence (HR 2.99; 95%CI 1.08–8.25;p= 0.034).\n\nIn the multivariate analysis adjusted for crucial factors, recipient age under 35 years (HR 3.16; 95% CI 1.33–7.52;p= 0.009), pre-transplant PRA levels of 20% or higher (HR 2.51; 95% CI 1.03–6.18;p= 0.044), non-tacrolimus-based immunosuppression at the time of dnDSA detection (HR 3.47; 95% CI 1.93–6.25; p < 0.001), and medication nonadherence (HR 3.32; 95% CI 1.12–9.91;p= 0.031) were significantly associated with the development of dnDSAs against HLA-DQ posttransplantation. The statistical results are detailed inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321629.t002\n\nIn overall cohort, the most common specific anti-DQ dnDSA was against HLA-DQ7 (23%), followed by HLA-DQ5 (22%) and HLA-DQ9 (17%) (Fig 2A). The prevalence of dnDSA development per each HLA-DQB1 MM was 11.31% (64/566 MM). The highest prevalence of anti-DQ dnDSA per MM was found in patients who had HLA-DQ7 MM (17.44%), followed by HLA-DQ9 (16.92%) and HLA-DQ2 MMs (14.28%). In contrast, the lowest prevalence was revealed in patients who had HLA-DQ6 MM (5.43%) (Fig 2B).\n\nA) Type of HLA-DQ dnDSAs found in overall cohort, B) The prevalence of dnDSAs occurrence per each HLA-DQ mismatch in Thai kidney transplant population.\n\nA) Type of HLA-DQ dnDSAs found in overall cohort, B) The prevalence of dnDSAs occurrence per each HLA-DQ mismatch in Thai kidney transplant population.\n\nhttps://doi.org/10.1371/journal.pone.0321629.g002\n\nAmong the 15 patients who developed an HLA-DQ7 dnDSA, 7 also exhibited an HLA-DQ7 MM along with another DQ antigen MM. Within this group of 7 patients, 5 presented an obligatory HLA-DQ7 antibody without dnDSAs to another DQ antigen (2 DQ2, 1 DQ8, 1 DQ5, and 1 DQ6), while only 2 patients had dnDSAs to both DQ7 and another antigen (1 DQ6 and 1 DQ8). In contrast, only 3 out of 70 patients with an obligatory DQ-6 MM developed HLA-DQ6 dnDSA. Out of the 23 patients with an HLA-DQ6 MM along with another DQ antigen MM, 2 developed dnDSAs to DQ6, while 2 had dnDSA occurrences to another DQ (1 DQ7, 1 DQ5) without anti-DQ6 antibody.\n\nWe further investigated the association between specific HLA-DQB1 MM and dnDSA development post-KT. Kaplan–Meier analysis revealed that recipients carrying HLA-DQ7 MM had a higher chance of dnDSA occurrence compared to those with HLA-DQ5 (log-rank p = 0.017) and HLA-DQ6 (log-rank p = 0.005), respectively. Recipients with HLA-DQ9 MM faced a significantly higher risk of dnDSA development than those with HLA-DQ6 (log-rank p = 0.026). No statistically significant differences were observed in other DQ antigen comparisons (Fig. 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321629.g003\n\nThe adjusted Cox model demonstrated that recipients with HLA-DQ7 MM had the highest risk of dnDSA formation (HR: 2.80; 95% CI: 1.21–6.52;p= 0.017), followed independently by those with HLA-DQ9 MM (HR: 2.63; 95% CI: 1.11–6.27;p= 0.028) (Table 2). When specifically compared to recipients with HLA-DQ6 MM, those with HLA-DQ7 MM (HR: 3.67; 95% CI: 1.20–11.25;p= 0.023) and HLA-DQ9 MM (HR: 3.391; 95% CI: 1.08–10.65;p= 0.037) had a significantly higher risk of dnDSA occurrence. No statistically significant differences were observed in other pairwise comparisons of DQ MM.\n\nOf the 491 KT recipients included in the study, 139 underwent allograft biopsy more than 6 months after KT due to allograft dysfunction, presence of dnDSAs, or clinical suspicion of glomerulonephritis. Biopsy-proven late rejection was found in 72 patients. Late active or chronic active AMR was diagnosed in 69.5% of patients with HLA-DQ dnDSAs. Kaplan–Meier analysis revealed that recipients with dnDSAs to HLA-DQ had significantly inferior rejection-free survival compared to those without dnDSAs to HLA-DQ (HR: 7.76; 95% CI: 5.00–12.03;P< 0.0001;Fig 4A). While the 5-year death-censored graft survival was similar for recipients with and without dnDSAs (94.6% vs 93.8%,P= 0.452), the 10-year survival was significantly lower for recipients with dnDSAs to HLA-DQ than for those without dnDSAs (70.2% vs 87.8%;P= 0.001). Overall graft survival was also inferior in those who had dnDSA to HLA-DQ (log rankP< 0.001;Fig 4B). In an adjusted Cox proportional hazards model, the presence of dnDSAs to HLA-DQ remained significantly associated with overall graft failure (HR: 3.875, 95% CI: 2.12–7.07) (Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321629.t003\n\nA) Biopsy-proven acute or chronic-active rejection, B) Death-censored graft survival.\n\nA) Biopsy-proven acute or chronic-active rejection, B) Death-censored graft survival.\n\nhttps://doi.org/10.1371/journal.pone.0321629.g004\n\nAcross the entire cohort, 20 patients (4.1%) had isolated non-DQB1 DSAs without accompanying DQB1 DSAs. Kaplan-Meier analysis revealed no statistically significant difference in rejection-free survival between recipients with HLA-DQ dnDSAs and those with non-DQ DSAs (log-rank P = 0.111)S1 Fig. However, recipients with dnDSAs to HLA-DQ had significantly lower overall graft survival compared to those with non-DQ DSAs (log-rank P = 0.038)S2 Fig. Additionally, survival analysis showed no significant difference in graft survival between recipients with non-DQ DSAs and those without DSAs (log-rank P = 0.67)S3 Fig.\n\nOur study is the first to demonstrate varying immunogenicity among specific HLA-DQ MM in KT recipients. Patients with HLA-DQ7 and HLA-DQ9 MM are at the highest risk for dnDSA occurrence, while those with HLA-DQ6 MM have the lowest risk, even when adjusted for crucial transplant factors. Our findings regarding risk factors for HLA-DQ dnDSA development, such as young age, high pre-KT PRA levels, medication nonadherence, and non-tacrolimus-based immunosuppression, are consistent with previous studies [1,10,11]. Our investigation also confirms the significant impact of anti-DQ dnDSA development on long-term adverse outcomes, including late AMR and graft loss [12–14].\n\nDespite advancements in medical care for transplant recipients, allograft rejection remains a major barrier to long-term graft survival. The detrimental effects of dnDSAs are well known, and dnDSAs can lead to late AMR, chronic glomerulopathy, and graft loss. The reported prevalence of DSAs has varied between studies, ranging from approximately 5% to 30% over a 1- to 10-year period after transplantation [15]. The median times at DSA detection post-KT in cohort studies from the United Kingdom and the United States were 9.8 and 19.5 months, respectively, earlier than our findings [12–16]. However, our median time of 4.2 years is comparable to reports from Canada and our antecedent studies [1,17,18].\n\nThe explanation for the relatively long time to dnDSA detection post-KT is the differences in immunologic risks and pharmacokinetic profiles of KT recipients. Most recipients in Thailand were nonsensitized and received their first solid organ transplantation, which is associated with a lower incidence of dnDSA development [19]. Our recipients also experienced higher MPA levels when exposed to a similar MPA dosage as the western population, which may have protected them against DSA occurrence [20,21]. Generally, the occurrence of dnDSAs precedes late AMR, which may remain asymptomatic for a relatively long period. Therefore, we did not observe a difference in 5-year survival; however, the 10-year graft outcome was markedly and significantly inferior in the dnDSA group.\n\nOur cohort’s risk factors associated with anti-DQ dnDSA formation are consistent with previous studies. Younger patients tend to have a more robust immunologic response, resulting in a higher chance of dnDSA occurrence after transplantation. Medication nonadherence is a well-known contributor to under-immunosuppression and the subsequent development of dnDSAs and late rejection [22–24]. Recipients with high pretransplantation PRA levels may have cryptic memory responses to various HLA antigens, leading to early dnDSA development [25]. Tacrolimus-based immunosuppression with archival target trough levels is associated with a lower incidence of dnDSA development [26]. The high rate of rejection and subsequent unfavorable graft outcomes observed in the anti-DQ dnDSA group in our study confirms the impact of dnDSAs observed in antecedent studies [2,12]. Another important finding in our study showed comparable rejection-free survival between recipients with anti-DQ and non-DQ dnDSAs; however, those with anti-DQ DSAs had significantly worse graft survival. This may indicate that anti-DQ DSAs exert a more detrimental effect on long-term graft outcomes compared to other types of DSAs. Further studies are required to elucidate this observation and better understand the clinical relevance of different DSA types.\n\nAnti-HLA-DQB1 is the most common type of dnDSA observed after KT, as seen in studies conducted in Thailand [6,7,18] and other populations globally [3,7,27]. The prevalence of specific HLA-DQB1 dnDSAs can differ among various populations. For example, a South Korean study found that the most frequent anti-DQ dnDSAs were directed against DQ6 (39.4%), followed by DQ9 (27.3%) and DQ8 (24.3%) [2]. However, a US-based study revealed that the most common dnDSAs were directed against DQ7 (25%), DQ2 (19%), and DQ4 (19%) [12]. Nonetheless, these studies did not report the ratio of recipients with dnDSAs to those carrying HLA-DQB1 MM.\n\nThe most prevalent anti-DQ dnDSAs found in our cohort were against HLA-DQ7 (24%), HLA-DQ5 (22%) and HLA-DQ9 (18%). However, the most common HLA-DQB1 MM found in recipients are DQ5 (32.2%), DQ6 (18.7%), and DQ7 (17.5%) MM. Therefore, when analyzing the ratio of dnDSA per MM, the most frequently occurring specific DQ antibodies were against DQ7 (17.4%), followed by DQ9 (16.9%) and DQ2 (14.3%). Adjusted Cox model confirmed that recipients carrying HLA-DQ7 and DQ9 MM are at the highest risk for dnDSA development. The genetic polymorphism of each population might influence the differences in the occurrence specific HLA-DQ antibodies after KT.\n\nAlthough the hypothesis regarding dissimilarity in immunogenicity among each HLA MM in KT is not well established, a study on heart and/or lung transplant recipients from Canada showed that an epitope MM of HLA-DQA1*05+DQB1*02 or DQB1*07 increased the risk for dnDSA occurrence by approximately 4-fold [8]. In general, DQB1 is co-localized with DQA1 antigen as a heterodimer on the surface of leukocytes. Variations in DQA1 typing may impact immunogenicity of the DQB1 antigen. However, the population in our country is homogeneous, primarily comprising Thai ethnics, resulting in less diverse HLA typing. Additionally, DQA1 typing in our center was conducted after 2014. Recipients with DQB1*7 mostly (75%) carried the gene DQA1*0601+DQB1*0301 which is relatively restricted in Southeast Asia and the South Pacific, while the remaining 25% carried the gene DQA1*0505+DQB1*0301, consistent with a previous study [28]. Our findings, in line with previous Canadian data in heart and lung transplantation [8], support that the notion that the problematic MM might be DQ7 more than the colocalized DQA. All recipients who had DQ9 carried the gene DQA1*0302+DQB1*0303. Therefore, determining pathogenic MM in each population should be based on their own data.\n\nThe current concept regarding HLA and epitope MM focuses on the number of MM rather than the specific HLA types [5,29]. Our study also revealed that recipients with double DQ MM tended to be at higher risk for DSA development than those with single MM (17.3% vs. 11.1%). However, the rate of DSA development in double MM was not twice as high as in single MM, suggesting that the quality of MM may play a more meaningful role in DSA formation than the quantity alone. Patients with two low-immunogenicity MM may have a lower risk of developing dnDSA than those with one high-risk MM. Notably, HLA-DQ5 and HLA-DQ6 MM have an even higher epitope load than HLA-DQ7 or HLA-DQ9 [30,31]. Further studies are needed to explore the qualitative differences in epitope immunogenicity, as some epitopes may elicit stronger alloimmune responses than others. Identifying common pathologic HLA antigen or epitope MM in the population could inform personalized immunosuppression and dnDSA surveillance to mitigate high-risk MM-associated dnDSAs. Future allocation systems should consider preventing the generation of high-risk MM rather than solely matching the number of HLA MM.\n\nOur study’s strengths include a large population size with an extended follow-up, the availability of HLA-DQB typing information even for earlier patients, routine DSA surveillance, and low loss to follow-up (approximately 1.2%). However, several limitations should be acknowledged. First, data on HLA-DQA1 typing were unavailable for some earlier patients, however the association between HLA-DQB1 and HLA-DQA1 is relatively restricted in our population. Second, protocol biopsy was not performed routinely, and graft biopsy was not performed in all cases with dnDSAs, as some cases resolved after adjusting immunosuppression. Therefore, early AMR may have been underdiagnosed, particularly in cases with low DSA MFI. Third, incomplete data on BK nephropathy in our cohort, prevented us from including this factor in the survival analysis. BK nephropathy is a known contributor to graft loss, and future studies with complete data on this variable would provide a more comprehensive understanding of the impact of dnDSA on graft outcomes. Lastly, epitope MM assessment was unfeasible for earlier patients without complete HLA typing. The number and rate of interesting outcomes among patients who underwent higher-resolution HLA typing lacked sufficient power to evaluate the effect of epitope MM. Therefore, we plan to investigate this issue in future studies. However, currently, the detection of dnDSA still relies on HLA antigen rather than epitope, and assessing antigen MM remains more applicable in several countries where high-resolution HLA typing is not routinely performed due to higher associated costs.\n\nOur findings support the notion that anti-HLA-DQB1 antibodies are significantly associated with allograft rejection and inferior graft outcome. Moreover, our study demonstrated differences in the immunogenicity of HLA-DQ MM in KT recipients, with patients who carry HLA-DQ7 and HLA-DQ9 MM having a significantly higher risk of dnDSA occurrence than other DQ MM. Based on these results, it may be worthwhile to consider kidney allocation and individualized adjustment of immunosuppression based on the type of HLA-DQ MM to prevent dnDSA development and improve long-term graft survival.\n\nhttps://doi.org/10.1371/journal.pone.0321629.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321629.s002\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321629.s003\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0321629.s004\n\n(TIF)\n\nThe authors thank Mr. David Park for his assistance with language editing.",
    "category": "immunology"
  },
  {
    "title": "Study protocol: Fecal Microbiota Transplant combined with Atezolizumab/Bevacizumab in Patients with Hepatocellular Carcinoma who failed to achieve or maintain objective response to Atezolizumab/Bevacizumab – the FAB-HCC pilot study",
    "authors": "Katharina Pomej, Adrian Frick, Bernhard Scheiner, Lorenz Balcar, Larissa Pajancic, Anton Klotz, Abelina Kreuter, Katharina Lampichler, Katharina Regnat, Kerstin Zinober, Michael Trauner, Dietmar Tamandl, Christoph Gasche, Matthias Pinter, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321189",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321189",
    "content": "The gut microbiota is often altered in chronic liver diseases and hepatocellular carcinoma (HCC), and increasing evidence suggests that it may influence response to cancer immunotherapy. Strategies to modulate the gut microbiome (i.e., fecal microbiota transplant (FMT)) may help to improve efficacy of immune checkpoint inhibitors (ICIs) or even overcome resistance to ICIs. Here, we describe the design and rationale of FAB-HCC, a single-center, single-arm, phase II pilot study to assess safety, feasibility, and efficacy of FMT from patients with HCC who responded to PD-(L)1-based immunotherapy or from healthy donors to patients with HCC who failed to achieve or maintain a response to atezolizumab plus bevacizumab.\n\nIn this single-center, single-arm, phase II pilot study (ClinicalTrials.gov identifier: NCT05750030), we plan to include 12 patients with advanced HCC who failed to achieve or maintain a response to atezolizumab/bevacizumab. Patients will receive a single FMT via colonoscopy from donors with HCC who responded to PD-(L)1-based immunotherapy or from healthy individuals, followed by atezolizumab/bevacizumab every 3 weeks. The primary endpoint is safety, measured by incidence and severity of treatment-related adverse events. The main secondary endpoint is efficacy, as assessed by best radiological response according to RECISTv1.1 and mRECIST. Additional exploratory endpoints include data on the effect of FMT on recipient gut microbiota, as well as metagenomic analysis of stool samples, analyses of circulating immune cells and serum and stool proteomic, metabolomic and lipidomic signatures.\n\nThe results of this study will help to define the potential of FMT as add-on intervention in the systemic treatment of advanced HCC, with the potential to improve efficacy of immunotherapy or even overcome resistance.\n\nEudraCT Number: 2022-000234-42\n\nClinical trial registry & ID: ClinicalTrials.gov identifier: NCT05750030 (Registration date: 16.01.2023)\n\nCitation:Pomej K, Frick A, Scheiner B, Balcar L, Pajancic L, Klotz A, et al.  (2025) Study protocol: Fecal Microbiota Transplant combined with Atezolizumab/Bevacizumab in Patients with Hepatocellular Carcinoma who failed to achieve or maintain objective response to Atezolizumab/Bevacizumab – the FAB-HCC pilot study. PLoS ONE 20(4):\n           e0321189.\n        \n        https://doi.org/10.1371/journal.pone.0321189\n\nEditor:Po-Yao Hsu, Kaohsiung Medical University Hospital, TAIWAN\n\nReceived:November 6, 2024;Accepted:February 13, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Pomej et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:No datasets were generated or analysed during the current study. All relevant data from this study will be made available upon study completion.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:I have read the journal's policy and the authors of this manuscript have the following competing interests: KP has nothing to disclose. AF received travel support from Takeda and Amgen, he received speaker honoraria from AbbVie. BS received travel support from AbbVie, AstraZeneca, Gilead and Ipsen, speaker honoraria from Eisai as well as grant support from AstraZeneca and Eisai. LB received speaker honoraria from Chiesi and Gilead. LP has nothing to disclose. AKL has nothing to disclose. AKR has nothing to disclose. KL has nothing to disclose. KR has nothing to disclose. KZ has nothing to disclose. MT received speaker honoraria from Albireo, BMS, Falk Foundation, Gilead, Intercept, Madrigal and MSD; he has advised for Abbvie, Albireo, BiomX, Boehringer Ingelheim, Falk Pharma GmbH, Genfit, Gilead, Hightde, Intercept, Ipsen, Jannsen, MSD, Novartis, Phenex, Pliant, Rectify Regulus, Siemens and Shire. He further received travel grants from Abbvie, Falk, Gilead Intercept and Jannsen and research grants from Albireo, Almylam, Cymabay, Falk, Gilead, Intercept, MSD, Takeda and Ultragenyx. He is also co-inventor of patents on the medical use of NorUDCA filed by the Medical Universities of Graz and Vienna. DT served as a speaker and/or consultant and/or advisory board member for Siemens, Roche, Sanova, Bristol-Myers Squibb and received travel support from Bayer and Siemens. CG holds Roche shares. MP received speaker honoraria from AstraZeneca, Bayer, BMS, Eisai, Ipsen, Lilly, MSD, and Roche; he is a consultant/advisory board member for AstraZeneca, Bayer, BMS, Eisai, Ipsen, Lilly, MSD, and Roche; he received grants from AstraZeneca, Bayer, BMS, Eisai, and Roche; he received travel support from Bayer, BMS, Ipsen, and Roche.\n\nAbbreviations:AESI,\n            Adverse event of special interest; BOR,\n            Best overall response; CTCAE,\n            Common Terminology Criteria for Adverse Events; CR,\n            Complete response; FMT,\n            Fecal microbiota transplant; GMP,\n            Good manufacturing practice; HCC,\n            Hepatocellular carcinoma; ICI,\n            Immune checkpoint inhibitor; IMP,\n            Investigational Medicinal Product; IQR,\n            Interquartile range; mRECIST,\n            Modified Response Evaluation Criteria in Solid Tumors; MASH,\n            Metabolic dysfunction-associated steatohepatitis; NCI,\n            National cancer institute; OS,\n            Overall survival; PBMCs,\n            Peripheral blood mononuclear cells; PD,\n            Progressive disease; PD-(L)1,\n            Programmed cell death protein 1 (ligand) 1; PFS,\n            Progression-free survival; PR,\n            Partial response; Q6h,\n            Every 6 hours; RECIST 1.1,\n            Response Evaluation Criteria in Solid Tumors, Version 1.1; SD,\n            Stable disease; TACE,\n            Transarterial chemoembolization; VEGF,\n            Vascular endothelial growth factor.\n\nHepatocellular carcinoma (HCC) represents 90% of all primary liver cancers and one of the most common cause of cancer-related death globally [1]. Resection, local ablation, and liver transplantation are potential curative therapies, but are reserved for early-stage HCC. Unfortunately, most patients are diagnosed at an advanced tumor stage, where only palliative treatment options are available. Patients with liver-limited, multifocal HCC are usually treated with transarterial chemoembolization (TACE), while those with macrovascular tumor invasion or extrahepatic metastases are typical candidates for systemic therapy [1].\n\nEncouraging data on immune checkpoint inhibitors (ICIs) in HCC from phase II trials directed the research progressively towards immunotherapy. However, subsequent randomized controlled phase III trials testing programmed cell death protein 1 (PD-1)-targeted monotherapy with nivolumab or pembrolizumab failed to significantly improve survival endpoints [2]. These setbacks suggested that combined systemic approaches may be needed to implement immunotherapy in HCC. VEGF’s promotion of immunosuppression in the tumor microenvironment was the rationale to combine ICIs with VEGF-targeted agents [2]. In a pivotal phase III trial, the combination of atezolizumab plus bevacizumab improved both primary endpoints overall survival (OS) and progression-free survival (PFS) versus sorafenib, and demonstrated good safety and improved quality of life data [3]. Consequently, atezolizumab plus bevacizumab was implemented as the new standard of care in systemic front-line treatment of HCC for most patients [4,5]. Moreover, the combination of tremelimumab plus durvalumab also improved its primary endpoint of OS in a phase III trial [6], and represents an alternative immunotherapy-based treatment option in the systemic first-line setting [7].\n\nEven though these results represent milestones in the systemic treatment of HCC, only around one-third of patients responds to atezolizumab/bevacizumab [3]. While patients with stable disease (SD) still show improved overall survival compared to subjects with progressive disease (PD), patients with complete (CR) or partial response (PR) are those most likely to derive a long-term survival benefit from immunotherapy [8]. Currently, there is no established biomarker to predict response to immunotherapy [2,9].\n\nThe gut microbiota is often altered in chronic liver diseases and HCC and may modulate cancer-promoting and cancer-suppressing pathways associated with immunity and inflammation [10]. For instance, in metabolic dysfunction-associated steatohepatitis (MASH)-related HCC, gut dysbiosis promotes peripheral immunosuppression [11]. Increasing evidence suggests that the gut microbiome may influence response to cancer immunotherapy [12–14]. Hence, strategies to modulate the gut microbiome (i.e., FMT) may help to improve efficacy of ICIs or even overcome resistance to immunotherapy. Indeed, in preclinical studies, FMT obtained from patients responding to ICIs into mice enhanced the efficacy of anti-PD-(L)1 treatment and augmented T cell response, while FMT from non-responders did not [12–14]. Two recently published clinical pilot studies confirmed the feasibility and safety of this innovative approach in humans [15,16]. In a phase I clinical trial, 10 metastatic melanoma patients with confirmed progression on PD-1-targeted immunotherapy received FMT from donors with metastatic melanoma who had achieved complete remission for at least 12 months with PD-1-targeted immunotherapy. Reintroduction of anti-PD-1 treatment after FMT led to 2 partial responses and 1 complete response. The safety profile was excellent with mild bloating being the only FMT-related adverse event [15]. The second clinical trial investigated the safety and efficacy of responder-derived FMT in combination with PD-1-targeted immunotherapy in patients with melanoma primary refractory to anti-PD-1 treatment. Of 15 patients evaluable for radiological response, 3 achieved complete (n=1) or partial (n=2) remission and 3 patients had durable stable disease for more than 12 months. No relevant FMT-related adverse events were reported [16]. Moreover, a recently published phase I trial testing upfront combination of healthy donor FMT with first-line immunotherapy in 20 advanced melanoma patients reported a good safety profile and an encouraging objective response rate of 65% (including four complete responses) [17].\n\nHere, we describe the design and the rationale of FAB-HCC, a single-center, single-arm, phase II pilot study of atezolizumab plus bevacizumab in combination with FMT in patients with HCC who failed to achieve or maintain a response to atezolizumab plus bevacizumab. The primary endpoint of this study is safety (i.e., incidence and severity of treatment-related adverse events), and secondary endpoints include radiological response, progression-free and overall survival, as well as quality of life.\n\nFAB-HCC is a single-center, single-arm, phase II pilot study designed to evaluate the safety, feasibility, and efficacy of atezolizumab plus bevacizumab in combination with FMT from anti-PD-(L)1 responders or healthy donors to adult patients with HCC who failed to achieve or maintain a complete or partial radiological response to atezolizumab plus bevacizumab according to mRECIST [18].\n\nThe study was approved by the Ethics Committee of the Medical University of Vienna (Date of approval: 27.05.2022, approval number: 1054/2022), as well as the Austrian Competent Authorities (Bundesamt für Sicherheit im Gesundheitswesen (BASG) represented by the Agency for Health and Food Safety (AGES Medizinmarktaufsicht)). If necessary, amendments to the protocol are possible and must be disclosed to the respective authorities. The clinical trial will be performed in full compliance with the legal regulations according to the Drug Law (AMG – Arzneimittelgesetz) of the Republic of Austria and was registered to the European Clinical Trial Database (EudraCT number: 2022-000234-42). The study will be performed in compliance with the Declaration of Helsinki and the principles of Good Clinical Practice. Written/signed informed consent is obtained from each patient and donor before study entry.\n\nThe study is planned to enroll a total of 12 patients with HCC, mainly patients who progressed according to mRECIST on this treatment, but study participation will also be offered to patients who have achieved stable disease as best radiological response according to mRECIST after the first 12 months of treatment initiation, as it is unlikely that a response to atezolizumab/bevacizumab will occur after one year [19]. Eligible patients will receive one single FMT on Day 0, followed by Cycle 1 of atezolizumab/bevacizumab (± 3 days), which they will continue to receive at the approved standard dose every 3 weeks (± 5 days) thereafter.\n\nThe investigational medicinal products (IMPs) used in this pilot study are atezolizumab and bevacizumab. Atezolizumab (trade name: Tecentriq, manufacturer: Roche), is an Fc-engineered, humanized IgG1 anti-programmed death 1 ligand 1 (PD-L1) monoclonal antibody produced in Chinese hamster ovary cells by recombinant DNA technology [20]. Atezolizumab will be administered by IV infusion at a fixed dose of 1200 mg on day 1 and then every 21 days. Bevacizumab (trade name: Avastin, manufacturer: Roche), is a recombinant humanized monoclonal antibody against VEGF and is also produced by DNA technology in Chinese Hamster Ovary cells. Bevacizumab will be administered by IV infusion at a dose of 15mg/kg on day 1 and then every 21 days. The clinical safety profile for the combination of atezolizumab plus bevacizumab as therapy in HCC has emerged from clinical trials [3].\n\nFAB-HCC will recruit patients (aged ≥18 years) with histologically or radiologically confirmed HCC with progressive disease (according to mRECIST) during treatment with atezolizumab/bevacizumab (without or with prior complete or partial response as best radiological response according to mRECIST) or patients with stable disease as best radiological response (according to mRECIST) after the first 12 months of atezolizumab/bevacizumab treatment. Patients will require adequate hematological and end-organ functions, as well as a known variceal status with adequate medical or endoscopic treatment. Detailed eligibility criteria are provided inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321189.t001\n\nThe start of the study is defined as the date of the first patient’s first visit. The end of the study is defined as the date when every patient enrolled had a follow-up of at least 20 weeks (2 scheduled follow-up imaging visits), if not progressed or deceased earlier. Based on previous phase III second-line studies in HCC [21–23], a disease control rate of less than 50% is below what would be expected. Thus, to ensure that a likely unsuccessful therapeutic strategy is not pursued, the study will stop enrollment prematurely if the disease control rate of the first 6 patients included is less than 50%.\n\nThis clinical trial plans to include 12 patients. The start of recruitment period for this study is planned for August 14, 2023 and the end of recruitment period is planned for May 31, 2025. The number of patients planned to be included is expected to be sufficient to fulfill the pilot study’s objectives. No inferential statistical testing is planned for the primary safety endpoint and secondary efficacy endpoints, and therefore an exact sample size requirement has not been specified. Previous studies evaluating the efficacy of FMT in patients with advanced melanoma not responding to immunotherapy included a comparable number of patients [15,16].\n\nAfter obtaining written informed consent, screening evaluations must be completed and reviewed by study staff to confirm that patients meet all eligibility criteria before enrollment. All necessary study procedures (including medical history, concomitant medication, physical examination, vital signs, and electrocardiogram) will be performed at baseline and prespecified visits. The schedule of activities to be performed and a study flow chart are provided inFigs 1and2. Laboratory testing will be performed at every visit, and blood and stool sampling will take place at predefined timepoints (seeFig 1andS1 Table). Patients included in the FAB-HCC trial, will undergo tumor imaging at week 6 and every 12 weeks thereafter. FMT will be performed once on Day 0. Patient-reported outcome data will be obtained using the EQ-5D-5L questionnaire to fully characterize the study participants.\n\nFurther ECGs should be performed upon clinical suspicion.bAt week 1, week 2, and week 3.cRepetitive pregnancy assessment in women with childbearing potential.dEvery 4thcycle.eEvery other visit (odd cycles).\n\nFurther ECGs should be performed upon clinical suspicion.bAt week 1, week 2, and week 3.cRepetitive pregnancy assessment in women with childbearing potential.dEvery 4thcycle.eEvery other visit (odd cycles).\n\nhttps://doi.org/10.1371/journal.pone.0321189.g001\n\n(original figure, no copyright permission required, created with BioRender.com), Abbreviations: A/B, atezolizumab plus bevacizumab; CT, computed tomography; FMT, fecal microbiota transplant; HCC, hepatocellular carcinoma; IT, immunotherapy; mRECIST, modified Response Evaluation Criteria in Solid Tumors; RECISTv1.1, Response Evaluation Criteria in Solid Tumors version 1.1.\n\n(original figure, no copyright permission required, created with BioRender.com), Abbreviations: A/B, atezolizumab plus bevacizumab; CT, computed tomography; FMT, fecal microbiota transplant; HCC, hepatocellular carcinoma; IT, immunotherapy; mRECIST, modified Response Evaluation Criteria in Solid Tumors; RECISTv1.1, Response Evaluation Criteria in Solid Tumors version 1.1.\n\nhttps://doi.org/10.1371/journal.pone.0321189.g002\n\nFMT is still a novel treatment modality and therefore, data about the most efficient way of performing FMT is scarce. Our study will be conducted according to the Austrian consensus [24] as well as the European guidelines on FMT [25].\n\nPotential donors will be patients with unresectable HCC treated with anti-PD-(L)1-based immunotherapy with complete or partial response for at least 12 months or healthy donors. In total, we are planning to include 2 donors, one immunotherapy responder and one healthy donor, of whom stool for FMT will be used for 6 patients each, after ruling out infectious agents in the stool by repetitive stool sampling. Donor-specific exclusion criteria are listed inTable 2. Initial serological testing will be performed within 14 days prior to donor stool acquisition. Processed donor stool will be tested for the respective targets by applying the methods listed inTable 3. Donors repeatedly used for FMT will be retested every 6 months or sooner, in case of certain risks for infectious diseases [16].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321189.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321189.t003\n\nFecal material will be collected and prepared as described elsewhere [26,27]. Donor feces will be collected after the completion of the safety screening phase. Donor’s feces are processed under good manufacturing practice (GMP) conditions and for the preparation process, regulations for the work with feces, classified as biohazard level 2, will be followed (wearing of water-repellent garments, gloves, facemasks, protective goggles, or shields). After the extraction of the fecal probe (approximately 50g of fecal matter for one colonoscopy-based implant), the entire donation will be diluted with 100–500 mL of sterile saline (0.9% NaCl) using 3x the weight of donor stool. Afterwards the mixture is homogenized in a sterilized blender or similar device, especially designated for this purpose. Afterwards the probe will sequentially be sieved to remove particulate material. Since instant application of fresh fecal probes to study recipients is not possible, the processed donor stool is mixed with glycerol (10% of total weight) and frozen at monitored temperature (-80°C). Before usage, the fecal probes will be gently reheated in a 37°C warm water bath over a period of 2 hours.\n\nPatients will be prepared according to standard care with a colon lavage, routinely given prior to colonoscopy. To deplete the innate gut microbiota, patients receive an antibiotic treatment, according to protocols previously published [15,24,28], prior to colonoscopy consisting of an oral antibiotic treatment with vancomycin 500mg and neomycin 1000mg q6h for 72 hours.\n\nFor the application process, the Austrian consensus paper [24] recommends the lower gastrointestinal tract as the preferable route. The colonoscopy will be performed by an experienced endoscopist, and the procedure does not alter from standard colonoscopies, except for the administration of the fecal probes. During bowel intubation with the colonoscope residual stool will be suctioned to achieve maximal mucosal cleansing. After reaching 20 cm into the terminal ileum, a 100mL fecal implant suspension will be administered via a catheter in the following sequence: 20mL in the terminal ileum, 40mL in the cecum and right colon, 20mL in the transverse colon and 20mL in the descending colon. After procedure completion, the recipients remain lying on prone Trendelenburg position for at least 4 hours to maintain the FMT suspension in the bowel. The day of the colonoscopy-based FMT is considered as day 0 of the trial protocol [15]. In patients with insufficient bowel lavage (i.e., patients with significant amounts of residual stool), colonoscopy will be prematurely terminated (due to an increased risk for bowel perforation), bowel lavage will be repeated and a second colonoscopy will be scheduled.\n\nThe primary endpoint will be analyzed using descriptive statistics. In detail, the incidence and severity of treatment-related adverse events determined according to National Cancer Institute (NCI) Common Terminology Criteria for Adverse Events (CTCAE) version 5.0 will be described. Secondary endpoints include efficacy and quality of life. Efficacy will be evaluated by the number (percentage) of study participants achieving complete response (CR), partial response (PR), stable disease (SD) or progressive disease (PD) as best radiological response evaluated according to mRECIST and RECIST v1.1 criteria. Objective response is defined as either complete or partial response, while disease control rate comprises complete/partial response as well as stable disease. Changes of quality of life during the study period as assessed by EQ-5D-5L questionnaire will be evaluated using paired T-test or Wilcoxon signed rank test. Exploratory endpoints will include data on the effect of FMT on recipient gut microbiota, as well as metagenomic analysis of stool samples, single cell analyses of circulating immune cells, and serum and stool proteomic, metabolomic and lipidomic signatures.\n\nAll adverse events (both non-serious and serious), whether reported by the patient or noted by study personnel, will be classified in associated and not associated with the IMP, and will be recorded. Adverse events associated with IMP exposure and likely to have an immune-mediated underlying mechanism will be considered as adverse events of special interest (AESI). AESI may occur already after the first dose to weeks/months after the last dose. IMP will be interrupted or discontinued, after excluding other potential etiologic causes, if an AESI is suspected. A detailed list of AESIs for this study can be found inTable 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321189.t004\n\nNo dose modifications are allowed for atezolizumab and bevacizumab. However, treatment may be temporarily interrupted in patients experiencing toxicity considered to be related to study treatment. Furthermore, if continued administration of the study drug is believed to be contrary to the best interests of the patient, the investigator must temporarily interrupt or permanently discontinue the study drug. The interruption or premature discontinuation of study drug might be triggered by an AE, a diagnostic or therapeutic procedure, an abnormal assessment (e.g., laboratory abnormalities), or for administrative reasons, in particular withdrawal of the patient’s consent.\n\nFor the analysis of the primary safety endpoint, all subjects who underwent technically successful fecal microbiota transplantation and received the study drug (at least one dose) and did not violate the protocol in a way that might affect the evaluation of the effect of the combination of FMT and the study drugs on the primary endpoint, i.e., without major protocol violations, will be included. Patients who do not undergo FMT will be replaced.\n\nAn interim analysis of clinical data will be performed after 6 subjects (50% of the planned study population) underwent at least one radiological follow-up. If disease control (CR/PR/SD) as best radiological response according to mRECIST cannot be achieved in ≥50% (3 subjects) of the first 6 participants, the study will be terminated prematurely as a disease control of >50% would be expected with alternative second line treatment options. Full data analysis, including exploratory endpoints, will be performed when the study is completed.\n\nThe primary endpoint and secondary efficacy endpoints will be analyzed using descriptive statistics. Kaplan-Meier method will be used to calculate progression-free survival and overall survival. Distribution of quality-of-life parameters will be assessed by plotting histograms. Baseline and follow-up values will be demonstrated as mean (+/- standard deviation) or median (IQR), as applicable. Changes of quality of life during the study period as assessed by EQ-5D-5L questionnaire will be evaluated using paired T-test or Wilcoxon signed rank test.\n\nIn addition to clinical endpoints, FAB-HCC will collect blood and stool samples at different timepoints (Supplemental Table 1) to investigate different exploratory endpoints and generate mechanistical hypotheses. The effect of FMT on recipient gut microbiota composition, diversity (alpha and beta), rate of change from baseline and similarity (Bray-Curtis dissimilarity) to donor stool composition over time (engraftment) as well as comparison of responders and non-responders, will be analyzed by extracting bacterial DNA from stool by using an established pipeline with MiSeq technology. Metagenome assemblies and functional pathway analysis will be performed by using shotgun metagenomic sequencing. We will also collect peripheral blood mononuclear cells (PBMCs) before and at different timepoints after FMT for single cell profiling. Finally, serum and stool proteomic, metabolomic, and lipidomic signatures before and after FMT will be analyzed after processing data using specific commercial software.\n\nThe combination of atezolizumab plus bevacizumab represents a reference standard in systemic front-line therapy for advanced stage HCC [3,4,7]. Patient who respond to this treatment can derive a long-term survival benefit [8]. However, only around one-third of patients treated with atezolizumab/bevacizumab achieves CR or PR, while around 20% have a primary resistance reflected by disease progression already at the first radiological evaluation. Patients who achieve stable disease (~40%) have an initial clinical benefit, but most of them will eventually show progression of the disease during the course of treatment [3].\n\nDisease progression usually triggers a change in systemic treatment, but given that all available second-line agents have been tested in sorafenib-pretreated patients, no established second-line option exists after atezolizumab/bevacizumab and treatment sequencing after first-line immunotherapy remains purely empirical [9]. Approved targeted therapies (i.e., sorafenib, lenvatinib, regorafenib, cabozantinib, ramucirumab) are recommended as per off-label availability [4]. However, these agents have limited efficacy (median OS improvement: <3 months vs. placebo; response rate: 2%-11%) [21,22,29]. Only lenvatinib showed a somewhat higher response rate (19%) but failed to improve OS compared to sorafenib [30], and its availability is limited as it is only approved in systemic first-line [4]. Given the lack of an established treatment with long-term survival benefit after first-line atezolizumab/bevacizumab and the poor prognosis of patients with advanced stage HCC, this patient population is considered appropriate to study novel therapeutic strategies.\n\nIn advanced melanoma patients, immune checkpoint inhibitors combined with FMT from immunotherapy responders to immunotherapy-refractory patients or from healthy donors to previously untreated patients demonstrated good tolerability and promising efficacy in early phase clinical trials [15–17]. Whether microbial composition has a predictive value for immune checkpoint inhibitor therapy remains under investigation, as is to studying algorithms that may predict response to immunotherapy [31,32]. Based on these emerging clinical data and on the fact that the gut microbiota is often altered in HCC and chronic liver diseases [10,11], we will conduct the FAB-HCC pilot study in order to evaluate the safety and efficacy of FMT combined with atezolizumab plus bevacizumab in HCC patients with failure of prior atezolizumab plus bevacizumab. Although the sample size is limited, the study aims to generate mechanistical hypotheses, which will help to define the potential of FMT as add-on intervention in the systemic treatment of advanced HCC, with the potential to improve efficacy of immunotherapy or even overcome resistance.\n\nAbbreviations: HBV, hepatitis B virus; HBsAg, hepatitis B surface antigen; HBcAb, hepatitis B core antibody; HCV, hepatitis C virus; HIV, human immunodeficiency virus; DNA, deoxyribonucleic acid; RNA, ribonucleic acid.\n\nhttps://doi.org/10.1371/journal.pone.0321189.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321189.s002\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321189.s003\n\n(PDF)",
    "category": "immunology"
  },
  {
    "title": "The burden of HIV/AIDS in Ethiopia: Unveiling 30 years of trends in incidence, mortality, and disability—insights from the Global Burden of Disease study (1990–2021)",
    "authors": "Tegene Atamenta Kitaw, Molla Azmeraw, Biruk Beletew Abate, Befkad Derese Tilahun, Alemu Birara Zemariam, Addis Wondmagegn Alamaw, Abebe Merchaw Faris, Addisu Getie, Molalign Aligaz Adisu, Tesfaye Engdaw Habtie, Melesse Abiye Munie, Ribka Nigatu Haile, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321024",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321024",
    "content": "Over the past three decades, Ethiopia has witnessed a dynamic shift in the burden of HIV/AIDS, a public health crisis that has profoundly impacted communities nationwide. While significant strides have been made in combating the disease, evolving trends in incidence, mortality, and disability reveal the complexity of progress. The insights drawn from the Global Burden of Disease Study (1990–2021) offer a comprehensive perspective on the successes and ongoing challenges. Understanding these trends is critical for refining public health strategies and achieving more equitable health outcomes. This study delves into the data, unveiling key findings that inform future policies and interventions.\n\nThis study used data from the 2021 Global Burden of Disease Study (1990–2021) to evaluate HIV/AIDS incidence, mortality, and DALYs in Ethiopia. The dataset, including age-standardized rates and 95% uncertainty intervals, was obtained from the Global Health Data Exchange (GHDx). Statistical analyses included Joinpoint regression to identify trend shifts and calculate the Annual and Average Annual Percentage Change over time, with significance determined at a p-value of 0.05. Geographic variations were visualized using ArcGIS Pro, highlighting regions with varying HIV burdens. The comprehensive methodology adhered to GATHER guidelines for transparent reporting.\n\nIn 2021, 715,839 individuals (95% UI: 568,889.58–914,511.59) were living with HIV in Ethiopia, and 839,819.31 DALYs (95% UI: 620,558.56–1,154,483.92) were recorded. There was a significant decline in the age-standardized HIV incidence rate, from 175.4 per 100,000 in 1990 to 22.4 per 100,000 in 2021, with an average annual percentage change (AAPC) of -6.64% (p <  0.001). Mortality rates rose from 14.2 per 100,000 in 1990 to 79.7 in 2000 but decreased to 13.6 by 2021, with an AAPC of -1.19%. DALYs peaked in 2010 at 1,695.1 per 100,000 and declined to 770.9 per 100,000 in 2021, with an AAPC of -1.43%. Higher incidence (28.1) and mortality (17.7) were observed in females compared to males (16.7 and 9.6). The Gambela region reported the highest burden, with an incidence rate of 176.3 per 100,000, a mortality rate of 78.4 per 100,000, and 4,220.7 DALYs per 100,000.\n\nEthiopia accounts for 1.8% of the global HIV/AIDS prevalence. While significant progress has been made in recent years, sustained efforts are necessary to further reduce the burden of the disease. The disproportionate impact on females and the Gambela region underscores persistent disparities in prevention and care. To achieve equitable health outcomes across the country, it is crucial to implement targeted, evidence-based interventions that address these gaps in the HIV/AIDS response.\n\nCitation:Kitaw TA, Azmeraw M, Abate BB, Tilahun BD, Zemariam AB, Alamaw AW, et al.  (2025) The burden of HIV/AIDS in Ethiopia: Unveiling 30 years of trends in incidence, mortality, and disability—insights from the Global Burden of Disease study (1990–2021). PLoS ONE 20(4):\n           e0321024.\n        \n        https://doi.org/10.1371/journal.pone.0321024\n\nEditor:Deepak Dhamnetiya, Atal Bihari Vajpayee Institute of Medical Sciences & Dr Ram Manohar Lohia Hospital, INDIA\n\nReceived:November 20, 2024;Accepted:February 27, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Kitaw et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:For access to the data utilized in this analysis, please refer to the GBD 2021 data-input sources tool available on the Global Health Data Exchange (GHDx) platform athttps://ghdx.healthdata.org/gbd-2021/data-input-sources.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe HIV/AIDS epidemic has been a formidable public health challenge impacting millions of lives worldwide and exerting immense strain on healthcare systems, particularly in low- and middle-income countries [1]. Characterized by its ability to compromise the immune system and increase vulnerability to life-threatening infections and cancers, HIV/AIDS has caused widespread mortality and disability over the past four decades [2,3]. Sub-Saharan Africa has been disproportionately affected by this epidemic, accounting for a significant percentage of global HIV/AIDS cases, with Ethiopia standing among the hardest-hit countries in the region[4,5]. The burden of HIV/AIDS in Ethiopia has not only affected the health and well-being of individuals but also contributed to considerable socio-economic challenges, including reduced workforce productivity, increased healthcare costs, and widespread poverty due to loss of income from affected individuals [6,7].\n\nDespite various global health initiatives and national campaigns aimed at reducing HIV transmission and improving access to antiretroviral therapy (ART), Ethiopia continues to grapple with high rates of HIV incidence and AIDS-related mortality [8,9]. The disease affects vulnerable populations at a greater rate, including women, young people, and marginalized groups, intensifying existing inequalities in healthcare access and economic opportunity [10]. Furthermore, the epidemic has led to significant and persistent consequences, including years of life lost (YLL), years lived with disability (YLD), and cumulative disability-adjusted life years (DALYs), which collectively represent the profound toll on individual and public health [11,12].\n\nTracking and understanding these impacts are essential for shaping effective health policies and intervention strategies [13]. The Global Burden of Disease (GBD) study offers a systematic and comparative framework for evaluating disease burden, providing insights into the trends and patterns of HIV/AIDS and its multifaceted impacts on population health [14]. Through metrics like YLL, YLD, and DALY, the GBD study captures not only the direct effects of HIV/AIDS but also its enduring consequences on the quality and duration of life [15]. Despite the importance of these metrics, updated evidence on the full burden of HIV/AIDS remains limited in Ethiopia.\n\nThis analysis of GBD data from 1990 to 2021 for Ethiopia focuses on the incidence, mortality, and disability metrics associated with HIV/AIDS. By examining these factors over three decades, this study aims to elucidate key trends, assess the outcomes of public health interventions, and identify areas that require enhanced focus. Such findings are critical for healthcare stakeholders, policymakers, and international organizations dedicated to reducing the burden of HIV/AIDS in Ethiopia and informing sustainable strategies for long-term epidemic control. This study also explores the regional distribution of HIV/AIDS burden within Ethiopia, mapping how incidence, mortality, and disability metrics vary across different regions. Ultimately, this research seeks to contribute valuable insights that can guide future policy-making, support resource allocation, and foster better health outcomes for individuals affected by HIV/AIDS in Ethiopia.\n\nFor the study, we utilized data from the 2021 Global Burden of Disease (GBD) Study, covering the years 1990 to 2021, to examine HIV/AIDS prevalence, mortality, years of life lost (YLLs), years lived with disability (YLDs), and disability-adjusted life years (DALYs). This dataset includes rates per 100,000 population for HIV/AIDS prevalence, mortality, and DALYs, along with 95% uncertainty intervals (UIs). The data can be accessed via the Global Health Data Exchange (GHDx) at the Institute for Health Metrics and Evaluation (IHME), University of Washington (http://ghdx.healthdata.org/gbd-results-tool).\n\nGBD is a systematic, scientific effort to quantify the comparative magnitude of health loss caused by diseases and injuries by age, sex, and location over time. GBD 2021 involves a comprehensive analysis. Data was gathered from various sources, including censuses, household surveys, vital statistics, air pollution monitoring, civil registration, disease registries, healthcare utilization, satellite imagery, disease alerts, and more. The Cause of Death Ensemble model and spatiotemporal Gaussian process regression were employed to calculate cause-specific death rates and cause fractions [16].\n\nThe study adheres to the Guidelines for Accurate and Transparent Health Estimates Reporting (GATHER)[17]. (supplementary file 1).The specific search criteria used in the “Search” interface were as follows: GBD Estimate (HIV/AIDS cases of death or disability), Measure (Incidence, Deaths), Metric (Count, Percent, Rate), Cause (HIV/AIDS), Location (Ethiopia), Age (All ages, age-standardized, and specific age groups from < 5 years to 95 + years), Sex (Both, Male, Female), and Year (1990–2021). The data included age-standardized incidence rates (ASIR), incidence counts, age-standardized disability-adjusted life year (DALYs) rates, and DALYs counts. Age-standardized death rates (ASDR) and death counts were available from 1990 onwards. Additionally, data from nine regions and two sub-cities were analyzed to map the distribution of the HIV/AIDS burden across the country. Age-standardized disability-adjusted life years (DALYs) is a measure used to assess the overall burden of disease in a population, accounting for both the years of life lost due to premature death (YLL) and the years lived with disability (YLD). The age-standardization process adjusts the DALYs value to a standard age distribution, allowing for comparisons between populations with different age structures or over time.\n\nThe burden of HIV in the country was quantified using incidence, mortality, years of life lost, years lived with disability, and disability-adjusted life years. Age-standardized rates (ASRs) for specific age groups, along with estimated values and 95% uncertainty intervals (UIs), were extracted from GBD 2021. ASR was computed using the formula:\n\n=Whererepresents the age-specific rate for theage group anddenotes the number of individuals (or the weight) in the same age group within the GBD 2021 standard population. N is the number of age groups.\n\nWe calculated the percentage change in the number of incident cases and deaths by comparing the case counts from 1990 to 2021.\n\n= Y can refer to either the total number of incidentcases or the total number of deaths.\n\nWe employed Jointpoint regression to analyze the trends in the incidence and mortality rates of HIV/AIDS in Ethiopia from 1990 to 2021. This method allows us to identify points in time where the rate of change in the data significantly shifts. The regression model fits multiple linear segments to the data, with each segment representing a distinct trend. Joinpoints, where the slope of the trend changes, were identified to examine periods of acceleration or deceleration in HIV/AIDS burden. We calculated the Annual Percentage Change (APC), which reflects the rate of change in the data within that segment. The Average Annual Percentage Change (AAPC) was then computed by averaging the APC values across all identified segments, weighted by the duration of each segment. The AAPC provides a summary measure of the overall rate of change in HIV/AIDS incidence and mortality over the study period, accounting for any shifts in the trends. Significant of change was determined at P-value of 0.05.\n\nWe utilized ArcGIS Pro to visualize and map the distribution of the HIV burden across Ethiopia. Geographic data from 9 regions and two sub-cities were analyzed to create detailed maps representing the incidence and mortality rates of HIV. Using spatial analysis tools in ArcGIS Pro, we visualized the geographic variation in the HIV burden, enabling a clear depiction of areas with higher or lower rates\n\nThis study did not require ethical board approval since it relied on a publicly available dataset and did not involve human or animal trials.\n\nIn 2021, a total of 715,839 people (95% UI: 568,889.58–914,511.59) were living with HIV in Ethiopia. From 1990 to 2021, HIV/AIDS prevalence in Ethiopia showed a notable rise in the early 1990s, peaking in 1998 across all sex groups. The overall prevalence increased from 0.3979% in 1990 to 1.1715% in 1998, after which it gradually declined to 0.6722% by 2021. Males followed a similar trend, with rates rising from 0.2778% in 1990 to 0.8313% in 1998, before decreasing to 0.4819% in 2021. Females consistently had higher prevalence rates throughout the period, beginning at 0.5186% in 1990, peaking at 1.5189% in 1998, and declining to 0.8637% by 2021. (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.g001\n\nFrom 1990 to 2021, the overall death rate per 100,000 population saw a modest decline, decreasing from 14.2 to 13.6. In the < 20 years age group, the death rate dropped from 4.4 in 1990 to 3.3 in 2021. For the 20-54 years age group, the rate decreased more significantly from 29.8 in 1990 to 24.1 in 2021, with a notable mid-point drop to 142.9 in 2005. The > 54 years age group showed a different trend, with the rate increasing from 16.9 in 1990 to 48.8 in 2021, though a mid-point in 2005 saw a lower rate of 53.1, indicating fluctuations rather than a steady decline. When comparing by sex, females consistently had higher death rates than males. In 1990, the death rate for males was 9.8, which slightly decreased to 9.6 by 2021, with a mid-point in 2005 showing a rate of 45.3. For females, the rate dropped from 18.6 in 1990 to 17.7 in 2021, with a mid-point rate of 84.0 in 2005, suggesting a more substantial overall reduction. Overall, while all groups experienced reductions, the decline was more pronounced in the 20-54 years age group, and the most significant fluctuations were observed in those aged > 54 years, particularly among females. (Table 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.t001\n\nFrom 1990 to 2021, HIV Disability-Adjusted Life Years (DALYs) decreased from 4,461,606 to 770,900, with an average annual percentage change (AAPC) of -17.92%. DALYs for females dropped from 2,937,811 to 541,421 (AAPC: -10.36%), and for males from 1,523,794 to 239,879 (AAPC: -11.44%). In the < 20 years age group, DALYs showed minimal change (AAPC: 0.46%). The 20-54 years group saw a substantial decrease (AAPC: -13.28%). In contrast, the > 54 years age group experienced an increase in DALYs (AAPC: 3.43%). (Table 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.t002\n\nIn 2021, the YLD due to HIV/AIDS reached 78,772.2, a significant rise from 28,674.2 in 1990, with the most substantial increase seen in individuals over 54 years, whose YLD surged from 1,351.3 in 1990 to 10,860.8 in 2021, reflecting an AAPC of 6.22%. For females, YLD amounted to 50,557.4, up from 18,578.9, while for males, it reached 28,214.7, increasing from 10,095.3; their respective AAPCs were 2.66% and 2.72%, indicating similar annual growth rates for both sexes. The overall AAPC for YLD from 1990 to 2021 was 2.68%. In the same year, YLL due to HIV/AIDS was 761,047.1, an increase from 417,432.5 in 1990. Females experienced YLL of 490,864.0, up from 274,792.9, and males had YLL of 270,183.2, rising from 142,639.5. The YLL for those under 20 years increased from 108,844.7 in 1990 to 150,303.6 in 2021, while those aged 20-54 years saw a substantial rise from 293,256.7 to 549,776.9, and the > 54 years group experienced growth from 15,331.0 to 60,966.6. The overall AAPC for YLL from 1990 to 2021 was 0.89%. (Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.t003\n\nThe table shows a significant decline in age-standardized HIV incidence from 1990 (175.4 per 100,000) to 2021 (22.4 per 100,000), with an average annual percentage change (AAPC) of -6.64% (p <  0.001). Mortality rates increased from 14.2 per 100,000 in 1990 to 79.7 in 2000 but declined to 13.6 by 2021, with an AAPC of -1.19%, but the change is not significant (p >  0.05). Disability-adjusted life years (DALYs) peaked in 2010 at 1,695.1 per 100,000 before decreasing to 770.9 in 2021, with an AAPC of -1.43%, but the change is not significant (p >  0.05). In 2021, a 839,819.31 (95UI: 620,558.56 - 1,154,483.92) DALYs was observed. (Table 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.t004\n\nThe incidence of HIV/AIDS saw a sharp rise from 1990 to 1992, with an APC of 16.85%, followed by stabilization between 1992 and 1995 (APC: -0.27%). From 1995 onwards, a steady and significant decline occurred, with the steepest drop between 1995 and 2004 (APC: -9.95%). This downward trend continued from 2004 to 2010 (APC: -5.84%), with further declines between 2010 and 2014 (APC: -9.06%), 2014 to 2018 (APC: -6.97%), and 2018 to 2021 (APC: -10.00%). (Fig 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.g002\n\nThe mortality rate attributable to HIV/AIDS increased sharply from 1990 to 1993 (APC: 38.39%) and continued to rise at a slower pace between 1993 and 1996 (APC: 18.97%). From 1996 to 2000, the increase slowed further (APC: 6.07%) before peaking in 2000. Following this peak, the mortality rate declined gradually from 2000 to 2004 (APC: -2.33%), with a significant decrease from 2004 to 2010 (APC: -15.53%), and continued to fall from 2010 to 2021 (APC: -5.87%). (Fig 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.g003\n\nFrom 1990 to 1996, HIV/AIDS DALYs increased significantly, with an APC of 37.03% and 17.69% respectively, peaking in 2000. Following this, the trend reversed, with a gradual decline in DALYs from 2000 to 2004 (APC: -2.97%) and a sharper decrease from 2004 to 2010 (APC: -14.41%). This decline continued through 2021, though at a slower rate (APC: -6.28%). (Fig 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.g004\n\nAn analysis of the geographical distribution of the HIV/AIDS burden shows that the highest age-standardized incidence rate is observed in the Gambella region, with 176.3 (95UI:65.7-360.5) cases per 100,000 population, followed by Addis Ababa (the capital city of Ethiopia) with 78.4 (95UI: 30.3-169.1) cases per 100,000 population and Dire Dawa with 58.4 (95UI:17.6-132.4) cases per 100,000 population. (Fig 5).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.g005\n\nThe highest age-standardized mortality rate associated with HIV/AIDS is observed in the Gambella region, with 78.4 (95UI: 46.01- 140.4) per 100,000 population, whereas the lowest mortality rate, 10.6 (95UI: 5.9- 20.4) per 100,000 population, is observed in the SNNPR. (Fig 6).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.g006\n\nThe highest age-standardized DALYs were also found in the Gambella region, with 4,220.7 (95UI: 2,515.2 - 7,592.7), followed by Addis Ababa with 3,271.3 (95UI: 2,180.2 - 5,339.9) Dire Dawa with 2,465.7 (95UI: 1,209.6 - 4,170.34) - and Afar with 1,701.7 (95UI: 974.3- 2,952.9). (Fig 7).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321024.g007\n\nThis study aimed to assess the overall burden of HIV/AIDS in Ethiopia using data from the Global Burden of Disease Study. In 2021, a total of 715,839 people were living with HIV in Ethiopia, representing a prevalence of 0.67%. This figure accounts for 1.8% of the global HIV/AIDS prevalence, with an estimated more than 40 million people living with HIV/AIDS worldwide [18]. The proportion attributed to Ethiopia demonstrates that, while the country is not among the highest contributors to the global burden compared to other Sub-Saharan African countries, it remains a critical area for intervention, particularly in Sub-Saharan Africa, where HIV/AIDS continues to be a leading cause of morbidity and mortality.\n\nThe overall prevalence increased from 0.3979% in 1990 to 1.1715% in 1998, after which it gradually declined to 0.6722% by 2021. The introduction of global and national HIV/AIDS programs likely played a critical role in controlling the epidemic and reducing the number of new infections.\n\nThe reduction of the HIV/AIDS burden can be attributed to the implementation of a variety of targeted programs. These include school-based HIV education programs, condom distribution initiatives, pre-exposure prophylaxis (PrEP), integrated Voluntary Medical Male Circumcision (VMMC) services, targeted outreach efforts, peer service provider (PSP) programs, and specialized HIV services for prisoners. Despite the decline, the prevalence remains a significant public health challenge, with substantial numbers of individuals requiring ongoing treatment and care. This trend underscores the need for sustained investment in prevention, treatment, and education programs to maintain the gains achieved and further reduce the burden of HIV/AIDS in Ethiopia.\n\nDespite a decrease in prevalence and incidence, females still disproportionately suffer from the burden of HIV. In 2021, significant inequalities were observed in prevalence, with males at 0.48% compared to females at 0.86%. The gender disparity in HIV prevalence can be attributed to multiple factors that increase women’s susceptibility to the virus. These include starting sexual activity at a younger age, engaging in sexual transactions with older men, and facing sexual violence [19]. Additionally, biological factors contribute to a higher likelihood of HIV transmission from men to women, particularly among younger women [20].\n\nBetween 1990 and 2021, the overall mortality rate per 100,000 population demonstrated a gradual decline, decreasing from 14.2 to 13.6. A recent systematic review conducted in Ethiopia also revealed that 5% to 40.8% of patients died during the follow-up period [21]. While this modest reduction indicates some progress in public health and healthcare delivery, it also highlights the slow pace of improvement and the need for more targeted and effective policy measures to accelerate health outcomes. The slight decline in mortality highlights the need for policies that improve healthcare access and quality, especially in underserved areas. Investments in healthcare infrastructure, preventive care, and workforce training are essential. Strengthening health data systems and community-based programs can support evidence-based planning and enhance health outcomes.\n\nIn 2021, a significant burden of disease was observed, with 839,819.31 Disability-Adjusted Life Years (DALYs) attributed to HIV/AIDS. This marks notable progress from 2016, when 1.1 million DALYs were reported [6]. The decline in DALYs indicates improvements in HIV prevention, treatment, and care strategies over the past few years. However, the continuing substantial burden emphasizes the need for sustained efforts to further reduce the impact of HIV/AIDS, particularly through expanded access to antiretroviral therapy, enhanced prevention programs, and addressing social determinants that contribute to the spread of the virus.\n\nDespite significant progress over the past 30 years, the COVID-19 pandemic may present challenges to the ongoing efforts to control the HIV epidemic in Ethiopia. A recent study highlighted a notable decline in several key indicators, including the number of HIV tests, consultations, viral load tests, antiretroviral therapy (ART) initiations, and ART adherence [22]. Similar studies also assert that the pandemic has disrupted routine clinical care and treatment, leading to treatment failures and increased drug resistance [23,24].\n\nThe findings indicate that the Gambela region (western Ethiopia) faces a disproportionately high burden of HIV/AIDS, as reflected in higher incidence, mortality, and DALYs compared to other regions. Addis Ababa and Dire Dawa also showed significant HIV/AIDS prevalence, but the extent of the burden in Gambela is notably greater. A recent study corroborates these findings, highlighting a persistent and high prevalence of HIV/AIDS in these regions [25,26,27]. There is a need for region-specific policies that focus on improving access to HIV prevention, testing, and treatment services, particularly in the Gambela region. This includes enhancing healthcare infrastructure, increasing availability of antiretroviral therapy (ART), and expanding HIV awareness programs. Additionally, addressing social determinants such as poverty, education, and healthcare access can help reduce vulnerability to HIV. Ensuring equitable distribution of resources and strengthening local healthcare systems are critical steps to improving outcomes in these high-burden regions.\n\nThe study has several strengths and a few limitations. Several strengths include providing valuable insights over a long period (1990–2021) using data from the Global Burden of Disease Study, ensuring credibility and national relevance. It also offers a comprehensive national perspective on the HIV/AIDS burden, making it useful for policymakers and healthcare planners. Additionally, the use of a globally recognized dataset enhances the reliability of the findings. However, the study is limited by its reliance on secondary data, which may not capture local nuances or emerging trends. The lack of primary data means specific regional challenges might be overlooked, and variations in reporting methods over time could affect data consistency.\n\nThe findings indicate significant progress in the fight against HIV/AIDS in Ethiopia, demonstrated by notable declines in incidence, mortality, and DALYs over the past three decades. Despite these achievements, challenges such as persistent gender disparities and regional inequalities remain, with the Gambela region continuing to experience a high burden of the disease. While past interventions have contributed to improvements, sustained efforts are necessary to maintain these gains and address ongoing disparities.\n\nPolicymakers should focus on gender-sensitive, age-specific interventions. For women, empowerment programs, access to reproductive health services, and prevention methods like PrEP should be prioritized. For adolescent girls and young women (AGYW), comprehensive sexual education, skills training, and economic empowerment programs are essential to reduce vulnerability. For older adults, HIV awareness and treatment services should be targeted to ensure access, including tailored counseling and ART.\n\nIn high-burden regions like Gambela, region-specific interventions are needed. These should include improving access to care, enhancing community-based prevention, and reducing stigma through outreach and education.\n\nPrevention efforts should address high-risk populations with targeted programs for those engaging in risky behaviors, such as sex workers and drug users, with age-specific harm-reduction programs.\n\nTo ensure equitable access to treatment, focus on women of reproductive age by providing ART and maternal health services to prevent mother-to-child transmission. For children and adolescents, expanding access to pediatric ART and involving caregivers in treatment plans will be vital.\n\nMaintaining strong surveillance systems that capture age- and gender-specific data will guide targeted interventions. Strengthening community-level health programs by engaging local leaders and establishing peer support networks for different age groups is essential.\n\nhttps://doi.org/10.1371/journal.pone.0321024.s001\n\n(PDF)",
    "category": "immunology"
  },
  {
    "title": "Extra virgin olive oil mitigates lung injury in necrotizing enterocolitis: Effects on TGFβ1, Caspase-3, and MDA in a neonatal rat model",
    "authors": "Mustafa Tuşat, Recep Eröz, Ferhan Bölükbaş, Erkan Özkan, Mehmet Semih Demirtaş, Hüseyin Erdal, Osman Okan Özocak, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0320938",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320938",
    "content": "Necrotizing enterocolitis (NE), which is common in premature babies, has been associated with lung damage. Our aim is to explore the effect of enterally administered extra virgin olive oil (EO) with rich polyphenol content on clinical parameters, histopathological score,Transforming growt factor beta-1(TGFβ1), Caspase 3 and Malondialdehyde (MDA) levels in NE-related lung injury of neonatal rats.\n\nThree groups (control, NE, NE+EO) were created, with 8 neonatal rats in each group. NE was induced by hypoxia-hyperoxia-hypothermia and formula feeding. EO was given to the treatment group by orogastric probe for 3 days. Intestinal and lung tissue were excised for analysis.\n\nTGFβ1expression levels, TGFβ1 and MDA concentration levels were higher in the NE compared to NE +  EO and control groups (p < 0.001), and their levels decreased after EO treatment compared to the NE group (p < 0.001). It was determined that EO treatment significantly reduced the histopathological damage and the caspase-3 (CASP3) expression level in the lung (p < 0.001).\n\nOur findings emphasize thatTGFß1has an crucial function in NE-related lung injury and that EO has therapeutic potential in NE-related lung injury.\n\nCitation:Tuşat M, Eröz R, Bölükbaş F, Özkan E, Demirtaş MS, Erdal H, et al.  (2025) Extra virgin olive oil mitigates lung injury in necrotizing enterocolitis: Effects on TGFβ1, Caspase-3, and MDA in a neonatal rat model. PLoS ONE 20(4):\n           e0320938.\n        \n        https://doi.org/10.1371/journal.pone.0320938\n\nEditor:Rami Salim Najjar, Georgia State University, UNITED STATES OF AMERICA\n\nReceived:September 28, 2024;Accepted:February 21, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Tuşat et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All data underlying the findings described in the article are available at URL passcode ''https://osf.io/6za8q/'' and DOI number ''' DOI10.17605/OSF.IO/6ZA8Q'' in a public repository. All data were also uploaded to PLOS ONE as supporting information in the form of an excel file.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nNecrotizing enterocolitis (NE) is a life-threatening gastrointestinal problem characterized by inflammation, necrosis and frequently affecting the terminal ileum and colon, seen especially in premature newborns in the presence of various risk and etiological factors [1]. It is known that NE affects many organs [2] and lung damage occurs in 10–15% of premature babies with NE [3]. This lung damage is an important complication of NE, and NE is an important predisposing risk factor for the development of more severe lung damage than broncho pulmonary dysplasia (BPD), which can often be observed in premature babies [2,4].\n\nTransforming growth factor-beta-1(TGFβ1) is a member of the TGF-β family of growth factors, which has various physiological roles such as apoptosis, inflammation, proliferation, differentiation, and control of immune function, andTGFβ1is theTGFisoform most frequently formed in tissue damage [5].TGFβ1exerts its effects through thesmall mother against decapentaplegic (SMAD)/TGFβ1cascade. SMAD proteins are nuclear proteins inTGF-βsignaling. InSMAD/TGFß1signaling, TGFß1 first binds to TGF-ß receptor (TßR)1 and 2 receptors and then TßR-1 phosphorylates SMAD2 and SMAD3 proteins, enabling the activation of these structures. Activated SMAD2 and SMAD3 proteins form a complex with SMAD4 and translocate to the nucleus to regulate transcription in genes whereTGFβ1is effective [6].\n\nCaspase-3 protein is a member of the cysteine-aspartic acid protease (caspase) family and is encoded by thecysteinyl aspartate-specific proteinase-3(CASP3) gene (located on the long arm of Chromosome 4 (region 4q35.1) and contains nine exons) is a common key enzyme of the execution phase of cell apoptosis and pyroptosis pathways [7]. Caspases are synthesized in the pro-caspase form, i.e., as inactive zymogens, and are activated upon appropriate stimulation. In response to apoptotic signaling events, CASP3 is cleaved and activated by upstream initiator caspases (caspase-8,10) and transported to the nucleus to cleave nuclear proteins, resulting in apoptotic nuclear changes [7,8].\n\nIt is known thatTGFβ1plays a role in lung damage in which sepsis, fibrosis, inflammation and epithelial-mesenchymal transformation (EMT) occur [9,10]. It has been reported that pro-inflammatoryTGFβ1cytokine levels are increased in the lungs of babies with neonatal hyaline membrane disease and neonatal BPD [11] and that the expression and protein levels of proinflammatoryTGFβ1increase in the bronchoalveolar-lavage fluid (BALF), lung tissue in acute lung injury (ALI) and bleomycin-induced lung fibrosis [12,13].\n\nExtra virgin olive oil (EO), fundamental component of the Mediterranean diet, has positive effects on human health mainly caused by the polyphenol content of EO [14]. In studies conducted on humans and animals in vivo or in vitro, EO has beneficial effects resulting from its anti-inflammatory, antioxidant and antimicrobial properties [1,14,15]. Enteral administration of tyrosol (Tyr), Oleuropein (Ole) and hydroxytyrosol (HTyr), which are polyphenol compounds of EO, reduces lipopolysaccharide (LPS)-induced ALI by inhibiting inflammation and oxidative stress (OS) [16–19]. The unsaponifiable fractions of orally administered EO reduce aluminum chloride (AlCl3) and acrylamide-induced lung and DNA damage [20], and Ole has an antifibrotic effect by exhibiting anti-inflammatory and antioxidant properties in bleomycin-induced lung fibrosis in rats [21]. In a study investigating the effect of orally administered 25% HTyr containing olive leaf extract on rats with the acetic acid-induced colitis model, it was shown that HTyr inhibited OS and inflammation by reducing colonic MDA andTGFB1expression [22]. In dextran sodium sulfate-induced colitis models, it was determined that the use of EO caused a significant decrease in the expression levels ofTGFB1andCASP3in colon tissue and alleviated inflammation [23,24]. It has been reported that intraperitoneal and oral administration of olive oil significantly reduced the levels of MDA and TGFβ1 in liver tissue in mice with carbon tetrachloride (CCl4)-induced liver fibrosis [25–27]. It has been reported that Tyr caused significant decreases in MDA andCASP3expression levels in rats with testicular damage caused by AlCl3[28]. In vitro renal hypoxia model induced by cobalt chloride (CoCl2) using human renal proximal tubular cells (HK-2), it was observed that the application of HTyr caused a significant decrease in theTGFB1gene expression levels, which is effective in inflammation and fibrosis [29]. It was detected that oral administration of EO rich in triterpenic acids for 8 weeks caused a significant decrease inTGFB1level and reduced collagen accumulation in the arterial walls of hypertensive rats [30]. A strong correlation between serum MDA and placental TGFB1 has been shown in preeclamptic rats, and researchers reported that EO treatment reduced abnormally elevated levels of MDA and TGFB1 in placental tissue [31]. Another study reported that treatment with Ole reduced CASP3 expression in brain tissue in a mouse model of hypoxic-ischemic encephalopathy [32]. It has been reported that phenolics secoiridoids such as HTyr, Ole aglycone in EO, act as anti-aging phytochemicals by inhibitingTGFB1-induced fibrogenic and oncogenic EMT in Madin–Darby canine kidney (MDCK) cells and human breast cancer (MCF-7) cells [33]. In addition, in our study investigating the protective effect of EO on the intestines of rats with experimental NE, we detected that EO treatment exhibited anti-inflammatory, antioxidant, anti-apoptotic and cytoprotective effects by significantly reducing the levels of MDA, interleukin 1 beta (IL1β), interleukin 6 (IL6), Epidermal growth factor (EGF) and the number of CASP3 positive cells (Casp-3+cells) [1]. Considering the anti-inflammatory, antioxidant and antimicrobial properties of EO and related studies, it is likely that EO has a positive effect on NE-related lung damage. To our knowledge, the effect of EO rich in phenol content on lung damage in rats with NE has not been investigated.\n\nIn our study, we aimed to evaluate the impact of enterally administered EO with rich polyphenol content on clinical parameters, histopathological scoring (HPS), Casp-3+cells,TGFβ1gene expression level and both TGFβ1, MDA lung tissue homogenate level on lung damage caused by the NE model experimentally created in rats.\n\nFor this study, approval was received from the Animal Experiments Ethics Committee of Aksaray University Experimental Animals Application and Research Center (dated 24/04/2024 and decision number 2024/04–16) and the National Institute of Health’s Guide for the Care and Use of Laboratory Animals was followed throughout the experiment and all procedures are reported in accordance with ARRIVE guidelines. Neonatal rats were sacrificed with high doses of ketamine and xylazine before surgical procedures. Every effort was made to minimize pain during the experimental procedures.\n\nNeonatal rats used in the study were obtained from Aksaray University Animal Experiments Application and Research Center. For the study, 4 Wistar Albino female rats, 10–12 weeks old and weighing 200–250 g, were impregnated and kept with in a 12-hour light/dark environment, at 23 ±  1 ˚C temperature and 55–60% humidity in polycarbonate cages. Pellet feed and drinking water were provided ad libitum. Starting from the 20th day of pregnancy, the rats were transferred to cages and monitored. As birth approaches, the frequency of observation was increased. Births were carried out under the supervision of a veterinarian, and neonatal rats were randomly divided into 3 groups, with 8 members. To avoid the protective effect of breast milk, neonatal rats to be induced NE were taken from their mothers immediately after birth and placed in an incubator with a temperature of 37 °C and 65–70% humidity, 12 hours dark and 12 hours light. The health and behavior of neonatal rats were monitored hourly during the experiment. Our research team included a veterinarian and the other researchers were certified in the handling of experimental animals. Induction of NE was performed for 3 days and rats were sacrificed on the morning of day 4 performed by intraperitoneal administration of 10 mg/kg xylazine and 90 mg/kg ketamine [34]. Acetominophen was prepared to be administered oragastrically at a dose of 200mg/kg in the event that pain signs were observed in rats [35].\n\nNeonatal rats in group 1 (Control) stayed with the mother and were fed with breast milk, and this group was not exposed to any procedures. NE induction to the rats in group 2 (NE) and group 3 (NE+EO) was performed according to the model specified by Güven et al. [36]. For NE induction, neonatal rats were fed with formula consisting of a mixture of 100 cc puppy milk (Baephar-Bogena. BV Sedel. The Netherlands) and 20 g similac 60/40 (Ross-Pediatrics. Columbus. Ohio) by gavage and 0.2 ml each time. The daily dose was increased by 0.1ml according to tolerance. Additionally, neonatal rats were exposed to 100% Carbon dioxide (CO2) inhalation for 10 minutes, followed by 97% Oxygen (O2) inhalation for 5 minutes, and cold for 5 minutes at + 4°C, twice a day for 3 days [36]. EO, which contains rich polyphenols, was given to neonatal rats in Group 3 at a dose of 2ml/kg via oral gavage for 3 days. Baby rats in control and NE groups were given distilled water at a dose of 2ml/kg via oral gavage. EO (Sidyma, Muğla, Turkey), which contains rich polyphenols with a polyphenolic content of 832mg/kg, was purchased from the local market and the polyphenolic compound levels and fatty acid levels are stated inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t001\n\nIn order to prevent unnecessary pain, suffering and stress in animals used in research, which are both ethically and scientifically important, the humane endpoint criteria specified in the studies were complied with in our study. The Humane endpoints in our study address the physical and psychological status of the animals, such as general health, behavioral changes, pain, weight loss, loss of appetite, and respiratory distress [37]. In our study, if the threshold values of these criteria were reached, euthanasia was performed with intraperitoneal administration of 10 mg/kg xylazine and 90 mg/kg ketamine [34]. The humanitarian endpoint criteria established in the study were evaluated. These criteria are\n\nIn the present study, humane endpoints were tabulated and neonatal rats were monitored hourly throughout the experiment. On the 3rd day of the study, loss of movement and severe respiratory distress were observed in an animal in the NE group. Since the humane endpoint criterion was reached before the end of the experimental period, the neonatal rat was euthanized with high dose anesthesia 15 minutes after the determination of the humane endpoint criterion under the control of a veterinarian. In our study, there were no rats that died without meeting the euthanasia criteria. The other 23 neonatal rats used in our study completed the experiment without reaching the human endpoint criteria.\n\nNeonatal rats were weighed every day throughout the experiment with a very sensitive balance, including birth weight (BW) and last day weight (LW). The daily CIS of neonatal rats was evaluated according to the scoring system determined by Zani et al [38]. For this purpose, a blind observer calculated a CIS. Deaths due to NE and other causes were recorded daily throughout the experiment.\n\nOn the morning of day 4 of the experimental model, neonatal rats were sacrificed with a high dose of anesthetic drug. After entering the abdomen through a median incision and the thorax through a sternotomy, the abdomen and chest cavity were explored. Macroscopic evaluation was performed according to the method described by Zani et al. and bowel macroscopic score (BMS) was calculated [38]. Then, 3 cm of intestine was excised, including the terminal ileum and proximal colon. In the lung tissue sample, the lower lobe of the right lung was excised. Half of the samples were reserved for immunohistochemical and histopathological analysis, while the other half were washed with saline and stored at –80 °C for genetic and biochemical investigations\n\nThe tissues were rinsed with pre-cooled PBS to completely remove excess blood before homogenization. Then, an equal weight of tissue (~70 mg) from each group was weighed using a precision scale. Following, 1ml of 1X pre-cooled PBS was added on the tissues and homogenizated via bead mill homogenizer (Scientific industries, digital disruptor genie Cat no:si-dd38) at 2000 rpm for 5 minutes. Finally, the supernatant were collected and stored in aliquots at ≤  –20 °C for ELISA.\n\nLung tissue samples from whole rats were analyzed in duplicate. TGFβ1 lung tissue levels were analysed by ELISA method with RatTGFβ1ELISA Kit [catalog number: ELK2311]. The analysis results were expressed as nanograms/milliliter (ng/mL). The MDA lung tissue levels were analysed with ELISA method and ELK Biotechnology Rat MDA ELISA Kit [catalog number: ELK8612].\n\nTissue specimens were fixed in 10% formalin and embedded in paraffin blocks. Sections (6 µm thick) were taken from the blocks and stained with the Hematoxylin-eosin [39] method for histopathological examination. The prepared preparations were examined under a microscope (Leica DM2500, Leica Microsystems GmbH, Germany) and photographs of the necessary areas were taken with a digital camera (Leica DFC 320). Changes observed as a result of histopathological examination of preparations stained with hematoxylin-eosin were scored between 0 and 4. Scoring was performed according to the method described by Caplan 1994 [40]. NE is indicated by a score of 2 or higher, while severe NE is indicated by a score of 3 or higher.\n\nLung tissue specimens taken from newborn rats were fixed in 10% formalin for 24 hr, underwent a series of histological preparations and, were sectioned into 6 μm thick tissue sections using a rotary microtome. The sections were stained with Hematoxylin-eosin staining method [39]. Histopathological evaluations were performed using a modified version of the scale developed by the American Thoracic Society (ATS), Made according to Drucker et.al. 2018 (Table 2). Scores from 0 (normal) to 2 (acute lugn injury) are given for six different parameters and added up to obtain a score between 0 and 12; 0 indicates normal lung, and 12 indicates severe acute injury with bleeding [41,42].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t002\n\nStaining of tissue samples taken for immunohistochemical procedures was carried out with a procedure based on streptavidin-biotin-peroxidase complex (sABC). For this purpose, 6 µm thick sections taken on poly L-lysine coated slides were dried by keeping them in an oven at 37oC overnight. Subsequently, the sections were deparaffinized and rehydrated and boiled in a microwave oven in citrate buffer solution (pH 6) for 5 minutes for antigen retrieval. To inhibit endogenous peroxidase activity, the sections were kept in 3% hydrogen peroxide solution for 20 minutes and nonspecific binding sites were blocked by incubating in blocking solution (Thermo Fisher Scientific Inc., UK) for 5 minutes. The sections were then incubated with the primary antibody (Caspase-3 (STJ97448, St John’s Laboratory, 1:200 dilution) for 1 hour at room temperature, followed by biotinylated goat polyvalent antibody (Thermo Fisher Scientific Inc., UK) for 30 minutes. Sections washed with buffered phosphate saline (PBS, Biotech) were incubated with streptavidin-peroxidase (HRP, Thermo Fisher Scientific Inc., UK) for 30 min at room temperature. While DAB (3–3’-diaminobenzidine, Thermo Fisher Scientific Inc., UK) was used as chromogen, Mayer’s hematoxylin solution was preferred for nuclear staining. Negative control preparations were prepared by incubating tissue sections with PBS instead of primary antibody. The stained sections were covered with coverslips using synthetic adhesive (Entellan, Merck) after being dehydrated through a graded alcohol series and passed through xylene.\n\nAll preparations were examined under a light microscope (Leica DM2500) and then were photographed by a digital camera (Leica DFC 320). In the sections stained with the immunohistochemical method, all Casp-3+cells were counted in 6 different randomly selected regions of 10.000 µm2at x400 magnification. All evaluations were performed by two researchers blinded to the sample identification.\n\nRNA was isolated from lung samples via both Hybrid-R (Catalog No: 305–101) and RiboEx (Catalog No: 301–001) isolation kits base on the manufacturer’s protocol. cDNA, copy of the RNA molecule, was obtained using A.B.T.™ cDNA Synthesis Kit with Rnase Inh. (High Capacity) cDNA synthesis kit (Catalog No: C03–01–05) via ProFlex thermalcycler. A total 20 µ L mastermix (10 µl isolated RNA sample, 0.5 µl RNase Inhibitor, 2 µl Random hexamer, 2 µl 10X Reaction Buffer, 1 µl 20X dNTP mix, 1 µl RTase, 3.5 µl RNase free water) was used for cDNA synthesis. cDNA synthesis condition were at 25 °C for 10 m in step 1, at 37 °C for 120 m in step 2, at 85 °C for 5 m in step 3 and finally at 4 °C for ~  m.\n\nThe following primers were used for the genes expression\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t003\n\nFor each cDNA sample, expression ofTGF1βand the reference gene (GAPDH) were detected via the Applied Biosystems™ QuantStudio5 Real-Time PCR System. Polymerase chain reactions (PCRs)were performed using Mastermix that include 4 μl cDNA Template, 10 μl 2X MasterMix (with SYBR-Green), 1 μl Forward Primer (10 μM), 1 μl Reverse Primer (10 μM), 3 μl RNase-Free Distilled Water, 1 μl ROX Dye with a final volume of 20 µ L.\n\nCycle conditions of PCR were 1 cycle initial denaturation at 95 °C for 300 sec, 40 cycles denaturation at 95 °C for 15 s and 40 cycles annealing at 60 °C for 60 second. TheGAPDHwas used as reference gene and fold Change had been calculated.\n\nThe Statistical Package for Social Sciences (IBM Corp., Armonk, NY, USA) 22.0 were used for the data analyze (S1 Dataset). Resource Equality Method, which is a frequently used method, based on the Degrees of Freedom error was used to determine the number of subjects to be assigned to groups. The distribution of data was detected via Shapiro Wilk test. The descriptive statistic was done. Because the normally distribution of data (p >  0.05), One-Way Anova test was used for each group comparisons. Since the variances of the groups were homogeneous, Tukey HSD test was used. Also polynominal regression test was carried out. The p <  0.05 was accepted as statistically significant.\n\nOn the 3rd day of the study, one rat in the NE group showed signs of human endpoint and the neonatal rat was euthanized and subsequent laparotomy revealed necrosis and perforation in the terminal ileum. There were meaningful differences among the groups for LW, BMS, CIS, TGFβ1 expression,MDA and TGFβ1 concentration levels (p < 0.05) (Table 3,Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t004\n\nThree main groups rats as control, NE, and NE+EO each of them with 8 members were included in the study. BothTGFβ1gene expression and concentration levels, MDA concentration levels, histopathological scoring and Casp-3+cells count/unit area of groups were detected. As a response to the cellular damage caused by NE, the expression and translation levels of the different genes may be changed in the nucleus of cells. Depending on the NE, the lung tissue concentration level of MDA significantly increased (a). Also the histopathological scoring (H&E scored 0–12) (b) and Casp-3+cells count/unit area (c) in lung tissue significantly increased depending on the NE injuries. TheTGFβ1gene is transcribedTGFβ1mRNA, andTGFβ1proteins are translated from matureTGFβ1mRNA. There was statistically significant differences among the groups in terms ofTGFβ1 geneexpression levels. The expression level ofTGFβ1gene significantly increased depending on the NE injuries (d). Also depending on the NE, the lung tissue concentration level ofTGFβ1significantly increased (e). It may be said that, the EO has an important protective effect against lung tissue damage caused by NE injuries.\n\nThree main groups rats as control, NE, and NE+EO each of them with 8 members were included in the study. BothTGFβ1gene expression and concentration levels, MDA concentration levels, histopathological scoring and Casp-3+cells count/unit area of groups were detected. As a response to the cellular damage caused by NE, the expression and translation levels of the different genes may be changed in the nucleus of cells. Depending on the NE, the lung tissue concentration level of MDA significantly increased (a). Also the histopathological scoring (H&E scored 0–12) (b) and Casp-3+cells count/unit area (c) in lung tissue significantly increased depending on the NE injuries. TheTGFβ1gene is transcribedTGFβ1mRNA, andTGFβ1proteins are translated from matureTGFβ1mRNA. There was statistically significant differences among the groups in terms ofTGFβ1 geneexpression levels. The expression level ofTGFβ1gene significantly increased depending on the NE injuries (d). Also depending on the NE, the lung tissue concentration level ofTGFβ1significantly increased (e). It may be said that, the EO has an important protective effect against lung tissue damage caused by NE injuries.\n\nhttps://doi.org/10.1371/journal.pone.0320938.g001\n\nHPS of bowels, Casp-3+cells and HPS for lungs were significantly difference among the goups (p < 0.001) (Table 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t005\n\nThe lungs of rats in control group showed normal histology. In NE group, significant histopathological lesions such as neutrophil infiltration, hyperemia, bleeding, and thickening of the interalvelor septum were detected in the lung tissue. It was observed that the histopathological damage to the lung was importantly reduced in the NE+EO group (p < 0.001) (Tables 4,5Fig 2A,2B,2CS1 Fig,S2 Fig,S3 Fig).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t006\n\nA. Control group, Bar: 100µm, B. NE group showing increased neutrophil infiltration and severe lung tissue damage, C. Treatment group. Haemotoxylene-Eosin staining (H-E) Bar: 50µm.\n\nA. Control group, Bar: 100µm, B. NE group showing increased neutrophil infiltration and severe lung tissue damage, C. Treatment group. Haemotoxylene-Eosin staining (H-E) Bar: 50µm.\n\nhttps://doi.org/10.1371/journal.pone.0320938.g002\n\nImmunohistochemically, CASP3 activity was evaluated to detect the apoptosis process in the lung in all groups. It was determined that CASP3 expressions increased in the lung cells of the NE group. It was observed that CASP3 expressions decreased significantly in the NE+EO group (p < 0.001) (Table 4,5Fig 3B,3C,3DS4 Fig,S5 Fig,S6 Fig,S7 Fig).\n\nA. Negative control. B. Control group. C. NE group, D. Treatment group. Arrowhead: Casp-3+negative cells. Arrows: Casp-3+cells. It is noteworthy that Casp-3+cells were more numerous in the NE group than in the treatment group. Streptavidin-biotin-peroxidase method, Bar: 50µm.\n\nA. Negative control. B. Control group. C. NE group, D. Treatment group. Arrowhead: Casp-3+negative cells. Arrows: Casp-3+cells. It is noteworthy that Casp-3+cells were more numerous in the NE group than in the treatment group. Streptavidin-biotin-peroxidase method, Bar: 50µm.\n\nhttps://doi.org/10.1371/journal.pone.0320938.g003\n\nAccording to binary comparison, important differences between NE and NE+EO, between control and both NE and NE+EO were detected in terms of LW, CIS and BMS (p ≤ 0.001), (Table 5).\n\nAlso meaningful differences between NE and NE+EO, between control and NE were detected in terms ofTGFβ1Expresssion Levels, Concentration Levels of TGFβ1 and MDA (p < 0.001), (Table 5).\n\nWhen the Casp-3+cells and HPS for lungs to be considered, statistically significant differences between NE and NE+EO, between control and both NE and NE+EO were detected (p ≤ 0.001), (Table 5).\n\nAccording to polynominal regression analaysis results, meaningful relations were detected between TGFβ1 Concentration levels and all of LW, CIS, BMS, MDA,TGFβ1Expressions, Casp-3+cells and HPS for lung (p < 0.001) (Table 6,Fig 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t007\n\nThere were statistically significant relation between TGFβ1 concentration levels and all of last day weight (b), clinical disease score(c), bowel macroscopy(d), MDA concentration levels (e), Caspase-3 positive cell count/unit (f) and histopathological scoring (H&E scored 0–12) (g). Conversly the relation between TGFβ1 concentration and birth day was not significant (a).\n\nThere were statistically significant relation between TGFβ1 concentration levels and all of last day weight (b), clinical disease score(c), bowel macroscopy(d), MDA concentration levels (e), Caspase-3 positive cell count/unit (f) and histopathological scoring (H&E scored 0–12) (g). Conversly the relation between TGFβ1 concentration and birth day was not significant (a).\n\nhttps://doi.org/10.1371/journal.pone.0320938.g004\n\nAdditionally, there were meaningful relations between MDA and all of LW, CIS, BMS,TGFβ1Expressions, Casp-3+cells and HPS for lung (p < 0.001) (Table 6,Fig 5).\n\nThere were statistically significant relation betweenMDAconcentration levels and all of last day weight (b), clinical disease scor(c), bowel macroscopy(d), Caspase-3 positive cell count/unit (e) and histopathological scoring (H&E scored 0–12) (f). Conversly the relation between MDA concentration and birth day was not significant (a).\n\nThere were statistically significant relation betweenMDAconcentration levels and all of last day weight (b), clinical disease scor(c), bowel macroscopy(d), Caspase-3 positive cell count/unit (e) and histopathological scoring (H&E scored 0–12) (f). Conversly the relation between MDA concentration and birth day was not significant (a).\n\nhttps://doi.org/10.1371/journal.pone.0320938.g005\n\nWhen TGFβ1 expression levels to be considered, meaningful relation betweenTGFβ1expression levels and all of LW, CIS, BMS, MDA, Casp-3+cells, HPS and TGFβ1 Concentration levels detected for lung (p < 0.001) (Table 7,Fig 6).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320938.t008\n\nThere were statistically significant relation betweenTGFβ1expression levels and all of last day weight (b), clinical disease scor(c), bowel macroscopy(d), MDA concentration levels (e), Caspase-3 positive cell count/unit (f), histopathological scoring (H&E scored 0–12) (g) andTGFβ1concentration levels (h). Conversly the relation betweenTGFβ1expression levels in lung tissue and birth day was not significant (a).\n\nThere were statistically significant relation betweenTGFβ1expression levels and all of last day weight (b), clinical disease scor(c), bowel macroscopy(d), MDA concentration levels (e), Caspase-3 positive cell count/unit (f), histopathological scoring (H&E scored 0–12) (g) andTGFβ1concentration levels (h). Conversly the relation betweenTGFβ1expression levels in lung tissue and birth day was not significant (a).\n\nhttps://doi.org/10.1371/journal.pone.0320938.g006\n\nIn lung injury, various studies have been conducted about the role of genetic markers such asNF-κB, the cysteinyl aspartate‐specific proteinase‐8 (CASP8), Mitogen-activated protein kinase 1 (MAPK1), the cysteinyl aspartate‐specific proteinase‐3 (CASP3), Beclin-1 and Ribosomal Deoxyribonucleic Acid (rDNA)genes in the maintaining cellular homeostasis and viability [7,43–46].\n\nTo our knowledge, our study is the first that showed EO with rich phenol content administered by gavage in the hypoxia-hypothermia-hyperosmolar food-induced NE model of rats, which significantly reduces TGFß1 and MDA tissue homogenate levels, expression level of TGFß1 gene and tissue damage in the lung tissue (p < 0.05). We detected that in contrast to the LW, all of CIS, BMS and HPS were importantly higher in NE induction group than in healthy group. Because of one rat received 2 points, four rats received 3 points and three rats received 4 points in the HPS of the intestine, we concluded the adequacy of the model in creating NE.\n\nIt was reported that NE causes an increase in inflammation in the lungs, neutrophil infiltration, significant histopathological changes such as thickening and bleeding in the alveolar septum [2,4,42,47–49], and an increase in apoptosis [2,47,48]. We detected significant histopathological lesions such as neutrophil infiltration, hyperemia, bleeding, and thickening of the interalvelor septum in the lung tissue of NE group. The HPS and Casp-3+cells numbers in the lung tissue were significantly decreased in the NE + EO group compared to the NE group (p < 0.001, p < 0.001 respectively). We determined that enteral EO administration reduced apoptosis by decreasing Casp-3+cells in the lung tissue and had a histological protective effect on NE-related lung damage.\n\nOlive oil (olivea oleum), an important part of the Mediterranean diet, is grown throughout the Mediterranean basin and is obtained from olives [50] by mechanical pressing and contains relatively high amounts of polyphenolic [51]. The main components of EO are fatty acids (95–99%) composed of 55–83%monounsaturated fatty acids (MUFA) (especially oleic acid), 4–20% polyunsaturated fatty acids and 8–14% other fatty acids. The remaining part is minor polar compounds constitute 1–2% of EO and include tocopherols, phytosterols, squalene and phenolic compounds with important biological activities [52]. In EO, phenolic compounds are generally found in concentrations ranging from 50 to 940 mg/kg [53]. EO contains at least 36 different phenolics such as HTyr, Tyr, Ole, Ole aglycone, oleocanthral, flavonoids and lignans. The number and concentration of these compounds depend on the variety and maturity of the olive, the age of the tree, the region where it is grown, the time of harvest, the method of production and storage conditions. While refining EO by exposing to chemical processes does not cause any change in its fatty acid components, it causes a decrease or even disappearance in the amount of phenolic compounds of it [51,52]. It has been shown that these phenolic compounds, which are responsible for the main biological properties of EO, have effects such as antioxidant [1,22,54,55], anti-inflammatory [1,22,55], antimicrobial [56], neuroprotective [57], anti-apoptotic [1,22] and antidysbiotic [58].\n\nIn the literature, many studies have been conducted on the therapeutic efficacy and relationship with molecular mechanisms of EO and its phenolic compounds. In rats with testicular damage induced by AlCl3, while MDA levels increased, glutathione (GSH) and Catalase (CAT) activity decreased, but Tyr significantly improved these values in the testes. In addition, spermatological parameters such as motility, dead/live and abnormal spermatozoa ratios, testicular biopsy scores, bothCASP3andB-cell lymphoma gene-2(Bcl-2)expression levels were observed to improve significantly with Tyr treatment. It was detected that significantly decreased expression levels ofNuclear factor erythroid 2-related factor 2 (Nrf-2),which induces the production of many antioxidants and detoxification enzymes, andHeme oxygenase-1 (HO-1), a protective factor against OS, caused by AlCl3application, reached the levels measured in the control group with Tyr treatment. As a result, oral Tyr treatment for 10 weeks in AlCl3-induced testicular damage alleviates oxidant stress, increases antioxidant activity and reduces apoptosis by inducing the Nrf-2/HO-1 signaling pathway [28].\n\nIn a study investigating the effect of phenolics secoiridoids such as HTyr, Ole aglycone in EO onTGFB1-induced fibrogenic and oncogenic EMT in Madin–Darby canine kidney (MDCK) cells and human breast cancer (MCF-7) cells, it was determined that the expression of the epithelial marker E-cadherin decreased and the expression of the mesenchymal marker Vimentin increased withTGFß1induction in MDCK cells, and then after the cells were treated with EO, the expression of E-cadherin increased significantly and the expression of Vimentin was significantly inhibited. AlsoSnail family transcriptional repressor 2 (SNAI2), a transcription factor that promotes EMT, is up-regulated byTGFß1induction in MDCK cells, but EO treatment reverses this effect. The cellular changes observed inTGFβ1-induced MCF-7 breast cancer epithelial cells resembled tumor cells undergoing EMT, E-cadherin expression, which was decreased inTGFβ1-induced cells, was increased by EO treatment. Also,SMAD4andSNAI2expression, which promote EMT, were upregulated byTGFß1, whileSMAD4andSNAIexpressions were suppressed by EO treatment. In conclusion, it was reported that phenolics secoiridoids such as HTyr, Ole aglycone in EO, act as anti-aging phytochemicals by inhibitingTGFB1-induced fibrogenic and oncogenic EMT in MDCK cells and MCF-7 cells [33].\n\nOlive leaf extract containing 25% Htyr given orally for 1 week after induction of colitis in albino rats with rectal acetic acid reduced mortality rate and disease activity indices. While a significant decrease was observed in nitrite oxide (NO), MDA and myeloperoxidase (MPO), conversely a significant increase was detected in superoxide dismutase (SOD), CAT and glutathione peroxidase (GSH-Px) activities in the colon tissue of the treatment group. Additionally, significant decreases were detected in the expression levels of proinflammatory cytokines (PIC) (IL-1β, Tumor necrosis factor-alpha (TNF α), IL10),cyclooxygenase-2 (Cox-2),Inducible nitrite oxide synthase (iNOS),TGFβ1,monocyte chemoattractant protein-1 (MCP1)andnuclear factor kappa-B (NF-κB). Also, the apoptotic geneBcl-2-associated X protein(Bax) was downregulated, while the anti-apoptotic geneBcl-2was upregulated. As a result, it was reported that olive leaf extract enriched with HTyr reduced OS, inflammation and apoptosis in colitis-induced rat colon tissue [22]. In another colitis model induced with oral dextran sulfate, EO given by gavage for 11 days alleviated the clinical findings in mice and significantly decreased the gene expression levels ofIL-1β,TGFβ1andIL-6in colon tissue. In the histopathological examination, EO improved intestinal permeability and histopathological damage caused by inflammation [23].\n\nIn a liver fibrosis model induced by oral CCl4 administration for 8 weeks of rats, the CCl4 administration increased OS in the rat liver and caused significant increases in MDA levels, whereas EO administration during the induction period caused significant decreases in MDA levels by reducing lipid peroxidation. TheTGFß1,Toll Like Receptor 4 (TLR4),Reduced nicotinamide adenine dinucleotide phosphate(NADPH) oxidaseandNF-κBexpression levels were increased in the CCl4 group compared to the control group, but after the EO treatment these increased mRNA expressions were significantly decreased. In the western blot analysis, the levels of NADPH oxidase, NF-κB and TGFβ1 proteins, which were increased by CCl4 induction in the liver, were significantly reduced by EO treatment and as a result, it was reported that EO suppressed OS and inflammation [27]. In rats with hepatic toxicity induced by oral fluoxetine, both EO and olive leaf extract administered orally showed anti-inflammatory effects by significantly reducing Alanine Transaminase (ALT), Aspartate Transaminase (AST), alkaline phosphatase (ALP) and PIC (TNF-αandIL-1β) that increased in the circulation with fluoxetine induction. Histopathological analysis showed that abnormal histological changes accompanying inflammatory cell infiltration in the liver tissue were improved by the application of EO and olive leaf extract. EO and olive leaf extract reduce lipid peroxidation by causing significant decreases in MDA and NO levels in liver tissue, and also show antioxidant effects by significantly increasing the activities of SOD, CAT and GSH-Px, which are antioxidant enzymes that have decreased due to induction in liver tissue. The gene expression levels ofBaxandCASP3, which increased with fluoxetine induction, decreased significantly, while the gene expression level of decreasedBcl-2increased significantly with these treatments. As a result, it has been reported that both EO and olive leaf extract exhibit anti-inflammatory properties, reduce OS, increase antioxidant effect and also prevent apoptosis [59].\n\nIt was shown that triterpenic acids rich EO attenuated systolic and diastolic blood pressure increases in spontaneously hypertensive rats, increasedendothelial nitric oxide synthase(eNOS) expression in aortic tissue, reducedTNF-αlevels, and collagen accumulation in the arterial wall by causing a significant decrease inTGFB1, which regulates collagen accumulation [30].\n\nInflammation and OS has crucial role in the pathogenesis of lung injury, and infections, sepsis, environmental pollutants, smoking, allergens and genetic predisposition cause lung damage [60]. Since EO and phenolic compounds have the above-mentioned properties, they prevent lung damage by suppressing excessive amounts of PIC and OS in the pathogenesis of lung damage.\n\nIL-17A induces OS, DNA damage and apoptosis in the A549 human lung epithelial cell line in vitro, but Ole reverses these effects [61]. In a study examining the both effects of enterally administered Ole and silver nanoparticle-loaded Ole on lung tissue for 11 days on intraperitoneal LPS-induced ALI in albino rats, a significant decrease MDA and increase GSH and SOD activities were observed in both treatment groups. There was an important decrease the levels of PIC (TNF-α, IL-6 and IL-1β) in the rats given Ole treatment. These PIC were higher in the silver-loaded Ole treatment than the only Ole treated group, but were significantly reduced compared to the LPS induction rats. In addition,P2X purinoceptor 7 (P2X7R), Bax, IL-1β,TNF-α,and TLR4gene expressions were importantly higher in LPS-induced rats, and the expressions of these genes were significantly decreased in both treatment groups. The histological appearances in the lung were similar, and that both Ole and silver-loaded Ole treatment reduced OS, inflammation, tissue damage and apoptosis in the control and both treatment groups [62].\n\nIn ALI, which occurred after intratracheal LPS administration to rats for 20 days, it was seen that while neutrophils in the BALF and MDA levels increased in serum and lung tissue, the GSH levels, GSH-Px and CAT activities decreased. A significant increase in IL-6, TNF-α, MPO and NF-kB was observed in BALF, serum and lung tissue, in addition to interalveolar septum widened due to capillary hyperemia, edema and Polymorphonuclear leukocyte (PMNL) infiltration in the lungs after LPS induction. The vascular-bronchial interstitial edema, congestion and intense inflammatory cell accumulation occured. Oral administration of Ole simultaneously with LPS induction positively affects the above-mentioned biochemical and pathological changes in serum, BALF and lung tissue, and as a result, Ole causes significant improvements in the histological damage of the lung by reducing OS and inflammation [17].\n\nIn a study examining the effect of HTyr on lung damage caused by nasal LPS induction, it was found that HTyr reduced lung edema, inflammatory cells in BALF and lung tissue, and strongly regulated PIC as well as LPS-stimulated sirtuin (SIRT) expression and autophagy inhibition, Mitogen-activated protein kinase(MAPK) phosphorylation regulated by HTyr and ameliorates lung injury [18]. Exposure to 85dB noise and toluene inhalation for 6 weeks caused lung damage in rats, increased inflammation and OS, and olive extract given orally once a day for 6 weeks reduced MDA levels. It increases SOD and CAT activities and prevents lung damage by suppressing OS and inflammation by reducing PIC such as TNF-α and IL-1β [63]. In the study evaluating the effect of Tyr on ALI caused by LPS induction in mice, it was found that Tyr reduced PIC increased in BALF and lung tissue as a result of LPS induction. The activations of inflammatory molecules such as increased COX-2, iNOS and phosphorylated-IκBα were suppressed by the presence of Tyr in lung tissue. The increase in MPO and the decrease in SOD activities caused by LPS were inhibited by Tyr. In addition, Tyr reduced the expressions ofiNOS,COX-2and PIC and the nuclear translation ofNF-kBin LPS-stimulated RAW 264.7 macrophage, resulting in Tyr ameliorating LPS-related ALI, inhibiting NF-κB, reducing the release of PIC and it may be a potential therapeutic agent in inflammatory lung diseases [16]. In another study investigating the effect of Try on another LPS-induced mouse lung injury model, Tyr improved pulmonary permeability and histopathological changes, decreased the expression of PIC and increased the expression of antioxidant enzymes [19]. Pulmonary fibrosis is a response to endothelial and epithelial cells that are frequently damaged by the invasion of inflammatory cells. In the rat study investigating the effects of Ole on pulmonary fibrosis induced by intratracheal bleomycin, TNF-α, IL-13, TGFβ1, Platelet-derived growth factor (PDFG), lung collagen index and MDA increased significantly in BALF, but Ole prevented pulmonary fibrosis by reversing these effects [21].\n\nWhen the above detail studies conducted to show the effect of EO on markers known to be effective in anti-inflammatory (IL-1β, TNF α, IL10, IL-6, IL-17A, TGFB1, MAPK, Cox-2, iNOS, MCP1, NF-κB, eNOS, TLR4, NADPH, NF-κB, P2X7R, SIRT, IL-13, Nrf etc.), antioxidant (MDA, GS, CAT, Nrf-2, HO-1, NO, MPO, SOD, CAT, GSH-Px etc.) and antiapoptotic (CASP3, Bcl-2, Bax etc.) pathways to be taken into consideration, these clearly indicate the anti-inflammatory and antioxidant capacity of EO.\n\nNE is one of the leading causes of gastrointestinal-related mortality in premature babies [64]. Incomplete development of the intestinal mucosal barrier and immune system due to prematurity, increased OS as a result of inadequate antioxidant capacity, dysbiosis, and feeding with osmolar formulas are among the most important predisposing risk factors for NE [65]. While the severity of NE in the intestine is an important determinant of initial mortality in preterms with NE, long-term complications due to NE related the severity of other organ involvement, especially the lungs [66]. In particular, NE-related lung damage is more severe and more difficult to treat than BPD, which is frequently observed in the premature neonatal period [2,4]. The pathogenesis of NE-induced lung damage remains unknown, but current ongoing research focuses on explaining and preventing the mechanisms that lead to NE-related lung damage, which is an important cause of mortality and complication, in addition to studies on the etiopathogenesis and prevention of NE.\n\nTLR4, which plays an important role in the innate immune response to pathogens, is found in the intestine and lung, andTLR4activation plays a role in the intestinal and lung damage that occurs in NE [4].NF-κBis activated by theTLR4signaling transduction pathway, passes into the nucleus and causes increased gene expression of PIC [67]. In mice with NE induction, significant histopathological damage, increased neutrophil infiltration and MPO expression occured, but these effects were significantly improved with orally administered bovine milk exosome treatment.TLR4andNF-κBexpression significantly increased in the lungs of the NE group, conversely to the exosome treated group. While the levelof Nod-like receptor protein 3(NLRP3) mRNA expression increased in the lungs of NE group, exosome treatment did not reduce this increase, but the increased NLRP3 protein level in the NE group was significantly reduced with exosome treatment. Also significantly increased caspase 1 protein expression, another component of the NLRP3 inflammasome, was significantly decreased in the exosome-treated group. Results suggest that milk-derived exosomes have the ability to regulate NE-associated lung injury by inhibiting theNF-κBinflammatory pathway andNLRP3inflammasome activity [48].\n\nIn a study using human bronchial epithelial cell line (HBE 135-E6E7), mice and human tissues to elucidate the pathogenesis of NE-associated lung injury and to evaluate the efficacy of aerosolized C34, aTLR4receptor inhibitor, it was shown thatTLR4expression in lung tissue gradually increases after birth and that mice and premature infants with NE-associated lung injury express higher levels of pulmonaryTLR4than age-matched controls. The expression of proinflammatory moleculesiNOS,IL-8,TLR4and histopathological damage are significantly increased in both the intestines and lungs of premature infants with NE and NE-induced mice. In mice with transgenicTLR4deletion in the intestinal epithelium, no damage was observed in the intestines and lungs as a result of NE induction, whereas in mice with transgenicTLR4deletion in the lung epithelium, damage developed in the intestines but not in the lungs when NE was induced. As a result, it was reported that pulmonaryTLR4has a role in NE-associated lung injury and thatTLR4signaling is required in the intestines and lungs.TLR4activation in the intestinal epithelium of wild-type mice with NE induced the release of High mobility group box 1 (HMGB1) protein, a proinflammatory molecule, but did not induceHMGB1release in mice with TLR4 transgenically deleted in the intestinal epithelium, and the release ofHMGB1into the circulation in NE is dependent onTLR4signaling in the intestinal epithelium.HMGB1released into the circulation activates pulmonary epithelialTLR4, inducingCXC-Chemokine Ligand-5(CXCL5), a chemotactic cytokine for neutrophils, and thus causing lung injury due to the accumulation of proinflammatory neutrophils in the lung tissue. Also aerosolized application of theTLR4inhibitor C34 failed to prevent damage in the intestines of NE-induced mice, but significantly improved the histological appearance in the lung tissue and significantly reduced the expression ofIL-6,CXCL1andCXCL5in the lung tissue and the percentage of neutrophils in BALF. Finally, it has been reported that C34 interrupts theTLR4mediated neutrophil recruitment cascade in lung tissue [4].\n\nIn a study on the effects of Extracellular cold-inducible RNA-binding protein (eCIRP) on the severity of NE-associated intestinal injuiry and the effects of treatment with eCIRP scavenger peptide milk fat globule-epidermal growth factor VIII (MFG-E8) derived oligopeptide 3 (MOP3) [68], eCIRP levels in prospective stool samples of neonates with NE were reported to be 3.1-fold higher than in age-matched healthy controls. After NE induction, in addition to 64-fold increased systemic eCIRP levels in wild-type mice compared to mice with transgenic deletion of CIRP,IL-6, TNF-α, IL-1βgene expression and histopathological damage increased in lung tissue of wild-type mice, NE-compatible damage occurred in their intestines whereas no increase was observed in transgenic mice. It has been reported that apoptotic cells are significantly reduced in transgenic mice compared to wild-type mice and that eCIRP contributes to lung inflammation and injury in NE. In addition, MOP3 treatment reduces the severity of NE in the intestines by regulating systemic eCIRP, which increases as a result of NE induction. In lung tissue, MOP3 treatment has been reported to be effective in NE-associated lung injury because it significantly reduces histopathological damage and the number of apoptotic cells, as well as decreasing the mRNA levels ofIL-6, TNF-αandIL-1β[69].\n\nIt was observed that the mRNA expression levels ofIL-6,IL-1βandTNF-αincreased in both intestine and lung tissue of NE-induced mice and caused histopathological damage. The significant increase in the number of neutrophils in the alveolar interstitium of NE-associated lung tissue and in neutrophil elastase and MPO secreted by neutrophils suggest that neutrophils are important in the pathogenesis of lung injury. Stimulation of neutrophils purified from lung tissues with N-formyl-methionyl-leucy1-phenylalanine (fMLP), a neutrophil activator, showed a significant increase in reactive oxygen species (ROS) in the NE group compared to the control group. The N-Asetil Sistein (NAC) treatment administered to mice via the nasal cavity during the NE induction period resulted in significant decreases in histopathological damage, neutrophils, neutrophil elastas and MPO as well as mRNA expression levels ofIL-6,IL-1βandTNF-αin intestinal and lung tissues. Kelch-like ECH-associated protein 1 (Keap1) andNrf2gene expression levels decreased in NE-associated lung-injured tissue, and significant increases in these decreased gene expressions were recorded with NAC treatment. The mRNA expression levels ofHO-1, SOD1andNAD(P)H quinone oxidoreductase 1 (NQO1) genes controlled by the Keap1-Nrf2 pathway were decreased in NE-related lung tissue, but these levels are increased with NAC treatment. So it was concluded that the Keap1-Nrf2 pathway ultimately contributes to NEC-induced lung damage [70].\n\nIn another NE model, it was shown that lung and intestinal damage were more severe and IL-6 levels were higher in eNOS knockout mice than in wild-type mice. This effect was due to eNOS increasing NO synthesis in the mesentery, which indicates that it also modulates IL-6 release in addition to its antioxidant and vasodilator effects [42]\n\nUmbilical mesenchymal stem cells have been shown to reduce disease presumably via paracrine release of H2S in animal models of NE [71]. H2S, a gasotransmitter secreted from umbilical mesenchymal stem cells during oxidative stress, is synthesized in cells by cystathionine-β-synthase, cystathionine-γ-lyase and 3-mercaptopyruvate sulfurtransferase (3-MPST) enzymes [72]. In a study using NE-induced mouse and human umbilical mesenchymal stem cells, inhibition of these enzymes was achieved by siRNA transfection in cultured human umbilical mesenchymal stem cells. It has been reported that in vitro, there is more H2S production in normal stem cells under hypoxia, but H2S production is reduced in cells with enzyme inhibition. It was also reported that in mice treated intraperitoneally with negative control siRNA stem cells, clinical disease scores as well as intestinal and lung histological damage scores were significantly improved compared to the NE group, but in the group treated with enzyme inhibited stem cells, these parameters were significantly worse compared to the negative control siRNA group. As a result, it has been reported that H2S is protective in cases where oxidative stress occurs in relation to the mentioned pathways [73].\n\nHydrogen Sulfide (H2S) is an important agent that causes a vasodilator effect by causing an increase in NO in tissues via eNOS and has important properties such as antioxidant, angiogenetic, and cell proliferation [74]. Both lung and intestinal damage was observed in both wild-type mice and eNOSC440Gmutant mice with genetic ablatedeNOSgene after NE induction, and that intraperitoneal administration of GYY4137, H2S donor, during the induction period reduced lung and intestinal damage in wild-type mice, while this effect was not observed in eNOSC440Gmutant mice. H2S has a NO-dependent vasodilator effect, reduces ROS production, may have protective effects on the lung and intestine by protecting the development of alveolar and lung vascular networks, and as a result, H2S provides its protective effects in experimental necrotizing enterocolitis by using Cysteine 440 on eNOS [75]. In a study investigating NE-related lung damage in mice and the effect of H2S-Mesalamine, H2S donor, on lung damage, NE induction significantly increase TLR4 and IL-6 levels in the intestinal and lung tissues of both wild-type and transgenicallyeNOSgene knockout mice. It was observed that H2S derivative treatment attenuated the increase of TLR4 and IL-6 in wild-type mice and induced clinical and histological improvement, but did not have these effects in transgenic mice. As a result, it has been reported that eNOS plays an important role in NE-related lung damage and that H2S-Mesalamine acts through eNOS [49].\n\nIn a study evaluating NE-related lung injury in mice and the effect of formula enriched with digested fat, NE induction resulted in increasedTNF-αandlipocalin-2(Lcn-2) gene expressions, and 3’-nitrotyrosine (3’-NT), an indicator of OS, and the transcription of the superoxide-producing NADPH oxidase 2 (NOX2) enzyme in lung tissue. Histologically, alveolar destruction, vascular extravasation and PMNL accumulation occur in the lung, and immunohistologically, MPO activity, the expression of neutrophil-specific enzyme ELANE andpro-apoptosis gene p53 up-regulated modulator of apoptosis(PUMA) gene are increased and intense apoptosis has been reported to be observed. Also, the building block proteins SP-A and SP-D of surfactant secreted by epithelial type 2 cells, which are an important structure in the defense of the lung, were significantly reduced by immunostaining method. In addition, Zonula Occludens (ZO)-1, a tight junction protein in lung tissue, causes a significant decrease in immunostaining and quantity [47].\n\nIn mice and humans with NE, a decrease in T regulatory lymphocytes (Treg), which are involved in the accumulation of Th17 proinflammatory leukocytes and the maintenance of immune homeostasis, has been reported to be associated with severe lung injury. It has also been reported that administration of CD4 + T lymphocytes isolated from NE-induced mouse lungs to the lungs of immunosuppressed mice causes severe lung injury, that depletion of Tregs exacerbates NE-associated lung injury, and that consequently, Th17/Treg imbalance is required for the induction of NE-associated lung injury. Furthermore, selective deletion of TLR4 from surfactant protein C-1 (SFTPC1) pulmonary epithelial cells has been reported to reverse lung injury, while TLR4 activation has been reported to induce chemokine (C-C) ligand 25 (CCL25), which mediates chemotaxis of Th17 in mouse lungs as a result of NE induction. Aerosolized inhibition of CCL25 and TLR4 has also been reported to restore Tregs that attenuate NE-associated lung injury. As a result, it was reported that TLR4 activation in SFTPC1 cells disrupts the Treg/Th17 balance in the lungs via CCL25 and causes NE-associated lung injury, while TLR4 inhibition protects against NE-associated lung injury by stabilizing the Th17/Treg balance in the lungs [76].\n\nIn summary, it is predicted that preventing the inflammatory response, OS and chemotaxis of inflammatory cells to the lungs may prevent NE-related lung damage. OS, inflammation, structural and functional factors, and apoptosis appear to be involved in the pathogenesis of NE-associated lung injury.\n\nIn our study important differences were detected among the groups for MDA lung tissue concentration levels (p < 0.05). Immunohistochemically, in all groups, CASP3 activity was evaluated to detect the apoptosis process in the lung andCASP3expression was observed to be increased in the NE group and significantly decreased in the NE+EO group (p < 0.001) (Table 4,5Fig 3B,3C,3D). Also, statistically meaningful relation between MDA levels and all of LW, CIS, BMS, Casp-3+cells and HPS for lung were detected.\n\nTGFβ1is a pleiotropic cytokine that plays a role in many physiological and pathological processes such as cellular differentiation, migration, apoptosis, regulation of immune systems, immune tolerance, hemostasis, fibrosis, inflammation, cancer progression, and its effects depend on the tissue and agent [77]. Its opposing effects, both suppressing and activating inflammation, are important in maintaining immunological balance [78].TGFβ1promotes healing by inhibiting the immune response and uncontrolled inflammation. However,TGFβ1serves as one of the main mediators and initiates fibrosis and apoptosis endothelial cells that can cause tissue damage if left uncontrolled, and in infective cases the role ofTGFβ1is largely tissue and pathogen dependent [79]. Although the pathogenesis ofTGFβ1-mediated lung damage is not fully known, studies have reported thatTGFβ1causes damage to the lungs by increasing lung microvascular alveolar permeability and increasing actin stress fiber formation [80]. In different studies, various pathways that affectTGFβ1and/or are affected byTGFβ1have been stated. In ALI induced mice after nickel inhalation, while a decrease in the expression of genes that play important roles in alveolar fluid resorption, synthesis or reuse of surfactant proteins and phospholipids, a significant increase ofTGFβ1levels and gene expression levels in BALF were found. As a result,TGFβ1is a central mediator of ALI [81]. While miR-1258 expression and SOD activities were decreased,TGFβ1expression, p-SMAD3 protein levels, histological changes indicating ALI, IL-6, IL-1β, TNF-α, MDA level,PBX/knotted 1 homeobox 1(Pknox1)gene expression and protein levels were increased in septic ALI patients, in LPS-induced Immortalized human bronchial epithelial cell line(BEAS)-2B cells and LPS induced mice,miR-1258expression treatment inhibit inflammation and OS in ALI through theTGFβ1/SMAD3 cascade regulated byPknox1[10]. It has been reported thatTGFβ1expression increases in fibrosis of human lung and bleomycin-induced mouse lung tissues.TGFβ1increased the expression of ornithine aminotransferase (OAT) in fibroblasts, and the increase in OAT expression regulated bothTGFβ1-induced and constitutive expression of collagen, fibronectin and alpha-smooth muscle actin (α-SMA), which are important components of fibrosis, so OAT is important in lung fibrogenesis. Also OAT causes OS as a result of the production of ROS in the mitochondria by activating proline dehydrogenase, and OAT inhibition with L-canaline suppressesTGFβ1activity and signaling pathway. As a result, it was observed that OAT could regulateTGFβ1expression and that OAT inhibition suppressed the Smad-dependent and Smad-independent signaling pathways induced byTGFβ1[13]. Severe Coronavirus disease 2019 (COVID-19) is characterized by excessive release of PIC leading to acute respiratory distress syndrome (ARDS) and potentially life-threatening systemic inflammation. In ARDS patients,TGFβ1increases in the parenchyma and blood in the early stages, and in the later stage, chronic inflammation dominated byTGFβsignaling and Immunglobulin-A2 production develops, which induces fibrosis [82]. In a study a significant increase inTGFβ1, C-Reactive Protein (CRP) and D-Dimer levels, and a positive correlation betweenTGFβ1and CRP were detected in Covid-19 patients compared to the control group. As a result, it has been reported thatTGFβ1levels are the main molecule for the pathophysiology of the disease and are a marker that can be used in the early diagnosis of COVID-19 and the course of the disease [83].TGFß1, which is a predisposing risk factor for the severity of COVID-19, has a profibrotic effect [84] and is associated with disease severity. In a study, serumTGFβ1levels showed a positive correlation with inflammatory markers such as CRP, leukocyte count, absolute neutrophil count, platelet count, fibrinogen in all patients. The higher serumTGFβ1concentrations, which increased with the severity of COVID-19, were measured andTGFβ1levels at hospitalization is distinctive in predicting the severity and development of complications.\n\nIn the study investigating the effect of Tyr, one of the phenolics of EO, on the nonalcoholic steatohepatitis model, steatosis and hepatic fibrosis and increasedTGFβ1gene expression were observed. Tyr reversed these effects and had a positive effect on nonalcoholic steatohepatitis model [84]. In a study investigating the effectiveness of HTyr in the renal hypoxia model created by exposing the human proximal tubule cell epithelial cell line (HK-2) to CoCl2for 24 hours, HTyr treatment reduced the formation of both ROS and reactive nitrogen species (RNS), in addition to prevention of GSH depletion in hypoxia-induced cells. It has also been reported that HTyr has antioxidant, anti-inflammatory and anti-fibrotic effects on hypoxic renal cells by reducing the gene expressions of IL-6 andTGFß1, which are modulators of inflammation and fibrosis [29]. Autosomal dominant polycystic kidney disease is a genetic disease that destroys the kidney parenchyma with fluid-filled cysts that lead to kidney failure. The pathological feature of this genetic disease is the development of interstitial inflammation and fibrosis with the accumulation of inflammatory cells. In an in vitro autosomal dominant polycystic kidney disease model, phenolic-rich olive leaf extract decreased the gene expressions of PIC, which play a role in cyst formation, andTGFß1, which has a fibrotic effect, fibronectin, eCadherin and α-SMA. In a separate series of experiments, it was reported thatTGFß1stimulation of cells has been reported to produce a fibrotic effect and that olive leaf extract had an anti-fibrotic effect by reducingTGFβ1[85].\n\nAccording to the our results, statistically important differences among the groups for bothTGFβ1expression andTGFβ1concentraion levels were detected. TheTGFβ1expresssion,TGFβ1and MDA concentration levels of NE group were significantly different (p < 0.001) from the both of both of NE+EO and control group. There were significant relation betweenTGFβ1levels and all of LW, CIS, BMS, MDA levels,TGFβ1expressions, Casp-3+cells and HPS for lung (p < 0.001). Also the relation between MDA levels and all of LW, CIS, BMS,TGFβ1expressions, Casp-3+cells and HPS for lung were significant for lung (p < 0.001).\n\nAlthough our NE model is perfectly established, it does not fully represent the pathophysiological events that occur in NE in premature neonates because of the physiological and metabolic differences between rat and human neonates is one of the limitations of our study. Another limitation of our study is that the effects of EO, which has lower total phenolic content, or individual olive oil phenols to determine the effective components were not evaluated. Additionally other limitations of our study are, while the acute effects of EO were determined in our experimental model coversly its’ long-term effects were not evaluated, and we evaluated a limited number of parameters related to inflammation and oxidative stress.\n\nOur findings emphasize thatTGFß1has an important role in NE-associated lung injury and can be used as a biomarker to indicate lung injury. In addition, when the protective and therapeutic effects of EO on NE-associated lung injury in newborn rats are evaluated as a treatment strategy in high-risk newborns, our study provides a promising basis for future clinical studies. We think that future clinical studies including different dose and application time of EO for optimizing EO dosage and duration may provide a new approach to prevent NE-associated lung injury by demonstrating that olive oil may be a safe and effective therapeutic agent could be translate into clinical applications of of high-risk newborns.\n\nhttps://doi.org/10.1371/journal.pone.0320938.s001\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320938.s002\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320938.s003\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320938.s004\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320938.s005\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320938.s006\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320938.s007\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0320938.s008\n\n(XLSX)",
    "category": "immunology"
  },
  {
    "title": "A novel gastric ulcer model in rats using filter paper with acetic acid",
    "authors": "Siyuan Dong, Xudong Wang, Yixin Liu, Lu Qiao, Qiong Xue, Yixin Zhou, Zhao Xu, Qun Chen, Chen Chen, Na Liu, Jinhai Wang, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0319096",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319096",
    "content": "Gastric ulcer animal models are essential for research, but conventional acetic acid-based methods are limited by technical complexity, prolonged modeling duration, and poor applicability for solid anti-ulcer drug testing. This study described a novel and simplified method for inducing gastric ulcers in rats using filter paper imbued with acetic acid. The method provided consistent ulcer formation with uniform size and shape, allowing for targeted drug efficacy testing. Results indicated that the 75% acetic acid concentration yielded the most clinically relevant gastric ulcer model, completed ulcer forming within a day and healing visible after seven days. In conclusion, this model closely replicates human gastric ulcers and is well-suited for preclinical testing of anti-ulcer drugs.\n\nCitation:Dong S, Wang X, Liu Y, Qiao L, Xue Q, Zhou Y, et al.  (2025) A novel gastric ulcer model in rats using filter paper with acetic acid. PLoS ONE 20(4):\n           e0319096.\n        \n        https://doi.org/10.1371/journal.pone.0319096\n\nEditor:Sairah Hafeez Kamran, Lahore College for Women University, PAKISTAN\n\nReceived:June 27, 2024;Accepted:January 27, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Dong et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and its Supporting information files.\n\nFunding:This research was funded by National Natural Science Foundation of China (grant number 81673115 and 82073496), Huimin project of Ministry of Science and Technology of China (grant number 2012GS610101), International Cooperation Foundation of Shaanxi province (2020KW-057), Department of Health of Shaanxi Province (grant number 2018D050) and International Cooperation Foundation of Shaanxi province (2020KW-057) and Key Laboratory of Se-enriched Products Development and Quality Control, Ministry of Agriculture and Rural Affairs/National-Local Joint Engineering Laboratory of Se-enriched Food Development (Se-2023C02). Qun Chen, the recipient of these funds, contributed to the result interpretation, manuscript writing, reviewing & editing. Chen Chen was funded by The University of Queensland, Australia, and involved in interpreting the results, writing the manuscript, and conducting the review and editing processes. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nPeptic ulcer disease (PUD) is a gastrointestinal disorder caused byHelicobacter pylori(H. pylori) infection and nonsteroid anti-inflammatory drugs [1]. The global prevalence of PUD is 5–10%, with a rate of approximately 7.07% in China, varying between 8.82% in men and 5.4% in women [2]. Gastric ulcers, a subtype of PUD with a global prevalence of 3.15%, are chronic and recurrent, presenting significant clinical challenges [3]. Symptoms include upper abdominal pain and/or discomfort, abdominal distension, acid reflux, nausea, and vomiting. Establishing an easy and good gastric ulcer animal model is crucial for exploring the etiology, pathogenesis, and progression of pathological changes, as well as for defining therapeutic methods and developing new drugs [4]. At present, there are a variety of animal models of gastric ulcer, among which the glacial acetic acid-induced ulcer model is the most widely used one due to its similar occurrence, healing process and pathological morphology to human gastric ulcer. The commonly used glacial acetic acid modeling methods also include filter paper method, glass tube method and injection method [5]. The glass tube method and filter paper method are conducted on serous membrane of the stomach, which poses a high risk of intraperitoneal infection, bleeding, excessive damage, and stomach adhesion to other organs. The injection method, meanwhile, presents potential challenge to precisely control the affected depth of the injection into the stomach wall. As for the efficacy of anti-ulcer medicine, drugs in liquid form maybe intragastrical administrated after successfully establishment of the models with above methods. However, solid drugs are difficult to accurately reach the ulcer site by oral administration. The efficacy for evaluation of solid drugs after successful modeling is therefore difficult and challenging. At present with current modelling methods, it is unsure whether solid drugs are effectively reaching the ulcer site at a given dose. Thus, the comparison of drug efficacy among different candidates may be inaccurate. Therefore, the development of a new animal model that ensured the given dose of drug acting directly on the ulcer site with maximized efficacy and accuracy is urgently required (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319096.g001\n\nAn improved rodent model of gastric ulcer, which allows direct drug application to the ulcer site, would be highly valuable for evaluating solid anti-ulcer drugs under endoscopy [6]. However, this method demands advanced surgical skills and extensive training. Its complexity, including the need for a special mold, has limited its widespread adoption in research.\n\nThis study aimed to improve the modeling techniques of producing gastric ulcer in rats, which had no physical damage to the gastric wall, and could perform drug test in a self-controlled, dosage-controlled, rapid and easy way. It is hopeful to have this technique widely used in the evaluation of anti-ulcer drug efficacy.\n\nThe specific information regarding the chemicals and reagents was provided inTable 1. The filter paper was cut into a small sheet with a diameter of 5 mm. The amount of glacial acetic acid adsorbed by the small sheet ranged from 0.01 mL to 0.10 mL. The mold used in this study was a cylindrical plastic object with a diameter of 5 mm and a length of 1 cm containing a hollow center. The 6–0 suture, 4–0 suture, 2–0 suture and needles were used in this study.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319096.t001\n\nThirty-five virgin female Sprague-Dawley (SD) rats weighing between 180 and 220 g were obtained from Animal Center of Xi’an Jiaotong University. The rats were maintained at the room temperature 25 °C± 2 °C and a 12 h light/dark cycle. The animal room was well-ventilated, with humidity controlled between 50% and 70%. The rats had free access to food and distilled water (Milli-Q Direct Water Purification System, USA).\n\nAbove mentioned thirty-five SD rats were randomly (random number table) divided into 3 groups, namely, Injection group (5 rats), Mold group (5 rats) and New model group (25 rats). The New model group was then divided into 25% acetic acid group, 50% acetic acid group, 75% acetic acid group, 100% acetic acid group with 5 rats in each group except 10 rats in the 75% acetic acid group. Based on the preliminary experiment, an additional five rats were added to 75% acetic acid group for a prolonged observation of ulcer healing. The animal grouping and treatment were shown inFig 2&Table 2. The rats were fasted for 24 h before operation, with free access to water. 1% pentobarbital sodium was injected intraperitoneally at a dose of 30 mL/kg body weight (BW) in rats. The rats were then given skin preparation and fixed supine. The abdominal skin of the rats was disinfected with iodophor and covered with sterile towel. A 2–3 cm longitudinal incision was made from the xiphoid process along the median line of the rat abdomen to open the abdominal cavity and to isolate the rat stomach for further treatment.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319096.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319096.g002\n\nA total of 35 Sprague-Dawley (SD) rats were randomly divided into three groups: the New Model group (25 rats), the Mold group (5 rats), and the Injection group (5 rats). The New Model group consisted of four subgroups: 25% acetic acid (5 rats), 50% acetic acid (5 rats), 75% acetic acid (5 rats), and 100% acetic acid (5 rats). After the procedure, 5 rats from each group were sacrificed after 1 day. Additionally, based on preliminary experiments, five more rats were added to the 75% acetic acid subgroup for extended observation of ulcer healing, being sacrificed 7 days post-operation.\n\nIn the Injection group, a 34 G 1.5 mm needle was connected to a micro-syringe, and 0.03 mL 75% acetic acid was injected into the anterior and posterior walls of stomach, respectively. The depth of injection was designed to inject acid between the muscular layer and the serous layer of gastric wall [7].\n\nIn the Mold group, 5 mm incision was made at the fundus region along the greater curvature of stomach. The mold was placed into the stomach. The anterior and posterior wall of stomach was covered by the mold placed by hand or toothless forceps, and 0.2 mL 75% acetic acid was injected into the mold. The glacial acetic acid in the mold was then removed after 90-sec exposure, and the stomach cavity was rinsed with sodium chloride injection solution and the stomach wall was sutured [6].\n\nIn the New model group, the surgical and treatment procedure was shown inFig 3. An incision of about 5 mm was made at the fundus of stomach along the greater curvature. The filter paper that was weighed and soaked in different concentrations of glacial acetic acid (while the amount of glacial acetic acid was 0.1 mL) was put into the stomach. The anterior and posterior wall of stomach was covered by the filter paper held by hand or toothless forceps for 30 sec twice with1 min interval. The filter paper was then removed, and the stomach wall was sutured with sodium chloride injection after two repetitions.\n\n(a). The round filter paper with a diameter of 5 mm; (b). The rat stomach was isolated after anesthesia and 2 mm incision was made in the fundus of the stomach; (c). The filter paper absorbed acetic acid was put into the stomach; (d). The anterior and posterior walls of the stomach were pinched by fingers and for up to 30 sec, and repeated twice; (e). The filter paper removal and typical “kissing ulcers” were formed. The abdominal wall was sutured layer by layer after the operation.\n\n(a). The round filter paper with a diameter of 5 mm; (b). The rat stomach was isolated after anesthesia and 2 mm incision was made in the fundus of the stomach; (c). The filter paper absorbed acetic acid was put into the stomach; (d). The anterior and posterior walls of the stomach were pinched by fingers and for up to 30 sec, and repeated twice; (e). The filter paper removal and typical “kissing ulcers” were formed. The abdominal wall was sutured layer by layer after the operation.\n\nhttps://doi.org/10.1371/journal.pone.0319096.g003\n\nAfter operation, the rats were kept in individual single cages. The standard postoperative procedure was designed to control pain and infection. The rats lied on a heat preservation pad after the operation. 2% ceftiofur sodium at a dose of 3 mg/kg BW was injected intra-bitonally and the tetracaine hydrochloride gel (Zhen’ao Jinyinhua Pharmaceutical Co. Ltd.) was applied to the surgical site. The surgical site was cleaned and redressed daily to prevent infection and to monitor for suture site dehiscence. The rats were fasted for 2 days after the operation, with free access to 5% glucose saline and distilled water. Normal feeding began on the third day after the operation. Daily observations were made and recorded for food intake, water consumption, excretion, and general condition. The experiment was immediately terminated, and euthanasia was performed if the rats exhibited any signs of respiratory distress, diarrhea, urinary incontinence, inability to eat or drink, persistent seizures, abnormal weight gain or loss, or infection and suppuration at the surgical site. Euthanasia was performed using an overdose of pentobarbital sodium, supplemented by bilateral thoracotomy as an auxiliary physical method.\n\nFive rats in each group were sacrificed one day after the operation. Based on preliminary results, the 75% acetic acid group exhibited typical gastric ulcer morphology both microscopically and macroscopically, and the general condition of rats was relatively stable. Therefore, the 75% acetic acid group was selected for long-term observation. An additional five rats from the 75% acetic acid group were sacrificed seven days after the operation (Fig 2). The stomach was extracted and rinsed with sodium chloride solution. Subsequently, the stomach was cut open along the large-curved side of stomach. The morphological changes of the gastric mucosa and the ulcers were observed macroscopically. Digital photographs were taken using a digital camera, and the ulcer area was measured using the Image J 2.9.0 image analysis system.\n\nGastric mucosa sample was excised from each rat stomach for histological examination in this study. Tissue samples of approximately 0.5 cm × 1 cm were excised from the ulcer margin of the stomach that developed gastric ulcers, as well as from the corresponding location in the stomach without gastric ulcers. The samples were fixed in 4% paraformaldehyde and embedded in paraffin [8]. The paraffin sections were cut at a thickness of 5 µm and stained with hematoxylin and eosin. The extent of inflammatory cell infiltration and mucosal injury was scrutinized under microscope and quantified using the Image J 2.9.0 image analysis system [9].\n\nIn this experiment, the parameters were measured more than 3 repeats in each group. SPSS 23.0 software (SPSS Inc., Chicago, IL, USA) was used for statistical analysis. All results are presented as mean ± SEM (Standard Error of Mean). The normality of distribution was assessed by the Shapiro-Wilk test. For the examination of homogeneity of variance and the comparison of data among multiple groups, one-way analysis of variance (ANOVA) was employed, followed by Tukey’s post hoc test. Student-t test or Mann-Whitney U was used to analyze the significance in the paired comparison for evaluation of treatment between the anterior and posterior walls in the New model group of each rat.P< 0.05 was considered statistically significant. No control group was designed because the focus was to establish a new and better gastric ulcer model in rats in comparison to other established rat models.\n\nThis study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. The protocol was approved by the Institutional Animal Care and Use Committee in Xi’an Jiaotong University (approval No. 2022–1295). All experimentalists received prior training at the Laboratory Animal Center of Xi’an Jiaotong University. All methods were reported in accordance with ARRIVE guidelines. All surgery was performed under sodium pentobarbital anesthesia, and every effort was made to minimize suffering.\n\nAll rats survived after surgery. There was no significant difference of excretion and mental state of rats among Injection group, the New model group including 25% acetic acid group, 50% acetic acid group and 75% acetic acid group before and after experimental surgery. The mental states of rats in the Mold group and the New model group of 100% acetic acid group were significantly deteriorated after surgery; showing arched back and hair erection, slow movement, less drinking, etc. The condition of rats from up to 75% acetic acid group was the same as that of the normal rats 7 days after operation.\n\nOn the first day after operation, the rats were observed and sacrificed. In the Injection group, the abdominal cavity adhesion was serious; the round protrusion was visible on the serous surface of the stomach; and multiple mucosal defects in the anterior wall of the stomach were visible with different sizes and colors. The largest ulcer was black in color, with an area of 0.8094±0.0780 cm2, while the rest ulcers were mostly red, with an average area of 0.1818±0.0698 cm2. The surrounding mucosa was hyperemia and edema. No obvious ulcers were observed on the posterior wall, possibly due to different injection depths (Fig 4a). In the Mold group, there was no obvious abdominal adhesion. The gastric wall was opened and examined, where only round mucosal defect was observed in the posterior wall of stomach with peripheral mucosal edema. No obvious lesions were found in the anterior wall of stomach, and the ulcer area was 0.0650±0.0036 cm2(Fig 4b).\n\n(a). In the Injection group, multiple mucosal defects (blue circles) were found in the gastric wall 1 day after operation, but the depth of the lesions was different, and no ulcer was formed in the symmetrical position. (b). In the Mold group, only a round mucosal defect (blue circle) was observed on the posterior wall 1 day after operation, with no obvious lesions and mucosal edema on the anterior wall, and no obvious signs of congestion and bleeding. (c). In 25% acetic acid group, mucosal hemorrhage, and edema in the symmetrical position of the gastric wall (blue circle) were observed. (d). In 50% acetic acid group, ulcer formation was observed in the symmetrical position of the gastric wall (blue circle), with clear mucosal lesions and peripheral mucosal edema. (e). In 75% acetic acid group, ulcer formation in the gastric wall at the symmetrical position (blue circle) was obvious, and the size was identical with surrounding mucosa congestion and edema. (f). In 100% acetic acid group, ulcer formation was obviously observed in the gastric wall in the same position (arrow) while mucosa was clearly congestion and edema. (g). 7 days after operation in 75% acetic acid group, the ulcer scar was formed in the symmetrical position of the stomach (yellow circles), and the surrounding bulge formed an ulcer spout, which was covered by white moss.\n\n(a). In the Injection group, multiple mucosal defects (blue circles) were found in the gastric wall 1 day after operation, but the depth of the lesions was different, and no ulcer was formed in the symmetrical position. (b). In the Mold group, only a round mucosal defect (blue circle) was observed on the posterior wall 1 day after operation, with no obvious lesions and mucosal edema on the anterior wall, and no obvious signs of congestion and bleeding. (c). In 25% acetic acid group, mucosal hemorrhage, and edema in the symmetrical position of the gastric wall (blue circle) were observed. (d). In 50% acetic acid group, ulcer formation was observed in the symmetrical position of the gastric wall (blue circle), with clear mucosal lesions and peripheral mucosal edema. (e). In 75% acetic acid group, ulcer formation in the gastric wall at the symmetrical position (blue circle) was obvious, and the size was identical with surrounding mucosa congestion and edema. (f). In 100% acetic acid group, ulcer formation was obviously observed in the gastric wall in the same position (arrow) while mucosa was clearly congestion and edema. (g). 7 days after operation in 75% acetic acid group, the ulcer scar was formed in the symmetrical position of the stomach (yellow circles), and the surrounding bulge formed an ulcer spout, which was covered by white moss.\n\nhttps://doi.org/10.1371/journal.pone.0319096.g004\n\nIn the New model group, except for the 100% acetic acid group, the remaining surgical site wounds healed well, and there was no obvious abdominal adhesion or seroperitoneum. In 25% acetic acid group, round or flake mucosal injury was observed in the symmetrical position of the stomach, covered with blood-colored moss, and surrounded by mucosal hyperemia and edema (Fig 4c). In 50% acetic acid group, there were obvious mucosal defects in the symmetrical position in the stomach, and the ulcers were mostly oval and covered by blood-colored moss (Fig 4d). In 75% acetic acid group, kissing ulcers were formed with clear boundaries, and the shape was more regular than that in 50% acetic acid group. The ulcers were mostly round or oval, flat at the bottom, with brown mucosa, partly covered by blood-colored moss, with peripheral mucosa hyperemia and edema (Fig 4e). In the 100% acetic acid group, obvious lesions were observed in the symmetrical position of the stomach; the ulcer surface was red and swollen and in a round or oval shape; the intermediate mucosa was obviously defective, colored brown and slightly white; and the peripheral mucosa was obviously congested with bleeding and significant edema (Fig 4f). Seven days after operation in 75% acetic acid group, the ulcer scar was formed in the symmetrical position of stomach, and the surrounding bulge formed an ulcer spout, which was covered by white moss (Fig 4g).\n\nThe amount of acetic acid and mean ulcer area in the New model group were shown inTable 3. The ulcer areas of the New model groups were shown inFig 5. The mean ulcer areas of 50% acetic acid group, 75% acetic acid group and 100% acetic acid group were proportionally increased in comparison with that of 25% acetic acid group (Fig 5a,P<0.0001). The mean ulcer area of 75% acetic acid group or 100% acetic acid group was significantly increased from that of 50% acetic acid group (P=0.0206<0.05 compared with 75% acetic acid group,P=0.0001<0.001 compared with 100% acetic acid group). There was no significant difference in the mean ulcer area between 75% acetic acid group and 100% acetic acid group (P=0.3287). There was no significant difference in the mean ulcer area of anterior and posterior wall of the stomach within each group (Fig 5b,P=0.6344 for 25% acetic acid group,P=0.6652 for 50% acetic acid group.P=0.9003 for 75% acetic acid group,P=0.9729 for 100% acetic acid group).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319096.t003\n\nS1 Table).(a). The calculation results of ulcer area induced by different concentration of acetic acid. (b). The calculation results of similar ulcer sizes between the anterior and posterior gastric wall. ****P<0.0001 (compared to 25% acetic acid group);#P<0.05,###P<0.001 (compared with 50% acetic acid group).\n\nS1 Table).(a). The calculation results of ulcer area induced by different concentration of acetic acid. (b). The calculation results of similar ulcer sizes between the anterior and posterior gastric wall. ****P<0.0001 (compared to 25% acetic acid group);#P<0.05,###P<0.001 (compared with 50% acetic acid group).\n\nhttps://doi.org/10.1371/journal.pone.0319096.g005\n\nThe gastric tissue of the lesion site was collected. Paraffin-embedded sections of the tissue were observed under light microscope after HE stains. The most obvious lesion in the Injection group was a partial loss of mucosal epithelium. Bleeding on the ulcerative surface was significant, accompanied by inflammatory cell infiltration. The mucosal epithelium structure was intact in the remaining lesions, and some mucosal epithelium had a small amount of bleeding (Fig 6a). One day after surgery, no obvious ulcer was observed in the Mold group; the gastric mucosa epithelium was intact; the cells were arranged neatly; and there was a small amount of inflammatory cell infiltration in the affected mucosal layer (Fig 6b). In 25% acetic acid group, mucosal epithelial bleeding was obvious; cell edema was clearly observed; and many inflammatory cells were infiltrated in the submucosa; but no obvious mucosal loss was detected (Fig 6c).In the 50% acetic acid group, there was obvious bleeding in the mucosa and submucosa; mucosal glandular structure disappeared; and a large number of inflammatory cells were infiltrated the submucosa (Fig 6d). In 75% acetic acid group, the ulcer site was characterized by a loss of mucosal epithelium; the surface of ulcer was covered by necrotic tissues; the peripheral mucosal glandular structure disappeared; and the infiltration of a large number of inflammatory cells was observed in the mucosa and submucosa (Fig 6e). In the 100% acetic acid group, there was significant damage to the mucosal structure at the ulcer site, with a loss of mucosal epithelium and mucosal glands, a massive bleeding on the surface and submucosa of the ulcer, a significant inflammatory cell infiltration, and a congestion and edema in the glandular interstitial of the mucosa surrounding the ulcer (Fig 6f). Further quantitative analysis revealed that compared with 25% acetic acid group, the degrees of inflammatory cell infiltration in 50%, 75% and 100% acetic acid group were significantly increased (50% group:P= 0.0031 < 0.01, 75% group:P= 0.0012 < 0.01, 100% group:P< 0.0001). However, there was no significant difference in the degree of inflammatory cell infiltration among the 50%, 75%, and 100% acetic acid groups (Fig 6h). Seven days after surgery, compared to the day 1, the mucosa epithelium at the ulcer in the 75% acetic acid group was obviously missing; the glands were disappeared; the necrotic tissue was less at the position of ulcer; the granulation tissue hyperplasia was visible under the ulcer; there was less inflammatory cell infiltration; and the mucosal glandular interstitial around the ulcer was congested with edema (Fig 6g).\n\n×).(a). In the Injection group under the microscope, the structure of mucosal glands at the largest size ulcer disappeared (blue arrow); the mucosal hyperemia and edema were obvious (red arrow); and some mucosal epithelium was missing. (b). No obvious ulcers were observed in the Mold group, the mucosa epithelium was intact, and the glandular structure was arranged neatly. Only a small amount of mucosal necrosis at the top (red arrow). (c). Mucosal epithelial cell bleeding (red arrow) and inflammatory cell infiltration (blue arrow) were observed in the 25% acetic acid group 1 day after surgery, without mucosal loss. (d). The massive bleeding in the mucosa and submucosa of 50% acetic acid group was observed (red arrow). The infiltration of local inflammatory cells (blue arrow), and partial disappearance of mucosal glandular structure were also observed. (e). The mucosal deletion was observed in 75% acetic acid group (red arrow). The surface was covered with necrotic tissue; mucosal glandular structure disappeared (blue arrow); and the infiltration of many inflammatory cells was observed. (f). In the 100% acetic acid group, the mucosal structure was significantly damaged (red arrow); the surface was covered with necrotic tissue; and the mucosal glandular interstitial was hyperemia and edema surrounding the ulcer (blue arrow). (g). 75% acetic acid group 7 days after surgery, there were significant loss of mucosa at the ulcer, with overlay of necrotic material (red arrow), granulation tissue hyperplasia under the ulcer (yellow triangle), inflammatory cell infiltration (blue arrow), and surrounding mucosa in presence of hyperemia and edema. (h). The degree of inflammatory cell infiltration induced by different concentration of acetic acid (S2 Table). **P<0.01, ****P<0.0001 (compared to 25% acetic acid group). 4x:500 μM, 10x:100 μM.\n\n×).(a). In the Injection group under the microscope, the structure of mucosal glands at the largest size ulcer disappeared (blue arrow); the mucosal hyperemia and edema were obvious (red arrow); and some mucosal epithelium was missing. (b). No obvious ulcers were observed in the Mold group, the mucosa epithelium was intact, and the glandular structure was arranged neatly. Only a small amount of mucosal necrosis at the top (red arrow). (c). Mucosal epithelial cell bleeding (red arrow) and inflammatory cell infiltration (blue arrow) were observed in the 25% acetic acid group 1 day after surgery, without mucosal loss. (d). The massive bleeding in the mucosa and submucosa of 50% acetic acid group was observed (red arrow). The infiltration of local inflammatory cells (blue arrow), and partial disappearance of mucosal glandular structure were also observed. (e). The mucosal deletion was observed in 75% acetic acid group (red arrow). The surface was covered with necrotic tissue; mucosal glandular structure disappeared (blue arrow); and the infiltration of many inflammatory cells was observed. (f). In the 100% acetic acid group, the mucosal structure was significantly damaged (red arrow); the surface was covered with necrotic tissue; and the mucosal glandular interstitial was hyperemia and edema surrounding the ulcer (blue arrow). (g). 75% acetic acid group 7 days after surgery, there were significant loss of mucosa at the ulcer, with overlay of necrotic material (red arrow), granulation tissue hyperplasia under the ulcer (yellow triangle), inflammatory cell infiltration (blue arrow), and surrounding mucosa in presence of hyperemia and edema. (h). The degree of inflammatory cell infiltration induced by different concentration of acetic acid (S2 Table). **P<0.01, ****P<0.0001 (compared to 25% acetic acid group). 4x:500 μM, 10x:100 μM.\n\nhttps://doi.org/10.1371/journal.pone.0319096.g006\n\nGastric ulcer is a globally prevalent disease. Bleeding, perforation, stomach outlet obstruction and other common complications often bring great pain to patients [10]. To deeply understand and explore the pathogenesis and to have a more effective treatment of gastric ulcer, the careful animal experiments are required [11]. Currently, commonly used ulcer models are divided into stress induced model, non-stress induced model, exercise stress model, drug induced model, ethanol induced model, acetic acid and glacial acetic acid induced model, and pyloric ligation induced model [12–18]. Among them, gastric ulcer model induced by glacial acetic acid and/or acetic acid is the most widely used one because of its similar pathological characteristics and healing process to those in human chronic ulcer [19]. The common methods of glacial acetic acid induced gastric ulcer model are as follows, with serious limitations.\n\nIt is difficult to quantify the drug dose in above ulcer modeling due to the treatment of the gastric serosa surface in the methods (2) and (3). The glacial acetic acid may flow out along the gastric wall and cause glacial acetic acid corrosion in the other parts of gastric wall, even in the abdominal cavity or other organs, which affects the survival rate of rodents. In addition, the methods (2) and (3) are difficult to form a pair of similar ulcers for self-controlled drug test. In addition, the time to form a model is relatively long. The glass tube method may have some physical damage to the gastric wall too. The New model method reported here was simple and easy. In addition, this new method guaranteed that the drug acted directly on the ulcer without the acetic acid leakage.\n\nFor drug efficacy evaluation study, the above three methods have certain limitations to test non-liquid drugs and drugs used with endoscopy. Although liquid drugs may be tested by intragastric administration after successful modeling, solid drugs may not be applied to the ulcer sites after intragastric administration, and the drug dosage may not be accurately quantified. Careful self-controlled experiments in same animal may not be able to perform either. The evaluation of drug efficacy has obvious been compromised.\n\nAn improved method for the modeling of gastric ulcer in rats was reported recently [6]. After the stomach of the rats was isolated, an “O” mold was used. The mold was placed into the stomach and held with the hand, glacial acetic acid was injected into the mold for 90 sec, and the ulcer was formed in the stomach. However, in actual operation, after injecting glacial acetic acid into the mold, the contact time of the anterior or posterior gastric wall of the stomach was variable. It was also difficult to quantify the dosage of the drug, and the operation was complex requiring surgical skills. Therefore, such model is not widely used yet.\n\nThe current study aimed to provide a new model of gastric ulcer in rats, which had advanced drug testing system with self-controlled comparison, dosage-controlled ulcer size and depth, rapid modeling process, and easy to perform. Employed round filter paper was regular in shape and had no physical damage to the stomach wall. The filter paper was cheap and easy to obtain. In addition, due to the adsorptive properties of the filter paper, successful modeling allowed for the application of drug-laden filter paper to the gastric wall. By the measurement of filter paper weight before and after insertion into the gastric wall, the dosage of drug applied to the gastric wall could be calculated. This approach enabled a more precise assessment of therapeutic efficacy of the administered drug. Moreover, after the filter paper was placed inside the stomach, the anterior and posterior gastric walls of the stomach formed a sandwich with the filter paper causing two identical ulcers of same size, shape, and extend in the symmetric positions of the stomach, namely “kissing ulcers”. Such “kissing ulcers” achieve the purpose of experiment with self-controlled comparison.\n\nThe overall surgery of this New model was much simpler than other models, and the experiment was highly repeatable. In addition, the modeling time was as short as only 1 day. After the operation, the gastric ulcers were obvious, and the size and depth were identical among the same dose group. In the pre-experiment, the New model group (75% acetic acid group and 100% acetic acid group) displayed typical ulcer formation 1 day after surgery, with ulcer scar formation observed 7 days post-surgery. While the injection group and the low dose New model groups (25% acetic acid group and 50% acetic acid group) exhibited no typical ulcer formation at 1 day after surgery. Based on the experimental findings, the ulcer observed in the 75% acetic acid group exhibited the most typical characteristics of human gastric ulcer, and the overall condition of experimental rats was relatively favorable for the recovery test. Consequently, an additional five rats were added for a prolonged observation of ulcer healing process at 7 days post-surgery.\n\nAfter 7 days, the gastric wall was dissected with obvious ulcer scar formation, which was convenient for the calculation of ulcer area and evaluation of drug effect. In addition, this study explored the variable concentrations of glacial acetic acid. The rats using 25%, 50% and 75% acetic acid concentrations had a very good post-operation recovery with very high survival rate. The 25% acetic acid caused only mucosal congestion and edema, without ulcer formation. Although ulcer-like lesions were observed macroscopically in the stomach of 50% acetic acid group, no obvious mucosal defects were observed under the light microscope. Only 75% acetic acid showed clear ulceration both macroscopically and under light microscope. Ulcers were typical when the concentration was 100%, with poor recovery after surgery. Therefore, the 75% acetic acid was ultimately recommended.\n\nThis New modeling method provides a versatile platform for evaluating both liquid and solid drugs. The model allows drugs to act directly on the ulcer site, enabling more accurate and efficient evaluations of therapeutic efficacy. For solid drugs specifically, the paired “kissing ulcers” in the anterior and posterior gastric walls allow for one ulcer to be treated while the other used as a self-control. This eliminates inter-animal variability and improves the reliability of experimental results. In addition, this model mimics the clinical scenario of endoscopic drug delivery, offering a preclinical platform to deliver drugs directly on to the gastric ulcer sites under endoscopy. This application provides significant clinical relevance, as it fills the gap between preclinical studies and clinical drug delivery methods.\n\nThis study has however certain limitations that should be acknowledged. The model was only validated in rats, and its applicability to other species remained to be explored. Additionally, further research may be needed to determine the suitability for testing drugs with different physicochemical properties, particularly those requiring sustained release or complex formulations. Future studies should also be performed to investigate the long-term effects of repeated drug administration simulating chronic treatment scenarios.\n\nIn conclusion, this New acetic acid-induced gastric ulcer model in rats represents herein a protocol with a short modeling duration, cost-effective process, defined ulcer lesion site, and reliable internal controlled ulcer pairs. This model has advantageous in evaluating drug efficacy, and improving limitations of previous acetic acid-induced gastric ulcer models. Specifically, this model allows tested drugs to act directly on the ulcer site. Compared to traditional intragastric administration, this model enables more accurate assessment of therapeutic effects, particularly for solid drugs. Moreover, it simulates the efficacy evaluation of drugs delivered directly via endoscopic methods. Thus, it represents a straightforward, and highly efficient novel gastric ulcer animal model that may advance preclinical research in gastric ulcer treatment.\n\nhttps://doi.org/10.1371/journal.pone.0319096.s001\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0319096.s002\n\n(XLSX)",
    "category": "immunology"
  },
  {
    "title": "The association between healthcare access and shingles vaccination among older adults in Virginia, United States",
    "authors": "Chidozie Declan Iwu, Pramita Shrestha, Alyson J. Littman, Julia E. Hood, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0316429",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0316429",
    "content": "Shingles is a debilitating vaccine preventable disease that poses a health threat to older adults. However, the uptake of shingles vaccines remains low, and the factors contributing to the low uptake are not clearly understood. This study assessed the association between healthcare access and shingles vaccination among older adults, as well as the impact of COVID-19 pandemic on vaccine uptake.\n\nThis was a cross-sectional study among adults 50 + years in Virginia (n = 16,576) using data from the Behavioral Risk Factor Surveillance System (2018, 2019, and 2021). We calculated the prevalence of shingles vaccination by health insurance and access to primary health care provider (used as proxies for healthcare access) and in relation to the COVID-19 pandemic (pre vs during). Log binomial regression models were used to estimate prevalence ratios (PR), adjusting for confounders.\n\nShingles vaccination was substantially higher among those with healthcare access compared to those without. Specifically, shingles vaccination was 35% among those with health insurance vs. 10% among those without (adjusted PR (aPR): 2.03, 95% CI 1.44, 2.86), and 36% among those with a primary healthcare provider vs 15% among those without (aPR: 1.99, 95% CI: 1.65-2.41). Finally, shingles vaccination was 41% during the COVID-19 pandemic vs. 30% before (aPR:1.26, 95% CI: 1.20–1.33).\n\nIndividuals with health insurance and access to a primary healthcare provider were significantly more likely to receive the shingles vaccine compared to those without such access. Moreover, the prevalence of shingles vaccination during the pandemic period was substantially higher compared with shingles vaccination before the pandemic.\n\nCitation:Iwu CD, Shrestha P, Littman AJ, Hood JE (2025) The association between healthcare access and shingles vaccination among older adults in Virginia, United States. PLoS ONE 20(4):\n           e0316429.\n        \n        https://doi.org/10.1371/journal.pone.0316429\n\nEditor:Swarnali Goswami,, Neurocrine Biosciences Inc, UNITED STATES OF AMERICA\n\nReceived:April 10, 2024;Accepted:December 11, 2024;Published:April 15, 2025\n\nCopyright:© 2025 Iwu et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nEach year in the United States, about one million individuals are diagnosed with shingles, a painful and debilitating illness caused by the reactivation of the varicella-zoster virus (VZV) [1]. This translates to an incidence rate of 542 to 685 per 100,000 person-years, and approximately 30% lifetime risk of acquiring the disease [2]. The incidence of shingles increases with age, particularly after the age of 50 years. Shingles is typically diagnosed based on clinical symptoms, which include a painful, localized rash that progresses into fluid-filled blisters, often accompanied by burning or tingling sensations. In some cases, individuals may also experience fever, headache, and fatigue [3]. Although shingles typically resolve within a few months, the associated symptoms of painful and itchy blisters can lead to severe long-term complications, such as nerve pain and encephalitis [4]. Management of this condition is costly, with an estimated annual financial burden of $1.3 billion in medical care costs and $1.7 billion in indirect costs in the United States [5].\n\nIn the United States, childhood varicella vaccination, introduced in 1995, is now widely administered, with coverage rates exceeding 90% in recent years [6]. This vaccination has significantly reduced the incidence of primary varicella infections, but some studies suggest that reduced exposure to wild-type varicella in adults may lead to decreased natural immunity boosting, potentially increasing the risk of shingles in older adults [7]. Studies have reported an increase in the incidence of shingles over the past two decades in various countries, including the United States, Canada, the United Kingdom, Spain, Japan, Taiwan, and Australia [8–14]. The underlying causes of the observed increase in shingles incidence are still not fully understood, but several hypotheses have been suggested. One possibility is that the availability of antiviral therapy may have increased patients’ willingness to seek care for shingles, therefore increasing diagnosis of shingles. Another possibility is that the widespread use of childhood varicella vaccination may have decreased the natural boosting of immunity from exposure to wild-type VZV. Finally, the increasing use of immunosuppressive therapies for multiple chronic conditions may increase susceptibility to shingles [15].\n\nIn response to the growing incidence of shingles, the US Advisory Committee on Immunization Practices (ACIP) recommended the routine use of varicella vaccination for children in 1996 and shingles vaccination for older adults (≥60 years) in 2006 [16]. Two vaccines against shingles, Zostavax (introduced in 2006) and Shingrix (introduced in 2017) have been approved in the United States [17]. The US Centers for Disease Control and Prevention (CDC) recommends that people 50 years and older get two doses of Shingrix separated by 2 to 6 months [18]. These recommendations aim to alleviate the burden of shingles and its associated complications, particularly in high risk populations like the elderly and immunocompromised individuals [19]. Despite these recommendations, the vaccination rate among adults 50 years and older remain low [17]. States in the South Atlantic region including Virginia (34.7%), Florida (28.5%), Georgia (27.2%), North Carolina (32.2%), South Carolina (26.4%), and West Virginia (26.6%) have lower vaccination compared to the US average (35%) [20,21]. Regardless of the state, vaccination rates for shingles is significantly lower compared to the vaccination rates for influenza which was approximately 49% between 2020-2021 according to CDC [22]. In Virginia and other states in the South Atlantic region, the lower uptake of shingles vaccination could be due to socio-economic inequities, highly rural population, and poor healthcare access [17,20,21]. Access to healthcare has a strong and positive correlation with influenza vaccination rates at the state level across diverse population groups [23]. Poor healthcare access constitutes a critical barrier to vaccine awareness, availability, and uptake [24]. Access to healthcare hinges on having health insurance coverage. Individuals without healthcare coverage, including children and non-elderly adults, are less likely to possess a consistent healthcare provider or have had recent medical visits compared to their insured counterparts. In the United States, most individuals under 65 years of age obtain their healthcare coverage from private employer-sponsored group health insurance [25], while nearly all adults aged 65 and above have health insurance through Medicaid or Medicare [26]. Aside from the influenza, pneumococcal polysaccharide, and Hepatitis B vaccines, which are covered by Medicare Part B (included as part of standard medical insurance), all other vaccines, including the shingles vaccine, are covered by Medicare Part D (optional prescription drug coverage that may require an additional premium) for individuals aged 65 years and older [27].\n\nPrevious research has shown that healthcare access positively influences vaccination rates for influenza [28] and COVID-19 [29]. However, there remains a gap in understanding how healthcare access affects shingles vaccination among adults. The COVID-19 pandemic introduced unprecedented challenges to healthcare systems, including vaccination efforts [30]. Interestingly, some studies suggest that the pandemic had a positive impact on general vaccination behavior, likely due to heightened awareness of disease risk [31,32]. Yet, there is a scarcity of studies examining the pandemic’s impact on shingles vaccination. To address these gaps, this study aimed to assess the association between healthcare access and shingles vaccination among older adults (≥50 years) in Virginia, and to explore the effects of the COVID-19 pandemic on vaccine coverage. We hypothesize that access to healthcare is a determining factor in Shingles vaccine uptake among older adults in Virginia, United States, and that the COVID-19 pandemic increased the uptake of shingles vaccine. Data from this study will help inform policies and interventions aimed at improving shingles vaccine coverage among older adults.\n\nWe conducted a cross-sectional study utilizing data from the Behavioral Risk Factor Surveillance System (BRFSS) for the years 2018, 2019, and 2021 in Virginia, United States. The BRFSS survey consists of annual telephone interviews that capture health-related risk behaviors, chronic health conditions, and use of preventive services [33]. BRFSS collects data from residents from all 50 states, the District of Columbia, and three US territories, and each state can choose to add additional questions to their surveys. We focused on Virginia because it was the only state that collected data on shingles vaccination across our years of interest. We chose BRFSS because it provides a large population-based, representative sample and allows for state-specific analysis [34].\n\nThe study population included adults 50 years and older in Virginia who participated in the shingles module of the BRFSS survey during the years 2018, 2019, and 2021. A total of 16,576 individuals were included in the final analysis (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0316429.g001\n\nWe used health insurance and access to a primary healthcare provider as primary exposures. These exposures are related to healthcare access but have different constructs. We classified respondents as having health insurance, if they responded “yes” to the question, “Do you have any kind of healthcare coverage, including health insurance, prepaid plans such as HMOs, or government plans such as Medicare or Indian Health Service?”. Individuals who responded “do not know” or did not answer the question were excluded from the analysis.\n\nAccess to primary healthcare provider was determined based on the question,“Do you have one person you think of as your personal doctor or healthcare provider?”. Those who responded “yes, only me” or “more than one” were classified as having access to a primary healthcare provider, while those who responded “no” were classified as not having access to a primary healthcare provider. Those who refused to answer, responded “do not know” or did not answer the question were excluded from the analysis.\n\nThe COVID-19 pandemic period was dichotomized as “Pre COVID-19 pandemic” (2018–2019) and “During COVID-19 pandemic” (2021). No information on shingles vaccine was collected in 2020.\n\nUptake of the shingles vaccination was the outcome of interest. Shingles vaccination was determined based on affirmative responses to, the question, “Have you ever had the shingles or zoster vaccine?”.\n\nMinimum sets of potential confounders were identified a priori using Directed Acyclic Graphs (DAGs) created by the authors and informed by previous literature [17,35] using DAgitty, version 3.0. This was done to avoid over fitting of the model, ensures a parsimonious model that blocks all non-causal paths, and avoids unnecessary adjustments that could introduce bias or increase variance. For the association between health insurance and shingles vaccination, the minimum set of confounders included age, sex, education, income, rurality and race/ethnicity as shown in S1 Fig inS1 Data. For the association between access to a primary healthcare provider and shingles vaccination, the minimum set of confounders included age, sex, income and race/ethnicity as shown in S2 Fig inS1 Data. For the association between COVID-19 pandemic period and shingles vaccination, the minimum set of confounders included age, sex, race/ethnicity, and rurality as shown in S3 Fig inS1 Data. In this study, we categorized age into two groups as 50–64 years and 65 years and above. Sex was binary variable as male, and female based on the BRFSS question, i.e., “Are you male or female?”. Race/ethnicity was categorized as Black only non-Hispanic, Hispanic, multiracial non-Hispanic, white only non-Hispanic, and another race non-Hispanic. Marital status was grouped as married, unmarried, and never married. Educational status was classified as less than college level, college 1-3 years and college 4 or more years. We grouped income as below $25,000, $25,000–$75,000, and above $75,000. Rurality was dichotomized as urban and rural and employment was classified as employed, retired and unemployed.\n\nDescriptive statistics were summarized to evaluate participant characteristics and to determine the proportion of individuals who reported having access to any health insurance and/or healthcare provider. CDC survey weights were applied to account for BRFSS’s complex survey design and non-response [33]. We evaluated the prevalence of shingles vaccination among the exposure groups. To determine the association between shingles vaccine uptake and access to healthcare, as well as the association between shingles uptake and COVID-19 pandemic periods, log binomial regression models were used to estimate crude and adjusted prevalence ratios and associated 95% confidence intervals. Since approximately 99% of adults aged 65 + years in the United States reported having health insurance [26], a stratified analysis was used to examine if the association between health insurance and shingles vaccination varied between the two age categories (50-64 years and 65 + years). R version 4.2.1 software was used to analyze the data.\n\nThe University of Washington institutional review board determined that BRFSS analyses do not constitute human subject research. Thus, institutional review board review was not obtained.\n\nOf the 16,576 individuals who met inclusion criteria, 6,493 individuals indicated having received the shingles vaccine.Table 1illustrates the characteristics of the BRFSS participants in Virginia stratified by Shingles vaccination status. Most of the study participants (67%) were drawn from the combined 2018 and 2019 BRFSS surveys, compared to 33% from the 2021 survey. Nearly 55% of adults were between the ages of 50-64 years and 45% were 65 years or older. The study had more males (54%) than females (46%). An overwhelming majority reported having health insurance (95%) and access to a primary healthcare provider (91%).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0316429.t001\n\nCompared to those who were not vaccinated, a higher proportion of vaccinated respondents were sampled during the COVID-19 pandemic (40% vs. 29%), were 65 years and older (66% vs. 35%), were female (55% vs. 53%), had four years of college or more (44% vs. 31%), were insured (99% vs. 94%), and had access to a primary healthcare provider (96% vs. 88%).Table 2illustrates the prevalence and prevalence ratios of shingles vaccination by health insurance, access to primary healthcare provider and COVID-19 period. In the adjusted analysis (Table 2), the prevalence of shingles vaccination was about two times higher in those with health insurance versus those without health insurance (adjusted prevalence ratio [PR]: 2.03, 95% CI: 1.44-2.86), and those who had access to a primary healthcare provider versus without access to a primary healthcare provider (adjusted PR: 1.99, 95% CI: 1.65-2.41). The prevalence of shingles vaccination was higher during the COVID-19 pandemic (2021) compared to before the COVID-19 pandemic years (2018-2019) (adjusted PR: 1.26, 95% CI: 1.20-1.33).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0316429.t002\n\nWhen stratified by age, the prevalence of shingles vaccination was substantially lower among those who were uninsured and 50-64 years (6%) than uninsured and 65 + years (31%). Shingles vaccination rates were higher among those insured, with vaccination rates higher among those 65 + vs. 50-64 (50-64: 22%; 65 + : 50%). When examining the associations between health insurance and shingles vaccination, they were stronger among people 50-64 years old (adjusted PR: 2.70, 95% CI: 1.64-4.46 than among those 65 + years old (adjusted PR: 1.31, 95% CI: 0.85-2.00,Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0316429.t003\n\nIn this study, we explored the extent to which access to healthcare, including health insurance and access to a primary healthcare provider as well as the COVID-19 pandemic were associated with rates of shingles vaccination among adults aged 50 + years in Virginia. The prevalence of shingles vaccination was twice as high for people with health insurance and access to primary healthcare provider than for those without health insurance or a primary care provider. These findings are consistent with previous findings that have looked at vaccination rates by various factors that comprise the broad definition of “healthcare access” [21], thus shedding light on the disparity of healthcare access. Additionally, the findings contribute to addressing the knowledge gap regarding the impact of healthcare access and the COVID-19 pandemic on shingles vaccination in the older adult population, showing that shingles vaccination was higher during the pandemic compared to in the years prior.\n\nWe focused on insurance coverage and primary healthcare providers as proxy measures of healthcare access. These factors have been previously found to be major predictors of healthcare-seeking behaviors [36]. The shingles vaccine can often cost $300 USD or more without insurance, which places a financial barrier that many low-income individuals cannot overcome [37]. Thus, for individuals who may already be struggling economically, the cost of the vaccine makes receiving it unlikely. It is not surprising then, that because shingles vaccination is covered by many health insurance plans [1], vaccination is higher for those who are insured. This emphasizes that individuals without health insurance might face barriers in accessing preventive services like vaccinations, leading to lower vaccination rates. This disparity highlights the importance of making preventive measures more accessible to all individuals regardless of their insurance status, to ensure equitable healthcare outcomes. These findings were consistent across the two age categories of our study participants after stratifying on age and health insurance. However, the association was less pronounced in the 65 + age group, likely because almost everyone in this group possessed some form of health insurance coverage. This underscores the influential role of health insurance in promoting vaccine uptake, highlighting the need to provide preventative care to people younger than 65 years [38]. Similarly, the prevalence of shingles vaccination was higher among those with access to a primary healthcare provider compared to those without. As with insurance, access to a primary healthcare provider has been shown to increase engagement in preventative health services [39]. Primary healthcare providers often act as a main source for addressing health problems and providing encouragement and treatment protocols which a patient can follow. Virginia’s Medicaid expansion in January 2019 likely bolstered healthcare access for those aged 50–64, potentially contributing to the observed increase in vaccination coverage among this demographic. This policy change underlines the critical role of health insurance in fostering equitable access to preventive services, a factor that may have strengthened vaccination rates among Virginia’s lower-income residents [40].\n\nWe found that the prevalence of shingles vaccination was higher during the COVID-19 pandemic than a few years prior. This corroborates a previous study [32] suggesting that the heightened awareness of disease risk and the increased focus on vaccinations during the pandemic may have positively influenced the uptake of other recommended vaccines, such as the shingles vaccine, in older adults. Although we cannot infer causality due to the cross-sectional nature of this study, several factors including public awareness campaigns, healthcare provider engagement and integration with COVID-19 vaccination effort may have driven the results we found. Those disproportionately affected by COVID-19, the elderly and immunocompromised, are also the same demographic which shingles tend to affect the most. Thus, because COVID-19 hospitalization and mortality were particularly high among elderly individuals, the perceived susceptibility to vaccine preventable illness may have increased among older adults, leading to higher vaccination rates among that population. These insights underscore the interconnectedness of health crises and the potential for public health responses to have far-reaching positive impacts. One study observed an increased risk of shingles following COVID-19 vaccination, which provided some evidence of the complex interplay between pandemic, vaccination for COVID, and vaccination for other illnesses. [41].\n\nThis study has several limitations. Firstly, our definition of healthcare access did not consider other types of healthcare access, providing a limited view of the complexities of healthcare. Nonetheless, these factors have been found to be important indicators of healthcare access. Secondly, the relatively small number of people without health insurance and access to primary healthcare makes this study only generalizable to older people. Further, the cross-sectional nature of our study limited causal inference; temporality cannot be determined and claims about causality cannot be established. Key exposures and outcomes were based on self-reported data, which may introduce biases such as social desirability, recall bias, and nonresponse. An important strength of our study was the large sample size, which allowed us to have enough statistical power to infer the associations of interest. This study used BRFSS data, a well-established and widely used survey that captures health-related risk behaviors and preventive service utilization. This ensures that the findings are representative of the population in Virginia. To the best of our knowledge, this is a first study that assessed the impact of the COVID-19 on shingles vaccination among older adults. This study also provides insights into how health disparity impacts preventive measures such as vaccinations.\n\nThe prevalence of shingles vaccination was higher among individuals with better healthcare access and during (vs. before) the COVID-19 pandemic. The association between health insurance and shingles vaccination was stronger among those 50–64 years old compared to 65 + years old. Understanding the link between healthcare access and vaccination rates can guide targeted efforts to increase vaccination uptake among vulnerable populations. It might prompt initiatives to improve vaccine equity among older adults. The findings of this study could also guide the development of policies and interventions aimed at enhancing vaccination efforts regardless of the presence of public health emergencies. We recommend that future studies incorporate further healthcare access indicators for comprehensive understanding and conduct a longitudinal study to understand the long-term impact of public health emergencies on other health conditions.\n\nS2. The Directed Acyclic Graph for the association between health care provider and Shingles vaccination (minimum set of confounders: age, race/ethnicity and income). S3. The Directed Acyclic Graph for the association between COVID period and Shingles vaccination (minimum set of confounders: age, race/ethnicity, rurality, and sex).\n\nhttps://doi.org/10.1371/journal.pone.0316429.s001\n\n(DOCX)\n\nWe would like to appreciate the hard work of the BRFSS team members and the valued participants of this survey.",
    "category": "immunology"
  },
  {
    "title": "Modeling and simulation of an effectual triangular slotted UWB flexible antenna for breast cancer detection and healthcare monitoring",
    "authors": "Aparna Singh, R. K. Dwivedi, Vinod Kumar Singh, Manish Sharma, Kanhaiya Sharma, Bulent Yilmaz, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320806",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320806",
    "content": "With refinements in electromagnetics, diverse medical applications have evolved to detect diseases efficaciously. Breast cancer, a dominant cause of mortality among women worldwide, necessitates early diagnosis and screening for timely medical intervention. This research establishes the design, simulation, and analysis of an advanced triangular slotted circular flexible Ultra-wideband (UWB) antenna optimized for breast cancer detection and healthcare monitoring. The proposed antenna employs an extensive frequency range of 2.95 GHz to 24.2 GHz, accomplishing an impressive impedance bandwidth of 156%. It authenticates directional and omnidirectional radiation patterns with compact dimensions of 46.3 × 52.6 × 1.076 mm³. Key aspects divulge a resonance frequency at 14.35 GHz with a significant input reflection coefficient of −37.8 dB. The antenna achieves a peak gain of 3.16 dB at 5.8 GHz, with efficiencies of 59.56% and 66.88% at 5.8 GHz and 4.48 GHz, respectively. A meticulous case study involving SAR evaluation confirms the antenna’s safe exposure levels. For a flat human phantom, SAR values are 0.774 W/kg at 13.5 GHz and 0.712 W/kg at 14.35 GHz for 10 gm of tissue. For the breast phantom model, SAR values are 0.201 W/kg at 11.4 GHz and 0.152 W/kg at 14.35 GHz for 10 gm of tissue. Besides that, the antenna’s flexible design promises an excellent execution under several bending conditions, making it ideal for wearable applications. These findings establish the antenna as an efficient solution for breast cancer detection and healthcare monitoring, combining safety, flexibility, and the aptness to ameliorate early diagnosis while lowering mortality rates. Wearable antennas are pivotal for advanced healthcare applications. This section presents the literature and discusses the work related to flexible UWB antenna designed for breast cancer detection and healthcare monitoring, tackling challenges in early diagnosis and patient care.\n\nCitation:Singh A, Dwivedi RK, Singh VK, Sharma M, Sharma K, Yilmaz B (2025) Modeling and simulation of an effectual triangular slotted UWB flexible antenna for breast cancer detection and healthcare monitoring. PLoS ONE 20(4):\n           e0320806.\n        \n        https://doi.org/10.1371/journal.pone.0320806\n\nEditor:Vishal Sorathiya, Parul University, INDIA\n\nReceived:December 23, 2024;Accepted:February 25, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Singh et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and its Supporting Information files.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist\n\nThe rapid advancement of Wireless Body Area Networks (WBANs) has revolutionized wearable technology, with applications spanning medicine, defense, emergency services, and consumer electronics. WBANs consist of bio-sensors, motion sensors, and wireless antennas, facilitating body-centric wireless communication, categorized into on-body and off-body systems. On-body systems feature sensor nodes with antennas mounted on the body for monitoring biological signals [1–3]. Wearable devices, including smartwatches and bright clothing by brands like Apple and Nike, have enabled the tracking of medically relevant data. Information and Communication Technology (ICT) and e-health solutions connect urban doctors to remote patients, addressing chronic diseases [4,5]. Wearable antennas are gaining attention for healthcare monitoring and breast cancer detection, a disease that accounted for over 2.26 million new cases globally in 2020, per WHO data, and remains a leading cause of death among women [6–8]. Ultra-wideband (UWB) antennas are ideal for medical imaging due to their compact size, flexibility, and high diagnostic accuracy. Operating between 3.1 GHz and 10.6 GHz, UWB antennas enable deeper tissue penetration, which is critical for early breast cancer detection and other biomedical applications [9,10]. They must be lightweight and conformal and maintain performance under bending and stretching. Recent antenna designs with slots and unconventional geometries enhance impedance bandwidth and radiation efficiency, [11]. Safety is paramount, with SAR values kept low to minimize thermal effects from RF energy absorption. Optimized UWB antennas not only meet these safety standards but also deliver high efficiency for wearable health monitoring [12–16]. Microwave imaging, a non-invasive and cost-effective alternative to traditional methods like MRI or PET, leverages the dielectric property contrast between normal and malignant tissues for breast tumor detection, offering significant promise in early diagnosis without the risks of ionizing radiation [17].\n\nMicrowave imaging offers a cost-effective, non-invasive, and radiation-free approach for detecting abnormalities in vivo, enabling real-time, portable applications suitable for seamless integration with mobile health systems. By sending RF signals into tissues and analyzing scattered waves, 3D images are generated, leveraging differences in dielectric constants (ℇr) between healthy and pathological tissues to detect even minor lesions [18]. Unlike X-ray mammography, this method avoids compression and harmful radiation, enabling frequent image captures for early detection. Microwave hyperthermia complements imaging by treating breast tumors through targeted electromagnetic energy, offering a painless, cost-effective alternative to surgery. It has proven effective in achieving tumor necrosis, particularly when combined with radiotherapy or chemotherapy. Researchers advocate integrating imaging and treatment systems to streamline processes and enhance patient care [19]. Differential dielectric properties between normal and cancerous breast tissues (1:2.3 to 1:10) underpin microwave sensing's effectiveness. Advanced antennas enhance microwave detection, including horn antennas, CPW designs; patch antennas, and textile-based spiral discs. These developments, particularly in flexible and wearable antenna systems, promise improved cancer detection and treatment efficiency . Abdelghany et al. present a compact UWB antenna (77 ×  40 ×  1.6 mm3) for breast cancer detection, covering 3.1–10.6 GHz, achieving a peak gain of 4.1 dBi and 85% efficiency. SAR levels at the left, correct head and stomach vary across 2.45, 3.5, and 5.8 GHz, demonstrating safe exposure. Mahmood et al. designed a 60 ×  50 ×  0.7 mm³ microstrip antenna for WBAN and breast cancer detection, while Srinivasan et al.] introduced a textile antenna using jeans substrate (ℇr =  1.7) for the 2.4 GHz ISM band with input reflection coefficient>  −35 dB and a gain of 145.3 dB. D. N. Elsheakh et al. [20] developed monopole and microstrip antennas for tumor detection operating within 2.2–8 GHz and 2.4 GHz for ISM band applications. Despite advancements, bandwidth restrictions, and incomplete SAR validations highlight areas for improvement. Addressing these gaps, the proposed triangular-slotted circular UWB flexible antenna resonates from 2.95–24.2 GHz with a peak at 14.35 GHz, offering 156% impedance bandwidth, a 3.16 dB gain, and dimensions of 46.3 ×  52.6 ×  1.076 mm³. It demonstrates directional and omnidirectional patterns, excellent bending performance, and low SAR values (0.712 W/kg for flat and 0.152 W/kg for 10 gm tissue models), proving effective for non-invasive diagnostics and remote healthcare monitoring. The study details the antenna design, material selection, geometry, parametric analysis, and performance assessment. Results include surface current, radiation patterns, and SAR studies, concluding with a discussing of future potential in medical diagnostics.\n\nThis section details the methodology employed in developing the proposed wearable UWB antenna, highlighting key formulas to ensure optimal performance of the presented antenna.\n\nDesigning antennas requires assessing the electromagnetic properties of textile substrates, as changes in substrate properties affect dimensional geometry and resonance frequencies]. Innovative fabrics integrated with electronic components enable advanced functionalities like e-textiles and tracking garments, with embedded antennas providing wireless features without discomfort [21,22]. Materials such as cotton, polyester, jeans, leather, and felt serve as substrates for flexible antennas, with their dielectric constants influencing radiation efficiency. Higher dielectric constants reduce antenna size and decrease efficiency, making compact and practical designs crucial for WBAN applications [23]. Traditional rigid materials are unsuitable for wearables, which benefit from electro-textiles that adapt to stretching and deformation. The performance of wearable antennas depends on the properties of conductive (radiating element) and non-conductive (substrate) materials, selected based on dielectric characteristics, durability, and electrical conductivity. Equation 1 can estimate the material's conductivity.\n\nWhere σ is the material's conductivity, ρ is the surface resistivity, and τ is the thickness of the material []. Fabricating a miniaturized flexible UWB antenna for wearable implants requires low-loss tangent materials with a high dielectric constant to match breast permittivity, enhance coupling, and align simulation with measurement results [24]. The proposed antenna utilizes jeans textile as a substrate, an adhesive copper sheet for the ground, and a patch element.Table 1outlines the material properties.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.t001\n\nWearable technologies integrate electronic devices and intelligent sensors like antennas directly on the body for continuous health monitoring with minimal energy use. For breast monitoring, wearable microwave sensing and imaging systems offer a cost-effective, non-ionizing, and passive solution for long-term disease detection. The proposed system provides a comfortable textile-based wearable option for breast cancer screening, particularly for young women with dense breast tissue, using microwave imaging as an alternative to X-ray mammography. Material selection is based on dielectric constant measurements, including conductive and substrate materials. High conductivity and low resistivity are essential to minimize losses and optimize power radiation and reception [25]. The material selection and the antenna design were finalized by evaluating the length and width using different formulas mentioned in equations 2, 3, 4, 5, 6, 7, and 8. Finally, the prepared design was further simulated and optimized by CST software. After that, the design of the flat phantom and the breast phantom model is ready with the desired parameters. The vector network analyzer (VNA) is used to measure the real-time performance of the fabricated antenna design, which has yielded satisfactory results in terms of the desired parameters. The calculation of the length (L) and width (W) of the patch, ground size (LG & WG), and the dielectric value is completed by equations 2, 3, 4, 5 and 6.\n\nThe extension of the length ∆ L is calculated by Equation7. Furthermore, equation 8 gives the formula for calculating the radius of the patch.\n\nWhere L and W are the length and width of the patch as well as the substrate, c is the speed of light, LGand WGare the length and width of the ground, hsis the height of the substrate, and R is the radius of the patch measured in mm, fris the resonance frequency, and ℇris the permittivity.\n\nThis section contours the geometrical design, simulation, and validation of the proposed wearable UWB antenna for effective breast cancer detection and healthcare monitoring.\n\nEffective transmission of signals during microwave imaging requires the appropriate antenna design. Previous wearable UWB antennas suffer from low resolution, low bandwidth, high SAR values, and significant size issues. A wearable antenna should have broad bandwidth, low SAR, and be compact with unique characteristics for early breast tumor detection. Microstrips patch antennas with conformal designs, i.e., low cost and easy manufacturing, are extensively used. They comprise a conductive ground layer, dielectric, and conducting patch. While generally narrowband in design, substrate thickness can be varied to tune bandwidth. It is also possible to enhance the performance of this antenna by incorporating notches and slots on patches for wide bandwidth applications [26,27]. A jeans material (ℇr =  1.7 and tanδ =  0.025) is integrated at the center of two copper patches as a substrate, and one patch functions like a radiator while the bottom acts like a ground plane. This configuration increases the bandwidth and decreases surface wave losses. Moreover, a circular slot and partial ground method are used to overcome the bandwidth limitations. Therefore, the circular shape was preferred for the antenna due to its compact area and volume contrasted to other geometries, which facilitates higher bandwidth. The incorporation of a triangular slot in the circular structure amplifies impedance matching and supports ultra-wideband (UWB) operation. This design insures effective resonance at the desired frequencies with fundamental input reflection coefficient and stable radiation patterns. Additionally, the shape enables omnidirectional and directional patterns, making it ideal for wearable applications, including healthcare monitoring and breast cancer detection [28–30].\n\nThe triangular slotted antenna circular antenna has the size 52.6 × 46.3 × 1.076 mm3with the 50Ω microstrip line feed. The textile antenna is formed with jeans fabric and used as a substrate to make it more flexible. Further, examine the breast with it for early cancer detection and use it on fabric to monitor the health records of distant patients. The back part of the antenna contains the partial ground plane of 46.3 × 11.3 mm2fabricated from an adhesive copper sheet. An adhesive copper sheet manufactures the flexible antenna's front part on jeans.Fig 1depicts the steps of forming the presented antenna's design, andFig 2illustrates the geometry and background of the proposed flexible antenna.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g002\n\nRefers toFig 1, which shows the final proposed antenna configuration. Firstly, Antenna-1 is constructed and contains only the circular patch with the feed line. After the next iteration, Antenna-2 is achieved which is the ring-like structure appears as if the circular patch is a slot from the center. Further, join the triangular part (Antenna-3) to the ring and slot the ring from the above section. Finally, slot the triangular structure of antenna three again to obtain the proposed antenna.Fig 2illustrates the geometrical structure of the patch and the back view of the anticipated antenna with the partial ground, which shows that the length and width of the substrate (jeans) and the ground (copper) are L and W and LGand WG.The radius of the outer circle of the patch (copper) is R1, and the inner slotted circle is R2. The radius of the adjoined triangle is the same as R2, and the radius of the circular slot from the ring and the triangular slot from the triangle is R3and R4, centered at (0, 12). Moreover, the length and width of the microstrip line feed, centered at (0, −25), are FLand FW.\n\nHere, F1is the length of the minor slot in the feedline, enhancing the anticipated antenna's performance. In addition to the above,Table 2encapsulates the antenna's geometrical dimensions, andFig 3displays the front and back view of the actual model of the proposed fabricated textile antenna.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g003\n\nFig 4displays the performance characteristics and the input reflection coefficient [32] pattern of the presented antenna model at the different frequencies and optimization steps (antenna 1, antenna 2, antenna three, and the proposed antenna). Moreover,Fig 4implies that antenna 1 in stage 1 has −20 dB of input reflection coefficient at its resonance frequency, i.e., 14.35 GHz. Moreover, antenna 2 in stage 2 has the same input reflection coefficient value at the same resonance frequency. However, the input reflection coefficient value of antenna three increases to −22 dB at its resonance frequency. Finally, the proposed antenna has an excellent value of the input reflection coefficient, i.e., −37.8 dB, and the antenna is flawlessly operated between the frequency range of 2.95GHz to 24.2GHz which shows that the proposed antenna is highly efficient and suitable for different applications which includes fitness tracking (embedded sportswear), healthcare monitoring (tracking vital signs like heart rate, blood pressure, glucose levels), bright clothing (enable communication, navigation connectivity features), telemedicine (remote monitoring, transmitting real-time health data), WBAN's (connecting multiple sensors on the human body and collecting the data for the detection of different health issues, chronic diseases like cancer) and so on. The graph shifts toward the left or backward and becomes smooth at its final stage. (i.e., the proposed stage of the antenna design).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g004\n\nWearable antenna testing is conducted in an anechoic chamber, a controlled environment that absorbs electromagnetic waves to eliminate external interference and reflections. This ensures accurate evaluation of parameters like input reflection coefficient, gain, efficiency, and impedance, simulating free-space conditions. The chamber tests the antenna's radiation in various directions, assessing performance across all frequency bands. An input reflection coefficient below −10 dB confirms good impedance matching and minimal signal reflection. Since wearable antennas are closely integrated with the human body, deformation effects and compliance with regulatory standards, such as SAR limits, are also evaluated in the chamber. Together, the anechoic chamber and free-space measurement system are pivotal in enabling wearable antennas to be designed so that they will reliably perform when deployed.Fig 5displays the presented antenna placed inside the anechoic chamber.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g005\n\nIn the section below, we present the evolution of human phantom design models, incorporating flat and breast phantoms, to simulate realistic human tissue interactions and evaluate the antenna's performance in breast cancer detection scenarios.\n\nAn advanced human phantom model is a computational or mathematical implementation of the antenna on the body. These models unveil how an occupant interacts with its environment, precisely their radiation pattern against one another. This model is essential for evaluating and optimizing wearable antennas for applications in health monitoring, medical imaging, and communication systems.\n\nHuman flat phantom models, such as antennas, are simplified body part representations often used in electromagnetic device testing. These models have a flat surface, ideal for simulating interactions between wearable sensors or antennas and the human body. They allow controlled testing of parameters like transmission, reflection, and absorption, particularly in microwave imaging. Constructed with materials mimicking human tissue properties (permittivity and conductivity), these models simulate how radio waves interact with the body. Phantom models are applied in various areas, including antenna optimization for wearable devices like heart rate monitors and glucose sensors and for medical applications like breast cancer detection using microwave imaging. Testing on these models ensures comfort, efficiency, and signal quality (e.g., radiation patterns, SAR) in real-world applications.\n\nFig 6represents the flat human phantom model of the presented antenna whose dimensions have been considered from the triple band, dual band and mmWave wearable antenna presented by Mitra et al., Ahmad et al. and Khan et al. after experimentation and modification. The model contains the three layers of the human phantom, i.e., skin, fat, and muscle, having sizes 2 mm, 4 mm, and 10 mm. Besides that, when placing the antenna at a distance of 6 mm, the antenna model is simulated using CST software. Note the performance and the SAR value, which is crucial in developing and testing wearable antennas. This SAR ensures that these devices function effectively and safely when used in real-world scenarios on the human body.Table 3outlines the specifications of the flat phantom model.\n\n(a) Top view, (b) Side view.\n\n(a) Top view, (b) Side view.\n\nhttps://doi.org/10.1371/journal.pone.0320806.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.t003\n\nThe breast phantom model is designed to simulate the anatomy and electromagnetic properties of the breast, making it ideal for developing and evaluating new medical imaging techniques. Breast cancer remains a leading cause of death among women globally, with cancerous cells spreading to nearby tissues and lymph nodes, eventually to other body parts, such as the lungs, bones, and brain, particularly in advanced stages (stage 4). Early diagnosis is critical for improving cancer outcomes, and breast phantom models are used to safely assess and optimize antenna performance for wearable detection devices. These systems ensure that outcomes are practical, accurate, and non-hazardous for patients [30].Fig 7exhibits the breast phantom model with a tumor and its simulation with the antenna presented on CST software. The phantom out of commodities chemically similar to the dielectric properties of tissue and imitation targets as tumors. Breast phantoms are the simplified anatomical structures of the human body and can incorporate skin, fats, and glandular layers. They can also include non-invasive tumors or some other pressing factor. Model complexity may range from homogeneous (uniform material combination) to more heterogeneous phantoms that capture the entire progression of breast morphology.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g007\n\nOn top of that, phantoms are essential for developing wearable breast cancer detection systems as they can be used to test how well the antennas detect and localize tumors, verifying that not only is it able to find small targets efficiently but also remains harmless by SAR calculation.Table 4illustrates the required specifications for preparing the breast phantom model. Creating phantoms enables imaging algorithms, antenna design, and system performance to be optimized before clinical trials or deployment in real-world environments. Researchers have previously tested microwave-based breast cancer detection techniques using phantoms to determine the effectiveness of the systems in detecting tumors of various sizes and depths.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.t004\n\nThis section presents the parametric analysis of the proposed antenna, exploring the impact of key design parameters on its performance to ensure optimal functionality for wearable applications.\n\nResearchers systematically explore parameterized studies, showing that variations in parasitic loops help to understand antenna performance. Such a study is necessary to tune the antenna's properties to meet the performance standards and requirements, especially well-being monitoring and communication on top of an array of medical imaging and cancer detection. Researchers alter the physical dimensions of the antenna to investigate their role in resonance frequency, bandwidth, and radiation pattern. The antenna performance is enhanced for a particular application by surveying various shapes, such as rectangles, circles, and ellipses. Therefore, one meaningful way to analyze wearable antennas is through parameterized study. A parameterized study of a particular antenna helps adjust the changeable parameters to universally perform across conditions and applications with the best results from the designed point of view. Significant parameters can be systematically and systematically analyzed to design such antennas for wearable technology safely. Parametric analysis modulates an antenna's specific absorption rate (SAR) so that the changes in various parameters like substrate material, geometry, feed position, and frequency affect a change in electromagnetic field deposition pattern and magnitude. The SAR is directly associated with these changes. Adapting these will help reduce SAR levels, which could be safely used in wearable antennas while maintaining good performance.\n\nThe feed length variation of a wearable antenna greatly influences impedance matching, resonance frequency bandwidth, and radiation pattern. Altering the feed length may make the impedance match better or worse; this affects how well the return ratio can be shown from the antenna end to the system side. Moreover, the longer feed can help lower the resonance frequency, while a shorter one will increase it. A feed of proper length can increase the bandwidth and ensure that more frequency bands are effectively radiated from this antenna. On the other hand, an improper feed length can decrease bandwidth, changing the current distribution on top of the antenna and might result in a difference in the radiation pattern. If the feed length is not well matched, higher SAR may be generated; therefore, it is essential to select the best match so that both performance and safety can run in unison.\n\nIn the proposed work, on increasing the feed length by .2 mm, the input reflection coefficient performance of the antenna is affected, and the graph is shifted upward when FL =  1.2 mm. When FL = 1.4 mm, the antenna reflects a reasonable input reflection coefficient performance, i.e., −45 dB at 11.2 GHz. Further, at FL =  1.6 mm, the graph is again shifted backward at the same input reflection coefficient level at the frequency of 10.8 GHz. This shift is because of the resonance frequency shift, which lengthens the feed and increases the electrical path for the signal to travel. Longer path lengths may decrease the resonance frequency of the antenna, which will shift the peak to lower frequencies. If we increase the feed length, the graph shifts the element to the left. Moreover, impedance mismatch, phase delay, and coupling with a ground plane or substrate can also result in the backward and up shift of the graph.Fig 8mentions the shift in the graph on increasing the length of the feed on an antenna.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g008\n\nChanging the width of the ground plane in a wearable antenna can have several effects on its performance. Moreover, separating the ground plane width in wearable antennas is a crucial design feature. Typically, widening the ground reduces resonance frequency, which results in a narrow bandwidth, making the radiation pattern more directional. Conversely, decreasing the width can increase resonance frequency and broaden bandwidth while the radiation pattern becomes more approximated to the omnidirectional pattern. The ground plane width also affects the efficiency and SAR values, as both needs to be balanced carefully for optimum antenna performance.Fig 9shows the distortions in the graph when changing the width of the ground of an antenna.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g009\n\nHere, when the width of the ground decreases, the graph goes up and down and shifts towards the left and sometimes upwards, increasing the resonant frequency and bandwidth of the antenna. Additionally, this will improve impedance matching, depending on the specific design. However, it may also decrease efficiency and increase SAR values, which are essential factors to consider in wearable antenna applications.\n\nChanging the radius of the outer circle, such as a circular patch element, can significantly affect several performance parameters associated with an antenna. Change in the outer circle of an antenna mainly affects its resonant frequency (wavelength) bandwidth, radiation pattern, and gain. A higher radius generally leads to lower resonant frequency and more considerable gain, and a narrower beam width lowers the radius and has the opposite effect. It needs to be carefully optimized, especially for applications where the size and SAR are essential.\n\nThe plot illustrations shown inFig 10manifest that when the radius of the patch of the proposed antenna is decreased; it results in an upward shift of the antenna. Generally, when the patch radius becomes smaller, this also illustrates an upward shift in the graph of a wearable antenna and suggests poor impedance matching causes higher resonant frequency and narrowing bandwidth that results in much more surface wave losses, thereby causing less radiation efficiency but surging SAR. This results in less effective performance, as demonstrated by the trajectory up and to the right.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g010\n\nThis section presents and analyzes the experimental results obtained from the wearable antenna designs, highlighting the key findings and their implications for future applications in wireless communication and medical fields. Detailed discussions are provided on the performance metrics and potential improvements.\n\nThe input reflection coefficient behavior of a wearable antenna directly affects its performance and efficient operation. Typically, input reflection coefficient of −10 dB or better over the desired frequency bands ensures minimal reflections and power radiates most effectively. Good design, proper material selection, and environmental consideration are vital in obtaining wearable antennas with excellent input reflection coefficient performance. The wearable textile antenna's standard input reflection coefficient plot shows how well it matches the transmission line over its working frequency range. The x-axis of the plot displays the band at which the antenna is used to operate, generally in GHz or MHz. The y-axis represents the input reflection coefficient in dB. Small negative values are used in plotting [31,32].\n\nMoreover, the antenna's performance with power transfer is better when input reflection coefficient becomes more negative. The points where the input reflection coefficient drops substantially below −10 dB are the frequencies at which that antenna is well-matched. The frequency bandwidth in which the input reflection coefficient is still smaller than −10 dB is the frequency range that exhibits the antenna's effective area.\n\nHere, the present antenna's input reflection coefficient is obtained by simulating the prepared design on the CST software. Secondly, real-time analysis and measurement can be done by connecting the antenna with the vector network analyzer (VNA) and taking the measurements using the software. The simulated and measured plot is disposed of inFig 11, and real-time VNA measurements are depicted inFig 12, which illustrates that the antenna resonates between the wide frequency range below −10 dB and the resonance frequency of the antenna, is 14.35 GHz with a maximum −37.8 dB input reflection coefficient performance. Then, the antenna's bandwidth is 66.88%, which manifests that the antenna is suitable for cancer detection and WBANs, biotelemetry, and healthcare applications. Moreover, the measured and simulated input reflection coefficient is similar, meaning the simulated antenna is perfect for real-time analysis.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g011\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g012\n\nAlthough the close alignment of simulated and measured results inFig 11accentuates the robustness of the propounded antenna design. This remarkable agreement, while unprecedented, stems from precise fabrication techniques, rigorous VNA calibration, and explicit simulation modeling that mirrored experimental conditions. Minor deviations were minimized through meticulous design and measurement processes.\n\nThe surface current distribution on a wearable antenna is essential to predict its radiation performance and how it may be affected by materials, bending, and presence near the human body. Additionally, current distribution illustrates how the electric current moves along the radiating elements of an antenna through its surface. The substrate material (e.g., a fabric cotton, polyester, or jeans) and the conductive materials employed within them (i.e., copper /conductive threads) play a role in how surface currents are distributed through fabrics. Changes in the dielectric constant of the substrate material can alter current distribution, radiation pattern, and antenna efficiency. The antenna's resonance frequency and radiation characteristics can be shifted, potentially by bending its current paths, which changes the effective length of the current path. Near-field surface currents depend on tissues ' dielectric properties when the antenna is attached to the human body. This proximity can give the detuning of antenna configurations that will degrade its input reflection coefficient, gain, and efficiency. The surface current distribution is generally exposed to electromagnetic simulation tools, such as CST microwave studio and high-frequency simulation software (HFSS), that can show the amount of curl on a contour layer throughout the antenna. Additionally, measurements can be taken with special devices to verify the simulation results.\n\nFig 13(a)andbillustrates the current distribution across the proposed antenna at the two frequencies 4.48 GHz and 14.35 GHz, which represents that the amplitude of current across the feedline is about 71.1 A/m at the frequencies 4.48 GHz and 14.35 GHz and the current ranges from 40 A/m to 0 A/m is distributed evenly across the antenna at both the frequencies determining the antenna's good performance and reliability, especially under varying conditions encountered in practical use.\n\n(a) 4.48 GHz and (b) 14.35 GHz.\n\n(a) 4.48 GHz and (b) 14.35 GHz.\n\nhttps://doi.org/10.1371/journal.pone.0320806.g013\n\nThe radiation pattern of a wearable textile antenna is an essential feature for its practical operation since it shows how the electromagnetic energy emitted by the source has been radiated in different directions. This type of antenna integrated into clothes or fabrics is usually more comfortable and even available for visitors simultaneously. Most wearable textile antennas have a directional or semi-directional radiation pattern, thus directing energy in specific directions. It helps optimize signal strength, which reduces interference when the antenna is body-worn. Moreover, the radiation pattern is a function of the distance between the antenna and the human body. The human body's dielectric properties can also absorb and reflect electromagnetic (E.M.) waves, which may induce deformation in pattern shape, potentially decreasing radiation efficiency. Also, developing wearable textile antennas requires considering the influence of surrounding materials, such as clothing, in daily life and orientation when placed on or near a human body, and this aims to obtain the radiation pattern that satisfies the application's needs for communication, health monitoring, or any other use. Thus, the antenna's design, material properties, and interaction with the human body influence the radiation pattern of wearable textile antennas. Achieving a reliable and efficient radiation pattern in these flexible, body-worn devices requires careful consideration of these factors to ensure optimal performance in real-world conditions.\n\nFig 14displays the antennas simulated and measured polar E-plane and H-plane radiation patterns at 4.48 GHz and 14.35 GHz resonant frequencies. Additionally,Fig 14demonstrates that at the lower frequency, 4.48 GHz, the antenna shows the directional radiation pattern, but at the higher frequency, 14.35 GHz, the antenna exhibits the omnidirectional radiation pattern with main and back lobes, and the antenna resonates in all the directions. Omnidirectional antennas provide uniform coverage in all directions, making them suitable for general-purpose communication. In contrast, directional antennas focus energy in a specific direction, offering more excellent range and reduced interference, which is ideal for targeted communication needs. Furthermore, the presented polar plot of an antenna mentions that the simulated E and H- planes of the antenna at both frequencies are somewhere similar to the measured radiation plot of the presented antenna, which means that the simulations in the CST environment are similar to the measured real-time radiation plot measured on VNA.\n\n(A) 4.48 GHz and (B) 14.35 GHz.\n\n(A) 4.48 GHz and (B) 14.35 GHz.\n\nhttps://doi.org/10.1371/journal.pone.0320806.g014\n\nParameters like gain, directivity, and radiation efficiency are significant in the performance characteristics of any antenna, whether it be a semicircular slotted wearable textile (SWT) or another instance. Gain measures the carving ability of an antenna to concentrate input power for generating radio waves in a particular direction. Decibels (dB) typically measure gain. The higher gain causes more input power in a specific direction, which is significant for wearable antennas. Their use involves body effects or presence near radiating materials, causing the signal strength at various regions around them to be disrupted frequently due to continuous movement. The gain (G) can be measured as the ratio of radiation efficiency (η) to the directivity (D), as shown in Equation9.\n\nBesides that, directivity quantifies the extent to which an antenna's radiation pattern is preferentially in one direction. It is the degree of the radiation intensity in one direction to a reference point, comparing across all other directions. It is an essential parameter for some applications of interest. It can be efficiently employed to determine how well the wearable textile antenna radiates or receives signals from a given direction, as this happens naturally with bright e-textile clothing.\n\nMoreover, the radiation efficiency is the ratio of the power that comes out from an antenna to send some signal and the total input power of the antenna, and it includes losses due to materials (the textile substrate) and the antenna's design parameters. Some materials employed in wearable antennas have higher losses than those used for conventional antennas. In wearable applications, this is critical as high radiation efficiency implies that the antenna effectively radiates most of the power it receives, facilitating a good performance.Fig 15(a), 15(b) and 15(c) depict the simulated and measured gain, directivity, and radiation efficiency plot which shows that the presented antenna has a peak gain of 3.16 dB at 5.8 GHz with the peak directivity of 6.5 dB and 8 dB at 5.8 GHz and 24 GHz and radiation efficiency of more than 150% at 2.5 GHz, 59.56% at 5.8 GHz and 66.88% at 4.48 GHz respectively. Likewise, the plot of the gain, directivity, and radiation efficiency can exhibit fluctuations (going up and down) due to the complex interplay between the antenna's design, the materials used, the environment in which the antenna operates, and the frequency-dependent behaviors. Understanding and mitigating these factors is crucial for optimizing the antenna's performance. In Wearable antennas, particularly those with complex shapes such as slots, patches, or other geometries, multiple resonant modes can be excited simultaneously. Due to this, the radiation patterns of each mode will have a different shape, and hence, directivity may change at various frequencies as we excite these modes. Furthermore, the resonant modes of the antenna change as a function of frequency and are responsible for how well an antenna focuses energy in different directions. In addition, changes in the dielectric constant, physical deformations, body proximity effects, interaction with nearby objects, and narrow bandwidth for several frequencies can influence the antenna's effective radiation pattern and lead to fluctuation in a directivity plot.Table 5represents the simulated gain, directivity, and radiation efficiency values.\n\n(A) Gain, (B) Directivity and (C) Radiation efficiency of the presented antenna at different frequencies.\n\n(A) Gain, (B) Directivity and (C) Radiation efficiency of the presented antenna at different frequencies.\n\nhttps://doi.org/10.1371/journal.pone.0320806.g015\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.t005\n\nBesides that, the plots of gain, directivity, and radiation efficiency are indistinguishable in all ways; only there are specific peaks mismatch, which does not cause any change in the results and applications, and the presented antenna is perfect for the applications of cancer detection, telemedicine, remote health care monitoring and for all body-centric wireless communication (BCWC).\n\nBending analysis of wearable antennas is essential due to their deformation effect on the human body. Bending can significantly impact wireless properties, affecting resonance frequency, input reflection coefficient, radiation pattern gain, and specific absorption rate (SAR). Placing the wearable antenna over curved human tissues distorts the antennas’ physical size and radiation lengths upstream. That can cause a change in the resonant frequency. Bending may cause a change in input reflection coefficient, probably due to the excitation mismatch between the antenna and transmission line or feeding network, forcing more reflections and lower power transfer efficiency, resulting in worse input reflection coefficient. Due to bending, poor impedance matching leads to low performances and often results in decreased gain due to the variations of effective aperture and radiation pattern. Further, bending can alter how the antenna interacts with the body and, in some cases, increase SAR at specific regions. Also, this is important for how much R.F. energy a body absorbs, and the safe limit should not be exceeded. By characterizing how bending impacts the antenna, engineers can ensure that their designs will be robust and reliable even when worn on a human body. With the mix of materials and careful optimization of antenna geometry, it is possible to mitigate this performance degradation due to bending and maintain impressive real-world (3D) radiated efficiency. In the presented antenna, both sides of the cylindrical bending of the antenna are performed in CST software at the radius of 4 cm, i.e., 40 mm, and we are obtaining an excellent input reflection coefficient performance of the presented antenna.\n\nFig 16shows the bending done at 40 mm in the CST environment and the proposed antenna's simulated, measured, and bending input reflection coefficient performance. The presented antenna is simulated again in the CST environment, and the input reflection coefficient parameters obtained are more than satisfactory; this confirms that the presented antenna is bent correctly on the human arm or breast or the cloth, and thus, it is further helpful for the breast cancer detection as well as healthcare monitoring and WBAN's. Thus the above bending analysis confirms that the wearable antenna presented in this research is designed as a proof of concept for breast cancer detection using UWB technology. While the results provided in the paper are based on modeling and simulations, they are grounded in established electromagnetic principles and real-world material properties. The authenticity of the antenna's performance is demonstrated through simulations and analysis, which are indicative of its potential for practical application. However, further experimental validation, including clinical trials, will be necessary to confirm its real-world effectiveness and accuracy for healthcare monitoring.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g016\n\nThe specific absorption rate (SAR) in the case of wearable antennas is the amount of radio frequency (R.F.) electromagnetic energy a human absorbs when exposed to R.F. radiation from an antenna. It is the benchmark for examining how much E.M. waves are absorbed by tissues. SAR is the standard level to measure how many electromagnetic waves can be packed into human tissues when exposed near an antenna. Normal restrictions have been recognized to point out the secure ranges of SAR. SAR levels were judged based on USA and European standards. For wearable antennas, the design must be in such a way that its SAR will remain below the standards of the USA established by the Federal Communication Commission (FCC), i.e., 1.6 W/Kg and the EUROPE standard established by the International Commission for Non-ionizing Radiation Protection (ICNIPR), i.e., 2 W/kg for optimal designing purposes [32]. The human phantom model design mimics the characteristics of a human body during simulations. Also, the closer to our body that we hold an antenna, the higher the SAR radiation levels will be fixed. Antennas must limit the amount of energy they absorb while maintaining performance. The conductive and dielectric properties of materials used in wearable antennas affect SAR values. Furthermore, SAR generally increases with frequency, operating mode, and top transmission powers. Wearable antennas will be subject to bending and deformation, further changing their electromagnetic performance, hence changing the SAR. Thus, SAR estimation provides a safe exposure level to electromagnetic radiation and ensures that it will not deteriorate the wireless communication of wearable antennas.\n\nFlat phantom models allow the SAR to be tested for wearable antennas in a repeatable way, guaranteeing that such devices can be operated safely close to the human body.\n\nThe flat phantom model is designed to measure the SAR of a source in terms of safety for wearability antennas. The flat phantom model simulates human Tissue to determine how much electromagnetic energy gets absorbed when it is on or near the body. It is important because it matters whether the total power of all wearable devices, once used, adds up to an amount that exceeds the regulatory limits for electromagnetic exposure.Fig 17exhibits the SAR calculations at the two distinct frequencies and one resonance frequency, simulated in the CST environment. Here, the best acceptable SAR value at the resonance frequency of the antenna, i.e., 14.35 GHz, is 0.712 W/Kg for 10 gm of Tissue. The rest of the SAR values are 0.774 W/Kg and 0.794 W/Kg for 10 gm of Tissue at the frequencies 13.5 GHz and 15 GHz, which also seem to be the satisfactory values, and all these values fulfil the required estimated values for the desired WBANs and healthcare applications as they are under the safety limits.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g017\n\nThe specific absorption rate (SAR) evaluation of wearable antennas for breast health monitoring and other biomedical applications is a crucial process, which generally requires performance measurement inside an anatomically realistic that mimics the human body. The breast phantom model is designed to simulate the dielectric properties of human breast tissue and can be used to evaluate R.F. power absorbed while operating an antenna near breasts.\n\nFig 18(a)and(b)represent the SAR value at two frequencies: its resonance frequency and the requisite SAR value obtained under the secure limits. The proposed antenna exhibits a 0.201 W/Kg SAR value at the frequency of 11.4 GHz and 0.152 W/Kg at the resonance frequency of 14.35 GHz, which is perfectly under the USA and EUROPE standards. Thus, this is a breast phantom SAR study to ensure the subsequent wearable antennas for breast health monitoring are safe and compliant with acceptable E.M. exposure. Antenna design, frequency of operation, and distance from the target are essential in lowering SAR to be satisfactory to the affected person's protection.\n\n(A) 11.4 GHz, (B) 14.35 GHz.\n\n(A) 11.4 GHz, (B) 14.35 GHz.\n\nhttps://doi.org/10.1371/journal.pone.0320806.g018\n\nIn simulating the radiation pattern of a wearable antenna on a breast phantom model, several factors affect how much energy the wireless appliance radiates through tissue. Any breast phantom model, posing the same characteristics as human tissue material near an antenna, can influence radiation patterns greatly due to its dielectric or absorption properties.\n\nFig 19illustrates the simulated E-plane and H-plane polar radiation pattern, taken by placing the proposed antenna at three different places from the breast phantom model, i.e., at 50 mm, 40 mm, and 30 mm. Observing an isotropic, directional, and omnidirectional radiation pattern at 4.48 GHz, and isotropic and directional lobes attain 14.35 GHz. Thus, the radiation pattern of a conventional wearable antenna on the phantom always differs from that in free space.\n\n(a), (b) 4.48 GHz and (c), (d) 14.35 GHz when it is applied on breast phantom model.\n\n(a), (b) 4.48 GHz and (c), (d) 14.35 GHz when it is applied on breast phantom model.\n\nhttps://doi.org/10.1371/journal.pone.0320806.g019\n\nThe shift from free space to the actual body will cause several practical problems, such as reduced gain, asymmetric radiation due to energy absorption by tissue, and shifted directivity. Accurate modeling of these effects is essential, simulating the antenna performance for human health monitoring on wearable applications such as breast health monitors.\n\nWhen the wearable antenna is placed at varied distances from a breast phantom, the input reflection coefficient response varies due to impedance matching and coupling between the antenna and phantoms.\n\nClose proximity to the human body:Closer to the breast phantom, electromagnetic waves interact more with the tissue, which causes variations in the input impedance of this antenna. Moreover, for smaller distances, the absorption of electromagnetic waves by the breast tissue is increased, which results in higher input reflection coefficient (a lower dB value). Also, the tissue would shift the antenna's resonant frequency, causing its designed operating frequency to no longer align perfectly. Moreover, if the phantom is too close to the antenna, there will be too much coupling, causing unwanted signal reflection and degrading the input reflection coefficient.\n\nFarther from the human body:The reduction in coupling between the antenna and breast tissue translates to less loss and lower reflections, which improves input reflection coefficient at longer distances. Removing the antenna slightly from the phantom leads to a better match between an antenna and its feed line, improving input reflection coefficient performance. In addition, when the distance increases, the tissue interacts less with energy, and input reflection coefficient improves because less radiation is absorbed. However, separations that are too high can result in lower performance detection or monitoring.Fig 20presents the plot of input reflection coefficient performance on placing the antenna at discrete places from the breast phantom model. The input reflection coefficient of the antenna changes on changing the distance. Also, as the distance decreases, the resonance frequency shifts towards the backward direction by changing the antenna range to 11 GHz with −29 dB return loss.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.g020\n\nDesigning and simulating the triangular-slotted circular UWB flexible antenna for breast cancer detection and healthcare applications shows advanced progress in wearable antenna technology. The developed antenna has demonstrated that it can offer a wide band around 2.95–24.2 GHz with a bandwidth of approximately equal to156% and shows good potential for medical applications. Its 46.3 × 52.6 × 1.076 mm3size and bending properties make it appropriate for healthcare monitoring and breast cancer detection. If the antenna lacks a wide range of frequencies and is more prominent in size, this would reduce the quality of high-resolution images. Also, the antenna will be restricted to specific communication and protocols as the devices cannot support the multiple band frequency.\n\nMoreover, an antenna that is too large or cumbersome to wear would be awkward. The user would need to stay longer for it to function as a helpful tool. Such a design would also restrict its usability for permanent health monitoring or fitness tracking since it may be uncomfortable to wear. Also, the large size results in performance degradation and high-power consumption; therefore, the presented antenna is compact, resulting in many advantages. The most significant requirement for these antennas is that they should be small enough to be hidden within clothing or wearable devices. An antenna that is too big may be too stiff for use in intelligent fabrics or wearable medical technology.\n\nThe antenna exhibits input reflection coefficient of −37.8 dB at its resonance frequency of 14.35 GHz. It indicates the efficient radiation properties that improve transmission with minimum signal reflection or impendence matching, making it suitable for its potential applications. Therefore, the antenna is desirable for microwave imaging and cancer detection. Bending tests have shown that the antenna retains its performance after deformation. The antenna's flexibility ensures it can instantly conform to the body by delivering reliable performance and additional validations required for real-world healthcare scenarios. This adaptability offers comfort for its wearers but maintains functional integrity simultaneously. In addition, the SAR values of 0.712 W/kg for the flat phantom model and 0.152 W/kg breast phantom models are significantly below the safety limits. This value of SAR confirms that the antenna is also safe under prolonged use at a near distance from human tissue in daily life operations. The small SAR values demonstrate for the first time in detail how effectively a wearable medical device can minimize electromagnetic exposure. In addition, if the SAR value exceeds 2 W/Kg, it can cause immoderate heating of the body tissues, leading to thermal damage, discomfort, and burns. Long-term exposure to high SAR values can also affect the nervous system and other biological effects. Therefore, keeping SAR levels within safe limits is crucial for wearable antenna design and usage. Alternatively, the microwave imaging application shows the potential of using this antenna as an inexpensive and non-invasive substitute to regular screening methods for the detection of breast cancer. Miniaturization, comprehensive frequency coverage, and flexibility of the presented antenna will pave the way for future wearable healthcare devices that can act as an excellent tool in continuous women's healthcare monitoring, including early breast cancer detection.\n\nFuture plans for this research include testing the proposed triangular-slotted UWB flexible antenna design on human subjects to validate its effectiveness in breast cancer detection. The results from these tests will be compared with traditional mammography images to assess the accuracy and reliability of the antenna. This comparison aims to establish the antenna as a non-invasive, radiation-free alternative or complement to mammography. Additionally, efforts will focus on optimizing the design for real-world applications, ensuring it meets clinical standards and is suitable for widespread healthcare use. These steps will help transition the technology from simulation to practical implementation.\n\nThis section presents a comparative analysis of the key performance metrics of the proposed wearable antenna against existing designs. It evaluates parameters such as antenna dimensions, wavelength, SAR and designs to highlight the advantages and limitations of the proposed approach.\n\nThe significant factors for performing the performance comparison between wearable antennas are input reflection coefficient, gain, directivity, SAR, bandwidth radiation efficiency, flexibility, and material properties. The section provides the performance analysis of different wearable antennae, including microstrip patch, monopole, slot, and textile-based antennas.Table 6represents the performance characteristics of different antennas and the triangular-slotted wearable textile antenna. Here, we observe that the performance characteristics of the other antennas are not correctly determined, the bandwidth and the efficiency are low, and the SAR value is calculated only for the breast phantom model. The researchers have not done the comparative analysis of the flat and breast phantom correctly. However, the proposed antenna's performance characteristics have been determined correctly. The SAR value for the flat and breast phantom models is calculated and compared appropriately. The antenna exhibits a good frequency range, which is suitable for many BCWC, biotelemetry, and healthcare monitoring applications, and it has a good range and SAR value for early breast cancer detection.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320806.t006\n\nIn conclusion, the proposed triangular slotted circular UWB flexible antenna performs well for health care applications and is highly suitable for breast cancer detection. A brief review of research papers based on the recent approaches to designing microstrip patch antennas for breast cancer detection suggests that microwave imaging is a promising candidate for offering an alternative way of breast screening. Microwave exposure is considered safe for humans. Microwave imaging is considered a safer, low-cost alternative for tumor screening in the breast than other currently existing methods. In addition, wearable and non-wearable microstrip patch antennas have been surveyed for breast cancer detection and other on-body applications. The presented antenna is constructed from the jeans substrate having dielectric constant ℇr = 1.7, which is in between the ground and the patch layer, forms with the adhesive copper sheet with an ultra-wideband operation from 2.95 GHz to 24.2 GHz and large bandwidth of up to 156%; it can achieve around −37dB input reflection coefficient at the resonance frequency14.35GHz, which is very stable across operating range effects due its fractal radiator design. With a footprint measuring just 46.3 x 52.6 mm² and only 1.076 mm high, it is ideally fitted for use in wearable applications with safe specific absorption rate (SAR) values of the antenna are also achieved, with 0.712 W/kg for a flat phantom for 10 gm of tissue at an operating frequency and 0.152 W/kg in case of a breast phantom again for 10 gm of tissue, making it safe for deploying inside medical environments as well. The achievement of miniaturization, wide frequency range, and high bandwidth property suits it well for amplifying continuous health monitoring and breast cancer detection techniques for future trends.",
    "category": "materials_science"
  },
  {
    "title": "Mechanical properties research of unconsolidated hydrate-bearing sediments under the effect of clay minerals",
    "authors": "Yuanwei Sun, Yuanfang Cheng, Cui Li, Liqiang Wang, Xiaodong Dai, Chuanliang Yan, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0319772",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319772",
    "content": "The shallow hydrate reservoir in the Shenhu Sea area is mainly composed of clayey silt. Clay mineral has an important impact on the mechanical properties, and the hydrate decomposition aggravates this impact. Therefore, the composition and geological conditions of shallow clay hydrate-bearing sediment in Shenhu sea area are fully considered, hydrate-bearing sediment samples with similar physical properties are synthesized in situ. Then, indoor triaxial mechanical experiments are carried out, and the effect of clay minerals on the mechanical property is analyzed. The results show that the clay content and clay type have an important impact on the mechanical properties of unconsolidated hydrate-bearing sediment. With the increase of clay content, the strain hardening characteristics are prominent, the yield stage is longer, and the plasticity is enhanced. Hydrate-bearing sediment with different clay content shows similar mechanical laws under the influence of hydrate saturation and effective confining pressure. The peak strength, elastic modulus and Poisson’s ratio all show a downward trend, but the peak strength and elastic modulus change more obviously. The peak strength changes linearly with hydrate saturation, while nonlinearly with effective confining pressure, especially 0–3 MPa. This is the comprehesive result of clay particle’s movement and fragmentation, clay hydration and expansion, affecting hydrate formation and sediment cementation. When the content ratio of montmorillonite/illite decreases, the peak strength and elastic modulus show an increasing trend. Because the frictional resistance and connection strength of illite crystal layer are larger with bigger particle size, weaker hydration and thinner water film. The research can provide reference for drilling and production engineering of natural gas hydrate (NGH) reservoir in the Shenhu sea area.\n\nCitation:Sun Y, Cheng Y, Li C, Wang L, Dai X, Yan C (2025) Mechanical properties research of unconsolidated hydrate-bearing sediments under the effect of clay minerals. PLoS ONE 20(4):\n           e0319772.\n        \n        https://doi.org/10.1371/journal.pone.0319772\n\nEditor:Jianguo Wang, China University of Mining and Technology, CHINA\n\nReceived:August 16, 2024;Accepted:February 9, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Sun et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper.\n\nFunding:This work had been financially supported by the Dongying Science Development Fund (DJ2023001), the National Natural Science Foundation Project of China (51974353, 51991362, 52104014), the Natural Science Foundation of Shandong Province (ZR2019ZD14), the CNPC Major Science and Technology Project (ZD2019−184−003) and the Project Establishment and Construction Team of Young and Innovative Talents Introduction and Education Plan of Colleges and Universities in Shandong Province.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAs a new clean energy in the 21st century, NGH is characterized by abundant reserves and high energy density, which organic carbon is twice the total carbon of existing oil, natural gas and coal [1–3]. The exploration and development will help optimize the energy structure and reduce carbon emissions.\n\nThe Shenhu sea area is in the middle of the northern continental slope of the South China Sea. The shallow hydrate reservoir is mainly clay silty sand, with a water depth of 1230 ~ 1245m and a seafloor temperature of less than 4 °C. The average ground temperature is 14.37 °C, and the formation pressure exceeds 10 MPa. The hydrate is distributed 183 ~ 225m below the mudline, and filled in the unconsolidated sediment in a dispersed form [4,5]. The sediment is mainly composed of terrigenous clastic mineral, clay mineral and little biocarbonate with a lower median pore radius of less than 1.5μm. The clastic mineral is mainly silty sand with particle size of 4-63μm [6]. The clay mineral is mainly illite and montmorillonite, accounting for more than 65%. The hydrate saturation is 16% ~ 45% and the porosity is 0.2–0.45 [6–10]. The hydrate decomposition leads to the change of formation pressure. The water rock interaction and seepage process aggravate the change of formation microstructure, resulting in complicated mechanical properties and deformation characteristics [9–20]. Therefore, the mineral composition, particle size distribution and physical properties of hydrate-bearing sediment have an important impact on the mechanical properties.\n\nAt present, researches have been carried out on the physical and mechanical properties of hydrate formation [21–27]. Indoor triaxial experiment is a commonly used research method. The experiment on the undisturbed samples of submarine NGH is carried out, and the result is compared with that of artificial hydrate samples and reconstituted hydrate samples [28,29]. It is believed that the particle size and cementation state will affect mechanical properties. The characteristics of natural hydrate-bearing samples, artificial hydrate-bearing samples and ice bearing samples are discussed, showing that the hydrate increases the shear strength and longitudinal wave velocity, but the longitudinal wave velocity of fine sediments is smaller than that of coarse sediments [30–32]. On this basis, the impact of filling types is further observed [33]. Then, the experimental conditions are analyzed, and the hydrate formation temperature has less effect on the mechanical properties, while the temperature, back pressure, effective confining pressure and hydrate saturation during triaxial experiments have significant effect [34–36]. The thermal, electrical, acoustic and mechanical properties are systematically studied, showing that the thermal conductivity is related to the phase state, saturation and spatial distribution, and the peak strength increases with the increase of hydrate saturation and confining pressure [37–39]. Now, the resonant column experiment is used to test the dynamic mechanical properties, and the dynamic elastic modulus and damping structure change law under confining pressure are explored [40,41].\n\nDuring the NGH exploitation, the hydrate decomposition caused by temperature, pressure and phase equilibrium would weaken the formation strength, and influence the mechanical properties and constitutive relationship [41,42]. The strength and deformation characteristics in permafrost regions under different exploitation conditions are studied, showing that when the load is greater than the sediment strength after decomposition, thermal injection would lead to reservoir damage [43,44]. Kaolin is used to simulate submarine hydrate bearing sediments, showing that with the increase of confining pressure, the peak strength first increases, then remains flat, and finally decreases [45]. It is similar to the nature of frozen soil hydrate [46], because the effective confining pressure causes the pressure melting of ice crystals in the sample. The stress-strain curve of strongly cemented siltstone reservoir shows a typical rock stress-strain relationship under low effective confining pressure, which is different from the less obvious peak strength and strain hardening characteristics under high effective confining pressure [47].\n\nIn conclusion, researches on the mechanical properties of NGH have been carried out, but fail to consider NGH decomposition, clay content and clay type. Therefore, fully considering the geological and mechanical characteristics of NGH reservoir in the Shenhu sea area, hydrate samples with different clay content and type are synthesized in situ, triaxial experiments are carried out. Then the mechanical parameters and change laws under different clay content, clay type, effective confining pressure and hydrate saturation are obtained. The research is helpful to clarify the mechanical characteristics and deformation characteristics of NGH reservoir, and provides basis and reference for the design and optimization of drilling and production engineering.\n\nThe experimental device mainly includes the NGH in-situ synthesis system, low-temperature rock mechanics triaxial experiment system, core preparation device and physical property measurement instrument. The flow is shown inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g001\n\nThe M190C microcomputer is used to control the low temperature cold storage for environmental constant temperature with a range of −25 °C to 50 °C and an accuracy of 0.1 °C. The TAW-100 microcomputer is adopted to control low temperature of triaxial testing machine. The axial pressure range is 0–100 KN, with an accuracy of 0.1 KN, the confining pressure range is 0–100 MPa, with an accuracy of 0.1 MPa, and the pore pressure range is 0–80 MPa, with an accuracy of 0.1 MPa. The axial deformation range of the sensor is 0–10mm, the radial deformation range is 0-6mm, and the measurement accuracy is 0.25% FS. The axial load is driven by ball screw, which avoids poor hydraulic oil fluidity at low temperature. The autoclave uses high quality carbon steel forgings. The chip deformation sensor is improved by using special low temperature viscose, suitable for low temperature and high pressure. The methane purity is 99.9%. The equipment is shown inFig 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g002\n\nThe gas hydrate phase equilibrium model [48] of porous medium is adopted, and the hydrate formation conditions and rate are comprehensively considered. The temperature is set at 2 °C. The model is shown inequation (1).\n\nwhere, P is the pressure of NGH system, MPa; T is the temperature of NGH system, K.\n\nThe chemical equation for NGH formation is shown inequation (2).\n\nwhere, n is the reaction coefficient, 5.75.\n\nThe quality of H2O required to be added to the hydrate sample can be calculated byequation (3).\n\nwhere,is the quality of water required, g;Vis the total volume of hydrate sample, cm3;ϕis the porosity, dimensionless;Shis the saturation, dimensionless;is the density of hydrate sample, g/cm3.\n\nThe “immersion+dropping” composite method is used to add water to ensure that the sample density error does not exceed 0.01g. While the amount of hydrate formation is verified by measuring the CH4volume after the experiment. The hydrate saturation is obtained comprehensively. The calculation method is as shown inequation (4).\n\nwhere,is the theoretical target density of hydrate sample, g/cm3;mcoreis the dry sample quality, g.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g003\n\nThe specific settings of experimental contents are shown inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.t001\n\nAccording to the hydrate reservoir conditions in Shenhu sea area [49], the test parameters are set. The range of plastic limit values for hydrate-bearing sediment samples with different viscosities is 21.4% –25.6%, the range of liquid limit values is 56.1% –60.3%, and the range of residual moisture content is about 12%. The stress strain curve is obtained when the effective confining pressure is 2.5 MPa, the saturation is 30%, the clay content is 0%, 8%, 16%, 24%, 32% respectively, and the content ratio of montmorillonite/illite is 1:1, as shown inFig 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g004\n\nFromFig 4, the stress-strain curve (Cclay= 0%) is obviously divided into compaction stage, elastic stage, yield stage and post peak stage. While the stress-strain of clay hydrate sample is relatively vague in stage division, with short elastic stage and long yield stage. The axial deformation is obviously greater than the radial deformation (axial strain>lateral strain). With the increase of clay content, the peak strength is less obvious, and the strain hardening feature is more prominent. This is because the clay blocks the pore communication channel, hinders hydrate formation, and changes the sediment cementation. Moreover, the clay particles are small in size, easy to be hydrated and expanded, and the friction and cohesion between particles are relatively small, reducing the peak strength. Meanwhile, the slope of the stress-strain curve decreases, the elastic stage shortens, the plastic stage lengthens, and the deviator stress changes slightly during the plastic stage, indicating that during the loading process, clay particles will enter the hydrate gap, making the sample more compact and bearing capacity enhanced.\n\nWhen the hydrate saturation is 30%, the effective confining pressure is 0.5 MPa, 1 MPa, 3 MPa, 5 MPa respectively, the clay content is 0%, 8%, 16%, 24%, 32% respectively, and the content ratio of montmorillonite/illite is 1:1, the peak strength, elastic modulus and Poisson’s ratio are obtained, as shown inFigs 5–7respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g007\n\nFromFig 5, with the increase of clay content, the peak strength decreases, but the decrease amplitude is large at the initial stage, then decreases and remains basically unchanged. It is due to the obvious blocking effect on hydrate formation caused by clay entering the pore channel at the initial stage. With the increase of clay content, the peak strength further decreases under the combined effect of clay cementation and pore filling, but the reduction effect is weakened. When the effective confining pressure is large, the effect of clay content on reducing the peak strength will be further weakened. With the increase of effective confining pressure, the peak strength under different clay content shows a nonlinear increase. Especially, when the confining pressure increases from 1 MPa to 3 MPa, the peak strength appears a significant jump. The reason is that the effective confining pressure makes the sample more compact and the strength increases. But when the effective confining pressure increases to a certain extent, the ice crystal would melt under pressure, the clay hydration would be enhanced, and the cementation would be weaken, leading to the strength reduction.\n\nFromFig 6, the elastic modulus is less than 1.0 GPa, showing a strong plasticity. With the increase of clay content, the elastic modulus shows a downward trend, but individual data is irregular. With the increase of effective confining pressure, the elastic modulus increases, and when the confining pressure increases from 1 MPa to 3 MPa, the elastic modulus increases greatly. When the effective confining pressure is low, the elastic modulus changes slightly with clay content. When the effective confining pressure is high, the elastic modulus decreases more obviously with the increase of clay content. FromFig 7, with the variation of clay content, the overall range of Poisson’s ratio is 0.2–0.4, showing no regular change. Poisson’s ratio decreases with the increase of effective confining pressure generally.\n\nWhen the hydrate saturation is 30%, the effective confining pressure is 2.5 MPa, the total clay content is 0%, 8%, 16%, 24%, 32% respectively, and the content ratio of montmorillonite/illite is 1:0, 2:1, 1:1, 1:2, 0:1 respectively, the peak strength, elastic modulus, and Poisson’s ratio are obtained, as shown inFigs 8–10respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g009\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g010\n\nFromFig 8, when the content ratio of montmorillonite/illite decreases, the illite content increases, and the peak strength shows an increasing trend, indicating that the cementation of illite is stronger than that of montmorillonite. This is because the particle size of illite is bigger than that of montmorillonite, the specific surface area is smaller, leading to weaker water absorption and swelling properties, the bonding strength of illite crystal layer is greater. Moreover, the hydration film of illite mineral is thinner, and the friction resistance between particles is greater during sliding. However, with the increase of clay content, the peak strength decreases, the illite content increases, and the decrease of peak strength slows down, indicating that clay type influences the peak strength greatly.\n\nFromFig 9, the elastic modulus of hydrate-bearing sediment decreases with the increase of clay content. But with the decrease of montmorillonite/illite content ratio, the illite content increases, and the elastic modulus changes differently, but the overall trend is increasing, and the elasticity is enhanced.\n\nFromFig 10, the Poisson’s ratio is mainly distributed between 0.15–0.40. Generally, with the increase of clay content, the Poisson’s ratio shows a downward trend, indicating that the more the clay content is, the more severe the deformation is. As the content ratio of montmorillonite/illite decreases, the content of illite increases, and the Poisson’s ratio shows a downward trend, which may be caused by the greater connecting force of illite crystal layers and the greater energy required for deformation.\n\nThe effective confining pressure is 2.5 MPa, and the content ratio of montmorillonite/illite is 1:1, the clay content is 0, 8%, 16%, 24%, 32% respectively, the peak strength, elastic modulus, and Poisson’s ratio are obtained when the hydrate saturation decreases from 45% to 0, 15%, 30%, and 45% respectively, as shown inFigs 11–13respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g011\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g012\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g013\n\nAs shown inFig 11, when the hydrate saturation is degraded from 45% to low saturation, the peak strength is lower than that of sample with the same saturation simply prepared, which is caused by the destruction of sediment structure during the hydrate decomposition. The hydrate-bearing sediment with different clay content shows similar mechanical properties. With the decrease of hydrate saturation, the peak strength decreases nearly linearly. This is because NGH has the role of cementation and skeleton support, and the hydrate forms adhesion on the particle surface, making the loose contact more solid. When the clay content is high, with the increase of hydrate saturation, the peak strength increases, but the increase amplitude decreases, indicating that the cementation effect and skeleton support effect of clay minerals are weaker than that of hydrate.\n\nFromFig 12, with the increase of hydrate saturation, the elastic modulus increases, but the regularity becomes worse. When the clay content is between 0%–8%, the elastic modulus changes more obviously with the saturation. When the clay content increases to 16%–40%, the changing amplitude decreases, and the influence of hydrate saturation decreases. This is because that when the clay content exceeds 16%, hydrate cementation and framework support are greatly weakened, resulting in weakened elasticity and strengthened plasticity. With the increase of clay content, the elastic modulus decreases, especially when the clay content increases from 0% to 8%. FromFig 13, there is no clear law between Poisson’s ratio and hydrate saturation, but in general, with the increase of hydrate saturation and decrease of clay content, Poisson’s ratio decreases, fluctuating between 0.2–0.4.\n\nThe hydate saturation is 30%, the clay content is 0%, 8%, 16%, 24%, 32% respectively, and the effective confining pressure is 0.5 MPa, 1.0 MPa, 3.0 MPa and 5.0 MPa respectively. The peak strength, elastic modulus and Poisson’s ratio are obtained as shown inFigs 14–16respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g014\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g015\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.g016\n\nFromFig 14, when the clay content is certain, the peak strength increases with the increase of effective confining pressure. The peak strength increased greatly when the effective confining pressure is within 0–3 MPa, while small when the effective confining pressure is 3–5 MPa. When the effective confining pressure remains unchanged, the peak strength decreases with the increase of clay content, but the decreasing amplitude decreases. This is because the increase of effective confining pressure enhances the binding effect on sediment particles, increases the biting force and density between sediment particles, and increases the frictional resistance for relative movement.\n\nFromFig 15, the elastic modulus increases with the increase of effective confining pressure. When the effective confining pressure is less than 3 MPa, the elastic modulus increases greatly, while small when the effective confining pressure is greater than 3 MPa. When the effective confining pressure remains unchanged, the elastic modulus decreases with the increase of clay content, but the reduction extent decreases. FromFig 16, Poisson’s ratio has no obvious correlation with effective confining pressure. In general, Poisson’s ratio decreases with the increase of effective confining pressure, indicating the sample is laterally restrained caused by effective confining pressure at the stage of axial loading.\n\nClay mineral is an important component of shallow hydrate-bearing sediment in the Shenhu sea area, with a content of 0–36%, which influences the mechanical properties greatly. Currently, there are many studies on the mechanical properties and influence factors, but few studies on clay content and clay type, which would have impact on wellbore collapse, reservoir sand production and fracturing stimulation during drilling and exploration.\n\nTherefore, through in-situ synthesis of artificial samples similar to the mineral components of shallow unconsolidated hydrate in the Shenhu sea area, mechanics experiments are carried out to explore the mechanical properties of clay hydrate-bearing sediments, especially the influence of clay content and clay type. Currently, a large number of studies have been conducted on the mechanical properties of various types of hydrate-bearing sediments (fine sandy, silty), the effects of hydrate saturation, effective confining pressure, temperature are focused on. While there are few experimental studies on the impact of clay content and clay type, and this research can better compensate for this lack, which will have great significance for guiding hydrate drilling and exploration operations.\n\nThe montmorillonite and illite are discussed in the paper, and the mineral components are shown inTable 2. The purity of montmorillonite is 88.87%, and the purity of illite is 89.08%, both are high. From the comparison betweenFig 3Aand3B, the particle size of selected montmorillonite and illite is less than 5 μm, which is significantly smaller than the size of quartz sand. And the particle size of montmorillonite is smaller than that of illite. The clay causes changes in the structure of sediment. As the clay content increases, the average particle size of the sediment gradually decreases, thereby the frictional force between particles is reduced and the sample strength decreases also. At the same time, clay minerals themselves also have a certain lubricating effect on sediment particles, which can further weaken the friction between particles. Therefore, the higher the clay content, the lower the peak strength compared to sandy hydrate. Moreover, because the particle size of montmorillonite is smaller than illite, the specific surface area is larger, the water absorption capacity is stronger, and the water film formed on the particle surface is thicker, resulting in less contact between particles, less friction and cohesion, more prone to dislocation of particles, and rock damage. Therefore, when the montmorillonite content is high, the hydrate-bearing sediment shows reduced strength and enhanced plasticity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319772.t002\n\nDue to limited time and article space, some work needs to be further carried out. We have obtained the change rules and influencing factors of mechanical properties, especially the clay content and clay type, and have provided theoretical explanations for the change rules. However, there is a lack of support from the micro structure level, and a more in-depth exploration of the structure and mechanism of the two clay minerals-montmorillonite and illite needs to be conducted. In the future, SEM technology and CT technology will be developed, which will be helpful to explain the microscopic mechanism of clay mineral action. The qualitative introduction of the mechanical properties changes under the effect of clay minerals is foused on, but in-depth analysis and summary are not provided. The formation of failure strength criteria and constitutive models for hydrated sediments that consider the impact of clay minerals limits the application of research results, which will be the next research direction.\n\nFully considering the composition and geological conditions of shallow clay hydrate in Shenhu sea area, NGH samples with similar composition are synthesized in situ, and triaxial experiments are carried out to analyze the mechanical properties of unconsolidated hydrate-bearing sediment under different conditions. The following conclusions are obtained:",
    "category": "materials_science"
  },
  {
    "title": "A minimal biophysical model for the temperature dependence of CO2fixation rates based on macromolecular rate theory",
    "authors": "Erica J. Prentice, Margaret M. Barbour, Vickery L. Arcus, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0319324",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319324",
    "content": "Accurately predicting how the global environment will change under continued CO2and temperature increases is currently a critical issue. Predictions are dependent on global models that represent this complex system of natural and anthropogenic inputs, responses, and feedback loops. These models must include accurate descriptions of complex biological processes such as photosynthesis, which is currently responsible for the removal of 123 petagrams of atmospheric carbon annually. Here, we develop a simplified approach to model the effect of concurrent changes in temperature and CO2concentrations on the rate of C3carbon fixation. The model simplifies the temperature response of the CO2fixation pathway into a three-parameter curve (as modelled by macromolecular rate theory, MMRT), which incorporates the limitations of RuBisCO kinetics, and CO2and O2solubility as simple system constraints. This framework fully accounts for the temperature and CO2dependence of CO2fixation rates in sweet potato (Ipomoea batatas) leaves with just three parameters, in combination with defined biophysical constraints.\n\nCitation:Prentice EJ, Barbour MM, Arcus VL (2025) A minimal biophysical model for the temperature dependence of CO2fixation rates based on macromolecular rate theory. PLoS ONE 20(4):\n           e0319324.\n        \n        https://doi.org/10.1371/journal.pone.0319324\n\nEditor:Susmita Lahiri (Ganguly),, University of Kalyani, INDIA\n\nReceived:March 19, 2024;Accepted:January 31, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Prentice et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:EJP and VLA were supported through the Marsden Fund of New Zealand (19-UOW-035) for this work. The funders had no role in study design and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nPredictions for the trajectory of our global environment are reliant on our ability to accurately model the climate now and into the future under changing temperature and CO2regimes. A central component of global modelling is the ability to predict the rate at which photosynthetic species are removing CO2from the atmosphere, especially extrapolations to changes in CO2fixing capacity in response to increasing temperature and atmospheric CO2concentration. For example, models need to capture the changes in CO2fixing capacity over the predicted future temperature increases of up to four degrees, accompanied by up to a tripling of CO2concentrations by the year 2100 (RCP 8.5) [1].\n\nRates of net CO2exchange display a curved response to temperature, with increasing rates of CO2fixation up to peak in activity (Topt), above which rates decline [2–5]. This curvature has been accounted for in various ways. Farquhar and colleagues have fit a Gaussian (which is curved and symmetric about an optimum temperature) to the electron transport component of photosynthesis [6]. In accounting for the temperature response of net CO2assimilation in sweet potato, the limiting processes of carboxylation (Vcmax), electron transport (Jmax) and phosphate regeneration are modelled as curves [7]. Medlyn developed a ‘peaked’ model, which incorporates the negative effect of enzyme damage at high temperatures, which is applied to the temperature dependence ofVcmaxandJmax[4]. Further, the temperature response of net CO2assimilation rates has recently been described in a three parameter single quadratic [2]. Currently, incorporation of CO2fixation at the global scale typically models leaf physiology based on the equations developed by Farquhar and colleagues, parametrising the temperature response ofVcmaxandJmaxbased on the fit of modified Arrhenius functions to a range of data [4,8] and incorporating smoothing functions to transition between limiting factors and allow for co-limitation [9–11].\n\nMacromolecular rate theory (MMRT) has been developed to account for the curved temperature dependence of enzyme catalysed rates [12,13]. The basis of MMRT is the expansion of the Eyring-Polanyi equation [14–16] to account for the unusual properties the arise for enzyme catalysis due to the large size of enzymes – hencemacromolecular rate theory. Specifically, enzymatic reactions undergo a narrowing of the conformational space as the reaction progresses from the enzyme-substrate complex to the tight binding enzyme-transition state complex [17]. As the enzyme-transition state complex has a reduced heat capacity, enzymatic reactions are associated with a negative activation heat capacity () [16,17]. The incorporation of a negativeinto the Eyring-Polanyi equation quantifies the degree of negative curvature of enzyme catalysed rates with temperature [14,16]. This accounts for the temperature optimum and decreases in rates at high temperature observed in enzyme catalysis, without the need to invoke enzyme denaturation [12,13].\n\nGiven that enzyme catalysed reactions are the underlaying driver of biological rates at increasing scales of complexity, MMRT has been applied to the temperature response of multiple biological systems. This has included the temperature response of rates for bothin vitroandin vivometabolic pathways [18], as well as various soil processes [15], leaf respiration rates [19] and net ecosystem photosynthesis and respiration [20]. At these increasing scales of biological organisation, the temperature dependence of rates for these various processes are well described by MMRT. The basis for this scaling from enzymes to metabolic pathways has been investigated, showing that the temperature dependent curvature of a metabolic pathway is dependent on the temperature response of the constituent enzymes [18]. This raises the possibility for the application of MMRT to describe the temperature dependence of the CO2fixation as anin vivometabolic pathway. In terms of global scale models of CO2fixation, utilising a curved function like MMRT to describe the temperature response eliminates the need to incorporate smoothing functions between limiting factors [9–11]. Compared to the curved functions which are also used [2], this would concurrently extract information on the thermodynamics of the enzyme driving the process [13,18].\n\nHere, we address this possibility by applying MMRT to describe the temperature response of portions from the CO2fixation pathway of increasing complexity. We find that the temperature response of isolated RuBisCO enzyme, as a large complex macromolecule, is fully accounted for by MMRT. We also find the temperature response ofVcmaxandJmax, representing portions of the CO2fixation pathway measuredin vivo, are well described by MMRT. We further extend this to apply MMRT to model the temperature response of net CO2fixation rates in the C3species sweet potato (Ipomoea batatas) leaves across concurrent changes in temperature and CO2concentration. We find that MMRT, in conjunction with limitations imposed by RuBisCO enzyme kinetics and gas solubility, describes the temperature dependence of net CO2exchange in sweet potato leaves with just three fitted parameters. By incorporating MMRT into this model, the curved temperature response of the enzymes catalysing the CO2fixation process is mechanistically accounted for. This describes net CO2assimilation rates over a 30-degree temperature and 360 ppm(g)CO2range and models the curved response of rates to temperature and associated changes in curvature with altered CO2concentration. Overall, this accounts for the changes in CO2fixation rates due to these two critical environmental factors with a combination of biological and physical parameters in a minimal biophysical model, underpinned by enzyme thermodynamics. For global scale modelling, MMRT presents a promising tool for incorporating a mechanistic understanding to the curvature of the CO2fixation process, while also simplifying input parameters and maintaining model accuracy.\n\nWe firstly define an artificial state of saturating CO2(substrate), no O2(inhibitor) and ideal light and moisture. The rate of this reaction is defined as:\n\nWherecis a constant andkpis the rate constant for the CO2fixation reaction. At saturating substrate, the reaction rate is not dependent on substrate and in the context of laboratory-based experiments, we assume that the number of CO2fixing centres, c, is constant (over the course of the experiment). We seek to calculate the value forkpacross the temperature range,kp(T). Ifkp(T) is well defined, then the rates of net CO2exchange in the lab/field may be calculated directly using this function and can be incorporated into models.\n\nWe use an existing dataset to definekp(T) as follows: the CO2assimilation rate under experimental conditions is a function of ckp, the concentration of substrate available to RuBisCO (dissolved CO2and its observed binding constant (), the inhibitor concentration (dissolved O2) and its observed binding constant (), and the degree of cooperativity associated with the enzyme catalysed reaction (the hill coefficient,n). This is a Michaelis Menten equation with a competitive inhibitor (as in the Farquhar–von Caemmerer–BerryVcmaxequation [11]) with the addition of a cooperativity term (n). These parameters are defined byEquations 2–4. Bothandare calculated directly from the partial pressures of these gases at any temperature, simplifying the myriad of complex components related to the bioavailability of CO2into a simple physical constant applicable to C3plants which rely on passive CO2dissolution (Equation 6). Due to this, the model is not applicable to C4/CAM plants, as the CO2concentrating mechanisms in these species circumvent the physical constraints of CO2dissolution.\n\nCombining (2) and (3) givesEquation 4\n\nFor sweet potato,Equation 4was parametrised by a fit of intercellular CO2partial pressure (Ci) vs rate data with high and low O2concentrations to define the response of RuBisCO to substrate and inhibitor (Fig 3) [7]. These data were fit over three temperatures to define the temperature dependence of the parameters. Final model fitting ofEquation 1was achieved withindependent of temperature (0.094 ppm(aq)), whereaswas linearly dependence on temperature, as defined byEquation 5.\n\n(A) The change in solubility constants with temperature for CO2and O2(Equation 6). Both gases become less soluble with increasing temperature. (A insert) The ratio of CO2and O2solubility. With increasing temperature, CO2becomes proportionally less soluble compared to O2. (B) The effect of temperature on dissolved gas concentrations of current atmospheric O2and three CO2concentrations.\n\n(A) The change in solubility constants with temperature for CO2and O2(Equation 6). Both gases become less soluble with increasing temperature. (A insert) The ratio of CO2and O2solubility. With increasing temperature, CO2becomes proportionally less soluble compared to O2. (B) The effect of temperature on dissolved gas concentrations of current atmospheric O2and three CO2concentrations.\n\nhttps://doi.org/10.1371/journal.pone.0319324.g001\n\nRates are fit to MMRT (Equation 7), with the exception of RuBisCO fromT. thyasirae, which is fit using MMRT with a temperature dependent(see S2 supplementary in S1 File). Fitted values are reported in S1 Table in S1 File. RMSE values for the fitting from A-C are given in the table to the top right of the figure.\n\nRates are fit to MMRT (Equation 7), with the exception of RuBisCO fromT. thyasirae, which is fit using MMRT with a temperature dependent(see S2 supplementary in S1 File). Fitted values are reported in S1 Table in S1 File. RMSE values for the fitting from A-C are given in the table to the top right of the figure.\n\nhttps://doi.org/10.1371/journal.pone.0319324.g002\n\nThe data show positive cooperativity, setting an average hill slope of 2.24 over all temperature and O2treatments for the final model. For all data, aqueous CO2and O2concentrations were calculated using the known solubility constants for the specific gases across the temperature range (andrespectively) [21,22].\n\nThe temperature dependence ofvalues are defined by Henry’s law and physical constants for CO2and O2(Equation 6andFig 1).\n\nThe maximum rate at a given temperature (kp) is defined by MMRT (Equation 7), whereis the Boltzmann constant,his Planck’s constant,Ris the ideal gas constant,Tis temperature in Kelvin,andare the activation enthalpy and entropy at the reference temperature (T0), andis the change in heat capacity associated with the reaction. For the analysis here,T0was set to 4 °C below the temperature at which the fastest rates were measured (303 K; 30 °C). While the exact value ofT0does not influence the fitting, this approach of selectingT0is consistent with standard MMRT fitting practise.\n\nJust three parameters are fitted in this equation:,and. Furthermore,andare linked and define the magnitude of rates.then defines the curvature of the temperature response.\n\nThe above model was fit using GraphPad Prism (GraphPad Software, La Jolla, CA,www.graphpad.com; S1 Supplementary in S1 File). Sensitivity analysis of this model was performed by assessing the model fit (R2) through stepwise alteration of the, slope of(Equation 5) andnparameters about the typical error range of these values (as given in S4–S9 Tables in S1 File).\n\nTo test the application of MMRT to CO2fixation, data were fitted for isolated RuBisCO from a bacterial [23] and an archaeal [24] species, as well asVcmaxandJmaxfrom a selection of temperate tree species [25] (Fig 2; additional data is in S4 Supplementary section in S1 File). Data for isolated RuBisCO from both species is well described by MMRT (Equation 7) across a wide temperature range (Fig 2A). For the archaeal type III RuBisCO (Pyrococcus kodakaraensis), data from 25 to 100 °C is accounted for by the MMRT model (Equation 7). For the bacterial type II RuBisCO (Thiomicrospira thyasirae), the fitting requires the inclusion of temperature dependent, consistent with other high quality, wide temperature range enzyme data (see S2 Supplementary in S1 File for fitting details) [16] . Further, data across a 30 °C range for bothVcmaxandJmaxis well described by MMRT, accounting for the range of curvature in responses observed across the species for both processes.\n\nData for the CO2and O2response of net CO2fixation is available for sweet potato leaves at three temperatures [7]. From this, the binding affinities for the two molecules to RuBisCO can be determined by treating O2as a competitive inhibitor (Equation 4). This reduces the full Farquhar–von Caemmerer–Berry model down to the RuBisCO (Vcmax) portion alone to simplify the analysis for this specific application, while maintaining a full account of the range ofCidata. The aqueous CO2and O2concentrations are calculated fromCibased on the equilibrium constant for each gas at the experimental temperature (Equation 6).\n\nFor RuBisCO from sweet potato, affinity for CO2is independent of temperature. The binding constant (), representing where the RuBisCO pool is half saturated, remains constant at about 0.094 ppm(aq)over a temperature range from 10 to 31 °C (Fig 3). The data also displays positive cooperativity, characterised by an average hill slope of 2.24. In comparison, RuBisCO from sweet potato has two orders of magnitude lower affinity for O2compared to CO2, consistent with the biological function of the enzyme. However, the affinity for O2increases with increased temperature (Fig 3D). This increases the relative affinity for O2compared to CO2as temperature is increased.\n\nGiven the parametrised temperature dependence of gas solubilities and RuBisCO binding constants, along with the curved response of enzymatic pathways [18], accounting for the full temperature and CO2dependence of net CO2fixation rates is possible. Temperature data under differentCiconcentrations have previously been collected in sweet potato [7]. These data at three CO2concentrations are simultaneously fit withEquation 1.\n\nHere we find these data can be simply modelled in terms of an intrinsic temperature dependent rate constantkp(T) based on MMRT, the exponential decreases in gas solubility with increases in temperature, and the effects this has on CO2fixation versus photorespiration rates due toandvalues respectively (Fig 4). The complete dataset, representing anin vivometabolic pathway over a 10–40 °C temperature span, three CO2concentrations and rates varying up to nine fold, can be simultaneously fit with just three parameters (Equation 7), these being the magnitude (and) and the curvature () of rates.\n\n(A-C) Rate versus aqueous CO2concentration curves for high (200 mbar O2(g); red) and low (30 mbar O2(g); green) O2concentrations at 10, 25 and 31 °C respectively. Aqueous O2concentrations are given as ppm(aq)within individual graphs. Each temperature is fit withEquation 4, to fit both O2treatments simultaneously to gain binding constants for CO2() and O2(). All CO2and O2concentrations are corrected fromCivalues to account for gas solubility at the given temperature. (D) The temperature dependence of binding constants for sweet potato, as determined in fits A-C.\n\n(A-C) Rate versus aqueous CO2concentration curves for high (200 mbar O2(g); red) and low (30 mbar O2(g); green) O2concentrations at 10, 25 and 31 °C respectively. Aqueous O2concentrations are given as ppm(aq)within individual graphs. Each temperature is fit withEquation 4, to fit both O2treatments simultaneously to gain binding constants for CO2() and O2(). All CO2and O2concentrations are corrected fromCivalues to account for gas solubility at the given temperature. (D) The temperature dependence of binding constants for sweet potato, as determined in fits A-C.\n\nhttps://doi.org/10.1371/journal.pone.0319324.g003\n\n(A) Global fit ofEquation 1to temperature curves at varying CO2concentrations. TheToptunder each condition are labelled.R2for the global fit =  0.9724. Fitting parameters and further statistics are provided in S3 Table in S1 File. (B) Intrinsic curvature (Equation 7) extrapolated from the fitted data, representing maximum rates of CO2fixation in unlimited conditions (saturating CO2, low O2, optimal light and moisture). (C) Realised proportion of maximum rates (kp) given the CO2and O2concentration in solution and binding constants to RuBisCO with temperature. Colouration is the same as panel A for the three CO2concentrations. The deviations away from 100% capacity quantify the physical and biophysical restrictions placed on the CO2fixation system.\n\n(A) Global fit ofEquation 1to temperature curves at varying CO2concentrations. TheToptunder each condition are labelled.R2for the global fit =  0.9724. Fitting parameters and further statistics are provided in S3 Table in S1 File. (B) Intrinsic curvature (Equation 7) extrapolated from the fitted data, representing maximum rates of CO2fixation in unlimited conditions (saturating CO2, low O2, optimal light and moisture). (C) Realised proportion of maximum rates (kp) given the CO2and O2concentration in solution and binding constants to RuBisCO with temperature. Colouration is the same as panel A for the three CO2concentrations. The deviations away from 100% capacity quantify the physical and biophysical restrictions placed on the CO2fixation system.\n\nhttps://doi.org/10.1371/journal.pone.0319324.g004\n\nSensitivity analysis indicates the model parameters are well defined by the data and are essential for the full fitting of the CO2and temperature response. The ability of the global fit to accurately model the 140 ppm(g)CO2curve is highly sensitive to the input of the, slope ofandn. For example, increasingby 10% alters theR2for fitting of the 140 ppm(g)CO2curve from 0.76 to 0.41, reducing the predictive power of the model at these low CO2concentrations. Further data for the sensitivity analysis is given in S4–S9 Tables in S1 File.\n\nCO2fixation displays a curved response to changes in temperature, with roughly symmetric decreases in rates either side of an optimum [26]. This curvature is characteristic of a range of biological processes, from enzymes to metabolic pathways, organism growth rates and various ecosystem processes [12,15,18,20]. Across these scales, curvature is well described by MMRT (Equation 7). At the enzyme level, the temperature dependent curvature of rates is a consequence of the large decrease in heat capacity () upon progression from the enzyme-substrate complex to the enzyme-transition state. This decrease in heat capacity occurs for the enzyme bound reaction system as the enzyme tightly binds to the transition state species, resulting in a narrowing of the conformational space. A large negativedefines the temperature dependence of the free energy barrier for a reaction (), expanding the Eyring-Polanyi equation to account for curvature in enzyme rates that is independent of enzyme denaturation [12,13]. Recently, MMRT has been extended to show that the temperature dependent curvature of anin vitrometabolic pathway is a function of the curvature of the enzymes contributing to the catalytic cascade [18]. The temperature dependence of leaf [19] and soil [15] respiration, representingin vivometabolic pathways, has also been described by MMRT. Further, analysis of a the global FLUXNET dataset has shown that MMRT can simultaneously describe the temperature dependence of ecosystem photosynthesis and respiration [20]. Considering CO2fixation as anin vivometabolic pathway raises the possibility the process may be described by MMRT, where the temperature response of the pathway is a function of the thermodynamics of the individual enzymes in the cascade. This would then define the inherent temperature response of CO2fixation based on the enzymes catalysing the process, upon which other temperature limitations would layer. Defining the curvature of the photosynthetic pathway with MMRT gives a theoretical basis to the curvature of the temperature response (based on the curvature of individual enzymes), allowing access to information about the thermodynamics of the enzymes underpinning the process. This fitting is mathematically equivalent to the three-parameter single quadratic fit that has previously been used for net CO2assimilation rates [19,27].\n\nTo test the applicability of the MMRT equation to the CO2fixation pathway, we fit the temperature response of isolated RuBisCO, as well asVcmaxandJmaxfrom a range of sapling species (Fig 2, S1 Fig in S1 File). Across the range of these data representing isolated RuBisCO enzyme and portions of thein vivopathway, MMRT fully accounts for the temperature response of the rates. Further, enzyme data from bacterial type II RuBisCO fromThiomicrospira thyasiraerequires the extension to include the temperature dependence of, a parameter previously applied to high quality enzyme data over wide temperature ranges [16].\n\nWe further extended this analysis to develop a minimal model to fully account for net CO2exchange in sweet potato leaves. For this, the response of RuBisCO to changing concentrations of dissolved CO2and O2was defined from existing data (Fig 3). The binding constants of CO2and O2were parametrised with temperature based on an enzymatic competitive inhibition model. The binding constant for CO2(), is relatively independent of temperature at 0.094 ppm(aq)across this temperature range (Fig 3D), although this binding constant could be expected to increase sharply at higher temperatures [28]. Given a typical CO2concentration and temperature (Ciof 250 ppm(g)and 18 °C), CO2dissolves to a concentration of 0.19 ppm(aq). Thus, CO2fixation rates are not substrate saturated under typical conditions and are highly sensitive to changes in CO2concentration about current atmospheric levels. The binding constant for O2is two orders of magnitude lower compared to CO2, consistent with the biological function of the enzyme. However, the affinity for O2increases with increasing temperature. Due to this, the rate of photorespiration will increase with temperature as the relative binding affinities change.\n\nTo be available for fixation, CO2must dissolve from the gas phase in the intercellular space into the aqueous environment of the leaf mesophyll. The movement of CO2from the gas phase to the chloroplast is complex and involves both membrane and cytosolic conductances, many of which are also temperature dependent, variable between species and poorly understood [29–32]. Whilst cognisant of these complexities, for the purposes of this minimal model, these are simplified into a single solubility parameter which captures the broad effects of reduced aqueous CO2with temperature in a well defined physical constant. At all temperatures, the solubility of CO2provides a significant limitation on the substrate available to C3plants for fixation as the equilibrium strongly favours the gas phase (by a factor of 1400 at 20 °C). This equilibrium under a given set of conditions is a physical constant, defined by an equilibrium constant (Keq). With increasing temperature, CO2solubility decreases exponentially, placing further limits on substrate availability (Fig 1;Equation 6). Incorporating the limitations on CO2supply with temperature via well-defined fundamental restrictions of CO2solubility greatly simplifies the temperature considerations for C3plants, removing reliance on the nuances of membrane and cytosolic conductances.\n\nThe rate of net CO2assimilation is complicated by the competing reaction of O2with RuBisCO (photorespiration). Photorespiration temporarily takes a portion of the RuBisCO pool out of CO2fixing capacity, and also requires the release (as CO2) of a fixed carbon to recycle the products of two photorespiratory O2turn overs [33]. Net CO2assimilation rates are thus the rate of CO2fixation offset by the rate of CO2release by photorespiration and respiration. The proportion of carboxylation to oxygenation is partially dependent on the aqueous concentrations of CO2and O2(along with the relative binding constants of the two molecules). O2is less soluble than CO2, however due to the larger proportion of O2in air, is more prominent in the aqueous phase. For example, under current atmospheric conditions of 210,000 ppm(g)O2(21%) and 400 ppm(g)CO2, at 25 °C the gases dissolve to 4.7 and 0.25 ppm(aq)respectively. O2solubility also decreases with increasing temperature, however due to a more gradual decrease in solubility, relative concentrations of dissolved O2compared to CO2increase with temperature (Fig 1Ainsert). Thus, the physical limitation of gas solubility places further constraints on CO2fixation at elevated temperatures due to the relatively greater solubility of O2compared to CO2and the effects this has on photorespiration rates [26,34–36].\n\nBy taking these effects into account, the full response of sweet potato across three different CO2concentrations and a 30°C temperature range is accounted for (Fig 4). Rate decreases from a maximum rate curve (‘intrinsic pathway curvature’,Fig 4B) and shifts in theToptof CO2fixing capacity are captured by the changes in gas solubility (physical constraints), and the effect these have of RuBisCO CO2saturation and photorespiration rates (biological constraints). This maximum rate curve represents the temperature profile of CO2fixation rates in an unconstrained system of saturating CO2, vanishingly low O2, as well as optimal light and moisture. As CO2concentration is lowered, rates over the whole temperature range drop as RuBisCO becomes less saturated, and photorespiration is higher as the CO2:O2ratio is decreased. As CO2is reduced, CO2fixing capacity peaks at a lower temperature due to the lower temperature at which inhibitory ratios of CO2:O2are reached when CO2is decreased and O2held constant (Fig 4C). This shifts theToptof CO2fixation from 38 °C to 25 °C between a CO2saturated system (Fig 4B) and 140 ppm(g)CO2. The expansion of this analysis to other species is currently limited as this full data set is only available in sweet potato, however the general scale and magnitude of these responses is evident in the literature. AToptshift of similar scale has been reported previously under both high CO2and low O2conditions inAgropyron smithii(Western wheat grass) [34], as well as drought stressedTriticum aestivum(winter wheat) operating under reduced stomatal conductance andCi[37]. Such shifts in the temperature optimum of CO2fixation are critical to accurately capture in models of a climate likely to experience more regular and sever temperatures spikes and increased atmospheric CO2[1].\n\nThe capacity of this simple model to incorporate the recent advances in our understanding of the temperature responses of enzymes and metabolic pathways, as well as accounting for the curvature and changes inToptunder different CO2regimes has value for global scale modelling. Given the intertwined effects of changing temperature and CO2, encompassing the extensive finer details of CO2transport through the mesophyll into a simple solubility term offers great benefit for incorporation into global models, along with other major limiting factors (light, water, nutrient availability). Given the exponential decreases of gas solubility with temperature, this presents a critical component for capturing the subtleties of CO2transport in C3plants into a defined physical constant for understanding large scale CO2fixation over short time scales (in the absence of adaptation mechanisms). To fully realise the potential of this, further data is needed to define the range and variability of the biological parameters of the model (the binding and inhibition constants) across multiple C3species, collet data across a wider temperature range, and assess if biome specific average of these parameters are a possibility.\n\nCurrently, terrestrial biosphere models employ a range of approaches to model carboxylation, electron transport and phosphate regeneration rates in response to incident radiation, CO2and temperature (compositions of the major models are summarised in [38]). These models simulate rates based primarily off the equations by Farquhar [11] or Collatz [39]. In addition, these models incorporate a rate-limiting selection between the three processes, and often a smoothing function to even out transitions between the limiting processes and allow for co-limitation [38]. By comparison, the approach presented here fits these limiting processes in one function (Equation 4), simply capturing the net effect of CO2assimilation rates of these three rate-limiting processes and transitions, along with the effects of O2. This effectively halves input parameters and removes the need for smoothing functions, reducing model complexity while maintaining output accuracy.\n\nCO2fertilisation has been presented as a mitigating process to rising atmospheric CO2concentrations [40]. The CO2fertilisation effect proposes that elevated CO2concentrations stimulate higher rates of carbon fixation, increasing atmospheric carbon removal to reverse some of the impact of increased anthropogenic inputs. However, when coupled to rising temperatures, this effect will be reduced due to the decreased solubility and bioavailability of the CO2at higher temperatures. For example, from 1991–2015 atmospheric CO2has increased by 40 ppm(g), however the concurrent global average temperature rise of 0.5 °C mitigates the effect of this rise in terms of dissolved CO2bioavailable to plants (per the temperature dependence of CO2solubility;Equation 6). Over this period, no evidence of CO2fertilisation is measurable at a global scale [20]. Future predictions up to the year 2100 indicate that CO2rises (to 700 ppm) are significantly steep compared to projected temperature rises of three degrees to increase dissolved CO2overall from 0.34 to 0.53 ppm(aq)(based on the RCP 6.0 scenario) [41]. This suggests that, in the absence of other major limiting factors [42], increased CO2concentrations will stimulate increased CO2removal. A full understanding of the extent to which CO2fertilisation will mitigate atmospheric CO2increases involves consideration of CO2solubility with temperature, and species-specific data such as RuBisCO binding and inhibition constants to predict wide scale responses to these changes. The analysis presented here provides a simple framework for this modelling, allowing the characterisation of CO2fixation rates of C3plants to concurrent changes in temperature and CO2concentration.\n\nHere, we show that MMRT can successfully account for the intrinsic curvature of the CO2fixation pathway with temperature. This curvature is well described at the enzyme (RuBisCO), process (VcmaxandJmax), and full biochemical pathway level. This presents MMRT as a valuable tool for the incorporation into global scale models to account for the temperature response of the enzymes driving the CO2fixation pathway by incorporating fundamental enzyme kinetics. Here, the ‘real world’ limitations of substrate solubility and photorespiration have been successfully incorporated to account for reductions in carbon fixation potential under limited CO2in the C3species sweet potato. Further work is required to assess the range and variability of the parameter set determined here in a wider variety of C3plant species, and how other factors such as light, water and nutrient limitations layer on top of the underlaying enzymatic responses defined here. The model presented here incorporating MMRT along with the limitations imposed by substrate availability and the effects this has on enzyme rates illustrates the potential of this approach in capturing the nuance of temperature-based curvature in a complex metabolic system with a simple model based on fundamental enzyme behaviour. This provides a framework, based on the thermodynamics of enzyme activity, for building other limiting processes of the photosynthetic process onto, as a basis for incorporation into global scale models.\n\nhttps://doi.org/10.1371/journal.pone.0319324.s001\n\n(DOCX)",
    "category": "materials_science"
  },
  {
    "title": "Heat transfer analysis of Oldroyd–B nanofluid flow over a horizontal plate",
    "authors": "Ruishi Liang, Hanifa Hanif, Jie Song, Rahimah Mahat, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0317297",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0317297",
    "content": "Non–Newtonian fluids have grown in popularity across a wide range of engineering disciplines. Generalized Oldroyd–B fluids are a type of non–Newtonian fluid that may mimic the behavior of many dilute polymeric liquids. On the other hand, heat transmission is important because it has industrial applications. The use of nanofluids, which have a higher heat transfer capacity, can enhance the overall efficiency of the thermal system. Therefore, this research considers the generalized Oldroyd–B nanofluid over a horizontal plate. The nonlinear fractional model is solved using the finite difference method. The integer order derivatives are integrated using the Crank–Nicolson method whereas the time fractional derivatives are evaluated using the Caputo derivative. The simulations are carried out in MATLAB software. The results revealed that the retardation time parameter slow downs the fluid. The heat transfer rates increased with increasing values of the nanoparticle volume fraction. The heat transfer of regular fluid increased by 9.4% on adding nanoparticles.\n\nCitation:Liang R, Hanif H, Song J, Mahat R (2025) Heat transfer analysis of Oldroyd–B nanofluid flow over a horizontal plate. PLoS ONE 20(4):\n           e0317297.\n        \n        https://doi.org/10.1371/journal.pone.0317297\n\nEditor:Hasan Shahzad, University of Science and Technology of China, CHINA\n\nReceived:June 28, 2024;Accepted:December 25, 2024;Published:April 17, 2025\n\nCopyright:© 2025 Liang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper.\n\nFunding:R. L. and J. S. would like to acknowledge the financial support from Shaoguan University under Shaoguan University Encouragement Research Grant (SZ2024KJ07).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nOver the past century, nanotechnology has gained widespread recognition as a field of research [1]. Numerous novel materials and gadgets with applications in nanomedicine, nanoelectronics, biomaterials, energy generation, and consumer goods may be created using nanotechnology. The dispersion of nanoparticles in a base fluid has been suggested to modify the fluid’s properties to maximize its thermal performance; Choi and Eastman first presented this concept [2,3]. The resultant fluid is known as a nanofluid in the literature. Nanofluids have several uses in drug delivery, heating/cooling, electronics, solar energy, food processing, etc. The use of nanofluid in automobile cooling systems was proposed by Choi [4]. A nanofluid’s efficiency and application depend on the nanoparticles floating in the base fluid. Nanoparticles are particulate substances with a minimum size of 100 nm [5]. Depending on their physical and chemical properties, nanoparticles can be categorized into several classes such as metal, metal oxide, graphite, carbon nanotubes, etc [6]. Furthermore, one of the frequent problems in a variety of sectors, including manufacturing, heavy machinery and engines, electronics, and other industries, is heat transmission. Conventional heat transfer fluid has some drawbacks; these restrictions can be removed by nanofluid through enhanced thermophysical characteristics [7]. Heat transfer and entropy generation in nanofluid within a pipe were examined by Qin [8]. The obtained results showed that the Nusselt number augments about 18.3% as the width ratio changes from 0.25 to 0.75. Furthermore, the novel nanofluid has superior thermal properties compared to water. Turkyilmazoglu [9] found that using a single–phase model resulted in reliable thermal prospects and outputs for nanofluid flow. Hanif et al. [10,11] discussed how can nanoparticles optimize the heat transfer and entropy generation of fluid. Du et al. [12] conducted an experimental study and used water–based CuO nanofluid to examine the thermal performance of a geothermal heat exchanger. They discovered that using nanofluid boosted the geothermal heat exchanger system’s pumping power consumption and heat transfer rate by 16.75% and 39.84%, respectively.\n\nThe researchers are now investigating the flow of non–Newtonian fluids from various perspectives. Non–Newtonian fluids present distinct challenges and opportunities in many applications, while Newtonian fluids are well understood [13]. The most common applications of non–Newtonian fluid include molten polymers, milk, ketchup, shampoo, paint, grease, drilling fluid, unusual lubricants, and polymer solutions [14]. Non–Newtonian fluids have unique properties that cannot be described by a single constitutive relation [15]. Non–Newtonian fluids’ versatility drives innovation across various industries [16,17]. The Maxwell fluid is the simplest subclass of rate–type fluids [18]. It predicts just stress relaxation effects, not stress retardation effects. To address this shortcoming, an Oldroyd–B fluid model was developed to study stress relaxation and retardation effects. The Oldroyd–B fluid model also provides the greatest description of the behavior of viscoelastic materials, especially the reaction of various polymeric liquids. These fluids also experience the memory and elastic effects that most biological liquids and polymers do, which makes them highly valuable in the chemical and process industries [19]. Heat transfer and flow of non–linear Oldroyd–B over a stretching cylinder were studied by Yasir and Khan [20]. They found that the heat transfer rate increased when the prescribed surface temperature was replaced with a constant wall temperature. Jyoti et al. [21] discussed the 3D flow of Oldroyd–B fluid subject to the activation energy. They claimed that the average kinetic energy of fluid particles increases in direct proportion to the radiation parameter values. Increased kinetic energy leads to more frequent and intense collisions between fluid particles, which raises the fluid temperature. Dadheech et al. [22] examined the effects of melting, slip, angled magnetic field, and chemical reactions on Oldroyd–B fluid flow across a permeable surface. Gope et al. [23] examined heat transfer and entropy generation in Oldroyd–B with a hybrid nanostructure on a radially stretched surface. According to their results, augmented relaxation and retardation time parameters control the rate of heat transmission. Furthermore, entropy generation is minimized against relaxation and retardation parameters. Sun et al. [24] investigated the instability features of the Oldroyd–B fluid with non–Fourier heat flux using the Chebyshev collocation method. The results revealed that the non–Fourier effect and relaxation time help to destabilize the system for oscillatory convection. They also claimed that the retardation time might reduce the instability of the convective system. Rathore and Sandeep [25] investigated the viscoelastic nature of blood using Maxwell and Oldroyd–B hybrid nanomodels. Their results revealed that the flow of GO–Al2O3suspended blood using the Oldroyd–B model results in a faster heat transfer rate than the Maxwell model. Additionally, medication resistance is negligible in Oldroyd–B flow.\n\nThis work aims to give a numerical analysis of heat transfer of Oldroyd–B nanofluid flow over a horizontal plate. The considered nanofluid is the mixture of Al2O3and mineral oil. An unconditionally stable numerical strategy based on the L1 algorithm and Crank Nicolson technique is used to achieve the numerical solutions. Examining how regulating factors affect fluid characteristics, the findings are visually shown and thoroughly described. The impacts of controlling factors on fluid characteristics are investigated, and the findings are graphically shown and explained in depth.\n\nThe following constitutive relation predicts the rheology of an Oldroyd–B fluid.\n\nwhereP: hydro–static pressure,I: identity matrix,S: extra stress tensor given as\n\nHereμdenotes viscosity,λ1is relaxation time,is retardation time,denotes Rivlin–Erickson tensor, †indicates transpose operation and theDrepresents Oldroyd derivative defined as\n\nLet the Oldroyd–B nanofluid flow over a plate parallel toxz–plane, shown inFig 1. The heat transfer of an Oldroyd–B nanofluid flow is characterized by continuity, momentum, and energy equations [26,27]:\n\nhere, andTrepresent the density, heat capacity, thermal conductivity, body force, and temperature, respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g001\n\nLet (ex,ey,ez) be the canonical basis for ℝ, then the velocity field is defined as\n\nBecause the mainstream flow occurs along thex–axis, andv= 0 =w, we arrived at\n\nand the extra stress tensor is\n\nFor the Oldroyd–B nanofluid with the velocity field (8), the relation (2) with fractional time derivative yield us\n\nUsing Eqs(1)to(3)and(8)to(11)in governing Eqs(4)to(6)yields us to\n\nThe considered initial and boundary conditions are\n\nFurther, we assume that a pressure gradient is applied at timet= 0 and then maintained for a time interval [0t], defined as\n\nwherep0is the constant pressure gradient andH(t)  is the Heaviside step function defined by:\n\nIn Eq(13),qris the radiative heat flux and defined as [27]\n\nNow, let us introduce the following set of non–dimensional variables is introduced:\n\nBy using(18), after dropping bars for brevity and the adoption of the same notation for non-dimension quantities, Eqs(12)and(13)become:\n\nHere\n\nThe initial and boundary conditions are:\n\nNote: The mathematical expressions of nanofluid properties are presented inTable 1and the thermo–physical properties of nanoparticles and base fluid are presented inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.t002\n\nLetandbe the numerical solutions at. Define, where,Δz= 1 ∕qare the mesh size and, is the time step. Then we can define the following approximations\n\n(i) for:\n\n(ii) fractional order derivativefor 0<α<1 usingL1algorithm:\n\nSubstitutingand changing the summation indexs=k−myields:\n\nEvaluating the integral results in:\n\nwhere.\n\nExploiting aforementioned approximations in Eqs(19)and(20), we arrived\n\nThe discrete equations Eqs(29)and(30)are further solved using MATLAB software. The numerical method is validated by comparing the current results with previously published work [27] for limited case, seeFig 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g002\n\nThis part is dedicated to investigating the effects of several physical factors on the Odroyd–B fluid occupying space over a horizontal plate. The physical factors considered in this research include fractional exponentsα,β, relaxation timeλ1, retardation timeλ2, nanoparticle volume fractionφ, thermal radiationRd, dissipation parameterE, and conjugate heat parameterγ. Furthermore, the obtained results are explained in depth for the parameter ranges: 0 . 1 ≤α≤β≤ 0 . 8,, 0 ≤φ≤ 0 . 04, 0 ≤Rd≤ 0 . 8, 0 . 1 ≤E≤ 0 . 8, and 0 . 1 ≤γ≤ 0 . 6.\n\nBegin with theFig 3which explains the impact of fractional exponentsαand the relaxation timeon the velocity fielduwhenβ= 0 . 8,,φ= 0 . 02,Rd= 0 . 2,E= 0 . 1 andγ= 0 . 2. It has been established that fractional exponents have a significant influence on the velocity field. As the value ofαrises, the magnitude of the velocity diminishes as seen inFig 3. However, a rising velocity behavior is evident with increasing values of relaxation time.\n\nFig 4shows how the velocity is affected by the fractional exponentβand the retardation timeparameters whenα= 0 . 1,,φ= 0 . 02 ,Rd= 0 . 2,E= 0 . 1 andγ= 0 . 2. It is obvious that raising the power indexβincreases the velocity, whereas growing the values of the time retardation parameterdecreases the velocity.\n\nThe temperature profile for various values of dissipation parameterEand nanoparticle volume fractionφis plotted inFig 5whenα= 0 . 1,β= 0 . 8,,,Rd= 0 . 2 andγ= 0 . 2. This figure shows that the temperature of the fluid increases asEincreases. The fundamental reason for this is that whenErises, higher viscous dissipation occurs, in which mechanical energy is transformed into internal energy, causing the fluid temperature to increase. Moreover, this also figure shows an increasing trend in temperature for the accumulated values ofφ. This behavior was due to the high thermal conductivity of the nanoparticles.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g005\n\nFig 6represents effects of thermal radiationRdand thermal slip parameterγon temperature whenα= 0 . 1,β= 0 . 8,,,φ= 0 . 02 andE= 0 . 1. The results revealed that the temperature of the fluid increases for higher values ofRdandγ.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g006\n\nInFig 7, the surface plots(left) and contour lines (right) for the velocity are depicted. This figure shows a relationship between velocityuand the nanoparticle volume fractionφwhenα= 0 . 1,β= 0 . 8,,,Rd= 0 . 2,E= 0 . 1 andγ= 0 . 2. A monotonic decrease in velocity with the enhancement of nanoparticle volume fractionφis attributed. As the nanoparticles’ volume percentage grows, the particles’ interactions become more significant. These interactions cause drag forces inside the fluid and slow down the fluid.\n\nThe surface and contour plots inFig 8present the temperature variations for different nanoparticle volume fraction valuesφwhenα= 0 . 1,β= 0 . 7,,,E= 0 . 1 andγ= 0 . 2. These graphs demonstrate that the temperature of the fluid increased when the nanoparticle volume fraction increased.\n\nThe variations in the Nusselt number due toαandare depicted inFig 9when,φ= 0 . 02 ,Rd= 0 . 2,E= 0 . 1 andγ= 0 . 2. This figure reveals that the heat transfer rates are higher for maximum values of the fractional exponent and the relaxation time parameter.\n\nFig 10is drawn to show the effects of fractional exponentβand the retardation timeon Nusselt number when,E= 0 . 1 andγ= 0 . 2. InFig 10, it is evident that when the value ofαincreases, the magnitude of the Nusselt number decreases. On the other hand, in contrast to the situation withβ, a rising behavior of the Nusselt number is shown with increasing values ofinFig 10.\n\nThe Nusselt numberNuas a function of dissipation parameterEand nanoparticle volume fractionφis illustrated inFig 11whenα= 0 . 1,β= 0 . 8,,,Rd= 0 . 2 ,  andγ= 0 . 2. This graph shows that the heat transfer rates are significantly increased with the increase in the volume fraction of nanoparticles. It is worth mentioning that the thermal conductivity of nanoparticles is greater than that of the base fluid. Therefore, the thermal conductivity of the fluid is increased when nanoparticles are introduced to it. As a result, the nanofluid transfers heat more efficiently. Moreover, the heat transfer rate of mineral oil increased by 9.4% on adding a 4% volume fraction of nanoparticles. Note thatφ= 0 represents mineral oil base fluid. However, the Nusselt number decreases for increasing values ofE.\n\nInFig 12, then effects of thermal slip parameterγand thermal radiationRdon Nusselt number are depicted whenα= 0 . 1,β= 0 . 8,,,φ= 0 . 02 ,  andE= 0 . 1. The obtained results showed that the Nusselt number decreases for increasing values ofRdwhereas increases for increasing values ofγ.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g009\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g010\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g011\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317297.g012\n\nThis research analyzed heat transfer and flow of Oldroyd–B nanofluid over a horizontal plate. The non–linear fractional model is solved using the finite difference method. The integer order derivatives are integrated using the Crank–Nicolson method whereas the time fractional derivatives are evaluated using the Caputo derivative. The situations are carried out using MATLAB software. The results revealed that the relaxation time and retardation time parameters slow downs the fluid. The heat transfer rates increased with increasing values of nanoparticle volume fraction. Some major findings of the study are\n\nNon–Newtonian nanofluids are used in enhanced oil recovery and drilling fluids to improve the efficiency of extraction processes. There are a few aspects of the present analysis. Although the analysis was conducted for fluid flow on a horizontal surface, it may be applied to various heat exchanger structures. The research has not considered hybrid nanofluid, which could be more beneficial in terms of applications. Therefore, heat transfer performance in a non–Newtonian fluid using hybrid nanoparticles under physical factors like magnetic field and thermal radiation, etc., is recommended.",
    "category": "materials_science"
  },
  {
    "title": "Evaluation and characterization of framycetin sulphate loaded hydrogel dressing for enhanced wound healing",
    "authors": "Zhuo Wu, Iqra Yaqoob, Mehreen Afzal, Furqan Muhammad Iqbal, Waseem Hassan, Xinjun Chen, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0317273",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0317273",
    "content": "Hydrogels loaded with antibiotics can be an effective drug delivery systemfor treating skin diseases or conditions such asinburns and wound healing.\n\nThe current research work was planned to preparea hydrogel dressing for an effective wound healing. The hydrogel formulation was aimed to provide sustained drug release, reducing the frequency of repeated applying the transdermal drug formulation or patch.\n\nDifferent polymers, polyvinyl alcohol, sodium alginate, and polyvinyl pyrrolidonein varying ratios were used to prepare hydrogels by freeze-thawing method. The prepared hydrogel formulations were loaded with framycetinsulphate (FC-S), a topical aminoglycoside.\n\nSwelling behaviour, drug release pattern, wereinvestigated.Equilibrium and dynamic studies were conducted atpH7.4. The prepared hydrogel formulations showed Euilibriumswellingratio of 197.5%.The in-vitrorelease pattern of FC-Shydrogels was determined by dissolution testing. The prepared hydrogels were characterized by scanning electron microscopy (SEM)andfourier transform infrared (FTIR)spectroscopy.Animal study was conducted on rats to evaluatethein-vivotherapeutic effectiveness of FC-S hydrogels in wound healing. For that purpose,wounds were induced in the animals. The drug loaded hydrogel dressing was effiecent in wound heaing as the wound treated with FC-S loaded hydrogel was almost completely healed (97%) on the fifth day in comparison to commercially available product (Sofra Tulle gauze) that healed 86%, whereas free FC-S manifested healing at 76%.\n\nIt was observed that hydrogel dressing loaded with FC-S was therapeutically more efficient and can be used as a potential candidate for wound healing.\n\nCitation:Wu Z, Yaqoob I, Afzal M, Iqbal FM, Hassan W, Chen X (2025) Evaluation and characterization of framycetin sulphate loaded hydrogel dressing for enhanced wound healing. PLoS ONE 20(4):\n           e0317273.\n        \n        https://doi.org/10.1371/journal.pone.0317273\n\nEditor:Ghulam Murtaza, COMSATS University Islamabad - Lahore Campus, PAKISTAN\n\nReceived:July 16, 2024;Accepted:December 24, 2024;Published:April 17, 2025\n\nCopyright:© 2025 Wu et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nTransdermal drug delivery system (TDDS) is prepared to deliver effective therapeutic drug doses across the skin [1]. TDDS is preferable for drugs that are metabolized by the liver and decomposed in the stomach and intestine. The drug is directly absorbed into the systemic circulation avoiding first-pass metabolism eventually [2]. It avoids drug-drug, drug-food, and drug-gastrointestinal microflora interactions [3]. TDDS is suitable for old-agedpatients with limited oral activity [4]. It provides extensive benefits to the wound area. It is less traumatic to wounds and removes the excess exudates from wounds [5]. Thehydrogel dressing is a popular TDDS, due to its numerous advantages like higher entrapment effiecncy and sustained release characteristics [6].\n\nHydrogels are a hydrophilic, three-dimensional network of crosslinked polymers capable to swell and holdanlarge amount of water and biological fluids without losing their structure [7–11].The hydrogel can absorb wound exudates and provide a moist environmentthat is effective for wound healing. Hydrogel has semi-occlusive properties, it hydrate the wounds and has ability to rehydrate eschar, and helps in autolytic debridement [12]. Hydrogel dressings provide a convenient, non-invasive,cost-effective, and painless application with reduced dosing frequency and controlled release characteristics to provide prolonged delivery of the drug. They are more effeicient in comparison to other modern wound dressings, as they can be combined with mesenchymal stem cells for effective wond healing [13,14]. Different formulation methods of hydrogel preparation have been used by the pharmaceutical researchers, like ionic gelation, radiations and freeze-thawing [15–17]. Microwave radiations have been used successfully for hydrogel synthesis [18]. Hydrogels prepared by the freeze-thawing method have great potential for biomedical uses [19,20]. A literature survey revealed that various skin infections are treated with neomycin Sulphate (S) and gentamycin S-loaded hydrogel patches [21].\n\nIn this current research work,FC-S-loaded hydrogel dressing was prepared and evaluated for wound healing effect. FC is a broad-spectrum bactericidal antibiotic belonging to the class of aminoglycoside.Its Chemical Formula\n\nC23H46N6O13and structure is given asFig 1. FC class III drug, BCS that is white to off white powder with melting point 160 °C, freely soluble in water, very slightly soluble in alcohol and practically insoluble in acetone.Themechanism of the action of inhibition includes the interruption in peptide-chain elongation, which blocks the A site of ribosomes leading to the genetic code misreading. FC-S has an effeicientwoundhealingand could be used as an alternative to silversuphadiazine, as it providespainless application without causingnephrotoxicity, ototoxicity and skin discoloration [22]. FC-Sis availableas cream, gel and ointment. It is also commercially available as guaze dressing for wound healing. It has been also studied by researchers as microsponge loaded gel for its efficient wound healing effect [23]. However, many studies have been conducted on preparing hydrogel dressings for wound healing, we selected a conveinient and economical method for preparing FC-S hydrogels without using crosslinker. This present study was aimed to formulate a TDDS of the FC-S-loaded hydrogel dressing by freeze thawing method. The FC-S hydrogel dressing was designed to provide sustained drug release, reducing the frequency of application that maintains the drug stability in polymeric network. FC-S-loaded hydrogel dressing composed of drug/polyvinyl alcohol/Polyvinyl pyrrolidone/sodium alginate by the freeze-thawing method has an advantage of physical crosslinking without using crosslinker. It avoids the possible toxic effect due to the crosslinking agent used in the preparation of chemically crosslinked hydrogels [24,25]. The prepared with FC-Shydrogel dressings were evaluated by different characterization techiques including FTIR, SEM, swelling behaviour,invitrodrug release andinvivowound healing studies. The wound healing characteristics were studied in comparison to a commercial product, Sofra Tulle gauze.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.g001\n\nPolyvinyl alcohol (PVA) (average Mw=85000–124000, 99+%hydrolyzed), Polyvinyl alcohol (Average Mw 72000) from Sigma Aldrich, polyvinyl pyrrolidone (PVP) having Average Mw 40,000), were bought from Sigma-Aldrich. Sodium alginate, monobasic potassium phosphate, and sodium hydroxide werepurchased from UNI-CHEM.Allchemicalsusedwere of analytical grade.\n\nVarious concentrationsofpolyvinylalcohol, polyvinyl pyrrolidone, and sodium alginatewereused and different formulations of hydrogel dressingswereprepared. The composition of hydrogel is shown inTable 1. The various formulations of hydrogel wound dressings were prepared by dissolving a accurately weighed 1 g as mention inTable 1. of polyvinyl alcohol by continuously stirring at 100–150 rpm at 80°C temperature for 1 hour as described [26]. Predetermined sodium alginate amount weighed and dissolved in distilled water by continuous stirring at 60°C for 15 minutes at 80rpm. Polyvinyl pyrrolidone was weighed and dissolved in distilled water. Polyvinyl alcohol (PVA) solution was mixed in already prepared sodium alginate solution (SA) and polyvinyl pyrrolidone solution and again stirred for 1 hour. The resulting solution was placed in a sonicator to remove the air bubbles. A weighted amount of FC-Swasadded to it. The resulting solution was poured intopetri dishes. These petri disheswereplaced for freeze-thawing and frozen at -20°C for twenty hours and then at room temperature. Hydrogels were thawed for three consecutive cycles of freeze-thawing. After thawing these prepared hydrogels were washed with distilled water to remove the unreacted polymer. And then hydrogelswereplaced on blotting paper to remove the excess water. FC-S-loaded hydrogels were prepared with both PVA (average Mw=85000–124000, 99+ % hydrolyzed) and were found more stable as compared to polyvinyl alcohol (Average Mw=72000) because of the higher molecular weight of PVA. It also remains stable at higher temperatures and is more strongly crosslinked with sodium alginate.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t001\n\nDEE is typically determined by quantifying the amount of drug encapsulated within the hydrogel compared to the initial amount used. This is often achieved by dissolving a known quantity of the drug-loaded hydrogel in an appropriate solvent and measuring the drug concentration using analytical techniques such as UV-Vis spectroscopy or high-performance liquid chromatography (HPLC).\n\nCalculation:\n\nThe hydrogel dried disk was crushed for FTIR by using pestle mortar.Powdered material of hydrogel in 1:100 proportion of potassium bromide was added mixed and then dried at 40 ̊C.Thin films of 1–2mm thickness wereobtained [27]. FTIRspectra were measured in the range of 3500–1000 cm-1. Spectra were recorded during twenty-four scans using f FT-IR BRUKER.\n\nThe morphological characteristics were determinedby using a scanning electron microscope (Evo LS 10 Zeiss Germany). Drug loaded hydrogels and drug free hydrogel formulutions were taken for SEM images to observe the changes illustrating the drug entrappedin hydrogel.\n\nThe swelling study was conducted by measuring the dynaminc swelling ratio and equilibrium swelling ratio to investigate the water absorption capacity of hydrogels dressings. Swelling behaviourcan be evaluated by using different buffering agents [28,29].\n\nHydrogel dressing made a network which has high and increased porosity. The ability of the hydrogel to imbibe an enormous quantity of water is shown as a swelling ratio of the hydrogel. The swelling ratio is an important requirement of hydrogel dressing for the dressing of wounds. Four formulations of the prepared hydrogel dressing PVA/PVP/SA loaded with FC-Swereselected for the swelling study. The selected (2 cm×2 cm) hydrogels were cut into pieces and dried at 45°C for 12 hours in a dry oven. Hydrogels were immersed in Phosphate-buffered saline (PBS) ofpH7.4. These swollen hydrogels were taken out from the solution at regular time intervals then placed on blotting paper and weighed the swollen gel and then these swollen hydrogels were put back in the same solution [30]. The swelling ratio of hydrogels was calculated byequation 1.\n\nWhere the weight of swollen hydrogel isWs;Wiis the initial dried hydrogel weight [31–33].\n\nHydrogel dressing pieces were dried at 45°C for 12 hours. Then immersed these hydrogels in desired PBS of pH of 7.4 for 24 hours. These hydrogels in the swollen state from the solution were taken out and weighed until constant weight is achieved [34]. The equilibrium swelling ratio was calculated by using the formula written inequation 2.\n\nPercentage equilibrium swelling is determined by using the formula written inequation 3[35,36]\n\nWhereWhis the swollen hydrogel weight andWdis the weight of the hydrogel dried.\n\nStock solution 1 and stock solution 2 were prepared with a concentration of 1000µg/ml and 100µg/ml respectively. Different dilutions were prepared from stock solution 2, i.e., 10µg/ml, 20µg/ml, 30µg/ml, 40µg/ml, 50µg/ml by taking 1, 2, 3, 4, 5ml and make it upto 10 ml in volumetric flask. The solvent used was PBS, pH 7.4 By using UV spectrophotometer, these dilutions were analyzed at λ=258 nm [37]. Graphically shown inFig 1.\n\nFour formulations of the synthesized hydrogel dressing polyvinyl alcohol/Polyvinyl pyrrolidone/sodium alginate loaded with FC-Swereselected for dissolution study on basis of greater water absorption characteristics measured byswellingratios.The selected formulations were FH5, FH9, FH11, FH12. The dissolution apparatus recommended by USP was used. Paddle apparatus was utilized to determine the release study. For this purpose,thehydrogelwasdried in an oven at 45°C for 24 hours. Dried hydrogels were immersed in100mL dissolution medium (PBS of pH of 4.4.4),ina dissolution apparatus beaker and the dissolution medium used. The dissolution medium was maintained at 32°C.4mL aliquots were obtainedat specified time intervals of 0.5, 1, 1.5, 2, 3, and 4 hours in dissolution medium is PBS 7.4 it is replenished with freshly prepared distilled water\n\nalso added throughout this procedure to keep the dissolution medium level up to the mark. Absorbance was analyzed by using an ultraviolet spectrophotometer for studying drug release patterns and compared with the standard curve of the drug used.For release kinetics of drug various models such as First order, Higuchi model, Zero order and Korsmeyer-Peppaswere used. Drug release mechanism studied in previous studies on hydrogels was fickian when n = 0.5, while the diffusion mechanism is called non-fickian when 0.5 <n<1 [16,38]\n\nIn-vivowound healing studies were carried on male wistarrats with the approval of Pharmacy Ethical Committee, Bahauddin Zakariya University Multan, Pakistan (No.187/PEC/2020) [39]. Twenty-fourmale healthy Wistarrats weighing 250–300 g were obtained from the animal house of the Faculty of Pharmacy, Bahauddin Zakariya University, Multan. The environment and cages were kept clean during the entire experiment. All the procedures were conducted in accordance to ARRIVE guidelines. Dorsal hairs of rats were shaved, the skin was cleaned with ethanol (70%), and anaesthetized with lignocaine gel. An abrasion wound (1.5 cm×1.5 cm) was induced by rubbing the sand-paper over the shaved skin and acetone was used untiloozing of skin wound and bleeding of skin starts. It was ensured that this procedure only damage the superficial part of the skin.\n\nRats were randomly divided into four groups of 6 rats each group. The wound of rats in Group A, Cand Dwas covered with FC-S-loaded hydrogel dressing having composition drug/polyvinyl alcohol/Polyvinyl pyrrolidone/sodium alginate (0.1/1/0.08/1),Sofra Tulle gauze, a sterile guaze which is a commercial product and drug-free hydrogel dressing having composition polyvinyl alcohol/Polyvinyl pyrrolidone/Sodium alginate (1/0.08/1), respectively. Group B was kept untreated (control). All the hydrogel dressings (2×2 cm) were applied on the wound area and fixed with an elastic adhesive bandage. All rats were kept in separate cages and dressing was changed every day for the experimental duration. Size of wound in cm was measured by measuring tape. The images of the wound were taken and preserved at 0, 1, 3, 4, and 5 day. Wound size reduction was calculated by using theequation 4.\n\nWhere,WSiandWStare the sizes of wound at initial time andttimerespectively. Values were presented as mean ± SD (n-6). All the animals were released after complete wound healing.\n\nThis study aims to synthesizebio-degradable and bio-compatible FC-S hydrogels. FC-S, a constituent of neomycin S [40] is an aminoglycoside with known pharmacological action in burn and woundtreatmet [22,41–43]. The visual aspect of hydrogel, FTIR, SEM, swelling studies,in-vitrodrug release of hydrogel were performed for charaterization.Furthermore,in-vivohealing study was also performed on rats. As topical formulations of neomycin is already established in wound healing [44,45], the charaterisation of one of its constituent with advanced drug delivery system can be a useful.\n\nThe entrapment efficiency of optimized formulation is given inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t002\n\nFTIR spectra of FC-Sare shown inFig 2(A). The peak at 3740 cm-1isrelated to OH stretching and the peak at 2017 cm-1shows N=C=S stretching. Similarly, peak at 1524 cm-1represents N-O stretching while the peak at 1050 cm-1relates to the stretching vibration of S=O.Thespectra of FC-S-loaded hydrogel dressingareshown inFig 2(B), where peaks at 3242 cm-1is due to OH stretching vibrations and 2919 cm-1due to C-H stretching. The peak at 1418 cm-1depicts the O-H bending. At 1141 cm-1S=O, indicates the stretching vibrations due to S group of FC-S, whereas, 1087 cm-1absorbance frequency exhibit the C=O stretching due to secondary alcohol-related to PVA [18]. The FTIR spectra revealed successful cross-linking through significant shifts in characteristic wavenumbers. For instance, the –OH stretching vibration at ~3800 cm⁻¹ showed a shift to ~3740 cm⁻¹, indicating reduced free hydroxyl groups. Similarly, the C=O stretching peak shifted from ~1068 cm⁻¹ to ~1087 cm⁻¹, suggesting the formation of ester bonds. These shifts confirm the successful integration of cross-linking agents within the hydrogel network\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.g002\n\nIn general, the SEM exhibits microstructure morphologies of hydrogels. The SEM of the synthesized hydrogel is shown inFig 3. This picture verifies that the synthesized polyvinyl alcohol-based hydrogel in this work has a porous structure. In hydrogels existence of these pores strongly increases the swelling kinetics and drug release of the resulted product. The SEM images showed that the hydrogel was porous and pores were distributed uniformly. The porosity enables faster swelling which is useful for drug loading and release [11,18].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.g003\n\nThe swelling ratio of selected samples FH5, FH9, FH11and FH12 of FC-S-loaded hydrogels is shown inFig 4andTable 3. The hydrogels loaded with FC-S sample FH5 show maximum equilibrium swelling. Results indicate that sodium alginate showed greater swelling capacity than PVP. It suggests that the addition of sodium alginate increases the swelling capacity and has a positive effect on the equilibrium swelling ratio. FH5 Formulation has the highest weight ratio of sodium alginate which is1/0.1/0.8. By decreasing the sodium alginate ratio, swelling decreases [46].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.g004\n\nA dynamic swelling study was performed on four selected samples FH5, FH9, FH11, and FH12 having a ratio of Polyvinyl alcohol/Polyvinyl pyrrolidone/Sodium alginate(1/0.1/0.8), (1/0.6/0.3), (1/0.8/0.1), (0.9/0.9/0.1)with model drug FC-S 0.1g respectively. The most important hydrogel characteristic is swelling capacity without losing its shape and form from which water can not be removed under pressure [47]. The swelling ratio is affected by several factors such as hydrophilicity attributed to hydrophilic groups present on the polymer chain, polymer concentration and stiffness. These factors modify the average spaces in closslinked structure that affects the water absorption and structure. During the first duration of time in contact with solution rapidly swelling increases due to crosslinked polymer enabling to diffuse water quickly. The swelling ratio value of the hydrogels in this experiment was examined for 8 h at a time interval of 1h, and then at 24 h. It was observed that swelling ratio is affected by soaking time,the longer the period of soaking, the greater the swelling. It is according to the previously reported characteristics of hydrogels [48]. Dynamic swelling ratio observed for 8 hr, which is represented graphically and shown inFig 5andTable 4for samples FH5, FH9, FH11, FH12. All the samples show a gradual increase in the swelling of hydrogel dressing. FH5 shows higher dynamic swelling because of sodium alginate due to more hydrophilic nature [49].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.g005\n\nTheinvitrodrug release of FC-S hydrogel dressings was determined, where, 50% of drug release was observed in all formulations in the 2 hours. Irrespective of polymers of dressing all the formulations were possessing the release rate of about 80% for 4 hours. The hydrogel dressing prepared with drug/PVA/PVP/SA of ratio 0.1/1/0.1/0.8, sample FH5 showed maximum drug release upto 88% in 4 hours. Other formulations FH 9, FH 11, and FH 12 showed drug release upto 80% after 4 hours as shown inFig 6. It was showing the release of drug for longer period of time to provide a sustained effect. Drug release characteristics are related to water absoption capacity of hydrogels, ingress of aqueous mediumin hydrogel polymeric network eventually affects the release of drug [50]. To study drug release order, values of ʻʻR2ʼʼ were studied. The model for release of the drug is best when values of ʻʻR2ʼʼare close toʻʻ1ʼʼ. In this release study, the values of ʻʻrʼʼ of most samples for release of the drug were close to ʻʻ1ʼʼ. So the model that best fits with FC-Srelease was first order. These values of (R2) and (K) have written inTable 4. However, values for ʻʻR2ʼʼ for higuchi model for drug release have exhibited a diffusion-controlled mechanism for the release of FC-S because when plotted against the fraction of drug release, the linear plot is obtained.\n\nThe framycetin sulphate loaded hydrogel dressing were composed of Framycetin sulphate drug polyvinyl alcohol, polyvinylpyrrolidone,sodiumalginate.\n\nThe framycetin sulphate loaded hydrogel dressing were composed of Framycetin sulphate drug polyvinyl alcohol, polyvinylpyrrolidone,sodiumalginate.\n\nhttps://doi.org/10.1371/journal.pone.0317273.g006\n\nThe slope and intercept of ʻʻ lnʼʼ in korsmeyerpeppas have been manipulated to determine the ʻʻnʼʼ value. The results for values of ʻʻnʼʼ have exhibited a non-fickian release of FC-S because values obtained were among 0.45–1. The drug release pattern of FC-S-loaded hydrogels FH5, FH9, FH11, and FH12 by employing different kinetics modelsisshown inTable 5.Table 6exhibit the values of ʻʻnʼʼ. Drug release data for samples FH5, FH9, FH11, and FH12 are shown inTable 7.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t007\n\nThe natural mechanism of regenerating epidermal and dermal tissues is called wound healing. The mechanismsof tissue healing have been characterized into phases which involve the proliferative, inflammatory phase, and remodelling phases. In the inflammatory phase, debris and bacteria are removed and phagocytosis, mediator and cytokines are released that cause division of cells and migration including in the proliferative phase. Collagen, angiogenesis, granulation, deposition, epithelization, tissue formation and wound contraction occurs in the proliferative phase. To cover the wound, the epithelial cells start moving across during epithelization. By the process of wound contracture, the wound is eventually closed by a combination of all these. Collagen is realigned and remoulded in the maturation and remodelling phase, along tension lines and cells removed by the method of apoptosis. The images representing the wound on the rat modelareshown inFig 7and the wound curing profile is shown inFig 8. Wound treated with drug-free hydrogel dressing (D), treated with hydrogel dressing loaded with FC-S (A) and treated with commercial product showed higher healing rate (C) and exhibited accelerated wound curing as compared to non-treated rat wound (B). Wound size reduction is given inTable 8and percentage wound healing is numbered inTable 9. The commercial product sufre tulle treated rat wound showed accelerated curing and high curing rate compared to non-treated wound and treated with drug-free hydrogel dressing [51]. From the initial point at day 2–5 wound healing rate was higher in FC-S-loaded hydrogel as compared to the non-treated wound on rats, treated with a commercial product, and wounds treated with drug-free hydrogel dressing [46]. On days 3 and 5 wound healing rate was highest by FC-S-loaded hydrogels. At day 5 healing of wound rate in non-treated rats, wounds treated with drug-free hydrogel dressing, wounds treated with FC-S loaded hydrogel and wounds treated with commercial product were 50, 70, 86, 78% respectively. Results exhibited that wound treated with FC-S-loaded hydrogel shows maximum wound healing. Such excellent wound healing effect by FC-S-loaded hydrogel was mainly due to a moist environment with good swelling capacity. A moist environment was very helpful for the migration of keratinocytes, cell growth factors, and cytokine fibroblast [52]. Moreover,theFC-S model drug used is an aminoglycoside antibiotic which has a positive effect on wound healing because of its established mechanism of action on bacteria. Sodium alginate in hydrogel maintainsamoist environment that helps to increase healing and the making of granulation tissue. TheFC-S loadedhydrogel dressing was evaluated as efficient TDDS in curing wounds in comparison to the commercially available sterile guaze due to its firm adhesionand mechanical protection. The polymeric network due to the shape adaptability characteristics on contact with skin, that provide a sufficient coverage needed for safeguarding of wound [53,54].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.t009\n\nThe framycetin sulphate loaded hydrogel dressing were composed of framycetin sulphate drug/Polyvinyl alcohol/Polyvinyl pyrrolidone/Sodium alginate ratio.\n\nThe framycetin sulphate loaded hydrogel dressing were composed of framycetin sulphate drug/Polyvinyl alcohol/Polyvinyl pyrrolidone/Sodium alginate ratio.\n\nhttps://doi.org/10.1371/journal.pone.0317273.g007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317273.g008\n\nIn current research, FC-S hydrogel dressinghave been developed by a physical cross-linking of PVA, PVP, and SA by freeze-thawing method. It can be concluded that preparedFC-S incorporated hydrogelshad high porosity and desriable morphological characteristics, suitablely possessing high swelling capacity in aqueous solution at pH 7.4. The swelling of a polymeric network was not markedly affected by composition of polymers,howeverSA has a minor effect on swelling behaviour. The hydrogel dressing had high ability to hold drug and able provide a sustained release characteristics. FC-S-loaded hydrogel dressing displayedimproved wound healing results than a commercial product due toimprovedmoistenvironment and wound exudates absorbing capacity. Furthermore, this hydrogel dressing would be expected to have better patient compliance as the application of local preparation would substantially decrease side effects systemically.\n\nFH 5 swelling.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s001\n\n(XLSX)\n\nFH 11 swelling.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s002\n\n(XLSX)\n\nFH9 swelling.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s003\n\n(XLSX)\n\nFH12 swelng.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s004\n\n(XLSX)\n\nFH5 drug release.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s005\n\n(XLSX)\n\nFH9 drug release.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s006\n\n(XLSX)\n\nFH11 drug release.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s007\n\n(XLSX)\n\nFH12 drug release.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s008\n\n(XLSX)\n\nFTIR_data.\n\nhttps://doi.org/10.1371/journal.pone.0317273.s009\n\n(DOCX)",
    "category": "materials_science"
  },
  {
    "title": "High-throughput assessment of the behavioral responses to toxic organic solvents inCaenorhabditis elegans",
    "authors": "Masahiro Tomioka, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0311460",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0311460",
    "content": "Novel chemical compounds are continuously being developed for use in various industries and daily life. Workers in these industries assess and avoid chemical hazards based on published information about chemical toxicities. However, avoiding the hazards associated with chemicals with unknown toxicity is difficult. Therefore, understanding the toxicities of chemicals in a high-throughput, multifaceted manner is essential. In this study, I developed a high-throughput method for assessing chemical toxicities through quantitative measurement of behavior inCaenorhabditis elegans. I determined the acute response to 30 organic solvents, including alcohols, cellosolves, ethers, ketones, and acetate esters, which are widely used in industries, with motility as an endpoint. Exposure to 0.5%–6% organic solvents caused a dramatic decrease in locomotion speed. The adverse effects of organic solvents on motility were proportional to the lipid solubility of the chemicals, similar to the positive relationship between the anesthetic effects of volatile organic chemicals and their lipid solubility in organisms, including humans. In addition to their effects on motility, organic solvents affect posture during locomotion in different ways depending on the chemical’s functional group. Solvents with hydroxyl groups, such as alcohols and cellosolves (0.5%–3%), reduced the amplitude of body bending, whereas solvents with ketone groups, such as ketones and acetate esters (0.5%–4%), increased it during undulatory locomotion. In addition, organic solvents caused changes in chemotaxis plasticity based on the association between starvation and chemical signals at concentrations lower than those that affect locomotion. This study describes a high-throughput method for acute chemical toxicity testing and provides new insights into behavioral responses to organic solvents that are toxic to humans and other animals.\n\nCitation:Tomioka M (2025) High-throughput assessment of the behavioral responses to toxic organic solvents inCaenorhabditis elegans. PLoS ONE 20(4):\n           e0311460.\n        \n        https://doi.org/10.1371/journal.pone.0311460\n\nEditor:Myon-Hee Lee, East Carolina University, UNITED STATES OF AMERICA\n\nReceived:September 18, 2024;Accepted:March 10, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Masahiro Tomioka. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nOrganic solvents are used in various industries as well as in our daily lives. Many organic solvents are amphiphilic and can penetrate the epithelium, thus posing a risk of health hazards to organisms, especially workers in industries. Commonly used organic solvents, such as alcohols, ketones, and ethers, can cross the blood–brain barrier and cause neurotoxicity when exposed to high levels of these chemicals. For example, low concentrations of benzyl alcohol are generally used in daily life, such as in foods, drugs, and cosmetics. However, benzyl alcohol intoxication has been reported in workers using paint strippers containing high concentrations of benzyl alcohol [1,2]. Intoxicated patients collapsed during paint stripping in a state of unconsciousness, and severe damage to the central nervous system has been reported [1]. To reduce hazardous chemical risks, a hazard assessment has been performed using information on chemical toxicities, such as the Globally Harmonized System of Classification and Labelling of Chemicals (GHS) [3,4], which classifies chemicals based on accident cases and toxicity studies on animals. However, many chemicals have unknown hazards. Benzyl alcohol had not been classified as a chemical with specific target organ toxicity to the brain before serious accidents occurred in Japan. To predict chemical hazards and prevent accidents before they happen, it is important to fundamentally understand the toxic effects of chemicals and the mechanisms of their adverse effects on organisms.\n\nExternal chemicals interact with proteins and lipids on plasma membranes, as well as extracellular biological molecules, such as the extracellular matrix, and can cause toxic effects. Furthermore, chemical toxicities occur through the penetration of chemicals into cells, where they subsequently interact with biological molecules. Cell permeability depends on the chemical’s physicochemical characteristics, including molecular size, melting point, and lipid solubility. The externally incorporated chemicals interact with biological molecules, such as proteins, lipids, and DNA, to exert their toxic effects. Exposure to high levels of organic solvents causes acute toxicity to the brain, followed by disturbances in consciousness, similar to the effects of volatile anesthetics. More than 120 years ago, Meyer and Overton independently reported that the anesthetic effects of volatile organic chemicals increase with increasing lipid solubility of the chemicals [5,6]. Subsequent studies have shown that increased lipid solubility elevates passive transport into cells through the plasma membrane, which is constituted of a lipid bilayer, and could affect the function of multiple lipids and proteins within the cell membrane, such as ion channels and synaptic proteins, although the mechanisms are not fully understood [7]. These findings explain, at least in part, the Meyer–Overton hypothesis, which suggests a positive relationship between the anesthetic effect and lipid solubility of organic chemicals. Similarly, it has been reported that lipid solubility is linearly correlated with the adverse effects on growth in microorganisms, such as yeast [8]. Thus, lipid solubility increases the general toxicity of organic chemicals across multiple cell types and species.\n\nThe nematodeCaenorhabditis eleganshas been widely used as a powerful model organism in basic science research, including genetics, molecular biology, and neurobiology. Moreover, its use in toxicology research has increased in recent years [9]. Several studies have shown similarities betweenC. elegansand other organisms exhibiting chemical toxicities [10]. Biological targets appear to be relatively similar betweenC. elegansand higher organisms based on the conservation of genes that compose the cellular structure, molecular signaling, and enzymes that produce biological materials [9]. Furthermore, the small body size of approximately 1 mm in adults and the fast life cycle of approximately 3 days from egg to mature adult under optimal conditions enable high-throughput screening, such as chemical screening, using large quantities of nematodes [11]. Therefore,C. elegansare ideal animal models for understanding chemical toxicities in organisms and their underlying cellular and molecular mechanisms. Although a standardized protocol for assessing environmental toxicity has been developed [12], no standardized protocol exists for determining chemical toxicity in humans usingC. elegans.\n\nThe behavioral effects of anesthetics, such as halogenated hydrocarbons and halogenated ethers, and alcohols like ethanol, have been well studied inC. elegans[13,14]. Exposure to these anesthetics or alcohols causes changes in locomotion, such as uncoordinated and slow movements, eventually resulting in complete immobility. It has been shown that the paralyzing effects of these volatile chemicals are highly correlated with their lipid solubility [15,16]. Genetic studies have identified several genes and molecular mechanisms underlying paralyzing effects. UNC-79 and UNC-80 encode key molecules that regulate a voltage-insensitive cation channel, the NALCN (Na+leak channel, non-selective) channel, inC. elegans. Mutants ofunc-79andunc-80show hypersensitive phenotypes to a subset of volatile anesthetics, while being normal or resistant to other sets of volatile anesthetics and ethanol, suggesting that UNC-79 and UNC-80 mediate responses to only a subset of volatile anesthetics and that multiple mechanisms underlie anesthetic effects inC. elegans[16,17]. The direct targets of volatile anesthetics and alcohols have also been identified through genetic studies ofC. eleganscombined within vitrostudies using their mammalian homologs [18–20]. Ethanol was shown to activateC. elegansand mammalian BK potassium channelsin vivoandin vitro, and an alcohol-binding site of the BK channel was identified via crystallography [21,22]. It has also been revealed that several other proteins, such as ion channels and gap junction proteins localized to microdomains known as lipid rafts in the cell membrane, play important roles in the anesthetic effects of volatile chemicals inC. elegans[14,23].\n\nIn this study, I focused on 30 kinds of simple organic solvents with various functional groups, including alcohols, ethers, ketones, and acetate esters. These organic solvents are commonly used in chemical industries and are associated with the risk of neurotoxicity and/or anesthetic effects from high-dose exposure in humans. The locomotion of the nematodes was comprehensively analyzed after exposure to organic solvents using a tracking system. The motility of the nematodes substantially decreased and eventually ceased after exposure to any of the 30 organic solvents. The paralyzed nematodes recovered after incubation without the organic solvents, suggesting that the organic solvents had an anesthetic effect on the nematodes. The extent of the anesthetic effects was proportional to the octanol–water partition coefficient, which reflects lipid solubility. Therefore, a Meyer–Overton relationship was observed for the adverse effects of organic solvents, which is consistent with previous reports demonstrating a positive relationship between lipid solubility and the potency of several anesthetics inC. elegans[15].\n\nFurthermore, I quantified the amplitude of body bends during undulatory locomotion and found that the specific effects of organic solvents on posture during locomotion qualitatively differed depending on the solvent’s functional group. The amplitude of body bending considerably increased after exposure to chemicals with short-chain ketone and acetate ester groups at concentrations lower than those that resulted in complete paralysis. Conversely, it decreased after exposure to short-chain alcohol and cellosolve groups. The increased effects on amplitude depended on TAX-4, a cyclic nucleotide-gated channel involved in sensory responses in chemosensory neurons [24], suggesting that chemosensory input is required for the increase in amplitude of body bends during locomotion. Conversely, decreased amplitude was observed in mutant backgrounds of genes required for chemosensory responses. These findings imply that organic solvents affect the neural circuit in different ways depending on the solvent’s distinct functional groups.\n\nFinally, I have demonstrated that organic solvents cause substantial defects in salt chemotaxis learning, a paradigm of learned behavior in salt chemotaxis, at concentrations lower than those affecting locomotion speed [25]. These effects did not depend on ODR-3, an alpha-subunit of the Gi/Go-like G protein that is critical for the sensory transduction of volatile compounds in chemosensory neurons [26]. These results imply that organic solvents affect the sensory neural circuits regulating salt chemotaxis plasticity in parallel with ODR-3-mediated sensory input. This study provides an observation of the multifaceted effects of toxic organic solvents on speed and posture during locomotion, as well as learned behavior inC. elegans.\n\nThe nematodeC. eleganswere cultivated on nematode growth medium (NGM) plates using a standard protocol [27]. Wild-type N2, theunc-29(e193)CB193, thetax-4(p678)JN730, theosm-9(ky10)CX10, thedyf-11(pe554)JN554, theodr-3(n2150)JN1722, and thedaf-2c(pe2722)JN2722C. elegansstrains were used. TheEscherichia coliOP50 bacterial strain was used as the food source. To prepare synchronized populations ofC. elegansfor locomotion analysis, eggs were harvested from gravid adult nematodes via treatment with an alkaline hypochlorite solution. Approximately 600 eggs were cultivated on NGM plates at 18°C–20°C for 4–5 days until they reached the young adult stage.\n\nSynchronous populations of adultC. eleganswere transferred from the growth plates to 500 µL of KPO4buffer solution (5 mM potassium phosphate, 1 mM CaCl2, 1 mM MgSO4, and 0.05% gelatin). To determine the MC<50values, organic solvents, sodium chloride, or glucose were dissolved in KPO4buffer at 4–7 different concentrations within a range of 0.125%–6%, and the nematodes were exposed for 15, 30, 60, or 120 min. For the untreated control groups, a KPO4buffer without organic solvents was used for the exposure procedure. To examine recovery from paralysis, the nematodes were soaked in KPO4buffer containing organic solvents for 2 h at their minimum concentration that caused complete paralysis, which was defined as the average locomotion speed being below 10 µm/s, unless otherwise stated. The nematodes were then transferred into KPO4buffer without organic solvent and incubated for 30, 60, or 120 min. After these soaking procedures, a 30-µL droplet with approximately 50 nematodes was transferred onto a test plate (5 mM potassium phosphate, 1 mM CaCl2, 1 mM MgSO4, and 2% Bacto agar), and excess liquid was removed with paper wipers. The movement of the nematodes on the test plates was captured under a stereomicroscope (S6E, Leica Microsystems, Germany) equipped with a USB CMOS camera (J-scope, Sato Shoji Corporation, Japan) operating at 30 frames per second for approximately 1 min.\n\nC. eleganslocomotion was analyzed using the WormLab software (MBF Bioscience, Vermont, USA) with 1500-frame image sequences (50-second movie at 30 frames per second). The center point of each nematode on the agar plates was tracked (Fig 1AandS1 Movie), and the movement speed of each trace was determined. The plus value represents forward movement, the minus value represents reverse movement, and an absolute value below 30 µm/s was defined as an immobile state (Fig 1B). The locomotion speed of each trace was determined as the average speed during forward movement, and the mean locomotion speed of all traces was plotted along with the standard error of the mean (SEM) on a graph after normalization with the untreated control (Fig 1D, right). Immobility was determined as the proportion of the immobile state in each trace, and the mean value of all traces along with the SEM was plotted on a graph (Fig 1D, left). The length of each nematode was determined as the length from head to tail along the central axis, and the mean length of all nematodes was plotted along with the SEM on a graph (Fig 3A). The amplitude of the body bends during locomotion was determined as the average centroid displacement, which is the distance between the midpoint and the average location of the central axis points of nematodes (Fig 5B), and the mean amplitude of each trace was plotted on violin plots (Fig 5C). At least three traces were used for the analyses.\n\n(A) Representative trajectories of nematodeC. elegansmoving on an agar plate within an area of approximately 1 cm2for 50 s. A trace depicted by an arrow is used for the representative analysis of the locomotion speed shown in B. (B) Locomotion speed (µm/s) during 50 s of tracking atC. elegans. Positive values (red region) or negative values (blue region) are defined as “forward” or “reverse” movements, respectively. Absolute values below 30 µm/s (gray region) are defined as “immobile.” (C) Violin plots of locomotion speeds on an agar plate after soaking in KPO4buffer. The x-axis represents the soaking time before locomotion assay on an agar plate. Each dot represents the mean locomotion speed in each trace. The solid horizontal lines represent the median. The dotted horizontal lines represent the 25thand 75thpercentiles. (D) The proportion of the immobile state (left) and locomotion speed (right) after exposure to benzyl alcohol for 15, 30, 60, or 120 min. Each data point represents the mean ± the standard error of the mean (SEM). The locomotion speed was normalized to the average value of the untreated control.\n\n(A) Representative trajectories of nematodeC. elegansmoving on an agar plate within an area of approximately 1 cm2for 50 s. A trace depicted by an arrow is used for the representative analysis of the locomotion speed shown in B. (B) Locomotion speed (µm/s) during 50 s of tracking atC. elegans. Positive values (red region) or negative values (blue region) are defined as “forward” or “reverse” movements, respectively. Absolute values below 30 µm/s (gray region) are defined as “immobile.” (C) Violin plots of locomotion speeds on an agar plate after soaking in KPO4buffer. The x-axis represents the soaking time before locomotion assay on an agar plate. Each dot represents the mean locomotion speed in each trace. The solid horizontal lines represent the median. The dotted horizontal lines represent the 25thand 75thpercentiles. (D) The proportion of the immobile state (left) and locomotion speed (right) after exposure to benzyl alcohol for 15, 30, 60, or 120 min. Each data point represents the mean ± the standard error of the mean (SEM). The locomotion speed was normalized to the average value of the untreated control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.g001\n\n(A, B) Relationship between behavioral toxicity (MC<50) after alcohol exposure for 1 h and the carbon number of alcohols. The proportion of the immobile state (A) and locomotion speed (B) are used as the endpoints. (C, D) Relationship between the MC<50after exposure for 1 h to organic solvents and the chemical’s carbon numbers (C) or octanol–water partition coefficients (D). The locomotion speed is used as the endpoint. R2values were determined using simple linear regression analysis. (E) Estimated internal concentrations of ethanol after exposure to 500 mM ethanol for 10 or 50 min. Each bar represents the mean ± the standard error of the mean (SEM). n = 3 biological replicates. (F) Comparison of the MC<50after exposure for 1 h to organic solvents among the wild type,tax-4(p678), andosm-9(ky10)nematodes. The locomotion speed is used as the endpoint. The MC<50after acetone exposure inosm-9(ky10)is above 5% and is indicated as (>5) above the bar.\n\n(A, B) Relationship between behavioral toxicity (MC<50) after alcohol exposure for 1 h and the carbon number of alcohols. The proportion of the immobile state (A) and locomotion speed (B) are used as the endpoints. (C, D) Relationship between the MC<50after exposure for 1 h to organic solvents and the chemical’s carbon numbers (C) or octanol–water partition coefficients (D). The locomotion speed is used as the endpoint. R2values were determined using simple linear regression analysis. (E) Estimated internal concentrations of ethanol after exposure to 500 mM ethanol for 10 or 50 min. Each bar represents the mean ± the standard error of the mean (SEM). n = 3 biological replicates. (F) Comparison of the MC<50after exposure for 1 h to organic solvents among the wild type,tax-4(p678), andosm-9(ky10)nematodes. The locomotion speed is used as the endpoint. The MC<50after acetone exposure inosm-9(ky10)is above 5% and is indicated as (>5) above the bar.\n\nhttps://doi.org/10.1371/journal.pone.0311460.g002\n\nA salt chemotaxis learning assay was performed according to a previously published procedure with some modifications [25] (S18 Fig). To prepare a chemotaxis test plate, an agar block containing NaCl (50 mM NaCl, 5 mM potassium phosphate, 1 mM CaCl2, 1 mM MgSO4, and 2% Bacto agar) was placed at the edge of an agar plate (5 mM potassium phosphate, 1 mM CaCl2, 1 mM MgSO4, and 2% Bacto agar) to form a NaCl concentration gradient by overnight incubation at room temperature (S18A Fig, right). For conditioning, the nematodes were transferred into 500 µL of KPO4buffer solution (5 mM potassium phosphate, 1 mM CaCl2, 1 mM MgSO4, and 0.05% gelatin) with or without 20 mM NaCl and incubated for 1 h, and named NaCl(+) or NaCl(−) conditioning, respectively. To assess the effect of organic solvent exposure for 1 h, the organic solvents were dissolved in KPO4buffer solution for NaCl(+) or NaCl(−) conditioning. To assess the effect of organic solvent exposure for 1 min, the nematodes were soaked in buffer solutions with or without NaCl for 1 h, then transferred into NaCl(+) or NaCl(−) buffer, respectively, which included the organic solvents, and incubated for 1 min. After conditioning, a droplet with approximately 50–100 nematodes was transferred to the chemotaxis test plate, and excess liquid was removed with paper wipes. Just before transferring the nematodes onto the chemotaxis test plate, the agar block was removed, and 0.5 µL of 1 M sodium azide was spotted at both positions where the agar block was placed and the opposite side to anesthetize the nematodes at those positions (S18B Fig). After the nematodes freely explored the test plate for 15 min, the numbers of anesthetized nematodes at each position were counted, and the chemotaxis index was calculated, as shown inS18B Fig. When the chemotaxis index value is 1.0, all nematodes that migrated from the starting area moved toward the high-NaCl area. When the chemotaxis index value is −1.0, all nematodes that migrated from the starting area moved toward the low-NaCl area. Assays were repeated six times.\n\nInternal ethanol concentrations were calculated according to a previous report with some modifications [28,29]. Synchronized populations of approximately 500 wild-typeC. elegansat the young adult stage were transferred to 500 µL of KPO4buffer solution (5 mM potassium phosphate, 1 mM CaCl2, 1 mM MgSO4, and 0.05% gelatin) with 500 mM ethanol and incubated for 10 or 50 min at room temperature. The nematodes were washed twice with ice-cold ddH2O, and the supernatants were removed. The volume of the nematode-containing solution was adjusted to approximately 25 µL. After freezing at −80°C for >30 min, the nematodes were thawed and ground with a pestle in the tube on ice. The alcohol concentration in the homogenate solution was determined according to the manufacturer’s instructions using an Alcohol Assay Kit (Cell Biolabs, USA). The volume ofC. eleganswas calculated by assuming that a single nematode is a cylinder [28]. Based on movies for locomotion analysis, the length and width of a nematode were determined as the length of the central axis and the average length of cross-sections over the entire body, respectively, using WormLab (S19 Fig). The average body length and half of the average body width were used as the height (h) and radius (d) of the nematode, respectively, and the volume was calculated as a cylinder according to the following equation: volume = πr2h. The internal ethanol concentration (C₂) of the nematodes was calculated using the following equation: C1V1= C2V2, where C1= ethanol concentration of the homogenate solution, V1= total volume of the homogenate solution, and V2= the estimated volume of 500 nematodes. Three biological replicates were performed for each condition.\n\nStatistical analyses were performed using GraphPad Prism 10. A simple linear regression analysis was performed to calculate the values of the coefficient of determination, R² (Figs 2A–2D,7CandS4–S6). For multiple comparison tests, an unpairedt-test with Holm–Sidak correction (Figs 3B,5DandS9,S11C,S17), a one-way ANOVA with Dunnett’s test (Figs 5C,6,7DandS13,S15), and a two-way ANOVA with Dunnett’s test (Figs 7B,8andS14,S16) were used. Raw data and statistics are provided inS1–S4 Files.\n\n(A) Changes in body length after exposure to 2-butanone (left) or tetrahydrofuran (right). Each data point represents the mean ± the standard error of the mean (SEM). (B) Violin plots of the body lengths of nematodes after exposure to ketones (left) or ethers (right). The exposure concentrations are the MC<50values determined by locomotion speed after 1 h of exposure. Data were normalized to the average values of the control. Each dot represents the body lengths of a nematode after exposure (red) or without exposure (blue). *P< 0.05, unpairedt-testwith Holm–Sidak correction.\n\n(A) Changes in body length after exposure to 2-butanone (left) or tetrahydrofuran (right). Each data point represents the mean ± the standard error of the mean (SEM). (B) Violin plots of the body lengths of nematodes after exposure to ketones (left) or ethers (right). The exposure concentrations are the MC<50values determined by locomotion speed after 1 h of exposure. Data were normalized to the average values of the control. Each dot represents the body lengths of a nematode after exposure (red) or without exposure (blue). *P< 0.05, unpairedt-testwith Holm–Sidak correction.\n\nhttps://doi.org/10.1371/journal.pone.0311460.g003\n\n(A–D) Locomotion speed after recovery in KOP4buffer solution after 2 h of exposure to organic solvent. The exposure concentrations of the organic solvents are the minimum concentrations that cause complete paralysis. Each data point represents the mean ± the standard error of the mean (SEM).\n\n(A–D) Locomotion speed after recovery in KOP4buffer solution after 2 h of exposure to organic solvent. The exposure concentrations of the organic solvents are the minimum concentrations that cause complete paralysis. Each data point represents the mean ± the standard error of the mean (SEM).\n\nhttps://doi.org/10.1371/journal.pone.0311460.g004\n\n(A) Working model of the toxicity of organic solvents. Organic solvents have general toxicities that induce similar effects on organisms, as well as specific toxic effects that are qualitatively different among chemicals. (B) Quantification of the amplitude of body bending during locomotion. The midpoint (black dot) and the average location of the central axis points (green dot) are shown. (C) Violin amplitude plots after soaking in a buffer containing organic solvents for 15 min. Each dot represents the mean amplitude during each track. *P< 0.05, one-way ANOVA with Dunnett’s test, compared with the no-exposure control. (D) Violin amplitude plots after soaking in a buffer with (red) or without (blue) 2% 2-butanone for the indicated time. *P< 0.05, unpairedt-testwith Holm–Sidak correction.\n\n(A) Working model of the toxicity of organic solvents. Organic solvents have general toxicities that induce similar effects on organisms, as well as specific toxic effects that are qualitatively different among chemicals. (B) Quantification of the amplitude of body bending during locomotion. The midpoint (black dot) and the average location of the central axis points (green dot) are shown. (C) Violin amplitude plots after soaking in a buffer containing organic solvents for 15 min. Each dot represents the mean amplitude during each track. *P< 0.05, one-way ANOVA with Dunnett’s test, compared with the no-exposure control. (D) Violin amplitude plots after soaking in a buffer with (red) or without (blue) 2% 2-butanone for the indicated time. *P< 0.05, unpairedt-testwith Holm–Sidak correction.\n\nhttps://doi.org/10.1371/journal.pone.0311460.g005\n\nViolin plots showing the amplitudes after soaking in a buffer containing organic solvents for 15 min intax-4(p678)nematodes. Each dot represents the mean amplitude during each track. *P< 0.05, one-way ANOVA with Dunnett’s test or Welch’s t-test (for Ethyl acetate), compared with the no-exposure control.\n\nViolin plots showing the amplitudes after soaking in a buffer containing organic solvents for 15 min intax-4(p678)nematodes. Each dot represents the mean amplitude during each track. *P< 0.05, one-way ANOVA with Dunnett’s test or Welch’s t-test (for Ethyl acetate), compared with the no-exposure control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.g006\n\n(A, B) Locomotion speed (A) and body length (B) after glucose exposure for 15, 30, 60, or 120 min. Data were normalized to the average value of the untreated control. (C) Relationship between the logarithm of MC<50(mM) and the logarithm of octanol–water partition coefficients (Kow). R2values were determined via simple linear regression analysis using values for organic solvents (blue dots). (D) Comparison of body length after glucose, 2-butanone, and tetrahydrofuran exposure. Each bar (A) or data point (B, D) represents the mean ± standard error of the mean (SEM). *P< 0.05, one-way ANOVA with Dunnett’s test, compared with the non-exposure control (B, D).\n\n(A, B) Locomotion speed (A) and body length (B) after glucose exposure for 15, 30, 60, or 120 min. Data were normalized to the average value of the untreated control. (C) Relationship between the logarithm of MC<50(mM) and the logarithm of octanol–water partition coefficients (Kow). R2values were determined via simple linear regression analysis using values for organic solvents (blue dots). (D) Comparison of body length after glucose, 2-butanone, and tetrahydrofuran exposure. Each bar (A) or data point (B, D) represents the mean ± standard error of the mean (SEM). *P< 0.05, one-way ANOVA with Dunnett’s test, compared with the non-exposure control (B, D).\n\nhttps://doi.org/10.1371/journal.pone.0311460.g007\n\nSalt chemotaxis after soaking in buffer with or without NaCl. Nematodes were exposed to organic solvents for 1 h during the soaking procedure (A, C, D) or for 1 min after the soaking procedure (B). The exposure concentrations of organic solvents are the maximum concentrations at which no significant defect was observed in locomotion speed after exposure for 1 h. The wild type (A, B), theodr-3(n2150)mutant (C), and thedaf-2c(pe2722)mutant (D) were used. The chemotaxis index represents the extent and direction of chemotaxis, where +1 and −1 indicate that all nematodes are attracted to or avoid NaCl, respectively. Each dot represents the chemotaxis index calculated for each trial (n = 6 assays). The bar and error bars indicate the mean ± the standard error of the mean (SEM). *P< 0.05; **P< 0.01, two-way ANOVA with Dunnett’s test, compared with the no-exposure control.\n\nSalt chemotaxis after soaking in buffer with or without NaCl. Nematodes were exposed to organic solvents for 1 h during the soaking procedure (A, C, D) or for 1 min after the soaking procedure (B). The exposure concentrations of organic solvents are the maximum concentrations at which no significant defect was observed in locomotion speed after exposure for 1 h. The wild type (A, B), theodr-3(n2150)mutant (C), and thedaf-2c(pe2722)mutant (D) were used. The chemotaxis index represents the extent and direction of chemotaxis, where +1 and −1 indicate that all nematodes are attracted to or avoid NaCl, respectively. Each dot represents the chemotaxis index calculated for each trial (n = 6 assays). The bar and error bars indicate the mean ± the standard error of the mean (SEM). *P< 0.05; **P< 0.01, two-way ANOVA with Dunnett’s test, compared with the no-exposure control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.g008\n\nTo assess the effects of exposure to organic solvents, the solvents were dissolved in KPO4buffer solution, andC. eleganswere soaked in buffer for 15, 30, 60, or 120 min (Materials and Methods). After exposure,C. eleganswere transferred to agar plates, and locomotion was quantified using a tracking system to evaluate the effects of organic solvents on behavior. The speed of freely moving nematodes on an agar plate was measured, and the behavioral states were determined: forward movement, reverse movement, and an immobile state were determined based on the speed and direction during locomotion (Fig 1A–1CandS1 Movie). First, the effects of exposure to 10 kinds of monohydric alcohols with carbon numbers ranging from C1 to C7 were tested. The speed during forward movement and the proportion of the immobile state were quantified after exposure to alcohols at several concentrations for 15–120 min (Figs 1DandS1). For example, after exposure to 0.5% benzyl alcohol, the proportions of the immobile state and locomotion speed substantially increased and decreased, respectively. The proportion of the immobile state increased to >50% after exposure for >1 h, and the speed decreased to <50% after exposure for >30 min (Fig 1DandS2 Movie). The minimum concentrations of each alcohol that increased the immobility state to >50% or decreased the speed of locomotion to <50% after chemical exposure were determined, and the concentration was defined as MC<50. The MC<50was established for the 10 monohydric alcohols (Figs 1DandS1). It has been reported that the inhibitory effects of alcohols on growth increase with increasing numbers of carbon atoms in the yeastSaccharomyces cerevisiae[8]. The MC<50forC. eleganslocomotion was compared with the carbon numbers of the alcohols to which they were exposed.The MC<50for immobility and locomotion speed exhibited a strong correlation with the carbon numbers of the alcohols (Fig 2Aand2B). These results suggest that the behavioral toxicity of monohydric alcohol can be determined by immobility or locomotion speed and is proportional to its carbon number inC. elegans.To quantify the behavioral toxicity of chemicals, locomotion speed was primarily used as an endpoint in subsequent analyses.\n\nNext, the behavioral toxicity of organic solvents with distinct functional groups (ketone, acetate ester, ether, cellosolve, and cellosolve acetate) was determined using locomotion speed as an endpoint (S2andS3 Figs). Similar to the adverse effects of alcohol, exposure to these organic solvents decreased locomotion speed on an agar plate (S2andS3 Figs). Furthermore, the toxicities of chemicals with ketone or cellosolve groups were proportional to the chemical’s carbon numbers (S4 Fig). However, compared to the correlation of the MC<50with the carbon number of the 10 kinds of alcohols (Fig 2B), the correlation for the 30 kinds of organic solvents was low, presumably because the distinct functional groups exert various effects on locomotion (Fig 2C). The MC<50was then compared with the lipid solubility of organic solvents, which is an important property for several biological processes, such as skin permeability and anesthetic effect. High correlation levels were observed when the MC<50was compared with the octanol–water partition coefficient, which reflects lipid solubility (Figs 2DandS5). Meanwhile, no significant correlation was observed between the MC<50and the chemical melting points, which affect skin permeability (S6 Fig). These results suggest that lipid solubility is an important property of organic solvent toxicity on locomotion inC. elegans.\n\nAccording to a published method with some modifications, the concentration of ethanol inC. elegansinternal tissues was estimated [28]. The estimated internal concentrations of ethanol after exposure to 500 mM ethanol in KPO4buffer solution for 10 or 50 min were 25.7 ± 3.03 mM or 80.1 ± 12.7 mM, respectively (Fig 2E). The internal ethanol concentration after 50 min exposure was comparable to that in the previous report, where ethanol was exposed to the nematodes on an agar plate (89.3 ± 8.8 mM) [28]. Meanwhile, the internal ethanol concentration after 10 min exposure was lower than that in the previous report (67.5 ± 7.1 mM) [28]. The difference between the exposure methods (exposure on a plate vs. in liquid) may reflect differences in the time course of ethanol penetration between the current and previous studies [28].\n\nLevamisole, an anthelmintic agent, causes paralysis inC. elegans. Levamisole acts as a potent agonist of acetylcholine receptors, and its exposure causes muscle contraction followed by muscle relaxation [30]. I confirmed that levamisole reduced locomotion speed and eventually ceased movement at 100 µM after 1 h of exposure (S7AandS7B Fig). Impaired locomotion was associated with body shrinkage (S7CandS7D Fig, middle). Most nematodes were completely paralyzed by levamisole exposure at 1,000 µM, and body relaxation was observed after 1 h of exposure (S7A–S7D Fig, right). Similar to these observations, exposure to a ketone, 2-butanone, or an ether, tetrahydrofuran, gradually decreased body length at effective concentrations for impaired locomotion, followed by relaxation at concentrations that led to complete paralysis (Figs 3AandS2A,S2C,S8). The other C3–C6 ketones and C4 ethers, except 2-hexanone, exhibited similar effects (Fig 3B). In contrast, most alcohol, acetate ester, cellosolve, and cellosolve acetate chemicals had no significant effect on body shrinkage, except 2-hexanol and methyl acetate (S9 Fig).\n\nTo assess whether 2-butanone and tetrahydrofuran affect muscle function via levamisole-sensitive acetylcholine receptors, the effects of exposure to these chemicals were examined in a loss-of-function mutant of UNC-29, an essential subunit of levamisole-sensitive acetylcholine receptors expressed in the body-wall muscle [31]. It was first confirmed that the loss-of-functionunc-29(e193)mutant was resistant to levamisole exposure, which is consistent with a previous report that the acetylcholine receptors containing the UNC-29 subunit are the primary target of levamisole in the muscle (S10A Fig). In contrast, exposure to 2-butanone or tetrahydrofuran caused substantial locomotion impairment in theunc-29mutant (S10BandS10C Fig). Theunc-29mutant was sensitive to organic solvents, including 2-butanone and tetrahydrofuran, when immobility and locomotion speed were used as endpoints (S11AandS11B Fig). Exposure to acetone, 2-butanone, or tetrahydrofuran also caused a significant reduction in body size in theunc-29mutant (S11C Fig). These results suggest that low-molecular-weight ketones and ethers reduce locomotion speed and body size in a UNC-29 independent manner.\n\nTo examine whether locomotion impairment after exposure to organic solvent is reversible, the locomotion of nematodes was assessed after recovery in buffer solution without organic solvent. Nematodes were exposed to organic solvents for 2 h at concentrations that caused complete paralysis and were then soaked in KPO4buffer solution without the solvents. Impaired locomotion was recovered within 2 h of soaking in buffer after paralysis caused by exposure to most organic solvents, except benzyl alcohol, 2-pentanone, 2-hexanone, and ethyl acetate (Fig 4). Complete paralysis after exposure to benzyl alcohol, 2-pentanone, 2-hexanone, and ethyl acetate for shorter periods (15 or 30 min) was recovered by soaking in a buffer without the solvents (S12 Fig). These results suggest that nematodes are paralyzed after short-term exposure to organic solvents, which is reversible, whereas long-term exposure to some organic solvents can cause irreversible locomotion impairment. These phenotypes are reminiscent of those observed after exposure to human anesthetics inC. elegans[15].\n\nIn addition to the general adverse effects of organic solvents on locomotion, is there a specific effect that is qualitatively different based on the solvent’s chemical characteristics, such as its functional group (Fig 5A)? It has been reported that ethanol exposure decreases the amplitude of body bending and speed during locomotion inC. elegans[20]; therefore, the amplitude of body bending during locomotion was quantified (Fig 5B). As reported for ethanol exposure, exposure to alcohols, including methanol, isopropanol, and 2-butanol, for 15 min decreased the amplitude of body bends during locomotion at concentrations lower than MC<50(Figs 5CandS13AandS3 Movie). Similar effects on body bends were observed after exposure to cellosolves, including methyl, ethyl, and isopropyl cellosolve, as well as cellosolve acetate; these organic solvents decreased the amplitude of body bends (S13BandS13E Fig).\n\nInterestingly, when nematodes were exposed to ketones and acetate esters, the effects on body bending were opposite to those observed with alcohols and cellosolve. Exposure to ketones, including acetone, 2-butanone, and 2-pentanone, and acetate esters, including methyl acetate, ethyl acetate, and isopropyl acetate, for 15 min significantly increased the amplitude of body bends during locomotion at concentrations lower than MC<50(Figs 5CandS13CandS4 Movie). The effects of ether on amplitude were intricate: 1,4-dioxane decreased the amplitude of body bends; diethyl ether did not affect body bends; and tetrahydrofuran decreased and increased the amplitude of body bends at concentrations of 0.5% and 2%, respectively (Figs 5CandS13DandS5 Movie). These results suggest that exposure to organic solvents affects posture during locomotion differently at concentrations lower than those that cause cessation of motility.\n\nC. elegansreceive external volatile chemicals, such as alcohols, ketones, and ethers, through their chemosensory neurons and respond to these chemicals with attraction or repulsion behaviors, known as chemotaxis [32]. The sensory transduction of chemosensory cues is primarily mediated by ion channel effectors, TAX-4/TAX-2, a cyclic nucleotide-dependent cation channel complex, and OSM-9/OCR-2, a transient receptor potential channel superfamily protein complex [24,33,34]. To explore the extent to which chemosensory input is required for behavioral changes after prolonged exposure to organic solvents, locomotion speed was examined intax-4andosm-9mutants after exposure to several organic solvents (Figs 2FandS14). Both thetax-4andosm-9mutants showed increased MC<50values for isopropanol, that is, they are resistant to a decrease in locomotion speed after isopropanol exposure. Only theosm-9mutant exhibited resistance to a decrease in locomotion speed after exposure to acetone and tetrahydrofuran. In contrast, thetax-4mutant showed an enhanced decrease in locomotion speed after exposure to methyl acetate and ethyl acetate. Both mutant strains showed a decrease in locomotion speed after exposure to 2-butanone, comparable to that of the wild type. These results suggest that the chemosensory input of organic solvents may influence locomotion speed after prolonged exposure, with the extent and direction of the effects varying depending on the solvent.\n\nNext, changes in the amplitude of body bending after exposure to organic solvent were examined intax-4andosm-9mutants. Theosm-9mutant showed no substantial difference in increased amplitude after 15 min of exposure to 2-butanone, methyl acetate, ethyl acetate, and tetrahydrofuran, and a decrease in amplitude after isopropanol exposure compared with the wild type (Figs 5CandS15). Meanwhile, thetax-4mutant showed defects in increased amplitude after 15 min of exposure to acetone, 2-butanone, methyl acetate, ethyl acetate, or tetrahydrofuran, but showed a normal decrease in amplitude after isopropanol exposure (Figs 5Cand6). These results suggest that TAX-4-mediated sensory input is required for the increased amplitude of body bending after exposure to organic solvents such as ketones and acetate esters. It has been shown thatC. elegansrespond to decreased 2-butanone concentrations to promote 2-butanone attraction, where the AWC chemosensory neurons sense rapid changes in external 2-butanone concentrations [35]. To explore whether the increased amplitude of body bending after 2-butanone exposure is induced by rapid changes in 2-butanone concentrations, the amplitude of body bending was examined after 1, 5, or 10 min of exposure to 2% 2-butanone in the wild type. An increased amplitude of body bending was not observed after 1- or 5-min exposure to 2-butanone; however, 10-min exposure to 2-butanone significantly increased the amplitude (Fig 5D). This suggests that prolonged exposure (>5 min) is required for long-lasting increase in the bending amplitude.\n\nC. eleganslocomotion is affected by dehydration in hyperosmotic environments. Previous reports have shown that high concentrations of less toxic water-soluble chemicals, such as salt and sugar, exposed toC. elegansresult in changes in phenotypes, such as motility and body length, which are used to study the effects of external osmotic pressure [36,37]. In this study, to examine the effects of osmotic pressure on locomotion, NaCl or glucose was dissolved in ~15 mOsm KPO4buffer (also used to dissolve organic solvents in this study), and locomotion speed and body length were quantified after exposure to the buffer solution. Exposure to a >515 mOsm solution containing >250 mM NaCl for 15 min decreased locomotion speed by >50%, and a subsequent 15-min exposure (for a total of 30 min exposure) further decreased locomotion speed (S16A Fig). The decrease in locomotion speed is not primarily due to the chemosensory response, as similar changes were observed in adyf-11mutant in which the chemosensory response to water-soluble chemicals is abolished [38] (S16B Fig). As previously reported [36], decreased motility was recovered after subsequent exposure to the same solution for 30 or 90 min (total exposure of 60 or 120 min) (S16 Fig).\n\nExposure to >515 mOsm solution containing >499 mM (9%) glucose for 15 min also decreased locomotion speed by >50%, and the decreased motility was recovered after subsequent 105 min of exposure (total of 120 min) in the same solution (Figs 7AandS17A). The MC<50(mM) value of glucose was 499 mM (9%) after exposure for 15 min. The MC<50(mM) values for organic solvents with high hydrophilicity, such as methanol, ethanol, acetone, and 1,4-dioxane, were higher than that of glucose (Fig 7C, left): 978 mM (4%) methanol, 685 mM (4%) ethanol, 675 mM (5%) acetone, and 702 mM (6%) 1,4-dioxane, when exposed for 15 min. Organic solvents with lower hydrophilicity were more toxic and showed lower MC<50(mM) values than glucose (Fig 7C, left). For example, the MC<50(mM) value after 15 min of benzyl alcohol exposure was 96 mM (1%). As confirmed by the MC<50values expressed as volume percent (Figs 2DandS5), the MC<50(mM) values correlated with the octanol–water partition coefficient for 30 organic solvents (Fig 7C). Unlike NaCl and glucose, decreased motility after 15 min of exposure to each of the 28 organic solvents was not recovered by subsequent 105 min of exposure (total of 120 min) in the same solution, implying that organic solvents cause adverse effects on motility through mechanisms partly different from those caused by hyperosmolarity from NaCl or glucose exposure (Figs 7Cright andS17). The two exceptions were exposure to methanol and methyl cellosolve, in which reduced motility after 15 min of exposure was significantly recovered after 105 min of subsequent exposure in the same buffer (S17BandS17F Fig). This suggests that reduced motility after exposure to organic solvents with high hydrophilicity, such as methanol and methyl cellosolve, may occur, at least in part due to dehydration from hyperosmotic pressure.\n\nAs previously reported [37], body length significantly decreases in hyperosmotic environments. After exposure to >415 mOsm solution containing >200 mM NaCl for 15 min, body length significantly decreased, but subsequent exposure for 105 min (total of 120 min) in the same buffer recovered body length (S16 Fig). Similarly, exposure to >460 mOsm solution containing >444 mM (8%) glucose for 15 min resulted in significant body shrinkage, but subsequent exposure recovered body length (Fig 7B). Meanwhile, organic solvent-induced shrinkage occurred at lower concentrations than that caused by glucose exposure, and body shrinkage was not recovered by subsequent exposure. Exposure to 111 mM (1%) 2-butanone or 123 mM (1%) tetrahydrofuran for 15 or 120 min induced significant body shrinkage (Fig 7D). These data suggest that organic solvents, such as 2-butanone and tetrahydrofuran, cause body shrinkage through mechanisms partly different from those of dehydration due to high osmotic pressure.\n\nTo explore whether organic solvent exposure affects sensory processing inC. elegans, salt chemotaxis learning, a paradigm of behavioral plasticity, was examined [25].C. elegansrespond to various environmental chemicals, including NaCl, and exhibit behavioral plasticity appropriate for the given situation [39]. Nematodes are attracted toward NaCl, whereas after prolonged exposure to high concentrations of NaCl under starvation conditions, they avoid NaCl. This behavioral plasticity, termed “salt chemotaxis learning,” is interpreted as a form of learned behavior in which nematodes memorize NaCl concentrations in their environments experienced during starvation and avoid environments without food, using the NaCl concentration as a repulsive cue [40]. Organic solvents were added to a buffer for conditioning, in which the nematodes were exposed to the organic solvents in the presence or absence of NaCl for 1 h to evaluate the effects of the organic solvents on NaCl avoidance or attraction, respectively (S18 Fig). Organic solvents were added at concentrations that had no significant effect on locomotion speed on an agar plate (S1–S3 Figs). The nematodes were attracted to NaCl after exposure to organic solvents in the absence of NaCl, except for a significant defect observed when exposed to ethyl acetate (Fig 8A). Therefore, the NaCl sensation was not largely affected by exposure to organic solvents at doses that did not cause any significant defects in locomotion speed.\n\nMeanwhile, significant defects were observed in NaCl avoidance after exposure in the presence of NaCl when exposed to any of the organic solvents tested, including alcohol, ketone, acetate ester, ether, and cellosolve, except for methyl cellosolve (Fig 8A). These results suggest that these organic solvents cause defects in salt chemotaxis learning at concentrations lower than those that affect locomotion speed. Substantial defects in salt chemotaxis learning were not observed with exposure to any of the organic solvents for 1 min after starvation conditioning in the presence of NaCl, suggesting that prolonged exposure to organic solvents during conditioning is required for the establishment of suppressive effects on salt chemotaxis learning (Fig 8B).\n\nIn wild environments,C. elegansare commonly found in microbe-rich, rotting plant materials, where nematodes can be exposed to various organic compounds produced by microbes [41]. Sensory inputs from organic compounds may influence diverse behaviors, including salt chemotaxis learning. To test the extent to which sensory inputs from organic solvents affect salt chemotaxis learning, mutants of ODR-3, an alpha-subunit of the Gi/Go-like G protein expressed in chemosensory neurons, were examined.odr-3mutants are highly defective in most responses mediated by the AWA, AWB, AWC, and ASH neurons, which are the major chemosensory neurons responsible for chemotaxis to volatile compounds [26]. As suggested in previous reports [42], theodr-3mutant was defective in NaCl avoidance after NaCl conditioning under starvation conditions (Fig 8C). Importantly, exposure to the organic solvents 2-butanol, 2-butanone, methyl acetate, and tetrahydrofuran caused significant defects in salt chemotaxis learning in theodr-3mutant, suggesting that sensory input mediated by ODR-3 is not required for the suppression of salt chemotaxis learning by organic solvents.\n\nInsulin signaling plays a pivotal role in the regulation of salt chemotaxis learning. DAF-2c encodes an insulin receptor isoform localized in the neuronal axon, regulates the neuronal plasticity of the NaCl-sensing sensory neuron ASER, and adaf-2cmutant exhibits substantial defects in salt chemotaxis learning [43] (Fig 8D). Organic solvent exposure promoted the defect in NaCl avoidance or caused defects in attraction in nematodes with adaf-2cmutant background, suggesting that organic solvent exposure affects sensory processing, at least in part, independent of DAF-2c signaling in salt chemotaxis learning (Fig 8D).\n\nTo reduce the health hazards of industrial chemicals, which are continuously increasing, it is important to fundamentally understand their toxic effects on organisms. Due to its fast lifecycle and proliferative capacity,C. elegansare useful for high-throughput screening, including toxic chemical screening [10,11,44]. In this study, a high-throughput method was developed to assess the acute toxicity of organic solvents. The nematodes were exposed to chemicals by soaking in a buffer and were transferred onto an agar plate to capture a 1-min movie. The behaviors of the nematodes were then analyzed using the commercial tracking software, WormLab. This method is simple and does not require special skills. The behavioral toxicity of 30 organic solvents commonly used in industries was comprehensively analyzed using this method. Exposure to any of the organic solvents gradually decreased movement and locomotion was eventually halted. The paralyzed nematodes were recovered by soaking in a buffer without organic solvents, and locomotion impairments were reversible. When the locomotion speed was used as an endpoint, the extent of behavioral toxicities was proportional to the chemical’s lipid solubility. This relationship is reminiscent of the Meyer–Overton relationship in humans, in which there is a positive correlation between the anesthetic effects and the lipid solubility of inhalation anesthetics, such as halothane and isoflurane [7]. It has been reported that there is a positive relationship between volatile anesthetics and impaired locomotion inC. elegans[15]. Therefore, this study confirmed the feasibility of assessing the general anesthetic effects of industrial chemicals usingC. elegans.\n\nExposure to organic solvents, such as short-chain ketones and ethers, caused body shrinkage followed by relaxation, similar to the effects of levamisole, an anthelmintic agent. Levamisole is a well-known potent agonist of acetylcholine receptors, including UNC-29, inC. elegans[30]. As previously reported, theunc-29mutant is resistant to locomotion impairment caused by exposure to levamisole. Conversely, theunc-29mutant was sensitive to organic solvents, including alcohol, ketone, ether, and acetate esters, and required lower concentrations of these organic solvents to induce locomotion impairment than the wild type. The finding that theunc-29mutant exhibited body shrinkage after exposure to short-chain ketones or ethers suggests that an unknown molecule(s), other than UNC-29, is a major effector of body shrinkage caused by organic solvents. It has been shown that treatment with ethanol on an agar plate caused body shrinkage via acetylcholine signaling. UNC-63, a subset of the nicotinic acetylcholine receptor, but not UNC-29, is required for ethanol-induced body shrinkage [45]. Further investigation is required to reveal the molecular mechanisms underlying ketone- or ether-induced body shrinkage.\n\nIn addition to the general effect of organic solvents on behavior, it was found that organic solvents have specific effects on behavioral patterns, producing different qualitative effects on the amplitude during undulatory locomotion based on the differences in the chemical’s functional groups. Alcohols and cellosolves, which have hydroxyl groups, and ketones and acetate esters, which have ketone groups, decrease and increase the body bend amplitude during locomotion, respectively (Fig 9). No significant increase in body bending amplitude was observed in thetax-4mutant. TAX-4, a cyclic nucleotide-gated channel, plays a pivotal role in sensory transduction in chemosensory neurons, including the AWC olfactory neuron, which senses a variety of volatile chemicals, such as 2-butanone [24].In vivocalcium imaging experiments have shown that a decrease in external odorant concentration activates AWC within seconds [35]. AWC senses constantly changing odor concentrations and produces probabilistic responses, such as changes in turning frequency and turning angle during chemotaxis behavior [35,46]. Meanwhile, more than 5 min of exposure to organic solvents was required to increase the amplitude of body bending, which lasted for at least 1 min. These findings are consistent with the notion that prolonged sensory input from olfactory neurons, such as AWC, induces a long-lasting increase in the amplitude of body bending in a manner different from that in the regulation of chemotaxis. Alternatively, I cannot exclude the possibility that TAX-4-mediated signaling is prerequisite for amplitude alteration after prolonged exposure to organic solvents. Further studies are required to elucidate the molecular and cellular mechanisms of the different qualitative effects of organic solvents on behavioral patterns and their possible conservation across species.\n\nOrganic solvents affect the amplitudes of body bending during locomotion in opposite ways depending on the chemical’s functional groups. Exposure to short-chain alcohols and cellosolve, which have a hydroxyl group, decreases the amplitude of body bending (top), whereas exposure to short-chain ketones and acetate esters, which have a ketone group, increases the amplitude of body bending (bottom).\n\nOrganic solvents affect the amplitudes of body bending during locomotion in opposite ways depending on the chemical’s functional groups. Exposure to short-chain alcohols and cellosolve, which have a hydroxyl group, decreases the amplitude of body bending (top), whereas exposure to short-chain ketones and acetate esters, which have a ketone group, increases the amplitude of body bending (bottom).\n\nhttps://doi.org/10.1371/journal.pone.0311460.g009\n\nI examined the effects of exposure to NaCl and glucose, which are less toxic, water-soluble chemicals, and compared these with the effects of exposure to organic solvents. Fifteen minutes of exposure to >515 mOsm solutions containing NaCl or glucose caused a marked decrease in locomotion. The locomotion speed reduction was recovered after a subsequent 105-min exposure (total of 120 min of exposure) in the same solution. The MC<50(mM) values of organic solvents with high hydrophilicity, such as methanol, ethanol, and acetone, were higher than those of glucose. These organic solvents are amphiphilic and can penetrate the cell membrane via passive transport. The penetration of ethanol into theC. elegansbody was experimentally confirmed, and ethanol was shown to act on the neuronal BK potassium channel, followed by inhibition of neuronal activity [20].In contrast, organic solvents with higher lipid solubility were more toxic, and prolonged exposure to these chemicals did not recover the decreased motility. For example, the MC<50(mM) value of benzyl alcohol is more than 10 times smaller than those of ethanol, NaCl, and glucose. Although the mechanism of action of organic solvents with high lipid solubility is unclear, it is possible that they bind proteins or lipids within theC. elegansbody and exert adverse effects on motility. Methanol and methyl cellosolve have lower lipid solubility than ethanol, and prolonged exposure to these chemicals recovers slow motility after short-term exposure, as observed after exposure to NaCl or glucose. Therefore, it is possible that exposure to methanol, methyl cellosolve, and other organic solvents causes adverse effects on motility due to dehydration from hyperosmotic pressure to some extent.\n\nOrganic solvents cause defects in learned behavior termed “salt chemotaxis learning” at concentrations lower than those that affect locomotion speed. Nematodes respond to water-soluble chemicals, including NaCl, mainly by chemosensory neurons called ASE. ASE neurons extend neuronal processes to the nose tip of the head, and the ciliated ends are exposed to the outside environment through a sensory organ called the amphid [33]. There are molecular mechanisms that regulate sensory transduction and sensory processing in the ciliated ends of ASE [33]. Organic solvents may directly affect the mechanisms for sensory transduction and processing in the ASE cilia, which are directly exposed to the environment. It has been reported that the sensory cilia are targets of 3-octanone, a toxin produced by the basidiomycete oyster mushroomPleurotus ostreatus.Nematodes, includingC. elegansare paralyzed when in contact with the fungal hyphae ofPleurotus ostreatus, which contains 3-octanone [47]. 3-octanone disrupts the cell membrane integrity of multipleC. eleganstissues, resulting in cell death caused by extracellular calcium influx into the cytosol and mitochondria. Several mutants lacking cilia are resistant to paralysis and cytotoxicity caused by contact withPleurotus ostreatusor 3-octanone, and cilia are the primary target of 3-octanone [47,48]. In the present study, I demonstrated that low-dose organic solvents cause defects in salt chemotaxis learning, whereas they did not cause gross abnormalities in NaCl sensation. Therefore, organic solvents may have suppressive effects on the mechanisms of neuronal plasticity after NaCl sensation. It is important to understand the cellular and molecular mechanisms underlying the effects of organic solvent exposure in future studies to elucidate the mechanisms of responses to toxic chemicals in learned behavior.\n\nIt has been reported that anesthetic exposure affects several behaviors, such as male mating, egg laying, mechanosensation, and chemotaxis, inC. elegans[49]. In general, distinct mechanisms are used to exert different types of behaviors. Thus, observation of multiple behaviors provides an opportunity to understand multiple aspects of toxic effects on the nervous system. In addition to innate behaviors, several paradigms of learned behavior have been developed inC. elegans. For example,C. elegansmemorize external environmental cues such as chemicals and temperature during feeding and show learned attractive responses to these cues, which last for several hours [40,50,51]. Nematodes also form long-term memory that lasts for >24 h through repeated training of associations between chemical cues and feeding experience [52]. In future studies, it will be interesting to investigate the effects of toxicants on these complex behaviors and the underlying molecular and cellular mechanisms. These studies can then be applied to the toxicity assessment of higher organisms with complex nervous systems. As a limitation of research usingC. elegans, the lifespan of wild-typeC. elegansis 2–3 weeks under standard laboratory conditions, making it difficult to study the effects of chemical exposure over months or years in one generation.\n\nThe high-throughput toxicity assay developed in this study can also be used to test the toxicity of environmental pollutants, such as volatile organic compounds (VOCs), heavy metals, and nanoparticles. Toluene, a VOC, has adverse effects on locomotion differently than alcohol, and the underlying molecular mechanism is postulated to be different from that of alcohol inC. elegans[53,54]. The toxic effects of heavy metals and metal nanoparticles on the nervous and reproductive systems have been studied inC. elegans[55]. The effects of environmental chemicals, such as bisphenol A and nanoplastics, which are widely present in the environment, on nematodes are also being studied [44,56,57]. Hydrocarbons, such as toluene, are insoluble in water, making it difficult to expose nematodes to these chemicals in a buffer solution as reported in this study. By using methods for exposing toxicants from air [20,54], high-throughput assessments of chemical toxicities can be performed more broadly in the future.\n\nImmobility (A) and locomotion speed (B) after exposure to alcohols for 15, 30, 60, or 120 min. Each data point represents the mean ± the standard error of the mean (SEM). Locomotion speed was normalized to the average value for untreated control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s001\n\n(TIF)\n\nLocomotion speed after exposure to ketones (A), acetate esters (B), or ethers (C) for 15, 30, 60, or 120 min. Each data point represents the mean ± the standard error of the mean (SEM). Locomotion speed was normalized to the average value for untreated control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s002\n\n(TIF)\n\nLocomotion speed after exposure to cellosolves or a cellosolve acetate for 15, 30, 60, or 120 min. Each data point represents the mean ± the standard error of the mean (SEM). Locomotion speed was normalized to the average value for untreated control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s003\n\n(TIF)\n\nRelationship between the behavioral toxicity (MC<50) after 1 h of exposure to ketones (A) or cellosolves (B) and the carbon number of the chemicals. Locomotion speed is used as an endpoint. R2values were determined based on simple linear regression analysis.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s004\n\n(TIF)\n\nRelationship between the MC<50after exposure to organic solvents for 15, 30, or 120 min and the octanol–water partition coefficient (log Kow), which reflects the lipid solubility of organic solvents. Locomotion speed is used as an endpoint. R2values were determined based on simple linear regression analysis.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s005\n\n(TIF)\n\nRelationship between the MC<50after exposure to organic solvents for 1 h and the organic solvent’s melting point. Locomotion speed is used as an endpoint.Pand R2values are determined based on simple linear regression analysis, and no significant correlation is observed (P= 0.1913).\n\nhttps://doi.org/10.1371/journal.pone.0311460.s006\n\n(TIF)\n\n(A–C) Immobility (A), locomotion speed (B), and body length (C) after exposure to levamisole for 15, 30, 60, or 120 min. Each data point represents the mean ± the standard error of the mean (SEM). (D) Representative images of nematodes on agar plates after exposure to different concentrations of levamisole for 120 min.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s007\n\n(TIF)\n\nRepresentative images of nematodes on agar plates after exposure to different concentrations of 2-butanone (A) or tetrahydrofuran (B) for 120 min.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s008\n\n(TIF)\n\nThe mean values ± the standard error of the mean (SEM) of the body lengths of nematodes after 1 h exposure to organic solvents (red) or without exposure (blue). The exposure concentrations are the MC<50values, which were determined by the locomotion speed after 1 h of exposure. Data were normalized to the average values of the no-exposure control. *P< 0.05, unpairedt-test with Holm–Sidak correction.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s009\n\n(TIF)\n\nImmobility (left column) and locomotion speed (right column) ofunc-29(e193)after exposure to levamisole (A), 2-butanone (B), or tetrahydrofuran (C) for 15, 30, 60, or 120 min. Each data point represents the mean ± the standard error of the mean (SEM). Locomotion speed was normalized to the average value for untreated control (B, C).\n\nhttps://doi.org/10.1371/journal.pone.0311460.s010\n\n(TIF)\n\n(A, B) Relationship between the MC<50after organic solvent exposure for 1 h and the octanol–water partition coefficient (log Kow), which reflects the lipid solubility of an organic solvent. Immobility (A) and locomotion speed (B) are used as the endpoints in the wild type (blue) andunc-29(e193)(red). (C) Violin plots of the body lengths ofunc-29(e193)mutants after exposure to organic solvents. The exposure concentrations are same as those used for the analysis in the wild type (Fig 3B). Data were normalized to the average values of the no-exposure control. Each dot represents the body length of a nematode after exposure (red) or without exposure (blue). *P< 0.05, unpaired t-test with Holm–Sidak correction.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s011\n\n(TIF)\n\nLocomotion speed after recovery in a buffer solution after exposure to an organic solvent for 1 h (A), 30 min (B), or 15 min (C) are shown. The exposure concentrations of the organic solvents are the minimum concentrations that cause complete paralysis. Each data point represents the mean ± the standard error of the mean (SEM).\n\nhttps://doi.org/10.1371/journal.pone.0311460.s012\n\n(TIF)\n\nViolin plots of the amplitudes after soaking in a buffer containing organic solvents for 15 min. Each dot represents the mean amplitude during each track. *P< 0.05, one-way ANOVA with Dunnett test, compared with the no-exposure control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s013\n\n(TIF)\n\nLocomotion speed oftax-4(p678)(A, red bars),osm-9(ky10)(B, red bars), and the wild-type (blue bars) nematodes after exposure to organic solvents for 1 h. Each bar represents the mean ± the standard error of the mean. *P< 0.05, one-way ANOVA with Dunnett test, compared with the no-exposure control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s014\n\n(TIF)\n\nViolin plots of the amplitudes after soaking in a buffer containing organic solvents for 15 min inosm-9(ky10)nematodes. Each dot represents the mean amplitude during each track. *P< 0.05, one-way ANOVA with Dunnett test or Welch’s t-test (for Ethyl acetate), compared with the no-exposure control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s015\n\n(TIF)\n\nLocomotion speed (left) and body length (right) of the wild type (A) and thedyf-11(pe554)mutant (B) after exposure to sodium chloride for 15, 30, 60, or 120 min. Each bar or data point represents the mean ± the standard error of the mean. *P< 0.05, one-way ANOVA with Dunnett test, compared with the no-exposure control.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s016\n\n(TIF)\n\nLocomotion speed after exposure to indicated chemicals for 15 or 120 min. Each bar represents the mean ± the standard error of the mean. *P< 0.05, unpaired t-test with Holm–Sidak correction. Locomotion speed was normalized to the average value for untreated nematodes.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s017\n\n(TIF)\n\n(A) Procedure for the salt chemotaxis learning assay. (B) Format for the salt chemotaxis test and calculation of the chemotaxis index. (C) Size of a chemotaxis test plate.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s018\n\n(TIF)\n\n(A) The body length of a nematode was determined as the length from head to tail along the central axis (blue line). The body width was determined as the average length of cross-sections (red lines) over the entire body. (B) The average body length (left, 1049 µm) and the average body width (right, 92.30 µm) were determined based on body lengths and widths of 650 nematodes, calculated using Wormlab.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s019\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0311460.s020\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0311460.s021\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0311460.s022\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0311460.s023\n\n(XLSX)\n\nNematodes were exposed to a buffer without organic solvent for 1 h before recording the movement.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s024\n\n(MP4)\n\nNematodes were exposed to buffer, including 0.5% benzyl alcohol, for 1 h before recording the movement.\n\nhttps://doi.org/10.1371/journal.pone.0311460.s025\n\n(MP4)\n\nhttps://doi.org/10.1371/journal.pone.0311460.s026\n\n(MP4)\n\nhttps://doi.org/10.1371/journal.pone.0311460.s027\n\n(MP4)\n\nhttps://doi.org/10.1371/journal.pone.0311460.s028\n\n(MP4)\n\nI would like to thank Drs. Tatsushi Toyooka, Rui-Sheng Wang, Yukie Yanagiba, and Makiko Nakano at the National Institute of Occupational Safety and Health, Japan, for their helpful discussions and support. TheC. elegansandE. colistrains were provided by Dr. Yuichi Iino’s lab and the CGC, which is funded by NIH Office of Research Infrastructure Programs (P40 OD010440).",
    "category": "materials_science"
  },
  {
    "title": "Vigna radiataextracts in pumpkin and soya bean oil: A novel therapeutic approach for Alzheimer’s disease",
    "authors": "Haroon Amin, Shazia Anwer Bukhari, Zunera Chauhdary, Naheed Akhter, Maria Saleem, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321183",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321183",
    "content": "Vigna radiatealso known as mung beans, contains various bioactive compounds like polyphenols, flavonoids, and saponins. V. radiatatherapeutic potential is enhanced by preparation of its extract in Pumpkin oil and soya bean oil by enrichment of bioactive compounds holding antioxidant, anti-inflammatory, and neuro-protective properties. The research study was aimed was to explore the healing endeavors ofV. radiatepumpkin and soya bean oil extract in rectification of neuro-motor dysfunction and mental health decline in Alzheimer’s disease (AD) rat model. After preliminary physico-phytochemical characterization and GC-MS analysis, AD model was established by administration of oral D-galactose and aluminum chloride 150 mg/kg each for 42 days daily.V. radiateextract in pumpkin and soya bean oil at doses 250 and 500 mg/kg was administered and rivastigmine (3 milligrams per kilogram) to treatment animals. To determine the cognitive decline and neuro-coordination dysfunctions behavioral tests were performed along with biochemical, neurochemical and histopathological analysis. ELISA and real time polymerase chain reaction were carried out to estimate the expression of tumor necrosis factor-α, Interleukine-6 and mRNA expression of neurodegenerative biomarkers. Gas chromatography Mass Spectrometry findings revealed the existence of favorable amount of neuro-defensive bioactive compounds in both oil extracts.V. radiatepumpkin and soya bean oil extract dose proportionally alleviated the behavioral dysfunctions, modulated the first line antioxidant enzymes and neurotransmitters s’ level with anticholinesterase pursuits. The mRNA expression of AChE, IL-1β, TNF-α, IL-1α and β secretase were downregulated by these extracts treatment.V. radiateoil extracts also modulated the neuro-inflammatory protein expression and histopathological hallmarks in AD model animals. Therefore, it is purposed thatV. radiateenriched extract in pumpkin and soya bean oil could be used to treat AD like memory dysfunction and motor symptoms.\n\nCitation:Amin H, Bukhari SA, Chauhdary Z, Akhter N, Saleem M (2025)Vigna radiataextracts in pumpkin and soya bean oil: A novel therapeutic approach for Alzheimer’s disease. PLoS ONE 20(4):\n           e0321183.\n        \n        https://doi.org/10.1371/journal.pone.0321183\n\nEditor:Vara Prasad Saka, Dr. Anjali Chatterji Regional Research Institute for Homeopathy, INDIA\n\nReceived:October 22, 2024;Accepted:February 27, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Amin et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAlzheimer’s disease (AD) represents a subtle neurodegenerative condition and emerges as a prominent obstacle in contemporary public health during the 21stcentury. It stands as the primary contributor to dementia [1]. As the World’s population gets older, the number of people affected by this serious condition is going up. It’s expected to impact around 106.8 billion individuals by 2050. This emphasizes the crucial need to understand the detailed aspects of the condition and explore new and creative ways to research and intervene [2].\n\nAD is identified by the genesis of neuritic plaques outside brain cells and accumulation of hyperphosphorylated tau proteins inside them, causing the death of neurons and loss of connections between them. This progression results in gradual cognitive decline [3]. The development of AD, a neurodegenerative condition, is associated with the presence of neurofibrillary tangles (NFTs) containing overly phosphorylated tau protein within cells and the accumulation of amyloid ß-plaques outside cells in specific regions of the human brain, particularly the cortical and limbic areas [3].\n\nThe proper functioning of most proteins relies on them adopting specific three-dimensional structures. Irregular protein folding has been connected to a growing number of health issues [4]. Some diseases result from mutations causing harmful changes in protein function. In these cases, certain proteins that are not stable can clump together, forming deposits of insoluble and toxic fibrillar proteins inside or outside cells [5]. Presently, approximately 30 human diseases are associated with protein misfolding and the formation of amyloid structures [6]. These diseases encompass neurodegenerative conditions like AD and Parkinson’s disease (PD) [4].\n\nMarked by a gradual deterioration in cognitive abilities, AD deprives individuals of their uniqueness, skills, societal contributions, and cherished memories. This imposes a substantial emotional and economic burden on families and societies, estimated to be approximately $321 billion in the year 2022 [7].\n\nMung beans (Vigna radiataL.) have several polyphenols that can protect the brain, making them a potentially functional diet for preventing AD. A total of nineteen significant phenolic compounds were identified in green gram, comprising ten phenolic acids and nine flavonoids. By evaluating their amounts and optimal dosage in experiments using rodent models of AD, it is suggested that vitexin, isovitexin, sinapic acid, and ferulic acid may be the key potent compounds responsible for the neuroprotective effects of mung beans [8]. These plants have the potential to be an effective treatment for AD.\n\nGreen chemistry and green extraction principles aim to minimize environmental impact, reduce waste, and promote sustainability in chemical processes. By using vegetable oils for extraction, we align with these principles and contribute to a more environment friendly and sustainable future [9]. Therefore, the objective of the study was to prepare enrichVigna radiateL. extract by using pumpkin and soya bean oil and to assess the neuro-protective effects ofVigna radiataL in an animal model of AD.\n\nEthyl Alcohol, CHCl3, Folin – Ciocalteau reagent (FCR), gallic acid (C6H2(OH)3CO2H), piperine, bovine serum albumin (BSA), NaOH, aluminum nitrite (Al(NO2)3), quercetin, aluminum chloride (AlCl3), isopropanol, D-galactose, H2O for injection, and methyl Alcohol of laboratory grades were bought from sigmaAldrich (USA), rivastigmine from Novartis Pharma (Pak) Ltd; triazol (InvitrogenTM), cDNA kit (Thermo Scientific), cyber green (SYBR®Green master mix of Bio-Rad), primers (Thermo FisherScientific – US) were bought.\n\nAnimals of either sex, mice (25-30 g) for oral acute toxicity study, rats (150-200 g) for neuro-protective or anti-Alzheimer’s study were obtained from the animal house at Government College University Faisalabad. They were sheltered in standard laboratory situations (25 ±  3oC) with a twelve-hour bright and shady cycle and thirty to sixty percent dampness. The animals were allowed to move freely to meal in stainless steel separate cages. This animal study was approved and initiated after obtaining permission from the official review panel at GCUF.\n\nThe Institutional Review Board (IRB) at GC University granted approval for animal trials, and GCUF/ERC/410 was the approved number. Every experimental protocol followed the guidelines set forth by the National Research Council’s Institute of Laboratory Animal Resources, Commission on Life Sciences University, in 1996.\n\nMung beans were collected from Arifwala, Pakistan, in July 2023 and authenticated by the Botany Department at the University of Agriculture Faisalabad (UAF), Pakistan. A voucher specimen was put forward to the herbarium (745-08-2023). The beans were washed to eliminate dirt and unnecessary constituents, and then dehydrated under dark for one month. They were ground to make pulverized stuff, and extracts were prepared in pumpkin oil and soybean oil using the green extraction technique and microwave-assisted extraction procedure.\n\nThe plant material was weighed and added to 1000 mL beakers. The microwave oven was set to 9000 watts. In the first cycle, 900 mL of oil and 100 g of powder were combined in each beaker. The mixtures were heated for 2 minutes, followed by a 30-second pause. This procedure was carried out five times. Then, the supernatant was removed by means of filter paper. In the second cycle, the pellets were suspended with 500 mL of oil and the heating and filtration process was repeated five times. In the third cycle, 500 mL of oil was added to each beaker, and the process was repeated again. Finally, the filtrate was evaporated using a rotary evaporator at 40°C, yielding an oil-enriched extract used for further analysis [9,10].\n\nThe physicochemical properties were evaluated following the procedures outlined in the USP-National Formulary 2003. Various analyses were performed, including moisture content, total ash content, acid insoluble ash, water insoluble ash, sulphated ash, water-soluble extractive, alcohol-soluble extractive, total lipid content test, total protein content test, carbohydrate content test, total glycosaponins content test, estimation of secondary metabolites, total polyphenolic content test, total flavonoid content test, and total alkaloid test. These analyses encompassed a comprehensive assessment of the substance’s chemical composition and properties [11].\n\nThe prepared extract was quantitatively analyzed by GCMS analysis to estimate the quantity and quality of neuroactive compounds isolated in the extract. An Agilent (7890B) gas chromatograph provided with an inert mass selective detector (5977B) and a DB-5MS GC column (30m length, 0.25mm internal diameter, 0.25µm film thickness) was utilized for this process. Inoculation of specimen (2uL) was performed in the split less mode, with adjustment of temperature of injector 250°C and temperature of interface 280°C. The oven temperature was programmed from starting value of hundred degrees Celcius for thirty seconds, stepped up to 340°C at 20°C/min for a minute. Helium (He) served as the carrier gas, and electron impact ionization was employed at –70 eV in full-scan mode. The overall running time span was thirty minutes. NIST Library 20.0 was utilized for the search report.\n\nAcute oral toxicity studies were performed according to OECD 425 guidelines, this study was performed on nulliparous non pregnant female mice to determine LD50and safe dose level of VRSO and VRPO, 2000 mg/kg dose of each treatment was given for 14 days and animals were observed for any toxic reaction.\n\nAD was induced in experimental animals through oral administration of aluminum chloride and d-galactose at a dose of 150 mg/kg each for 28 days daily [11].\n\nAnimals were divided into 07 groups (n = 10, in each group): control (received distilled water), AD control (Alzheimer’s disease (AD) like phenotype group, received aluminum chloride and d-galactose at 150 mg/kg each), standard group (received rivastigmine at 3 mg/kg),Vigna radiataL. pumpkin oil groups (VRP500 and VRP250) at doses of 500 mg/kg and 250 mg/kg respectively, andVigna radiata L. soybean oil groups (VRS500 and VRS250) at doses of 500 mg/kg and 250 mg/kg respectively. This treatment was continued for 28 days. During the last week of experimental study animals were trained in Morris water maze for behavioral analysis. After completion of experimental treatment behavioral studies were performed to investigate the effect of VRSO and VRPO on AD associated motor and non-motor symptoms.\n\nAfter sacrifice brain tissues were isolated principally hippocampus for biochemical analysis, neurotransmitter quantification and gene expression analysis. Blood samples were collected to isolate serum samples for quantification of ELISA test of pro-inflammatory cytokines.\n\nAnimals were sacrificed under anesthesia by inhalant anesthetic isoflurane 3-4% with 100% oxygen supply by precision vaporizer. Euthanasia procedure was performed according to AVMA guidelines [12]. Animals of weight greater than 200 g were euthanized by cervical dislocation and animals of weight greater than 200 g were sacrificed under inhalant anesthesia by decapitation by commercially available guillotines by trained personals.\n\nMorris water maze task, open field test, passive avoidance test, Y-maze test, hole board test, wire hanging test, elevated plus-maze task were performed according to reported protocols [13].\n\nThe Morris Water Maze (MWM) set up comprises of a spherical chamber occupied with milky water, with external cues for navigation. Training involves placing animals in the tank to find a hidden platform. Animals can employ praxis, taxis, or spatial strategies for navigation. Various opacifiers and tank sizes are used, and training protocols include hidden-platform acquisition, probe trials, and working memory testing. Video tracking systems are commonly used for quantification, measuring parameters like escape latency, path length, and swimming behavior. During last week of experimental study, animals were allowed to explore MWM tank without platform and it was considered as acclimation phase. After that for 04 consecutive days four trials/day from different quadrants were performed and animals were trained and guided to reach hidden platform in 01 minute. We considered that animal have learned the task if we find reduction in escape latency time (less than 20 seconds and path length less than 1 meter after 04 day training sessions. At 05 day probe trails were performed and escape latency period from each quadrant was recorded.\n\nThe locomotor and habituation behaviors of twenty-one days treated animals were evaluated in a woody square case with measurement 40 x 60 x 50 cm. The surface of the field was separated into twelve equal squares. Rats underwent two consecutive turns, first for preparing and second for trial, each lasting 6 minutes. The number of crossings (movement across rectangles), rearings (standing on posterior limbs), and fecal matter were recorded in couple of turns. Crossings directed locomotors activity, whereas the decline in rearing between turns reflected a measure of habituation.\n\nThe maze assembly took place in an isolated room to eliminate any external disturbances, including noises, scents, or movement. Additionally, low-intensity white noise may have been introduced to the behavioral experiment room. It was crucial to remove any potential guidance cues, such as drawings on the walls, which could have biased the animals’ activity within the maze. The experimenter ensured minimal noise and movement throughout the trial and refrained from using any strong-smelling products to prevent inducing anxiety in animals Illumination levels in the room were carefully controlled using a lux meter, with low-intensity lighting preferred for analyzing anxiogenic effects and higher intensity lighting for assessing anxiolytic effects. Following the adjustment of experimental conditions, the animals were given time to acclimate to the environment before testing begun. Prior to each test session, the maze was meticulously wiped with 70% ethyl alcohol to get rid of any potential contaminants. Once preparations were complete, the video camera was activated, and each animal was introduced into the maze for a 5-minute exploration period. The experimenter maintained a distance from the maze to avoid influencing the rat’s behavior. After each trial, the maze was cleaned again to eliminate any lingering odors, and the next rat was tested in the same manner. This process continued until all animals had been tested. Recorded videos were later analyzed using automated software or manually with a chronometer, considering parameters such as entries in closed and open arms, time spent in each arm, and risk-assessment behavior.\n\nThe evaluation of spatial memory was conducted using the Y-maze test, comprised of black plexiglass with three arms arranged at 120° angles to each other. During the learning phase, one arm of the maze was closed off, while various pictorial signs were strategically positioned nearby the setup. Rodents were then introduced into the experimental environment and permitted to freely travel the remaining two arms for duration of fifteen minutes. Following this exploration period, the rats were returned to their cages. After a 4-hour interval, the obstacle blocking one arm was removed, granting the rat’s unrestricted access to all three arms for a 5-minute period. The performances of the rats were captured via camera and subsequently analyzed using Ethovision v1.90 software (Noldus). Parameters such as whole distance covered, average speed, incidence of appearing the new arm, and time devoted in the new arm were assessed from the recorded data.\n\nThe short and long term memory deterioration in an associative manner was studied using a shock- motivated task. In order to prevent shock, test animals suffering from AD resist their innate bias. The set-up utilized in this experiment was made of Plexiglas measuring 27 cm by 27 cm by 27 cm, and it had grill work at the base made up of stainless steel rods spaced eight millimeters apart and with a thickness of three millimeters. Grid was connected to a battery to provide a 20V current source. A wooden rostrum measuring 10 cm by 7 cm by 1.7 cm was positioned at half height. The animals were placed on the elevated surface and dealt gently from the tip of their tails. In the initial trial, the animal is supposed to keep its position for fifteen to twenty- two seconds before stepping down to the floor. Two hours later, after the first trial the second trial begun. Rats were put up at wooden rostrum for test trial, and their step down time was observed.\n\nBehavioral neurological science performs this test to assess rodents’ short term memory, spatial memory and intellectual deficit. As opposed to the AD animal model, test animals with normal behavior prefer to voluntarily change the arms of the maze because animals with unaffected memory and prefrontal cortex functioning have a natural desire to find unique areas. The wooden apparatus used for this work has three arms joined at 120-degree angle in the shape of Y. these arms had a trigonal middle zone and measured 35 cm in length, 25 cm in height and 10 cm in width, for eight minutes, the animal’s exploratory behavior in the Y maze was observed. To ascertain the spontaneous alteration, the rats were placed at the beginning point of each arm of apparatus, and their numbers of entries in each arm and number of triads (entry into three arms on consecutive selection) were recorded. Only when back paws fully penetrated to the arm, the arm entry was considered. The following formula was used to calculate spontaneous alteration:\n\nFormation of brain homogenate:Isoflurane was administered as an anesthetic to each animal, and the animals were euthanized to remove their brains. Brains were cooled to -80 °C in a biomedical freezer after being cleaned with frozen NS (normal saline). After homogenizing the brain tissues in a tissue homogenizer, the supernatant was recovered by centrifuging the mixture for thirty minutes at four degrees Celsius at 800 rpm.\n\nCalculation of malondialdehyde (MDA):The degree of lipid peroxidation is revealed by the MDA level. To conduct this evaluation, 200 microliters of brain homogenate was mixed with fifteen percent trichloroacetic acid (TCA), 0.25 molar Hydrochloric acid, and 0.38% (w/w) thiobarbituric acid (TBA) in a falcon tube. The entire combination was maintained at 90 °C for 15 minutes in a hot tub prior to chilling. The solution was centrifuged for ten minutes at 4000 rpm after cooling [14]. The optical density at 532 nm was recorded after the top layer was collected. MDA level was estimated using this formula:\n\nHere Y represents absorbance, Vt is the test mixture’s total volume (mL), E is the co-efficient 1.56 ×  105, wt is the brain’s weight (grams), and Vu is the aliquot volume (mL).\n\nMeasurement of Catalase Activity (CAT):The brain homogenate (50 μL), 1.95 mL of fifty milimolar phosphate buffer (pH 7.4), and 1 mL of thirty milimolar H2O2were taken for this investigation. At 240 nm, the optical density was observed. CAT was calculated using the subsequent formula:\n\nThe extinguishment co-efficient, which is 0.071 mmol cm − 1, is determined by multiplying the sample volume (mL) by the protein milligrams in the brain homogenate.\n\nEstimation of superoxide dismutase (SOD):The task involved creating a 3 mL total combination by mixing 100 μL of tissue homogenate with point one molar potassium phosphate buffer at 7.4 pH (2.8 mL) and 0.1 mL pyragallol solution. Using a spectrophotometer absorbance was recorded at 325 nm and correlated with the SOD standard linear regression curve (unit/mL).\n\nAssessment of reduced glutathione (GSH) level:In this experiment, 1 mL of tissue homogenate and the same concentration of trichloracetic acid were mingled together and centrifuged at 3000 rpm for 30 minutes. A mixture of point five milliliter DTNB and four milliliters of 0.1 molar phosphate buffer (7.4 pH) was added to the supernatant (2 mL). The OD of the specimen and control, which included all components but brain tissue homogenate, was measured at 412 nm. GSH amount was estimated by means of this formula:\n\nEstimation of nitrite level:The Griess mixture was prepared by mixing 2.5% H3PO4, point one percent N-1-naphthyl ethylene amine dihydrochloride, and one percent sulphanilamide. It was later equally combined with tissue homogenate to estimate the nitrite level. After 10 minutes of incubation, the test solution’s absorbance at 546 nm was determined [14]. Following that, the OD at 546 nm was recorded.\n\nSynthesis of aqueous part:Combine the brain tissue homogenate with a 5 mL solution of HCl-n-butanol to prepare the aqueous phase. Centrifuge for 10 minutes at 2000 rpm. Centrifugation was used to extract the outer phase, which was then combined with two point five milliliters of heptane solution and point three milliliter of Hydrochloric acid and forcefully shaken. The resultant mixture was centrifuged once again for 10 minutes at 2000 rpm. Next, the organic and aqueous layers were separated to estimate the amount of neurotransmitters.\n\nMeasurement of serotonin levels:Aqueous phase (point two milliliter) was mixed to O-phthaldialdehyde and subjected to heat at 100°C for ten minutes for estimating serotonin levels. The resultant extract was allowed to cool to room temperature before having its absorbance at 440 nm. Conc. Hydrochloric acid (0.25 mL) was used as a blank.\n\nDetermination of levels of noradrenaline and dopamine:Aqueous phase 0.2 mL was obtained, and 0.1 mL of EDTA solution and 0.05 mL of HCL (0.4 M) were added to it. Next, 0.1 milliliter of CH3COOH and same amount of iodine in 0.1 mL of ethanol and Na2SO3solution were added. The resulted combination was permitted to cool to ambient temperature (25 °C) after being preheated for six minutes at 100 °C. Next, absorbance for noradrenaline and dopamine was measured at 352 and 452. To prepare the blank for dopamine and noradrenaline, Na2SO3was added before the iodine solution.\n\nEstimation of acetylcholinesterase (AChE) activity:A tiny amount of brain tissue homogenate (0.4 mL) was combined with 2, 4 dithiobisnitrobenzoic acid (100 μL) and acetylthiocholine iodide (20 μL) in 0.1 molar phosphate buffer solution with a pH of 8.00 (2.6 mL). This test evaluated absorbance at 412 nm and generated a yellow tint when 2, 4 dithiobisniotrobenzoic acid and thiocholine reacted. In this experiment, the absorbance was taken at 412 nm and a yellow hue was formed by the interaction of 2, 4 dithiobisniotrobenzoic acid with thiocholine. The AChE activity was measured by following formula:\n\nHistopathological analysis:The brains were taken out and preserved in 4% formaldehyde. Paraffin-embedded brain tissues were cut into transverse sections using a scientific slicer (microtome) with a breadth of five micrometers, dyed with hematoxylin and eosin, and watched under a 10X compound microscope.\n\nPCR amplification in real-time:The following primers were used in a PCR approach to identify the gene expressions linked to AD: α-synuclein, IL-1α, IL-1β, TNF-α, AChE (acetylcholinestrase), β-secretrase, and ABPP (β-amyloid precursor protein). Using a nanodrop spectrophotometer, the 260/280 nm absorbance ratio of RNA isolated using the TRIzol technique was measured. Afterwards, Thermo Scientific cDNA kit was used to transcribe RNA into cDNA. GADPH served as a house-keeping gene for the quantitative real time polymerase chain reaction (qRT- PCR) used to calculate the amount of gene expression. In the experiment, five microliters of complementary deoxyribonucleic acid (cDNA) and same amount of (five microliters) of cyber green were added to microplate wells along with a forward primer (0.5 μL) and corresponding reverse primer (0.5 μL). By inserting a microplate into the thermal cycler, 40 cycles of denaturation (breaking hydrogen of DNA stands) at ninety-five degrees Celcius, annealing (binding of primers to untwisted DNA strands) at sixty degrees Celcius, and extension (binding of DNA polyemerase to initiate elongation) at seventy two degrees Celcius were programmed. By inserting a microplate into the thermal cycler, forty cycles of denaturation at 95 °C, annealing at 60 °C, and extension at 72 °C were programmed (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.g001\n\nELISA test of neuro-inflammatory markers:The quantities of proinflammatory cytokines, such as TNF-α and IL-6, in serum were measured using an Enzyme Linked Immunosorbent Assay kit procedure created by Wuhan Zokeyo Biotechnology Co., Ltd., China (catalog number Y-83079-48T for TNF-α and Y-84561-48T for IL-6).\n\nImmune assay for SFRP4:The SFRP4 expression in serum was determined using an ELISA. The mouse SFRP4 ELISA kit, developed by Wuhan Fine Biotech Com., Ltd., China, was used for this analysis [15,16]. The kit relied on sandwich enzyme-linked immunosorbent assay technology and was used for the quantitative detection of SFRP4 in serum.\n\nThe data was displayed as mean ±  SEM. Graphpad Prism version 6 was used to do One Way and Two-way ANOVA and Tukey’s post-hoc test.\n\nPhysico and phytochemical analysis revealed that all parameters of physicochemical analysis were in acceptable range according to USP and national formulary standard limits. As presented inTable 1. Results of primary and secondary metabolites revealed the existence of favorable concentration of bioactive compounds (Tables 1and2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t002\n\nGC/MS examination disclosed the potentiality of multiple bioactive compounds in VRSO extract and VRPO extract. As presented inTable 3. Linoleic acid higher concentration is present in VRSO similarly, VRPO showed the maximum concentration of oleic acid. Both compounds exhibited the robust neuroprotective potential as reported in previous studies (Figs 2and3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.g003\n\nAfter administration of limit dose 2000 mg/kg of VRSO and VRPO, no change in behavior was observed with any morbidity and mortality. Hematological, biochemical, liver function test and kidney function test revealed that VRSO and VRPO showed no toxic result on normal function of vital organs (Tables 4–6).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t006\n\nSo that both extract have LD50value greater than 2000 mg/kg. Therefore we selected dose level of both extract for further neuro-protective study in the light of LD50value. Histo-pathological analysis also revealed the intact architecture of vital organ tissues of VRSO and VRPO treated animals similar to control group animals (Fig 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.g004\n\nFindings of Morris water maze task revealed that in AD like phenotype group escape latency (an earliest measure of spatial learning and memory is a time to reach hidden platform) was increased (p <  0.001) significantly compared to normative treatments and standard care group. The average velocity was markedly decreased and the distance travelled was also expanded in AD like phenotype compared to other groups due to thigmotaxis behavior of animals. However, treatment with VRSO and VRPO dose dependently improved learning and spatial memory capability in treatment groups in Morris water maze tank (Fig 5).\n\nStatistical assessment (n = 10, in each group) Two-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group) Two-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g005\n\nIt is revealed from open field task that animals in all groups reside longer at edges of apparatus contrast to expedition time at center of apparatus. In AD like phenotype group, the frequency and duration of rearing behavior of animals significantly declined (p < 0.001) compared to normative, standard care and treatment groups. In AD like phenotype group, stretch attends posture, freezing moments and defecation observed more frequently (p <  0.001) relative to other treatment groups. In VRPO and VRSO treatment groups animals travelled the longer distance at periphery of chamber, crossed the greater number of lines with greater velocity (p <  0.001) dose dependently compared to AD like phenotype group. The grooming behavior of animals indicated the self- grooming, maintenance of fur and wounds, exploration and relaxation attitude by licking, nibbling, scratching and cleaning. The grooming social behavior significantly declined (p <  0.001) in AD like phenotype compared to normative and treatment groups (Table 7).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t007\n\nRats’ transfer latency (TL), a measure of the acquisition and retention of memory on an elevated plus-maze, was used to examine how VRPO and VRSO affected the learning and memory. It was observed that transfer latency was remarkably boost (p <  0.001) in AD like phenotype category contrast to normative category due to acquisition deficit induced by D-galactose and aluminum chloride. Although, curing by VRPO 250 & 500 mg/kg and VRSO 250 & 500 mg/kg increased consolidation, retrieval, acquisition and retention as manifested by significantly (p <  0.001) decline in transfer latency in treatment groups compared to AD like phenotype animals (Fig 6).\n\nStatistical assessment (n = 10, in each group), Two-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), Two-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g006\n\nThis task was designed to investigate fear conditioning and inhibitory avoidance in AD like phenotype group in which D-galactose and aluminum chloride administration impaired the aversive learning and fear conditioning compared to normative group. It was manifested that the step down response time was minimized in AD like phenotype category (p <  0.05) contrast to dose receiving category. VRSO and VRPO treatment groups showed the intact ability to learn and avoid an aversive stimulus. The step down latency was significantly increased in VRSO and VRPO treatment groups (Fig 7).\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g007\n\nIn Y-maze task total arm visits, spatial memory, score in triadic response, autonomic alternation score (%) and hemispheric dominance index were notably (p <  0.001) decreased in AD like phenotype category compared to normative, standard care, VRPO and VRSO treatment groups. However, treatment with VRSO and VRPO remarkably recovered spatial memory, learning and cognitive flexibility in Y-maze task (Table 8).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t008\n\nIt was manifested that AD like phenotype group showed a crucial decline (p <  0.05) in head dipping, locomotion, and exploratory way of behaving compared to normative group. In contrast, the standard care and VRPO and VRSO treatment groups exhibited significant improvements in exploratory behavior and head dipping, with a concentration related effect: the high concentration (500 mg/kg) showed the greatest improvement, followed by the low concentration (250 mg/kg) (Fig 8).\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g008\n\nOur study revealed a significant decrease (p <  0.05) in wire hanging time and a significant increase in falling down in AD like phenotype group compared to the normative group, standard care group, VRSO and VRPO treatment group. However, no significant differences (p >  0.05) were observed in suspending with wire and dropping times among the normative category, standard drug receiving category and VRSO & VRPO receiving category (Fig 9).\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g009\n\nIt was manifested that in AD like phenotype group the level of catalases, reduced glutathione and GPx remarkably lessened (p <  0.05) in comparison to normative group. However, due to perpetuation of oxidative stress brought on by D-galactose and AlCl3the level of lipid and proteins peroxidation increased, as manifested by significantly raised level of malonaldehyde in AD like phenotype group compared to normative group. VRPO and VRSO treatment markedly (p <  0.05) recovered or mitigated the level of first line antioxidant enzymes dose dependently in treatment group. VRSO and VRPO treatment remarkably (p <  0.05) diminished the level of malonaldehyde (MDA) in VRSO & VRPO receiving groups similar to standard care and normative group (Table 9).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t009\n\nIt is revealed that d-galacatose and aluminum chloride insult treatment to AD like phenotype group induced depletion of acetylcholine via up-regulation in acetylcholinesterase activity. In AD like phenotype group the quantity of AChE crucially up surged (p <  0.05) resulting in decreased level of acetylcholine. However, in VRPO and VRSO treatment groups the level of acetyl cholinesterase decreased resulting in recovered level of acetylcholine and recovery of associated motor and non -motor functions congruent to normative and standard care treatment groups (Fig 10).\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g010\n\nIn AD like phenotype group the level of principal neurotransmitters significantly declined compared to normative group. Whereas, standard care and VRSO and VRPO treatment significantly retained (p <  0.05) the concentration of these chemical messangers compared to AD like phenotype group (Table 10).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.t010\n\nIn AD like phenotype group the mRNA expression of Secreted Frizzled Related Protein 4 (SFRP4), interleukin 1 alpha (IL-1α), interleukin 1 beta (IL-1β), tumor necrosis factor alpha (TNF-α), acetyl cholinesterase (AChE), amyloid beta precursor protein (AβPP), beat secretase (β-secretase) significantly (p <  0.05) up-regulated compared to normal control category. However, VRPO & VRSO treatment significantly down-regulated the messenger ribonucleic acid (mRNA) expression of molecular markers of inflammation of nervous tissue and neuronal loss (Fig 11).\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g011\n\nIt was manifested by enzyme linked immune-sorbent assay (ELISA) that in AD like phenotype group the expression of inflammatory biomarkers remarkably raised (p <  0.05) contrast to normative group. However, VRPO and VRSO dose dependently decreased the expression of these inflammatory markers in treatment groups like normative and standard care group (Fig 12).\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g012\n\nThe serum concentration of SFRP4 was remarkably raised (p <  0.001) in AD like phenotypic category after administration of d-galactose and aluminum chloride. However, VRSO and VRPO dose dependently decreased the serum level of SFRP4 in treatment groups 500mg/kg>250 mg/kg (Fig 13).\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nStatistical assessment (n = 10, in each group), One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g013\n\nIt was manifested through histo-pathological analysis that treatment with VRPO and VRSO enriched extracts mitigated neurodegenerative hallmarks in brain tissues. D-galactose and aluminum chloride treatment induced the genesis of hyperphosphorylated tau proteins clumps inside neurons, pigmentation and plaques. The neuronal cell count also decreased in AD like phenotype group. However, normative, standard care and VRPO and VRSO treated group showed normal architecture of brain tissues (Fig 14).Fig 15showed the scoring or grading system of histo-pathological interpretations. It was manifested that highest scores of neurofibrillary tangles, senile plaques, neuro-inflammation and neuronal loss were marked to AD like phenotype group compared to standard care, VRSO and VRPO treatment groups. It was evident that VRSO and VRPO treatment at higher doses 500 mg/kg significantly recovered (p <  0.01) the neuronal architecture compared to AD like phenotype group.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321183.g014\n\n(Neurofibrillary tangles 0 (none), 1(Sparse), 2(Moderate), 3(Severe)), (Senile plaques 0 (none), 1 (Sparse), 2 (Moderate), 3 (Severe)), Neuro-inflammation 0 (none), 1(Mild), 2(Moderate), 3(Severe)), Neuronal loss 0 (none), 1(Mild), 2(Moderate), 3(Severe)). Statistical assessment One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\n(Neurofibrillary tangles 0 (none), 1(Sparse), 2(Moderate), 3(Severe)), (Senile plaques 0 (none), 1 (Sparse), 2 (Moderate), 3 (Severe)), Neuro-inflammation 0 (none), 1(Mild), 2(Moderate), 3(Severe)), Neuronal loss 0 (none), 1(Mild), 2(Moderate), 3(Severe)). Statistical assessment One-Way ANOVA showed significant variations compared to AD like phenotype group, with p-values indicating probabilities of *  less than 5%, ** less than 1%, and *** less than 0.1% and compared to normative group ### less than 0.1%, respectively.\n\nhttps://doi.org/10.1371/journal.pone.0321183.g015\n\nThis study explored the therapeutic potential ofV. radiata(green beans) also known as mung beans, extract in pumpkin oil and soya bean oil in an AlCl3and D-galactose-generated Alzheimer’s disease (AD) rat model. Our findings demonstrate that these natural extracts significantly improved cognitive function, reduced oxidative stress, and inhibited amyloid-β aggregation in the brain, as evidenced by behavioral studies, biochemical analysis, histopathology, and RT-PCR analysis.\n\nNeurodegenerative diseases like Parkinson’s and Alzheimer’s share common features, including protein accumulation and oxidative stress, but current treatments only address symptoms, not causes. Nutrition, particularly lipids like vegetable and animal oils or fatty acids, may help prevent or slow disease progression when incorporated into diet. Modern research suggests these lipids can inhibit cytotoxicity and oxidative stress, and future therapeutic/preventive approaches may involve improve delivery methods, such as lipid encapsulation, to target the brain and other vital organs.\n\nGC-MS study declared the existence of remarkable bioactive elements in VRSO and VRPO extract. In VRSO Linoleic acid, 9-Octadecenoic acid, 4-Phenylpyridine, gamma.-Tocopherol, Vitamin E, Stigmasterol, Gamma-Sitosterol and Chrysin were identified through NIST libraray. Vitamin E is a fat-soluble vitamin with antioxidant properties, gamma-tocopherol is part of the vitamin E classification group found in corn and soybean oils [23,31]. Stigmasterol and gamma-Sitosterol are plant sterol with neuroprotective effects [31]. Chrysin is a flavonoid with neurodefensive potential [30]. Consistent to our findings a study reported that mung bean or green gram, an abundant resource of neuro-protective polyphenols, may be a potential dietary intervention for Alzheimer’s disease (AD). Quantitative analysis identified nineteen phenolic compounds, including phenolic acids and flavonoids, with vitexin, isovitexin, sinapic acid, and ferulic acid speculated to be key biologically active compounds. These compounds likely exert neuroprotective effects through mechanisms including suppression of synthesis of β-amyloido proteins, tau hyperphosphorylation, free radical damage, and neuroinflammation, as well as encouragement of removal of unnecessary cellular componemts and AchE enzyme action. Principally, germination altered the antiproliferative and neuroprotective phenols level, with changes in individual compound levels [8].\n\nAlzheimer’s disease (AD) is a common form of memory loss or impairment in normal brain functioning with restricted treatment options. Natural ingredients, such asVigna radiataextract in pumpkin and soya bean oil have gained attention for its potential in treating neurological disorders, including AD. A previous study investigated thein vitroanticholinesterase and neuronal function promoting action of these plants. The extract ofV. radiataprepared in ethyl acetate (C4H8O2) displayed significant acetylcholine esterase (AChE) inhibitory action, with IC50values of 286.40 µg/mL. Additionally, extract exhibited dose-dependent neuroprotective effects against β-amyloid-generated cellular toxicity in SHSY-5Y neuroblastoma cells. The results proposed thatV. radiatamay prove a promising candidate for the synthesis of anti-Alzheimer’s medications [32].\n\nTherefore, keeping in view thein vitroneuroprotective potential ofV. radiate, current study revealed cerebro-protective ability ofV. radiatevegetable oil extracts in aluminum chloride and d-galactose induced AD like animal model. Behavioral studies revealed that VRSO and VRPO treated rats exhibited improved memory and learning abilities, indicating a potential reversal of AD-related cognitive decline. In behavioral studies during Morris water maze task, Y-maze task, elevated plus maze task, open field task, wire hanging and hole board test it is revealed that VRSO and VRPO significantly retained spatial learning, memory, cognitive flexibility, exploratory behavior, spontaneous alteration, muscular endurance and motor co-ordination.\n\nSimilar to our findings green moong bean (Vigna radiata) sprouts were investigated for their anti-Alzheimer potential using behavioral models in Swiss mice. Mice were divided into 23 groups and administered 2, 4, or 8% w/w moong bean sprouts (MBS) in their diet for 15 days [33]. Results showed that MBS significantly improved immediate memory and episodic memory in the Elevated Plus Maze and Passive Avoidance Paradigm models, respectively. MBS also reversed ethanol- and diazepam-induced memory deficits. Additionally, MBS increased brain glutathione levels, decreased acetylcholinesterase activity, and reduced malondialdehyde levels, suggesting a mechanism of action involving acetylcholinesterase inhibition, antioxidant activity, and neuroprotection via phytoestrogens. Overall, the outcomes declared thatV. radiatasprouts possess promising anti-Alzheimer potential [34].\n\nBiochemical tests indicated a crucial reduction in oxidative stress markers, such as malondialdehyde, and raise in the level of enzymes responsible for scavenging free radicals, like superoxide dismutase and catalase, in the brain tissues of VRSO and VRPO treated rats.\n\nSimilar to our results a study investigated the defensing effects of Ginkgo biloba extract (EGb) and pumpkin seed oil (PSO) against neouronal toxicity produced by rotenone in rodents. Both EGb and PSO improved dopamine and norepinephrine levels, antioxidant capacity, and lipid peroxidation, with EGb showing a more pronounced protective effect. The study suggests that EGb may prove helpful against neuronal damage caused by atmospheric neurotoxic chemicals, and PSO may have a role in limiting oxidative stress [35].\n\nAcetylcholinesterase (AChE) plays a crucial role in nerve function and signal transmission, but excessive activity during aging can deplete acetylcholine (ACh), leading to impaired neural communication and serious illnesses like dementia and Alzheimer’s Disease (AD) [36]. Inhibiting AChE activity to increase brain ACh levels is a proven approach for managing AD.\n\nIn current work, VRSO and VRPO decrease the excessive activity of this enzyme and restored the level of acetylcholine. Our study congruent to previous work cited the recent advances in using extracts and compounds obtained natural resources as AChE regulatory substances [37]. These include polyphenol-rich extracts, proteins, peptides, terpenoids, and carotenoids, which have shown efficacy in reducing brain AChE levels and improving memory functions [38].\n\nIn AD like phenotype model animals the significant decline in neurotransmitters like adrenaline, acetylcholine, dopamine and serotonin was observed. However, upon treatment with VRSO and VRPO level of these transmitters was markedly improved consistent to previous findings [8]. In previous work it was reported that presence of bioactive compounds such as Vitexin, Isovitexin, Sinapic acid, Ferulic acidV. radiatemodulated acetyl-cholinesterase activity and level of acetylcholine [8].\n\nVRSO and VRSPO downregulated the mRNA expression of neuronal deteriorating and neuro-inflammatory markers in RT-PCR analysis. AD a complex neurodegenerative disorder its pathogenesis involved the chronic neuro-inflammation, deposition of amyloid-β plaques intiated by central cascades of proinflammatory cytokines [39,40]. IL-1α, IL-1β, TNF-α, and IL-6 play a critical role in AD associated neuroinflammation. Acetylcholinestersae [41], Beta-secretase [42] and amyloid-β precursor protein (ABPP) [43] are key enzymes mainly involved in pathology of AD and production of amyloid-β deposits, while SFRP4 as modulator of Wnt/β-catenin signaling pathway also implicated in AD pathology [44]. Current findings revealed that VRSO and VRPO treatment markedly decreased the mRNA expression of IL-1α and IL-1β and therefore decreased the neuroinflammation and accumulation of β-amyloids significantly in treated groups compared to AD like phenotype group. It is manifested that both VRSO and VRPO markedly down-regulated the expression of TNF-α and IL-6 which are involved in immune response and neuroinflammation and subsequent AD pathogenesis. VRSO and VRPO markedly downregulated the mRNA expression of AD associated genes β-Secretase and ABPP, resulting in reduction in β-amyloid accumulation, senile plaque formation and formation of neurofibrillary tangles. Wnt/β-catenin signaling play a crucial role in synaptic plasticity, neurogenesis, neuronal integrity and overall brain health [45]. Oxidative stress or other neurotoxic substances down-regulated this signaling and induce AD like symptoms. SFRP4 (Secreted Frizzled Related Protein 4) is a down-regulator or negative regulator of this signaling. VRSO and VRPO treatment dosedependently restored Wnt/β-catenin signaling through downregulation in mRNA expression of SFRP4 suggesting a novel approach to treat AD.\n\nSimilarly, a study investigated that during menopause, decreased estrogen production can lead to reduced brain metabolism and increased risk of neurodegeneration. This study investigated the potential neuroprotective effects of pumpkin seed oil nanoparticles (PSO-NE) in an experimental postmenopausal model. The results showed that PSO-NE significantly increased estrogen levels, reduced neuro-inflammatory markers, and improved brain health, suggesting a prophylactic effect on neuro-inflammatory interactions [46].\n\nIn VRSO, soybean isoflavone (SIF) is a polyphenol with strong antioxidant activity, with genistein being the major isoflavone in soy foods. Research suggests that SIF may help alleviate deterioration of neuronal cells in various diseases like AD, and appropriate intake may diminish the threat of being suffered from AD. This research work analyze various aspects of AD pathogenesis and its association with SIF consumption, providing insights for AD prevention [47].\n\nSimilar to our work on vegetable oils used in extraction procedure for preparation of neuroprotective remedial agents. A study investigated the protective effects of three vegetable oils (olive, corn, and perilla) against intellectual disability in an AD in rats. Perilla oil, rich in alpha-linolenic acid (ALA), showed the most significant attenuation of cognitive impairment and reduced oxidative stress, inflammation, and improved brain function. The findings suggest that ALA-rich perilla oil may have potential for preventing or treating neurodegenerative diseases like AD [48].\n\nVRSO have soy isoflavones (SI) have been suggested to have neuroprotective effects against AD, but their mechanisms of action are not well understood. This study found that SI administration improved cognitive performance and enhanced cholinergic system function in mental disability brought on by scopolamine in rodent model. SI also suppressed oxidative stress and upregulated key signaling pathways, including ERK, CREB, and BDNF, in the hippocampus, suggesting its potential in recovering neuronal damage in many diseases like AD [49,50].\n\nHistopathological examination revealed decreased level plaques and hyperphosphorylated tau protein aggregates in the hippocampus and cortical region of standard and extract receiving animals, suggesting a possible neuroprotective effect [51]. RT-PCR analysis further confirmed the downregulation of genes involved in inflammation and oxidative stress, such as TNF-α and IL-1β. The outcomes revealed thatV. radiata, or mung beans pumpkin and soya bean oil extracts may be potential natural remedies for AD treatment, targeting multiple pathological mechanisms. The neuroprotective properties of these extracts may be credited to their reducing inflammation antioxidant, and neurotrophic actions.\n\nOur study highlights the importance of exploring natural products as alternative or complimentary therapies for AD, particularly in light of the limited success of current treatments. However, more study is required to clarify the primary mechanisms and raising the medicinal activities of these extracts. The findings of this research work offer a promising base for upcoming studies to utilizeV. radiata, pumpkin oil and soya bean oil extract in AD prevention and treatment.\n\nThis study demonstrates the therapeutic potential ofV. radiataextract in pumpkin oil and soya bean oil in an AlCl3and D-galactose generated Alzheimer’s disease (AD) rat model. The findings suggest that these natural extracts significantly improved cognitive function, reduced oxidative stress, and inhibited amyloid-β aggregation in the brain. The neuro-protective potential of VRSO & VRPO was probably be due to extracts’ free radical trapping, anti-inflammatory, and neurotrophic actions. The study highlights the importance of exploring natural products as alternative or complementary therapies for AD, particularly in light of the limited success of current treatments. Though, additional studies are necessary to explain the principal mechanisms and boost the medicinal potential of these extracts. The outcomes of this research work provide an ensuring foundation for future researches usingV. radiateor mung beans pumpkin oil, and soya bean oil extract in AD prevention and treatment. The neuroprotective effects of these extracts may offer a potential natural remedy for AD, targeting multiple pathological mechanisms. Generally, this research study adds to the accelerating pool of research on the neuroprotective activities of natural products and highlights the potential ofV. radiata, pumpkin oil, and soya bean oil extract as a natural therapeutic agent for AD treatment.\n\nhttps://doi.org/10.1371/journal.pone.0321183.s001\n\n(DOCX)",
    "category": "materials_science"
  },
  {
    "title": "Computer-based quantitative image texture analysis using multi-collinearity diagnosis in chest X-ray images",
    "authors": "Antonio Quintero-Rincón, Ricardo Di-Pasquale, Karina Quintero-Rodríguez, Hadj Batatia, (PLOS)",
    "publish_date": "2025-04-14",
    "doi": "https://doi.org/10.1371/journal.pone.0320706",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320706",
    "content": "Despite tremendous efforts devoted to the area, image texture analysis is still an open research field. This paper presents an algorithm and experimental results demonstrating the feasibility of developing automated tools to detect abnormal X-ray images based on tissue attenuation. Specifically, this work proposes using the variability characterised by singular values and conditional indices extracted from the singular value decomposition (SVD) as image texture features. In addition, the paper introduces a “tuning weight\" parameter to consider the variability of the X-ray attenuation in tissues affected by pathologies. This weight is estimated using the coefficient of variation of the minimum covariance determinant from the bandwidth yielded by the non-parametric distribution of variance-decomposition proportions of the SVD. When multiplied by the two features (singular values and conditional indices), this single parameter acts as a tuning weight, reducing misclassification and improving the classic performance metrics, such as true positive rate, false negative rate, positive predictive values, false discovery rate, area-under-curve, accuracy rate, and total cost. The proposed method implements an ensemble bagged trees classification model to classify X-ray chest images as COVID-19, viral pneumonia, lung opacity, or normal. It was tested using a challenging, imbalanced chest X-ray public dataset. The results show an accuracy of 88% without applying the tuning weight and 99% with its application. The proposed method outperforms state-of-the-art methods, as attested by all performance metrics.\n\nCitation:Quintero-Rincón A, Di-Pasquale R, Quintero-Rodríguez K, Batatia H (2025) Computer-based quantitative image texture analysis using multi-collinearity diagnosis in chest X-ray images. PLoS ONE 20(4):\n           e0320706.\n        \n        https://doi.org/10.1371/journal.pone.0320706\n\nEditor:Khan Bahadar Khan, Islamia University of Bahawalpur: The Islamia University of Bahawalpur Pakistan, PAKISTAN\n\nReceived:December 12, 2024;Accepted:February 23, 2025;Published:April 14, 2025\n\nCopyright:© 2025 Quintero-Rincón et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All chest X-ray images files are available from the Kaggle public databasehttps://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nImage texture analysis, quantification, and recognition are active research topics in biomedical imaging, computer vision, and pattern recognition. In the biomedical context, texture arises from the micro-and-macro-structural patterns of biological tissues [1]. Physicians are trained to visually interpret texture information across various imaging modalities, such as radiographic X-rays. The principle behind these anatomical images is based on the differences in attenuation among tissues, which are influenced by the material’s atomic number, tissue density, photon energy, and material thickness. Greater tissue density leads to increased attenuation. Chest X-rays are specifically employed to assist physicians in examining the anatomy of the lungs and heart. Pixel intensities correspond to the density of matter integrated along rays, often analysed according to their texture. Tissue attenuation in X-rays has extensively been studied in medical applications. Existing methods use various techniques to improve low contrast and low dynamic ranges to help discriminate tissues and precisely identify organs, bones, tumours, and nodules. Recent studies have focused on methods to remove [2] or amplify [3] tissue components, using multiscale Shannon-Cosine Wavelet models [4] or by adjusting parametric models based on the component attenuation, contrast, and image fusion [5]. Deep convolutional neural networks (CNN), such as VGG, ResNet, DenseNet, and DeTraC, have been applied directly [6–9], or as means of representation learning combined with conventional machine learning models [10]. Other deep learning methods have been proposed, including the triplet-constrained deep hashing [11], vision-transformer [12], the dual-ended multiple attention learning models (DMAL) [13], the centralised and federated learning [14], and Wasserstein distance and discrepancy metric [15].\n\nIn high-dimensional data analysis, such as image processing or computer vision, features can be correlated, making learning difficult. Various dimensionality reduction techniques exist, including subspace, manifold-based, and shallow and deep neural network methods. Principal Component Analysis (PCA) is a dimensionality reduction technique that belongs to subspace-based methods [16]. PCA aims to project the data onto fewer dimensions while preserving its inherent statistical patterns. Technically, PCA identifies the components along which the data matrix has the maximum variance. It has applications in data exploration, noise reduction, feature extraction, and data compression.\n\nThe most straightforward method to calculate PCA is through the conventional eigenvalue decomposition of the covariance matrix. However, Singular Value Decomposition (SVD) is the standard method used to prevent computational and numerical issues. SVD is a matrix factorization technique that decomposes a complex matrixXinto the product of three matrices, whereUandVare orthogonal matrices containing the left and right singular vectors, respectively, andΣis a diagonal matrix with singular values indicating the importance of each component. Principal components are extracted by selecting the desired number (k) of singular values and the corresponding columns ofV(). The lower-dimensional representation ofXcan then be computed. For more details about PCA and SVD, we refer the reader to [17–19].\n\nThis work proposes analysing the variability of tissue attenuation as a texture phenomenon in X-ray images using singular value decomposition (SVD). Singular values and conditional indices are proposed as textural features used in a multiclass learning model to classify clinical chest X-ray images as normal, COVID-19, viral pneumonia, or lung opacity. Note that the conditional indices of a matrix are derived using the well-known SVD method [20]. They are usually used in regression methods to diagnose multi-collinearity problems [21]. They have never been used as characteristics of texture.\n\nSVD is commonly used in image texture analysis, where the spatial arrangement of grayscale pixels in a neighbourhood is considered to characterize phenomena present in the image. This technique is used to solve problems related to segmentation, classification, and synthesis by using statistical, structural, model-based, and transform-based methods. These methods extract textural properties to describe image texels. Texels are texture units arranged in ways that can be characterized by specific feature descriptors, which in turn use texture operators [1]. The most frequently used texture descriptors relate to coarseness, homogeneity, density, neness, smoothness, linearity, directionality, granularity, and frequency [22].Table 1summarises the most popular textural operators.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.t001\n\nFor experimentation, singular values and conditional indices were used to analyse the variability of tissue attenuation of X-rays in cases of COVID-19, viral pneumonia, lung opacity, and normal. The aim is to derive that the two features characterise this variability well and can be used to discriminate against COVID-19 cases.\n\nCoronavirus disease 19 (COVID-19) is caused by a severe acute respiratory syndrome called coronavirus 2 (SARS-CoV-2) infection. Infected individuals have been reported with typical clinical symptoms involving fever, non-productive cough, myalgic, shortness of breath, and normal or decreased leukocyte count. Severe cases of infection cause pneumonia, severe acute respiratory syndrome, multi-organic failure, and death [23]. It is well-known that false-positive diagnoses often lead to more expensive follow-up tests and patient anxiety, while false-negative diagnoses may result in death if treatable conditions are not identified. It is essential to know that chest X-rays are a crucial tool for diagnosing lung infections in the medical field. The real challenge is identifying the diagnosis when an opacity is seen on the X-ray. Such an opacity could indicate bacterial pneumonia, viral pneumonia, COVID-19, or other causes of opacities (including pulmonary embolism, pulmonary oedema, pleural effusion, or lung cancer). Radiologists and pulmonologists use various imaging features to differentiate these conditions, but with generally variable results. The problem can be detected, but the precise nature of the issue would remain unclear, requiring follow-up steps such as computed tomography (CT) scans, sputum analysis, comparison with medical records, concordance with clinical symptoms, bronchoscopy, and biopsy.\n\nIt is well known that experts in biomedical imaging may have varied interpretations and potential errors. For example, symptoms of COVID-19 are very similar to viral pneumonia, potentially leading to misdiagnosis. This ambiguity is caused by the much more significant variations that occur during the texture mapping process when clinicians establish links between the visual observation of image patterns and the underlying cellular and molecular structures. These variations are partly due to the diversity of human biology, anatomy, image acquisition and reconstruction protocols, compounded by observer training. Therefore, early diagnosis using chest X-ray imaging can be crucial to avoid false diagnoses and delays in treatment, which can lead to additional costs, effort, and risks.\n\nTypical abnormal findings of COVID-19 pneumonia reported that, in chest X-ray, parts of the lungs appear as “normal well-aerated parenchyma”, which is associated with areas of accentuation of the pulmonary interstitium characterised by fine linear structures representing the foci of pneumonia, in addition to the so-called ground-glass opacities, typical of COVID-19 infection. Since these findings are among the first radiological manifestations of COVID-19 pneumonia, one can hypothesise that an accurate X-ray reading could help in the early/initial diagnosis of COVID-19 pneumonia on a routine basis, also providing the differential diagnosis with other non-COVID-19 pneumonias [24]. The progress of the disease course in some patients can be relatively rapid or plodding. Usually, the most significant involvement in COVID-19 is mainly perceived in the lower lung lobes, which evolve late into areas of pulmonary consolidation, predominantly peripheral, cloudy lung-like with bilateral pleural effusion [25]. Although COVID-19 pneumonia and other viral cases of pneumonia share similar radiographic findings, it was found typical in non-COVID-19 viral lung infections that the accentuation of the pulmonary interstitium is often at the bilateral parahilar level with a progressive extension towards the periphery.\n\nAlthough chest radiography is not sensitive enough to detect ground glass opacity, which is the primary imaging feature of COVID-19 pneumonia, chest X-ray imaging is the preferred method for follow-up COVID-19 pneumonia patients admitted to intensive care units [26]. Computed tomography (CT) is another imaging method that provides better accuracy and details. However, it implies a higher radiation dose: while a standard chest X-ray has a 0.02mSveffective dose (in adults), a CT chest study has a 7mSveffective dose [27]. Furthermore, it is not recommended that a chest CT scan be performed on frail patients in intensive care. Chest X-ray allows physicians to easily estimate the extent of alveolar opacity caused by infection, with the lowest radiation rate. When interpreting chest X-rays, it is essential to recognise particular clutter, artefacts, and ambiguities that can make diagnosing pneumonia difficult, especially when using artificial intelligence (AI) tools for automated detection. Motion artefacts, for example, can create pseudo-opacity due to the superposition of anatomical structures, particularly at the lung bases, such as the diaphragm. In addition, other artefacts are produced by the structures of the chest when X-rays are passed through. A typical case is the starburst effect around the coastal arches, generated by the high bone density of these structures. Correct identification and management of these artefacts are essential to avoid false positives and optimise the accuracy of AI systems in detecting pneumonia.\n\nTherefore, addressing the texture analysis based on tissue attenuation in chest X-ray images is complex and challenging. This work starts from the reasonable assumption thatCOVID-19, viral pneumonia, and lung opacity have tissues that exhibit a significantly different attenuation of X-rays compared to normal cases. More precisely, the hypothesis is that the relation between the singular values and the conditional indices of the image characterises this difference. These two quantities can, therefore, be used as texture features to classify COVID-19, viral pneumonia, lung opacity, and normal X-ray images. Note that this approach fits within the category of transform-based methods, seeTable 1.\n\nThe main contribution of this work is an original approach to image texture analysis using singular values and conditional indices. The underlying idea is to show that the phenomenon of near-collinearity [21] characterises the variability of attenuation in X-ray images. As an application, we design an algorithm for quantifying the variability of tissue attenuation in chest X-ray images. The algorithm estimates the proportions of the singular values and the condition indices. These are used as features to classify images as COVID-19, viral pneumonia, lung opacity, or expected. To our knowledge, this approach has not been investigated before for texture analysis in chest X-ray images. In addition, a tuning weight parameter derived from the variance-decomposition proportions is proposed to improve the multiclass classification. Precisely, the estimation of this parameter relies on the coefficient of variation derived from the minimum covariance determinant. The determinant is calculated using the bandwidth parameterh, which comes from the non-parametric empirical distribution of the variance-decomposition proportions. Singular values and conditional indices are multiplied by this weight to account for the attenuation variability. We will show experimentally that this tuning mechanism improves the detection of respiratory syndromes.\n\nThe remainder of the paper is organised as follows. Sect 2 presents the experimental dataset (Sect 2.1) and the proposed method (Sect 2.2), where, i) we review singular value decomposition (Sect 2.2.1), ii) introduce the Likelihood-based Scree plots (Sect 2.2.2, iii) present the non-parametric empirical distribution (Sect 2.2.3), iv) propose the coefficient of variation from the minimum covariance determinant (Sect 2.2.4), v) describe the derived features (Sect 2.2.5), vi) present theReliefFfeature selection algorithm (Sect 2.2.6), vii) describe the multiclass classification scheme (Sec. 2.2.7), and finally, vii) review the partial dependence analysis method (Sec.2.2.8). Experimentation using chest X-ray images is presented in Sect 3, and the results are discussed. Finally, Sect 4 draws conclusions and future works.\n\nThe Kaggle public databaseCOVID-19 Radiography Dataset[28] was considered for experimentation purposes. The dataset consists of chest X-ray images with 3616 COVID-19 positive cases, 6012 lung opacity cases (non-COVID lung infection), 1345 viral pneumonia cases (non-COVID infection) along with 10192 normal cases. It was compiled from Qatar University - Doha, the University of Dhaka - Bangladesh, and their collaborators from Pakistan and Malaysia.Figs 1and2show image sets of COVID-19, pneumonia, lung opacity, and healthy patients. See [29,30] for more information on the complete dataset.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.g002\n\nThis dataset has many challenging characteristics. For example, in some cases, the images seem to be either viral pneumonia, bronchitis, or normal. The issue arises from the fact that the lung conditions of COVID-19 patients are particularly severe and pronounced, as shown inFigs 1and2. For instance, inFig 1(a), there is a typical case showing no infiltrates or pulmonary opacities, with adequate aeration of both lung fields.Fig 1(b) shows a suspicious COVID-19, with an alveolar-interstitial pattern in the upper, middle, and lower fields (predominantly left side). InFig 1(c), there is a viral pneumonia suggestive image (non-covid) with a diffuse bilateral parahilar interstitial pattern.Fig 1(d) shows a non-pneumonia opacity, with slight accentuation of the bilateral parahilar peribronchovascular interstitial network predominantly on the right. These are the best-case scenarios in their respective classifications, indicating the severity of the COVID-19 cases.\n\nSimilarly,Fig 2(a) shows a normal adult chest X-ray. The right perihilar reinforcement appears normal, caused by the pulmonary hilum being more exposed than the contralateral left hilum. InFig 2(b), a patient is lying down for a chest posteroanterior (PA) view due to insufficient breathing, with numerous monitoring leads attached. In both lung fields, ground-glass interstitial infiltrates are observed at the vertices and bases that are usually linked to COVID-19.Fig 2(c) shows a standing patient for a chest posteroanterior (PA) view with relatively clean lungs, while a right parahilar interstitial infiltrate is present, representing indirect signs of air trapping. InFig 2(d), a lack of aeration can be seen in both lung fields, where it is impossible to specify the predominant pattern/infiltrate or a particular aetiology. These represent the worst-case scenarios in their respective cases, suggesting that the normal cases are less severe. In essence, the dataset displays a clear difference in disease severity between COVID-19, viral pneumonia, lung opacity, and normal chest X-ray images.\n\nThis work aims to find an original interpretable method to quantify the variability of tissue attenuation in chest X-ray images. The underlying idea is to assess the near dependencies among the image columns by calculating the large conditional indices. As mentioned, chest X-ray images of COVID-19, viral pneumonia, lung opacity, and normal cases are used for experimentation. For this purpose, a method composed of three stages is proposed (Fig 3). The first stage consists of applying the singular value decomposition to the X-ray image to obtain three parameters, namely the singular values (ζ), the conditional indices (η), and the variance-decomposition proportions matrix (Σ). In the second stage, a non-parametric empirical distribution is used as a dimension reduction of the variance-decomposition proportions matrixΣ. Next, the coefficient of variation based on the minimum covariance determinant is calculated from the bandwidth vector yielding a single weight. According to our hypothesis (see Introduction 1), this parameter represents tissue attenuation that leads to a near-collinearity phenomenon. It is used to tune the weight of the features from stage one. More precisely, the singular values and the conditional indices are multiplied by this weight to obtain our final feature vector. In the final stage, a classification scheme is used with this feature vector to distinguish COVID-19, viral pneumonia, lung opacity, and normal cases. These three stages are detailed in the following sections.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.g003\n\nLetbe the known chest X-ray image matrix, whereNis the number of rows considered here as the number of observations, andKis the number of columns viewed as the number of variables. By using the classical singular value decomposition (SVD) [31],Xcan be expressed as, where,,, andinclude the non-negative diagonal elements, representing the sorted singular values ofX.\n\nwithbeing the largest singular value, and. The conditional indices identify the number and strength of any near dependencies between variables and are given by\n\nwhere, and. Note that the largeris, the stronger the corresponding near-linear dependence.\n\nThe variance-decomposition proportions matrix, related toVandS, is given by\n\nwhereis a given variance parameter, and.\n\nComputing the SVD decomposition is the main computational cost component in the proposed method. When applied to large dimension  (M×N)  images, direct SVD decomposition is costly given itsO(MNmin⁡  (M,N) )  complexity. In this work, we used the augmented Lanczos bidiagonalization algorithm [32], implemented in the functionsvdsin MATLAB®. This algorithm computes the firstCsingular values with a complexity ofO(MNC) , hence reducing the complexity.\n\nThe scree plot [33] is a graphical representation of the eigenvalues against the component number, used to estimate the appropriate number of principal components to retain based on the elbow or break within its graph. Because the eigenvalues decrease monotonically from the first to the last value, a breaking point is created, though not in all cases, which suggests that the waveform begins to level off, seeFig 4. Note that this break or elbow allows choosing the number of significant components, and its dimensions can be estimated automatically using the profile likelihood function [34]. Components that appear before the break or elbow are assumed to be significant and are retained for data interpretation. In contrast, the components that appear after the break or elbow are assumed unimportant and are therefore not retained. Scree plots are helpful when there is an apparent significant deviation in the variation explained by the components [35]. For a comprehensive treatment of the scree plot, read [36,37].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.g004\n\nThe profile likelihood function is defined as follows. Letthep-dimensional vector that contains the ordered measurement of importance values or significant components, described as. The problem is determining how many components to retain according to the break or elbow on the waveform. Then, for a fixed number 1 ≤q≤p, if a break or elbow exists at positionq,, andare defined as independent samples from two different distributions, calledand, then the log-likelihood function under the naïve independence assumption can be written as\n\nFor any givenq, the maximum likelihood estimate ofandcan be obtained separately fromand. By plugging these estimates into Eq (4), a profile log-likelihood forqyields:\n\nComputingin Eq (5),qcan be estimated by maximizing the profile log-likelihood as\n\nAt this stage, we consider the distribution of the variance-decomposition proportions (i.e., the elements ofΣ). This matrix is reorganised into a vector. Letbe the density estimated from observed datax,\n\nwhereare considered random samples from the unknown distribution,K( . )  is the kernel smoothing function, andhis the smoothing parameter or bandwidth that controls the variance of the kernel.\n\nA Gaussian kernelK≈N( 0 ,h) , with zero mean and standard deviationh, was used to build a smoothing function to represent the probability distribution of the input data.\n\nThe smoothing parameter, or bandwidthh, determines how the probability associated with each observation [38] (i.e., in our case, proportion) is spread over the surrounding sample space. Assuming thatfis a normal density function, thenhcan be expressed as\n\nwherecan be estimated as follows [38],\n\nwithmaddenoting the median absolute deviation of the sample.\n\nLetthe dataset matrix, wherenstands for the number of observations andpfor the number of variables. The minimum covariance determinant (MCD) algorithm is a (uni)multi-variate location and scatter faster-robust-estimator [39]. The underlying idea of MCD is to findhobservations out ofn, such that, whose covariance matrix has the lowest possible determinant, therefore its mean (μ) and covariance (Σ) are given by\n\nThe parameter, called the consistency factor, has two targets. The first is to obtain consistency of the (uni)multi-variate normal distribution, and the second is to correct for bias at small sample sizes.\n\nThe parametersandare estimated from the elliptically symmetric unimodal distribution of the (uni)multi-variate data as follows\n\nwhereis the Mahalanobis distance,is a weight function withIas the indicator function,  ∗  denotes the complex conjugate,,is theα-quantile of the Chi distribution (), with, andhtaken such as  [ (n+p+ 1 ) ∕ 2 ] ≤h≤n. To comprehensively review the MCD analysis method, consult [39–42].\n\nThe coefficient of variation (CV) ratio, based on the MCD, indicates the covariance dispersion of data from the mean value. It is given by\n\nAs stated above, the experimental approach taken in this work is to differentiate COVID-19, viral pneumonia, lung opacity, and normal cases in chest X-ray images by identifying the near dependencies between the image columnsX. This identification is done by calculating the singular values and the associated large conditional indices following equations Eqs (1) and (2). Additionally, the variance-decomposition proportions (Σ)(Eq (3)) greater than a threshold of 0 . 5 are considered. These proportions are related to the groups of variables (i.e., image columns) involved in near dependencies. A single tuning weightωis introduced to improve the classification for these situations. Note thatis a vector of sizeM× 1 withMvalues greater than 0 . 5. To estimateω, the non-parametric empirical distribution is estimated (Sec. 2.2.3) for each variance-decomposition proportion, and the vectoris estimated following equations Eqs (8) and (9). The tuning weightωis then estimated as the coefficient variation based on the minimum covariance determinant Eq (12), denoted, of the univariate vectorh.\n\nThe resulting parameter feature vector is\n\nwhere 1 ≤k≤Ψ. Please note thatΨare the first most representative components. Because the number ofΨcomponents is not known in advance, the scree plot using the profile likelihood function is estimated; see Sect 2.2.2. Note that the elements of the vectorare in descending order, while the components of the vectorare in ascending order.\n\nThe ReliefF algorithm is used to select relevant texture features for classification. This algorithm is based on a filter-method approach [43]. It works by calculating a weightfor each feature. Given a dataset ofninstances ofpfeatures, the algorithm iteratively selects one random instance. It locates each class’s instanceclosest toand considers their feature vectors.\n\nInitially zero, the weightat iterationiis updated according to equations Eq (15) or Eq (16) depending on the class of:\n\nwith\n\nwhereandare the prior probabilities of the classes to which, andbelong, respectively;mis the number of iterations;is the difference of the value of the featurebetween observationsand;anddenote the value of the featurejfor the observationsandrespectively;is a distance function such as Euclidean;rank(r,q)  is the position of instanceqamong the nearest neighbours of the observationr, sorted by distance;kis the number of nearest neighbours;ϵis the distance scaling factor; note that for all nearest neighbours to have the same influenceϵ=∞. This feature weights procedure will allow us to assess the relative importance of the features used with our classification method. For a complete treatment of the ReliefF algorithm, read [44,45].\n\nThe final stage of our proposed method consists of using the feature vector developed above to classify X-ray images. The dataset used in this study is unbalanced. COVID-19 over normal cases has a ratio of 1:3, COVID-19 over viral pneumonia has a ratio of 3:1, and COVID-19 over lung opacity has a 1:2 ratio. The well-known ensemble learning method based on Bagged trees was considered for its good performance in various applications and for handling imbalanced data classes. The associated performance was evaluated according to the following metrics [46–48]: True Positive Rate (or recall, or sensitivity), False Negative Rate, Positive Predictive Values, False Discovery Rate, Area Under Curve, Accuracy Rate, and Total Cost. The execution time is given for comparison purposes based on a standard PC use.\n\nTo analyse the behaviour of the classification model and assess the effect of the two features on the predictions, we performed the partial dependence analysis. This technique is used in machine learning to interpret the relationship between a single feature (or a subset of features) and the model’s prediction. It helps to understand how the given feature (or subset of features) influences the predictions of the model while averaging out the effects of the other features. It consists of creating and interpreting partial dependence plots provided in Sect 3. The technique is utilised to understand feature importance and how they contribute to predictions. It is also essential to validate the behaviour of models in healthcare applications.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.g005\n\nLetf(Θ)  denote a predictive model, with the feature vector. For binary classification,f(Θ)  is the probability estimateP(y= 1 |x) . Letdenote a small subset ofΘ, with its complement, of size. The partial dependence betweenand the model’s output is defined as:\n\nwhereis the expectation taken over the marginal distribution ofin the dataset. In practice, given the discrete nature of the data,is computed as the average over all values of:\n\nForKclasses, the generalised partial dependence for classkis:\n\nEq21means that for each classk, the probability is marginalised over the complementary features to analyse howP(y=k)  varies with. We refer the reader to [19] for a comprehensive treatment of partial dependence analysis.\n\nIn our study,andK= 4. We calculated and displayed the partial dependence plots for each class to assess the effect of singular values and conditional indices on the model’s decision. We performed this analysis with and without applying the tuning weight. Results and discussion are provided in Sect 3.\n\nThis section reports the evaluation results of the proposed method using the previously introduced database. The dataset comprises chest X-ray images distributed as follows: 3 , 616 COVID-19, 1 , 345 viral pneumonia, 6 , 012 lung opacity, and 10 , 192 normal cases. Each chest X-ray image has a size ofN×K(whereN=K= 299). Images were converted to grayscale, retaining the luminance and eliminating the hue and saturation information.\n\nWe run two experimental scenarios. The first is without applying the tuning weights (scenario one), and the second is with the tuning weights (scenario two). For each scenario, the proposed features were used to train and test the classification model to discriminate between the four classes. For the first scenario, each image was reduced to two features. In the second scenario, the features were weighted using the tuning parameterω,. The scree plot method (see Sect 2.2.2) yields a boundary number ofΨ= 5, related to the first more representative singular values, seeFig 4. This leads to 10 features for each image, 5 times the two parameters:. Remember thatωis given by the coefficient of variation from the minimum covariance determinant of the smoothing parametersh(see Sects 2.2.3, 2.2.4, and 2.2.5). For illustration,Fig 5depicts the non-parametric distribution fitted to the variance-covariance matrix data. While the curves corresponding to the four classes appear very similar, they exhibit subtle variations that may not be visually perceptible. These variations are confirmed by the statistics of the smoothing parameterh(seeTable 2). Although minimal, these differences are sufficient for the ensemble model to capture class-specific characteristics. The parameterωamplifies these variations, enhancing the model’s ability to learn distinctive patterns for each class.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.t002\n\nBefore applying the classification, the ability of the features to discriminate the four classes was analysed.Fig 6shows the nonlinear scatter plots of the feature vectors over 105 , 825 observations.Figs 6(a) and6(d) show how the tuning weight parameter works. One can notice how the cases of normal (blue dots), COVID-19 (red dots), lung opacity (yellow dots), and viral pneumonia (purple dots) in the initial part, singular values () between 0 and 9 can be easily differentiated, as shown inFig 6(b). However, the cases are very close in the final part, as shown inFig 6(c). The feature vector(without the tuning weight) has the next bounds. The singular values (svd) are in the interval, while the conditional indices (idx) are in the interval. Large indices identify near dependencies among columns ofX. Therefore, the size of the indices is a measure of how near dependencies are to detecting all X-ray images under study, especially COVID-19. Thep-values were estimated by using the T-test method [49], withp-value= 0 . 0325 forζ, andp-value= 0 . 0001 forη, indicating high significance.Fig 7shows the rank importance of the predictors from the ReliefF algorithm. One can notice that the conditional indices are more representative concerning the singular values without the tuning weight parameterω, as seen inFig 6(b). All conditional indices can easily be differentiated for each case of study. However, singular values become more representative when applying the tuning weight parameter, as seen inFig 6(d). At first, the classes are even more separated, but in the end, the separation is optimal for all cases, especially COVID-19. Note that both conditional indices and singular values were rescaled. For illustration,Table 3shows the different thresholds for the two experimental scenarios (with and without the tuning weight parameter). The mean and standard deviation are high in the two scenarios for the COVID-19 class, which allows it to be used in a threshold detection scheme [50] to differentiate COVID-19 from the other classes under study.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.g006\n\n(a) Without the tuning weight parameterω. (b) With the tuning weight parameterω.\n\n(a) Without the tuning weight parameterω. (b) With the tuning weight parameterω.\n\nhttps://doi.org/10.1371/journal.pone.0320706.g007\n\nFor the classification stage, the dataset was randomly split into 90%(95 , 243 observations) for training and 10%(10 , 582 observations) for testing. The ensemble learning model, evaluated using 10-fold cross-validation, demonstrated promising results. Both experimental scenarios were assessed using standard performance metrics, including True Positive Rate (recall/sensitivity), False Negative Rate, Positive Predictive Value, False Discovery Rate, Area Under the Curve (AUC), Accuracy, and Total Cost. The confusion matrices, shown in the Supporting Information section inS1 Figfor the training andS2 Figfor the testing, indicate high performance across all classes with minimal false responses.S3 Figpresents the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) for both training and testing stages without the weight parameterω. All ROC curves exhibit high True Positive Rates and low False Positive Rates, with AUC values close to one for all classes. These findings suggest that the proposed model effectively distinguishes between the studied classes.\n\nTable 4summarises these results, highlighting that the False Negative Rate and False Discovery Rate remain low, while the tuning parameter substantially reduces the total cost.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.t004\n\nThe rescaled feature vector(i.e., multiplied by the tuning weight) improved the distinction between the four classes, especially COVID-19, as shown inFig 6(d). The tuning weightωwas found equal to  { 0 . 0142 ; 0 . 0173 ; 0 . 0143 ; 0 . 0161 } , respectively for the normal, COVID-19, viral pneumonia, and lung opacity classes. The singular valuesand the conditional indiceswere found in the ranges  [ 0 . 003 , 0 . 267 ]  and  [ 0 . 061 , 1 . 208 ] , respectively. The rescaling mapped the features onto a different scale, where the classes are better discriminated. This rescaling significantly improved the performance of the ensemble learning classifier.S4 FigandS5 FigFigs, in the “Supporting Information\" section, show the confusion matrices for training and testing, respectively. These results are aligned with the observed class separation shown inFig 6(d).\n\nFigs 8and9show the partial dependence plots of the two features, without and with the tuning weight. The curves show the effect of the features on predicting each class separately.Figs 8(a) and8(b) show the compared effect of the tuning weight with the conditional indices on the model’s behaviour. We can observe that the model has similar behaviour for conditional indices between 0 and 20 and their corresponding weighted values. In this range, the model favours the class “lung opacity\" (till index 8), then has more confidence in predicting “viral pneumonia\" (between 8 and 18), and then switches to predicting “COVID-19\" with high confidence (index around 18). However, after applying the tuning weight, the effect is obvious: the model predicts “COVID-19\" with high confidence and high probability, starting from the weighted value of 0 . 02. This observation aligns with our results, showing that the classification model with weighted features performs significantly better.\n\nSimilarly, when comparingFigs 9(a) and9(b), the model behaves similarly with and without the tuning weight for singular values between 0 and 4. The model first favours “COVID-19\" in this range with significant confidence. Then, it becomes more confident in predicting the “normal chest\" class with significant probability. However, with the weighted singular values, the model predicts the “normal chest\" class with high confidence and probability. Using the jointly weighted conditional indices and the weighted singular values, it appears clear that the model finds a combined pattern that allows it to differentiate the four classes and, more importantly, “COVID-19\" from “normal chest\".\n\nConsidering all the plots fromFigs 8and9, it is reasonable to hypothesise that using the four features together will be useful for learning complex image patterns. However, we did not test this hypothesis in this study, as the results were good with only the weighted features.\n\nThe x-axis values are the conditional indices in (a) and the weighted conditional indices in (b). Values of the y-axis are probabilities of predicting a class. For example, in (a), the probability of predicting COVID-19 is 0 . 9 when the conditional index is around 18. Curves show the variation of the probabilities of predicting each class depending on the values of the feature. Figure (b) shows that for values of the weighted conditional indices starting from 0 . 2, the model is highly confident in predicting COVID-19, with a high probability (more than 0 . 8).\n\nThe x-axis values are the conditional indices in (a) and the weighted conditional indices in (b). Values of the y-axis are probabilities of predicting a class. For example, in (a), the probability of predicting COVID-19 is 0 . 9 when the conditional index is around 18. Curves show the variation of the probabilities of predicting each class depending on the values of the feature. Figure (b) shows that for values of the weighted conditional indices starting from 0 . 2, the model is highly confident in predicting COVID-19, with a high probability (more than 0 . 8).\n\nhttps://doi.org/10.1371/journal.pone.0320706.g008\n\nThe x-axis values are singular values in (a) and weighted singular values in (b). Values of the y-axis are probabilities of predicting a class. For example, in (a), the probability of predicting COVID-19 is 0 . 9 when the singular value is around 0 . 40. Curves show the variation of the probabilities of predicting each class depending on the values of the feature. Comparing plots in (a) and (b), we notice that the behaviour of the model is similar in the range  [ 0 , 5 ] . However, Figure (b) shows that for the weighted singular values between  [ 0 . 005 , 0 . 010 ] , the model is highly confident in predicting normal chest, with high probability (close to 0 . 8).\n\nThe x-axis values are singular values in (a) and weighted singular values in (b). Values of the y-axis are probabilities of predicting a class. For example, in (a), the probability of predicting COVID-19 is 0 . 9 when the singular value is around 0 . 40. Curves show the variation of the probabilities of predicting each class depending on the values of the feature. Comparing plots in (a) and (b), we notice that the behaviour of the model is similar in the range  [ 0 , 5 ] . However, Figure (b) shows that for the weighted singular values between  [ 0 . 005 , 0 . 010 ] , the model is highly confident in predicting normal chest, with high probability (close to 0 . 8).\n\nhttps://doi.org/10.1371/journal.pone.0320706.g009\n\nIn texture analysis, the classification approaches are based on spatial localisation used in methods of edge detection and discrimination function features. Spatial localisation’s main challenge lies in the fact that it is difficult to distinguish the boundaries of the texture and the micro-edge found in the same texture. At the same time, the discrimination functions depend on the discriminative capacity of its texture characteristics. This way, the X-ray image class types can be defined based on anatomical or disease levels and include several cell and tissue types. This work specifically focuses on the characteristics given by singular values and conditional indices, which allows us to suggest that the features under study can be used for texture discrimination between different classes.Table 5shows some examples of classifiers and feature extraction for X-ray images. Remarkably, our method scores are higher than CNN-based deep learning methods, which are currently at the forefront of X-ray image classification. They generally outperform conventional feature-based methods but with higher computational costs. The reader is referred to [51–53] for a recent review about deep learning models for chest disease detection using X-ray images.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320706.t005\n\nThis work proposed an original method to classify chest X-ray images corresponding to different diseases, such as COVID-19, viral pneumonia, lung opacity, and normal. The proposed method is based on two features estimated using an SVD decomposition. These are the singular values and the condition indices. Traditionally, these parameters are used for multi-collinearity diagnosis in case of regression. This work uses them as features to characterise the image texture. In addition, we introduced a tuning weight parameter to consider the variability of the attenuation of X-ray tissues. This weight is estimated using the coefficient of variation of the minimum covariance determinant from the bandwidth of the non-parametric distribution of variance-decomposition proportions. The resulting features were used with an ensemble learning method to classify normal, COVID-19, viral pneumonia, and lung opacity X-ray images. Performance was assessed using True Positive Rate, False Negative Rate, Positive Predictive Values, False Discovery Rate, Area Under Curve, Accuracy Rate, and Total Cost. On average, the method achieved an accuracy of 88%without applying the tuning weight and 99%with it. This result suggests that the proposed method can be used as an efficient texture discriminator to characterise different tissues in X-ray images, especially in respiratory syndromes.\n\nIn addition to its excellent performance, the proposed method has a descent computational cost with imbalanced data, compared to current deep learning methods. Computer-based quantitative image texture analysis has an important potential to improve image interpretation by yielding reproducible results.\n\nThe proposed method’s main limitations are that it does not explicitly consider physiological and non-physiological artefacts, clutter, and ambiguities in the images, and it is difficult to deal with highly imbalanced data. In the medical context, there is a lack of clear definitions of biomedical texture information for validation and translation to routine clinical applications. There is also a lack of an appropriate framework for multiscale and multispectral analysis in 2D and 3D images. Computer-based quantitative imaging features can be challenging to interpret, as they can appear abstract to a physician, and their meaning in the clinical context may not be directly apparent.\n\nFuture work will focus on a more extensive evaluation of the proposed approach, the study of robust feature extraction methods using an approximation of the image by a sparse low-rank matrix [74–77]. Additional work can target image segmentation coupled with soft tissue decomposition to identify tissue-at-risk regions affected by COVID-19 and other respiratory pathologies, where all lung images exhibit patches. Also, it allows studying the taste receptors and their relationship with the walls of blood vessels in the lungs and the characterization of acute respiratory distress syndrome (ARDS) [78].\n\nhttps://doi.org/10.1371/journal.pone.0320706.s001\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0320706.s002\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0320706.s003\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0320706.s004\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0320706.s005\n\n(PDF)\n\nTo reproduce these results, please use:https://github.com/tonioquinterorincon/Computer-based-quantitative-image-texture-analysis-using-multi-collinearity-diagnosis-in-chest-X-ray\n\nThe authors are grateful to the Faculty of Engineering and Agricultural Sciences at the Pontifical Catholic University of Argentina (UCA) for providing financial support for the publication of this work.",
    "category": "materials_science"
  },
  {
    "title": "Empirical estimation of Young’s modulus for biological tissue mimics using acoustic impedance measurements: A study on agar gel tissue phantoms",
    "authors": "Shinri Morodomi, Kazushi Ito, Satoru Maegawa, Yoshihiro Ujihara, Shukei Sugita, Masanori Nakamura, (PLOS)",
    "publish_date": "2025-04-14",
    "doi": "https://doi.org/10.1371/journal.pone.0320705",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320705",
    "content": "The mechanical properties of biological tissues are significant biomarkers for diagnosing various diseases. The aim of this study was to develop an empirical formula to estimate Young’s modulus from the acoustic impedance measured by scanning acoustic microscopy. Agar, a material with mechanical properties similar to those of biological tissues, was prepared at concentrations ranging from 5% to 20%. The acoustic impedance was measured by scanning acoustic microscopy, and Young’s modulus was determined via indentation testing. The results showed that both the acoustic impedance and Young’s modulus increased with agar concentration. Theoretical models did not accurately describe the relationship between the acoustic impedanceZand Young’s modulusE; however, the empirical formula(withEin Pa andZin Ns/) provided a better fit. This formula could potentially be used to estimate Young’s modulus for biological tissues, aiding in the realistic analysis of stress fields and understanding the etiology of various diseases.\n\nCitation:Morodomi S, Ito K, Maegawa S, Ujihara Y, Sugita S, Nakamura M (2025) Empirical estimation of Young’s modulus for biological tissue mimics using acoustic impedance measurements: A study on agar gel tissue phantoms. PLoS ONE 20(4):\n           e0320705.\n        \n        https://doi.org/10.1371/journal.pone.0320705\n\nEditor:Pawel Klosowski, Gdańsk University of Technology, POLAND\n\nReceived:November 14, 2024;Accepted:February 23, 2025;Published:April 14, 2025\n\nCopyright:© 2025 Morodomi et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and its Supporting information files.\n\nFunding:This study was supported by the Japan Society for the Promotion of Science (JSPS) KAKENHI (JP22H00584 and JP24K22389 to M.N. and JP23H03855 to Y.U.) from the Ministry of Education, Culture, Sports, Science and Technology (MEXT), Japan, and Japan Agency for Medical Research and Development (AMED), JK240100 to M.N. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe mechanical properties of biological tissues are important biomarkers of health and pathological conditions in various diseases [1]. Measuring the mechanical properties of biological tissues, such as their density and elasticity, has valuable diagnostic applications. For instance, Yeh et al. [2] reported liver stiffness increased with fibrosis severity and showed the potential clinical value of ultrasonic elasticity imaging for assessing fibrosis severity. Krouskop et al. [3] demonstrated that breast carcinomas, particularly infiltrating ductal carcinomas, were significantly stiffer than other tissues at high strain levels, and highlighted the potential of elastography to differentiate tissue types based on stiffness, with implications for diagnosing breast and prostate pathologies. Lin et al. [4] revealed that patients with later stages of chronic kidney disease had stiffer kidneys, and thus concluded that renal elasticity is associated with proteinuria and rapid renal deterioration in patients with chronic kidney disease.\n\nVarious experiments methods are used to determine mechanical properties of biological samples. The tensile test is the most common method [5]. In this test, both ends of a sample are gripped, and it is pulled until it breaks or reaches a defined strain. Although biological tissues are typically inhomogeneous, viscoelastic materials that exhibit nonlinear stress–strain behavior, a linear elastic model described by Young’s modulus and Poisson’s ratio is generally used for representing the overall mechanical characteristics of a sample of interest. A uniaxial tensile test is a well-established and standardized method, making it easy to perform and interpret. For heterogeneous materials with potential directional dependencies (anisotropy), the uniaxial tensile test can reveal variations in mechanical properties along different axes. It also provides apparent mechanical properties of the material, which are often sufficient to understand its macroscopic characteristics. A “biaxial tensile test” applies tension in two directions on the specimen at once, providing a more comprehensive understanding of the material’s behavior under complex loading conditions. One of the limitations of the biaxial testing lies in the need of specialized testing machines with precise control over loads and displacements in multiple directions. Furthermore, stress concentrations and boundary effects near grips can lead to non-uniform strain fields outside the central region and near the gripping part, complicating data interpretation [6,7]. Digital image correlation (DIC) is a non-contact optical technique that measures surface deformation by tracking image patterns, suitable for delicate or heterogeneous materials. While DIC is versatile and compatible with various mechanical tests, its accuracy depends on high-quality speckle patterns, lighting, and camera systems, limiting its use for relatively small-scale measurements [8]. Compression tests, which evaluate material behavior under compressive loads, are straightforward and adaptable but require precise specimen preparation to ensure accuracy [9]. Atomic force microscopy (AFM) has emerged as a method for quantifying mechanical properties at the nanoscale [10]. AFM can achieve a vertical subnanometer resolution and a lateral resolution of a few nanometers, but it requires a large amount of time to measure large surfaces. Because of this limitation, care must be taken to avoid sample dehydration during measurements that are not performed under liquid conditions. Moreover, the scanned area is relatively limited; output images have lengths on the order of 0.1 mm. Additionally, the probe must be changed for each measurement or sample to avoid contamination, making AFM costly. Parameter setting is difficult for inexperienced operators although some machines perform this function automatically. These difficulties make AFM unsuitable for evaluating the mechanical properties of biological tissues with a large surface area. Micropipette aspiration measures mechanical properties of small, soft materials like cells by applying suction pressure and analyzing deformation [11]. Although effective for studying individual cells, it is time-consuming and requires skilled operators for precise pipette handling and alignment. Other than these mechanical loading tests, some studies employ microfluidics-based techniques to characterize stiffness of samples [12,13]. Compared with traditional mechanical loading tests, the microfluidics-based techniques have high throughput, but are weak in the accurate quantification of mechanical properties. Furthermore, it is basically limited to small samples, exclusively to cells and difficult to apply for tissues.\n\nNumerical analyses also play an important role in characterizing mechanical properties of materials. The finite element method (FEM) is a numerical technique used to solve complex problems in engineering and physics. FEM can model how materials deform under various loads (e.g., tension, compression, shear). The combination of FEM and inverse problems is particularly powerful for material characterization. Olson et al. developed computational techniques that use surface force measurements to create three-dimensional stiffness maps of breast tissue, aiming to refine and automate manual breast exams [14]. Odin et al. presented a method for determining the mechanical properties of mandibular bone using inverse analysis [15]. Moreover, Zhang et al. used the optimization method combined with FEM to inversely determine the mechanical properties of the iris in vivo based on [16].\n\nScanning acoustic microscopy (SAM) uses ultrasound signals to image the speed of sound in and the acoustic impedance of samples. The scanning area of SAM is on the order of several square millimeters. The acoustic impedance mode of SAM provides data on the local distribution of acoustic impedance in a cross section of the sample without requiring slicing. Owing to these advantages, SAM has been used to evaluate the acoustic properties of both soft and hard tissues. Saijo et al. [17] reported that the speed of sound in an atherosclerotic lesion is higher than that in unlesioned intima. Strohm and Kolios [18] scanned MCF7 breast cancer cells with SAM to characterize their acoustic properties. Hasegawa et al. [19] compared the acoustic velocity of biopsied iliac bones from normal and osteoporotic subjects and reported altered elasticity in the latter. Hatori et al. [20] applied SAM to dentistry to analyze the speed of sound in rat periodontal ligament at various developmental stages and demonstrated that it increases over the course of development. Although these studies demonstrate acoustic differences between normal and pathological tissues or cells, interpreting the corresponding differences in their mechanical properties remains challenging. If Young’s modulus could be derived from the acoustic impedance measured by SAM, it would enable the effective mapping of Young’s modulus across biological tissues using SAM. This approach would be especially advantageous for measuring relatively large sample areas.\n\nThe aim of the present study is therefore to establish an empirical formula that determines Young’s modulus from the acoustic impedance obtained by SAM. For this purpose, we measured the acoustic impedance and Young’s modulus for agar at different concentrations to characterize the relationship between them.\n\nAgar is a useful material for replicating the physical properties of human soft tissue because it has similar mechanical properties that can be adjusted based on concentration [21–24]. By adjusting the agar concentration, it is possible to create materials with various Young’s moduli in a range similar to that for biological tissues [25]. In the present study, agar samples were prepared at four different concentrations, ranging from 5% to 20% in 5% increments, relative to the weight of distilled water.Fig 1exhibits agar samples at these concentrations. Five samples were made for each concentration. Distilled water (10 mL) produced by an ultrapure water production system (Direct-Q UV 3, Yamato Scientific Co., Ltd.) was vacuum degassed for more than an hour using a vacuum degassing machine (VD, AS ONE Corporation, DA-20D, ULVAC KIKO, Inc.). Agar powder (01059-85, Nacalai Tesque, Inc.) was added to the vacuum-degassed distilled water, heated, and dissolved. The dissolved agar was poured into a 35 mm dish (150460, Thermo Fischer Scientific Inc.) and refrigerated until it solidified. The dish was treated with a hydrophilic treatment by irradiating it with an excimer lamp for 15 min.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.g001\n\nThe acoustic impedance of the agar was measured with a scanning acoustic microscope (AMS-50AI, Honda Electronics Co., Ltd.).Fig 2shows a schematic of the experimental setup. The agar sample to be measured was placed on the stage above a transducer with a center frequency of 80 MHz (HTD80-2025, Honda Electronics Co., Ltd.), which radiates an acoustic signal and receives the reflected signal. Distilled water was used as the coupling fluid between the dish and the transducer. The sample was scanned in thex- andy-directions with aid of a mechanical stage to obtain the acoustic impedance distribution of the sample. The measurement area was 4.8 mm × 4.8 mm, and scans were obtained with a resolution of 300  ×  300 pixels in this area.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.g002\n\nTo calculate the acoustic impedance of the agar, the acoustic impedanceof the substrate and thatof a reference material with a known acoustic impedance needed to be set.was set to 2.37 MNs/to match that of the material of the dish bottom (polystyrene) [26].\n\nDistilled water was used as the reference material to set. The sound speedcand densityρfor the distilled water were estimated from the water temperature measured with a thermometer (3003XT101B, BOMATA) based on existing literature [27–30]. The acoustic impedanceof the reference material was then determined from\n\nwhereZis equal to.\n\nThe acoustic impedanceZof the agar samples was measured after the samples had been stored at room temperature for a sufficient time. Measurements were conducted four times for each sample. The acoustic impedance in the measurement area was averaged to obtain a representative value for each measurement.\n\nYoung’s modulus for the agar sample was measured with a custom-made indentation tester.Figs 3and4present a photo and a schematic of the indentation tester, respectively. The indentation tester consists of a micro-force sensor (THK Precision Co., Ltd), a stylus (DM45505, Tokyo Seimitsu Co., Ltd.) fixed to the sensor and a Z-stage (KHE06008-CH, Suruga Seiki Co., Ltd.). The stylus is supported by a leaf spring (THK Precision Co., Ltd) installed inside the sensor. When a force is applied to the stylus, the leaf spring bends, causing the stylus to move vertically.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.g004\n\nThe bridge voltage signal from the strain gauge attached to the leaf spring is amplified by a sensor amplifier (FSA202S, THK Precision Co., Ltd.), and the amplified voltageVis recorded with an oscilloscope (DL850, Yokogawa Electric Co., Ltd.).\n\nThe magnitude of the received forceFwas calculated from the recorded voltageVas\n\nwhereλis a coefficient that was provided by the company that manufactured the strain gauge (THK Precision Co., Ltd.). Given the forceF, the deflection of the springδcan then be obtained as\n\nwherekis the stiffness of the spring. Finally, the indentation depthdfor the stylus is calculated as\n\nIn the experiments, the specimen placed on the stage was raised by the Z-stage controlled via a stepping motor (PK523HPB-C17, Oriental Motor Co., Ltd.) at a rate of 10 µm/s such that the specimen was quasi-statically indented with the stylus. The parameter values used wereN/V andN/µm, provided by a manufacturer of the micro-force sensor (THK Precision Co., Ltd).\n\nEach sample was indented at 20 different locations using a stylus with a tip radiusRof 25 µm. Young’s modulusEwas determined from the relationship between the fitting forceFand the indentation depthdusing Hertz’s contact theory described as\n\nwhereνis Poisson’s ratio. (Eq 5) was fit to the measurement data for an indentation depth range of 0–3 µm using MATLAB R2023a (9.14.0.2254940, MathWorks). Poisson’s ratioνfor the agar sample was assumed to be 0.499, indicating its incompressibility.\n\nTheoretically, Young’s modulusEis described as a function of the acoustic impedanceZas follows. According to the wave equation, the sound speedcis given by\n\nwhereKis the bulk modulus. If the sample is an isotropic linear material,Kcan be expressed as\n\nusing Young’s modulusEand Poisson’s ratioν. Thus, combining (Eq 1), (6), and (7) yields the relationship between the acoustic impedance and Young’s modulus as\n\nwhereαis the coefficient ofto be determined by fitting (Eq 8) to the experimental data.\n\nIn the present study, we also used the empirical formula\n\nto express the relationship between the acoustic impedance and the Young’s modulus, because (Eq 8) did not accurately represent the data, as shown in the following section. Here,αandβare constants to be determined by fitting.\n\nFig 5shows color-coded acoustic impedance images for agar samples prepared with different concentrations. The acoustic impedance of the agar appeared mostly uniform within the measurement area. As the agar concentration was increased from 5% to 20%, the acoustic impedance of the sample increased.Fig 6shows the average acoustic impedance of each sample plotted against its concentration.Table 1presents mean ± SD of the acoustic impedance of the samples. The acoustic impedance increased monotonically with agar concentration.\n\n(A) 5%, (B) 10%, (C) 15%, and (D) 20%. Bars: 1 mm.\n\n(A) 5%, (B) 10%, (C) 15%, and (D) 20%. Bars: 1 mm.\n\nhttps://doi.org/10.1371/journal.pone.0320705.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.t001\n\nFig 7shows representative force–indentation depth plots. As the agar concentration was increased, the reaction force against indentation by the stylus increased. The red lines inFig 7show the results of fitting using (Eq 5) to the force-indentation depth data, demonstrating a good fit.Fig 8shows Young’s modulus obtained by fitting (Eq 5) to the force-indentation depth data for each sample, which is seen to increase monotonically with agar concentration.Table 2presents mean ± SD of the Young’s modulus of the samples in numerical form.\n\n(A) 5%, (B) 10%, (C) 15% and (D) 20%. Lines were obtained by fitting () to the data.\n\n(A) 5%, (B) 10%, (C) 15% and (D) 20%. Lines were obtained by fitting () to the data.\n\nhttps://doi.org/10.1371/journal.pone.0320705.g007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320705.t002\n\nFig 9shows Young’s modulus plotted against the acoustic impedance, with both quantities averaged for each sample. A least-squares regression analysis demonstrated that (Eq 8) (blue line) did not account well for the experimental data (R2= 0.22). In contrast, (Eq 9) (red line), with an added bias term, accurately represented the measurement data (= 0.90). The obtained equation was\n\nBlue line: obtained by fitting (Eq 8),. Red line: obtained by fitting (Eq 9),.\n\nBlue line: obtained by fitting (Eq 8),. Red line: obtained by fitting (Eq 9),.\n\nhttps://doi.org/10.1371/journal.pone.0320705.g009\n\nwhere the units ofEandZare Pa and Ns/, respectively.\n\nIn this study, we measured the acoustic impedance and Young’s modulus for agar at concentrations ranging from 5% to 20% and examined the relationship between them. The fitting results using (Eq 8) showed that it did not accurately describe the measured data. (Eq 9), however, yielded a good fit. The use of (Eq 9) would enable Young’s modulus to be calculated from the acoustic impedance measured by SAM.\n\nAlthough there is a theoretical basis for (Eq 8), which describes a quadratic relationship between the acoustic impedance and Young’s modulus, the introduction of a bias term in (Eq 9) was necessary to obtain a good empirical model for our data. In the present study, the estimated bias termβwas  − 21.6347 MPa; such a negative intercept is unrealistic if we take into account that Young’s modulus for a material with zero acoustic impedance would equalβ. At present, it remains unclear why adding this term to the theoretically described equation was necessary to obtain a good fit. Although (Eq 9) aligns with the theory in a sense that the Young’s modulus increases quadratically with acoustic impedance, it is important to bear in mind that (Eq 9) is an empirical equation that has only been demonstrated for an acoustic impedance range of 1.54-1.74 MNs/.\n\nAccording to (Eq 8), Poisson’s ratio for agar can be estimated from the coefficientαunder the assumption that the densityρof agar is 1000 kg/. As seen in Supporting Information (S1 Fig,S1 Table), the density of agar samples was approximately 1000 kg/and did not vary significantly across the 5% to 20% concentration range (one-way ANOVA,p= 0.79). Extending this relationship to Eq (9) yields a Poisson’s ratio of 0.498, which agrees with the assumed value in the indentation test. This indicates that the empirical formula obtained is valid in terms of the value of Poisson’s ratio.\n\nThe acoustic impedance measured in this study ranged from 1.54 to 1.74 MNs/, and Young’s modulus from 0.57 to 7.19 MPa. The acoustic impedance of aneurysmal aortic regions has been reported to range from 1.48 to 1.65 MNs/[31]. Young’s modulus for elastin and smooth muscle cells, the major components of blood vessels, is generally in the range of 0.1-2.0 MPa [32]. The measured ranges of the acoustic impedance and Young’s modulus in this study approximately encompass those for vascular tissues, suggesting the potential to calculate the Young’s modulus distribution of vascular tissues using the derived equation.\n\nIn this study, the acoustic impedance and Young’s modulus of agar were measured at different locations. As the acoustic wave emanated from the bottom of the dish, the measured acoustic impedance was for the bottom of the sample. In contrast, Young’s modulus was measured with the indentation tester at the top surface of the sample. For confirmation, we measured Young’s modulus for one agar sample at both the top and bottom surfaces and found no significant difference between the two. Therefore, it is considered acceptable to correlate the acoustic impedance at the bottom surface of the agar with Young’s modulus measured at the top surface.\n\nIn looking atFig 6andFig 8, we found that the Young’s modulus of agar exhibited greater variation compared to the acoustic impedance, which can be attributed to two primary reasons. Firstly, the error associated with contact determination in the indentation test plays a significant role. The Young’s modulus was calculated using Hertz’s contact theory applied to the force-indentation curve, starting from a manually determined contact point. This manual selection introduces variation in the calculated Young’s modulus, whereas the acoustic impedance measurement using SAM does not involve such manual steps, resulting in more consistent acoustic impedance values. Secondly, the effect of surface drying of the agar during the indentation test contributes to the variation. The upper surface of agar exposed to air is prone to drying, making it brittle and potentially leading to variations in the Young’s modulus or causing the indenter tip to penetrate the brittle surface. In contrast, the SAM-based acoustic impedance measurement is performed on the bottom surface of the agar in the dish, which is not exposed to air, thereby minimizing the drying effect. These factors collectively explain why the Young’s modulus of agar shows greater variation compared to the acoustic impedance.\n\nWe used a transducer with a center frequency of 80 MHz. The spatial resolution of SAM is dependent on the center frequency, and an 80 MHz transducer provides a spatial resolution of approximately 20 µm [33]. Higher-frequency transducers provide a finer spatial resolution. Reportedly, a 320 MHz transducer would allow the measurement of the acoustic impedance of intracellular components [34]. However, to evaluate the mechanical properties at the vascular tissue scale, the transducer used in this study would be sufficient.\n\nStudies using finite element analysis to determine the stress field within the blood vessel walls often define uniform material properties for the vascular model [35,36]. However, real blood vessels are composed of multiple materials such as smooth muscle cells, elastin, and collagen, each with a different Young’s modulus, and thereby show spatially heterogeneous mechanical characteristics [37]. Some studies proposed a hypothesis that abnormal stresses within vascular tissues trigger the onset and progression of vascular diseases [38,39]. Functionally graded materials (FGMs), which exhibit spatially varying properties, offer a more realistic approach by mimicking the natural heterogeneity of vascular tissues. Research on FGMs, such as stress analysis in functionally graded thick-walled cylinders [40–42], demonstrates their potential to improve stress distribution modeling in vascular walls. Integrating FGM models with advanced techniques like scanning acoustic microscopy (SAM) can provide detailed maps of local mechanical properties, enabling more precise stress analysis and insights into vascular disease mechanisms. This approach holds promise for advancing the diagnosis and treatment of vascular pathologies by better capturing the mechanical complexity of blood vessels.\n\nPrevious studies investigating Young’s modulus for agar [25,43,44] have reported values up to concentrations of approximately 5%. Li et al. [25] measured Young’s modulus for agar at concentrations from 0.5% to 5% using a laser-generated surface acoustic wave phase velocity dispersion technique and reported that it increases quadratically with concentration. Young’s modulus for 5% agar obtained in the present study (0.57-1.1 MPa) was similar to the value of 1.3 MPa reported by Li et al. [25]. Extrapolation of their results, however, implies that Young’s modulus for 20% agar is approximately 27 MPa, equivalent to that for electrospun tubular scaffolds [45]. The measurements in the present study demonstrated that Young’s modulus for an agar concentration of 20% was approximately 7 MPa, about a quarter of what would be estimated by extrapolating the results of Li et al. [25]. Such a discrepancy suggests that while Young’s modulus for agar increases quadratically with concentrations up to 5%, this trend does not continue when the concentration is extended to 20%.\n\nAgar with a concentration above 5% is considered brittle [46]. It is difficult to measure Young’s modulus for brittle materials using mechanical loading tests such as tensile and compression tests because the samples are easy to break. The SAM-based method proposed in this study can measure Young’s modulus without applying any external force, providing a way to characterize the mechanical properties of relatively brittle materials such as mineralized tissues.\n\nThe stress-strain relationship in soft tissues is typically characterized by nonlinear behavior. However, it remains poorly understood how such material-specific nonlinear mechanical properties influence acoustic impedance. As an initial step toward elucidating how the mechanical properties of biological soft tissues are reflected in acoustic impedance, this study employed a simplified linear elastic model to investigate the relationship between acoustic impedance and Young’s modulus at zero strain. While the assumption of linear elasticity may not fully capture the mechanical complexity of soft tissues, it remains a widely utilized approach in finite element analyses of biological materials [35,36]. Although the stress and strain values derived under this assumption may lack quantitative accuracy, they provide a sufficient basis for qualitative interpretation of the underlying phenomena. The applicability of the empirical formula derived in this study under conditions of applied strain remains uncertain. Future work will focus on examining the relationship between acoustic impedance and Young’s modulus in agar under varying strain conditions to further assess the potential utility of ultrasonic microscopy in characterizing soft tissue mechanics.\n\nIn this study, an empirical formula was successfully derived to estimate Young’s modulus from the acoustic impedance measured by SAM, demonstrating a high correlation (= 0.90) and encompassing ranges typical of vascular tissues. This represents a significant step forward in non-invasive mechanical characterization, offering a practical and efficient alternative to conventional methods like AFM. The formula enables the analysis of brittle materials such as high-concentration agar, which are challenging to test with traditional mechanical approaches, and aligns with reported values for biological tissue mimics. However, the model’s reliance on an empirical bias term raises questions about its theoretical underpinnings, and its applicability is currently limited to homogeneous agar samples and a specific acoustic impedance range (1.54-1.74 MNs/). Additionally, while the resolution provided by the 80 MHz transducer is sufficient for vascular tissue analysis, it may not be suitable for finer biological features. Future studies should focus on addressing these theoretical and material-specific limitations, extending the model’s applicability to heterogeneous tissues, and validating it across diverse biological contexts.\n\nStatistical analysis was conducted with one-way analysis of variance (ANOVA). No significant difference was found in the density of samples across the 5% to 20% concentration range (p= 0.79).\n\nhttps://doi.org/10.1371/journal.pone.0320705.s001\n\n(TIF)\n\nDensity of agar samples,ρ[kg/]\n\nhttps://doi.org/10.1371/journal.pone.0320705.s002\n\n(PDF)\n\nWe thank Dr. Kazuto Kobayashi and Ms. Yuki Kawaguchi for their technical support for SAM.",
    "category": "materials_science"
  },
  {
    "title": "Personalized customization: Service resource configuration optimization driven by customer requirements accurately",
    "authors": "Chao Yu, Haibin Wang, (PLOS)",
    "publish_date": "2025-04-14",
    "doi": "https://doi.org/10.1371/journal.pone.0320312",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320312",
    "content": "Proposing an approach of service resource configuration optimization driven by customer requirements to address the issue of service resource configuration optimization in the context of personalized customization. Firstly, the importance judgment matrix, KANO model, and competitiveness evaluation are integrated to evaluate the relative importance of customer requirements. Secondly, the House of Quality (HoQ) and the intermediary variable “technical attributes” are utilized to determine the weight of each service module and its correlation with customer requirements. Afterwards, due to the varying customer requirements, the service candidate itemsets under the same service module will differ. To address this, a “one-to-many” relationship mechanism is introduced between the service module and service candidate itemsets. The service candidate itemsets are determined based on the correlated customer requirements. On this basis, the customer’s perceived utility is determined by applying the four types of utility measure functions. The service resource configuration scheme is established by formulating and solving an optimization model. Finally, the viability and efficacy of the approach are demonstrated with an example of living room customization by a customization company, utilizing an improved genetic algorithm (IGA).\n\nCitation:Yu C, Wang H (2025) Personalized customization: Service resource configuration optimization driven by customer requirements accurately. PLoS ONE 20(4):\n           e0320312.\n        \n        https://doi.org/10.1371/journal.pone.0320312\n\nEditor:Sivakumar Poruran, Dr NGP Institute of Technology (A Unit of Kovai Medical Center and Hospital), INDIA\n\nReceived:September 19, 2024;Accepted:February 18, 2025;Published:April 14, 2025\n\nCopyright:© 2025 Yu. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:Funding statement: This work was supported in part by the Liaoning Provincial Social Science Planning Fund [L21CGL021].\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nIn the current era of personalized customization, the market has shifted towards a “buyer’s market,” where customer diversity and personalized requirements are increasingly prominent. This poses significant challenges for traditional manufacturing companies, as they must balance the contradiction to meet individual customer requirements while also delivering products quickly and cost-effectively. To address this, enterprises must shift away from the traditional production mindset of “factory to customer” and instead adopt a “user-driven” approach to personalized production. This shift from product-oriented to service-oriented enterprises has become an inevitable trend in enterprise development [1]\n\nThe C2B2M business model based on mass customization is a business model that carries out mass customized production according to customer requirements, from customers to enterprises to factories. It is a business model supported by modern information technology and based on massive customer requirements through modular design and parts standardization to improve customer satisfaction with personalized requirements and improve the service efficiency of enterprise production [2]. The essence of mass customization is to identify the individualized requirements of customers and offer a tailored service resource configuration scheme. One of its core contents is service resource configuration optimization [3].\n\nTo begin with, service requirements analysis, as the source of service resource configuration optimization, mainly includes acquiring, categorizing, and evaluating service requirements. Based on this analysis, the relationship between service requirements and technical attributes or service modules is established [4]. Among them, service requirements importance evaluation has always been an important part of studying service requirements. Accurately evaluating the importance of customer requirements and establishing their priority accordingly can enhance the correlation of the service resource configuration scheme with the actual customer requirements. Hence, the matter of precisely acquiring the requirements of each customer and evaluating their importance remains deserving of consideration.\n\nFurthermore, what requires attention is that various service resource configuration schemes will exhibit varying levels of performance in satisfying customer requirements. This directly impacts customer satisfaction with the service resource configuration schemes and subsequently influences the company’s revenue [5].\n\nAccurate correlation and matching between service resources and customer requirements are essential to the service resource configuration scheme. Typically, customers will have specific expectations and requirements for service resource configuration scheme based on their individual circumstances. These expectations and requirements will serve as criteria to evaluate their satisfaction with the service resource configuration scheme and the level of satisfaction they experience. Simply speaking, customers’ perceived utility of configuration schemes will vary depending on the scheme [6]. Recent research has demonstrated that employing modular design for service resource configuration schemes is an efficient approach to addressing this issue [7].\n\nThe service resource configuration scheme matches customer requirements through the correlation of service modules and customer requirements. This ensures that customer expectations are met to the fullest extent and maximizes the customer’s perceived utility under certain constraints. Hence, in the process of service design, it is imperative to take into account the match of each service module with customer requirements in the service resource configuration scheme. However, in conventional research, there is typically a one-to-one relationship mechanism between service modules and their candidate itemsets. In this case, if a service module is correlated with multiple requirements, a situation may occur where the candidate itemset exhibits a high level of matching when connected with one requirement but lacks sufficient matching when correlated with another requirement. Consequently, the service resource configuration scheme has challenges in accurately and objectively fulfilling customer requirements and preferences.\n\nPresently, introducing a “one-to-many” relationship mechanism between the service module and its candidate itemset will effectively improve or resolve this issue.Fig 1provides a detailed example illustrating the concept of service modules and their candidate itemsets within the service resource configuration framework, as well as their “one-to-many” relationship mechanism. The Air Conditioner, functioning as a service module, will choose suitable candidate items from its various candidate itemsets to fulfill different customer requirements. Ultimately, it will generate a candidate item configuration scheme for the Air Conditioner. Thus, how to extract customer requirements and evaluate the importance of customer requirements, modularize the service resource configuration scheme, divide the candidate itemsets under the module, establish the corresponding relationship between the service module and the candidate itemset, and then realize an effective correlation between the service module and the customer requirements, and on this basis, the issue of supporting or assisting service-oriented enterprises in effectively optimizing the service resource configuration scheme is also worthy of attention.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g001\n\nConsidering the circumstances, the objective of this article is to present a service resource configuration optimization method driven by customer requirements. This method employs a combination of the importance judgment matrix, the KANO model, and competitiveness evaluation to quantitatively evaluate the importance of consumer requirements. On this basis, we apply the House of Quality of QFD and integrate it with the intermediary variable “ technical attributes” to evaluate the importance of each service module and the relationship between the service module and customer requirements. Afterward, it is considered that the candidate itemsets within the same service module would vary when the service module is correlated with different customer requirements. Consequently, the different service candidate itemsets associated with the customer requirements under the service module are defined. Next, the customer’s perceived utility is computed using the four types of utility measure functions. Additionally, we determine the service resource configuration scheme by formulating and solving the optimization model. Finally, taking the living room customization by a customization company as an example and using the improved genetic algorithm (IGA) to illustrate the feasibility and effectiveness of the method.\n\nThe subsequent parts of this article are arranged as follows: Section 2 briefly reviews the relevant literature on research regarding service resource configuration optimization methods. Section 3 describes the service resource configuration optimization issues studied in this article and defines parameters; Section 4 explains the basics of service resource configuration optimization based on customer requirements, and calculation steps; Section 5 is an introduction to the improved genetic algorithm(IGA); Section 6 is a case analysis and algorithm comparison; and finally, Section 7 is the conclusion of the full article.\n\nCurrently, the available research has made progress in the field of service resource configuration optimization. However, there is a scarcity of studies that consider the “one-to-many” relationship mechanism between service modules and their candidate itemsets. Prior study findings often center around three key areas: analysis of service requirements, modularization and processing of service resources, and configuration of service resource schemes. The specific results of relevant research are as follows:\n\nIn terms of service requirement analysis, customer requirements have always been the source of corresponding resource configuration analysis in service resource configuration optimization. We must fully acquire, categorize, screen, and evaluate customer requirements to ensure that the provided service resource configuration scheme meets them more efficiently. In contrast to conventional methods of requirement acquirement, such as questionnaires and telephone interviews, Wang et al. [8] proposed a graph-based context-aware requirement elicitation approach considering contextual information within the Smart PSS to extract implicit stakeholder requirements within a specific context. Ali et al. [9] proposed a social network service-based requirement engineering process. It considers the attributes of users’ opinions to determine variability and commonality. Chen et al. [10] proposed a hybrid framework integrating the rough-fuzzy best-worst method to identify and prioritize the customer activity-oriented service requirements for a smart product service system. Kayapinar et al. [11] proposed a service-quality approach connected with SERVQUAL and fuzzy QFD to determine customers’ requirements and then presented the FMODM for prioritizing design characteristics to minimize the technical difficulty and maximize the total weights of technical design requirements. Bi et al. [12] proposed a method for modeling customer satisfaction from online reviews. In the method, customer satisfaction dimensions (CSDs) are first extracted from online reviews based on latent Dirichlet allocation (LDA). The sentiment orientations of the extracted CSDs are identified using a support vector machine (SVM). Then, proposed an ensemble neural network-based model (ENNM) to measure the effects of customer sentiments toward different CSDs on customer satisfaction. Bi et al. [13]proposed an ensemble deep learning method for forecasting daily tourism demand for tourist attractions with big data to fully capture the relationship between these forecasting variables and actual tourism demand automatically. Jin et al. [14] proposed a method for mining online reviews with a Kansei-integrated Kano model for innovative product design. Enlightened by the Kano model, product features are prioritized based on affective emotions to show their importance to customer satisfaction. Aydin et al. [15] proposed a sustainable linear programming (LP)-based Quality Function Deployment methodology under the IVIF environment. The proposed method determines more accurate customer expectations and related service requirements. Sun et al. [16] proposed a Customer-Manufacturer-Kano (CM-Kano) model to analyze the ever-changing opinions of customers and manufacturers to provide improvement strategies for product design. Zhou et al. [17] proposed a framework of user experience-oriented smart service requirement (UXO-SSR) analysis for smart product service system development, which can provide an effective tool for acquiring the UX requirements of smart PSS from a holistic perspective.\n\nIn terms of service resources modularization, it is an effective approach to addressing the conflict between the diverse customer requirements and the service providers’ requirements for standardization and efficiency enhancement. It is widely used in industries like tourism, medical care, and finance. Zhang et al. [18] proposed a method to partition the service flow module based on fuzzy spaces quotient theory to reduce the subjectivity of module granularity selection in the research of modular design of service flow. Böttcher et al. [19] utilized propositional logic and linear temporal logic to examine the logical and temporal interdependencies among modules. Zhang et al. [20] proposed a Design Structure Matrix (DSM) as a technique for healthcare process modularization., and developed a DSM-based modularization and sequencing algorithm to support modular clinical pathway design. Ji et al. [21] proposed a green modular design for material efficiency that can facilitate life-cycle material efficiency through component material reuse and minimize resource commitment throughout the product realization process. Moon et al. [22] proposed a module-based service model to facilitate customized service design and represent the relationships between functions and processes in a service. They considered a module selection problem for platform design as a strategic module-sharing problem in a collaboration situation. Tuunanen et al. [23] proposed a modular service design framework and a service design method that adopts DPs to create effective modular ITeS designs and also offered ways to conceptualize and apply service modularization to improve the adoption of modular service design by service designers and managers. Chung et al. [24] conceptualized modularity as multidimensional and investigated how these multidimensional SDK-based modularity choices impact the performance of a key category of digital products—mobile apps. Van et al. [25] proposed that solution modularity is a critical mechanism for enhancing cross-selling opportunities. Ultimately, this can help the company achieve the optimal level of cross-selling opportunities, thereby facilitating its growth. Sheng et al. [26] identified four equifinal configurations sufficient for high MCC and categorized them into three types: modularity +  integration oriented, integration +  customer need oriented, and modularity +  integration +  customer need balance. Kang et al. [27] developed a moderated mediation model in which quality-oriented product design practices influence operational performance via supplier involvement under the different levels of product modularity.\n\nIn terms of service resource scheme configuration, based on the modularization of service resources, the service module content can be configured to generate a service resource configuration scheme that optimally fulfills customer requirements. Luo et al. [28] established a service configuration optimization model for multiple customers, considering service process information and time-varying service resource constraints based on quality function deployment and modularization. Li et al. [29] developed an SDF-oriented genetic algorithm to effectively create a manufacturing service composition with large-scale candidate services. Zhang et al. [30] studied product-oriented product–service system configuration optimization from a fine-grained perspective. A multilayer network composed of (i) a product layer, (ii) a service layer, and (iii) a resource layer was constructed to represent the elements (product parts, service activities, and resources) and relationships in PSS. Service activity selection and resource allocation were considered jointly to construct the mathematical model of product-service system configuration optimization. Wang et al. [31] proposed a method that adopts the digital twin and augmented Lagrangian coordination (ALC) to perform service model construction and optimal configuration of shared manufacturing resources. For the resource configuration and scheduling algorithm, Zhang et al. [32] proposed a dynamic priority based on the dominant resource proportion and valid active time to improve social welfare and resource utilization. Al-Wesabi et al. [33] presented new hybrid metaheuristics for energy efficiency resource allocation (HMEERA) for the cloud computing environment to achieve the optimal configuration of resources. Yang et al. [34] created a four-step generic product service system design method that is based on service requirements. The steps are smart and connected service product configuration, dynamic event-state knowledge graph-based service activity flow, and service resource network configuration. Nie et al. [35] established the cloud production line model to support the optimal configuration of the distributed idle manufacturing resources by applying a systematic evaluation method and digital twin technology, which reflect the actual manufacturing scenario of the whole production process. Dong et al. [36] proposed a novel Smart Product-service System configuration method oriented to Mass personalization to meet the personalized and dynamic requirements of customers, especially satisfy affective and functional requirements simultaneously throughout the reconfiguration life-cycle. Gai et al. [37] focused on the resource configuration issue in the Internet of Things and proposed a novel approach that uses a Reinforcement Learning mechanism to construct the strategy of resource configuration. Implementing a Reinforcement Learning mechanism intends to prevent contradictions and make resource configuration operations smart.\n\nIn conclusion, the available researches on service resource configuration optimization have achieved certain results in the three key areas of service requirements analysis, service resources modularization and processing, and service resource schemes configuration. Nevertheless, after associating the service modules in the service resource configuration scheme with customer requirements, it is rarely seen that “the service candidate itemset under the same service module will be different due to different customer requirements met by the module. The candidate itemset within the same service module will be different due to the different customer requirements met by the module; this means that there is a “one-to-many” relationship mechanism between the service module and its candidate itemsets, rather than just a “one-to-one” relationship mechanism. Hence, when modularizing the service resource configuration scheme, it is more practical and better aligned with customer expectations to take into account the “one-to-many” relationship mechanism between the service module and its candidate itemsets, which refers to situations where different candidate itemsets may exist under the same service module.\n\nThis study, as depicted inFig 2, concentrates on the problem of service resource configuration optimization driven by customer requirements. In this case, the personalized service platform engages in focused conversation and research with customers to dig out their requirements for service resource configuration scheme and, on this basis, uses appropriate mathematical methods to quantify and rank the importance of customer requirements; The platform divides service resource configuration scheme into several service modules. Each service module has several (at least one) service candidate itemsets. Each service candidate itemset contains several service candidate items.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g002\n\nIn actual applications, the same customer requirement may require multiple service modules in the service resource configuration scheme to satisfy it. Similarly, the same service module may also satisfy multiple customer requirements. At this time, the candidate itemset within the same service module will be different due to the different customer requirements met by the module; this means that there is a “one-to-many” relationship mechanism between the service module and its candidate itemsets. For example, in the whole customization process, when choosing an Air Conditioner, if you are concerned about the customer’s refrigeration and heating requirements, you need to pay attention to the air conditioner’s horsepower selection. If you are concerned about the customer’s energy-saving requirement, you need to consider the air conditioner’s energy efficiency index selection. When satisfying different requirements, the air conditioning service module selects different candidate itemsets, namely the horsepower itemset and the energy efficiency index itemset. The satisfaction of customers’ various requirements is influenced by different factors under Air Conditioner.\n\nHence, to satisfy customer requirements more accurately and efficiently, it is particularly important to select diverse candidate items, measure utility, and integrate them based on service modules for the same service module when satisfying different customer requirements. The problem to be solved in this study is how to accurately identify and evaluate customer requirements, and on this basis, select and integrate appropriate candidate items for different service modules under the conditions of satisfying different customer requirements and cost constraints, so as to determine the service resource configuration scheme.\n\nThe following are the sets and variables involved in the service resource configuration optimization problem driven by customer requirements that this study focuses on.\n\nis the customer requirement set, whererepresents thel-th customer requirement,.\n\nis the technical attribute set, whererepresents thea-th technical attribute,.\n\nis the service module set, whererepresents thei-th service module in the service resource configuration scheme.\n\nis the candidate itemset of service modulewhen satisfying the customer requirement, whererepresents thej-th candidate item of service modulewhen satisfying the customer requirement,,,.\n\nis all candidate item configuration schemes set in the service module, whererepresents the k -th candidate item configuration scheme in the service module, andrepresents thej-th candidate item of service modulewhen satisfying the customer requirement. If service moduleis correlated with the requirement,is a specific candidate item, otherwise,is  ∅ ,,,,.\n\nis feasible candidate item configuration schemes set in the service module, whererepresents thes-th feasible candidate item configuration scheme in the service module,,,.\n\nis the relative importance weight of the customer requirement.\n\nis the cost of the service module.\n\nis the fixed cost during the service process.\n\nis a “0-1” variable, which is used to represent the matching relationship between the candidate item configuration scheme and the feasible candidate item configuration scheme in the service module. If candidate itemsin the candidate item configuration schemeare all consistent with candidate itemsin,, otherwise,.\n\nis a “0-1” decision variable, if candidate itemsis selected,, otherwise,.\n\nThe problem to be addressed in this study is: based on the relevant decision-making information such as,,, and, combined with the research method of this study, solve the problem of service resource configuration optimization driven by customer requirements;andyare sets or variables utilized to facilitate solution screening.\n\nWhat needs to be clear is this article only deals with the issue of service resource configuration optimization in the context of personalized customization, investigates the customer’s demand for decoration industry and gives their importance judgments. There is no ethics involved. Survey of the requirements of customers covered in this example was conducted in May-June 2024. Participants were provided with the right to information and verbal consent was given by the participant, which was witnessed with a colleague who was investigating with them. This survey investigated 148 adult customers, not involving minors, and distributed questionnaires to them, mainly to investigate their requirements for the decoration industry and give their importance judgments. In this process, these 148 adult customers mainly participated in the filling of KANO model questionnaire for calculating the loss cost importance.\n\nThe following is a detailed description of the fundamental principles and calculation steps for service resource configuration optimization driven by customer requirements.Fig 3illustrates the flow chart of specific process of service resource configuration optimization problem.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g003\n\nDuring the service process, in order to make the service resource configuration scheme better satisfy the personalized customer requirements, before formulating the corresponding service scheme, it is necessary to conduct targeted investigation and research on customer requirements, quantify the importance weight of each customer requirement, and determine its priority. In actual applications, a customer requirement may require multiple service modules to jointly satisfy; that is, there is a certain correlation between the two. We use Quality Function Deployment (QFD) to refine customer requirements into specific technical attributes, establish a correlation between customer requirements and service modules, and determine the relative importance weight of each service module.Fig 4illustrates the transformation relationship between customer requirements, technical attributes, and service modules.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g004\n\nQuantification and prioritizing of the relative importance of customer requirements. To establish the correlation relationship between customer requirements and service modules, this study introduces the House of Quality (HoQ) in QFD into the research. During the process of constructing the HoQ, it is necessary to quantify and prioritize the importance of customer requirements. When the number of customer requirements is within a small range, the human brain’s prioritization of their importance is reasonable. We can let customers directly prioritize the importance of each requirement through questionnaires. However, in a comprehensive service process, there will be a substantial number of requirements that need to be studied. When the number of requirements is large, it is difficult for customers to objectively and reasonably make accurate judgments and prioritize the importance of each requirement. Taking this into account, the study utilized a method that combines three approaches: customer requirement importance judgment matrix, KANO model, and competitiveness evaluation. We used this method to prioritize and evaluate the importance of each customer requirement, as follows:\n\nStep 1:Requirement importance determination based on the requirement importance judgment matrix. Customers have varying priorities for their requirements, so it is necessary to evaluate their importance. In this study, we initially collect, categorize, and organize the customer requirements using the hierarchical analysis method to make the collected requirements more detailed and differentiated. Subsequently, on this basis, we utilize the customer requirement importance judgment matrix to evaluate the importance of customer requirements, as follows:\n\n(1) Using the customer requirement importance judgment matrix to compare the collected customer requirements and generate an importance judgment matrix, as illustrated inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t001\n\nThus, construct an importance judgment matrix, whererepresents the importance of customer requirementscompared to,,,.Table 2below displays the specific numerical criteria for.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t002\n\n(2) Calculation of customer requirement importance based on the customer requirement importance judgment matrix.\n\nThe formula for calculating the relative importance of customer requirements based on the customer requirements importance judgment matrix is as follows:\n\nwhereis the absolute importance weight of each requirement based on the customer requirement importance judgment matrix, and the calculation formula is as follows:\n\nStep 2:Calculation of loss cost importance based on the KANO model. The KANO model categorizes customer requirements into attractive requirements, one-dimensional requirements, must-be requirements, indifferent requirements, and reverse requirements. We categorize customer requirements by making and distributing KANO model questionnaires, fully utilizing the KANO model’s advantages in identifying customer requirements across various dimensions. According to the differences in customer requirements across different categories, the requirement elements that can cause customer dissatisfaction are focused on and evaluated.Table 3illustrates the specific numerical criteria of customer requirement importance in the KANO model.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t003\n\nBased on the established requirement importance numerical criteria and the questionnaire results of the KANO model, the calculation formulas for absolute importance and loss cost importance can be obtained as follows:\n\nwhereis the absolute importance ofbased on the KANO model,is the loss cost importance ofbased on the KANO model,,,,andare the numbers ofcategorized in the above five requirements categories in the valid questionnaires.\n\nStep 3:Calculation of the quality level increase rate. The service design team performs a thorough evaluation and rating of the current market, focusing on two aspects: (1) the degree to which the company’s products satisfy each customer requirement level; and (2) the degree to which competitors’ products satisfy the same customer requirement level. The service design team then analyzes the company’s target level to be achieved for each customer requirement and thus obtains the quality level increase rate:\n\nwhereis the quality level increase rate ofbased on the existing market competitiveness evaluation,is the current quality level of, andis the target quality level of.\n\nStep 4:Determination of the importance weight of customer requirements. Based on the above customer requirement importance judgment matrix, KANO model, and competitiveness evaluation analysis, the relative importance weight of customer requirements can be determined. The formula for relative importance weight is as follows:\n\nwhereis the final relative importance weight of.\n\nInfluenced by its own properties, the utility values of different candidate itemsunder each service module will have different trends as their parameter valueschange, that is, the utility measurement functions of different candidate itemsetsunder each service module will be different. Thus, before measuring the utility of the candidate items, it is necessary to determine the appropriate candidate item utility measurement function according to the properties of the candidate items, and on this basis, calculate the candidate item utility value, and then obtain the utility value of each service module, as follows:\n\nFirst of all, combined with the previous case study conducted by scholars [38], the utility measure function design schemes constructed for the candidate items in each situation are as follows:\n\nAs shown in the schematic diagram inFig 5, the candidate item decision’s utility structure follows the “0-1” binary format. This means that if the parameter valueof the selected candidate item equals or exceeds the expected level (in numerical or set form) under its correlating customer requirement, the utility value is 1; otherwise, it is 0. Therefore, the benefit-form binary utility measure function of the candidate decision is defined as follows:\n\n.\n\n.\n\nhttps://doi.org/10.1371/journal.pone.0320312.g005\n\nwhereandare the utility values when the expected level ofis in numerical and set form, respectively;is the parameter value of candidate item;andGare the expected levels ofunder the correlating customer requirements in numerical and set form, respectively.\n\nAs shown in the schematic diagram inFig 6, the candidate item decision’s utility structure follows the “0---1” ladder format. This means that if the parameter valueof the selected candidate item is less than its lower limit under the correlating customer requirement, the utility value is 0; Ifis in the interval, the utility value is; Ifis in the interval, the utility value is, otherwise, it is 1. Therefore, the benefit-form ladder utility measure function of the candidate decision is defined as follows:\n\n.\n\n.\n\nhttps://doi.org/10.1371/journal.pone.0320312.g006\n\nwhereis the utility value of the corresponding candidate item decision;is the parameter value of;,, andare the boundary values of;andare the utility values corresponding toin different intervals,,.\n\nAs shown in the schematic diagram inFig 7, the candidate item decision’s utility structure follows theparabolic growth format. This means that if the parameter valueof the selected candidate item is less than its lower limit under the correlating customer requirement, the utility value is 0; Ifis in the interval, utility value will increase in the form of diminishing marginal utility and the growth range is; otherwise, it is 1. Therefore, the benefit-form parabola utility measure function of the candidate decision is defined as follows:\n\n.\n\n.\n\nhttps://doi.org/10.1371/journal.pone.0320312.g007\n\nwhereis the utility value of the corresponding candidate item decision;is the parameter value of;andare the boundary values of,.\n\nAs shown in the schematic diagram inFig 8, the candidate item decision’s utility structure follows theinterval format. This means that if the parameter valueof the selected candidate item is less than its lower limit or more than its upper limit under the correlating customer requirement, the utility value is 0; Ifis in the interval, utility value will increase in the form of diminishing marginal utility and the growth range is; Ifis in the interval, the utility value is 1; Ifis in the interval, utility value will decrease in the form of increasing marginal utility and the growth range is. Therefore, the interval-form parabola utility measure function of the candidate decision is defined as follows:\n\n.\n\n.\n\nhttps://doi.org/10.1371/journal.pone.0320312.g008\n\nwhereis the utility value of the corresponding candidate item decision;is the parameter value of;,,andare the boundary values of,.\n\nThen, calculates the utility value of service modules. This study assumes that among each available service module, only one candidate item can be selected from the candidate itemset correlated with each customer requirement to form the service module’s candidate item configuration scheme and then form the final service resource configuration scheme. Therefore, once a service module selects specific service candidate items, it can calculate its utility value as follows:\n\nwhereis the utility value ofwhen satisfying the customer requirement;is a “0-1” decision variable, if candidate itemsis selected,, otherwise,.is the utility function value of, it should be pointed out that when calculating, it is necessary to select the utility measure function that is suitable forfrom the above four types of utility measure functions and then calculate the utility function value. The utility measure function will vary based on the candidate itemsets. In this way, the utility value of each service module can be obtained when satisfying different requirements.\n\nIn the QFD theory, the HoQ allows us to obtain the correlation matrix between customer requirements and technical attributes, as well as between technical attributes and service modules. By combining these matrices, we can derive the correlation matrix between customer requirements and service modules, as depicted inFig 3. The details are as follows:\n\nis the correlation matrix between customer requirements and technical attributes obtained through HoQ, whererepresents the correlation coefficient betweenand, which is used to indicate the level of correlation between customer requirements and technical attributes;,. Usually, the correlation coefficients are provided directly by specialists or the service design team.\n\nis the correlation matrix between technical attributes and service modules obtained through HoQ, whererepresents the correlation coefficient betweenand, which is used to indicate the level of correlation between technical attributes and service modules;,. Usually, the correlation coefficients are provided directly by specialists or the service design team.\n\nis the utility matrix of different service modules in a service resource configuration scheme when satisfying different customer requirements, whereis the utility value ofwhen satisfying the customer requirement,,.\n\nThe satisfaction utility matrix of the service resource configuration scheme for each customer requirement is as follows:\n\nwhereis the satisfaction utility of the service resource configuration scheme forwhen it satisfies,;is the identity matrix.\n\nThen the satisfaction utility value of the service resource configuration scheme for the customer is as follows:\n\nwhereqis the satisfaction utility value of the service resource configuration scheme for the customer. Based on the existing constraints, the objective of this study is to select the service resource configuration scheme with the highest satisfaction utility value among the generated schemes.\n\nTo calculate the cost of the service resource configuration scheme, we first need to establish a cost set of feasible candidate item configuration schemes under each service module in the service resource configuration scheme. Then, we can compare the obtained candidate item configuration schemes with the cost set to obtain the cost of each service module and then integrate the total cost of the service resource configuration scheme, as shown inFig 2. The specific process is as follows:\n\nis cost set of, whererepresents the cost of,,.\n\nIt is known thatis the final candidate item configuration scheme for the service module. At this time, the cost of the service modulecan be determined based on the cost setand the determined candidate item configuration scheme, that is,,,.\n\nThe cost calculation formula for the service resource configuration scheme is as follows:\n\nwhereis the sum cost of the service resource configuration scheme,is the fixed costs incurred during the design, production, and installation of the service resource configuration scheme,is the cost of the service module.\n\nIn this mathematical model, formula (17) is the objective function, which means maximizing the satisfaction utility value of the service resource configuration scheme when satisfying customer requirements; Formula (18) represents that only one candidate item can be selected from each candidate itemset; Formula (19) ensures that only candidate items that satisfy the correlating customer requirements can be selected; Formula (20) represents that the sum cost of the service resource configuration schemes cannot exceed the specified upper limit; Formula (21) represents that the decision variable can only take the value of 0 or 1; Formula (22) represents that the candidate item configuration scheme used for configuration must be feasible.\n\nWhen dealing with large-scale problems, Exact Algorithms (EA) may encounter a range of issues, including combinatorial explosion, lengthy optimization time, and failure to reach the optimal solution within a reasonable timeframe. Genetic Algorithm (GA), as an effective meta-heuristic algorithm, has been widely used in various engineering optimization problems in product development due to its advantages such as rapid search speed, strong robustness, and excellent convergence effect. Hence, to address the service resource configuration optimization problem in this study, an improved genetic algorithm (IGA) was devised. This algorithm takes into account the candidate item selection problem and the cost screening and matching problem of the service module, considering them from the perspective of multi-requirement correlation. The specific process of the IGA is depicted inFig 9.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g009\n\nStep 1:Encoding. The initial stage involves encoding the problem that needs to be resolved. Encoding involves the transformation of feasible solutions from the solution space of a problem to the search space of IGA. This is the initial stage of IGA. It is necessary to ascertain the solution’s interval and precision and thereafter encode the initial population based on these parameters. There are several methods of encoding, such as binary encoding, grey code, real number encoding, and character encoding.\n\nStep 2:Population initialization. Before commencing the genetic algorithm iteration process, it is necessary to initialize the population and establish parameters such as population size, population number, DNA length, number of evolutions, and mutation rate. The population’s variety is defined by its size, whereas the encoding process defines the length of the chromosome. The initial population is often generated randomly. However, if the actual distribution of the population is known, the initial population can also be formed based on this distribution.\n\nStep 3:Fitness value calculation and selection operation. Calculate the fitness value of each individual, which represents their performance in the problem space. The fitness function is a criterion for measuring the quality of individuals, which is defined according to the specific objective of the optimization problem; the selection operation is the process of selecting individuals from the previous generation population to the next generation population. Generally, individuals are selected based on the distribution of individual fitness.\n\nStep 4:Criss-cross inheritance operation. The criss-cross inheritance operation involves the random selection of two individuals from a group of selected individuals. Their gene sequences are subsequently exchanged at one or more specific places to generate new progeny. This method emulates genetic recombination in biological reproduction.\n\nStep 5:Mutation Operation. The mutation operation is to make a small probability random change to the gene sequence of the newly generated individuals in order to increase the population’s diversity. This helps the algorithm jump out of the local optimal solution and explore a wider solution space.\n\nStep 6:Gene sequence matching and new population evaluation. In contrast to traditional genetic algorithms (GA), considering the inconsistency of candidate itemsets of service modules from the perspective of multi-requirement correlation, this study adds a gene sequence matching process when using genetic algorithms to ensure that the generated individuals actually exist, and then calculates the fitness values of the new individuals generated after the operation. The specific screening and matching process is consistent with the yellow background color labeling part inFig 2.\n\nStep 7:Update population. The original population is replaced with individuals of the new generation, and then the above selection, crisscross inheritance, mutation, matching, and evaluation process is repeated until the termination criterion is achieved. The termination criterion can be reaching the maximum number of iterations or the fitness value reaching the preset target threshold.\n\nStep 8:Comparison of evaluation results. The fitness value of the population evaluated at the current parameter level set is compared with the fitness value obtained at the previous parameter level, and the population with a higher fitness value is retained as the comparison population. This cycle is iterated until all given parameter combinations are traversed. This process is the outer loop cycle process inFig 9.\n\nStep 9:Decoding and outputting results. Decode the encoded chromosome to obtain the original form of the problem solution. Then, output the current optimal solution and its corresponding ideal fitness value.\n\nTo validate the efficacy and viability of the method proposed in this study, we demonstrate its potential applicability in the field of living room customization.\n\nWithin the whole-home customization industry, as customer requirements become more sophisticated and diversified, the requirements for the diversity of decoration resources and the flexibility of decoration processes are gradually increasing. To provide high-quality customized services, a large whole-home customization company intends to improve the whole-home customization service products of houses by taking living room customization as an example.\n\nIn the whole customization process, modules can be divided based on indoor space, such as windows, floors, ceilings, etc., which can all be used as a single service module. A complete whole customization service resource configuration scheme can be obtained by selecting and configuring all modules. In this process, customers’ requirements need to be met by related service modules, but the candidate itemsets that need to be configured for the same service module will be different when meeting different requirements. For example, the air conditioner pays attention to the configuration of its temperature control system when meeting the temperature requirement of customers, and pays attention to the configuration of its humidity control system when meeting the humidity requirement of customers.\n\nThe company comprehensively determined the six customer requirements for living room customization in the whole-home customization process through the distribution of questionnaires, website browsing, expert interviews, and targeted communication and investigation with customers, as shown inTable 4, and defined eight technical attributes, as shown inTable 5.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t005\n\nConstructing a modular framework for living room customization. The living room customization process is divided into 8 service modules. Simultaneously, combined with the actual situation, a service module may satisfy multiple customer requirements. The candidate itemsets in the same service module will be different due to the different customer requirements satisfied by the service module. Therefore, several candidate itemsets are established for each service module, and several candidate items are established for each candidate itemset. Each candidate item in the same candidate itemset has similar functions and effects and can be replaced by each other, but there will be certain differences in performance, cost, and quality.Table 6below illustrates the hierarchical division of service modules and candidate v\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t006\n\nTo address the problem of service resource configuration optimization in living room customization, the following is a concise overview of the research process that utilizes the service resource configuration optimization method above to determine the service resource configuration scheme.\n\nIt is known that the living room studied in this example covers an area of 30 square meters and is located in Shenyang City, Liaoning Province, China. The budget cost is 25,000 yuan. The correlation between the “customer requirements-technical attributes-service modules-candidate itemsets” relationship is shown inTable 7.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t007\n\nThe cost of each candidate item configuration scheme in the existing service module (product) in this case is shown inTable 8below.RMB.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t008\n\nCalculate the relative importance weight of customer requirements. The importance judgment matrix, KANO model, and competitiveness evaluation are integrated to evaluate the relative importance weight of customer requirements. We investigated 148 adult customers, not involving minors, and distributed questionnaires to them, mainly to investigate their requirements for the decoration industry and give their importance judgments in May-June 2024. Participants were provided with the right to information and verbal consent was given by the participant, which was witnessed with a colleague who was investigating with them.\n\nIn order to ensure the rationality, validity and authenticity of the obtained data, and ensure that it can fully reflect the requirements of customers in Shenyang for living room customization. Among the 148 adult customers in this survey, there are mainly two customer groups: the customers who have customized the living room and the customers who are customizing the living room. Both of them have the requirement for living room customization and have a certain understanding of living room customization. These 148 adult customers were randomly selected by multi-stage sampling, stratified sampling and other sampling methods, and their ages were mainly concentrated in the young and middle-aged group, that is, the 18–59 age group. The places where they live are located in ten administrative districts and three counties in Shenyang. This survey mainly investigated their requirements for the decoration industry and give their importance judgments. In this process, these 148 adult customers mainly participated in the filling of KANO model questionnaire for calculating loss cost importance.\n\nStep 1:By comparing the customer requirements collected for the living room customization, the customer requirements importance judgment matrix is obtained as follows:\n\nBased on the importance judgment matrix and formula (2), theofare 1.6189, 0.7418, 0.6934, 2.4980, 0.7782, and 0.6177, respectively. Based on formula (1), the relative importance of customer requirements is:,,,,,.\n\nStep 2:We conducted a questionnaire survey on 148 customers within the company’s jurisdiction in May-June 2024 and obtained customer requirement survey results based on the KANO model. Based on formulas (3) and (4), thebased on the KANO model was determined.Table 9displays the specific results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t009\n\nStep 3:Calculation of the quality level increase rate. Before conducting the market competitiveness evaluation, the service design team comprehensively evaluated the characteristics and technical indicators of the entire customization industry and selected XX Company as the target competitor for analysis. The service design team utilized a five-level scale to evaluate the performance of the company and its competitors regarding each customer requirement, to determine the relative competitive advantages and disadvantages of the company and its competitors, and to recognize the areas that need to be maintained and improved in their service products.Table 10displays the specific market competitiveness evaluation results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t010\n\nStep 4:Based on,,and formulas (6) and (7) obtained in the above process, theofare finally calculated.Table 11below displays the calculation results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t011\n\nEstablish the correlation between customer requirements and service modules.establishes the correlation between customer requirementsand technical attributes, whileestablishes the correlation between technical attributesand service modules. The correlation matrix provided by the service design team is as follows:\n\nTable 12displays the utility measure function of the candidate itemsets under each service module.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t012\n\nInTable 12, the utility measure function type of each candidate itemset is selected in Section 4.2 according to the changing trend of customer satisfaction utility with the parameters of the set. For example, the candidate item “horsepower (HP) of air conditioners” affects whether the air conditioner has sufficient cooling and heating capacity, that is, whether the air conditioner can be adjusted to a specific temperature in a specific area and environment. Combined with field research and expert opinions, the customer’s response to the air conditioner’s temperature adjustment is in a binary form, that is, it is satisfactory to reach a specific temperature effectively, but not satisfactory to reach it. Therefore, the utility measure function of the candidate itemsetis a Benefit-form binary utility measure function. And so on.\n\nOn this basis, the setting of parameter node values in the utility measure function of each candidate itemset mainly refers to China national and local standards, some industry standards, authoritative measurement articles in related fields, expert opinions and the change trend of “satisfaction utility value-parameter” of the candidate itemset itself. For example, the refrigeration unit of civil air conditioner is “HP”, and 1 HP= 2324 W. According to the recommended standards of air conditioning industry and the climatic conditions in Shenyang, the cooling load of the case house should be 150and the 30living room should be 4500W, so 2 HP is regarded as the parameter nodes ofthat meet the standard. In a similar way, the parameter node values of the candidate set”Energy Efficiency Index” is determined according to the Chinese national standard GB 21455–2019, namely “Minimum allowable values of the energy efficiency and energyefficiency grades for room air conditioners”, and so on.\n\nThis model optimization was programmed in Python 3.12 and executed on a personal computer with the following configuration: CPU: 12th Gen Intel(R) Core(TM) i7-12700H 2.30 GHz, RAM:16.0 GB, Operating System: Windows 11 23H2.\n\nCombined with the candidate itemset data given under the existing service modules provided by the enterprise, the number of selectable candidate items under each candidate set is converted into binary digits: 3 + 4 + 3 + 2 + 2 + 1 + 3 + 3 + 2 + 3 + 2 + 2 + 2 + 2 + 3 + 3 + 3 = 43 bits. Therefore, the DNA length of the improved genetic algorithm is set to 43; in addition, in the genetic algorithm, the setting of the three parameter values of population size, number of generations, and mutation rate usually depends on the complexity of the specific problem. This is a process that requires trial and error and adjustment, and the setting of parameters will also affect the final solution’s results and efficiency. Therefore, according to the complexity of the problem in this case, this study gives different parameter setting sets in the IGA for the next step of genetic algorithm parameter optimization and model solution, as shown inTable 13.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t013\n\nBased on the above optional IGA parameter levels, parameter optimization is performed by cross-validation traversal parameter combinations to obtain the optimal parameter combination and the corresponding model optimization results.Table 14presents the optimal parameter combination and model solution result of service resource configuration optimization.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.t014\n\nFig 10shows the iterative optimization evaluation process under the known optimal parameter combination. The objective function value generally rises as the number of IGA iterations increases. There is a significant fluctuation before the 30th generation, and it tends to be stable between the 40th and 70th generations, but there are still slight fluctuations. After the 70th generation, the optimization result of this decision can be stably obtained.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g010\n\nAccording to the cost data inTable 8, the minimum and maximum values of the actual service configuration cost are calculated to beand, respectively. Therefore, we divide the cost of this case into intervalsbased on the actual market situation and cost data, and set the step length to 1000 RMB.Fig 11displays the results of the cost sensitivity analysis. It can be seen that cost has a positive impact on the fitness value (i.e., customer satisfaction utility); that is, for customers, the higher the cost budget, the better the scheme will be and the more satisfied they will be. When, the impact of cost on the fitness value tends to be flat; when, reaches the maximum value and remains unchanged, considering the cost performance and corporate profit,can be used as the maximum cost limit; and when, due to the low fitness value of the customer, it is not within the consideration range, so the cost limit range can be set to.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g011\n\nGenetic Algorithm (GA), as an effective meta-heuristic algorithm, has been widely used in various engineering optimization problems in product development due to its advantages such as rapid search speed, strong robustness, and excellent convergence effect. To verify the effectiveness and superiority of the service resource configuration optimization model and the improved genetic algorithm (IGA) proposed in this paper, the IGA is compared with the original GA using the case data.Fig 11displays the comparison results in a Box-plot.\n\nAs shown inFig 12, this paper sets the parameters of the original GA involved in the comparison to two cases, namely GA-1: PS =  100, NG =  100, MR =  0.05, DL =  43, and GA-2: PS =  300, NG =  100, MR =  0.1, DL =  43. In the three cases, including IGA, we use Python 3.12 to run the programs 10 times, respectively, and finally compare the fitness values. It is found that the result of the IGA algorithm is better than the GA algorithm in both overall and average values. Specifically, in the 10 results, first, the lowest fitness value solved by the IGA algorithm is 0.91381596737829, which is higher than the highest fitness value solved by the GA algorithm under the two parameter combinations, namely 0.908748324334096 and 0.906090096485994; secondly, the average fitness value solved by the IGA algorithm is 0.927195658, which is 5.75% and 4.55% better than the average fitness values of GA-1 and GA-2, respectively. Finally, the results of IGA have a smaller fluctuation range and are more stable than those of GA. Therefore, this study demonstrates the superiority and positivity of the IGA algorithm in terms of overallness, average value, and stability.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320312.g012\n\nService resource configuration optimization is an important technical approach to achieve personalized customization and provide customers with the most suitable service. This study proposes a new service resource configuration optimization method. Compared with the available research, the primary contributions of this study are as follows:\n\nThe research methods mentioned in this study can be widely extended to the customized service industry, which optimizes service resource configuration based on service modularization, such as customized home appliances and software configuration in cloud environment. Taking customized smart refrigerator as an example, it is a typical modular customized product with complex structure. Smart refrigerators include intelligent coolers, compressors, thermostats and other service modules, which will have different candidate itemsets when they are associated with different customer requirements. At this time, the service requirement analysis method and the “one-to-many” relationship mechanism mentioned in this study can help enterprises make products better meet customer requirements and improve enterprise efficiency.\n\nOne limitation of this study is that it does not consider generating service resource configuration schemes for multiple customers at the same time. In practice, enterprises need to generate service resource configuration schemes for multiple customers at the same time and take into account multiple customer requirements based on the existing resources.\n\nAnother limitation is that some parameters of the optimization model proposed in this study need to be estimated beforehand, such as the QFD-based correlation matrix and the demand importance judgment matrix. In actual operation, enterprises can use their historical data to help service designers make more accurate parameter settings. In the service requirement analysis and algorithm solution, enterprises also can introduce the application of machine learning and artificial intelligence technology to improve the accuracy and effectiveness of the research results.\n\nFuture research potentials may include: 1) Based on this study, consider the situation of generating service resource configuration schemes for multiple customers at the same time, taking into account the requirements of multiple customers and the time requirements of customers, and effectively scheduling and optimizing existing resources; 2) Since customer requirements are vague, how to combine customer requirements quantitatively and qualitatively and integrate dynamic customer requirements that may change over time into service resource configuration is still a topic worthy of research; 3) From a full life cycle perspective, consider the impact of supplier behavior on platform service resource configuration, establish a three-party interaction mechanism among suppliers, customization companies, and customers, and better help enterprises configure service resources.\n\nhttps://doi.org/10.1371/journal.pone.0320312.s001\n\n(DOCX)",
    "category": "materials_science"
  },
  {
    "title": "Structural deformation control in bridge construction based on error analysis and correction",
    "authors": "Juan Li, Rengye Zhao, Shengliang Cao, (PLOS)",
    "publish_date": "2025-04-14",
    "doi": "https://doi.org/10.1371/journal.pone.0319844",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319844",
    "content": "Structural deformation control of constructed bridges not only affects the alignment of the bridge, it is also the key to ensure safety. Factors such as temperature and time interval in actual construction can make the bridge deviate from the design state, therefore, this paper proposes a method based on error analysis and correction to eliminate these errors, and realize the structural deformation control in bridge construction control. The cantilever deflection in main girder is modeled and the effect of subsequent cantilevers on deflection at current section is further considered. The error in elevation caused by factors such as temperature and time interval is calculated, and a linear minimum variance estimate is employed to reduce this error. Practical engineering verification is carried out on a bridge in Shanxi, where the proposed error analysis method is further implemented by measuring the current cantilever elevation and comparing it with the original design value, with a purpose of obtaining a reasonable elevation for the next cantilever. The results show that, with the application of error analysis and correction, the elevation error generated during construction process is less than 20 mm, and the elevation error after the completion of bridge is less than 30 mm, the linear shape and internal condition of the bridge structure can also be further conformed to design requirements.\n\nCitation:Li J, Zhao R, Cao S (2025) Structural deformation control in bridge construction based on error analysis and correction. PLoS ONE 20(4):\n           e0319844.\n        \n        https://doi.org/10.1371/journal.pone.0319844\n\nEditor:Salar Farahmand-Tabar, University of Zanjan, IRAN, ISLAMIC REPUBLIC OF\n\nReceived:August 7, 2024;Accepted:February 8, 2025;Published:April 14, 2025\n\nCopyright:© 2025 Li et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The study was supported by the Shaanxi Province Innovation Capability Support Plan Project (grant no. 2022TD-16). The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nFor the rapidly developing transportation industry, bridges have not only made access easier, which have also been extended to cross mountain streams, traverse bad geology, or meet other transportation needs [1,2]. The monitoring of bridge construction process is a systematic project, which consists of monitoring and control. Monitoring [3] refers to the use of data acquisition systems to measure large amounts of data during construction, such as stresses and deformations. The control of bridge construction [4] involves analyzing these data to guide the parameters of the next phase of construction.\n\nThere are a large number of studies on bridge monitoring. Soyoz et al. [5] used accelerometers to monitor vibration and structural stiffness changes in a new concrete bridge over a 5-year period, and stated that the study is significant for long-term bridge health assessment. Casas et al. [6] discussed the application of fiber optic sensors in bridge construction monitoring, and they pointed out that fiber optic sensors have the advantages of strong anti-interference ability and high accuracy when monitoring parameters such as bridge strain, temperature, and loading. Ntotsios et al. [7] utilized vibration sensors to capture bridge vibration values and further developed a bridge health monitoring system based on a Bayesian inference framework, and this approach was also validated by experiments. Farhangdoust et al. [8] summarized the application of NDT for health monitoring of closed joints in bridge construction, with different inspection methods for different types of closed joints. Similarly, Lin et al. [9] indicated the feasibility of Fiber Bragg Grating (FBG) sensors for bridge construction monitoring applications, which can not only monitor shrinkage and creep in bridge construction with high accuracy, it can also examine the prestress distribution in overall construction. Butler et al. [10] discuss the two main challenges of implementing fiber optic sensors in bridge construction, temperature compensation and strain variation, and they suggest the feasibility of using cable encapsulation and deploying glass fibers for sensors. As mentioned above, embedding sensors in bridge structures to capture changes in parameters such as temperature, stress, and strain is a key means of bridge inspection, which not only evaluates the health status of the bridge after completion, it also guides the operation of bridge construction process [11,12]. Orcesi et al. [13] effectively incorporate structural health monitoring (SHM) data into bridge structural assessment and prediction models, and its helps in bridge maintenance and operation. Gatti [14] noted that dynamic load tests can be used as a supplement to static load tests for bridge monitoring. Guzman-Acevedo et al. [15] pointed out the application of smart sensors for bridge monitoring, real project‘s results showed that fusion smart sensors are suitable for SHM of real-scale bridges. Gaxiola-Camacho et al. [16] proposed a method for bridge condition monitoring using GPS, which is realized by GPS reception of dynamic bridge displacements. He et al. [3] discussed the current challenges and future research directions for integrated SHM systems with respect to the characteristics of bridges.\n\nAlthough the placement of various sensors can effectively obtain bridge parameters, further parameter processing to obtain bridge health status and bridge construction control is particularly critical. Liu et al. [17] proposed a method for evaluating the performance of bridge systems based on structural health monitoring, with strain data from a long-term inspection of a bridge in US. Li et al. [18] analyzed the stress and deformation data obtained from bridge monitoring, then proposed an analytical method for traffic load effects and expansion joint temperatures, with final proposals for bridge service performance assessment and service life prediction. Jang et al. [19] established a structural health monitoring system based on wireless smart sensor network (WSSN) and combined it with finite element modeling to evaluate the bridge condition. He et al. [3] analyzed the data signals captured by sensors buried in bridge structures with artificial intelligence-based data processing methods, and developed a bridge structural health monitoring system. It can be seen that the implementation of monitoring data processing and analysis for completed bridges is the primary measure to maintain the health of bridges. Farahmand et al. [20] developed the optimal parameters for improving the support system in cable arch bridges to suppress force fluctuations and overstressing problems.\n\nFurther, since the bridge construction is phased, the stresses and deformations of its structure in each phase can be predicted by modeling and actual measurements [21–23], and once it is found that there is a large error between the actual values monitored and calculated predicted values during construction, it is necessary to correct the relevant calculations in construction, which is the significance of bridge construction control. To assure bridge quality and construction safety, Cho et al. [24] introduced a finite element analysis method by using the obtained data from sensors, to quantitatively assess risk during the bridge construction phase. Wu et al. [25] used simulation to generate a bridge construction schedule, while it took into account the available resources and the interdependence of individual tasks, it was unable to finely examine the effects of structural forces and settlement on the construction schedule after this phase. Tan et al. [26] conducted a study of prestressed concrete bridges under construction, where forward and backward analyses were used to calculate structural deformations, respectively, and the pre-tilt angle of each cantilevered construction pipe section was obtained, which serves as a basis for construction control. Qin et al. [27] described the application of stress-free state theory to bridge construction control and noted that the theory can guide staged construction. There have also been studies utilizing machine learning as a basis for bridge construction control [28–30].\n\nReviewing the aforementioned literature, various approaches such as machine learning, finite element analysis, and simulation techniques have been introduced to implement bridge construction control. However, the above-mentioned methods can produce large errors in practical application owing to the influence of various factors such as construction environment, operation mode and human intervention. For example, complex soil composition, rock types and even climatic conditions will greatly affect the finite element analysis, while the maintenance management of bridges during construction is difficult to realize in all kinds of prediction models, and what’s more, the human errors occurring during construction are even more uncontrollable. Therefore, this paper proposes a structural deformation control of bridge based on parameter identification and error analysis. The deflection calculation of each cantilever section is first introduced based on the conjugate beam method, which is the basis for obtaining the actual elevation. Then the errors brought about by temperature, time and process changes are modeled. Finally, the theoretical value of the cantilever elevation during bridge construction was calculated. When the theoretical value of the elevation has a large error with the measured value, the error model is calibrated so that the predicted value converges to the measured value. The method will be validated in real engineering applications.\n\nThe study was exempt from institutional ethics committee approval. Regardless of construction method, the bridge structure in the construction process will always produce deformation, and the deformation will be affected by many factors, which will easily make the actual position of constructed bridge (elevation, planar position) deviates from the expected state. Thus, it is difficult for the bridge to be joined together smoothly, or the permanent linearity of bridge is not in conformity with design requirements. Taking the bridge construction in Shanxi Province as an example, the bridge has a total length of 681 m, with a width of 15 m for each left and right span its engineering phases are shown inFig. 1. And which can be roughly divided into six stages, including pier construction, each cantilever pouring, side-span joining and main-span joining. Specifically, the cantilever sections were poured in stages and the completed cantilever was fixed at one end and free at the other. Therefore, the cantilever is prone to settlement and deformation due to temperature and workmanship factors, which deviate from the required condition.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319844.g001\n\nConstruction control serves to ensure the safety of the structure during construction and guarantee that the linear and internal state of the structure conforms to the design requirements. However, as construction control is inevitably subject to errors due to, for example, temperature, time and process variations. Therefore, in order to predict the reasonable mold elevation of the next cantilever, it is necessary to observe the deflection changes of the main beams in each construction process of the current cantilever to obtain the measured state. The control parameter error analysis and modified prediction control method is used to compare and analyze the measured state with the original ideal state, to filter out the random error and make a judgment on the systematic error. If there is an obvious systematic error, the first requirement is to correct the data related to the structural calculation, and the parameter error identification is adjusted, and then forward and backward analysis is carried out. The construction control process of bridge deformation based on parameter identification and error analysis is shown inFig. 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319844.g002\n\nIn the theoretical analysis, the deflection calculation of each cantilever section is first introduced based on the conjugate beam method, which is the basis for obtaining the actual elevation. Then the errors brought about by temperature, time and process changes are modeled. Finally, the theoretical value of the cantilever elevation during bridge construction was calculated. When the theoretical value of the elevation has a large error with the measured value, the error model is calibrated so that the predicted value converges to the measured value.\n\nTo implement structural deformation in bridge construction control and further obtain the construction elevation of next cantilever section, the elevation of currently constructed cantilever is required to be measured first. The measured elevation contains the pier elevation and main girder deflection, by calculating their theoretical values and further comparing them with the measured values, the error can be checked and the next step of error analysis can be facilitated.\n\nFor the cantilever deflection calculation of varied sections, the conjugate beam method is employed to solve the problem [31], as shown inFig. 3. The conjugate beam method exhibits extremely high accuracy in bridge engineering, especially in the fitting of deflection curves of simply supported Euler-Bernoulli beams. In the mid-span region where the deflection is large, the relative error of fitting can even be reduced to about 0.5%. This means that the conjugate beam method can predict the deflection changes of bridges very accurately and provide reliable data support for bridge design and monitoring. It is because of the high accuracy and convenient calculation of the conjugate beam method that it is widely used in bridge engineering. When sectionjis constructed, the deflection at section, where any pointKon the main beam is located, can be calculated as [32]\n\n(a) Structural and (b) cantilever deflection calculation diagram for the bridge construction.\n\n(a) Structural and (b) cantilever deflection calculation diagram for the bridge construction.\n\nhttps://doi.org/10.1371/journal.pone.0319844.g003\n\nwhereandrepresent the transverse coordinates of observation pointKand the midpoint of sectionL, respectively.,andare the modulus of elasticity, inertia moment and length of sectionL, respectively. Specifically,denotes the bending moment experienced at the midpoint of sectionLafter sectionjhas been built, which is formed by the weight and applied tensile force of sectionLand subsequent sections built thereafter, and it can be calculated as\n\nThe tension force that forms the moment acted on sectionLrefers to the hanging basket cable tension, e.g., the tension force of cableion sectionLis denoted by.means the self-weight of beam in sectioni, andis the equivalent force arm from sectionito the center of sectionL. Additionally, the step functionrepresents the moment of elastic deformation.\n\nOn the other hand, the pier height is compressed by the beam and self-weight, which also causes the change in cantilever elevation. After sectionjis built, the height of pointKon girder can be expressed as\n\nwhereandrepresent the moment of completion and tensioning of sectioni, respectively, anddenotes one quarter of the pier’s self-weight.Eandare the elastic modulus and cross-sectional area of the pier, respectively, andshows the relative height.\n\nAfter tensioning the prestress in sectionj, the height of pointKcan be denoted as\n\nCombining Eqs.3and4, the difference in elevation at pointKbefore and after tensioning the prestress for sectionjcan be obtained, and which can be expressed as\n\nFurthermore, the difference in elevation at pointKafter the sectionj+ 1 is poured can be calculated as\n\nThe above theoretical calculation of elevation only considers the cantilever’s elastic deformation. However, climate change, construction period, fluctuation of material properties and construction technology, etc. will all lead to the difference between the data used in design and actual construction, and these differences are the main reasons for error between measurement and design [33]. By analyzing the influence of each factor and establishing the functional relationship between these differences and measurement error, accurate bridge construction control can be achieved [34]. The effect of pier height on deflection is analyzed firstly. Since the piers are high, temperature changes affect the measured values; moreover, the piers carry their own weight and the weight of beams added section by section, and their load and compression deformation are increasing. At the same time, the creep deformation and elastic deformation increases proportionally, the proportion coefficient is related to loading time [35], which is expressed as\n\nwheretis the time from completion of each cantilever, andτrepresents the loading time. Since the cantilever beams were built at different times for each section, the starting point for loading time calculation was different. Therefore, the loading time is given byto facilitate the subsequent calculation, whereanddenote the build and load moments of sectionL, respectively. Thus, the pier height in subjected to continuous compressive deformation can be expressed as\n\nwhereindicates the moment of pier completion.\n\nNext, the beam deflection analysis is performed. The beam deflection is formed by self-weight and cable tension [36]. The effect of self-weight on the deflection is continuous, and its creep law is\n\nThe creep pattern of tension deflection caused by steel cables is different from that of self-weight, which is caused by that the steel cables will be loosened under the effect of creep, and the tensile force has to be decreased. Therefore, the creep process of tension deflection can be given as\n\nCombining Eqs.8,9and10, the difference in elevation at pointKbefore and after tensioning of sectionjcan be obtained and it is expressed as\n\nEq.11indicates that any difference between the moment of measurement and ambient temperature will bring about a measurement error. The above equation can be expanded as\n\nIn particular, it is noticed thatand the last term is formally the same as the calculated elevation difference shown in Eq.5. However, considering the differences in process and construction materials, the elastic modulus of actual project will differ from the design data, and the last term in Eq.12can be corrected as\n\nThe other terms in Eq.12can be expanded separately and expressed as\n\nwhere,αis the temperature coefficient of pier,ΔtandΔTrepresent the time interval and temperature difference between the two measurements before and after tensioning, respectively. It is obvious from Eqs.13and14that the measured values contain not only the calculated values, there is also the error caused by ambient temperature, construction period and technological process. Further combining Eqs.5and12, an analytical expression for the relationship between the measurement error and above factors can be obtained by\n\nwhereandare the errors in elastic modulus for piers and girders, respectively.,andrepresent the creep coefficients of deflection owing to pier, girder tensioning and girder self-weight, respectively. Additionally,toare detailed as follows\n\nSimilarly, for the measurement error before and after the cantilever casting of sectionj+ 1, it can be expressed as\n\nBased on the above deflection calculation and error analysis, it is possible to utilize the error expressions shown in Eqs.16and17, and the errors between calculations and measurements can be obtained for all cantilever construction sections, and the relationships between these errors and temperature coefficients, elastic modulus, and creep coefficients can also be studied. It is worth noting that none of these parameters are known accurately, and it is necessary to utilize the measured data from construction to estimate them.\n\nThe six parameters (α,,,,and) in the error model derived above are the parameters which need to be estimated. Linear minimum variance is employed to perform these parameters [37,38]. In this estimation method, the variance of estimated parameters and the weighted average of variance for measurement noise are continuously utilized to obtain the evaluated values. Where the design data is used as the initial valueX(0), the initial varianceP(0) is the error range of field construction parameters, which can be given empirically. The variance for measurement noiseR(x) is available from the data preprocessing. The linear minimum variance estimate can be expressed as\n\nBy solving sequentially and recursively for the parameters at the time of construction on each cantilever section, their valuation is obtained and calculated as\n\nNotably, after processing one measurement point, the measurement varianceR(x) and the measurement value are scalars, and the inverse of the computation for gain matrixG(x) can be written asY(k) =ξ(k) −H(k)X(k) ⋯ ⋯K= 1 ∼ 100.\n\nThese valuations can be used to correct the calculation parameters; and the corrected parameters can be further realized to forecast the deflection or elevation of later cantilever construction, which is an effective measure to improve the construction accuracy.\n\nTaking a bridge in Shanxi shown inFig. 1as an example, the whole construction process is regarded as a system, which is the noise-disturbed process of error analysis and correction for control coefficients with physical prototypes. Therefore, the gray system theory model [39] is selected to predict and control the bridge construction.\n\nAccording to the requirements of gray system theory model, the number of control parameters should not be less than 4. Therefore, when the elevation data observation of cantilever construction in the bridge in Shanxi is carried out, the previous 4 sections of cantilever should be erected according to design state and construction knowledge. The elevation should be observed in the same time interval and the measured elevation of each cantilever should be corrected by the temperature effect, thus, a data series can be formed as follows\n\nwherei= 1, 2, 3 andrepresents the original measured elevation data series.,,anddenotes the measured cantilever elevations of sections 1, 2, 3 and 4, respectively.\n\nThe data series in Eq.20after accumulating (1-AGO) can be expressed as\n\nwherecan be established as a differential equation in the following whitened form\n\nTo simplify the solution of differential equation, the parameter column is set to\n\nThe solution is further carried out by using the least squares method as follows\n\nThe solution of differential equation in whitened form shown in Eq.22is finally obtained by\n\nThe values of elevation change for each cantilever casting section can be predicted according to Eq.24, and then the elevation prediction sequence can be formed by reduction generation (accumulation). The four previous predictions are compared with the data series shown in Eq.20to determine whether error correction needs to be performed.\n\nTaking the construction of a bridge in Shanxi as an example, each cantilever section of the main girder is firstly distinguished for subsequent analysis. As shown inFig. 4a, the bridge has two main piers (piers-7 and 8) and two side piers (piers-6 and 9). The midpoint of mid-span joint is marked as a distinction, the side near pier-7 is the left section of bridge, and the section near pier-8 is the right section of bridge. Furthermore, the two main piers also serve as demarcation points, and they are flanked by the left and right sections of either pier-7 or 8, the four main girders contain 20 cantilevers that need to be poured in sequence. Therefore, the direction and cantilever number are used to name the cantilever for each construction phase, e.g., LL20 denotes the cantilever section-20 in bridge’s left section, which is also located at the left section of pier-7. Additionally, the length of each cantilever is generally consistent, but the cantilever on either side of the abutment is determined based on the actual construction conditions. Furthermore, as shown inFig. 4ball constructed cantilever sections of the bridge from left to right are numbered from No. 1 to No. 83, which facilitates subsequent analysis.\n\n(a) Naming and (b) numbering of all construction cantilever sections.\n\n(a) Naming and (b) numbering of all construction cantilever sections.\n\nhttps://doi.org/10.1371/journal.pone.0319844.g004\n\nIn actual bridge construction, the cantilever 0 on the main pier is poured firstly, and then baskets are hung to each end and cantilevers 1 to 20 are poured in turn at intervals, as shown inFigs. 4aand5a. Before the construction of a cantilever, deflection or elevation observations of the previous cantilever to which it is connected are required to ensure the linearity and stability for the final completed bridge. Therefore, the monitoring position of each cantilever should be set at the end of last cantilever section, as shown inFig. 5c. Three elevation monitoring points are installed in the currently constructed cantilever, one of which is in the middle of cantilever end (Oand), and the other two are symmetrically distributed along the main girder (A,Band,), with a distance of 0.75 m from both sides, which not only measures the cantilever’s deflection, it can also observes the torsional deformation. Notably, the bridge has left and right sides, and the same observation method should be implemented on both sides, as shown inFig. 5b. A plan view of the bridge during construction inFig. 5d.\n\n(a) Construction of cantilever section for main girder around bridge pier-7, (b) left and right sides of the bridge, (c) location of elevation monitoring for construction of the cantilever section and (d) a plan view of bridge.\n\n(a) Construction of cantilever section for main girder around bridge pier-7, (b) left and right sides of the bridge, (c) location of elevation monitoring for construction of the cantilever section and (d) a plan view of bridge.\n\nhttps://doi.org/10.1371/journal.pone.0319844.g005\n\nThe elevation is obtained by measuring the spatial coordinates and deformation values of the construction cantilever using a total station (TCR1201+R400) and a level meter (DSZ01), respectively. Further, since human monitoring of elevation also generates errors, and in order to minimize such errors caused by human operations, the final elevation is derived by averaging ten measurements. On the other hand, temperature variations, especially daytime temperature differences, have a particularly significant effect on the deflection of main girder during construction. To minimize the effect of temperature, the deflection monitoring is scheduled in the morning before the sun rises. After obtaining the actual measured elevation, the actual measured value is compared with the predicted value, and if the error between the two is within a reasonable range, the construction of the next cantilever can be continued according to the prediction model. When the error is overlarge, the prediction model needs to be corrected until the corrected error meets the requirements.\n\nThe most basic requirement for bridge construction control is to ensure the structure’s safety during construction, and it is necessary to keep the structure’s linearity and internal force in accordance with design requirements. For the bridge linear control, the measured deflection during the construction period is compared with the theoretical design deflection, and error analysis and correction prediction should be carried out to obtain the appropriate construction elevation of next cantilever section. Therefore, the results of linearity control after bridge completion and the control data during construction are analyzed, which come to check the conformity of results for bridge construction control.\n\nThe completed bridge linearity is first analyzed, and data are collected from 84 monitoring sections from bridge’s left section to the right. The linearity of the center and both-sides for left-side bridge are shown inFig. 6aand6c. Owing to the bridge’s geographic location and engineering requirements, the elevation decreases continuously along the direction of increasing observation section number. Additionally, the elevations of the measured cantilever sections are basically consistent with the design elevations after error correction, with an error of less than 30 mm, as shown inFig. 6band6d, where the error is calculated by subtracting the measured elevation from design elevation. Moreover, the linear trends measured in the middle and both sides of left-side bridge are in agreement, which further illustrates the effectiveness of structural deformation control in bridge construction control based on error analysis.\n\nElevation errors at (a) center and (c) both-sides of left-side bridge.\n\nElevation errors at (a) center and (c) both-sides of left-side bridge.\n\nhttps://doi.org/10.1371/journal.pone.0319844.g006\n\nSimilarly, the linearities of bridge’s right-side shown inFig. 5bare analyzed inFig. 7aand7c, which plots the elevations of bridge’s right-side located at the center and both-sides after the completion of bridge construction, which are obtained from measurements and design with error corrections. Consistent with the left-side of bridge, the measured elevations along the entire bridge on right-side are basically same with the theoretical elevations obtained after error modification. And all errors are controlled within 30 mm, which is given inFig. 7band7d. However, the elevation at right-side at the bridge’s center is slightly higher than that on left-side, which is determined by the actual engineering requirements.\n\nElevation errors at (a) center and (c) both-sides of right-side bridge.\n\nElevation errors at (a) center and (c) both-sides of right-side bridge.\n\nhttps://doi.org/10.1371/journal.pone.0319844.g007\n\nIn this study, error analysis is applied to obtain the optimal elevation of bridge’s each cantilever construction. The elevation of current construction cantilever is measured and compared with the original design value, and the reason for error between the two is evaluated, and the original design value is revised to correct the error before proceeding to construction of next cantilever. This can ensure the linearity and strength of when bridge construction completes. Obviously, it has been preliminarily confirmed the role of error analysis in bridge construction control from bridge linearities inFigs. 6and7.\n\nIn the implementation of construction control for a bridge in Shanxi, the construction process of each cantilever is divided into four phases, namely: basket positioning, concrete pouring, tensioned prestressing steel, and forward movement of basket. There is a necessity to focus on elevation control of the cantilever after construction and tensioning prestress, respectively. The elevation control data during the construction of main girder from section LL0  ∼  LL20 are randomly selected for analysis.\n\nFig. 8plots the measured elevation and the corrected design elevation with error analysis derived from the last constructed cantilever section during the pouring phase, and they are obtained from cantilever LL0  ∼  LL20 in bridge’s left-section. According to the gray system theoretical model in Section 2.4, the cantilever construction of LL1  ∼  LL4 should be carried out empirically, while the cantilevers from LL5 to LL20 are built by using the theoretical design with error correction mentioned in Section 2. As can be seen fromFig. 8, the error between the theoretical and measured values generated in the center of bridge’s left-section (O) during the construction for each section is not more than 15 mm, and the error between the two generated on one-sides of the bridge’s left-section (A) is less than 20 mm, which are smaller than the errors when the bridge is completed, as shown inFig. 6. This phenomenon is probably explained by the fact that the construction of subsequent cantilever had an unnegligible effect on the deflection on current cantilever.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319844.g008\n\nThen, the measured and modified design values of elevation in the center (O) and one-side (A) of cantilever after tensioning prestressing steel are also listed. As shown inFig. 9, most constructional data of cantilevers in LL5  ∼  LL20 are shown by engineering protocols. It can be noticed that when the cantilever was tensioned with prestressing steel, there is a slight effect on its deflection and elevation, however, this stage reduces the error between measured and measured elevation overall.\n\nSince the bridge construction is critical and irreversible, to validate the effectiveness of proposed method for error analysis and correction in bridge construction control, it can only be achieved by analyzing the linearity of completed bridge and the difference between the designed elevation and measured one in every construction stage. By analyzingFigs. 6–Fig. 9, it can be inferred that at the beginning of one cantilever’s construction, by comparing the measured elevation of previous cantilever with the original design elevation, and further correcting the difference between the two, the revised design elevation can be obtained eventually. The proposed method can make the error generated during bridge cantilever’s construction less than 20 mm, and keep the error of bridge’s elevation after finishing the bridge’s construction less than 30 mm.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319844.g009\n\nThis paper proposes a method for controlling structural deformation in bridge construction control based on error analysis, which is aimed at minimizing the influence of process, material, temperature and environmental factors on the theoretical design, thereby the reasonable linearity and structural strength of the bridge can be guaranteed. The main conclusions is shown as follows:\n\nSignificantly, the error analysis mainly relies on the actual measurement data, and in the actual bridge construction process, the measurement data are always affected by a variety of factors, such as the measurement device’s accuracy, tester’s operation, and environment, which leads to a certain degree of discrepancy between it and the actual situation. Therefore, future research will focus on improving the measurement accuracy of bridge engineering.\n\nMeasured and theoretical elevations with error corrected of cantilevers LL5 ∼ LL20 after pouring and tensioning prestressing steel during the construction of the left-side bridge.\n\nhttps://doi.org/10.1371/journal.pone.0319844.s001\n\npptx",
    "category": "materials_science"
  },
  {
    "title": "Functional perspectives in mental jigsaw puzzles: Insights from eye-tracking, questionnaire, and behavioral data",
    "authors": "Tsuyoshi Yoshioka, Hiroyuki Muto, Jun Saiki, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0321217",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321217",
    "content": "This study investigated cognitive strategies in mental jigsaw puzzles, integrating mental rotation and translation with a focus on directionality and detour arguments. Unlike object mental rotation tasks, these puzzles introduced physical constraints, revealing systematic directional tendencies in both eye movements and subjective reports. Specifically, smaller protruding objects were consistently directed toward larger indented objects. This was accompanied by longer completion times and reduced linearity, paralleling strategies used in physical puzzle-solving. Behavioral asymmetries observed in the puzzles unexpectedly mirrored those found in object mental rotation tasks. While controlling for mental motion directions showed comparable completion times at 300° between tasks, the study did not fully clarify the role of detours, indicating the need for further research.\n\nCitation:Yoshioka T, Muto H, Saiki J (2025) Functional perspectives in mental jigsaw puzzles: Insights from eye-tracking, questionnaire, and behavioral data. PLoS ONE 20(4):\n           e0321217.\n        \n        https://doi.org/10.1371/journal.pone.0321217\n\nEditor:Sheikh Arslan Sehgal, Cholistan University of Veterinary and Animal Sciences, PAKISTAN\n\nReceived:December 7, 2024;Accepted:March 3, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Yoshioka et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Stimuli, raw data, and code are available on the Open Science Framework (OSF) platform athttps://osf.io/4ku38/, where preregistration information and preprint versions (originally made available in 2023) are also accessible.\n\nFunding:This research was supported by JSPS KAKENHI (https://www.jsps.go.jp/j-grantsinaid/) Grant Number 20H00107 awarded to JS. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nJigsaw puzzles, along with related activities such as building blocks and digital games like Tetris®, are widely recognized for engaging mental rotation skills, as suggested by various studies [1–4]. Some studies treat rotation tasks as involving both matching and fitting processes [2,5], such as aligning and joining puzzle pieces, and suggest that these processes share similar cognitive demands across related tasks [4,6]. However, task demands may differ significantly [7]. This may be reflected in the mixed outcomes of studies with primary school children, where puzzle-like mental rotation training showed benefits in arithmetic performance [8,9] but not in matching and puzzle-like tasks [10]. This study pioneers the investigation of cognitive strategies in two tasks under voluntary conditions and could offer deeper insights into cognitive processes in real-world contexts, despite the complexity of cause-and-effect relationships.\n\nControlling experimental variables is fundamental to uncovering clear cause-and-effect relationships, as seen in managing trajectories in mental scanning tasks [11] or imagery [12,13] and directionality [5] in object mental rotation tasks [14]. However, such constraints may not fully reflect the complexity of cognitive strategies in real-life scenarios. For instance, in everyday activities, smaller protruding connectors typically move toward larger indented connectors, as seen when plugging a protruding terminal into an indented power strip. This cognitive strategy persists even though the process can be reversed. While connectors are often described using gendered terminology in electronics, to avoid confusion with biological gender categorization, the present study refers to protruding terminals asT-typeobjects and indented terminals asU-typeobjects (Fig 1A). Reflecting on mental rotation tasks involving pairs of T-type objects, a question arises:Could cognitive strategies differ if the pairs involved one T-type object and another U-type object?\n\nIn each stimulus, participants were asked to judge whether two objects matched or fit.(A): The present study refers to objects (connectors) with a ‘dip’ as U-type and those with a ‘bump’ as T-type, inspired by the shapes and meanings of the Japanese kanji characters for concave and convex.(B.1),(C.1): objects are rotated 60° on the left side.(B.2),(C.2): objects are rotated 60° on the right side.(B.1)represents the less-wall side, while(B.2)represents the wall side. The U-type and T-type objects fit together to make a whole cube. The objects to be matched or fit are wholly or partially shaped, respectively, yet they occupy the same space.\n\nIn each stimulus, participants were asked to judge whether two objects matched or fit.(A): The present study refers to objects (connectors) with a ‘dip’ as U-type and those with a ‘bump’ as T-type, inspired by the shapes and meanings of the Japanese kanji characters for concave and convex.(B.1),(C.1): objects are rotated 60° on the left side.(B.2),(C.2): objects are rotated 60° on the right side.(B.1)represents the less-wall side, while(B.2)represents the wall side. The U-type and T-type objects fit together to make a whole cube. The objects to be matched or fit are wholly or partially shaped, respectively, yet they occupy the same space.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g001\n\nThe novelty of the present study lies in its task design employing U-type and T-type objects, contrasting with traditional tasks focused solely on matching T-type objects. This study introduces amental jigsaw puzzle paradigmto explore cognitive strategies (Fig 1Band1C). Unlike conventional object mental rotation tasks, which primarily assess rotational alignment, this task integrates both rotation and translation, incorporating physical constraints that must be considered when fitting objects together. This design allows for a more ecological investigation of cognitive strategies, bridging the gap between theoretical rotation tasks and real-world spatial problem-solving.\n\nParticipants were asked to judge whether two objects matched in matching tasks (MT: a pair of T-type objects) or fit together in fitting tasks (FT: a pair consisting of a U-type object and a T-type object). In FT, physical constraints required participants to consider how objects interlock when fitting them together. However, the space in the U-type object corresponds precisely with the T-type object in MT, suggesting that FT could be solved similarly to MT by focusing on the space. This task design offers a new perspective on mental rotation tasks by integrating spatial reasoning with physical constraints.\n\nA study by Mutlu et al. [4] supports this matching approach, where participants were instructed to judge whether a puzzle piece would ‘fit’ into a gap, referring to this fit as a ‘match’ condition, indicating similar cognitive processes. Similarly, Frick et al. [15] and Frick and Pichelmann [6] demonstrated the interchangeable use of ‘fit’ and ‘match’ in describing the cognitive process of aligning a rotated ghost with a corresponding hole in puzzle-like tasks. Their findings showed a medium correlation between their puzzle-like tasks and object mental rotation tasks involving matching objects [6].\n\nWhile ignoring physical constraints may be theoretically sound, it might not apply well in real-world contexts. The purpose of jigsaw puzzles extends beyond merely judging a visual match or fit, aiming to achieve a physical fit, as seen in daily activities like fitting suitcases into a car trunk [16]. Motor simulation, involving both visual and physical aspects, prepares for subsequent actions. Therefore, employing strategies similar to those used in physical puzzles might be more effective. This task design allows for detailed investigations of cognitive strategies, particularly in terms of directionality.\n\nIn this study,directionalityrefers to the preferred orientation or movement direction that entities possess. For example, people tend to prefer the path requiring the smallest degree of rotation during manual rotation tasks with three-dimensional (3D) T-type objects, manipulated via a hand knob, even if a longer path in the opposite direction is possible (e.g., rotating 60° clockwise instead of 300° counterclockwise), as shown by Wohlschläger and Wohlschläger [17]. Directionality encompasses different types of movements, similar to the motion of a rigid body: specifically, translation (leftward/rightward, backward/forward, downward/upward) and rotation (counterclockwise/clockwise around axes: pitch, yaw, and roll). Radial movements (inward/outward) are considered a type of translation, as they involve movement toward or away from a central point.\n\nXue et al. [5] were among the first to systematically investigate object mental rotation tasks under conditions where translation directions were controlled in advance, demonstrating that cognitive processing patterns vary depending on the specific object being rotated and aligned. This highlights the importance of considering directionality in cognitive tasks, as different strategies can emerge based on these directional preferences. Various outcomes in directionality may arise when the tasks in this study are performed voluntarily.\n\nOne possibility is that no specific directionality bias exists. In tasks such as FT and MT, where two objects need to be simply matched or fit together, there may be no specific directional bias. This perspective is consistent with findings from eye-tracking research, such as Just and Carpenter [18], which demonstrated that multiple saccades are exchanged between two objects during matching, indicating no inherent preference for one direction over another.\n\nHowever, certain contexts may introduce directionality biases. The first potential bias is a left-to-right preference. This might arise due to a common lateral bias, similar to the one observed in reading this sentence, where movement progresses from left to right. Walker [19] demonstrated that people often depict motion in still images with a left-to-right directional bias, suggesting that this preference is deeply rooted in visual processing and may influence how we approach rotation tasks.\n\nIn contrast, a right-to-left bias could also emerge, particularly in right-handed individuals. The proximity of objects to the right hand, which is dominant for most people [20], may contribute to this bias. For example, the handedness questionnaire by Nicholls et al. [20] suggests that right-handed individuals often hold a matchbox with their left hand while striking a match with their right. This tendency might encourage a preference for right-to-left directionality in tasks that involve rotation or alignment.\n\nAnother bias to consider is a rotated-to-canonical position bias. Tarr and Pinker [21] found that people tend to rotate objects into their canonical positions, or the most familiar orientations. This bias is likely to appear in FT, particularly when rotating a larger U-type object (remnants of a rotated cube) to align with a smaller T-type object to create an upright cube. This process reflects the cognitive preference for recognizing objects in their familiar orientations.\n\nLastly, a piece-to-assembly bias, commonly observed in jigsaw puzzle solving, may also emerge. Jigsaw puzzles often involve transferring smaller pieces to a larger, partially completed assembly, and this bias may become evident when rotating smaller T-type objects to fit with larger U-type objects.\n\nBeyond directionality, there may be two distinct trajectory strategies in solving FT, as it might be approached similarly to physical jigsaw puzzles. Unlike MT, which lacks obstacles, FT introduces barriers that could require participants to navigate puzzle pieces through indirect routes (detours) rather than direct routes (shortcuts). This study considers multidisciplinary literature to incorporate more ecological perspectives, thereby enriching the review.\n\nMental Rotation:Shepard and Metzler [14] demonstrated a linear relationship between angular disparity and reaction time in mental rotation tasks involving 3D T-type objects, suggesting the use of shortcuts across two sides without barriers for aligning two objects. Indeed, Cave et al. [22] found steeper slopes across temporal distances in sequentially cued tasks with prior shape and orientation information, indicating the involvement of more than just attentional shifts. These findings align with the concept of rotation and translation as two independent physical motions in a rigid body.\n\nMental Scanning:Kosslyn et al. [11] found similar linearity in mental scanning tasks, where participants imagined moving a point across a straight path in a bird’s eye view, visualizing unimpeded traversal through a bay’s barriers. This supports a cognitivetunneleffect [23], favoring the use of shortcuts in such scenarios.\n\nMental Navigation:Thorndyke and Hayes-Roth [24] explored mental navigation in a corporate building, showing that both map learners (bird’s-eye view) and experienced navigating learners (worm’s-eye view) excelled at estimating distances along direct paths onsite, supporting the idea of cognitive tunneling.\n\nMotor imagery:Sekiyama [25,26] revealed behavioral asymmetry in hand laterality tasks, highlighting the challenges of imagining physical movements. Echoing these findings, Tomasino and Gremese [27] suggested the involvement of the bilateral sensorimotor network in processing bodily stimuli and motor imagery. Notably, the mental rotation of hand tools may activate the premotor cortex in the hemisphere opposite the dominant hand, influenced by the object’s manipulability [28], which could similarly play a role in handling puzzle pieces.\n\nAffordances and Embodied Cognition:Gibson’s affordance theory explains that the environment offers certain actions to actors [29], while embodied cognition examines how the body itself or the body’s interaction with the environment shapes cognition [30]. Flusberg and Boroditsky [12] demonstrated the role of embodied cognition, showing that mental rotation slows under motor imagery following the physical experience of heavier objects, with similar effects reflected in mental navigation findings [31].\n\nLockman [32] and Lockman and Adams [33] studied this interplay through the detour paradigm, observing that infants engage with their environment, particularly barriers, to learn about affordances [34]. In contrast, mature adults quickly resort to detours when encountering barriers, often without considering shortcuts—such as when parking a car.\n\nThe primary objective of this research is to investigate how physical constraints influence cognitive strategies in FT under voluntary conditions.\n\nConceptualization and Predictions.Daily observations suggest that when solving physical jigsaw puzzles, there is often a directional preference for moving smaller pieces toward larger assemblies, with detours commonly employed. These interactions shape cognition and reflect the affordances provided by the puzzle environment, where contextual cues influence movement strategies. In the context of FT, the presence of larger U-type objects may alter the functional role of smaller T-type objects, guiding both their directionality and trajectories.\n\nThis study employs subjective reports and eye-tracking to capture potential directional biases. Previous research has employed eye-tracking to investigate various strategic differences, including those across angles [18], sex [35–38], congruency [39], spatial ability [36,40], and time-course [18,36].\n\nIn addition to directionality, this study investigates behavioral performance in FT. As shown inFig 1, imagining the physical fitting of puzzle pieces in condition (B.1) is less complex than in (B.2), as there are fewer obstacles along the way. Furthermore, even within conditions (B.1) and (B.2), the degree of obstacles varies depending on the angle (e.g., 60° versus 300°). Cave et al. [22] suggested that longer distances lead to longer reaction times in sequentially cued tasks, involving both mental rotation and translation. Echoing this, longer reaction times in the present study may correspond to longer trajectory lengths due to the presence of obstacles, while shorter trajectories result in shorter reaction times. In contrast, conditions (C.1) and (C.2) involve no obstacles, indicating typical behavioral symmetry around 180°. In sum, examining the relationships between reaction time, angles, and the side of the U-type object may help distinguish between shortcut and detour strategies.\n\nThis study took the stance that there will be a piece-to-assembly bias in the directionality argument and a tendency toward detours in the trajectory argument. The primary predictions are as follows:(1)an emphasis on the larger U-type object as the destination for the smaller T-type object (functional differences in cognitive strategies),(2–1)longer completion times when navigating obstacles (behavioral asymmetry in FT), and(2–2)longer times and distinct differences, contrasting with the symmetry and linearity typically assumed in MT (behavioral differences between FT versus MT).\n\nA total of 30 out of 40 participants, all of whom were undergraduate and graduate students with normal or corrected-to-normal vision, and most of whom were right-handed (as assessed by the FLANDERS handedness questionnaire [20,41]), completed the entire main experiment (Table 1). The participation rate aligns with similar eye-tracking studies [37–39] and exceeds the recommended sample size of 25 suggested in a pilot study [7], employing similar methodology to previous research [17,42]. The remaining 10 participants exited early due to reasons such as drowsiness, potential overtime, fluctuations in eye-movement signals, eye fatigue, and dizziness. Of the original 40 participants, 37 completed a post-experimental questionnaire, with seven experiencing the experiment partially. Participants enrolled in the experiment between June 26, 2023, and August 2, 2023.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321217.t001\n\nEthics approval for this study was provided by the Ethics Committee of the Graduate School of Human and Environmental Studies of Kyoto University (Initial Approval No. 23-H-5; Revised Approval No. 23-H-8). All participants provided written informed consent prior to the commencement of the experiment. This study was conducted in accordance with the Declaration of Helsinki.\n\nStimuli were created using Blender®version 3.1.Fig 2presents the bisectional rotation axes, with initial angles at 0°, and objects rotated counterclockwise around the bisectional axis. A total of 576 images were generated, with variables including six angles (0° to 300°), two head types (left and right forward protrusions), same-mirrored pairs (congruent and incongruent), six object types, and two tasks. The T-type object was created by subtracting 115 unit-cubes from a whole cube of 125 unit-cubes, and the U-type object was created by subtracting the T-type object from the whole cube. The visual angles of the objects roughly ranged from 3.9° to 5.5°.\n\nThe yellow axes are bisectional between the local blue and red axes. The cross points of the local axes on both sides correspond to the geometric centers of whole cubes of 5 ×  5 ×  5 unit-cubes. The directions of the axial arrows and their rotations are aligned with the right-hand rule, where the thumb points in the direction of the bisectional axis, and the curled fingers indicate the rotational direction.\n\nThe yellow axes are bisectional between the local blue and red axes. The cross points of the local axes on both sides correspond to the geometric centers of whole cubes of 5 ×  5 ×  5 unit-cubes. The directions of the axial arrows and their rotations are aligned with the right-hand rule, where the thumb points in the direction of the bisectional axis, and the curled fingers indicate the rotational direction.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g002\n\nThe experiment was conducted in a private dark room with no ambient lighting to minimize distractions. An EyeLink®1000 Plus Desktop Mount eye tracker was used in binocular remote mode, positioned on a table with a chin rest between the participant and a 15.6-inch monitor, which served as the primary light source, at a distance of approximately 735 mm. A foot pedal with two steps was placed under the table to record behavioral responses. The eye tracker used a 25 mm camera lens with a sampling rate of 1,000 Hz, managed by the supplier’s supplemental computer and operating system version 5.50. Only the left eye was tracked to avoid reflections from the monitor on the right eyeglass lens. Eye-tracking data were extracted using the supplier’s Data Viewer software version 4.3.1, and the experiment was run using PsychoPy®version 2023.1.2 [43] on a Windows®10 computer.\n\nFig 3Aoutlines the experiment, which included the handedness questionnaire, a practice block, the main block, and a post-experimental questionnaire. The practice and main blocks began with calibrating and validating the eye-tracking (C/V). The entire procedure took approximately 75 minutes. This study used a five-point C/V [39], with validation criteria set to an average error below 0.5° and a maximum error of 1.0°.\n\n(A)PreQ: handedness questionnaire, C/V: calibration and validation of eye-tracking, PostQ: tactics questionnaire. The fitting task (FT) and the matching task (MT) are randomly presented in every trial. The practice block included 16 trials without feedback, using unique stimuli to simulate the main block. The main block consisted of six subblocks, each containing 96 visual stimuli. A total of 576 stimuli were randomly assigned to each subblock, ensuring an equal distribution of conditions (task, congruency, rotation side, angle factors) across the first and last three subblocks. Questionnaires were completed on a tablet computer using custom applications developed in Android Studio®version 2022.2.1.(B)A fixation cross appeared randomly, lasting between 800 and 1,200 msec in increments of 100 msec, as a precaution against rhythmical responses. The size of the fixation cross differs from that used in the main experiment. Reaction time and eye-tracking data were measured at the third step.\n\n(A)PreQ: handedness questionnaire, C/V: calibration and validation of eye-tracking, PostQ: tactics questionnaire. The fitting task (FT) and the matching task (MT) are randomly presented in every trial. The practice block included 16 trials without feedback, using unique stimuli to simulate the main block. The main block consisted of six subblocks, each containing 96 visual stimuli. A total of 576 stimuli were randomly assigned to each subblock, ensuring an equal distribution of conditions (task, congruency, rotation side, angle factors) across the first and last three subblocks. Questionnaires were completed on a tablet computer using custom applications developed in Android Studio®version 2022.2.1.(B)A fixation cross appeared randomly, lasting between 800 and 1,200 msec in increments of 100 msec, as a precaution against rhythmical responses. The size of the fixation cross differs from that used in the main experiment. Reaction time and eye-tracking data were measured at the third step.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g003\n\nFig 3Bdetails each trial. Participants were instructed to press the right foot pedal if the two objects matched or fit, and the left pedal if they did not, responding as quickly and accurately as possible. Between trials, they were asked to fixate on a cross at the center of the screen. To minimize hand gestures [42] or movements during the experiment, participants were instructed to place their fingers crossed (hands covered) below their stomachs.\n\nThe post-experimental questionnaire used a two-alternative forced-choice method with four randomized questions. Participants were asked to indicate whether they generally matched (fit) the left block with the right block or vice versa. Participants were instructed to respond honestly.\n\nThis study employed a within-participants design, manipulating angles (Angle: 0°, 60°, 120°, 180°, 240°, 300°), rotation side (R-side: left, right), and task type (Task: FT, MT). Subjective reporting variables included direction (Direction: left →  right, left ←  right). This research collapsed both head and object types, and analyzed only the congruent condition. Key metrics included reaction time (RT) and error ratio (ER) for behavioral data, dwell time ratio (DTR) for eye-tracking data, and positive responses for self-report data.\n\nThis study calculated ER as the ratio of errors to total responses, and determined DTR as the ratio of fixation time within one rectangular area of interest (AOI) on the rotation side, to the combined fixation time within two rectangular AOIs. A DTR value greater than 0.5 indicates a bias toward the rotated object’s side.Fig 4provides a detailed example of how the eye-tracking data were calculated. Behavioral and eye-tracking data were collected at the third step shown inFig 3B.\n\nGreen rectangle: left AOI (area of interest), red rectangle: right AOI, yellow circle: fixation, magenta arrow: saccade, cyan arrow: the first saccade and transit saccade, and numerals: fixation sequence and dwell time. DTR: dwell time ratio. The fixation times within each AOI were tallied to calculate the DTR, which is the ratio of fixation time within the AOI on the rotation side to the total fixation time across both AOIs. A DTR value greater than 0.5 indicates a bias towards the rotated object’s side. The AOIs were standardized to capture the activity related to two objects located on the left and right sides of the screen, each sharing the same area (960 ×  1,080 pixels). The fixations shown are illustrative.\n\nGreen rectangle: left AOI (area of interest), red rectangle: right AOI, yellow circle: fixation, magenta arrow: saccade, cyan arrow: the first saccade and transit saccade, and numerals: fixation sequence and dwell time. DTR: dwell time ratio. The fixation times within each AOI were tallied to calculate the DTR, which is the ratio of fixation time within the AOI on the rotation side to the total fixation time across both AOIs. A DTR value greater than 0.5 indicates a bias towards the rotated object’s side. The AOIs were standardized to capture the activity related to two objects located on the left and right sides of the screen, each sharing the same area (960 ×  1,080 pixels). The fixations shown are illustrative.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g004\n\nBehavioral data underwent screening to exclude responses over 30 seconds, those below 200 msec [44], and outliers identified using the median absolute deviation method with a threshold of 2.5 [45]. Approximately 80% of congruent trials were analyzed for mean correct RT, with all participants achieving a trial accuracy rate above 70%.\n\nEye-tracking data underwent screening to exclude the first fixation, trials without effective records, and fixations outside AOIs, leading to the removal of about 2% of congruent trials. The analysis also excluded trials that were removed from correct RT. Self-report data focused on participants who completed or partially completed the main block and the post-experimental questionnaire. A secondary analysis found no significant gender differences in key metrics, such as RT, ER, and DTR [46]. These findings indicate that gender did not play a significant role in shaping participants’ behavioral or eye-tracking patterns in this study. Hence, gender was collapsed in the analysis to streamline the interpretation of results.\n\nAll analyses and visualization were performed using R software [47], along with the following packages: rstatix (version 0.7.2) [48], ARTool (version 0.11.1) [49,50], DescTools (version 0.99.49) [51], ggpubr (version 0.6.0) [52], and gridExtra (version 2.3) [53]. Parametric tests included repeated measures analysis of variance (RM-ANOVA), with Greenhouse–Geisser correction and effect sizes [54], as well as the one-sample Student t-test. Nonparametric tests included RM-aligned rank transform-ANOVA (RM-ART-ANOVA) with effect sizes [50,55], ART contrasts (ART-C) contrast test [56], the one-sample sign test, the Breslow–Day test, the Pearson chi-square test with Yates correction, and the binomial test. All tests were two-tailed, with priority-based and Bonferroni–Holm p-value corrections applied where appropriate.\n\nThis study investigates directionality using both eye-tracking and self-report data. If FT is not solved like physical jigsaw puzzles, no bias is expected in DTR, and the self-report data should reflect chance levels. On the other hand, if FT follows physical operations, participants are expected to operate from the smaller T-type object to the larger U-type object, with increased focus on the U-type assembly as the end point of the movement, showing differences from MT.\n\nAdditionally, this study analyzes the relationship between reaction times and angle conditions to examine trajectories. If FT is not solved like physical jigsaw puzzles, typical behavioral symmetry, as assumed in MT, should be observed. In contrast, if FT follows physical operations, behavioral asymmetry is anticipated. Specifically, longer reaction times are expected when the U-type object is rotated at 240° and 300° on the left side and at 60° and 120° on the right, while shorter times are expected at 60° and 120° on the left and at 240° and 300° on the right. This pattern would create behavioral asymmetry around 180°, distinct from the symmetrical patterns typically assumed in MT. Furthermore, these behaviors would reflect reduced linearity in FT compared with MT.\n\nDTR.Fig 5Aillustrates task differences for DTR. The three-way RM-ANOVA for Task showed a significant interaction effect among Angle, R-side, and Task [F(5, 145) =  2.842,p= .036,= .008,= .088]. A simple effects analysis of the two-way RM-ANOVA for Task showed significant interaction effects of Angle and Task on both rotation sides (allp< .001,≥ .026,≥ .143). A simple-simple effects analysis of the one-way RM-ANOVA for Task on both rotation sides showed significant main effects of Task at all angles (allp< .01,≥ .191,≥ .338). The one-sample Student t-test, with Angle and R-side collapsed, showed a significant difference from 0.5 in FT [t(29) =  16.909,p< .001,= .908]. Hence, the fovea dwelled more on the side with a rotated object, particularly on the side with a rotated U-type object compared to a rotated T-type object.Table 2provides descriptive statistics for DTR measures.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321217.t002\n\nTask differences at rotation-side levels (A) for dwell time ratio across angles and (B) for the proportion of positive responses in subjective matching/fitting direction.(A)Eye-tracking dwell time ratio (DTR) is the ratio of dwell time within an AOI on the rotation side to that within both AOIs combined. Values above 0.5 indicate more time spent fixating on the rotation side, associated with rotated U-type objects in the fitting task (FT) and T-type objects in the matching task (MT).(B)Questionnaire results show significant associations between Direction and Task on both rotation sides. The present study refers to indented object as ‘U-type’ and protruding object as ‘T-type.’ In FT, participants tended to match or fit T-type objects leftward toward U-type objects rotated on the left, and rightward toward those rotated on the right. ns:p≥ .05,*p< .05,**p< .01,***p< .001.\n\nTask differences at rotation-side levels (A) for dwell time ratio across angles and (B) for the proportion of positive responses in subjective matching/fitting direction.(A)Eye-tracking dwell time ratio (DTR) is the ratio of dwell time within an AOI on the rotation side to that within both AOIs combined. Values above 0.5 indicate more time spent fixating on the rotation side, associated with rotated U-type objects in the fitting task (FT) and T-type objects in the matching task (MT).(B)Questionnaire results show significant associations between Direction and Task on both rotation sides. The present study refers to indented object as ‘U-type’ and protruding object as ‘T-type.’ In FT, participants tended to match or fit T-type objects leftward toward U-type objects rotated on the left, and rightward toward those rotated on the right. ns:p≥ .05,*p< .05,**p< .01,***p< .001.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g005\n\nFig 5Billustrates task differences for direction proportion. The Breslow–Day test showed a significant non-homogeneity of odds ratios between Direction and Task on the strata of rotation sides [(1, N =  37) =  44.209,p< .001, W =  1.195]. The post hoc Pearson chi-squared test showed significant associations between Direction and Task on both rotation sides (allp< .001, W ≥ .334).\n\nAt individual task levels, the chi-squared test for both FT and MT showed significant associations between Direction and R-side (allp< .05, W ≥ .126). The binomial test for FT showed significant biases from 0.5 on both rotation sides (allp< .001); for MT, there was only a significant bias on the right rotation side (p= .005). Hence, FT operated in a systematically directional manner, while MT was systematic on the right but not the left rotation side.Table 3provides descriptive statistics for subject report measures.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321217.t003\n\nFigs 6Aand6Billustrates rotation-side differences and angle-pair differences for correct RT, respectively. The three-way RM-ANOVA for Angle and R-side showed no significant interaction effect among Angle, R-side, and Task (= .001,= .024), but a significant interaction effect between Angle and R-side [F(3.26, 94.60) =  21.290,p< .001,= .028,= .423]. A simple effects analysis of the one-way RM-ANOVA for R-side, after collapsing tasks, showed significant main effects of R-side at three angles (60°, 240°, 300°; allp< .001,≥ .050,≥ .512) but not at other angles (all≤ .009,≤ .170). Another simple effects analysis of the one-way RM-ANOVA for Angle showed significant main effects of Angle on both rotation sides (allp< .001,≥ .392,≥ .686). The post hoc paired Student t-test on both rotation sides showed significant differences both between 60° and 300° and between 120° and 240° (allp< .05,≥ .160).\n\n(A) Rotation-side differences for correct RT across angles after collapsing tasks. Correct RT across angles (B) at rotation-side levels after collapsing tasks and (C) at task levels after collapsing rotation sides. (D) Regression lines for correct RT in tasks across half-round angular disparity after collapsing rotation sides and half of angles. (B)Rearranged graph from(A).(D)Significant linear trends observed in the fitting task (FT) and the matching task (MT). Dashed lines indicate regression lines with equations; shaded areas represent 95% confidence intervals. ns:p≥ .05,*p< .05,**p< .01,***p< .001.\n\n(A) Rotation-side differences for correct RT across angles after collapsing tasks. Correct RT across angles (B) at rotation-side levels after collapsing tasks and (C) at task levels after collapsing rotation sides. (D) Regression lines for correct RT in tasks across half-round angular disparity after collapsing rotation sides and half of angles. (B)Rearranged graph from(A).(D)Significant linear trends observed in the fitting task (FT) and the matching task (MT). Dashed lines indicate regression lines with equations; shaded areas represent 95% confidence intervals. ns:p≥ .05,*p< .05,**p< .01,***p< .001.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g006\n\nTo explore symmetry after collapsing asymmetric behaviors, the R-side factor was collapsed. The one-way RM-ANOVA for Angle in both tasks, after collapsing rotation sides, showed significant main effects of Angle (allp< .001,≥ .321,≥ .585), and the post hoc paired Student t-test in both tasks showed no significant difference either between 60° and 300° or 120° and 240° (all≤ .081).Fig 6Cillustrates this. Both FT and MT exhibited the same behavioral asymmetry, with the same characteristics at 120°, which diminished when collapsing rotation sides.\n\nA previous study by Shepard and Metzler [14] simplified rotation sides to a general direction and reduced angles to a 0°–180° range, facilitating linear regression analysis and allowing for exploratory examination of cognitive shortcuts and detours in FT.\n\nA trend analysis, after collapsing to a 0°–180° range, showed significant linear relationships between angular disparity and correct RT for both FT [F(1, 87) =  126.01,p< .001,= .325,= .592] and MT [F(1, 87) =  281.64,p< .001,= .515,= .764]. While FT demonstrated significant linearity, the angular disparity explained approximately 19% less variability in correct RT compared to MT.Fig 6Dillustrates this trend.\n\nFig 7Aillustrates task differences for correct RT. The separate three-way RM-ANOVA for Task showed a significant main effect of Task [F(1, 29) =  33.338,p< .001,= .040,= .535], but no other significant effects (≤ .008,≤ .080). Hence, FT generally took more time overall than MT.Table 4provides descriptive statistics for correct RT measures.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321217.t004\n\n(A)Significant main effect of Task observed.(B)Controlling for confounders: subjective matching/fitting direction (first and second levels) and both this direction and rotational direction (first and third levels). FT: fitting task, MT: matching task. ns:p≥ .05,*p< .05,**p< .01,***p< .001.\n\n(A)Significant main effect of Task observed.(B)Controlling for confounders: subjective matching/fitting direction (first and second levels) and both this direction and rotational direction (first and third levels). FT: fitting task, MT: matching task. ns:p≥ .05,*p< .05,**p< .01,***p< .001.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321217.t005\n\nTask differences in ER were less distinctive, with speed compatible with accuracy. The three-way RM-ART-ANOVA for Task showed no significant interaction effect between Angle, R-side, and Task (= .017), but a significant interaction effect between Angle and Task [F(5, 667) =  3.657,p= .009,= .027]. The post hoc ART-C showed a significant bias of FT over MT only at 120° [t(667) =  2.680,p= .045].Table 5provides descriptive statistics for ER measures.\n\nFrom the participants’ subjective reports (Fig 5B), FT on the left rotation side shared the same direction as MT on the right rotation side. At the same time, rotation also has a direction. This study accounted for these two confounders in an exploratory analysis by controlling for rotational direction and flipping the MT graph on the R-side right level at 180° (Fig 8).\n\nHorizontal arrow in red: direction of matching, rotational arrow in green: direction of rotation. The first row displays the left rotation side in the fitting task. The second row shows the right rotation side in the matching task, controlling for the subjective direction. The third row further controls for the rotation direction by flipping the positions at 60° to 300° and 120° to 240° from the second row.\n\nHorizontal arrow in red: direction of matching, rotational arrow in green: direction of rotation. The first row displays the left rotation side in the fitting task. The second row shows the right rotation side in the matching task, controlling for the subjective direction. The third row further controls for the rotation direction by flipping the positions at 60° to 300° and 120° to 240° from the second row.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g008\n\nFig 7Billustrates task differences for correct RT after controlling for direction confounders. The two-way RM-ANOVA for Task showed a significant interaction effect between Angle and Task [F(10, 290) =  7.180,p< .001,= .041,= .198]. A simple effects analysis of the one-way RM-ANOVA for Task showed significant main effects of Task at five angles (allp< .001,≥ .080,≥ .378) except 180° (= .015,= .052). The post hoc pairwise comparison mostly showed significant differences between Task levels at five angles (allp< .05,≥ .149), except at 180° (= .052) and between FT and MT (flipped) at 300° (= .078). Thus, FT still took more time than MT at most angles from 0° (60°, 120°, 240°).\n\nThis study examined how physical constraints influence cognitive strategies in FT under voluntary conditions by addressing the following three points:\n\nSubjective reports and eye-tracking data both support the directionality argument. Participants consistently showed a preference for matching/fitting smaller T-type objects with larger U-type objects, indicating a directional bias in cognitive strategies. This was further reinforced by eye-tracking data, which showed stronger dwell times on rotated U-type objects, underscoring a systematic directional bias in task processing. Together, these findings suggest that participants employed a directional strategy resembling the physical act of assembling jigsaw puzzles, where pieces are typically fit in a specific direction.\n\nLonger completion times, reduced linearity, and directionality in FT—mirroring physical jigsaw puzzles—support the detour argument. Nevertheless, unexpected breaches of symmetry and linearity in MT raise challenges for this perspective. Instead, behaviors observed in both tasks, after controlling for motion directions, suggest the involvement of both shortcuts and detours in FT.Fig 9illustrates this angle-dependent behavior, with shortcuts occurring at angles under 90° and detours at angles over 90°.\n\nDashed lines denote the degrees of represented routes. The present study refers to indented object as ‘U-type’ and protruding object as ‘T-type.’ The diagram is illustrative.\n\nDashed lines denote the degrees of represented routes. The present study refers to indented object as ‘U-type’ and protruding object as ‘T-type.’ The diagram is illustrative.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g009\n\nAngle-dependent behaviors themselves appear to hold. The face inversion effect [57,58] highlights orientation-sensitive cognitive thresholds at roughly ± 90° [59–61], applicable to other stimuli by shaping prototypes or expertise in recognition [62–64]. Similarly, an investigation by Edelman and Bülthoff [65] implied a decline in object recognition accuracy for novel angles away from trained angles, mostly from 80° onward after repeated sessions. The role of object recognition in mental rotation may be complemented by physical rotation research by Gardony et al. [66], where participants appeared to make congruence judgments between two objects during same trials with angular disparities below 90°. The threshold concept extends to strategies; for example, occupational experiences of podiatrists might lead to strategic shifts from motor to non-motor imagery in mentally rotating inverted foot stimuli [67].\n\nAlternative explanations.Given the voluntary nature of the conditions, several alternative explanations might account for the findings, though none fully explain them in isolation, particularly the systematic directionality and angle-dependent behavior. Instead, a combination of these explanations, along with the trajectories, may provide a more comprehensive understanding of the present findings. These include the following.\n\nOne possibility is detours in MT. While MT lacks physical barriers, the possibility of detours cannot be entirely dismissed. The mental process of matching objects in MT may be analogous to fitting T-type objects into U-type objects in FT. This process might involve mentally envisioning a tight-fitting ‘box’ around the T-type object, requiring detours to fit the T-type object within this U-type ‘box.’ This possibility is supported by the findings that linearity in MT accounted for only half the variability and by the observed behavioral asymmetry. However, MT explained 19% more variability than FT, suggesting that while detours may be involved in both tasks, they likely play a lesser role in MT.\n\nA second potential explanation is coherence in concepts. Behavioral asymmetry may arise from conceptual coherence, akin to phenomena observed in the Stroop effect, Simon effect, or stimulus-response compatibility [68,69]. For example, Guiard [70] demonstrated how sensory laterality (ear stimulation) aligns with rotational directions in motor actions (steering wheel), illustrating an interaction between rotational direction and laterality. This concept could apply to the mental rotation tasks in this study. Specifically, the coherence between rotation [17,21] and translation (matching/fitting) directions could account for much of the observed behavioral asymmetry, as illustrated inFig 10. When the translation direction is coherent with the object’s rotational direction (e.g., a leftward translation paired with counterclockwise rotation), cognitive processing may be facilitated (e.g., leftness and leftness). Conversely, when translation and rotation directions are incoherent (e.g., leftward translation paired with clockwise rotation), cognitive processing may be delayed (e.g., leftness and rightness). This interpretation suggests that translation itself, regardless of whether it represents a shortcut or detour, can create systematic asymmetries due to the coherence of laterality. Such coherence in concepts may also influence behavioral asymmetries seen in motor responses [17,72], rotational motion aftereffects [73,74], laterality in both objects [75,76] and hands [25,77].\n\nHorizontal arrow in red: direction of translation, rotational arrow in green: direction of rotation. The head was selected as the starting point of rotation, given that this area may receive more biased fixation during the mental rotation of T-type objects [5,71]. Pairing a leftward comparison direction with a counterclockwise rotation from the head is coherent (leftness and leftness), compared to a leftward comparison with clockwise rotation from the head (leftness and rightness). This same asymmetry can be also achieved with the directions of translation and rotation switched. The same coherence behavior applies to object mental rotation tasks, achieved by visualizing T-type objects emerging from the blank spaces surrounding U-type objects. The present study refers to indented object as ‘U-type’ and protruding object as ‘T-type.’.\n\nHorizontal arrow in red: direction of translation, rotational arrow in green: direction of rotation. The head was selected as the starting point of rotation, given that this area may receive more biased fixation during the mental rotation of T-type objects [5,71]. Pairing a leftward comparison direction with a counterclockwise rotation from the head is coherent (leftness and leftness), compared to a leftward comparison with clockwise rotation from the head (leftness and rightness). This same asymmetry can be also achieved with the directions of translation and rotation switched. The same coherence behavior applies to object mental rotation tasks, achieved by visualizing T-type objects emerging from the blank spaces surrounding U-type objects. The present study refers to indented object as ‘U-type’ and protruding object as ‘T-type.’.\n\nhttps://doi.org/10.1371/journal.pone.0321217.g010\n\nA third possibility is parts recognition. Hoffman and Richards [78] suggested that visual processing often involves segmenting shapes at their concave regions, which are perceived as natural dividing points. In this study, both T-type and U-type objects contained concave regions; however, U-type objects featured more extensive concave grooves. These more pronounced concave features in the U-type objects may require more complex cognitive processing as the visual system attempts to structurally segment these shapes. Such increased complexity could explain the longer reaction times observed in tasks involving the U-type objects, particularly at 0°, where no rotation is required.\n\nThe observed behavior at 0° may reflect object recognition or figure-ground segregation processes within the ventral pathway, including regions such as the lateral occipital complex, V2, and potentially V1 [79–82]. Conversely, the dorsal pathway, which is involved in mental rotation and includes the inferior and superior parietal cortices [27,83], may handle the mental manipulation of these objects. This division of labor between the ventral and dorsal pathways might explain the performance dip at a 60° angular disparity.\n\nA fourth explanation is part/whole comparisons. Bilge and Taylor [16] demonstrated a tendency for bisected 3D objects to result in longer completion times than whole 3D stimuli, particularly at 0° and angles greater than 90°. This suggests that FT may employ a piecemeal strategy, whereas MT relies on a more holistic approach. The angle-dependent behavior observed in this study could result from a strategy shift occurring at 90°, as indicated in previous research [84].\n\nA fifth potential explanation is motor planning. FT may require more complex motor planning than MT, given the physical nature of fitting objects. This aligns with research indicating longer execution times for more complex motor sequences [85,86]. While the actual translation time for detours may be short, the preparation time for movement could be longer, contributing to the extended completion times observed in FT.\n\nLastly, bodily constraints may also play a role. While this study attempted to minimize the beneficial effects of hand gestures [42], such restrictions may have inadvertently hindered performance. Previous research has shown reduced performance in awkward postures during hand laterality tasks, particularly when the hand is positioned on the back rather than the front [13,87], and this effect is influenced by right-handedness [88]. This is consistent with findings of slower responses in amputees with aesthetic prostheses [89] and expanded body representations in macaques after using tools [90,91]. These results suggest that even when the hand is resting in a natural position on the front, right-handedness and the resulting bodily constraints may have exerted a greater impact on FT under motor imagery compared to MT.\n\nThe relationship between jigsaw puzzle solving and mental rotation tasks has been explored in various contexts, including manual tasks. Aguilar Ramirez et al. [92] conducted an angle-free analysis and found that men tend to excel in 3D mental rotation tasks, while women outperform men in assembling two-dimensional (2D) jigsaw puzzles. The puzzle-assembling findings are consistent with earlier research on children using tablet-based 2D puzzles [93] but differ from research involving physical puzzles [94]. Aguilar Ramirez et al. [92] also performed a mediation analysis, interpreting their results as evidence of partial independence between visuospatial abilities in jigsaw puzzle solving and mental rotation tasks.\n\nHowever, the analysis may not fully account for other potential factors. For example, sex differences in physical and motor characteristics [95], as well as differences in fine motor skills [94,96], may help explain the superior performance of females in assembling 2D jigsaw puzzles. Another relevant factor is the frequent 90° flips involved in rotation during physical jigsaw puzzle-solving, where pieces are repeatedly flipped until they fit or match. This process may reflect a greater tendency among females to attempt fitting pieces into incorrect locations [92]. This flipping process is analogous to how Tetris®operates, with each press of the controller rotating a piece by 90°. As such, a trial-and-error approach may play a more crucial role than visuospatial abilities in this context. Previous research on the cognitive training effects of Tetris®found no significant cognitive transfer, such as mental rotation performance, but rather task-specific transfer, rhetorically referring to the training as ‘Game over’ [97]. Nevertheless, mental rotation itself may still contribute to performance in the block game [3].\n\nInterestingly, this study’s secondary analysis found no gender differences in eye-tracking or behavioral outcomes for both FT and MT [46], which used a pair of 3D T-type objects from Shepard and Metzler [14], alongside a pair of 3D smaller T-type objects and their corresponding larger U-type objects. Hence, the present research provides a more direct, ‘apple-to-apple’ comparison, investigated through detailed angle-specific analysis in both object mental rotation and mental jigsaw puzzle tasks [7], thereby facilitating a deeper understanding of functional differences in visuospatial strategies.\n\nOther research explored cognitive tasks using jigsaw puzzle pieces [4] or ghost figures [6,15], both in 2D formats. These studies share similarities with the present research in that mental jigsaw puzzles appear to engage mental rotation. Notably, monotonic, linearity-like behaviors have been observed [6,15], and increased neural activation in the dorsolateral prefrontal cortex at larger rotation angles has been documented [4], aligning with findings from a meta-analysis on mental rotation [27].\n\nIn terms of shapes, both piece and asembly pairs add up to primitive shapes, such as square-like shapes [4] or circles [6], resembling the cube used in the present study. Regarding individual assembly shapes, Mutlu et al. [4] employed white puzzle pieces fully framed by dark edges and gray assemblies, while Frick et al. [15] and Frick and Pichelmann [6] employed light-gray ghost figures fully framed by dark edges and dark circles or squares. Both studies employed T-type puzzle pieces that were color-matched with the corresponding T-type spaces of the U-type assemblies. Hence, despite the U-type and T-type pairings, these visual cues could imply a predominantly T-type to T-type pairing. Indeed, Frick and Pichelmann [6] employed a factor analysis to demonstrate that the ghost puzzle tasks measured the same ability as established object mental rotation tasks. This reflects the interchangeable use of ‘fit’ and ‘match’ in these studies [4,6,15]. The presence of fully framed U-type figures may have provided the inner space with a clear meaning, guiding the participants’ perception of the T-type shapes.\n\nIn contrast, the present study’s fitting areas for U-type pieces are not fully framed by unit cubes, resulting in partial shapes. This is similar to the process in physical jigsaw puzzles, where fitting mostly involves adding pieces along partially shaped edges. Notably, even with incomplete information, a whole can be sometimes effortlessly perceived. Specifically, figures can still be recognized even when partially shaped, as illustrated by the Rubin vase, Kanizsa triangle, and Gregory’s Dalmatian dog illusions. Once the figure is recognized, its identification becomes easier in subsequent trials. This recognition process could be facilitated in FT by identifying the space within the U-type assembly and matching the two T-type pieces, typically using shortcuts. Hence, those with stronger Gestalt perception skills—typically, the ability to form a meaningful whole from parts—may have relied on such shortcuts, whereas participants who found it more challenging to fully recognize the figure might have employed alternative strategies, such as detour strategies via motor imagery.\n\nPrevious mental rotation studies using fMRI have indicated that object-related affordances influence activation in motor-related regions. For instance, Vingerhoets et al. [28] required participants to compare two objects—either hands or tools—and determine whether they were the same or different. Their imaging data revealed activation in primary regions associated with mental rotation, including the superior parietal lobule, for both hand and tool stimuli. However, they observed a key difference in premotor activation: hand stimuli elicited bilateral premotor activation, while tool stimuli primarily activated the left premotor cortex in right-handed individuals. These findings were interpreted as evidence that the afforded actions of objects play a role in engaging motor-related regions through motor imagery in a way that reflects natural, real-world interactions [28]. In the context of the present study, puzzle pieces may similarly elicit affordance-driven activation patterns in motor-related regions, potentially clarifying participants’ trajectory strategies.\n\nThe sample size in this study was determined based on a behavioral pilot study using unique methodologies [7]. While this provided a foundation, the calculation may not fully account for all analyses conducted in this study, potentially leading to underestimation or overestimation in certain areas. To mitigate this, effect sizes have been provided where relevant, and raw data are extensively available. Another limitation is the potential reduction in internal validity due to the nature of voluntary conditions in the study design, as discussed in the alternative explanations for the detour argument. Participants were allowed to choose their cognitive strategies, which introduced variability that complicates the control of confounders, such as directionality. However, this variability mirrors real-world scenarios, providing valuable insights into natural cognitive processes.\n\nOther limitation pertains to the angular disparities employed in this study. Angles of 0°, 60°, 120°, 180°, 240°, and 300° were systematically used to assess rotation and translation strategies. While this approach ensures consistent measurement and comparability, it may not fully capture behaviors associated with more randomized angular variations, which could better simulate real-world scenarios. One possible improvement could involve the use of angular variation bins, as employed by Gardony et al. [66].\n\nAdditionally, this study exclusively tested configurations involving smaller T-type objects and larger U-type objects, referencing the traditional stimuli by Shepard and Metzler [14], but did not examine cases with smaller U-type objects and larger T-type objects. Under a piece-to-assembly perspective, it is expected that smaller U-type objects could also move toward larger T-type objects, as seen when plugging a U-type protective cap onto a T-type terminal. However, this perspective may vary depending on context, and future research could investigate whether this reversed configuration elicits similar cognitive strategies or introduces distinct spatial biases.\n\nBuilding on the findings and discussion points of this study, future research could explore several avenues for further investigation.\n\nFirst, future experiments could examine the neural correlates of translation strategies and object recognition, potentially using fMRI or EEG, to clarify the underlying cognitive mechanisms. For instance, investigating the activation of motor-related regions, as highlighted by Vingerhoets et al. [28], could provide deeper insights into the role of motor imagery and affordances during mental jigsaw puzzle tasks.\n\nSecond, the role of conceptual coherence warrants further exploration. The behavioral asymmetry observed in this study may originate from conceptual coherence, where the output of mental rotation is influenced by decision-making steps, disrupting the expected pure symmetry and linearity across angles.\n\nThird, more detailed eye-tracking analyses could be conducted. The current research primarily used two bisectional sides to investigate directional bias. However, future studies could analyze fixation patterns on specific parts of the objects to gain valuable insights into strategies such as piecemeal versus holistic approaches [16]. This could offer a deeper understanding of cognitive processing during FT and MT.\n\nFourth, metacognitive approaches [98] could be explored in addition to objective data to further investigate the role of detours. Ongoing research aims to examine participants’ self-awareness of their strategies during MT and FT. Understanding how individuals reflect on their cognitive strategies could provide valuable insights into these tasks.\n\nLastly, incorporating hand tracking in future research could open new avenues for understanding the role of motor function and its interaction with visuospatial strategies. Upcoming research aims to investigate how hand-tracking data could enhance our understanding of trajectory strategies during FT and MT. This approach could bridge the gap between the start and end points in cognitive tasks by examining the middle stages, offering a more comprehensive view of how physical constraints influence cognitive strategies.\n\nThis research demonstrates that participants approached mental jigsaw puzzles using strategies similar to those employed in physical puzzle-solving, with a notable emphasis on systematic directionality under voluntary conditions. The study introduces mental jigsaw puzzles as a pioneering experimental methodology that integrates mental rotation and translation. Although behavioral asymmetry, reduced linearity, and angle-dependent behavior were observed, the roles of detours remain partially unclear, underscoring the need for further research.\n\nThe authors thank Dr. Kurt Debono, a former laboratory member who opted for anonymity, and Yana Yu for their support of the eye-tracking system.",
    "category": "mathematics"
  },
  {
    "title": "A lightweight detection algorithm of PCB surface defects based on YOLO",
    "authors": "Shiwei Yu, Feng Pan, Xiaoqiang Zhang, Linhua Zhou, Liang Zhang, Jikui Wang, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0320344",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320344",
    "content": "Aiming at the problems of low accuracy and large computation in the task of PCB defect detection. This paper proposes a lightweight PCB defect detection algorithm based on YOLO. To address the problem of large numbers of parameters and calculations, GhostNet are used in Backbone to keep the model lightweight. Second, the ordinary convolution of the neck network is improved by depthwise separable convolution, resulting in a reduction of redundant parameters within the neck network. Afterwards, the Swin-Transformer is integrated with the C3 module in the Neck to build the C3STR module, which aims to address the issue of cluttered background in defective images and the confusion caused by simple defect types. Finally, the PANet network structure is replaced with the bidirectional feature pyramid network (BIFPN) structure to enhance the fusion of multi-scale features in the network. The results indicated that when comparing our model with the original model, there was a 47.2% reduction in the model’s parameter count, a 48.5% reduction in GFLOPs, a 42.4% reduction in Weight, a 2.0% reduction in FPS, and a 2.4% rise in mAP. The model is better suited for use on low-arithmetic platforms as a result.\n\nCitation:Yu S, Pan F, Zhang X, Zhou L, Zhang L, Wang J (2025) A lightweight detection algorithm of PCB surface defects based on YOLO. PLoS ONE 20(4):\n           e0320344.\n        \n        https://doi.org/10.1371/journal.pone.0320344\n\nEditor:Azim Uddin, Zhejiang University, China\n\nReceived:October 17, 2024;Accepted:February 16, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Yu et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The PKU-Market-PCB dataset was downloaded fromhttps://robotics.pkusz.edu.cn/resources/dataset/.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nWith the development of the electronics industry, it has become an important component of modern manufacturing. Printed Circuit Boards (PCBs) are crucial electronic components that provide circuit connections and hardware support for devices. However, PCBs are typically made up of materials such as glass fibres, composite epoxy resins, and laminates. The manufacturing process is very complex and prone to errors, resulting in the presence of defects on the surface of PCBs [1]. Therefore, in order to ensure the safety and reliability of electronic products, it is imperative to conduct surface defect detection on PCBs before they leave the factory [2].\n\nTraditional manual detection is easily influenced by external factors, which affects the quality and efficiency of the detection and introduces uncertainty [3,4]. Later on, due to the development of electronic devices, researchers started using image detection instead of manual detection [5]. Liu and Qu processed PCB images using a hybrid recognition method of mathematical morphology and pattern recognition and labelled PCB defect images for defect identification using an image aberration detection algorithm [6]. Khlong Luang and Pathum Thani proposed a PCB defect classification method using arithmetic and logical operations, Circular Hough Transform (CHT), Morphological Reconstruction (MR), and Connected Component Labelling (CCL) [7]. Mukesh Kumar et al. proposed a method for detecting defects in bare PCBs by combining image enhancement techniques with standard template generation particle analysis [8]. Although the accuracy of these methods reaches the detection needs, the detection speed is low, which is more limited in the actual detection. Currently, there has been rapid progress in the field of deep learning, with researchers successfully applying it to the task of defect detection in target objects [9]. Kuo et al proposed a graph convolutional network to detect components on printed circuit boards [10]. Liang and Gu et al proposed a multi-task learning model for locating and identifying waste materials simultaneously [11]. Nowakowski et al used CNN (a deep learning convolutional neural network) to identify and classify specific types of e-waste [12]. However, the application in PCB defect detection is limited by the computational power and time delay. The existing mainstream deep learning object detection algorithms can be mainly classified into two categories: one category is represented by the R-CNN series, which are two-stage algorithms [13]. This algorithm utilizes a region proposal network in the first stage to generate a large number of anchor boxes. The second stage involves performing classification and regression operations on these anchor boxes. Niu et al. proposed an improved PCB defect detection algorithm based on Faster RCNN [14]. They replaced ordinary convolutions with depthwise separable convolutions to reduce computational complexity. They also improved the feature pyramid to extract features at several depths, effectively combining low-level geometric details with semantics. Zeng et al. proposed an enhanced multi-scale feature fusion algorithm based on an asymmetric balanced feature pyramid network [15]. They utilized dilated convolutions to capture abundant contextual information and achieved effective PCB defect detection. Zhang et al. proposed a cost-sensitive residual convolutional neural network that effectively balances the different misclassification costs of sample imbalance and false defects in PCB detection [16]. Another category is represented by first-stage algorithms such as YOLO (You Only Look Once) and SSD (Single Shot MultiBox Detector) [17,18]. These algorithms directly utilize convolutional neural networks to extract target features and perform classification and regression on the targets. Li J et al. propose an improved algorithm based on YOLOv3, which uses a real PCB picture and a virtual PCB picture with synthesized data as a joint training dataset, which greatly increases the recognizability of training electronic components and provides the greatest possibility for data enhancement [19]. Lim JY et al. propose an enhanced deep learning network that addresses the difficulty in inferring tiny or varying defects on a PCB in real-time [20]. The proposed model is capable of performing accurate and reliable real-time PCB inspection with the aid of an automated alert capability. Chen W et al. propose a Transformer-YOLO network detection model to solve the problem of low accuracy and efficiency in printed circuit board (PCB) defect detection [21]. The network model better balances the detection accuracy, detection speed, and the volume. Jiang W et al. A joint multiscale PCB defect target detection and attention mechanism. The article built a feature fusion module to efficiently fuse low-level feature information with high-level feature information to produce a more complete feature map and improve the accuracy of fault recognition [22].\n\nIn order to address the above issues, this paper proposes a lightweight PCB surface defect detection model for low-computing power devices based on the YOLOv5 model.\n\nThe YOLO series algorithm is a single-step object detection algorithm based on convolutional neural networks, which significantly improves speed compared to two-step object detection algorithms. The network architecture of YOLOv5 consists of four components: input, backbone, neck, and prediction. The first part of the input includes the Mosaic data enhancement method and adaptive anchor box calculation. The second part of the system is Backbone, which consists of the Focus structure, CSP structure, and SPP structure, primarily used for feature extraction. The Focus structure deepens the feature dimension of the input image through slice operations. The CSP architecture divides the feature maps of the base layer into two parts and then merges them through a cross-stage hierarchical structure. The SPP module extracts feature information at different scales, increasing the receptive field and enriching the expressive power of the feature map. The third part Neck is the feature fusion part which includes the FPN+PAN structure. The FPN architecture efficiently conveys strong semantic features from top to bottom, aggregating parameters from different backbone layers to different detection layers, thereby enhancing the network’s ability to extract features. The fourth part Prediction includes Bounding box loss function calculation and NMS non-maxima suppression. The GIOU_Loss is used as the loss function for bounding box in Yolov5. During the post-processing stage of object detection, NMS is mostly used for filtering bounding boxes. Yolov5 employs a weighted NMS approach.\n\nThis article proposes an enhanced model based on a single-stage detector, which improves classification accuracy and defect detection speed. Additionally, the computational complexity has been reduced. To address the problem of large numbers of parameters and calculations, GhostConv and GhostBottleneck are used in Backbone to keep the model lightweight. The improved YOLOv5 network is more suited for industrial applications in the real world due to its lighter network structure and lower hardware requirements. Second, slow model detection is caused by the YOLOv5 neck network’s CBS structure’s high memory utilization and a huge number of ordinary convolutional parameters. The number of parameters in the neck network can be efficiently decreased and the model detection speed increased by using DSConv to improve the ordinary convolution in the CBS structure. Afterwards, convolutional neural networks are prone to lose a large amount of high-level feature information after many convolution operations, resulting in a decrease in the detection ability of the network. Therefore, through the multi-head self-attention force Swin Trans-former module across the inter-window information interoperability characteristics, and the original C3 module fused with the composition of the new module C3STR, in order to better retain the global feature information at all scales. Solves the problem of confusion caused by background clutter and simple defect types in defect images. Finally, the PANet network structure is replaced with the bidirectional feature pyramid network (BIFPN) structure to enhance the fusion of multi-scale features in the network. During the network training process, because of the different sizes of different targets, it leads to the fact that the features of large targets can be retained as the convolution goes deeper during the convolution process, while the features of small targets may disappear. Therefore, it is necessary to fuse feature layers of different depths of the same target. Although PANet can effectively fuse different feature layers, it is still a simple addition of different features. However, due to the different sizes of the detected targets in different images, features with different resolution sizes are generated during training. They are still simply summed in PANet, which will result in unequal weighting of different sized features of the same type on the fused output. Large size features are incorporated more into the network while small size features contribute less. In order to enhance the detector’s ability to adapt to targets of different scales by integrating features from multiple scales. This helps to address the challenge of large differences in defect scales and poor detection capabilities for small defects. The network structure of our model is shown inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g001\n\nMobileNet, ShuffleNet, EfficientNet, etc. are often used in the detection of surface defects in lightweight hot-rolled strips [23–25]. The use of DWConv deep convolution or GConv group convolution has been achieved to lighten the model detection task [26,27].\n\nGhostNet is a lightweight convolutional network architecture proposed by Han K, et al [28]. The Ghost module is also known as Ghost Convolution. The fundamental concept is to improve the computational efficiency of the network by using ordinary linear variation to obtain redundant feature maps.Fig 2depicts the structural layout of the Ghost module.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g002\n\nThe specific process of GhostNet is\n\nThe first step is the convolution operation,is the input feature map,is the output m feature maps, andis the convolution kernel of size. The second operation is the linear operationfor each feature mapin, and finallyoutput feature mapsare obtained, and after calculation, it can be concluded that the ordinary convolution operation is about s times of Ghost module.\n\nThe GhostBottleneck module is the bottleneck layer in the GhostNet network architecture. It is composed of two Ghost modules that are stacked. By substituting the features generated by direct linear transformation for the ones provided by ordinary convolution, the model’s complexity is significantly reduced. The first Ghost module is followed by the Relu activation function, and the second Ghost module is followed only by the batch normalisation process. This structure not only reduces the model parameters and computation but also optimises the feature maps through the Ghost modules and improves the detection efficiency of the model. In addition, the two Ghost modules in Ghost Bottleneck can be connected by a deep convolution with stride =  2.Fig 3depicts the structural layout of the GhostBottleneck module.\n\nLeft: Ghost bottleneck with stride = 1; right: Ghost bottleneck with stride = 2.\n\nLeft: Ghost bottleneck with stride = 1; right: Ghost bottleneck with stride = 2.\n\nhttps://doi.org/10.1371/journal.pone.0320344.g003\n\nSlow model detection is caused by the YOLOv5 neck network’s CBS structure’s high memory utilization and a huge number of ordinary convolutional parameters. The ordinary convolution in the CBS structure is lightened and improved to decrease the number of neck network parameters and increase the speed of model detection. Depthwise Separable Convolution (DSConv) uses less resources and requires few memory [29]. The number of parameters in the neck network can be efficiently decreased and the model detection speed increased by using DSConv to improve the ordinary convolution in the CBS structure.\n\nThere are two stages in DSConv. Depthwise convolution is the initial step. This step uses a different convolution kernel to conduct convolution for each input channel. Pointwise convolution is the second step. This step uses convolution to modify the number of channels based on the pointwise convolution findings.\n\nAssumeis the input feature size,is the number of input channels,is the output feature size,is the number of output channels, andis the convolution kernel size. The computation of ordinary convolutionis:\n\nThe computationof DSConv is:\n\nThe ratio of DSConv to ordinary convolutional computation is:\n\nFrom the above equation, it can be seen that the computational volume of DSConv is much less than that of normal convolution.\n\nFig 4displays the improved CBS model’s structure based on DSConv. By adding DSConv to the YOLOv5 neck network, the CBS structure’s regular convolution is reconstructed into depthwise and pointwise convolutions. This structure is defined as DBS. Model detection speed can be increased by decreasing the amount of parameters and memory utilisation of the YOLOv5 neck network.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g004\n\nConvolutional neural networks are prone to lose a large amount of high-level feature information after many convolution operations, resulting in a decrease in the detection ability of the network. Therefore, through the multi-head self-attention force Swin Trans-former [30] module across the inter-window information interoperability characteristics, and the original C3 module fused with the composition of the new module C3STR, in order to better retain the global feature information at all scales. The improved C3STR structure is shown inFig 5.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g005\n\nThe Swin-Transformer module is composed of paired Window Multi-head Self-Attention (W-MSA), Shifted Window Multi-head Self-Attention (SW-MSA) and Multi-Layer Perceptron (MLP) blocks. The sublayers between each module are connected using residual edges. The W-MSA module first divides the windows in different regions and then completes the computation of self-attention separately. This can greatly reduce the computational complexity and improve the training speed of the network. SW-MSA module adds the offset mechanism, i.e., sliding window operation mechanism, based on W-SMA module. SW-MSA first re-slices the window partitions between the continuous self-consciousness layers and obtains the new window layout again by cyclic shifting of the sliding method. Then use the cross-window connection technique to recalculate the attention weights inside each newly generated window. In order to achieve the feature unit to exchange feature information between different windows, capture more different contextual information, to improve the ability to obtain the global information of the network. By limiting the computation to windows, these two sub-modules considerably lower the computational complexity when compared to the Transformer self-attention MSA sub-module.\n\nDuring the process of convolution, the fine details of low-level features are often lost in the downsampling process [31]. To obtain feature maps with richer semantic information, replace PANet in the Neck with BiFPN. The use of a bidirectional network connection method based on the weighted bidirectional feature pyramid structure (BiFPN) improves the effectiveness of surface defect detection on PCB boards. The main idea of BiFPN is the bidirectional cross-scale connections and weighted feature fusion [32]. The network structure of BiFPN and the BiFPN network structure used in this paper is shown inFig 6.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g006\n\nis the intermediate feature of P6 layer andandare the input and output features. The band-weighted feature fusion formula for BiFPN is:\n\nWhere: Conv is the corresponding convolution operation; Resize is the up-sampling or down-sampling operation; ω is the corresponding weight of each layer, which is used to distinguish the importance of different features in the process of feature fusion; and ε is a very small non-zero number.\n\nBiFPN networks possess the ability to perform feature fusion at several levels across various scales, while also exhibiting bidirectional connectivity. The model eliminates the P3 and P7 layer feature fusion nodes that have minimal contribution to the network in order to decrease the computational workload. Additionally, it incorporates an edge to connect the input deterioration outputs. Acquire profound semantic data and preserve additional geographical details without incurring additional expenses. Utilizing the fusion of shallow feature maps enhances the precision of detecting small targets. This leads to a decrease in the expenses associated with processing and storage, while simultaneously enhancing the precision of detection.\n\nPKU-Market-PCB is a publicly available dataset from Peking University’s Open Laboratory for Intelligent Robotics, and it is a publicly synthesized PCB defect dataset [33]. The dataset contains 693 images of PCB defects that were cropped to produce 10,668 images. The dataset consists of 10,668 images, each of which contains one of six types of defects: missing hole (Mh), mouse bite (Mb), open circuit (Oc), short (Sh), spur (Sp), and spurious copper (Sc).Table 1shows the number of images for each defect type. Defects in the PCB images were labelled using the LabelImg tool and stored in the Pascal VOC dataset format. The dataset was then divided into a training set and a test set in a ratio of 8:2.Fig 7shows the defect images in the PCB defect dataset.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g007\n\nThe specific configuration of the experimental environment is shown inTable 1.\n\nThe parameter settings for this experiment are shown inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.t002\n\nDue to the small dataset, the training process employs a transfer learning method, where pre-trained weight parameters are loaded on the PCB surface defect dataset. At the beginning of the training, there is a large distance between all the parameters obtained randomly and the final training result. Training with a very large learning rate will result in unstable values. So a small learning rate is used at the beginning to get closer to the approximate location of the solution space, and at this stage the learning rate is increased to the initially set value. Throughout the initial three training Epochs, the model’s learning rate gradually increases. Upon the completion of three Epochs, the learning rate will be modified to 0.01.\n\nTable 3shows the specific parameters of the model and the results of the ablation experiments. Our model parameters decreased by 47.2%, GFLOPs decreased by 48.5%, Weight decreased by 42.4%, mAP increased by 2.4%, and FPS decreased by 2.0% when compared to the YOLOv5s model. The introduction of GhostNet achieves a lightweight model. PConv uses ordinary convolution for spatial feature extraction on only some of the input channels. Keeping the rest of the channels unchanged at the same time ensures that the inputs and outputs have the same number of channels. The computational complexity of the model is effectively reduced while preserving the spatial information. When the model outputs feature maps, there are many output features that are very similar. These similar feature maps can basically be obtained by simple linear transformations, without the need for complex non-linear transformations. One of the feature maps can be obtained by cheaply transforming another feature map, and one of the feature maps can be considered the ‘Ghost’ of the other. Therefore, since some of the feature maps are not obtained by convolution operation, a cheaper operation is used to generate the ‘Ghost’ feature maps. Therefore, the missing part of the information will reduce the quality of feature extraction when the PCB background is cluttered, resulting in a slight decrease of mAP from 94.8% to 94.2%. Lightweight improvement of the ordinary convolution in the CBS structure by using DSConv. It effectively reduces the number of parameters in the neck network and improves the model detection speed. By fusing Swin-Transformer with the C3 module on the neck. The parameters and GFLOPs had a small rise, while the modeled mAP showed a significant improvement of 3.3%. It effectively enhances the model’s ability to deal with the cluttered background of defect images and the easy confusion of defect types. Replacing the PANet in the neck network with a BiFPN resulted in a 1.1% increase in the model’s mAP. This is because BiFPN networks can perform multi-level feature fusion across scales while having bi-directional connectivity. Gain deep semantic information and retain more positional information. The shallow feature maps are fused to improve the detection accuracy of small targets such as PCB surface defects. In contrast to PANet, BiFPN references Attention to increasing the weights of the fused features of different sizes. It dynamically learns to adjust the contribution of each scale so that the network can better integrate features of different sizes as they become available. At the same time, it adds residual connections to enhance the feature representation.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.t003\n\nIn order to show the effect of C3STR directly,Fig 8shows the visual comparison of the feature maps before and after adding the C3STR module. It can be seen from the figure that the addition of C3STR makes the model acquire more detailed information about the target and the target features are more obvious. C3STR enables the algorithm to have a larger sensory field while fully retaining more strong semantic information in the feature map. This is more conducive to recovering the feature information at the defects in order to obtain high-quality feature maps of PCB surface defects, which provide rich feature map information for the lower-level detection tasks. It achieves a more accurate localisation of the defect target, thus improving the detection accuracy of the network.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g008\n\nOur model’s mAP compared to the six defects of YOLOv5s is shown inTable 4. The mAP of Mh, Mb, Oc, Sh, Sp, and Sc increased by 1.9%, 3.4%, 1.4%, 1.9%, 2.5%, and 3.6%, respectively. Mb, Sp, and Sc show significant improvement, whereas the improvement in Mh, Oc, and Sh is not evident. The former features are less obvious and belong to small targets, and the model improves the detection of small targets, so the lift is higher. The latter features are more obvious, so the lift is not high.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.t004\n\nBased on the above analysis, the inclusion of GhostNet and DBS has effectively reduced the parameters, GFLOPs, and weight of the model. The introduction of Swin-Transformer and BiFPN significantly improves the model’s mAP.Fig 9depict some detection results of our model.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.g009\n\nIn this paper, we choose SSD, Faster R-CNN, Retina-Net, YOLOv3, YOLOv4, YOLOv7, and YOLOv8 to compare the performance with our model.Table 5demonstrates that our model’s mAP surpasses that of SSD, Faster-RCNN, Retina-Net, YOLOv3, YOLOv4, and YOLOv7 by a significant margin. The SSD uses a multi-layer feature fusion approach. The feature extraction part of SSD uses VGG as the main part. Due to the low network complexity of VGG, it is difficult to extract the key target feature content in the PCB. For small targets such as PCB defects, their features cannot be fully extracted, resulting in a mAP that is 25.8% lower than our model when Parameters, GFLOPs, and FPS are much higher. Faster R-CNN is a two-stage detection algorithm. Candidate frames are first generated and then classification and regression operations are performed to get the location and category of the target. The tracing frame mechanism of Faster R-CNN achieves comprehensive recognition of targets in the inspected image by traversing the feature map. However, due to the complex background of PCB boards, the difference between defective targets and normal targets is small. When the tracing frame starts traversing, the selected targets may contain normal regions, resulting in a larger impact of the detection model on the category accuracy rate. Meanwhile, the algorithm is computationally intensive, and the mAP and FPS are 18.0% and 70.0% lower than our model, respectively. The detection speed is difficult to meet the requirement of real-time detection. The YOLOv3 is poor at capturing small targets. The detection accuracy of YOLOv4 is 12.7% lower than our model, while the detection speed is also low, making it difficult to deploy. YOLOv7 adopts a new feature extraction structure, ELAN, and designs a deeper network with an accuracy of 89.6%. However, the deeper network often tends to lead to the loss of small targets and edge information, which is not conducive to PCB defect detection. Additionally, the mAP of our model is slightly higher than YOLOv8 by 2.5%. This is due to the fact that most of the current methods for detecting PCB surface defects are only good for specific defect categories and lack good applicability to multiple categories of defects. We have made corresponding improvements to address specific needs. Moreover, the parameters and GFLOPs of the model is much higher than other models due to the introduction of GhostNet and DBS. This indicates that the model is capable of meeting the detection requirements of low computational power platforms.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320344.t005\n\nIn this paper, a lightweight PCB defect detection algorithm based on YOLO is proposed. To address the problem of large numbers of parameters and calculations, GhostNet are used in Backbone to keep the model lightweight. Second, the ordinary convolution of the neck network is improved by depthwise separable convolution, resulting in a reduction of redundant parameters within the neck network. Afterwards, the Swin-Transformer is integrated with the C3 module in the Neck to build the C3STR module, which aims to address the issue of cluttered background in defective images and the confusion caused by simple defect types. Finally, the PANet network structure is replaced with the bidirectional feature pyramid network (BIFPN) structure to enhance the fusion of multi-scale features in the network. The results indicated that when comparing our model with the original model, there was a 47.2% reduction in the model’s parameter count, a 48.5% reduction in GFLOPs, a 42.4% reduction in Weight, a 2.0% reduction in FPS, and a 2.4% rise in mAP. The model is better suited for use on low-arithmetic platforms as a result. The experimental results show that the improved lightweight network obtains better detection results. However, there is still potential for further improvements in terms of detection speed and efficiency. In the next study, we will introduce richer datasets to strengthen their generalisation ability.",
    "category": "mathematics"
  },
  {
    "title": "Urdu adaptation and validation of a disease-specific quality-of-life questionnaire in a Pakistani population of Achalasia",
    "authors": "Sameen Abbas, Syed Sikandar Shah, Tayyab Saeed Akhhtar, Kiran Hameed, Saima Mushtaq, Amjad Khan, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321933",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321933",
    "content": "Achalasia, a rare esophageal disease marked by dysphagia, impacts health-related quality-of-life (HRQoL), measurable by disease-specific tools like achalasia-specific questionnaire (ASQ) that assess symptom severity and QoL. However, to ensure its reliability and validity across different populations, cross-cultural adaptation is necessary. So, for this reason, this study aimed to validate an Urdu-translated version of an ASQ in a Pakistani population of achalasia patients.\n\nA prospective cross-sectional study involving 52 participants was conducted at the Center for Liver and Digestive Diseases, Holy Family Hospital, Rawalpindi. ASQ was translated into the Urdu language by a forward-backwards translation process with expert input. Validation included factor analysis, known-group techniques, Cronbach’s alpha for reliability, and an independent t-test comparing ASQ scores with Eckardt scores for criterion validity.\n\nAmong 52 participants (27 males, median age 30 years; 25 females, median age 48 years), 63.5% had Achalasia type I, 26.9% type II, and 9.6% type III. Factor analysis confirmed a well-defined construct with good validity, and internal consistency was strong (Cronbach’s alpha = 0.89). The ASQ scores significantly correlated with Eckardt scores (p < 0.05), confirming its validity. 73.1% of participants found the translated version easy and completed in a short time duration.\n\nUrdu-translated ASQ proved to have good psychometric properties, with strong evidence of validity, reliability, and feasibility regarding health status in Pakistani achalasia patients. It can be recommended as a reliable QoL measure for clinical and research purposes. Future studies should explore its application in larger, more diverse cohorts and further refine its use in achalasia management.\n\nCitation:Abbas S, Shah SS, Akhhtar TS, Hameed K, Mushtaq S, Khan A (2025) Urdu adaptation and validation of a disease-specific quality-of-life questionnaire in a Pakistani population of Achalasia. PLoS ONE 20(4):\n           e0321933.\n        \n        https://doi.org/10.1371/journal.pone.0321933\n\nEditor:Ali Ahmed, Riphah International University, Pakistan\n\nReceived:November 18, 2024;Accepted:March 13, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Abbas et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All data are in the manuscript andsupporting informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAchalasia is a rare disease caused by the loss of ganglionic cells in the esophagus, leading to the denervation of the smooth muscles. It affects approximately 1–3 individuals per 100,000 and is mostly diagnosed in people aged 25–60. The condition is characterized by esophageal aperistalsis (lack of coordinated contractions) and impaired relaxation of the lower esophageal sphincter (LES) during swallowing, resulting in obstruction and dilation of the esophagus. Symptoms include difficulty swallowing (dysphagia), regurgitation, chest pain, and weight loss [1]. Diagnosis is typically made using a barium swallow X-ray to assess esophageal dilation and poor emptying, as well as esophageal manometry to measure LES relaxation and peristalsis and is classified into three subtypes: classic achalasia, achalasia with compression, and spastic achalasia, based on the pattern of pressure in the non-peristaltic esophagus [1,2].\n\nUnderstanding quality-of-life (QoL) in achalasia requires a comprehensive framework that accounts for both symptom severity and its broader psychosocial consequences. The World Health Organization’s Quality of Life (WHOQOL) framework and the biopsychosocial model provide valuable perspectives, emphasizing the interplay between biological dysfunction, emotional distress, and social limitations. This approach is particularly relevant for moderate to severe medical conditions, as it assesses how the disease progression and related interventions impact daily functioning. Patient-focused questionnaires are commonly used to measure QoL, serving purposes such as validating diagnostic procedures, monitoring patient improvement, evaluating the effectiveness of treatments, and guiding clinical interventions [3,4]. In the case of achalasia, the Eckardt score and the achalasia-specific quality of life questionnaire (achalasia-DSQoL questionnaire and/or ASQ) are widely utilized to assess the quality-of-life (QoL) in patients with achalasia.\n\nEckardt score was first used and implied in the early 1990s and was based on the clinical practices of the researchers. It is a simple questionnaire that is widely employed for estimating QoL in patients of achalasia [5]. ASQ questionnaire is a straightforward, easy-to-use tool used for assessing clinical manifestations of achalasia, designed by Urbach and his colleagues, and is a validated ten items-based questionnaire where quantification and qualifications of esophageal symptoms of achalasia patients were made possible relating to dysphagia of solids as well as liquids, specific types of foods, other related symptoms, and overall QoL and/or health of patients of achalasia [6]. Its simplicity allows for practical application in clinical and research settings, making it accessible for both patients and healthcare providers. As achalasia is a rare disease with a very low prevalence, Urbach et al. were not able to validate their questionnaire in a population other than the one for which it was designed.\n\nCultural diversity can influence the applicability of health-related questionnaires [7] like ASQ. To ensure validity across different populations, the Food and Drug Administration (FDA) recommends validating the health status reported by patients in terms of their ethnic and linguistic differences, especially when applying the questionnaire to a new or different population [8]. Cross-cultural adaptation addresses the challenges related to cultural and linguistic differences and involves adapting and comparing the questionnaire to different ethnicities based on its source with that of the target population [9]. Additionally, validating the questionnaire in the local language not only improves communication between patients and healthcare professionals but also enables the assessment of QoL based on patients’ experiences without intervention from healthcare professionals [10,11].\n\nWhile similar tools exist in other languages, no validated version tailored to the Pakistani demographic has been available. By refining the ASQ for local use, the study enhances diagnostic accuracy and symptom tracking to overcome cultural and linguistic barriers, allowing for a detailed assessment of disease symptoms and impaired QoL among Pakistani achalasia patients. In clinical practices and further research, ASQ needs to be translated and validated in the local or native language, Urdu, the local language of Pakistan, spoken by approximately 85% of the population. The current study aims to validate a translated version of the ASQ by evaluating the structural validity and reliability in Achalasia patients present in the population of Pakistan.\n\nA prospective cross-sectional study was conducted at the Center for Liver and Digestive Diseases, Holy Family Hospital, Rawalpindi, from 7thSeptember 2022–15thNovember 2023. The study received ethical approval from the Institutional Research and Ethics Forum of Holy Family Hospital, Rawalpindi, with protocol approval number 269/IREF/RMU/2022, and the Institutional Ethical Review Board and Bio-Ethical Committee (BEC) of Quaid-I-Azam University, Islamabad, with protocol approval number BEC-FBS-QAU2022–381. The sample size for validating the ASQ questionnaire was determined to be 52 participants, considering five participants for each item in the instrument and accounting for a 20% dropout rate [12]. Written informed consent was obtained from all participants.\n\nThe Canadian English version of the ASQ questionnaire was obtained from previous literature (S1 Table) and made freely accessible. The translation into Urdu was performed by a team consisting of two research scholars and an assistant professor from the university. To ensure the accuracy of the translation, a native Urdu speaker proficient in English was chosen to forward-translate the ASQ from English to Urdu. The translated versions of the ASQ in Urdu were reviewed by a team of medical experts, academicians, and the translator, who discussed and resolved any discrepancies. To validate the newly translated Urdu version and ensure its content equivalence to the original version, two independent translators translated it back into English. The forward and backward translated versions, along with the input from the team of experts, including health professionals, academicians, and translators, were carefully reviewed to create the final version of the Urdu-translated ASQ. The translated version was critically reviewed for semantic, fluent, practical, and conceptual equivalence. Clear and culturally appropriate language was used in the translated questionnaire to reduce communication bias. To further validate the translated version, it was initially filled out by five achalasia patients, who were interviewed to ensure their understanding of the questionnaire and the meaning of each item. The patients reported no difficulty in comprehending or answering the questions. Therefore, the Urdu version of the ASQ was considered the final version of the questionnaire (Fig 1). The corresponding author can provide the Urdu version of the ASQ upon request.\n\n*Achalasia-specific questionnaire.\n\n*Achalasia-specific questionnaire.\n\nhttps://doi.org/10.1371/journal.pone.0321933.g001\n\nPatients were included if they: (1) had confirmed achalasia, (2) showed no other gastric disorders on endoscopy, (3) received no treatment in the past 4 weeks, (4) had no conditions that could significantly impact their QoL in the short term, and (5) had no disabilities. After clinical assessment, patients completed a form with demographic, clinical, and health status data (ASQ and Eckardt scale). Non-technical staff assisted those with poor eyesight, reading difficulties, or shaky hands, providing non-directive guidance for any questions about the questionnaire.\n\nThe symptom scoring system assesses the frequency of common esophageal symptoms like weight loss, dysphagia, regurgitation, and chest pressure, with scores from 0 to 3, indicating the occurrence of symptoms never, occasionally, daily, or with meals. Scores correlate with achalasia stages: 0–1 for stage 0, 2–3 for stage I, 4–6 for stage II, and above 6 for stage III. Stage 0 and stage I generally indicate significant relief of symptoms, while intervention is considered unsuccessful for stages II and III [13,14].\n\nThe questionnaire consists of 10 items assessing various aspects of HRQoL and includes food tolerance (item 1: 1–3 points; items 2–4: 3–8 points), dysphagia-related behavior modifications (item 5: 1–3 points), pain (item 6: 1–4 points), heartburn (item 7: 1–5 points), distress (item 8: 1–2 points), lifestyle limitation (item 9: 1–2 points), and satisfaction (item 10: 1–4 points). The total score ranges from a minimum of 10 points to a maximum of 31 points. A lower score indicates a better disease-specific HRQoL [6].\n\nFactor analysis was conducted to evaluate the internal structure of the translated questionnaire and assess the item’s importance. Principal component analysis (PCA) with varimax rotation and explanatory factor analysis (EFA) using Bartlett’s test of sphericity helped identify dimensions linked to “disease-specific HRQoL.” The model fit was determined by the Kaiser-Meyer-Olkin (KMO) value, with ≥0.8 to ≤1.00 indicating a good fit, ≥0.7 to <0.8 indicating a satisfactory fit, ≥0.6 to <0.7 indicating an acceptable fit, and values below 0.6 are considered unacceptable [10]. PCA involved plotting eigenvalues, representing the amount of variance explained by each factor. The factors with relatively larger eigenvalues were retained up to the point where there was a break (with a value >1). The uni-dimensionality was assessed by calculating the percentage of explained variance. It is recommended that the first factor accounts for more than 20% of the total variance [15].\n\nIn this stage of validation, the ability of the ASQ to differentiate between different groups is assessed [16]. Specifically, in this study, the focus was on classifying patients based on disease severity using the Eckardt clinical symptom score. The ASQ questionnaire was compared between two groups: achalasia patients in clinical remission (Eckardt clinical symptom score ≤ 4) and patients not in clinical remission (Eckardt clinical symptom score > 4). To compare the two groups, a t-test for independent groups was conducted.\n\nThe internal consistency reliability of both the total score and subscale scores of the ASQ was evaluated using Cronbach’s alpha coefficient. Cronbach’s alpha values were used to assess the internal consistency reliability of each scale. An excellent level of internal consistency reliability is indicated by Cronbach’s alpha ≥ 0.9, a strong level by Cronbach’s alpha ≥ 0.8, an acceptable level by Cronbach’s alpha ≥ 0.7, and a reasonable level by Cronbach’s alpha ≥ 0.6 [17].\n\nThe feasibility of the measure was evaluated by gathering data on two aspects. First, participants were asked to rate the level of difficulty they experienced while completing the ASQ questionnaire. The response options included “easy,” “moderate,” or “difficult.” Second, participants were asked to estimate the time it took them to complete the questionnaire, with response options ranging from less than 5 minutes, 5–15 minutes, or more than 15 minutes. By assessing these factors, we aimed to gauge the practicality and user-friendliness of the ASQ measure in terms of ease of completion and time required.\n\nIn cases where an item was missing from the ASQ or Eckardt clinical symptom score, it was replaced with the median value of the items within the corresponding subscale. However, if multiple items were missing from a subscale, the questionnaire was excluded from further analysis. Additionally, efforts were made to retain participants throughout the study to minimize dropout bias, such as providing detailed study explanations and follow-up reminders. These measures enhance the reliability and validity of the findings. Data analysis was performed using Excel and SPSS version 25.0 (SPSS Inc., Chicago, IL, USA).\n\nA total of 52 (91.2%) out of 57 patients were included. Five patients were excluded because of insufficient command of the Urdu language and missing responses to the ASQ with more than one item. So, the questionnaires of 52 patients (27 males; median age 30 years-25 females; median age 48 years) were used for analysis (Table 1). Out of the selected respondents, 33 patients were suffering from Achalasia type I, while 26.9% and 9.6% were diagnosed with Achalasia type II and Achalasia type III, respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321933.t001\n\nThe EFA factor model was adequate, with a significant Bartlett’s test of sphericity (p < 0.001), evaluating whether the correlation matrix is an identity matrix, meaning there is no correlation between variables. In this case, the rejection of the null hypothesis suggests that there is a significant relationship among the items analyzed. Also, a KMO value of 0.771 indicates that the sample has a moderately good level of adequacy for further EFA.\n\nTable 2presents communalities, reflecting the shared variance between items and extracted EFA factors. High communalities indicate strong variance explained by the extracted factors, while lower values suggest additional factors may be needed to account for the unexplained variance. For example, the item “Raw hard fruits and vegetables” has a high extraction communality of 0.889, indicating that 88.9% of the variance in this variable is accounted for by the extracted factor. However, items such as “Rice” (extraction communality = 0.689) and “How much do you agree with the following statement about how satisfied you are with your health concerning achalasia?” (Extraction communality = 0.653) have lower communalities, indicating that a smaller proportion of variance is explained by the extracted factors for these variables.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321933.t002\n\nThe PCA was conducted to assess the dimensionality of the Urdu-translated ASQ. These dimensions align with the theoretical framework of achalasia-related symptom burden and QoL. The findings from PCA further support the validity of the ASQ as a reliable tool for assessing HRQoL in achalasia patients.Table 3presents the results of the PCA with three different measures: initial eigenvalues, extraction sums of squared loadings, and rotation sums of squared loadings.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321933.t003\n\nThe initial eigenvalues indicate the variance explained by each item before any rotation or adjustment. For example, the first item has an initial eigenvalue of 4.216, explaining 42.158% of the total variance. Subsequent items have progressively smaller eigenvalues, indicating a decreasing proportion of explained variance. The extraction sums of squared loadings show the variance explained by each item after the extraction process, with the same pattern as the initial eigenvalues. The rotation sums of squared loadings represent the variance explained by each item after an optional rotation process. It’s important to note that the remaining items from the fourth to the tenth do not have values reported in the table, suggesting their minimal contribution to the total variance.\n\nTable 4displays the Component Matrix, revealing the correlations between the items and the extracted components in the factor analysis. It helps understand the relationship of each item with the underlying factors. In Component 1, variables such as “How much has achalasia limited the types of food you have been able to eat in the last month?” (0.838), “Rice” (0.832), “Clear fluids (water, juice, coffee, tea)” (0.763) and “Raw hard fruits and vegetables” (0.713), show positive correlations suggesting that Component 1 is associated with food limitations and difficulties in consuming specific items due to achalasia. Component 2 exhibits positive correlations with variables linked to the impact of achalasia on lifestyle, including mealtime duration and daily activity limitations. Component 3 shows positive correlations with variables concerning the presence of pain and heartburn symptoms during eating, such as “How often have you experienced pain when eating during the past month?” (0.739) and “During the past month, how much of a problem for you was heartburn?” (0.590). Negative correlations indicate an inverse relationship between the variable and the corresponding component. For example, “When you sit down to eat a meal, are you bothered by how long it takes you to finish eating?” (−0.681) exhibits a negative correlation with Component 1, implying that individuals who are less bothered by mealtime duration tend to have fewer food limitations due to achalasia.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321933.t004\n\nThe Rotated Component Matrix (Table 5) clarifies variable relationships with rotated components, enhancing interpretability. Component 1 has high loadings for items related to food limitations due to achalasia, such as “Raw hard fruits and vegetables” (0.894) and “Rice” (0.658). Component 2 reflects the impact of achalasia on lifestyle and mealtime duration, showing high loadings with items like “Has having achalasia limited your lifestyle?” (0.891). Component 3 indicates pain and heartburn symptoms associated with eating, with strong loadings on “How often have you experienced pain when eating?” (0.907) and “How much of a problem was heartburn?” (0.806). The rotated component matrix helps simplify interpretation by aligning items with their most salient components.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321933.t005\n\nInterviews revealed that 82.7% of patients were newly diagnosed with any type of achalasia, with an Eckardt score above 4, while 17.3% (9 patients) had previously been diagnosed and were receiving follow-up care, with their Eckardt clinical symptom score being less than or equal to 4. Patients in clinical remission had lower ASQ scores, indicating higher HRQoL (mean 19.7 ± SD 8.1), compared to newly diagnosed patients with higher ASQ scores (mean 36.8 ± SD 12.2). This difference was significant (p < 0.001), highlighting the positive impact of remission on HRQoL.\n\nTo evaluate the reliability of the Urdu version of the questionnaire, Cronbach’s Alpha coefficient was computed, and the resulting value was found to be 0.89, indicating a moderate to high level of internal consistency or reliability in the measurement instrument. This suggests that the questionnaire items consistently measure the same construct.\n\nFurthermore, a theoretical analysis was conducted to investigate the impact of removing specific questions on the overall reliability of the instrument (Table 6). Interestingly, when the question related to experiencing pain while eating food was hypothetically deleted, Cronbach’s Alpha value increased to 0.91, indicating that removing this particular question improved the internal consistency of the questionnaire. On the other hand, deleting any other question from the questionnaire led to a decrease in Cronbach’s Alpha, ranging between 0.5 and 0.75, suggesting that the remaining questions play an important role in maintaining the internal consistency and reliability of the measurement instrument.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321933.t006\n\nDuring feasibility evaluation, 73.1% of participants (38 individuals) found the translated questionnaire easy to use, indicating clear instructions and a user-friendly format. A further 10 patients (10.2%) were managed with minimal difficulty. In comparison, only 4 patients (7.7%) found it challenging, highlighting potential areas for further refinement or clarification of certain aspects of the translated version to enhance its usability for a wider range of individuals. 82.7% of participants completed the questionnaire in under 15 minutes, suggesting conciseness. However, 9 patients required more than 15 minutes to read, comprehend, and respond, indicating a need for additional support or simpler language for some items.\n\nIn a review published in 2021, the use of the Eckardt score as a prominent measure for assessing achalasia outcomes was extensively discussed, highlighting the need to use the Eckardt score, which has gained widespread acceptance and recognition in the field, with its endorsement by esteemed organizations such as the International Society of Diseases of the Oesophagus and the American Society of Gastrointestinal Endoscopy [18]. Also, the RAND Delphi process aimed at establishing consensus on quality indicators for achalasia. This process involved a panel of experts who assessed various aspects of achalasia care, revealing a lack of confidence in the current patient-reported outcome measures’ ability to accurately identify treatment failure and the need for further intervention, particularly in specific populations [5,18]. This suggests that the existing measures used to evaluate achalasia outcomes can be improved, as they may not capture the full extent of treatment effectiveness and patient experiences.\n\nSo, it was aimed to validate a disease-specific HRQoL measure, i.e., ASQ in Pakistani achalasia patients speaking Urdu, a local and national language. Our results demonstrated highly acceptable reliability and validity of ASQ in Urdu-speaking Pakistani achalasia patients. As suggested by studies on HRQoL adaptation in South Asia [19], the Urdu-translated ASQ could serve as a foundational tool for similar South Asian contexts, helping to generate region-specific data and improve healthcare practices, specifically for patients suffering from rare disorders. The findings support the call for more cross-cultural research to ensure that HRQoL metrics are adaptable and globally applicable.\n\nOur study followed a robust adaptation process validated by experts and patients, consistent with the cross-cultural adaptation standards [20]. As achalasia is a rare disorder in which symptom onset is typically gradual and progresses over years, significantly affecting QoL with treatments focused on symptom relief rather than cure [21]. Therefore, self-management of symptoms is crucial for patients, and for this purpose, they have to be aware of their current HRQoL status. Similar methodologies have been used successfully in adapting HRQoL tools for various populations, confirming that comprehensive adaptation enhances both content validity and user relevance [22].\n\nThe symptom severity and HRQoL outcomes observed here align with findings from European and North American studies [3], indicating that untreated achalasia leads to significant QoL declines regardless of geographic location. Differences in social and cultural factors, however, can influence patient perceptions and management, as observed in HRQoL studies in Middle Eastern contexts [9]. The majority of patients found the questionnaire easy to use, aligning with studies that emphasize the importance of clarity and cultural relevance in HRQoL tools [10,12]. Similar usability studies, like those conducted in China and Latin America, show that culturally adapted questionnaires improve patient comprehension and response accuracy [23], underlining the utility of carefully adapted tools for the Pakistani context.\n\nThe validated Urdu version of the ASQ holds significant potential for improving clinical practice in Pakistan. Given the limited availability of standardized symptom assessment tools in the local healthcare system, this questionnaire can serve as a reliable instrument for symptom evaluation, aiding in both diagnosis and monitoring of achalasia patients. Future research should focus on expanding the validation of the Urdu ASQ across diverse clinical settings and larger, more heterogeneous patient populations to enhance its generalizability. Its implementation in gastroenterology clinics, particularly in settings where HRM is not readily available, can enhance early symptom detection and facilitate timely referral for diagnostic confirmation. Furthermore, the availability of an Urdu ASQ allows for more comprehensive patient-reported outcome assessments, contributing to personalized treatment strategies and improved patient care.\n\nAdditionally, longitudinal studies assessing the questionnaire’s responsiveness to treatment outcomes would provide valuable insights into its utility for monitoring disease progression and therapeutic effectiveness. Further psychometric evaluations, including test-retest reliability over extended periods, could strengthen the instrument’s stability. Moreover, exploring the adaptation of ASQ for digital health applications, such as mobile-based patient symptom tracking, could improve accessibility and real-time symptom management. Moreover, studies comparing the Urdu ASQ with other achalasia-specific tools in cross-cultural contexts would provide deeper insights into its global applicability.\n\nHowever, conducting the study in a single center in Pakistan may restrict the applicability of the findings to other regions within the country or globally, as healthcare resources and patient demographics could vary, including the multilingual approach of the Pakistani population. Future work could benefit from longitudinal designs and larger sample sizes to validate these findings further, especially research on HRQoL in chronic disease contexts.\n\nThis study concluded that the Urdu-translated ASQ exhibits strong psychometric properties, with high internal consistency, good construct validity, and reliable factor structure, confirming its suitability for assessing achalasia symptoms in Urdu-speaking populations. The validation process ensured linguistic and cultural adaptation while maintaining the integrity of the original instrument. This study supports these findings, with participant feedback indicating that cultural nuances were largely well-reflected and underscoring the importance of continuously evaluating and refining health and QoL outcome measures in achalasia research and clinical practice by using a translated version of ASQ in achalasia patients in Pakistan. By addressing the limitations identified by the expert panel, future efforts can strive to develop more comprehensive and reliable tools for assessing treatment outcomes and guiding decision-making in achalasia management.\n\nhttps://doi.org/10.1371/journal.pone.0321933.s001\n\n(DOCX)\n\nThe authors acknowledge all patients who had consented to participate in this project, including the staff of Holy Family Hospital, Rawalpindi, Pakistan.",
    "category": "mathematics"
  },
  {
    "title": "CT features and histogram analysis of non-contrast images for differentiating malignant and benign mediastinal lymph nodes in Non-Small Cell Lung Cancer (NSCLC)",
    "authors": "Pakorn Prakaikietikul, Yutthaphan Wannasopha, Juntima Euathrongchit, Apichat Tantraworasin, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321921",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321921",
    "content": "To evaluate the diagnostic value of CT features and histogram analysis in distinguishing between malignant and benign mediastinal lymph nodes in patients with non-small cell lung cancer (NSCLC).\n\nThis retrospective study analyzed non-contrast chest CT images from 40 NSCLC patients, comprising 80 pathology-proven mediastinal lymph nodes (46 benign, 34 metastasis). Morphologic features, including size, shape, margins, and internal composition, were independently assessed by two radiologists. Histogram analysis was conducted using the Synapse Vincent system with six parameters: mean attenuation, mean positive pixel (MPP), standard deviation (SD), skewness, kurtosis, and entropy. Statistical analysis included the Mann-Whitney test for continuous data, Fisher’s exact test for categorical data, and receiver-operating characteristic (ROC) curve analysis to assess diagnostic accuracy, with statistical significance set at p < 0.05.\n\nMalignant lymph nodes demonstrated significantly larger sizes (p < 0.001), ill-defined margins (p = 0.024), irregular shapes (p < 0.001), and the presence of necrotic areas (p < 0.001). A nodal size cutoff of 13.0 mm and volume of 1.632 ml were strongly associated with malignancy, yielding high diagnostic accuracy with sensitivities of 70.6% and 73.5% and specificities of 95.7% and 87.0%, respectively. Significant differences were observed between benign and malignant lymph nodes in several CT histogram parameters, including mean attenuation (p = 0.004), skewness (p = 0.041), kurtosis (p = 0.005), and entropy (p < 0.001). The integrating all CT histogram parameters yielded an area under the curve (AUC) of 0.870 for differentiating between benign and malignant lymph nodes.\n\nThe combination of morphologic CT features and CT histogram analysis offers a robust method for differentiating malignant from benign mediastinal lymph nodes in NSCLC patients, potentially enhancing diagnostic accuracy and informing treatment strategies.\n\nCitation:Prakaikietikul P, Wannasopha Y, Euathrongchit J, Tantraworasin A (2025) CT features and histogram analysis of non-contrast images for differentiating malignant and benign mediastinal lymph nodes in Non-Small Cell Lung Cancer (NSCLC). PLoS ONE 20(4):\n           e0321921.\n        \n        https://doi.org/10.1371/journal.pone.0321921\n\nEditor:Lorenzo Faggioni, University of Pisa, ITALY\n\nReceived:September 11, 2024;Accepted:March 13, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Prakaikietikul et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nLung cancer is the second most common type of cancer worldwide, causing 1.8 million deaths annually [1]. The most frequently occurring cell type is a non-small cell lung cancer (NSCLC) [2]. Early detection through the use of low-dose CT scans and accurate lung cancer staging are important tools for appropriate treatment planning and improving patient survival [3,4]. Mediastinal staging is a crucial factor in designing treatment plans for NSCLC, and contralateral mediastinal lymph node involvement (N3) is a criterion for identification of an inoperable case [5]. Positron emission tomography integrated computed tomography (PET/CT) is a useful non-invasive mediastinal staging modality in NSCLC but it has a high false positive rate, which varies from 6.5% to 47.5% [4,6,7], especially in the regions with a high prevalence of inflammatory or infectious lung diseases such as pulmonary tuberculosis [3,4]. Additionally, PET/CT is not widely available in some countries, including Thailand. Due to the high false-positive rate of PET/CT, patients may undergo invasive procedures such as endobronchial ultrasound-guided fine needle aspiration (EBUS) and mediastinoscopy which carry a risk of complications more frequently [8]. Furthermore, transbronchial biopsy may not be able to reach all areas of mediastinal lymph nodes, as recommended by the International Association for the Study of Lung Cancer (IASLC) lymph node stations [9], such as prevascular, subaortic, paraaortic, paraesophageal, pulmonary ligament, and some of left paratracheal stations [10].\n\nRecently, texture analysis, a key component of Radiomics, has been developed to assess and quantify tumor heterogeneity which cannot be detected by the human eye. Texture analysis can be applied to a variety of imaging modalities, including CT, Magnetic resonance imaging (MRI), and PET/CT. The first-order CT texture analysis (CTTA) involves creating a pixel intensity histogram in the area of interest, which provides quantitative measures of tissue heterogeneity. This approach is easily accessible and does not require expensive post-processing software. [11]. The concept behind CTTA is that the more heterogeneous a tumor is, the more biologically aggressive its behavior and the more resistance it will have to treatment [11].\n\nThe second-order and higher-order CTTA are more advanced techniques that provide more delicate details of the tumor, but they require specific software. A few studies have shown that the CTTA of mediastinal lymph nodes can differentiate between malignant and benign lymph nodes based on the hypothesis that metastatic lymph nodes are heterogeneous and of high density due to the loss of normal hilar fat. [10,12]. However, this is based on advanced CTTA techniques such as Run-length non-uniformity (RLNU), Gray-level non-uniformity (GLNU), and advanced metrics, while data about CT histogram is limited [7,13,14].\n\nThe CT histogram of mediastinal lymph nodes could be a significant method for mediastinal lymph nodal staging in NSCLC; however, there is limited data available, particularly in Thailand. This insufficiency motivated our search for an objective of this study, which was to evaluate the diagnostic value of the CT features and histogram analysis in differentiating between malignant and benign mediastinal lymph nodes in patients with NSCLC.\n\nThis study is a retrospective review of non-contrast chest CT scans of patients diagnosed with NSCLC. The population was searched using the keyword ‘primary lung cancer’ in the Envision program from January 2019 to June 2021, revealing 328 cases of primary lung cancer. Only 74 patients met inclusion criteria, which included the availability of pretreatment CT images in the CMU-PACS system, pathological confirmation of the lymph nodes through fine needle aspiration (FNA) or histology within an interval of less than three months and presence of ≥ 5 mm lymph nodes. Exclusion criteria included the absence of plain CT scans (30 patients) and poor image quality (4 patients), leaving 40 patients with 80 lymph nodes in this study (Fig 1). The study was approved by the institutional review board (RAD-2565-09120) and waived the requirement for informed consent due to its retrospective nature. The review of medical records was performed in accordance with institutional ethics review board guidelines.\n\nNSCLC; non-small cell lung cancer, CMU-PACS; Chiang Mai University Picture archiving and communication system.\n\nNSCLC; non-small cell lung cancer, CMU-PACS; Chiang Mai University Picture archiving and communication system.\n\nhttps://doi.org/10.1371/journal.pone.0321921.g001\n\nThe demographic data of patients, including gender, age, and pathologic reports, was collected from medical records. All protected health information (PHI) was securely stored in a password-protected computer in the Radiology Department. No traceable data that could identify the patients was collected.\n\nThe non-contrast CT images were obtained from machines from three manufacturers, including SOMATOM Definition (Siemens Healthcare, Forchheim, Germany), SOMATOM Force (Siemens Healthcare, Forchheim, Germany), and Philips IQon (Philips Healthcare, Best, The Netherlands). CT studies were obtained on multidetector CT systems with a breath-held helical acquisition of the entire thorax, 120 kV and modified mAs. A collimation of 128 × 0.6 mm with z-flying focal spot technique was used. The images were reconstructed with 1-mm slice thickness and the field of view (FOV) that covered the entire thorax. Axial images at interested mediastinal lymph nodes were used for evaluation.\n\nDuring surgery, the surgeons resected lymph nodes with some adipose connective tissue from the corresponding anatomic regions. The mediastinal lymph nodes were identified on the CT scan and correlated with the pathological reports by using size, location, and endobronchial ultrasound (EBUS) findings of the lymph nodes. The pathology of all the selected lymph nodes was verified by surgical pathology or fine needle aspiration from EBUS. The preoperative CT images of mediastinal lymph nodes were reviewed independently by two board-certified diagnostic radiologists; Y.W. and P.P. who had eleven years and five years of experience in chest imaging interpretation, respectively. Both were blinded to the pathological reports and clinical data. They focused on the following characteristics: size (short axis diameter), shape, margins, and internal composition, including the presence of calcification, necrosis, or fat components. Necrosis was defined as a focal area of low attenuation, appearing less dense than the surrounding tissues on CT scans [15].\n\nThe data from the CT scanner was sent to the workstation for CT histogram and the three-dimensional software automatically generated histograms of each node. The histogram features were computed by segmenting the whole volume of each lymph node using a three-dimensional volume of interest (VOI) approach. This method ensured comprehensive volumetric analysis, capturing spatial heterogeneity throughout the lymph node. The images were viewed using a standard mediastinal window setting with a level of 30 Hounsfield Units (HU) and a width of 400 HU (Fig 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.g002\n\nA board-certified diagnostic radiologist (P.P.) segmented the mediastinal lymph nodes using a semi-automated method and analyzed them with six histogram measurements: mean attenuation, mean positive pixel (MPP), standard deviation (SD), skewness, kurtosis, and entropy using the Synapse Vincent system (Fujifilm Corp., Tokyo, Japan) (Fig 3). The histogram parameters used in this study are defined as follows [11]: Mean attenuation refers to the average density of the region of interest in Hounsfield units (HU); Mean positive pixel indicates the average density of the region of interest where the attenuation is greater than 0 HU; Skewness measures the asymmetry of the histogram, indicating whether the data distribution is skewed to the left or right; Kurtosis describes the peakedness or flatness of the histogram, reflecting the distribution of pixel intensities; and Entropy quantifies the irregularity or complexity of the histogram, with higher entropy values indicating greater heterogeneity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.g003\n\nDescriptive analysis involved the calculation of frequencies and proportions for categorical variables. The interobserver agreement was reported using the Intraclass Correlation Coefficient (ICC) for continuous quantitative variables, and the kappa test was used for categorical variables. The ICC values below 0.5 suggest poor reliability, while values ranging from 0.5 to 0.75 indicate moderate reliability. Values between 0.75 and 0.9 indicate good reliability, and those exceeding 0.90 indicate excellent reliability [16]. The kappa values were evaluated based on the Viera classification, with the following interpretations: 0.01–0.20 indicating slight agreement, 0.21–0.40 indicating fair agreement, 0.41–0.60 indicating moderate agreement, 0.61–0.80 indicating substantial agreement, and 0.81–0.99 indicating almost perfect agreement [17]. The means with standard deviations (SDs) or medians with interquartile ranges (IQRs) of continuous variables were determined based on the distribution of the data. The collected data were evaluated using descriptive statistics, including absolute and relative frequencies. Group differences were analyzed using the Mann-Whitney test for continuous data and the Fisher’s exact test for categorical data. Receiver-operating characteristic (ROC) curve analysis was used to assess diagnostic accuracy. Statistical significance was determined at a p-value of less than 0.05. The analyses were performed using IBM SPSS software version 25.\n\nThis study included 40 patients and 80 lymph nodes. The mean age of the patients was 66.9 ± 7.89 years, with a slightly higher proportion of male patients compared to female patients. Out of the 80 mediastinal lymph nodes, 46 were benign and 34 were metastatic nodes, as proven by pathology. Of the metastatic lymph nodes, 29 (36.3%) were adenocarcinoma and 5 (6.3%) were squamous cell carcinoma. The demographic data are demonstrated inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.t001\n\nThe level of agreement between the two radiologists demonstrated excellent correlation in quantitative nodal size measurements (Intraclass Correlation Coefficient (ICC) = 0.94, p-value = 0.001). However, the agreement in qualitative nodal morphology evaluation showed fair to moderate agreement between the two radiologists (Kappa ranging from 0.412 to 0.756; p-value < 0.05) (Table 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.t002\n\nBased on the analysis of the median values of nodal size and volume, it was found that the malignant lymph nodes were larger than the benign nodes. The benign lymph nodes had a median short axis of 8.0 mm (ranging from 6 to 10 mm), while the malignant lymph nodes had a median short axis of 14.0 mm (ranging from 12 to 20 mm). The difference between the two groups was statistically significant (p-value < 0.001). The median volume of the malignant group was 2.49 ml, which was significantly different from that of the benign group, which was 0.87 ml (p-value < 0.001).\n\nWhen considering the morphologic appearances of the lymph nodes from the benign and malignant groups, analysis showed that the majority of the malignant nodes had an irregular shape (76.5%), ill-defined margins (73.5%), and contained necrotic components (50.0%), as compared to the benign nodes, with differences being statistically significant (p-value < 0.05). It was observed that the malignant lymph nodes did not have any internal fat component. However, the benign lymph nodes generally had an oval shape (65.2%), well-defined margins (93.5%), and a presence of internal hilar fat (17.4%).Table 3shows the comparison between the CT findings from the malignant and benign mediastinal lymph nodes in patients with non-small cell lung cancer.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.t003\n\nA comparison of CT histogram parameters between benign and malignant nodal groups revealed significant differences in the mean attenuation, skewness, kurtosis, and entropy, with p-values of 0.004, 0.041, 0.005, and <0.001, respectively. However, there were no significant differences in the Maximum Pixel Percentage (MPP) and Standard Deviation (SD), with p-values of 1.758, and 0.083, respectively.Table 3demonstrates the CT findings and histogram parameters, and the differences in histogram features between benign and malignant lymph nodes are illustrated using box plots (Fig 4). Additionally, the receiver-operating characteristics (ROC) curve analysis, incorporating all CT histogram parameters, yielded an area under the curve (AUC) of 0.870 for differentiating between benign and malignant lymph nodes (Fig 5).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.g005\n\nThe ROC curve analysis of qualitative features (shape, margin, and internal components) evaluated by radiologists for distinguishing benign from malignant lymph nodes showed an AUC of 0.827 (95% CI: 0.728–0.926). In comparison, quantitative histogram analysis achieved a higher AUC of 0.870 (95% CI: 0.781–0.959). However, the difference between the two methods was not statistically significant (p = 0.336).\n\nThe ROC curve analysis for the discrimination of benign versus malignant lymph nodes showed an AUC of 0.919 for nodal size and 0.849 for nodal volume (Fig 6). Further analysis revealed that a cut-off nodal size of 13.0 mm tended to indicate malignancy, with a sensitivity of 0.706, a specificity of 0.957, a Youden’s Index of 0.662, an accuracy of 0.850, and a positive likelihood ratio (LR+) of 16.23. Similarly, a cut-off nodal volume of 1.632 ml indicated a tendency toward malignancy, with a sensitivity of 0.735, a specificity of 0.870, a Youden’s Index of 0.605, an accuracy of 0.813, and an LR+ of 5.64. The results are summarized inTable 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321921.g006\n\nOur study showed that malignant lymph nodes were statistically significantly larger than benign ones. We used a cut-off nodal short axis of 13.0 mm and nodal volume of 1.632 ml to indicate malignant lymph nodes with precision, with an accuracy of 0.850 and 0.813, respectively. This supports most previously published studies that often use a short axis greater than 1 cm as the cutoff for a metastatic lymph node in NSCLC [18]. However, the sensitivity of using a short axis less than 1 cm to identify a normal lymph node is only between 46% and 57% [19,20], indicating that non-enlarged nodes can still be malignant. Meanwhile, emerging studies on normal lymph nodes suggest that relying solely on size to differentiate malignant from benign mediastinal nodes is not reliable, as these studies indicate a relatively high frequency of malignancy [21,22].\n\nIn our study, the majority of malignant nodes had an irregular shape (76.5%), ill-defined margins (73.5%), and contained necrotic components (50.0%). This could be due to the fact that benign nodes become more rounded or take on an irregular shape as a result of malignant infiltration. However, the contour of the node as seen on CT and MR imaging can have greater diagnostic value, as malignant nodes tend to show irregular or ill-defined borders as a result of extracapsular disease extension or uneven growth [13,23]. On CT images, large metastatic nodes often display a heterogeneous appearance. Heterogeneity is a well-known characteristic of cancer, reflecting alterations in tissue architecture that are probably the result of various factors such as cell infiltration, abnormal angiogenesis, myxoid changes, and tumor necrosis [24,25]. A lower density nodal center seen on CT can be a result of necrosis. Even normal-sized nodes with necrosis should be considered as potentially malignant in these patients. Although low attenuation nodes can be a feature of malignant infiltration, they are also found in tuberculosis and fungal infections, which were not included in our study. Therefore, low attenuation nodes alone are not diagnostic of malignancy [13,23].\n\nIn our study, the presence of internal hilar fat was seen exclusively in benign lymph nodes. This is consistent with published studies which suggest that the presence of a fatty hilum is a commonly used parameter for differentiating between benign and malignant lymph nodes [26,27]. A typical normal lymph node has a uniform appearance, and the presence of hilar fat can be indicative of benignity, although this is not always the case [23].\n\nOur study found that interobserver agreement for qualitative nodal morphology evaluation was fair to moderate (Kappa: 0.412–0.756; p < 0.05), suggesting limitations in subjective assessment of shape, margin, and internal components using visual inspection alone. Although the difference was not statistically significant (p = 0.336), quantitative histogram analysis achieved a higher AUC (0.870) than qualitative feature assessment by radiologists (AUC 0.827), indicating its potential for better distinguishing between benign and malignant lymph nodes. A possible explanation is that subjective image assessment relies on a radiologist’s perception, making it prone to inconsistency and variability. In contrast, objective assessment uses quantitative metrics for a standardized approach [28]. Radiomics and quantitative imaging extract measurable data to characterize tissue properties. The histogram analysis provides additional quantitative insights into the heterogeneity of mediastinal lymph nodes in NSCLC patients, which are not achievable through conventional morphologic evaluation alone.\n\nSome prior studies postulated that CT texture analysis is able to inform the histopathological tumor characteristics, and that the more heterogeneous a tumor is, the more biologically aggressive its behavior tends to be [11,29]. In this study, we utilized a first-order CT texture analysis and found significant differences in mean attenuation, skewness, kurtosis, and entropy between benign and malignant lymph nodes. In malignant lymph nodes, a higher density is expected due to the loss of fatty tissue in the hilar region, in contrast to benign lymph nodes. As expected, our results showed that malignant lymph nodes tend to have high mean attenuation and more negative skewness. However, the MPP in this study showed similarities between the two groups and was not statistically significant which may be attributed to several factors. One potential explanation is the heterogeneity within the malignant lymph nodes themselves. While malignant nodes are generally expected to have higher attenuation due to the loss of fatty tissue, the presence of necrotic areas, which were found in about 50% of the malignant nodes, could lower the overall attenuation [24], balancing out the mean values when compared to benign nodes. Additionally, benign lymph nodes can sometimes show increased attenuation due to reactive changes, such as inflammation or fibrosis, which can occur in response to infection or other non-malignant processes [27]. These changes can elevate the attenuation values of benign nodes, making the MPP values between benign and malignant nodes more comparable.\n\nSeveral features associated with texture derived from CT and MRI images are able to reflect unique histopathological tumor characteristics at a microstructural level. These features have proven useful in discriminating benign from malignant lymph nodes through the use of CT texture features [29]. The kurtosis of first-grade radiomics features reflects the peak apex degree of the gray distribution within the pixel. High kurtosis implies that the gray area is further away from the mean distribution, while low kurtosis indicates the opposite trend. Meanwhile, skewness reflects the offset characteristics and symmetry of the gray distribution relative to the mean. Higher skewness suggests higher tumor heterogeneity and a greater possibility of progression [30,31]. Presumably, higher heterogeneity in malignant lymph nodes is caused by the presence of tumor deposits, which results in increased CT heterogeneity that can be quantified using entropy-related second-order statistics [29].\n\nAccording to hypotheses pertinent to heterogeneity in malignancy, it can be expected that malignant tumors would have a less peaked histogram, a low kurtosis value, and a high entropy value. However, our study found the opposite results. The CT histogram texture features were analyzed to identify factors associated with lymph node differentiation. The possible explanation is that the density of lymph nodes can vary significantly based on their anatomical location and the underlying pathology [6]. Benign nodes, especially in regions with a high prevalence of infectious agents, particularly in Thailand, might develop calcifications or other changes that increase their heterogeneity on CT images. On the other hand, malignant nodes often exhibit rapid growth and central necrosis, leading to more uniform low-density areas [24], which could explain the lower entropy observed in malignant nodes.\n\nAnother possible explanation for these results is the presence of reactive changes in benign lymph nodes, which can occur due to inflammatory processes or infections. These reactive changes can introduce variability in the texture of benign nodes [27], leading to higher kurtosis and lower entropy values. However, our study suggests that integrating all CT histogram parameters is valuable for differentiating between benign and malignant lymph nodes, with an AUC of 0.870. This finding supports the idea that evaluating all CT histogram parameters collectively, rather than individually, can enhance the accuracy of nodal evaluation. Additionally, the use of first-order CT texture analysis, which focuses on basic histogram features, may not capture the complex microstructural differences between malignant and benign nodes as effectively as higher-order texture analysis methods.\n\nThis study has some limitations that should be considered. Firstly, the sample size is small and the study is retrospective in nature, which may limit the generalizability of the findings. Additionally, during post-processing, imaging filters such as Laplacian or Gaussian bandpass filters were not applied, potentially affecting some histogram parameters. To address these limitations and enhance the robustness of the findings, further evaluation using second-order statistical CT texture analysis is recommended, as it may provide more detailed and comprehensive information.\n\nIn summary, our study shows that morphologic CT features have the potential in distinguishing between malignant and benign mediastinal lymph nodes in patients with NSCLC. The histogram parameters obtained through CTTA can provide additional information that could assist in the differentiation between metastatic and benign lymph nodes. It is important to note that CTTA is not intended to replace tissue diagnosis, but it can be a valuable addition to the radiologist’s confidence for the characterization of lymph nodes and can have a significant impact on patient management. Further studies are warranted to compare CTTA with other diagnostic modalities, such as EBUS/EUS and F18-FDG PET/CT, on a patient-by-patient basis using a larger sample size, in order to determine its full potential in clinical practice.\n\nhttps://doi.org/10.1371/journal.pone.0321921.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321921.s002\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0321921.s003\n\n(PDF)\n\nThe authors would like to express our sincere gratitude to Mr. Yanakawee Khatsitalee for his assistance with statistical analysis and consultation for this study.",
    "category": "mathematics"
  },
  {
    "title": "Risk prediction models for non-suicidal self-injurious behavior in patient with depressive disorder: a protocol for systematic review and mata-analyisis",
    "authors": "Liu Huang, Xiao Liu, Jiao Xu, Ling Wang, Qiran Zhang, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321561",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321561",
    "content": "Non-suicidal self-injury (NSSI) frequently occurs in patients with depressive disorder and often presents as burning or severe scratching. NSSI plays a crucial role in increasing the risk of self-injury in individuals with depressive disorder. Despite the progressive development of various risk prediction models to identify NSSI, there are significant differences in their overall predictive performance. This systematic review aims to evaluate the quality and applicability of these models in predicting NSSI among patients with depressive disorders.\n\nA systematic review with meta-analysis was conducted targeting patients with depressive disorder. We included studies on risk prediction models for NSSI behavior in this population that were developed and published. The primary outcome was NSSI behavior as reported by the prediction models. Predictive variables were measured at different disease stages in patients with depressive disorder, with no specific limitations on the prediction horizon. The intended use of the risk prediction model is to individualize the prediction of NSSI behavior of in patients with depressive disorder, thus facilitating the implementation of preventive measures to avoid adverse events. Databases, including China National Knowledge Infrastructure (CNKI), Wanfang Database, VIP Database, PubMed, Web of Science, Medline, and Embase, were searched from inception to March 2024 by two independently reviewers. Data extraction followed the guidelines outlined in the Checklist for Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies (CHARMS). The risk of bias and applicability of the included studies were assessed using PROBAST. Descriptive statistical methods were employed to summarize the characteristics of the NSSI models and meta-analysis for model validation was conducted using Stata software.\n\nThe study will systematically review the prediction models for NSSI in patients with depressive disorders to enhance clinical practice. This research will also assist clinicians in selecting effective prediction models for NSSI in this patient population.\n\nCitation:Huang L, Liu X, Xu J, Wang L, Zhang Q (2025) Risk prediction models for non-suicidal self-injurious behavior in patient with depressive disorder: a protocol for systematic review and mata-analyisis. PLoS ONE 20(4):\n           e0321561.\n        \n        https://doi.org/10.1371/journal.pone.0321561\n\nEditor:Kyoung-Sae Na, Gachon University Gil Medical Center, REPUBLIC OF KOREA\n\nReceived:May 31, 2024;Accepted:March 9, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Huang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:No datasets were generated or analysed during the current study.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nNon-suicidal self-injury (NSSI) is defined by the intentional and direct infliction of harm to one's own body—such as self-cutting, burning, or severe scratching-without the intention of causing death and for purposes not recognized as socially acceptable [1]. Recently, NSSI has become increasingly prevalent worldwide, particularly among individuals with depressive disorders, thus emerging as a significant public health concern [2]. Research reveals that over 34.2% of those diagnosed with major depressive disorder have a history of NSSI, and individuals who engage in NSSI are at a heightened risk of receiving a diagnosis of major depressive disorder [3–4]. In addition, studies suggest that NSSI may significantly contribute to the risk of suicide within depressive disorders [5]. Notably, depressive disorders contribute substantially to the global disease burden, with a weighted lifetime prevalence of 3.4% in China [6].\n\nNSSI emerges from a complex interplay of heterogeneous factors, and categorizing cases according to social characteristics could enhance the accuracy of early prediction.. With advancements in data-driven clinical decision-making, developing robust systems for the early identification, monitoring, and warning of NSSI has become increasingly crucial. Biological factors commonly associated with NSSI include atypicalbrain functions, neurochemical imbalances, dysfunctions of the HPA axis, altered pain perception, and epigenetic modifications [7]. Recently, various data models have been proposed to predict NSSI at various stages of depressive disorders [8–9]. Nonetheless, many of these models have been critiqued for their lack of\n\nSeveral predictive models integrating multiple factors for anticipating NSSI have been developed. Wang et al. [9] identified childhood emotional abuse, along with sexual and physical abuse, as predictors of NSSI among depressed individuals, with childhood emotional abuse emerging as the most significant predictor.. Kim et al [8]. established a combination of factors to predict high-risk NSSI in patients with depression. However, to date, no study has systematically evaluated the quality and effectiveness of these predictive models.\n\nIn this study, we aim to systematically summarize the reported multivariable models developed for predicting NSSI in patient with depressive disorders, including their characteristics and performance. We will also evaluate whether these models have undergone external validation. Utilizing the Prediction Model Risk of Bias Assessment Tool (PROBAST), we will assess the risk of bias and applicability of the included studies that either develop or validate prediction models. For models with multiple validation studies, we will perform a meta-analysis to evaluate their performance and calibration, thereby providing more precise effect estimates.\n\nWe will design and conduct this systematic review in accordance with the guidelines outlined by the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) Protocol [10]. The Checklist for Critical Appraisal and Data Extraction of Systematic Reviews of Prediction Modelling Studies (CHARMS) was utilized for the assessment and extraction of data [11]. This framework supports the formulation of review's objectives, development of the search strategy, and establishment of criteria for study inclusion and exclusion [12]. The study protocol has been registered with PROSPERO under registration number of CRD42024524274.\n\nWe systematically searched both Chinese and English databases, including China National Knowledge Infrastructure (CNKI), Wangfang Database, China Science and Technology Journal Database (VIP), PubMed, Embase, The Cochrane and Web of science, from their inception through March 2024. The search strategy in supporting information 2. Two independent investigators will perform the literature search and screening, with any discrepancies resolved by a senior author. Additionally, we will seek out other relevant studies, including unpublished and ongoing articles. The retrieval flowchart is shown inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321561.g001\n\nWe will include all cohort studies that described the development and validation of original multivariable models for predicting NSSI behavior in patients with depressive disorders. Articles will be screened and selected based on both inclusion and exclusion criteria. Inclusion criteria for studies are as follows: (1) patients with depressive disorders;(2) Observational study design;(3) Reporting of a prediction model with internal validation; (4) Outcome of interest being NNSI behavior. The exclusion criteria are: (1) studies that did not develop a prediction model; (2) Unavailability of full text; (3) Fewer than two predictors. For the systematic review, we used the PICOTS framework (Population, Intervention, Comparator, Outcomes, Timing, Setting), as outlined inTable 1. According to PICOTS guidelines, our study design does not include randomized controlled trials; therefore competing models were not considered as comparators.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321561.t001\n\nTwo researchers independently extracted data following the recommendations of the CHARMS checklist and verified their findings. In cases of uncertainty regarding data extraction, the two researchers will consult and discuss the issues until an agreement is reached and proceed with data extraction. If disagreements persist, neutral third-party reviewer will be engaged to resolve the issues. The third reviewer will extract data based on CHARMS checklists. Finally, team will reach a consensus through discussion.\n\nThe extracted information will be categorized into two sections: general information and model information. General information will include details such as author, year, research design, model name, assessment tool, publication, and country. Model information will cover candidate variables, sample size, modeling methods, handling of missing data, predictive factor assessment, discriminative power, and model evaluation.\n\nThis study independently assessed the quality of included literature using PROBAST, a tool developed by Wolff et al. (2019) to evaluate the risk of bias and applicability of the literature.[13]. PROBAST is organized into four domains: participants, predictors, outcome, and analysis, comprising a total of 20 signaling questions designed to facilitate a structured judgment of risk of bias (ROB). ROB arises from deficiencies in study design, conduct, or analysis, leading to. systematically distorted estimates of model predictive performance. Each question was answered on a scale of yes, probably yes, no, probably no, no information. Domains were classified as low, high and unclear risk of bias. Details for the assessment rules are summarized inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321561.t002\n\nWe employ descriptive statistical methods to summarize the characteristics of NSSI models. For categorical variables, we will calculate frequencies or percentages, while for continuous variables, we will compute means, medians, and interquartile ranges (IQRs). Meta-analysis of the validated models was performed using Stata software. Heterogeneity was assessed using the I2index and Cochrane Q test. The criteria for heterogeneity are evaluated using this index, which mainly categorized into low, medium, and high [14]. In the presence of significant heterogeneity, a random effects model will be applied to merge effect sizes and address heterogeneity. Sources of heterogeneity will be explored through subgroup analysis and meta-regression. Additionally, sensitivity analysis will be conducted to exclude outlier studies, and meta-analysis will be repeated to compare results with those obtained without excluding anomalies. We will also perform a meta-analysis of C-statistics for prediction models.\n\nWe can also perform a sensitivity analysis to exploit the reliability of the research findings and ascertain the extent to which they are affected by other influencing factors..\n\nWe will assess the heterogeneity of meta-analysis to determine whether subgroup analysis is necessary\n\nEthical approval was deemed unnecessary, as all data will be sourced from previously published studies. We intend to publish these findings in a peer-reviewed journal. The PROSPERO registration number for this study is CRD42024524274.\n\nThis study constitutes a systematic review of the existing literature and was conducted without direct involvement from patients or the public in its design, execution, or reporting.\n\nThe protocol for this systematic review will be amended as needed during the peer review process. The author would publish when the study is complete.\n\nTo date, numerous prediction models have been developed to identify the NSSI, but many may not have been validated due to various limitations. We will systematically review the published studies on these prediction models for NSSI to enhance clinical practice. The findings aim to assist clinicians in selecting effective NSSI prediction models for patients with depressive disorders. We evaluate both the internal and external validity of these prediction model using various indicators. The primary limitation of this study is that it is a systematic review of existing literature on NSSI prediction models for depression patients and did not generate any new data. In the future, it may provide a theoretical foundation for the development of prediction or alert systems for NSSI and enable earlier targeted preventive measures.\n\nhttps://doi.org/10.1371/journal.pone.0321561.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321561.s002\n\n(DOCX)",
    "category": "mathematics"
  },
  {
    "title": "A protocol for a systematic review and meta-analysis of the effect of muscle energy techniques on shoulder joint pain",
    "authors": "Ye Ji Kim, Seojae Jeon, Hyeonjun Woo, Won-Bae Ha, Junghan Lee, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321176",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321176",
    "content": "Muscle energy techniques (MET) for shoulder muscles improve both shoulder muscle tension and the range of motion of the glenohumeral joint. This systematic literature review will investigate the effects of MET on shoulder pain as a result of muscle tension in the glenohumeral joints of patients with shoulder disorders and collect clinical evidence regarding the effectiveness of muscle energy techniques on glenohumeral joint pain. Based on previous studies, we anticipate that MET may significantly affect shoulder joint pain. We expect to provide moderate to high levels of evidence regarding the effectiveness of MET in the treatment of shoulder pain.\n\nNine electronic databases will be searched for articles published up to November 2024, including PubMed, EMBASE, CENTRAL, KCI, KISS, KMbase, RISS, DBpia, and OASIS. Search terms will consist of terms related to the outcome (e.g., “shoulder”) and intervention (e.g., “muscle energy technique,” “post-isometric relaxation,” “isometric stretching”). Studies selected for the systematic review and meta-analysis will include randomized controlled clinical trials and studies using MET applied to the human shoulder muscles. Qualitative and case studies will be excluded. Two authors will independently assess each study for eligibility and risk of bias and extract the data. This study will analyze the effects of MET on shoulder pain. Additionally, we intend to demonstrate the effect size of muscle energy techniques on factors such as range of motion. Our study will provide clinical evidence for the effects of muscle energy techniques on shoulder joint pain. Our study aims to provide clinical evidence supporting the moderate-to-high effectiveness of MET in treating shoulder joint pain.\n\nClinicalTrials.govCRD42024532367\n\nCitation:Kim YJ, Jeon S, Woo H, Ha W-B, Lee J (2025) A protocol for a systematic review and meta-analysis of the effect of muscle energy techniques on shoulder joint pain. PLoS ONE 20(4):\n           e0321176.\n        \n        https://doi.org/10.1371/journal.pone.0321176\n\nEditor:Seyed Hamed Mousavi, University of Tehran, IRAN, ISLAMIC REPUBLIC OF\n\nReceived:June 12, 2024;Accepted:March 2, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Kim et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Deidentified research data will be made publicly available when the study is completed and published.\n\nFunding:This research was supported by a grant of the Korea Health Technology R&D Project through the Korea Health Industry Development Institute (KHIDI), funded by the Ministry of Health & Welfare, Republic of Korea (grant number: RS-2023-KH142004).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe shoulder complex consists of four joints, the acromioclavicular, sternoclavicular, glenohumeral, and scapulothoracic joints, formed by articulation of the clavicle, scapula, ribs, humerus, and surrounding soft tissues such as muscles and ligaments. These structures produce highly coordinated movement across multiple joints. The shoulder complex prioritizes mobility over stability and offers the greatest range of motion (ROM) among the joints of the human body. Consequently, due to its anatomical instability, it is prone to pain and dysfunction [1].\n\nThe disruption or weakness of any muscle in this region can impede the inherent continuum of motion, resulting in pain [2]. Therefore, when considering shoulder pathology from a functional perspective, the entire shoulder complex must be investigated to restore muscle balance. Currently, surgical interventions dominate the treatment of shoulder disorders. However, these surgeries often lead to secondary complications, including stiffness and arthrofibrosis [3,4].\n\nOne method for minimizing surgical side effects, alleviating pain, and enhancing functional movement is the muscle energy technique (MET) [5,6]. The MET aims to reduce pain and improve restricted joint mobility [7]. Its mechanism involves post-isometric relaxation and reciprocal inhibition following muscle contraction. Muscle and joint tension decrease within approximately 15 s of isometric contraction, thus facilitating the natural expansion of joint movement [8]. Additionally, muscles treated with MET exhibit increased elasticity, whereas the joint capsule and surrounding tissue may elongate. Consequently, the elasticity and structure of the muscles and tissues change, ultimately increasing the joint range of motion and alleviating shoulder joint pain. Furthermore, MET-induced joint movements enhance proprioceptive feedback and improve motor control and learning abilities [9].\n\nBecause of these advantages, the MET is widely used in clinical settings, particularly in patients with adhesive capsulitis and upper crossed syndrome. Randomized controlled trials (RCTs) have been conducted on MET [10,11]. However, studies analyzing the effects of the shoulder joint MET on pain and ROM in all patients are lacking. Although numerous studies have analyzed the effects of massage, shoulder joint mobilization, manual therapy such as the Kaltenborn mobilization and Mulligan techniques, and stretching exercises on shoulder ROM and pain, no independent study has analyzed the effects of MET alone on shoulder joint pain and ROM [12–15]. Therefore, this study aims to analyze the effect size of MET techniques on shoulder joint pain and function through a systematic literature review and meta-analysis to comprehensively consolidate previous research findings.\n\nThe proposed systematic review was formally registered with the International Prospective Register of Systematic Reviews (PROSPERO) under the registration number CRD42024532367 on May 5, 2024. This study will involve a systematic review and update according to this protocol. This protocol strictly adheres to the guidelines outlined in the Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols 2015 statement [16] as well as the Cochrane Handbook for Systematic Reviews of Interventions [17]. Any modifications to previously published protocols will be explicitly noted, accompanied by a thorough delineation of the amendments.\n\nTwo independent researchers (YJK and SJJ) will comprehensively search nine databases from their inception up to November 2024. The study will encompass three English-language databases: MEDLINE via PubMed, EMBASE via Elsevier, and the Cochrane Central Register of Controlled Trials CENTRAL), and six Korean-language databases: Korea Citation Index (KCI), Korean Studies Information Service System (KISS), Korean Medical Database (KMbase), Research Information Service System (RISS), Data Base Periodical Information Academic (DBpia), and Oriental Medicine Advanced Searching Integrated System (OASIS). In addition, we will explore the reference lists of pertinent articles and conduct manual inquiries using Google Scholar to identify further contributions. Our search will encompass both peer-reviewed journal literature and “gray literature” such as theses and conference proceedings.\n\nThe search terms will comprise the disease term (e.g., “shoulder impingement syndrome” and “rotator cuff tear”) and intervention term (e.g., “muscle energy technique on shoulder”).Table 1shows the search strategies for the PubMed and EMBASE databases, which will be modified and used similarly for other databases.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321176.t001\n\nRCTs will be included in this systematic review and meta-analysis. Qualitative studies and case studies will be excluded from the analysis.\n\nWe will include studies of patients with shoulder pain attributed to shoulder joint disorders without restrictions on sex, age, or race. Studies using METs applied to human shoulder muscles will be included with no restrictions on comparator conditions (no treatment, stretching, or other manipulations).\n\nThe primary outcome measure will be the visual analog scale (VAS) score developed by Hayes and Patterson in 1921, which is used to subjectively evaluate acute and chronic pain, similar to other assessment tools used to evaluate shoulder joint pain in each study. Scores are documented by marking a 10-cm line, symbolizing a spectrum from “no pain” to “worst pain,” through handwritten notations adhering to academic conventions [18].\n\nTools for evaluating range of motion (ROM) and function related to the shoulder joint will be employed to assess the secondary outcomes.\n\nis a self-administered questionnaire designed to measure physical function and symptoms in individuals with musculoskeletal disorders of the upper limb. It comprises 30 items that assess the impact of arm, shoulder, and hand impairments on daily activities, work, and recreational tasks. Each item is rated on a 5-point Likert scale, and the overall score is calculated and transformed to a scale ranging from 0 (no disability) to 100 (most severe disability). The DASH has been widely validated and is recognized for its reliability in clinical research and practice [24].\n\nis a single-item, patient-reported outcome measure used to capture an individual’s overall perception of change in their condition following an intervention. Patients are asked to rate their change relative to baseline on a scale that typically ranges from –7 (a very great deal worse) to + 7 (a very great deal better), with 0 indicating no change. This scale provides a comprehensive overview of treatment effectiveness by reflecting perceived improvements or deteriorations in pain, function, and quality of life [25].\n\nTwo independent researchers (YJK and SJJ) will oversee the study selection process while adhering to the outlined criteria (Table 1). After eliminating duplicate entries, YJK and SJJ will scrutinize the titles and abstracts of the retrieved studies to determine their relevance, and thoroughly evaluate the full texts of the selected studies for eligibility. Any disagreements regarding the study selection will be resolved through consultation with other researchers. Our approach to literature selection will be documented in accordance with the PRISMA guidelines (Fig 1) [26].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321176.g001\n\nData extracted will encompass the primary author’s name, publication year, country of origin, paper title, sample size, dropout count, participants’ age and sex, intervention and comparison specifics, adverse effects of the intervention, research design, measurement tools employed and independent, dependent, mediated, and control variables as well as subfactors pertinent to shoulder joint pain.\n\nSpecifically, for data collection on intervention outcomes, in order to comprehensively understand the durability of the effects of MET, data on pain, joint range of motion, and quality of life will be collected at time points such as 3 months, 6 months, or even 1 year after treatment.\n\nFor instance, upon confirming that a study used METs or similar interventions, we will focus on quantifying the degree of improvement observed in shoulder joint pain based on the primary outcome measure. Subsequent considerations will include variables such as shoulder mobility and functional activity. Furthermore, studies that compare techniques, such as the Mulligan or Kaltenborn mobilization techniques, with METs, will be categorized and comparatively analyzed to assess their efficacy.\n\nThe compiled data will be systematically recorded using Excel 2024 (Microsoft, Redmond, WA, USA) and shared with the researchers using Dropbox folders (Dropbox Inc., San Francisco, CA, USA). If the data are deemed insufficient or ambiguous, correspondence with the respective authors of the included studies will be initiated via email to request supplementary information.\n\nTwo independent researchers (YJK and SJJ) will evaluate the methodological quality of the included studies and the quality of evidence of each primary finding. Discrepancies will be resolved through consultation with other researchers. The methodological quality of the studies will be assessed using the Cochrane risk-of-bias tool [27]. Random sequence generation, allocation concealment, blinding of participants and personnel, blinding of outcome assessments, incomplete outcome data, selective reporting, and other biases will be assessed in each study. Each domain will be categorized as “low risk,” “unclear,” or “high risk.” The evaluation results will be documented in an Excel 2024 spreadsheet and shared among the researchers using Dropbox.\n\nThe assessed outcomes will be comprehensively presented in a full review using ReviewManager version 5.3 (Cochrane, London, UK). The quality of the evidence will be depicted through a summary of the findings. The evaluation procedure will be shared and discussed among researchers.\n\nReviewManager version 5.3 and Excel 2024 will be used for data synthesis and analysis. Researchers will collaborate using Dropbox folders to share files. Descriptive analyses of participant demographics, interventions, and outcomes will be conducted for all included studies. Studies involving comparable interventions, comparisons, and outcomes will be quantitatively synthesized. Data will be analyzed in two phases: (1) data synthesis and analysis after the systematic review process and (2) categorization of studies with figures suitable for meta-analysis.\n\nThe first step is a systematic review to comprehensively organize and analyze studies that show significant effects of METs on shoulder pain among patients. Each study will be classified and coded to “author (year of publication),” “participants (patients),” “difference in shoulder pain before and after muscle energy technique,” “research methods,” “research procedures,” and “research result.” Second, the effects of METs on shoulder joint pain described in the selected papers will be systematized through discussions and reviews among the researchers.\n\nTo assess the correlation between shoulder pain and the MET score in each study, we will designate and code the analyzed items as follows: First, we will categorize and compare outcomes based on the techniques applied to patients with shoulder pain, while distinguishing MET from other techniques as variables. Second, in studies using only the MET, we will define MET application and non-application groups as variables and compare the differences in outcomes. Third, in studies examining the application of the MET in patients with shoulder joint pain, we will identify correlation codes, review theoretical backgrounds, classify each variable into an analyzable framework, and synthesize sub-variables. Subsequently, we will analyze the overall publication bias, verify homogeneity, analyze the overall effect size, and investigate the correlation effect size among all factors related to the rehabilitation period. The size of the correlation effects will be analyzed using Fisher’s z value [28] (0.1 =  small effect size, 0.3 =  medium effect size, and 0.5 =  large effect size) by calculating the correlation coefficient with a 95% confidence interval. We will evaluate the heterogeneity among the studies using both the chi-square test and the I-squared statistic. I-squared values >  50% and >  75% will be considered indicative of substantial and high heterogeneity, respectively. A random-effects model will be applied when significant heterogeneity is detected (I-squared value >  75%), whereas a fixed-effects model will be employed when heterogeneity is not significant, or if the number of studies included in the meta-analysis is very small and inter-study variance estimates lack precision. [29] If heterogeneity is deemed too substantial for synthesis (I-squared value >  75%), a subgroup analysis will be conducted to elucidate the source of heterogeneity.\n\nThe quality of evidence will be evaluated using the Grading of Recommendations, Assessment, Development, and Evaluation (GRADE) [30] framework across five categories: risk of bias, imprecision, inconsistency, indirectness, and other factors such as publication bias.\n\nIf heterogeneity is significant (I-squared value >  75%) and the necessary data are available, we will perform a subgroup analysis to account for heterogeneity. We will also conduct a subgroup analysis for the following potential factors: age, sex, race, session duration, different levels and types of joint mobilization, and other factors that may affect the results.\n\nTo assess the robustness of the meta-analysis results, sensitivity analyses will be conducted by excluding 1) studies with a high risk of bias, 2) studies with missing data, and 3) outliers.\n\nIf the analysis includes more than 10 trials, reporting biases, including publication bias, will be assessed using funnel plots and the trim-and-fill method. If asymmetry is observed in the funnel plots, indicating a potential reporting bias, further investigation will be conducted to identify the possible causes of the asymmetry.\n\nEthical approval is unnecessary as individual patient data will not be included in this systematic review. The findings will be shared through publication of the manuscript in a peer-reviewed journal and/or presentation at a pertinent conference.\n\nThe primary treatment goals of rehabilitation therapy are pain relief and ROM restoration. Particularly in the shoulder joint, which demands a wide ROM and is predominantly utilized in daily activities, pain and limited ROM can significantly affect an individual’s functional performance, making rehabilitation therapy a major focus in clinical practice [31]. Shoulder pain in patients with shoulder disorders reduces shoulder ROM, thereby compromising QOL [32]. Therefore, establishing effective treatment interventions is crucial for shoulder joint pain rehabilitation. MET is broadly applicable to various musculoskeletal conditions, with relatively immediate and sustained effects and minimal patient discomfort [33,34]. Therefore, it is considered useful for reducing muscle tension, improving pain, and restoring joint ROM. However, to date, no systematic literature review has been conducted on the effects of the MET on shoulder joint pain and function. This study aims to analyze the effect size of the MET on shoulder joint pain and its contribution to shoulder joint mobility, function, and improvement in patients’ quality of life. We believe that the results of this systematic review will provide clinical evidence for the use of the MET in treating restricted shoulder joint mobility. Furthermore, by proposing effective methods for shoulder rehabilitation, we hope to offer valuable and cost-effective alternatives for the healthcare sector. This systematic review and meta-analysis will have several limitations. First, significant heterogeneity is anticipated among the included RCTs. Variations in participant inclusion criteria, intervention protocols, assessment tools, and follow-up duration across studies may influence the overall interpretation of the findings. To address this, subgroup analyses using consistent criteria will be conducted to minimize heterogeneity. Second, there is a considerable risk of bias. Although the quality of the included studies will be assessed using the Cochrane RoB 2.0, the studies may not have been methodologically robust in terms of design or execution. Third, the use of diverse outcome assessment methods across the studies presents some challenges. Differences in follow-up periods and tools used to evaluate outcomes such as pain and functional recovery may complicate the aggregation of the results. To mitigate this issue, we will standardize the outcome measures or utilize statistical methods that allow for the integration of diverse outcomes. Fourth, the small sample sizes of some RCTs may lead to inadequate statistical power. Smaller studies are more prone to random errors, which could adversely affect the reliability of meta-analysis results. To compensate for this, wider confidence intervals will be used. Considering these limitations, caution is advised when interpreting the findings of this review, and larger-scale RCTs are required in future research to strengthen the evidence base.\n\nhttps://doi.org/10.1371/journal.pone.0321176.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321176.s002\n\n(PDF)\n\nThe authors have no acknowledgments to declare.",
    "category": "mathematics"
  },
  {
    "title": "CFD based design optimization of dimples induced on Blended Wing Body airframe using the Taguchi method",
    "authors": "Haris Ali, Mohammad Rasidi Rasani, Zambri Harun, Muhammad Ashhad Shahid, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320885",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320885",
    "content": "This research focuses on optimizing the design of dimples on a Blended-Wing-Body (BWB) airframe to enhance aerodynamic efficiency. Dimples serve as a passive flow control method intended to improve aerodynamic properties. Employing the Design of Experiments (DOE) framework and utilizing the Taguchi method, we examined five dimple design variables across three distinct levels. These variables included dimple placement, indentation depth, diameter, spacing between dimples, and the number of dimple rows on the BWB wing. An L18orthogonal array (OA) was implemented to assess the impact of these variables on the drag coefficient (CD), lift coefficient (CL), and lift-to-drag ratio (L/D), which were used as performance metrics. High-fidelity Computational Fluid Dynamics (CFD) simulations were conducted for each of the eighteen configurations outlined by the L18OA, across angles of attack ranging from 0° to 8°. Signal-to-Noise Ratio (SNR) analysis and Pareto Analysis of Variance (ANOVA) revealed that the dimple diameter had the most significant impact on bothCDandL/D, contributing 35.19% and 40%, respectively, while the indentation depth showed the least influence. The study identified an optimal combination of design variables (A1B1C1D3E3), which minimizesCDand maximizesL/D. This work provides actionable guidelines for dimple design as a passive flow control method in aerospace applications.\n\nCitation:Ali H, Rasani MR, Harun Z, Shahid MA (2025) CFD based design optimization of dimples induced on Blended Wing Body airframe using the Taguchi method. PLoS ONE 20(4):\n           e0320885.\n        \n        https://doi.org/10.1371/journal.pone.0320885\n\nEditor:Gökhan Küçüktürk, Gazi University: Gazi Universitesi, TÜRKIYE\n\nReceived:October 31, 2024;Accepted:February 25, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Ali et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors declare that they have no known financial conflicts of interest or personal relationships that could have affected the work presented in this paper.\n\nThe Blended-Wing-Body (BWB) aircraft, featuring a seamless integration of high-lift wings with a broad, airfoil-shaped fuselage, has recently attracted significant interest in contemporary aviation due to its enhanced aerodynamic performance and lower fuel or energy consumption. These benefits stem from the design’s minimized wetted area and reduced overall weight [1]. Additionally, the BWB configuration offers a substantial increase in internal volume, accommodating the placement of larger and heavier payloads. Liebeck first introduced the concept of the BWB for high-speed subsonic commercial aircraft [2]. Subsequent to this seminal proposal, numerous researchers have explored the potential of this configuration for various applications, including commercial airliners [3,4], Unmanned Air Vehicle (UAV) utilization [5–7], and cargo transport [8]. Several studies have highlighted an enhancement of up to 20% in theL/Dratio of BWB configurations, predominantly attributed to the absence of empennage [9,10].\n\nHowever, despite advancements, the imperative to enhance its aerodynamic efficiency, particularly in drag reduction and improvedL/Dratio, persists, necessitating innovative solutions for improved efficiency and sustainability in modern aviation. For civil and commercial transport aircraft, irrespective of size, skin friction drag usually accounts for about 40–50% of the total drag encountered during cruise flight [11]. As such, even small reductions in drag can lead to significant advantages. Generally, the aerodynamic performance of BWB airframes can be enhanced by employing surface flow control methods, which are instrumental in reducing skin friction drag [12]. These methods are divided into two categories: active and passive. Passive strategies are often preferred over active ones because of their simplicity and cost-effectiveness, making them more practical for enhancing the aerodynamic efficiency of lifting surfaces. These methods influence stall phenomena and delay flow separation without relying on external energy sources.\n\nOne innovative passive flow control method is the introduction of dimples on the surface of interest. Dimples, are small concavities impressed upon a surface which act as a type of surface roughness, facilitate the development of a turbulent boundary layer, thereby delaying airflow separation, diminishing wake region, and reducing friction drag [13]. They have been subjected to thorough investigation in past owing to their ability to augment surface heat transfer [14,15]. Using dimples on bluff objects, such as spherical surfaces like golf balls, is well-recognized for its impact on the boundary layer turbulence and flow separation [16]. Asaiet al. [17] carried out wind tunnel experiments to investigate volleyballs with dimpled and honeycomb-patterned surfaces. The findings showed a slight reduction in the critical Reynolds number for the modified balls. Additionally, the honeycomb-patterned balls exhibited a higherCDcompared to traditional designs, while dimpled balls demonstrated increased variability in flight orientation.\n\nMany researchers also explored the impact of dimples in the context of automobile industry. Wanget al. [18] employed computational modeling to reduce drag on an automotive structure by incorporating a dimpled, textured surface. This method effectively modified theCDby lowering turbulent kinetic energy and reducing wake vortex formation. Similarly, Chear and Dol [19] performed numerical calculations to investigate the influence of varying dimple depth and diameter combinations on theCDof a car model. Their findings showed that all examined combinations contributed to drag reduction, with the maximum decrease in theCDreaching 1.95%. Incorporation of dimples into streamlined objects like airfoils also have the potential to minimize wake size and postpone flow separation but studies are limited in context of aerospace and aviation industry. Allartonet al. [20] explored the use dimples on a NACA-6615 wing to enhance aerodynamic performance for automotive racing cars. Through CFD simulations and wind tunnel experiments, they investigate different dimple sizes at different angles of attack (AOAs). Their findings showed that the smallest dimples significantly improve performance at high AOA, reducingCDand increasing downforce, thus enhancing traction and cornering in motorsport applications. Josephet al. [21] carried out numerical studies at different AOAs to examine the effects of square dimples placed on the suction surface of a wing made up of NACA-0012 airfoil. Their findings indicated that these dimples might potentially prolong the stall angle by delaying the onset of stall.\n\nRecently, many researchers investigated the influence of dimples to augment the aerodynamic efficiency of wind turbines. Azlanet al. [22] explored the impact of dimples on the aerodynamic performance of the horizontal axis wind turbine (HAWT) using CFD. Dimpled surfaces on the turbine blade’s suction side were found to increase output torque by up to 8.41%. The findings suggest that incorporating dimples can effectively improve the efficiency of wind turbines. In another study, Sedighiet al. [23] analyzed the effects of dimple radius and location on HAWT performance through numerical simulations. The study demonstrated a remarkable 16.08% improvement in torque, thereby highlighting the potential effectiveness of this passive modification in optimizing wind turbine performance.\n\nHence, in addition to bluff bodies, the incorporation of dimples into streamlined objects like turbine blades and aircraft wings also have the potential to minimize wake size and postpone flow separation by promoting turbulent boundary layer and reducing friction drag, but studies are limited in context of aerospace and aviation industry [24]. Moreover, the multitude of dimple design variables awaiting examination presents a formidable challenge, as aerodynamic studies are predominantly conducted using CFD. While CFD provides high-accuracy aerodynamic evaluations, it is often resource-intensive and time-consuming.\n\nTo optimize dimple design while minimizing computational demands, one efficient approach is to limit the design space by focusing on a limited set of potential parameter combinations. This approach helps reduce the time and resources needed for trade research and optimization. Nevertheless, it is essential to ensure that this reduction in design scope does not compromise the accuracy of the analysis or the quality of the optimized results. The Design of Experiments (DOE) technique is a potential way to balance these issues. DOE applies statistical techniques to define the design space and strategically allocate resources before conducting an “experiment.” In this context, “experiment” refers to any optimization or trade study, whether conducted experimentally or via computational simulations.\n\nThe DOE is widely utilized in various aeronautical research projects, including the multifaceted design optimization of airframe wing structures, as demonstrated in [25]. In this particular case, DOE is applied to establish the design space for a Surrogate-Based Optimization (SBO) process that incorporates CFD analysis. Similarly, in [26], DOE is utilized to explore the influence of multiple design parameters, assisting in solving a lightweight optimization challenge for a variable-span, shape-shifting wing.\n\nAmong the various DOE methods, Taguchi’s approach stands out as one of the most widely adopted and efficient [27,28]. It simplifies experimental design, result analysis, and experimentation time by addressing the challenges of both full and fractional factorial experiments. Taguchi introduces a specific set of Orthogonal Arrays (OAs) that minimize the complexity of fractional factorial designs, significantly streamlining the process. This method determines the optimal combination of design parameters, or control factors, for each performance metric. It evaluates the impact of all design variables on performance metrics while reducing the required time and resources. This efficiency allows for the integration of more costly experimental techniques or high-fidelity computational tools. Additionally, the method incorporates the use of a signal-to-noise ratio (SNR) and analysis of variance (ANOVA) to examine and interpret the results effectively.\n\nGiven its practical nature, numerous Taguchi-based optimization studies can be found across various branches of mechanical engineering. For instance, in manufacturing engineering, studies like those in [29,30] examine the effects of machining parameters on material and process quality. In the aerospace field, the Taguchi method has been used in several studies to investigate the parametric influence of canards on flying wings and leading-edge slats on BWB UAV configurations [31,32]. Additionally, this approach has been applied to determine the finest combination of aspect ratio, taper ratio, and sweep angle for the layout optimization of a tactical BWB platform, as demonstrated in [33]. Therefore, the Taguchi method holds promise as a candidate for conducting trade studies during the design optimization of dimples on BWB airframes. However, to the best of our knowledge, no research to date has employed the Taguchi method to explore the effects of dimple design variables on BWB wing configurations.\n\nIn this study, a comprehensive parametric investigation of key design parameters of dimples integrated on the wings of BWB airframe is performed. The objectives of this study are to provide trends for the design of dimples as a passive flow control method for aerospace applications and also to identify critical design parameters of dimples which will influence the aerodynamic performance of BWB airframe. CFD approach is employed for the aerodynamic analysis combined with DOE framework to reduce analysis time, while preserving the predictions quality. By employing the Taguchi methodology, five dimple design variables are investigated on three distinct levels. The dimple placement location (x/c), indentation depth (did), diameter (Dd), spacing between dimples (Pd), and the number of dimple rows (rd) on the BWB wing are selected as the investigated design variables, whereas the drag coefficient (CD), lift coefficient (CL), and lift-to-drag ratio (L/D) are selected as the performance criteria. Additionally, Pareto ANOVA is applied to determine the percentage share of each design variable to the optimized performance metrics.Fig 1shows a comprehensive road map for the suggested optimization procedure.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g001\n\nThe baseline configuration employed in this study adopts an optimized fixed-wing BWB airframe geometry [34]. Airfoil profiles were extracted at various spanwise locations, extending from the central body to the outer wing, inclusive of the wing tip. These profiles functioned as the foundational elements for generating all geometries investigated in this study. The root chord (cr), at the center of the body measures 2.12m, the tip chord (ct), at the outermost section of the wing is 0.45m, and the kink chord (ck), at the intersection of the body and wing is 0.525m. The body exhibits a sweep angle (∧b), of 55°, while the wing showcases a sweep angle (∧w), of 27°. Additional details about the design procedure, layout, and tools utilized in this study are available in [34]. The external layout of the reference BWB airframe, presented inFig 2, serves as the benchmark configuration for the integration of dimples. The fundamental geometric details pertinent to the current investigation are presented inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t001\n\nThis section provides a detailed description of the Taguchi technique and the associated methods employed for optimizing the dimple design on a BWB airframe. The process begins by defining the dimple design variables and their corresponding levels. Taguchi based OAs are then applied to generate the design space, which, in this study, results in 18 distinct BWB layouts with dimples for evaluation. For each configuration, a specific CAD model is created, followed by aerodynamic analysis through the solution of multiple CFD cases at different AOAs. Once the aerodynamic data is obtained, the optimal dimpled BWB configuration for each performance criterion is determined by SNR analysis. ANOVA is used in conjunction with this to assess the influence of the input design variables.\n\nA planar solid surface modified with dimples is characterized by various design variables. Emphasizing the significance of a precisely defined parametric geometry is crucial in the pursuit of achieving optimal dimple performance. Chenet al. [35] introduced a specific type of circular dimple, originally designed as spherical indentations with circular footprints, which has gained popularity for its parametric nature and is utilized in our current investigation. This dimple design arises from the combination of a spherical indentation and a torus, intersecting tangentially in a uniform manner to eliminate sharp edges. The dimples are arranged in a staggered pattern with a specific spacing (Pd) between two adjacent dimples. This configuration has been reported to be more effective for flow control [13]. The cross-sectional view of the axially symmetrical dimple is shown inFig 3a, whileFig 3billustrates the staggered arrangement.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g003\n\nThe geometric attributes of this dimple are defined by four parameters: the diameter of the circular dimple (Dd), the indentation depth of the spherical ball (did), the curvature radius at the intersection of wall and spherical ball (re) and the curved radius of the spherical surface (R). The following analytical formula establishes the relationship among these dimple parameters [13]:\n\nThe curved radius of the spherical surface was directly related to the diameter of the circular dimple and, therefore, was not treated as an independent variable in this study. The curvature radius at the intersection of wall and spherical ball was also not included as an independent variable to avoid too much complexity in the design procedure and kept constant as 0.5Dd.\n\nConsequently, the number of geometric parameters considered in the current trade study for dimple design was reduced from four to two, allowing to include other dimple design variables to be considered with respect to their integration on the wings of BWB airframe. The remaining variables to be included in the optimization studies are the dimple placement location (x/c) on the wing of BWB airframe, the spacing between adjacent dimples (Pd) as shown inFig 3b, and the number of dimple rows (rd) on the BWB wing. Hence, the OA of the Taguchi method was determined by five parameters: the placement location (A), the indentation depth (B), the dimple diameter (C), the spacing between dimples (D) and the number of rows (E).\n\nTo ensure clarity and consistency, all dimple dimensions are normalized using standard aerodynamic conventions. Specifically, the dimple diameter (Dd) is normalized with respect to the kink chord (ck), while other parameters such as the indentation depth (did) and spacing between dimples (Pd) are normalized with respect toDd. Additionally,rdis used to denote the number of dimple rows andx/crepresents the normalized placement location of the dimples along the chord length. These notations are unique, descriptive, and consistently applied throughout the manuscript in equations, tables, and figures. A summary of all symbols is provided inTable 2for quick reference.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t002\n\nTo perform the CFD simulations for each configuration derived from the L18OA, a parametric 3D CAD model was implemented, ensuring accurate and consistent geometry across all configurations. The workflow for the design tool is illustrated inFig 4. Commercial 3D CAD software was utilized to generate the various BWB configurations based on the selected dimple design parameters. The BWB’s main body was first created, followed by the addition of dimples on the wings as separate solid bodies. Finally, the dimples were subtracted from the main wing structure to produce the desired configurations. Both wings of the BWB airframe were modified by integrating dimples near the trailing edge (TE) at 85% ofck. No dimples were applied to the fuselage or body of the airframe.Fig 5showcases the top view of two dimple configurations from the L18OA, demonstrating the CAD modeling process. Configuration 7 appears in blue on the left, while configuration 3 is depicted in red on the right.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g005\n\nIn modern aviation, advanced computational techniques and experimental methods are widely employed. While these approaches enable crucial optimization and trade-off studies, they are often limited by the significant demands they place on processing time, resource allocation, and manual input. As a result, the scope of the design space is frequently restricted, as illustrated by some studies about the winglet optimization reported in [36]. The complexity and expense of these studies increase even more when low-fidelity approaches, like vortex lattice methods, fail to accurately model intricate 3D configurations, such as the aerodynamic effects of dimples on a BWB airframe.\n\nThe total numberNof possible combinations forLlevels ofmdesign variables in a full factorial optimization study, where the entire design space is considered, is given by the following expression:\n\nTo minimize the resource and time demands of a full factorial analysis while still exploring the complete design space, Taguchi proposed a standardized DOE technique [37]. This approach, commonly adopted in the industry, enhances the creation of top-notch products by maximizing their durability and minimizing their vulnerability to unpredictable elements, all while keeping costs relatively low. Taguchi’s method accomplishes this by utilizing a specific set of OAs, which outline the minimum number of desired “tests” for the selected design variables, as outlined inTable 3. These tests guarantee that the conclusions derived from the smaller test set are still applicable for the whole design space.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t003\n\nWhile the Taguchi method is a well-known and widely applied DOE approach across various industries, the novelty of this study lies in its integration of Taguchi with ANOVA to quantify the impact of each dimple design parameter on the aerodynamics of the BWB airframe. This distinctive combination has not been explored in prior aerospace research.\n\nThe process of developing OA begins with determining the total degrees of freedom (DOF), which determines the least number of “tests” needed to evaluate the selected design variables. The DOF for each design parameter are determined by subtracting one from the number of levels (Equations (3–7)). Therefore, the total DOF are calculated by summing the DOF for each design parameter’s main effect, along with an additional DOF related to the overall mean [38].\n\nThe subsequent step involves selecting the appropriate layout for the OA, which is dictated by the total DOF and the quantity of design variables. The number of columns in the OA corresponds to the factors and their respective levels, while the number of rows must be no less than the total DOF. Field experts choose the design parameters based on the relevant field, theoretical considerations, and industry best practices. In this study, the design variables described earlier are provided inTable 4. Specifically, the selected design parameters include the dimple placement location,x/c(A), indentation depth,did(B), dimple diameter,Dd(C), spacing between dimples,Pd(D), and the number of dimple rows,rd(E). These five parameters are considered the most critical in the design and integration of dimples on BWB airframe wings, as they significantly impact the aerodynamic efficiency and, consequently, the overall performance of the airframe.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t004\n\nThe values for each level of design parameter were chosen on the basis of a reference BWB airframe, manufacturability constraints, and general guidelines for dimple design [13,39]. As a result, the arrangement of design variables and their respective levels (one parameter with two levels and the remaining four parameters with three levels each) produced an L18OA for the present optimization study, as shown inTable 5. Eighteen distinct dimple layouts were analyzed, and their impact on the aerodynamic characteristics of the BWB airframe was assessed. It is important to highlight that, through the use of the Taguchi method, the design space was significantly reduced from 243 possible configurations to just 18. This significant decrease in the number of layouts greatly minimized the CAD and CFD analysis workload compared to a full factorial approach.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t005\n\nThe aerodynamic performance of each layout from the L18OA was evaluated using high-fidelity CFD simulations. This study employs steady-state simulations to compare aerodynamic coefficients across various dimple configurations, focusing on subsonic cruise conditions and moderate AOAs (0°–8°). The primary objective was to establish design trends and optimize dimple configurations, rather than to investigate transient flow dynamics. The steady-state approach was chosen for its computational efficiency and ability to identify key aerodynamic trends with sufficient accuracy for the intended scope. While we acknowledge that unsteady effects, particularly at higher AOAs, may influence aerodynamic behavior, an in-depth examination of near- and post-stall phenomena is beyond the scope of this study. Future research could extend this analysis by incorporating unsteady simulation methods, such as URANS or LES, to better capture dynamic flow characteristics at higher AOAs and evaluate the role of dimples under those conditions.\n\nThe Reynolds-Averaged Navier-Stokes (RANS) equations are solved, together with thek-ωSST turbulence model, developed by Menter [40], for resolving the flow field. Thek-ωSST turbulence model was selected due to its well-documented ability to accurately predict flow behavior in scenarios involving adverse pressure gradients and flow separation, which are critical for assessing the aerodynamic performance of dimpled surfaces. This model combines the strengths of thek−ωmodel in the near-wall region with thek-εmodel’s robustness in the free-stream region, providing a balanced approach for high-fidelity simulations of complex aerodynamic flows. Numerical simulations were performed using ANSYS FLUENT to solve the RANS equations. The specific solution methods used in these simulations are outlined inTable 6.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t006\n\nThe CAD models were imported into the Fluent mesher to discretize the surrounding control volume and generate the appropriate computational meshes. Since the BWB airframe exhibits symmetry, only half of the model was simulated to conserve computational resources and time. In this study, both structured and unstructured meshes were employed to resolve the flow field. A structured mesh was applied near the surface of the BWB airframe to accurately capture the flow and its sharp gradients within the boundary layer, while the remainder of the domain was discretized with an unstructured mesh for greater flexibility and reduced mesh size. A high grid point density was maintained near the dimples and around the leading and trailing edges of the BWB airframe to ensure precise representation of the flow dynamics.\n\nIt is important to keep the y + parameter under 3 to ensure precise representation of the boundary layer in turbulent flow simulations when using thek-ωSST turbulence model [41]. To accomplish this, twenty-six prism layers were added adjacent to the walls, with the initial layer height set at 1.5 ×  10-5meters and a growth rate of 1.24. This configuration results in a y + value of approximately 1, ensuring that the near-wall mesh is sufficiently refined to capture the details of the viscous sublayer.Fig 6displays the entire computational domain along with a detailed view of the mesh in the dimpled region and inflation layers.\n\n(a) In domain and BWB; (b) Inflation layers; (c) Fine resolution near dimples.\n\n(a) In domain and BWB; (b) Inflation layers; (c) Fine resolution near dimples.\n\nhttps://doi.org/10.1371/journal.pone.0320885.g006\n\nA comprehensive grid independence study was performed to ensure that grid resolution did not influence the accuracy of the results. Four different mesh resolutions—coarse, medium, fine and very fine—were generated, comprising 3.75 million, 6.85 million, 10.45 million and 14.42 million cells, respectively. The configuration 4 of the L18OA was selected for this study and the finalized mesh settings were implemented for the remaining configurations. TheCDwas used as the metric for evaluating grid independence.Fig 7presents the variations inCDfor the different mesh resolutions at various AOAs. The results showed a deviation of approximately 6% to 7% between the coarse and medium meshes, while the deviation between the medium and fine meshes was approximately 2.3% to 3% at various AOAs. However, the variation inCDfor the fine and very fines meshes was less than 0.56%, even at the highest AOA of 8°. Consequently, the fine mesh comprising of 10.45 million cells was selected for subsequent simulations to balance computational efficiency and accuracy.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g007\n\nThe simulated configurations were analyzed over a broad range of AOAs, spanning from 0° to 8°, under sea level conditions. The selected range of AOAs was chosen to encompass the typical operational envelope of a BWB airframe during subsonic cruise and moderate maneuvering conditions. These angles represent the aerodynamic regime where such configurations are expected to operate efficiently, with minimal flow separation. This range allows us to focus on identifying design trends and optimal configurations under realistic and relevant conditions without delving into extreme angles that may result in significant flow separation or stall, which are outside the scope of this study.Table 7provides a summary of the boundary and initial conditions, including the turbulence boundary parameters at the inlet [42].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t007\n\nTaguchi introduced SNR as a key metric for analyzing results. Acting as both an efficiency gauge and a quality indicator connected to the loss function, SNR helps reduce process losses by being maximized. “Experimental/simulations” data is converted into SNR values using three distinct formulas, each tailored to the specific outcome being targeted (Equations (8), (9), (10)). The logarithmic transformation applied to observations in the SNR enhances the ability to predict improvements in the performance criteria.\n\nIn this instance,yrepresents the estimated performance metrics for each configuration, whilendenotes the total layouts being analyzed. Additionally,refers to the mean value, andindicates the variance for each performance metric (Equations (11), (12)) [43].\n\nIn this study, the performance criteria were optimized using different SNR definitions. For minimizingCD, the ‘Smaller the Better’ criterion was employed, while for maximizingL/Dratio, the ‘Bigger the Better’ criterion was applied. The design parameter combination with the highest SNR for each performance metric is regarded as the most optimal, indicating superior performance with the least amount of variation.\n\nAdditionally, an ANOVA approach [37,43] was employed to further analyze the results and determine the optimal parameter combinations for each performance metric. ANOVA, a statistical method, is employed to evaluate “experimental/simulations” data and assess how design parameters influence overall variation in the results. This approach enables the identification of the statistical significance of each design variable in relation to the chosen performance criteria. In this study, ANOVA was applied to both the reduction inCDand the increase in theL/Dratio, considering the SNR analysis results. This analysis provided insights into the relevance and proportional impact of input parametersx/c,did,Dd,Pdandrd.\n\nAccording to the methodology described in [43],icorresponds to the number of design variables andjrepresents the levels for each variable, withiranging from 1 to 5 andjranging from 1 to 3 in this study (refer toTable 3). Similarly,ksignifies the number of configurations, which in this case ranges from 1 to 18 (as shown inTable 4). The contribution of each design variable is determined by applying the standard ANOVA method, as outlined in Equation (13). This allows for a quantitative assessment of the influence each parameter has on the performance outcomes.\n\nThe termsSSiandSSrepresent the sum of squares of each design parameter and the total sum of squares, respectively, due to variation about the overall mean. The exact values ofSSiandSSare calculated using Equations (14) and (15).\n\nLastly,SNRijrepresents the average SNR for theithparameter at thejthlevel, whileSNRkcorresponds to the SNR for thekthconfiguration. The overall mean SNR is then determined using Equation (16), providing a baseline for evaluating the performance across all configurations.\n\nThis procedure is carried out for each performance criterion, resulting in five distinct percentage contributions in this study.\n\nAdditionally, anF-test is performed to determine the influence of studied design variables on the performance metrics. More precisely, theF-value for each variable is computed by dividing the mean square of the design variable by the mean square of the error (as shown in Equation (17)). This test helps assess whether the variation in the design parameter exert a meaningful statistical effect on the performance outcomes.\n\nThe mean squares of each design variable,MSi, and the mean squares of error,MSE, are in turn calculated using Equations (18) and (19):\n\nIn this context,dfirepresents the DOF for theithvariable, whileSSEanddfErefer to the sum of squares and DOF for the error, respectively. These values are determined using Equations (20) and (21), providing the necessary components for calculating the mean squares and conducting the F-test.\n\nLastly, A, B, C, D and E refer to the dimple design variables mentioned inTable 3, anddfTrepresents the DOF, which is the number of layouts in the OA minus one. This process is carried out for each performance metric, producing five F-values. A higher F-value indicates a stronger influence of the associated design variable on the performance outcomes.\n\nThe CFD analysis was segmented into multiple batches, where each batch represented the drag polar for a specific configuration. To define the drag polar, six different AOAs, i.e., − 2°, 0°, 2°, 4°, 6°, and 8°—were used for each configuration’s analysis. This resulted in a total of 108 CFD simulations using the Taguchi method, while a full factorial design would require 1,458 CFD cases. This approach reduced the number of “experiments” needed for the optimization trade studies by nearly 90%, significantly cutting down the analysis time.\n\nFig 8illustrates the CFD results for configuration 5 indicatively. The first step involved extracting the results from the CFD simulations for all 18 configurations, providing key aerodynamic coefficients such asCL,CD, andL/Dratio. The impact of dimples on the aerodynamic properties of the BWB airframe is evaluated through drag polar andL/Dratio assessments. The variation in drag polar andL/Dratio for all the examined dimpled BWB configurations is presented inFig 9a,9b,9c, and9d, respectively.\n\nα =6°;(a) Pressure distribution; (b) Wall y-plus (c); Flow streamlines.\n\nα =6°;(a) Pressure distribution; (b) Wall y-plus (c); Flow streamlines.\n\nhttps://doi.org/10.1371/journal.pone.0320885.g008\n\n(a) Drag polar - SS; (b) Drag polar - PS; (c) L/D ratio – SS; (d) L/D ratio – PS.\n\n(a) Drag polar - SS; (b) Drag polar - PS; (c) L/D ratio – SS; (d) L/D ratio – PS.\n\nhttps://doi.org/10.1371/journal.pone.0320885.g009\n\nAfter completing the numerical simulations, the optimal combination of design variables for each performance criterion was identified through SNR analysis. As outlined in Section 3.4, the performance criteria selected for optimization were the maximum reduction inCDand the maximum enhancement of theL/Dratio. The SNR for each configuration, based on these performance criteria, is calculated and presented inTable 8. The analysis reveals that the mean SNR for the maximum reduction inCDis 39.21 dB, while the mean SNR for the maximum improvement in theL/Dratio is 24.90 dB.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t008\n\nAs discussed in Section 3.4, the “Smaller is Better” SNR criterion was adopted for optimizing maximum drag reduction, while the “Bigger is Better” criterion was utilized for maximizing theL/Dratio. The SNR analysis results for each individual variable are shown inTables 9and10. The term “Delta” refers to the variation between the highest and lowest SNR values for each variable. The ranking of each variable, which indicates the degree of its impact on the response characteristic, is determined by dividing each variable’s delta by the sum of the deltas for all variables. This ranking reveals which variables have the most significant impact on the performance criteria.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t009\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t010\n\nThe effect of the input variables on the evaluation metrics is depicted inFigs 10and11. The optimal level for each variable, based on each outcome characteristic, is determined by the highest SNR value. Both the drag reduction (δCD) and theL/Dratio improvement (δL/D) exhibited similar trends, reaching their maximum values at the level one for parameters A (x/c), B (did), and C (Dd), and at the level three for parameters D (Pd) and E (rd).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g010\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g011\n\nTable 11summarizes the optimal combinations of input variable levels for each performance metric examined. The combination A1B1C1D3E3is identified as optimal for drag reduction, based on the “Smaller is Better” criterion and corresponding SNR analysis. Likewise, A1B1C1D3E3is also the optimal combination forL/Dratio enhancement, determined by the “Bigger is Better” criterion of the SNR. In terms of dimple location, dimples placed near the trailing edge on the suction surface prove to be the most effective for both drag reduction andL/Dratio improvement. This greater effectiveness on the suction surface can be attributed to the stronger interaction with high-energy airflow, leading to improved boundary layer control and vortex generation.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t011\n\nFor dimple depth, shallow dimples are found to be more effective than deeper ones. Across all optimized configurations, the smallest dimple diameter is preferred, suggesting that smaller dimples generate finer, more consistent vortices that enhance boundary layer mixing without causing excessive turbulence. In terms of dimple spacing, larger spacing yields the most significant aerodynamic benefits for the BWB platform, as increased spacing allows for efficient vortex generation and promotes boundary layer transition with minimal additional drag.\n\nFinally, increasing the number of rows of dimples further enhances aerodynamic performance by increasing the overall number of dimples, which, in conjunction with other optimized dimple parameters, leads to improved aerodynamic efficiency of the BWB airframe.\n\nThe ANOVA results, displayed inTables 12and13, highlight the impact of the design variables on each performance metric. As per the analysis, all parameters appear to be significant in reducingCDand enhancing theL/Dratio with a P-value less than 0.05.Dd(C) is the variable with the highest impact on δCDand δL/D. In contrast,did(B) has a less significant effect on δCDand becomes only marginally influential for δL/D.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t012\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.t013\n\nLastly,Fig 12illustrates the share of each design variable to the performance metrics through a bar chart representation. The authors emphasize that the insights drawn fromFig 12, along with the findings inTable 11, represent key outcomes of this optimization study. The chart provides a clear depiction of the influence of each design parameter. Notably, for both minimizing theCDand maximizing theL/Dratio,Dd(C) emerges as the most influential factor, contributing 35.19% and 40%, respectively. In contrast,did(B) has the least impact, with contribution factors of 12.96% for drag reduction and 10% for improving theL/Dratio.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320885.g012\n\nWhile this study demonstrates thatDdsignificantly influences the aerodynamic performance of the BWB airframe, its contribution might vary under different operating conditions. Specifically, at higher AOAs, where flow separation becomes more pronounced, the effectiveness ofDdin boundary layer control could differ. Additionally, under elevated turbulence intensities, the interaction between dimples and external turbulence structures may amplify or reduce their influence on drag and lift characteristics. Investigating these scenarios falls outside the scope of the current study but presents a compelling direction for future research to expand the applicability of the findings across a broader operational envelope.\n\nThe Taguchi technique, as part of the DOE framework, was employed in this optimization study to explore the influence of critical design parameters of dimples integrated into the BWB airframe. Dimples were proposed as a passive flow control method aimed at improving the aerodynamic performance of lifting surfaces. The trade studies were conducted using high-fidelity CFD simulations, with the goal of exploring the design space efficiently in terms of resources, while preserving the accuracy of the analysis. This approach was intended to extract optimization guidelines and provide a framework that can be applied to similar studies focused on passive flow control techniques.\n\nThe dimple location (x/c), indentation depth (did), diameter (Dd), spacing between dimples (Pd) and rows of dimple (rd) were considered as the design variables, while the performance criteria were the evaluation ofCDandL/Dratio. The primary conclusions derived from this optimization study are summarized as follows:\n\nIn summary, the CFD optimization study, in conjunction with the DOE method and the Taguchi technique, enabled the identification of design trends and optimization results that would otherwise have required significantly more resources and time. Although this study focused on a specific BWB airframe configuration with dimples, the proposed methodology is adaptable to other passive control device optimizations for various aircraft types, facilitating efficient trade studies.",
    "category": "mathematics"
  },
  {
    "title": "Capacity optimization configuration and multi-dimensional value evaluation of integrated energy system with power-to-hydrogen",
    "authors": "Kuiyuan Pan, Tianhe Sun, Xinfu Pang, Xiaoyi Qian, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320486",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320486",
    "content": "The research on the value evaluation system of power-to-hydrogen (P2H) equipment configuration in integrated energy systems is of great value for optimizing resource allocation, improving energy utilization efficiency, and promoting clean energy technology development. However, there is no comprehensive evaluation system for evaluating P2H equipment configuration in integrated energy systems. Therefore, a multi-dimensional value evaluation system is proposed to realize the thorough evaluation of P2H equipment with different capacity configurations in the integrated energy system. Initially, a mathematical model considering flexibility benefit, new energy consumption benefit, economic benefit, and environmental benefit is established to maximize the comprehensive benefits brought by P2H equipment to the integrated energy system, and the model is solved using an improved backbone particle swarm optimization (IBBPSO) algorithm; subsequently, a multi-dimensional value evaluation system based on the analytic hierarchy process (AHP) -entropy weight method is constructed, and the value of P2H equipment with different capacity configurations in the integrated energy system is compared and analyzed when the comprehensive benefit is optimal. The experimental results show that the IBBPSO algorithm exhibits better performance in solving the optimization model. Compared to PSO, IBBPSO, GWO, and WOA algorithms, it improves by 9.8%, 11.09%, 33.57%, and 17.7%, respectively. The optimal solution is achieved when the P2H equipment is configured to 50 MW.\n\nCitation:Pan K, Sun T, Pang X, Qian X (2025) Capacity optimization configuration and multi-dimensional value evaluation of integrated energy system with power-to-hydrogen. PLoS ONE 20(4):\n           e0320486.\n        \n        https://doi.org/10.1371/journal.pone.0320486\n\nEditor:Joy Nondy, Indian Institute of Technology Kanpur, INDIA\n\nReceived:November 30, 2024;Accepted:February 19, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Pan et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and its Supporting Information files.\n\nFunding:This research was funded by the Shenyang Young and Middle-aged Science and Technology Innovation Talent Support Program ( RC220456). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe electrolytic hydrogen production technology driven by new energy power is conducive to expanding the scale of hydrogen production from renewable energy in China and achieving the goal of carbon neutralization in advance. This technology will become a competitive choice, strongly supported by government policies [1]. Under the background of the “ double carbon “ goal to promote the rapid development of new energy, the comprehensive and accurate evaluation of the P2H equipment in the integrated energy system (IES), as well as the rational allocation in different application scenarios, has become one of the key measures to promote its rapid development and optimize resource allocation.\n\nCapacity configuration is essential to ensure system resources are efficiently allocated and used to improve performance, reduce costs, and meet specific business needs. Some scholars have combined two energy conversion technologies to establish a hybrid energy system (HES) and optimized its capacity configuration to improve energy efficiency and system reliability. Reference [2] discusses hydrogen storage’s potential in HES and establishes an economic evaluation model. In addition, a HES model including a reversible solid oxide battery (RSOC) has been established, which effectively reduces the power mismatch phenomenon [3]. Further, Reference [4] considers the impact of economic uncertainty on HES. Reference [5] establishes a photovoltaic-hydrogen hybrid energy system and analyses economic and environmental benefits and policy issues. To better manage various energy forms and optimize energy efficiency, some researchers have established a multi-energy system (MES). Reference [6] proposes a novel MES optimization model and discusses two hydrogen production methods: gas-to-gas and electric-to-gas. In addition, Reference [7] proposes a PV/battery/hydrogen MES for hydrogen production and establishes a stable optimization model to resist hydrogen uncertainty effectively. IES can provide comprehensive energy solutions, maximize energy efficiency, and promote sustainable development, so capacity configuration research is also essential. Reference [8] establishes an IES capacity configuration optimization model of cold-determined heat and heat-determined electricity. From the perspective of environmental benefits and economic analysis, cold and heat priority strategy can be used to maximize system efficiency and minimize carbon emissions. Reference [9] proposes a robust optimization model for traditional IES systems that considers demand response and thermal comfort. Reference [10] proposes an expansion planning model considering hybrid energy storage, which improves the utilization rate of renewable energy. In addition, an IES combining combined heat and power (CHP) and heat storage tank (HST) is established, and the influence of heat load on the capacity configuration of HST is analyzed [11]. These studies have shown that system capacity configuration significantly promotes intelligent and green transformation of energy systems.\n\nThe problem of system capacity configuration is a complex problem with multiple constraints and uncertainties, especially in HES, MES, and IES. To solve this problem, researchers have proposed various methods. Classical optimization algorithms can efficiently solve linear or nonlinear problems that can be transformed into convex problems to obtain accurate global optimal solutions. For example, Reference [12] formulates the optimal planning problem as a mixed integer linear programming (MILP) model to minimize the total annual cost. Reference [13] proposes a solution method based on sequence operation theory (SOT), which converts the scheduling model based on chance-constrained programming (CCP) into a linear programming problem that can be solved. Reference [14] proposes a least squares approximation method that simplifies the complex trigonometric functions representing the conversion efficiency of the bidirectional converter (BDC) as it varies with power, transforming the original non-convex relationship into a computationally efficient convex form. Although classical optimization algorithms have the advantages of high reliability and high-quality feasible solutions for solving linear problems, they cannot deal with highly nonlinear and uncertain problems. In these cases, meta-heuristic algorithms need to be combined to solve them. To improve the sustainability of energy production infrastructure in remote areas, some researchers have adopted a hybrid meta-heuristic algorithm [15], combining two or more algorithms to take advantage of their respective advantages to improve the solution’s quality and the algorithm’s convergence speed. Reference [16] proposes a hybrid Runge Kutta-gradient-based optimization algorithm, which combines the Runge Kutta optimizer and a gradient-based optimizer to solve a generation and transmission expansion planning model embedded with energy storage systems. Reference [17] develops a hybrid artificial rabbits sine-cosine algorithm to address complex non-convex problems in AC optimal power flow models. Reference [18] proposes a hybrid optimization algorithm (BAPSO) that combines particle swarm optimization (PSO) and bat algorithm (BA) to optimize solar power generation capacity. Reference [19] combines the features of the Marine Predators Algorithm (MPA) and the Honey Badger Algorithm (HBA) to propose a hybrid algorithm (MPA-HBA) for solving the integrated hosting capacity model for electric vehicles. A study also combines multi-objective particle swarm optimization (MOPSO) and TOPSIS algorithm to solve electric vehicles’ charging and discharging model considering demand response [20]. To improve the energy supply effect of the system, Reference [21] proposes a regional optimization design method combining K-means and genetic algorithm (GA). Multiple objectives, such as economic efficiency and environmental benefits, are often considered when configuring system capacity. Therefore, scholars have designed improved multi-objective optimization algorithms to obtain better solutions. Reference [22] introduces a multi-objective capacity configuration model and solves it using an improved hybrid multi-objective particle swarm optimization algorithm (HMOPSO). In another study, to reduce energy costs, reduce the probability of power failure, and increase the proportion of renewable energy use, a multi-objective variant of the crow search algorithm (MOCSA) is designed to solve the problem [23]. Reference [24] proposes an improved multi-objective artificial hummingbird algorithm (MOAHA) to optimize the distribution and size adjustment of distributed generation and battery energy storage system (BESS). In addition, many heuristic and meta-heuristic algorithms are applied to the capacity configuration problem. The improved particle swarm optimization (IPSO) is applied to the optimization of microgrid capacity [25,26], and the cat swarm optimization (CSO) is used to optimize the capacity of the gravity energy storage system [27]. There are also other improved algorithms, such as the improved pelican optimization algorithm (IPOA) [28], improved genetic algorithm (GA) [21], golden eagle algorithm (IGEO) [29], and NSGA-II algorithm [30–32]. These intelligent optimization strategies show higher flexibility and efficiency than traditional methods. The research status of key studies is summarized inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t001\n\nBy reviewing and analyzing the literature on capacity configuration in the system, most of the system capacity configuration optimization models only consider economic and environmental benefits, with less attention to new energy consumption and system flexibility. Furthermore, there is a lack of a comprehensive value evaluation system for the multi-dimensional evaluation of the benefits brought by P2H equipment after the system is operational. Establishing an evaluation system that comprehensively considers these four dimensions as assessment criteria enables better utilization of renewable energy resources, enhances system flexibility and stability, and achieves comprehensive economic and environmental benefits. Meanwhile, in solving the P2H equipment capacity optimization configuration model, traditional mathematical solution methods, due to the higher-order nonlinearity of the objective function in integrated energy systems, have become less applicable. The use of metaheuristic algorithms can effectively address this issue. Furthermore, in multi-objective optimization problems, methods based on Pareto usually require trade-offs between objectives and generate non-dominated solution sets, which significantly increase computational complexity. However, by combining multiple objectives into a single objective using weight coefficients, the model can be effectively simplified, thus improving computational efficiency.Given these challenges, the main contributions of this paper are as follows:\n\nThe remainder of this article is organized as follows. Section 2 proposes the system structure and the value evaluation strategy structure diagram. Section 3 describes the mathematical model and the improved algorithm. Section 4 presents a multi-dimensional value evaluation system. Section 5 carries out the simulation and analysis. Finally, Section 6 summarizes this study.\n\nThe structure of the IES with P2H is shown inFig 1. The source-side equipment of the system, such as the wind turbine, cogeneration unit, and gas turbine unit, is responsible for providing the necessary energy for the entire system. The intermediate equipment includes P2H equipment, an electric boiler, and an electric heat pump, which promotes the effective absorption of abandoned wind and provides the necessary flexibility for the system. The load side comprises electric load, heat load, and hydrogen market, which meets the needs of residents ‘lives and industrial production.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g001\n\nBy using the technology of P2H, the IES can realize the efficient integration and utilization of various resources such as electricity, heat, and gas. The IES that employs P2H technology not only effectively lowers the wind curtailment rate but also achieves the secondary utilization of electric energy as hydrogen energy, thereby securing the system’s economic benefits. Part of the hydrogen produced by the P2H equipment is methane to generate natural gas for the gas turbine unit used to generate electrical and thermal energy; the other part of hydrogen is transported to the hydrogen market through hydrogen tankers for industrial use of hydrogen or to meet other hydrogen energy needs.\n\nThe strategic structure of the P2H equipment configuration is shown inFig 2. To achieve energy conservation and emission reduction, maximize economic benefits, reduce wind curtailment rate and improve system flexibility of the IES, and determine the reasonable capacity configuration of P2H equipment in IES under these goals, a mathematical model considering new energy consumption, system flexibility, economy, and environmental benefits is constructed, and a comprehensive multi-dimensional value evaluation system is proposed. After obtaining the optimal solution of the mathematical model, a comprehensive value evaluation of the P2H equipment with different capacity configurations in the IES is carried out. The specific steps are as follows:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g002\n\nStep 1: Establish the mathematical model of the system.The optimization model is established by considering the system power balance, generator set, and equipment output constraints. The objective function is to maximize the comprehensive benefits brought by the P2H equipment to the IES, including new energy consumption, flexibility, and economic and environmental benefits. The input data includes 24-hour electric load demand, heat load demand, and wind turbine forecast output on a typical day.\n\nStep 2: Design the solution algorithm.IBBPSO is used to solve the mathematical model and compared with PSO and BBPSO. The effectiveness of the improved algorithm is verified by the output convergence curve and the results of ‘ multi-factor ANOVA ‘.\n\nStep 3: Build an evaluation system and value evaluation.Based on the AHP-entropy weight method, a multi-dimensional value evaluation system is established. When the comprehensive benefits brought by the P2H equipment to the IES are optimal, the value of the P2H equipment with different capacity configurations is compared, and the scores of the first-level indicators and the second-level indicators are output to find the appropriate capacity configuration and verify the effectiveness of the value evaluation system.\n\nTo maximize the comprehensive benefits brought by P2H equipment for IES, the new energy consumption benefits, hydrogen sales economic benefits, flexibility benefits, and environmental benefits brought by P2H equipment are comprehensively considered:\n\nwhereVrepresents the comprehensive benefits provided by the P2H equipment;represents the economy brought by the P2H equipment to absorb the excess wind power of the wind farm, that is, the reduced cost of wind abandonment;represents the economic benefits of hydrogen sales;represents the flexibility benefit brought by the P2H equipment as a flexible resource;represents the carbon treatment economy saved by reducing CO2 emissions from hydrogen-based synthetic natural gas.,,,are the weight coefficients between different objectives, which are calculated by AHP(Section 4.2).,,,satisfy the relationship:\n\nwhererepresents the total amount of excess wind power absorbed by the P2H equipment in the operation cycle of the wind farm;represents the abandoned wind power consumed by the P2H equipment at timet;andrespectively represent the upward flexibility and downward flexibility provided by the P2H equipment at timet;represents the total amount of hydrogen produced by the P2H equipment;represents the penalty coefficient of wind abandonment;represents the selling price of hydrogen per unit volume;represents the abandoned wind power consumed by generating unit volume of hydrogen;represents the cost of treating a unit volume of CO2;represents the coefficient of CO2 emission reduction per unit volume of hydrogen. Among them,\n\nwhererepresents the minimum value of wind energy absorbed by P2H equipment;represents the maximum value of wind energy absorbed by P2H equipment.\n\nThe decision variables include the cogeneration unit outputand, the electricity consumption power of the P2H equipment, the gas consumption of the gas turbine unit, the electrical energy consumption of the electric boilerand the electric heat pump.\n\nwhererepresents the electric energy generated by the cogeneration unit at timet;represents the electrical energy generated by the wind turbine at timet;represents the electric energy generated by the gas turbine unit at timet;represents the power demand for active load at timet;represents the electric energy consumed by the electric boiler at timet;represents the electric energy consumed by the electric heat pump at timet.\n\nwhererepresents the heat energy generated by the cogeneration unit at timet;represents the heat energy generated by the electric boiler at timet;represents the heat energy generated by the electric heat pump at timet;represents the heat energy generated by the gas turbine unit at timet;represents the power demand for the heat load at timet.\n\nwhererepresents the wind turbine’s minimum output;represents the wind turbine’s maximum output.\n\nwhererepresents the minimum value of the electric output of the cogeneration unit;represents the maximum power output of the cogeneration unit;represents the minimum value of the thermal output of the cogeneration unit;represents the maximum thermal output of the cogeneration unit. The electro-thermal coupling relationship of the cogeneration unit is as follows Formula (11), where,,,andare coupling parameters.\n\nwhererepresents the gas consumption power of the gas turbine unit;represents the gas-to-electricity efficiency coefficient;represents the gas-to-heat efficiency coefficient;represents the minimum gas consumption power;represents the maximum gas consumption power.\n\nwhereandrespectively represent the electric heat pump’s maximum and minimum power consumption;represents the power-to-heat coefficient.\n\nwhererepresents the power-to-heat coefficient;andrespectively represent the electric boiler’s maximum and minimum power consumption.\n\nThe traditional PSO topology is usually a global neighborhood topology. In this structure, each particle can communicate with all other particles in the swarm, meaning that all particles can directly obtain the position of the global optimum [33]. The advantage of this topology is that it can accelerate the search for the global optimum, but it may also lead to the algorithm easily getting trapped in local optima. The formula for particle positionand velocityupdate is shown in Formula (19):\n\nwherekis the iteration number;wis the inertia weight factor;andare learning factors;is the individual best position;is the global best position;.\n\nThe BBPSO algorithm uses Gaussian distribution regarding the global guider and individual guider of particles to update the particle positions [34]. It does not require setting control parameters such as inertia weight and learning factors, making it a particle swarm optimization algorithm with fewer control parameters. The particle position update formula is shown as Formula (20):\n\nwhererepresents the individual guider, which is the best position each particle has found during the search process;represents the global guider, which is the best position found by the entire particle swarm;.\n\nIn some cases, the BBPSO algorithm may still converge to the local optimal solution. To overcome this challenge and improve the global exploration ability of the algorithm in the early stage of search and the local refinement ability in the later stage of search, an improved BBPSO algorithm is introduced. The algorithm improves the particle position update formula in BBPSO to reduce the risk of premature convergence to the local optimal solution and ensure that a more comprehensive search space is explored [35]. The improved formula, as shown in Formula (21):\n\nwhererepresents the local search factor;represents the global search factor;represents the search range factor;represents the accelerating convergence factor.\n\nIn the early stage of the search, due to the small number of iterations,is smaller, whileis larger, thus increasing the global search range; in the later stage of the search,is larger, whileis smaller, the local search ability is enhanced, and the solution result is more accurate.\n\nIn the IBBPSO algorithm, the particle swarm is initialized first, and the fitness of each particle is evaluated to determine the individual and global optimal positions. Then, in each iteration, the particle position is updated by the above formula, and the boundary processing and fitness evaluation are performed to update the individual and global optimal positions until the maximum number of iterations or satisfactory fitness level is reached. The solving process of the IBBPSO algorithm is shown inFig 3. The specific steps are as follows:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g017\n\nThe evaluation system of IES with P2H adopts a tree structure, aiming at comprehensively evaluating the P2H equipment and its application benefits in the IES. The evaluation indicators are divided into two main categories to ensure the comprehensiveness and depth of the evaluation:(1) First-level indicators: The main direction and scope of the evaluation are determined, which are used to summarize the main evaluation areas and key performance indicators. (2) Second-level indicators: Based on the framework of the first-level indicators, the second-level indicators are further refined and analyzed in depth, with precise calculation methods and data sources to support the first-level indicators. The performance of P2H technology in IES is discussed and analyzed in depth by quantifying specific parameters.\n\nWhen constructing the value evaluation system, selecting the first-level indicators follows three principles: systematic, independent, and scientific, aiming to evaluate the benefits of P2H technology for IES from a broad perspective. The comprehensive value evaluation system has four first-level indicators: new energy consumption, economy, flexibility, and environmental benefits, as shown inFig 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g004\n\nThe second-level index is the basis of the whole evaluation system. It is the decomposition and quantification of the first-level index. It has four characteristics: measurability, clarity, consistency, and timeliness. It aims to evaluate the benefits of P2H technology for IES deeply. As shown inFig 4, starting from the four first-level indicators, combined with the index selection characteristics, eight second-level indicators are selected, specifically:\n\n(1)Flexibility\n\nThe flexibility marginis defined as the ratio of the flexibility provided by the P2H equipment in the system to the total flexibility during the operation cycle, as shown in Formula (22). The flexibility supplyis defined as the ratio of the flexibility provided by the P2H equipment at time t to the total flexibility in the system at that time, as shown in Formula (23):\n\nwhererepresents the flexibility provided by the P2H equipment per unit time;represents the flexibility provided by the system per unit time;Trepresents the running cycle;represents the number of P2H equipment;represents the flexibility provided by the P2H equipment at timet;represents the flexibility provided by the kth flexibility resource in the system at timet; M represents the number of flexibility resources.\n\n(2)New energy consumption\n\nThe static consumption rateis defined as the ratio of excess wind energy to original wind energy absorbed by the P2H equipment, as shown in Formula (24). The dynamic consumption rateis defined as the ratio of the square sum of the square of the wind energy change rate of the P2H equipment in the adjacent period to the maximum capacity of the P2H equipment, as shown in Formula (25):\n\nwhererepresents the remaining wind power after the conversion of P2H at timet.\n\n(3)Economy\n\nThe profitability indexis defined as the present value of the unit investment, that is, the ratio of the present value of the system value of all expected future hydrogen sales to the initial investment, as shown in Formula (26), and the profitability index should be greater than 1. The equipment utilizationis defined as the ratio of the total amount of wind power consumed by the P2H equipment during the operation cycle to the total power consumption of the P2H equipment at full load, as shown in Formula (27):\n\nwhererepresents the hydrogen sales revenue on the yth day;ρrepresents the daily interest rate of the bank;represents the initial investment, which is related toand the unit investment cost;represents the number of running days.\n\n(4)Environmental benefit\n\nThe CO2 saving rateis defined as the ratio of the CO2 emissions saved by the system to the CO2 emissions when the thermal power unit is powered, as shown in Formula (28). The primary energy efficiencyis defined as the ratio of the output of the cogeneration unit to the sum of the heat and power generation of the system during the operating cycle, as shown in Formula (29):\n\nwhererepresents the amount of CO2 consumed by hydrogen methanation;represents the coal consumption of thermal power units under the same conditions;represents the total output of cogeneration units during the operation cycle;represents the total electricity production in the system during the operation cycle;represents the total heat production during the operation cycle.\n\nIn the existing evaluation system, the distribution of weights usually adopts two methods: the subjective and the objective. The subjective weighting method adopts the AHP, relies on expert opinions, and is generally aligned with the system operation experience [36]. The objective weighting method uses the entropy weight method to evaluate the system’s operating status based on the system’s operating indicators, which is more aligned with the actual situation of the system [37]. The combination weighting strategy of AHP combined with the entropy weight method is adopted to integrate the advantages of subjective and objective evaluation methods and make up for their defects so that the weight distribution of the evaluation system is more in line with the needs of practical engineering applications.\n\nThe relative importance of subjective and objective weights is calculated, and the subjective and objective weight relationship coefficientsandof the final indicators are calculated as follows:\n\nwhererepresents the subjective weight of the second-level index of itemi; andrepresents the objective weight of the second-level index of itemi. Then, combined with the obtained weight relationship coefficient, the final combined weight is calculated:\n\nAll experiments in this study were conducted using MatlabR2021a software in a 64-bit Windows 10 environment with a 1.80 GHz 8th Gen Intel(R) Core(TM) i7-8565U processor and 8 GB of RAM on a computer.\n\nThe model is applied to an IES in Northeast China. The operation time of the IES with P2H is 24 h, and the operation interval is one h. Load power demand and wind turbine output power are shown inFig 5andFig 6. Experts are invited to score the relative importance of the secondary indicators. Based on these evaluations, a judgment matrix for the significance of the secondary indicators is derived to serve as the input data for the AHP, as shown in Table 2. Unit equipment parameters and other parameters are shown inTable 3andTable 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g006\n\nIn Table 1, A1, A2, A3, A4, A5, A6, A7, and A8 represent the flexibility supply, flexibility margin, static consumption rate, dynamic consumption rate, profitability index, equipment utilization rate, CO2 emission reduction rate and primary energy utilization rate in turn.\n\n(1) Algorithm parameters\n\nThe key algorithm parameters that need to be set for the IBBPSO algorithm include population size (Popsize), number of iterations (Iteration), and penalty factor (r). The Taguchi method is used to examine the impact of different levels of algorithm parameters on the solution. Each parameter is set to three levels, and an-orthogonal experimental table is established, as shown inTable 5. Each experimental group runs 10 times, and the overall evaluation normalized value method is used to calculate the total evaluation normalized value (GM) to assess the parameters. The calculation formula is as follows:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t005\n\nThe trend of parameter factor level changes is shown inFig 7. From the figure, it can be seen that the algorithm performs best when Popsize =  100, Iteration =  1000, and r =  100.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g007\n\n(2) Weight coefficients between different objectives\n\nThe determination of the weight coefficientsin Formula (1) is based on the importance judgment matrix inTable 2, calculated using the AHP method, and then derived through sensitivity analysis. As shown inFig 8, the analysis results indicate that the system achieves optimal performance.\n\n(a) Weight coefficient of a1. (b) Weight coefficient of a2. (c) Weight coefficient of a3. (d) Weight coefficient of a4.\n\n(a) Weight coefficient of a1. (b) Weight coefficient of a2. (c) Weight coefficient of a3. (d) Weight coefficient of a4.\n\nhttps://doi.org/10.1371/journal.pone.0320486.g008\n\nAccording to the load demand curve, wind power forecast curve, the characteristics of the unit, and the capacity of the P2H equipment, to analyze the reasonable capacity configuration in detail, the capacity of the P2H equipment is set to 5 different levels: 10MW, 20MW, 30MW, 40MW, and 50MW. To maximize the comprehensive benefits provided by the P2H equipment for the IES, the IBBPSO algorithm is used to solve the model. To avoid the influence of random errors, the comparison results of comprehensive benefits (V) under different capacity configurations are obtained by simulating ten times and taking the mean value. These benefits include four key first-level indicators: new energy consumption benefit (VR), flexibility benefit (VF), hydrogen sales economic benefit (VELC), and environmental benefit (VCO2). The score comparison results of the first-level indicators are detailed in Table 6.\n\nAccording to the results shown inTable 6, with the increase of the capacity of the P2H equipment, the comprehensive benefits brought by the P2H equipment to the integrated energy system and the benefits of each level of indicators are gradually increasing.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t006\n\nTo verify the superiority of the IBBPSO algorithm in solving the comprehensive benefits brought by the P2H equipment to the system, it is compared with the traditional PSO algorithm, BBPSO algorithm, Grey Wolf Optimizer (GWO) and Whale Optimization Algorithm (WOA). To specify the application scenario, the IES with a P2H capacity of 50 MW is selected as an example. To simplify the problem and facilitate the solution, the penalty function method deals with the equality constraints in the model. The comparison results are shown inTable 7.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t007\n\nThe numerical results inTable 7highlight the superior performance of the proposed IBBPSO algorithm compared to other algorithms. Specifically, the IBBPSO algorithm achieves the highest comprehensive benefits V of 376.447, which is 11.09% and 9.8% higher than the BBPSO and PSO algorithms, respectively. Compared to the GWO and WOA algorithms, the comprehensive benefits V of the IBBPSO algorithm are 33.57% and 17.7% higher, respectively, demonstrating its excellent optimization capability across multiple objectives. In terms of flexibility benefits, the IBBPSO algorithm achieves a value of 296.229, which is 14.79% and 9.21% higher than BBPSO and PSO, respectively, and 41.87% and 54.74% higher than GWO and WOA, respectively. Furthermore, the IBBPSO algorithm demonstrates significant advantages in renewable energy consumption benefitsand environmental benefits, highlighting its effectiveness in balancing economic, environmental, and flexibility objectives.\n\nFig 9shows the convergence curve comparison diagram of the algorithm—the significant advantages of the IBBPSO algorithm in convergence performance. Compared with the PSO, BBPSO, GWO and WOA, the convergence speed is faster, and the convergence result is better. The ‘ multi-factor ANOVA ‘ is used to analyze the comprehensive benefit results with a 95% confidence interval to compare the influence of different algorithms on solving the optimization model. The results are shown inFig 10. The comprehensive benefit obtained by the IBBPSO algorithm is significantly higher than that of the other two algorithms, which proves its superior optimization ability.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g009\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g010\n\nTo compare the result errors of different algorithms in solving this model, box plots were used to statistically analyze the results of 10 runs for each algorithm, as shown inFig 11. The data distribution indicates that the median of the IBBPSO algorithm is closest to the mean and significantly higher than those of other algorithms, suggesting that this algorithm exhibits greater stability and minimal error.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g011\n\nTable 8is for the time complexity analysis of the IBBPSO algorithm and PSO algorithm. The runtime results show that the average runtime of the IBBPSO algorithm is 4.332s, slightly higher than the 3.658s of the PSO algorithm, representing an 18.4% increase. This increase is attributed to the more refined particle position adjustment strategy and enhanced global-local search mechanism in the IBBPSO algorithm, which increase the computational complexity of each iteration. However, the improvements in solution quality and faster convergence speed demonstrate that this trade-off is reasonable, highlighting the superiority and stability of the IBBPSO algorithm.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t008\n\nTo evaluate the stability of the IBBPSO algorithm, benchmark comparisons are conducted using the Hartmann 4-D, Schaffer F7, and Kowalik and Osborne test functions. The expressions of the benchmark functions and their associated parameters are shown in theTable 9, with a population size of Popsize =  50 and a maximum number of iterations Iteration =  500. The corresponding function plots and simulation results are presented inFigs 12–14. The convergence curves of different algorithms demonstrate that the IBBPSO algorithm exhibits significantly superior convergence speed and final results compared to the other algorithms.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t009\n\n(a) Hartmann 4-D three-dimensional function image. (b) Algorithm convergence curve comparison.\n\n(a) Hartmann 4-D three-dimensional function image. (b) Algorithm convergence curve comparison.\n\nhttps://doi.org/10.1371/journal.pone.0320486.g012\n\n(a) Schaffer F7 three-dimensional function image. (b) Algorithm convergence curve comparison.\n\n(a) Schaffer F7 three-dimensional function image. (b) Algorithm convergence curve comparison.\n\nhttps://doi.org/10.1371/journal.pone.0320486.g013\n\n(a) Kowalik and Osborne three-dimensional function image. (b) Algorithm convergence curve comparison.\n\n(a) Kowalik and Osborne three-dimensional function image. (b) Algorithm convergence curve comparison.\n\nhttps://doi.org/10.1371/journal.pone.0320486.g014\n\nTo accurately evaluate the rational allocation of P2H equipment in the IES, achieve the goals of energy saving and emission reduction, improving system flexibility and economy, and reducing the rate of abandoned wind, the multi-dimensional value evaluation of the role of P2H equipment in the IES is made when the optimization model is optimal. The data obtained when solving the optimization model in the previous section are used as the initial data of this section. And the secondary indexes of the IES with P2H under different capacity configurations are calculated according to the secondary index calculation formula (22-29), as shown inTable 10, and the first-level indicator scores are shown inFig 15.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t010\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g015\n\nFrom the first-level indicators inFig 15the P2H equipment with a 50MW capacity configuration has a better value. According to the data inTable 10, with the increase of the capacity of the P2H equipment, the CO2 emission reduction capacity in the integrated energy system is significantly improved. At the same time, the flexibility index has improved considerably. The larger the capacity configuration, the higher the adjustment capacity of the P2H equipment can provide for the IES, thereby enhancing the system’s adaptability to the fluctuation of renewable energy.\n\nTo improve the accuracy and adaptability of the evaluation values, the subjective, objective, and final combination weights of each second-level indicator are calculated by combining the judgment matrix inTable 2and the calculation results of each indicator inTable 10according to the AHP-entropy weight method and Formula (30-31). The results are summarized inTable 11.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t011\n\nTo ensure the consistency of the evaluation system and the convenience of comparison, all indicators are expressed in percentage form. Specific to the profitability index, it is standardized by multiplying it by 100%. The comprehensive evaluation scores of the IES with P2H under different capacity configurations are calculated by comprehensively using the index data provided inTable 10and the combined weights inTable 11. The detailed results are shown inTable 12.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.t012\n\nAccording to the data in Table 12, the comprehensive score is the highest when the P2H equipment in the system is configured at 50 MW, followed by the comprehensive score at 40 MW, and the comprehensive score is the worst at 10 MW. The index score histogram is drawn, as shown inFig 16. Regarding flexibility and new energy consumption capacity, the P2H equipment in the system is significantly better than other capacity configurations when configured with a capacity of 50 MW. In comparison, 10 MW and 30 MW configurations are better than the profitability index. The CO2 emission reduction rate is the best when the capacity configuration is 40 MW, and the utilization rate of equipment and the primary energy utilization rate are less different in different capacity configurations. Therefore, the IES with solid flexibility and absorptive capacity is equipped with 30 MW P2H equipment to improve the profitability of the system; the IES with poor environmental benefits is equipped with 40 MW P2H equipment to enhance environmental benefits; the balanced system selects the capacity configuration with the best comprehensive score to improve the comprehensive performance.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320486.g016\n\nCompared with the single index evaluation, the multi-dimensional value evaluation system can more comprehensively reflect the multi-faceted impact of P2H equipment on the IES, which is helpful to guide the reasonable capacity allocation of P2H equipment in the IES and verify the rationality, effectiveness, and practicability of the comprehensive evaluation system.\n\nA mathematical model is proposed that considers new energy consumption, system flexibility, and economic and environmental benefits. The IBBPSO algorithm is used to solve the model. A multi-dimensional evaluation system is established, and the configuration of P2H equipment in the IES is evaluated and compared when the optimization model is optimal. Through in-depth analysis, the following main conclusions are drawn:\n\nThe limitations of this study primarily lie in the insufficient representativeness of the data, simplified model assumptions, and the computational efficiency of the algorithm, which may affect its applicability in different regions and larger-scale systems. Future research could enhance flexibility evaluation by expanding data sources, integrating various types of information, implementing dynamic assessment and real-time optimization, and introducing multi-objective optimization and intelligent scheduling methods such as reinforcement learning. These advancements would improve the accuracy and timeliness of flexibility assessments, better address the complex and changing demands of power systems, and promote efficient and sustainable operation of power grids.",
    "category": "mathematics"
  },
  {
    "title": "Behavioral insights during the COVID-19 pandemic in the Federation of Bosnia and Herzegovina: the role of trust, health literacy, risk and fairness perceptions in compliance with public health and social measures",
    "authors": "Šeila Cilović-Lagarija, Sarah Eitze, Siniša Skočibušić, Sanjin Musa, Stela Stojisavljević, Haris Šabanović, Faris Dizdar, Mirza Palo, Dorit Nitzan, Miguel Telo de Arriaga, Martha Scherzer, Benjamin Curtis, Katrine Bach Habersaat, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320433",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320433",
    "content": "Public health and social measures (PHSM) are critical aspects of limiting the spread of infections in pandemics. Compliance with PHSM depends on a wide range of factors, including behavioral determinants such as emotional response, trust in institutions or risk perceptions. This study examines self-reported compliance with PHSM during the COVID-19 pandemic in the Federation of Bosnia and Herzegovina (FBIH).\n\nWe analyze the association between compliance and behavioral determinants, using data from five cross-sectional surveys that were conducted between June 2020 and August 2021 in FBIH. Quota-based sampling ensured that the 1000 people per wave were population representative regarding age, sex, and education level based on the data from the latest census in Bosnia and Herzegovina. One-way analysis of variance (ANOVA) was used to identify significant changes between studies on determinants and PHSM measures. Regression was used to find relations between behavioral determinants and PHSM.\n\nParticipants reported strong emotional responses to the rapid spread of the virus and its proximity to them. Risk perception was spiking in December 2020 when rates of infection and death were particularly high. Trends in policy acceptance were divergent; participants did not rate PHSM as exaggerated, but perceived fairness was low. Trust in institutions was low across all waves and declined for specific institutions such as the health ministry. In five wave-specific regression analyses, emotional response (βmin/max= .11*/.21*), risk perception (βmin/max= .06/.18*), policy acceptance (βmin/max= .09/.20*), and trust in institutions (βmin/max= .06/.21*) emerged as significant predictors of PHSM.\n\nThis study contributes to the body of research on factors influencing compliance with PHSM. It emphasizes the importance of behavioral monitoring through repeated surveys to understand and improve compliance. The study also affirms the impact of public trust on compliance, the risk of eroding compliance over time, and the need for health literacy support to help reinforce protective behaviors.\n\nCitation:Cilović-Lagarija Š, Eitze S, Skočibušić S, Musa S, Stojisavljević S, Šabanović H, et al.  (2025) Behavioral insights during the COVID-19 pandemic in the Federation of Bosnia and Herzegovina: the role of trust, health literacy, risk and fairness perceptions in compliance with public health and social measures. PLoS ONE 20(4):\n           e0320433.\n        \n        https://doi.org/10.1371/journal.pone.0320433\n\nEditor:Iskra Alexandra Nola, University of Zagreb School of Medicine: Sveuciliste u Zagrebu Medicinski fakultet, CROATIA\n\nReceived:July 29, 2024;Accepted:February 19, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Cilović-Lagarija et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:In the following, anonymized OSF folder, the rwa data and the complete analysis script is provided, following open data and open analysis standards for easy replication.https://osf.io/5vr37/?view_only=c3ec4c6132f04c709a6cde333c3fd31b\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nEvidence-based public health and social measures (PHSM) were introduced around the world during the COVID-19 pandemic [1,2]. The PHSM measures included washing hands regularly, wearing masks, quarantine and isolation in case of certain conditions, school closures, limiting public events, using tissues when sneezing, cleaning and disinfecting objects, and social distancing. The World Health Organization recommended that governments implement a particular set of PHSM, considering epidemiological data, health system capacity, other data sources, and population-level risk perception and behaviors [3]. Risk perception and behaviors are essential for understanding compliance with PHSM, but in turn, they are influenced by several other factors, including individuals' perceptions of the consistency, competence, fairness, and objectivity of governmental authorities [4–6]. This study aimed to assess the behavioral determinants that influence compliance with PHSM in the Federation of Bosnia and Herzegovina (FBIH) during the first year of the COVID-19 pandemic 2020-2021.\n\nResearch suggests that when PHSM are communicated in an easily understood way, through trusted and accessible channels, it aids people in making informed choices to comply and protect themselves and their communities [7,8]. To provide a tool for countries to understand these population-level perceptions and behaviors and how they might influence PHSM compliance, the WHO Europe Regional Office worked together with a team at the University of Erfurt to develop a COVID-19 behavioral insights survey tool. This tool included a standard template protocol and questionnaire for adaptation by public health authorities at country or local levels.\n\nBoth PHSM policies, such as cancellation of mass gatherings and complementary behavioral research monitorings were implemented in the Federation of Bosnia and Herzegovina (FBIH), tailored and adapted to the specific epidemiological situation that changed over the course of the pandemic ([9–11]. The survey was delivered in five discrete waves between the spring of 2020 and the summer of 2021. The aims of the survey were to 1) monitor the behavioral determinants critical for population compliance with the PHSM, including health literacy, risk perceptions, trust, and perception of fairness of the measures; 2) assess population behavioral changes regarding uptake of PHSM over time; 3) see how those changes relate to behavioral determinants, and contribute to findings on factors encouraging PHSM uptake more broadly; and 4) identify socio-demographic factors (such as sex and age) that help to describe target groups with low compliance and low trust.\n\nThis study scrutinizes the results of the behavioral monitoring system in conjunction with self-reported behaviors. The paper begins by outlining the research methodology including the survey measures. Section II analyses the survey data across the five waves. Section III discusses the key behavioral determinants of PHSM uptake in FBIH. Section IV concludes and offers recommendations.\n\nThe research team fielded five cross-sectional survey waves in the FBIH during different periods of the COVID-19 pandemic in the country between June 2020 and August 2021, reaching a total of N = 5,195 participants, approximately 1,000 unique respondents per wave [12].\n\nInformation about the samples and data collections can be seen inTable 1. These surveys enabled us to monitor changes, trends, and patterns in the population's responses and attitudes toward the COVID-19 pandemic. The research company collecting the data distributed the online questionnaires to various population segments, enabling collection of a diverse range of respondents over time. While distribution methods were constant, response rates increased in the later waves (Wave 1: 21%, 4.818 invitations; Wave 4: 54%, 1.958 invitations; Wave 5: 47%, 2.158 invitations). All participants provided written informed consent documented by the data collection company, and the study was approved by the Ethics Committee in the FBIH and the WHO Ethical Review Committee. Participants could terminate their participation at any time. On average, people took around 17 minutes to complete the survey. Participants were allowed to end the questionnaire at any time. However, over all five waves only 8% of participants who started the questionnaires dropped out before giving all answers. Data were analyzed using R Studio. All scripts and analysis outputs are visible on OSF (https://osf.io/5vr37/?view_only=c3ec4c6132f04c709a6cde333c3fd31b) [13].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t001\n\nThe questionnaire was based on the WHO Regional Office for Europe COVID-19 behavioral insights questionnaire [14] and adapted to the FBIH context [13]. It was designed to obtain information on individuals' opinions about their risk perceptions, knowledge, self-efficacy, confidence in institutions, behaviors, rumors, affect, worry, resilience, trust in/use of information sources, and more. We report on the following subset of seven variables as we are interested in changes over time. In section II we report on the statistical analysis of these variables as behavioral determinants of PHSM uptake.\n\nSelf-efficacy refers to an individual's belief in their capacity to execute behaviors necessary to achieve specific outcomes [15]. It is a critical factor in several theories of health behavior [16,17] and has been shown to influence infection prevention [18,19]. Two items were used to assess self-efficacy. The first item covered the theoretical efficacy (i.e., knowing how to protect oneself) ranging from 1 (not at all) to 7 (very much so). The second item covers the behavioral self-efficacy (i.e., avoiding an infection in the current situation) ranging from 1 (extremely difficult) to 7 (extremely easy). Due to a low correlation of the items (r = .32), we only use the behavioral self-efficacy as a behavioral determinant in the regression analyses.\n\nIn line with the literature [20], perceived susceptibility, severity, and likelihood of contracting the novel coronavirus infection form cognitive risk perceptions. High risk perceptions are associated with increased protective behaviors [20]. On a 7-point Likert scale ranging from 1 (extremely unlikely/not severe/not susceptible)to 7 (extreme likely/very severe/very susceptible), respondents rated their agreement with each statement. A Cronbach’s alpha of 0.74 confirmed this scale's satisfactory internal consistency.\n\nEmotions, especially fear, can play a significant role in motivating individuals to adopt prevention behaviors. According to Bradley & Lang [21], dominance, valence and arousal are important dimensions of emotional responses. We collected the emotional response to the pandemic situation with eight items. All were collected on semantic differentials (e.g., Perceiving the virus as 1spreading slowvs. 7spreading fast; Perceiving the situation as 1not stressfulvs. 7extremely stressful). Two items, perceiving the pandemic as media-hyped (vs. not) and feeling depressed (vs. not) might cover the results of more complex cognitive and affective processes [22] rather than the initial emotional response dimensions. Reliability analyses showed that those items were not sufficiently correlated with the rest of the emotional response scale. To reach a sufficient Cronbach’s alpha (α = .71 [.70;.72]), the two items had to be excluded from the score.\n\nRespondents were asked to rate their level of trust in health professionals, the Ministry of Health, the Institute of Public Health, their employer, schools and churches. Respondents rated their agreement from 1 (strongly disagree) to 7 (strongly agree). A scale using trust in health professionals, in the Ministry of Health, and in the Institute for Public Health had very good internal consistency, indicated by a Cronbach’s alpha of α = .87 [.87;.88].\n\nAn individual's ability to access, understand, and apply health-related information about their health, disease symptoms, treatments, and preventive behaviors critical for engaging in protective health behaviors [23]. Individuals with higher health literacy are more likely to seek accurate information, understand public health guidelines, and take proactive steps, such as applying PHSM, to prevent illness [24]. In waves 2–4, participants were asked about their perceived ability to find the information they needed about symptoms, treatments, and behavioral recommendations for COVID-19. In wave 5, this scale was extended with six items to COVID-19 vaccination literacy. Respondents rated their agreement from 1 (strongly disagree) to 7 (strongly agree). Cronbach’s alpha indicates excellent internal consistency (α = .88 [.88;.89]) in all waves.\n\nDuring the COVID-19 pandemic, restrictions such as curfews, limitations of gatherings, isolation, and school closings were implemented to depress the number of infections. In each round, participants indicated via three items whether they thought the decisions made by politicians were fair, if they found them exaggerated, and if they convinced others that the decisions were right. We summarized these perceptions into the fairness and policy acceptance scale with moderate internal consistency (α = .64 [.62;.65]).\n\nOver all five waves of data collection, participants were asked whether they engaged in a total of seven recommended preventive behaviors, including handwashing for at least 20 seconds, wearing a face mask, maintaining physical distance, and disinfecting surfaces. Respondents answered these questions with a binary answer format in wave 1–4. In wave 5, the answer scale changed into a 7-point scale ranging from 1 (never) to 7 (always). For comparison, we recoded answers into a binary form for no (from 1–4) vs. yes (5–7) answers. The mean values internal consistency was sufficient (α = .74 [.73;.75]).\n\nFirst, descriptive statistics were calculated for all demographic characteristics and outcome variables to provide an overview of the sample.\n\nSecond, we aimed to examine whether the average values of behavioral determinants changed between the five survey waves. To do this, we performed six one-way analyses of variance (ANOVA), one for each behavioral determinant (self-efficacy, risk perceptions, emotional response, trust, health literacy, and fairness and policy acceptance). ANOVA is a statistical method used to compare means across multiple groups—in this case, the five survey waves—and determine if differences are statistically significant. Tukey post hoc tests were applied to identify specific pairwise differences between the cross-sectional samples. Additionally, we performed an ANOVA for protective behaviors to analyze whether they varied between the five waves.\n\nThird, multiple linear regressions were used for each wave to determine which behavioral determinants significantly predicted preventive behaviors. Regression analysis is a statistical technique that identifies the relationship between one dependent variable (e.g., preventive behaviors) and multiple independent variables (e.g., behavioral determinants). To further explore whether socio-demographic characteristics influenced behavioral determinants, additional linear regressions were conducted, with results detailed in Appendix 1. All analyses were performed using R-Studio, and the raw datasets are available for replication in an Open Science Repository. (https://osf.io/5vr37/?view_only=c3ec4c6132f04c709a6cde333c3fd31b) [13].\n\nSocio-demographic analysis shows that the age group of 30-49 years constituted the highest number of respondents with 44.5% (2,313), followed by the 50-64 age group with 26.5% (1,380), while females were represented by 51.8% (2,692) and males by 48.2% (2,503). Individuals residing in urban settlements accounted for 56.0% (2,911) of the sample.\n\nTable 1shows the samples' distributions. In comparison with representative census data, the samples were slightly more educated (university degree in the sample: 25%–32%, university degree in the population: 10,1%) [25], and had slightly more living conditions that included children (living with children in the sample: 39%–54.3%, living with children in the population: 25.2%) [26].\n\nTable 2shows the results of the ANOVA and Tukey post-hoc tests. For behavioral self-efficacy, there is a significant change between waves. The post-hoc tests show that self-efficacy decreased significantly from wave 1 to wave 3 and wave 4. Self-efficacy was initially measured with two items.Fig 1shows both items over time. We can see that perceived knowledge about protective measures is higher than behavioral self-efficacy in all waves, and it seems to be a fairly robust perception, as perceived knowledge remains relatively consistent whereas behavioral self-efficacy declines.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t002\n\nBars displaying mean values and 95%-Confidence Intervals.\n\nBars displaying mean values and 95%-Confidence Intervals.\n\nhttps://doi.org/10.1371/journal.pone.0320433.g001\n\nRisk perception, particularly concerning COVID-19, underwent significant fluctuations across multiple waves of data collection. Initially, there was a noticeable upward trend in the perception of risk among participants, steadily increasing through the first four waves. However, an intriguing shift occurred in the fifth wave, where there was a decline in overall risk perception compared to the preceding waves. This deviation from the upward trend observed in earlier phases suggests a dynamic and evolving perception of risk among individuals throughout the course of the study. Throughout these waves, the participants' perceptions across all dimensions of risk displayed consistent increases, signifying a broad-based elevation in risk awareness and concern. Additional analysis focused on psychological determinants influencing pandemic behavior reveals several noteworthy associations. Notably, individuals in urban areas or with chronic illnesses tended to exhibit higher levels of risk perception, highlighting how environmental and health-related factors may intensify perceived risk. Conversely, individuals with children tended to demonstrate comparatively lower levels of risk perception. This divergence underscores the potential influence of familial considerations or different risk assessment strategies employed by individuals with children, which warrants further exploration.\n\nThe statistical analysis, captured inTable 3, utilizing ANOVA and Tukey post-hoc comparisons, further delineated the nuanced shifts in risk perception across the waves of data collection. The ANOVA results indicated a significant variation in risk perception across the different waves, with subsequent post-hoc comparisons revealing specific pairwise differences between waves, underscoring the dynamic nature of risk perception across the study's duration. In summary, the participants' risk perception related to COVID-19 generally increased over the first four waves before declining in the fifth wave (Fig 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t003\n\nBars displaying mean values and 95%-Confidence Intervals.\n\nBars displaying mean values and 95%-Confidence Intervals.\n\nhttps://doi.org/10.1371/journal.pone.0320433.g002\n\nThe emotional response to the pandemic was a pivotal aspect examined throughout the five waves of data collection. The scale captured various emotional dimensions, ranging from anxiety to resilience, fear to hope, and stress. Each wave of data collection allowed for a nuanced understanding of how these emotional responses evolved and fluctuated over time, offering insights into the dynamic nature of individuals' reactions to the prolonged impact of the pandemic. In general, the items that the virus was “spreading fast” and “close” produced the strongest emotional reaction among respondents. Most items also displayed a spike in the fourth wave in December 2020.\n\nTable 4presents an analysis of variance (ANOVA) and Tukey post-hoc comparisons concerning risk perceptions across the different waves of data collection. These statistical analyses elucidate the relationship between emotional responses and risk perceptions, highlighting significant differences and patterns observed over the course of the study.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t004\n\nFig 3illustrates the items used to measure emotional responses across all five waves. Notably, items denoted with asterisks within the emotional response scale were integral in comprehending the spectrum and intensity of emotional reactions experienced by participants.\n\nEmotional response to the pandemic was measured on 7-point semantic differentials. The items marked with asterisks are included in the emotional response scale. Bars displaying mean values and 95%-Confidence Intervals.\n\nEmotional response to the pandemic was measured on 7-point semantic differentials. The items marked with asterisks are included in the emotional response scale. Bars displaying mean values and 95%-Confidence Intervals.\n\nhttps://doi.org/10.1371/journal.pone.0320433.g003\n\nConfidence in institutions encompasses trust in doctors, the Ministry of Health, the Institute for Public Health, educational institutions, employers, and religious organizations. Over all five waves there is a tendency of decreased trust, as can be seen from the general model of the analysis of variance inTable 5. However, in the post-hoc analysis using Bonferroni corrections, none of the data collections is significantly different from others because the effect is small. Descriptive differences between all waves and items can be seen inFig 4. Doctors emerged as the most trusted individuals throughout the pandemic. However, the Ministry of Health and the Institute for Public Health experienced a declining trend in trust during the fall and winter of 2020. Interestingly, churches, while being the least trusted institution in handling the pandemic, exhibited a notable increase in trust over time.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t005\n\nThe items marked with asterisks are included in the emotional response scale. Bars displaying mean values and 95%-Confidence Intervals.\n\nThe items marked with asterisks are included in the emotional response scale. Bars displaying mean values and 95%-Confidence Intervals.\n\nhttps://doi.org/10.1371/journal.pone.0320433.g004\n\nData on health literacy was collected in wave 2 to wave 5. Even though the scale changed in the last wave, we conducted an analysis of variance to see if there were any significant changes over time.Table 6shows that health literacy as a construct seems to be quite stable over the course of the pandemic. Looking into the descriptive differences of the single items inFig 5reveals great differences between respondents' perceived competence in different domains. Whereas most respondents were sure that they could find information about COVID-19 symptoms or vaccinations, far fewer were confident in their ability to judge reliability of information in the media.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t006\n\nBars displaying mean values and 95%-Confidence Intervals. The health literacy scale was adapted between wave 4 and wave 5., to cover additional questions about the vaccination.\n\nBars displaying mean values and 95%-Confidence Intervals. The health literacy scale was adapted between wave 4 and wave 5., to cover additional questions about the vaccination.\n\nhttps://doi.org/10.1371/journal.pone.0320433.g005\n\nParticipants in all waves were asked whether they accepted the official pandemic restrictions and if they perceived the restrictions as fair. An ANOVA revealed that these fairness and acceptance perceptions changed over time, asTable 7shows. Yet we can see fromFig 6that acceptance and fairness perceptions changed differently over the course of the pandemic. In all five waves, most respondents did not think of PHSM as exaggerated. However, fairness perceptions decreased over time, and being confident that the political decisions were right fluctuated as well. All measures significantly decreased during wave 3 in September 2020.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t007\n\nBars displaying mean values and 95%-Confidence Intervals. The first item was recoded, so that greater values always display greater acceptance. The original item was “I think, that the restrictions currently being implemented are greatly exaggerated”.\n\nBars displaying mean values and 95%-Confidence Intervals. The first item was recoded, so that greater values always display greater acceptance. The original item was “I think, that the restrictions currently being implemented are greatly exaggerated”.\n\nhttps://doi.org/10.1371/journal.pone.0320433.g006\n\nTable 8shows the results of a one-way ANOVA with the data collection wave as the independent variable and the mean value for protective behaviors as the dependent variable. Overall, protective behaviors decreased between June 2020 and August 2021. Post-hoc tests revealed that protective behavior was highest in June 2020, significantly increased again in the Winter of 2020 and then decreased to the lowest level in August 2021. Single descriptive developments for protective behaviors can be seen inFig 7. Levels of handwashing, mask wearing, and physical distancing in public remained relatively high across the survey waves. People were less engaged with the disinfection of surfaces and avoiding social events. Staying home from work/school was the least observed protective behavior. Being female was associated with higher odds of protective behavior for most outcomes. Exceptions were wearing face masks and adapting their work situation. Associations between respondents' age and individual behavior change were inconsistent and mostly weak. In our case, education level was connected with better information about symptoms.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t008\n\nSelf-reported number of protective behaviors during the COVID-19 Pandemic in FBIH. Participants over the five waves of data collection were asked whether they performed the respective behavior during the last 7 days. In wave 5, the answer format was changed from a binary format (1yes, 0no) to a 7-point Likert scale (1never, 7all of the time). For comparability, the answers were recoded into binary format (1 – former scale points 5-7, 0 – former scale points 1-4).\n\nSelf-reported number of protective behaviors during the COVID-19 Pandemic in FBIH. Participants over the five waves of data collection were asked whether they performed the respective behavior during the last 7 days. In wave 5, the answer format was changed from a binary format (1yes, 0no) to a 7-point Likert scale (1never, 7all of the time). For comparability, the answers were recoded into binary format (1 – former scale points 5-7, 0 – former scale points 1-4).\n\nhttps://doi.org/10.1371/journal.pone.0320433.g007\n\nAntecedents of protective behavior are mostly robust over the different data collection waves, as can be seen fromTable 9showing all regression results. In all five regression analyses, higher emotional response and higher policy acceptance are associated with more protective behavior. In three to four of the regression analyses, higher age, being female (vs. male), having higher trust in institutions, and higher risk perception is associated with more protection behaviors. Less robust are the results for effects of education, urban vs. rural living, self-efficacy, and health literacy. Overall fit of the regressions is between moderate to high (Wave 1: R2= .134, Wave 2: R2= .208, Wave 3: R2= .207, Wave 4: R2= .198, Wave 5: R2= .198).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320433.t009\n\nThis survey and its accompanying data analysis illuminate the significant impact of behavioral determinants in relation to PHSM. For this summary discussion we will focus on four factors most strongly associated with protective behaviors: emotional response, risk perception, policy acceptance, and trust in institutions. We will also address health literacy and relate our findings to the broader research literature.\n\nEmotional response was a strong predictor of protective behaviors. Our survey respondents reported the strongest emotional response to the perceived speed of the virus's spread and its nearness to them; they were less concerned about feeling helpless and thinking about the pandemic all the time. The perception of COVID-19 risks among the public and their willingness to adhere to preventive measures, such as vaccination, in our study is influenced by various factors. Risk perception generally remains high; however, factors such as trust in governmental initiatives, a shared sense of responsibility, and active participation in health-protective behaviors can significantly shape and potentially reduce these perceptions [27]. The spike in emotional response in the fourth wave likely relates to heightened risk perceptions, which would be consistent with findings from other research (see below). Our findings on the predictive power of emotional responses align with broader literature from Europe, Asia and North America [28–33]. In European countries, perceived threat and negative emotional reactions, such as worry, have been consistently identified as key predictors of self-reported preventive behaviors during the COVID-19 pandemic [30]. Research shows that individuals perceiving greater threats and experiencing stronger negative emotions, including fear and anxiety, are more likely to adopt protective measures such as social distancing, mask-wearing, and adherence to health guidelines [29]. Kim et al. found specifically thatnegativeemotions were strong predictors of protective behaviors in Korea [32]. Similarly, in a study by Liu et al., negative emotions increased risk perception, which in turn increased intentions to wear face masks in the US [33].\n\nRegarding COVID-19 risk perception, respondents initially exhibited a noticeable increase, which continued to rise steadily through the first four waves of data collection, culminating in a significant surge during the fourth wave. In the Federation of Bosnia and Herzegovina (FBiH), where the pandemic was marked by fluctuating case numbers, the population may have experienced fatigue in consistently adhering to preventive measures [27]. The data indicate a pronounced increase in risk perception around weeks 44 to 49 in 2020 (corresponding with the fourth wave), which coincided with a high number of COVID-19 positive people and deaths [11]. Notably, individuals living in urban areas or dealing with chronic illnesses tended to demonstrate heightened levels of risk perception, emphasizing the influence of environmental and health-related factors on perceived risk intensity. Our analysis revealed a positive correlation between risk perceptions and the increased adoption of protective behaviors, suggesting that heightened risk perception promotes the adoption of protective measures.\n\nOur findings reinforce trends observed in national and international studies. Multiple studies [34–39] have explored risk perceptions and consistently concluded that individuals perceiving greater risks are more likely to adopt protective behaviors. In another study in the FBIH, Musa et al. conducted a comprehensive assessment of risk perception, trust in institutions, and the impact on vaccine intention [40]. The index of risk perception—encompassing self-assessed probability of COVID-19 infection, susceptibility and perceived severity of COVID-19 illness—emerged as a highly significant driver of positive vaccine intentions. Noteworthy risk factors, such as older age, underlying medical conditions, and occupation requiring close contact with COVID-19-positive patients were identified as contributors to risk perception [40,41]. In a study conducted in Italy, Di Giuseppe et al. found a high risk awareness among the study population, though respondents had low confidence in their ability to protect themselves from infection [42]. These findings correspond with our results, where knowledge about protective measures was higher than behavioral self-efficacy across all data collections.\n\nPolicy acceptance and perceptions of fairness were also important predictors of protective behaviors in our analysis. Though participants did not generally think that PHSM were exaggerated, they had dimmer views of fairness, and relatively few said they would try to convince others that PHSM decisions were right. The lower ratings on these latter two items suggest low confidence in decision-making institutions. This conjecture is supported by the wider research literature, where policy acceptance is typically studied in the context of trust, whether in government or science [43,44]. For instance, Guglielmi et al. [45] show how institutional confidence and specific political support influence public acceptability of containment measures in Italy, suggesting that trust in institutions can either facilitate or hinder compliance depending on political contexts. In the FBIH pandemic monitoring here, we can see that the values for trust and policy fairness decreased to the same amount from wave 1 to wave 3, but we do not see that their increase is parallel in the last 2 waves. This evidence indeed points to trust as playing an important (albeit complex) mediating role in policy acceptance [45,46].\n\nThough our surveys did not measure trust in science, they showed that trust in institutions was generally low across all waves and declined for the Ministry of Health and the Institute for Public Health during the fall and winter of 2020. However, trust in family doctors remained relatively high and was linked to protective behaviors. Trust in government has generally been found to be positively associated with protective behaviors [47–49], though sometimes with a moderate impact in modelling studies [50]. Similar to a study from the Netherlands regarding H1N1 [51], our results have shown that people who trust the health ministry and the media are more likely to adopt recommended behavior to control the spread of a pandemic virus, compared with people who lack trust in the health ministry and the media.\n\nHealth literacy was not a significant antecedent of predictive behaviors in our analysis. Although health literacy is repeatedly associated in the literature with people being better able to understand and apply more proactive health protection, there is no relationship between health literacy and PHSM in the multiple regression. The global pandemic and the associated media attention could have made it easier to find information, so that everyone had access to easily understandable information. In line with this explanation, the data for health literacy showed that information seeking was assessed as relatively straightforward, with individuals feeling capable of finding information about symptoms or regulations. In contrast, lower values were evident when it came to translating this information into daily life, indicating difficulties in incorporating regulations and recommendations into everyday decisions\n\nFinally, it remains to mention the limitations of these pandemic monitoring surveys in the FBIH. Online samples hold a potential risk of bias because they reach only the people who have access to the internet. Even if there is a high level of internet usage (73.2% in 2020, 75.7% in 2021, and 78.7% in 2022 [52], this selection bias might be higher in older generations, so all effects where age is relevant would need to be replicated. Additional telephone surveys or household interviews might increase further insights about the effect size of this sampling bias and include underrepresented groups in the data set. Even if this additional sampling strategy was no option for this monitoring survey, future monitorings could include mixed methods in sampling. On the other hand, advantages of online surveys included that the samples were drawn to be representative and were collected in a short time period, reaching participants all over the country. Rapid data collection was of high importance during the pandemic to prevent additional confounding due to fast-changing measures and recommendations. Further, online samples are known to produce less social desirability biases [53], and especially when strict measures and recommendations were in place, social desirability might have biased the responses in interview formats. As a further limitation, we experienced a difference in the invitation/ participation ratio over the waves, with more people needed to be invited at the earlier waves of the cross-sectional survey. This might be caused by the intense information density at the earlier stages of the pandemic. In consequence, people may have been striving more for distraction, producing a self-selection bias in the early waves of our data. The people who were affected most strongly by the pandemic may have evaded the questionnaire study. Future pandemic studies with special panels could carefully address precisely these people, e.g., with help hotlines or counseling services, including qualitative approaches alongside the quantitative data for the general population. With this approach, behavioral insights could also be used for this target group to adapt pandemic decisions and support even better to the people who are psychologically affected most. Despite these limitations, the data collected were robust enough to contribute directly to the COVID-19 response in the FBIH in communications and messaging, interventions, programs, and policy.\n\nThis study highlights the importance of “public pulse monitoring” through ongoing surveys which can help tailor communication about PHSM to increase compliance. Our surveys in the FBIH showed how pandemic perceptions changed over time, and that responses to PHSM were influenced particularly by trust in institutions, risk perceptions, and emotional response. Given that our findings generally accord with similar conclusions from the wider research literature, we can offer several recommendations for future pandemic preparedness and to increase societies' resilience in health emergencies.\n\nFirst, the importance of trust is paramount; it is something that authorities must strive for and promote. Because public trust has a strong association with compliance to PHSM, and is vulnerable to eroding over time, there is a need to regularly review communication approaches and tailor information strategies for specific groups to help improve protective behaviors. Which channels and trusted sources may work best should be investigated continuously in behavioral insights surveys, as trusted sources and channels (such as social media platforms) change over time.\n\nSecond, and likewise related to communication, our results underscore the crucial role of behavioral insights surveys in providing well-tested and evidence-based information about risks and PHSM. Our data show how individuals with heightened risk perceptions were more inclined to adopt preventive measures and cautious behaviors, especially in the later stages of the pandemic. Hence, public health/scientific leadership will be essential in crafting effective risk communication strategies for future health emergencies [54]. Emergency recommendations should undergo thorough assessments for comprehensibility. Health messaging should also include clearly defined actions and provide practical examples to illustrate the recommendations.\n\nThird, and following from the previous two points, our analysis shows that communication about PHSM and promoting healthy behaviors, is not necessarily “one size fits all.” Behavioral surveys can provide valuable insights into how different sectors of a population will respond differently to emergency recommendations. For example, one possible explanation for divergent responses to PHSM we observed is that some measures were abandoned earlier when they entailed higher social and financial consequences for particular groups. Therefore, on the basis of behavioral research, emergency communication should address such consequences, act supportively, and if necessary, consider monetary or social assistance to particularly affected target groups.\n\nIt also includes descriptive gender differences of self-reported pandemic behaviors.\n\nhttps://doi.org/10.1371/journal.pone.0320433.s001\n\n(DOCX)\n\nThe initiative to collect these data as pandemic emergency response was led by the Behavioural and Cultural Insights Unit (BCI) in close collaboration with the regional WHO Europe emergencies programme, including the Risk Communication and Community Engagement (RCCE), the Public Health and Social Measures (PHSM) and the Essential Health Services (EHS) pillars.\n\nDisclaimer:The authors affiliated with the World Health Organization (WHO) are alone responsible for the views expressed in this publication and they do not necessarily represent the decisions or policies of the WHO.",
    "category": "mathematics"
  },
  {
    "title": "High impedance faults detection in power distribution networks using rogowski coils, kalman filtering, least-squares and non-recursive DFT computation engines",
    "authors": "Ziad M. Ali, Mostafa H. Mostafa, Shady H. E. Abdel Aleem, Ehab M. Esmail, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320125",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320125",
    "content": "This paper presents a novel computational engine based on non-recursive discrete Fourier transform (DFT) technology to detect high-resistance faults (HRFs) in power distribution networks. The non-recursive DFT approach utilizes the interconnection between a sliding window for current signals and a foundation function window during transient error. This non-recursive DFT technology is characterized by a fixed error in amplitude calculation and a rotated output angle. The proposed technique is compared against several established methods for high-resistance fault detection in distribution systems, including current reconstruction (CR) using Rogowski coils, Kalman filtering, and least-squares computational engines. The performance of each technique is evaluated by assessing the estimated percentage error in the calculation of fundamental and harmonic amplitudes. To study the proposed technique, the aforementioned methods were carefully modeled and simulated using MATLAB software for the IEEE 33-bus test feeder, simulated arcing faults, and Rogowski coils under various test conditions. The comparison is conducted under the influence of different arc models in the distribution system to assess the performance of the proposed technology. The comparative results demonstrate the effectiveness of the proposed non-recursive DFT-based technique in detecting high-resistance faults in power distribution networks, outperforming the other established methods considered in this study.\n\nCitation:Ali ZM, Mostafa MH, Abdel Aleem SHE, Esmail EM (2025) High impedance faults detection in power distribution networks using rogowski coils, kalman filtering, least-squares and non-recursive DFT computation engines. PLoS ONE 20(4):\n           e0320125.\n        \n        https://doi.org/10.1371/journal.pone.0320125\n\nEditor:Palanisamy R, SRM Institute of Science and Technology (Deemed to be University), INDIA\n\nReceived:November 19, 2024;Accepted:February 13, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Ali et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and itsSupporting Informationfiles.\n\nFunding:The authors extend their appreciation to Prince Sattam bin AbdulAziz University for funding this research work through the project number (PSAU/2024/01/29709).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nHigh-impedance faults (HIFs) pose a significant challenge in power distribution networks. HIFs occur when an electrical conductor contacts a highly resistant material during a fault, leading to a secondary fault current. These faults can be categorized into two types: active and passive. The passive type of HIFs results from the gradual deterioration of underground cable insulation over time [1]. The active type of HIF appears when an overhead conductor breaks and touches a high-resistance ground, generating an immediate temporary arc [2]. Values of currents associated with these faults are slightly lower than the normal load current, rendering conventional overcurrent relays ineffective for their detection [3]. Moreover, earth-sensitive relays are inaccurate during unbalanced load conditions [4]. The HIF current values can be influenced significantly by the type of conductive medium and its humidity level.\n\nIn such cases, the fault current is too small relative to the normal load current, resulting in conventional overcurrent relays failing to detect these faults. Traditional relays have been reported to be blind to approximately 80% of HIFs in the distribution system, leading to uncertainty in the effectiveness of protection schemes against HIFs [5]. Due to this undetected situation, HIFs pose a significant risk to public safety, as a dropped conductor can inflict dangerous shocks or cause fires through accidental human contact [6]. Furthermore, the damage inflicted on facilities by HIFs is viewed as a threat to the facility’s assets and could result in irreparable damage [7]. HIFs exhibit different characteristics compared to the typical short-circuit faults, and this complexity is attributed to the following factors:\n\nThese unique characteristics of HIFs make them particularly challenging to detect and diagnose using conventional protection schemes, necessitating the development of advanced techniques for reliable detection and mitigation. Besides, accurate knowledge of faults is crucial for engineers to develop effective solutions.\n\nSeveral researchers have explored technologies that can detect, classify, and locate HIFs during their unobserved state. This subsection aims to review the latest methodologies used to diagnose HIFs.\n\nOne conventional technique involves using a primary balanced current transformer to measure the neutral current, which is then used as an input to a sensitive ground fault relay. This method is widely used in industry [13]. However, the presence of unbalanced loads and the inherent residual current in the system requires adjusting the relay’s tolerance rate to avoid annoying false trips, making it more challenging to detect HIFs. Differential protection schemes are known to be sensitive to HIFs, but their implementation in distribution networks is complex due to the presence of multiple generating points and loading buses.\n\nAn alternative approach proposed in [14] involves installing a ground grid under the transmission line phases to capture a fallen conductor before it contacts a high-impedance surface. While this technique could potentially detect HIFs, it is not economically feasible due to the additional infrastructure required for the ground grid.\n\nApplied industrial techniques like broken conductor detection, ground wire grid technique, and watt-metric protective relaying have also been introduced [14]. These methods rely on the overcurrent relay’s ability to detect the fault once the conductor is connected to the network. However, this approach may not be practical for all scenarios because it requires an additional ground grid installed on the poles of the long transmission line. The approach proposed in [15] involves putting a mechanical hook under the phase conductors connected to the neutral. If the conductor is downed, this method aims to trigger a short circuit from the line to the neutral line, leading to the overcurrent relays isolating the line. The conventional techniques discussed have limitations in accurately detecting and diagnosing HIFs. This highlights the need for innovative solutions and advanced methodologies to address the challenges posed by HIFs.\n\nSignal processing techniques have been explored to analyze electrical currents during HIFs with nonlinear loads. A fast method based on the Fourier transform was introduced to investigate electric currents in 1φ feeders [16]. This method examines the even and odd harmonic components to evaluate the condition of the electrical distribution system. Analyzing the magnitude of the harmonics over time shows that the spacing between the 3rdto 7th-order harmonics is distinct during HIFs, allowing its detection. However, this approach is sensitive to noise and requires noise reduction techniques to achieve the intended results. Another proposed method utilizes the Stockwell transform (ST) and measures the continuous phase angle of the 3rdharmonic of the current signal [17]. The difference in the 3rdharmonic is linked to line loading and switching, and a consistent 3rdharmonic value suggests the presence of HIF. However, this method may take up to 150 ms to detect the fault, which could allow the power to increase the incident before it is identified. Hybridizing the maximum interference between discrete wavelets packet transform and empirical mode decomposition (EMD) was introduced in [18]. The probability of an existing HIF is indicated by this approach, which estimates the change in energy content between the inter-harmonic energy content in the fault signal and the pre-fault condition. However, not all HIF types may perform well under real-world operational settings, according to the model. A method has been proposed that uses the spectral density of the power calculated from the wave covariance matrix [19]. Discrete wavelet transformation is used to separate time information from frequency information, and the method uses wavelet transform (WT) to measure the third level of current signals. The calculation of the power spectral density of faulty current signals follows the analysis. This method uses threshold analysis as a framework for fault detection. However, it has yet to be validated to determine the precise location of the fault. Another technique to process 3φ voltage and current signals is based on the decomposition of the orthogonal component [20]. Under normal operating conditions, these calculated components maintain an absolute zero value, but they may experience variations during faulty conditions, resulting in HIF detection. Although this method’s fault detection capability is strong, in half of the studied scenarios, the absolute error in fault distance estimation is greater than 10%.\n\nIn the literature, researchers have made various advancements in the detection and analysis of HIFs in power distribution networks using mathematical-based methods. The key contributions include the extension of HIF detection methods to include mathematical and mechanical techniques [21]. This includes the introduction of a new low-frequency relay based on the pattern of the 3rdand 5thharmonic components of the high-resistance arc fault based on determining the time domain (pattern shape) of the harmonic voltage, current, power, and voltage/current ratios at these harmonic orders [22]. Creation of a differential equation-based technique to calculate the zero-sequence capacitance both upstream and downstream of the fault, allowing for the quick, noise-free, and self-calibrated detection of HIFs in isolated neutral networks [23,24]. Actual data can be used to estimate the fault admittance of medium-voltage systems, enabling the identification and localization of HIFs with resistances between 100 and 200 kΩ. A modified state estimation model for HIF diagnosis, incorporating voltage and power measurements, was introduced, but with significant errors during load variation [25]. An iterative approach to fault location requires a lot of computer processing power and uses the weighted least squares method to assess fault reactance and calculate resistance [26]. Using linear regression of the calculated fault distance components, an analytical estimator of the weighted least squares state is used to compute the fault voltage and current to identify HIFs in distribution networks [27]. A method estimating fault location by comparing fault parameters calculated from voltage and current measurements with reference data, but with a high computational burden and limited to single-feed distribution lines [28]. The representation of a time series of signal samples for HIF detection using linear prediction without taking nonlinear loading impacts into account [29]. These advancements demonstrate the ongoing efforts to improve the detection, analysis, and localization of HIFs in power distribution networks, enhancing grid reliability and safety.\n\nThree main steps are involved in AI-based methods for diagnosing HIFs: gathering data, extracting features through signal processing methods, and training with machine learning (ML) algorithms. The most recent developments in each of these procedures will be covered in this section.\n\nData acquisition:The intelligent methods for diagnosing HIFs rely on the type of measurement signal used [30]. These current measurements have been employed to detect and classify HIFs in distribution networks, even though current waveforms in HIFs have harmonic components that are noticeable from normal load states [31]. Pay attention to how the percentage errors of current transformers impact current measurements. In HIFs, arcing phenomena cause an occasional voltage spike, particularly when contact with objects like trees causes the malfunction. Variations in fault resistance will arise from the motion-induced introduction of air gaps between the conductor and the surface. A technique based on arcing voltage measurements has been discussed in [32]. However, voltage changes make capturing the waveform increasingly challenging because the voltage is dipped. Consequently, to improve findings, neural network (NN) training was used for both current and voltage waveforms in order to diagnose HIFs in distribution systems [33]. Unfortunately, this method expands the dataset for the neural network, necessitating a thorough study to restrict training on important features and manage the computational burden. It has been determined that the HIF problem is a pattern classification challenge that NN classifiers might face when training using features taken from measurements of magnetic field strength, voltage, and current [34]. The method of using resistance measurements to diagnose HIFs has also been introduced, where the resistance values are compared with the prime impedance values of the transmission line under normal operating conditions [35]. This comparison can shorten network outages and shed light on the line’s fault location. Resistance, however, is unable to adequately capture the nonlinearity, asymmetry, or arcing characteristics of HIFs, and it is severely compromised when attempting to identify such faults with these measurements. The synchronous phase-measurement units aim to employ a signal in a set period as an absolute value paired to the phase angle [36]. These measurements accurately represent voltage and current waveforms in power systems. The use of synchronous phase measurement units in HIF diagnosis has been discussed [37]. However, more research is needed to determine how to use these units for HIF diagnosis while taking fault asymmetry and nonlinear load into account. At present, low-power instrument transformers and sensors have become prevalent in power systems. This development is a result of the improved network management and control operations made possible by these new generations of instrument transformers [38]. Although not a novel concept, the Rogowski coil (RC), invented in the 19th century by Walter Rogowski, is one of the most widely used low-power instrument transformers. Its numerous applications are made possible by the developments in digital systems, signal processing, electronics, and other fields. Owing to its numerous benefits—lightweight, inexpensive, flexible, linear, immune to core saturation (because its core is composed of a non-magnetic material), and an easy-to-use design that allows it to be applied in a variety of RC settings has become increasingly popular. On the other hand, positional errors indicate that some RC measurements deviate from expected values. Nevertheless, achieving optimal coil design can reduce these errors to less than 0.1% [39]. Therefore, the design of the RC can be further improved using new optimization techniques, such as particle swarm optimization or others, to achieve the desired performance [40]. Another key consideration of the RC is its susceptibility to external magnetic fields generated by extraneous currents. However, this issue can be effectively mitigated through the use of shielding or by employing a design with two opposing coils, which helps minimize the impact of these external magnetic fields [41]. Furthermore, the RC differs considerably from the conventional current transformer. Traditional current transformers directly convert the input current to a lower current within their secondary coil, with the conversion ratio determined by the transformer design. However, at its output terminals, the RC generates a low-voltage signal. The reconstruction current, which is the intended sensing current, must then be obtained by specific processing of this voltage signal. Interestingly, research has also investigated the influence of geometric parameters on the high-frequency performance of the RC, particularly in the context of partial discharge measurements [42]. Furthermore, research has examined the behavior of the RC in relation to the position, form, and course of the power conductor as well as the influence of a non-circular coil geometry and the presence of external currents [43]. Finally, it is worth noting that low-cost RCs and their associated auxiliary circuits have found application in the measurement of power frequency quantities [44].\n\nFeature extraction:Signal processing techniques must be used to extract features so that machine learning (ML) algorithms can operate effectively. The Fourier transform is one such method that is frequently used in applications addressing power quality disturbances. This method finds signal frequency components when there are disruptions [45]. Although the Fourier transform is continuous over time, it is frequently used in discrete forms in computational applications, such as in the detection of HIFs [46]. Fast Fourier transform (FFT), another form, was also employed [47]. Only the features in the frequency range can be represented by the Fourier transform for the purpose of applying the HIF diagnostic. WT is a sophisticated method for signal processing that can represent information in both the time and frequency domains, in contrast to Fourier transform [48]. Furthermore, compared to discrete wavelet transforms, wavelet packet transform (WPT) conversions offer more information [49], as they can degrade in higher and lower frequency bands at each level. This application has given adequate results in the HIFs’ detection and classification of [50]. Furthermore, the application of multi-WT is discussed in [51]. Several scaling functions and associated multi-wavelets cause the threshold to be exceeded in the multi-WT, which is an extension of the scalar wavelet. As a result, the node will create a value product that is either equal to or close to one; if not, it will have zero.\n\nMachine learning:A neural network (NN) is a complex framework made up of many nodes that have undergone exact processing to carry out several demanding mathematical operations. The strength of the network administers these operations, referred to as weight, which is influenced by external inputs known as bias. This intricate process produces a set of historical patterns through the iterative mechanism of adaptation [52]. Typical artificial neuron inputs have signals weighted through multiplication factors and are aggregated along with the bias to feed a node. Following that, the value is compared to a predefined threshold. If the result matches or exceeds the minimum, the node will return a value that is almost identical to one; if not, it will provide a value of zero. NN training is mostly concerned with identifying the best weights and biases to achieve the desired results. The multi-perceptron-based model was employed to diagnose HIFs through the effective utilization of backpropagation technology. This approach trained the network to accurately detect and classify faults [53]. However, it has become evident that a more sophisticated technique is required to gather the suitable number of hidden layers and neurons to develop the most prominent results with reduced computational time; hence, a hybrid approach using the multi-perceptron in conjunction with the regression of the Gaussian process was implemented [54]. The multi-perceptron was utilized to find the optimal results (weights and biases) for the detection and classification of HIFs. At the same time, the Gaussian process regression was a linear regressor aimed at approximating the location of the fault within the transmission line. The ST has also been used as a preliminary processing and feature extraction technique to develop the most efficient approach [55].\n\nResearchers have suggested the use of RC in many applications, such as measuring power frequency current [56], pulse and pulse current measurement [57], detecting the fault in converters [58], tracking the condition of the high-voltage insulators [59], power network equipment [60], smart meters [61], and other applications. Power frequency current and various impulse current properties of single-core and multi-core cables are measured with it. Power frequency measurement has various applications, one of which is fault diagnosis. In [62], an RC model specified using the system identification toolbox is used to obtain the exact terminal voltage, and the transient slope of the ground and aerial voltage during the fault is extracted to classify the fault type, distinguish the fault section, and identify the faulted phase in each cycle. In [63], it has been shown that RC can detect high frequencies and identify high-frequency transient faults in a variety of fault scenarios, such as a high resistance fault and intermittent fault cases, where RC measures and extracts the fault’s surges. The distance the fault surge traveled to reach the measuring point determined the sensitivity of each RC and the surge arrival time. In covered conductor lines, RC has also been effectively employed to measure and extract high-frequency partial discharge signals [64]. Distributed RC is a fault pass indicator used to identify the active travel wave fault location, where active travel waves are injected by switching the neutral point of unearthed and compensated networks using thyristors [65]. This method can create traveling waves even when the faulty feeder is in service. The results confirm the applicability of using RCs for traveling wave applications in fault locating and fault management in distribution networks.\n\nThis work examines the computational engine utilized for detecting HIFs, which relies on a non-recursive DFT to measure the fundamental and higher-order harmonics within distribution networks. One of the modeling techniques selected for HIF was the numerical technique, which demonstrated accuracy in its modeling using MATLAB simulation software. Three computational engines were chosen to conduct an accurate comparison with the proposed engine, and this comparison revealed the proposed engine’s effectiveness in detecting HIF. The MATLAB simulation software modeled the IEEE-33 bus distribution feeder to facilitate this comparison. Furthermore, the comparison has been expanded to include recently published methods for HIF detection, as well as the computational engines under study. The simulation results demonstrated the proposed computational engine’s accuracy, reliability, and security in detecting this challenging type of fault. The novelty and key features of the proposed computational engine, which verify the effective achievement of its purpose in comparison to recently published studies, are (i) Function: The engine can accurately estimate all fundamental and higher-order harmonics; (ii) Cost: No new components are required, as the computational engine can be integrated into the pre-existing protective relay at the beginning of the feeder, in contrast to other existing schemes; (iii) Flexibility and autonomy: The engine does not rely on powerful threshold values and instead depends on the nature of its non-recursive DFT-based calculations; and (iv) Accuracy, reliability, and security: The engine offers advantages in terms of these standards compared to other existing schemes, as it provides distinct results for these criteria.\n\nThe remainder of the manuscript is organized as follows: Section 2 presents the HIF modeling methods found in the literature, and the most accurate modeling methods have been selected for inclusion. Section 3 details the modeling of both the IEEE 33 bus distribution feeder and the RC circuit used in one of the engines to detect HIF. In Section 4, four computational engines that can detect HIF are introduced. The results of the four computational engines are presented in Section 5. A comparison of the four computational engines is made in Section 6 to determine the proposed engine. Section 7 expands the comparison to include other methods from the literature to verify the efficacy of the proposed engine. Finally, Section 8 is devoted to the conclusions derived and future directions of the work. A schematic overview of the manuscript and the steps implemented for evaluating the proposed computational engine are depicted inFig 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g001\n\nThe innovation of the proposed engine and the important characteristics that prove its success in performing its function sufficiently compared to the previous methods are:\n\nProposed method\n\nSuperiority over existing methods\n\nThe proposed non-recurring DFT-based engine represents significant advances in HIF detection, addressing existing method limitations by providing improved accuracy, cost-effectiveness, and adaptability. This positions it as a valuable tool to enhance safety and reliability in power distribution networks.\n\nArc modeling includes the representation in different applications. They are either normal operations or abnormal conditions. These applications are as follows:\n\nAll these arc models are dynamics. According to the application type and conditions, the arc model parameters, including the arc elongation parameters, have been changed. This parameter has a significant effect on the arc voltage.\n\nMany research works include modeling HIFs as a crucial component since the modeling approaches’ ability to reproduce HIF features accurately is what determines how accurate the results are. To effectively mimic these HIF qualities in a simulated environment—such as nonlinearity, asymmetry, unpredictability, intermittency, build-up, and shoulder characteristics—complex modeling techniques are needed. As a result, the modeling strategies currently employed in the literature to depict these difficult HIF characteristics will be addressed throughout this section.\n\nThe ultimate objective of HIF diagnosis is solving an actual issue. Thus, a simple method that can be used is real data generated in a high-current research facility. In [22], a range of HIFs were simulated, and the corresponding current and voltage magnitudes were recorded using digital data recording equipment. Materials like tree branches, grass, and concrete surfaces were provided in both dry and wet circumstances. Owing to space restrictions, this method may only be feasible for some other researchers, even if it offers useful, practical data for research and is the closest approximation to genuine HIF. To replicate real HIF performance, laboratories will also require costly high-voltage equipment in addition to strict safety precautions to reduce the possibility of high-frequency arcing.\n\nThe fault conditions are simulated in a virtual environment as part of the second category of HIF modelling methodologies. This paper will describe several models, including those used in MATLAB, ATPDraw, and electromagnetic transient tools, that are used in the literature to mimic the characteristics of HIFs.\n\nUsing (1) to determine the arcing resistance (Rarc), this model was first developed by simulating the arcing properties of HIF based on the concepts of Cassie [67] and Mayr [68].\n\nwhereR0is the initial fault resistance, andtdenotes the timeand τ is a constant of the system. This method adds a degree of randomization to HIF simulations, but it misrepresents the fault’s asymmetry and nonlinear features.\n\nIn [69], the HIF illustration is depicted inFig 2(a). The fault resistanceRfis calculated using the following mathematical equation:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g002\n\nwhereαandβare user-defined constants,Ifdenotes the fault current, andI0denotes the initial fault current value. An inductor with a typical value ofLf=  3 mH is connected in series with the fault resistance [70]. The approach is simple to use and has a low computational burden overall. However, it is far from an accurate representation of actual HIF data due to the empirical assumptions made in the model.\n\nA good method for modeling the shoulder characteristics, build-up, asymmetry, and nonlinearity of HIFs was introduced in [71] through the use of two variable resistors, as shown inFig 2(b).R1is designed to model the asymmetry and nonlinear characteristics of the HIF currentIfand voltageVf, with values sampled over time. The build-up features are overlooked because the obtained values ofR1are from cycles with amplitudes that are comparable to those of prior cycles. Conversely,R2is intended to reflect the HIF’s build-up and shoulder features. The fault current will eventually attain a steady state value since the resistance will start high and gradually drop. The sampled data may differ based on the type and state of the surface. Furthermore, this model does not take the discharged arcing component into account [72].\n\nAnother model was introduced in [73] to represent the distinctive characteristics of HIFs, as depicted inFig 2(c). In this model, the resistancesR1andR2, together with inductancesL1andL2, add the nonlinear property to the HIF. Additionally, the factors ofVpandVnin the discharged arc voltage of the incident are incorporated. This model is designed with directional diodes so that ifVf>Vp, the fault current will flow from the source to the ground. The opposite will occur atVf<Vn, where current will flow back to the source, and whenVn<Vf, no current will flow into the system. Building upon this model [74], expanded on Emmanuel’s model through a variable resistance experiment, as depicted inFig 2(d). However, this model cannot simulate the build-up and shoulder features of HIFs.\n\nIn [75], a new HIF model was introduced, consisting of a nonlinear resistor, two diodes, and two DC sources that randomly change the amplitude every half cycle, as shown inFig 2(e). This model is designed to represent the specific dynamics and randomness of HIFs. The mean change and standard deviation of the DC source voltage amplitude are used to closely approximate the characteristics of different ground surfaces, such as asphalt, sand, and grass.\n\nThe high-resistance fault model introduced in [5] and shown inFig 2(f)is identical to the source diode resistance model. It consists of two DC sources,VpandVn, connected by two diodes,DpandDn, respectively. The DC sources have asymmetric magnitudes, and their random values vary aroundVpandVnevery 0.1 ms. This model captures the unequal nature of the fault current and the disappearance of the middle of the arc. The values ofVpandVnrely on the system voltage to perform the simulation and the amount of asymmetry that can be modeled. IfVph>Vp, the corresponding current flows towards the earth and is reflected whenVph<Vn. WhenVn<Vph<Vp, no current flows. The variance ofVpandVnvalues adds randomness to the number of asymmetries and the arc’s disappearance period. Variable resistancesRpandRnare also included in series with the diodes, alternating separately and randomly every 0.1 ms. The model parameters used for simulation areVp=  1.0 kV with a random difference of ± 10%;Vn=  1.0 kV with a random difference of ± 10%;Rp=  random difference with 100–150 Ω; andRn=  random difference with 100–150 Ω. This model is designed to restrict the fault current to always be less than 10% of the total load current of the feeder.\n\nThe improved method, introduced inFig 2(g), consists of two time-variable resistors,Rn(t) andRp(t), that are controlled by the transient analysis of an electromagnetic transient program control system. This method is designed to model the HIF arcing characteristics more accurately. The key aspects are:\n\nTo better capture the complex and dynamic behavior of HIFs, this amended method makes use of these two time-variable resistors controlled by transient analysis.\n\nMany numerical models have been developed to describe the behavior of arcs. Most of these models have been utilized for circuit breaker arcs [76], and several have been applied to long arcs [77] or arcing faults [78]. The most extensively used models are those based on the assumption of thermal equilibrium. The thermal model boasts the longest history among dynamic arc models, tracing its origins back to the work of Cassie in 1939 and Mayr in 1943 [79]. They provided the initial description of arc conductivity as a first-order differential equation. Over time, these dynamic equations have been optimized and modified to enhance model validity and reduce computational requirements. Notably, the arcing fault [78] is represented by a successive differential equation, as demonstrated in the following expression.\n\nwheretis the time,τis the arc time constant,gdenotes the instantaneous arc conductance, andGis the stationary arc conductance, which is defined as follows:\n\nwhereiarcis the instantaneous arc current, andVarcis the stationary arc voltage. The arc time constant is defined as:\n\nwhereAandBare constant parameters representing the experimental values of the positive and negative half cycles. However, the appropriate parameters for the half cycle do not provide good agreement in properties during the negative half cycle. The parameters were set to match the results of the experimental arc current introduced in [80]. The dynamic arc model per instantaneous arc currentiarcis solved by determining the arc parameters related to the Kizilcay arc modeling approach described in [78]. As seen inFig 3(a), the fault resistanceRffound in the HIF model is a linear resistance representing the fault path resistance through an object with high impedance (was a tree in that study).Fig 3(b)depicts the Simulink tools in the MATLAB platform used to simulate the arc model, where the resistance representing the arc is variable type, and its value is obtained through the inverse of the instantaneous arc conductance, which aligns with the Kizilcay arc model. Also, the dynamic arc model periarcexpressed in (3) was adapted to represent the long arcs.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g003\n\nAs seen inFig 4(a), the arc parameters are determined such that the arc time constant is 1.3 ms, the arc voltage per unit length is 12 V/cm, the arc resistance per unit length is 1.3 Ω/cm, and the arc length is 350 cm, as reported in [81]. Similarly,Fig 4(b)depicts its block diagram used to simulate the long arc model. The implementation of this arc model is suitable only for the primary arc period with characteristics of high arcing current. However, for the secondary arc period, the arcing current is significantly reduced due to the opening of the single-pole breaker at both terminals of the faulted phase, as discussed in [82], in terms ofU0denotes the characteristic arc voltage, andr0denotes the characteristic arc resistance.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g004\n\nThe parametersU0,r0, andτdepend on the arc length (larc) and are calculated using the following equations derived from arc measurements.\n\nwhereτ0is the initial time constant,l0is the initial arc length, andαis the negative value coefficient. In this work, the numerical model is utilized to distinguish the high-accuracy performance characteristics obtained from it.\n\nThe IEEE 33-bus 11 kV radial distribution feeder was selected as the study system. This feeder data was obtained from [83] and is presented in theS1 Table.Fig 5illustrates this feeder, depicting a single-line diagram of the modified feeder with added source and loading adaptors. A single circuit breaker is inserted at the beginning of the feeder, and 64 normally closed switches are positioned at each end of a section, as depicted inFig 5. In addition, the system has five normally open switches (also known as tie switches) to allow for system reconfiguration as described in [84]. The positive sequence data for the feeder parameter and loads characterize the test feeder.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g005\n\nMATLAB software was utilized to simulate the selected distribution feeder. Each feeder section was modeled using the π circuit representation in the Simulink tool. Each load was represented as a 3φ balanced load implemented through a set of RLC branches. Appropriate remote-control switches and communication systems were added to enable the feeder automation and fault management process. Finally, measurement units were already in the protection relay at the primary substation and each feeder lateral exit. A sampling rate of 200 samples per cycle was selected. The discrete recursive Fourier transform (DRFT) was employed to estimate the values associated with the fundamental currents and each harmonic, serving as a baseline reference for the methods presented in the following sections.\n\nInitially, the RC is placed around a current-carrying conductor, as shown inFig 6(a). The current that passes through the conductor is distorted with both low- and high-order harmonic components. The fault current can be expressed as follows:\n\n(a)RC is placed around a current-carrying conductor, and (b) lumped-parameters equivalent circuit of the RC.\n\n(a)RC is placed around a current-carrying conductor, and (b) lumped-parameters equivalent circuit of the RC.\n\nhttps://doi.org/10.1371/journal.pone.0320125.g006\n\nwhereImdenotes the maximum fundamental current component (A), ω stands for the fundamental angular frequency component (rad/s),trepresents the time in seconds,θdenotes the fundamental phase angle component (rad),Imnstands for the maximumnth harmonic current component (A),θnis thenth harmonic phase angle component (rad), andnrepresents the harmonic order. This expression captures the fundamental current component as well as the summation of thenth harmonic current components, which are necessary to fully represent the fault current waveform. The induced electromagnetic forces are generated in the coil with fundamental and harmonic components. The induced electromagnetic forces of Faraday’s law can be calculated as follows:\n\nwheree(t) denotes the EMF generated in the RC by induction (V),Mcdenotes the mutual inductance (H), andiis the current passing through the RC (A). Substituting equation (10) into equation (11) provides the following expressions fore(t) and the output voltage at the RC terminalsvo(t):\n\nwhereVomdenotes the maximum fundamental output voltage component (V),βdenotes the fundamental phase angle component of the output voltage (rad),Vomndenotes the maximumnth harmonic voltage component (V), andβnis thenth harmonic phase angle component (rad).\n\nIn practice, especially at higher frequencies, the output voltage at the RC terminals varies in both magnitude and phase angle from the EMFs. This is brought about by the RC’s resistance (Rc), coil capacitance (Co), and self-inductive effect (Lc) [56]. As stated in [56], an external resistance was previously used at the RC terminals to properly dampen the high-frequency components in the induced EMF.\n\nIn this work, the coil stray capacitanceCois used as a substitute for the terminal resistance, as shown inFig 6(b). The rationale for this choice is to obtain an output voltage signal with significantly reduced very high-frequency (noise) components while minimizing the difference between the output and the induced voltages.\n\nThe self-induction, in combination with the coil stray capacitanceCo,acts as a second-order low-pass filter. This configuration enables more accurate digital processing, especially with a low sampling time. By using the coil stray capacitance in this manner, the output voltage waveform can be conditioned to better reflect the induced EMF, facilitating improved signal processing and analysis.\n\nThe performance of the RC can be verified through accurate modeling, which is an essential requirement. Such modeling approaches can be classified into three main categories: models based on frequency measurements [85], lumped models [86], and distributed models [87]. This work develops a simulation model to validate the measuring process using a lumped modeling approach. For this, the MATLAB Simulink tool is employed. Using equations (11) and (14): The RC is simulated in accordance with the lumped equivalent circuit depicted inFig 6(b).\n\nBy employing the lumped modeling technique, the behavior of the RC can be accurately represented and analyzed. This simulation-based validation ensures that the mathematical formulation and the underlying assumptions are sound, providing confidence in the measurement process and the subsequent analysis. Hence, the simulation is carried out as shown inFig 7.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g007\n\nSeveral RC simulators have been used to measure fundamental current values and harmonics, with parameters such asRc=  2.4 Ω,Lc=  1.2 mH,Co=  10.3 nF, andMc=  1.8 μH [88]. These parameters were used to measure fundamental current and low/high harmonics. A practical RC coil was designed and manufactured in [56] with several 235 turns,Rc=  0.3 Ω,Lc=  1.345 mH,Co=  67.569 pF, andMc=  35.975 nH. Decreasing turns and smaller core diameters increase performance and resonant frequency, making it more suitable for higher frequency measurements. Other RC coils have been modeled in [89,63]. The rectangular shape of the RC for high-sensitivity purposes was suggested in [89], withRc=  0.1922 Ω,Lc=  2.5 μH,Co=  41.21 pF,Mc=  4.6825 nH, and the resonant frequency of this coil is 3.4 MHz. In [63], which has 1900 turns and an outer and inner diameter of 109 and 101 mm, respectively. Based on these values, the parameters of the equivalent circuit wereRc=  63 Ω,Lc=  0.191 mH,Co=  51.6 pF, andMc=  300 nH. This means that the RC parameters can be optimized for different performance requirements, particularly relating to frequency response and sensitivity.\n\nVarious computation engines are used for reconstruction. First, reconstruction engines to measure high pulse current have been developed. The standard computing engine was implemented to reconstruct the input current of RCs using an analog integration circuit at the output terminals [90]. At low frequencies, this integral-based approach was used because RC circuits perform as differentiators. The RC circuit and its integration circuit worked together to produce a rebuilt signal of low magnitude, which resulted in low sensitivity. On the other hand, increasing the output signals also increases the noise signals, which presents a significant problem for high-frequency applications. In [91], the authors consider the RC design in its form of integration. However, this method was limited to high-frequency applications. As mentioned in [64], a calibration-based method has been presented to reconstruct the current of an RC by monitoring the coil’s output voltage for a specific pulse and dividing the maximum value of the transmitting and receiving pulses. This method yields a constant calibration coefficient of the output voltage. This calibration-based method does not reconstruct the entire frequency spectrum’s output voltage; rather, it just reconstructs the measured signal’s peak value. Computation engines have also been introduced to reconstruct the current of the RC in either domain of time or frequency. The time-domain engine employs implicit model-based numerical integration on samples of time-domain data. Even this, the engine is dependent on the coil’s physical structure and has a restricted verification range relative to the coil’s complete range. The inverse transfer function is the basis of the frequency-domain engine and plays a major role in determining its performance. Nevertheless, this engine’s precision is restricted to the designated frequency range [92].\n\nIn order to minimize the phase difference between the measured current and the associated terminal voltage, the integration circuit has been improved in the coil design based on the frequency response [93]. This coil’s performance has been compared to that of traditional current transformers for protective relay applications. It can be utilized for both protective and measurement devices in low-frequency applications [94]. DFT computation engine was introduced to reconstruct the fundamental AC component of the power frequency [56]. In [95], a differential computation engine was introduced to reconstruct the current. It is only appropriate for measuring the fundamental power component. A computational engine was introduced to reconstruct AC voltage with power frequency [96]. The proposed computational motor uses a low-capacity capacitor and a double-wound RC. This computational engine is based on measuring the capacitor’s current using the RC double wound. The voltage is reconstructed via the capacitor connected in parallel with the system at which the AC voltage is intended to be measured. A non-invasive design of the RC for measuring three-phase currents through a three-core cable was utilized in [97]. This design is characterized by no need to remove the insulation layers of the 3-core cable to measure its core currents. The certified RC design uses three separate coils wound in the same non-magnetic circular core with equal spacing between them. The three induced EMFs are used to reconstruct the current passing through each cable core using a current reconstruction (CR) technique based on the basic concepts of the RCs working theory. Three-phase motor currents passing through a three-core cable were measured using a dual-coil RC [98]. A dual-coil RC is mounted externally around a three-core cable without removing its insulation layers, reducing the measurement’s complexity. Dual coils were mounted around a non-magnetic circular core, taking 120° between the center points into account. The EMFs induced in each coil due to the magnetic flux linkage between the coils and cable cores are used to reconstruct three-phase motor currents through the cable cores. The cable currents were reconstructed using the reconstruction computational engine introduced in [97] and developed in [98].\n\nThe authors of this work employed a computational engine to reconstruct, particularly at high frequencies, keeping in mind the previously stated caution that the output voltage should not be measured instead of the induced EMF. Only low-frequency currents can be used to accept output voltage instead of generated electromagnetic force because of their slight differences and the minimal influence of RC circuit characteristics. Errors in the output voltage’s magnitude and phase angle relative to the induced EMF can cause major errors in the reconstructed current when dealing with high-frequency currents. As a result, the reconstruction technique is developed using the coil’s measurable characteristics as a basis [88].\n\nBy injecting a current of 1 A at various frequencies, from the fundamental value to the appropriate value for high-order harmonics, the measured characteristics of the coil can be determined. A calibrated current source is required for this technique to be carried out. The maximum output voltage value and the phase difference between the injected current and the output voltage waveforms (ϕc,θc) are recorded at each frequency. Recursive DFT analysis is used to determine the maximum value and phase angle of the output voltage’s fundamental and harmonic components up to the required frequency. The output voltage is monitored at the RC terminals, as depicted inFig 8. This is accomplished by adding the phase error of the measured characteristics to the phase angle at the corresponding frequencies and dividing the maximum value of each component by the maximum value recorded at the frequency corresponding to the measured coil characteristics. Once each frequency component’s maximum value and phase angle have been determined, a sine waveform can be constructed for each component. The total reconstructed current waveform can be obtained by summing these individual sine waveforms. This approach allows for the reconstruction of the input current waveform by analyzing the output voltage measured at the RC terminals, considering the measured characteristics of the coil, and using a recursive DFT to extract the individual frequency components and their corresponding phases, whereEpndenotes the peak value of induced the EMF at the order of thenth harmonics;θndenotes the phase angle at force at the order of thenth harmonics;Ipndenotes the peak value of CR at the order of thenth harmonics;Epndenotes the peak value of induced electromotive force at thenth harmonics;Epncdenotes the peak value of measured coil characteristic at thenth harmonics;θcndenotes the corrected phase angle at the order of thenth harmonics;θerror_ndenotes the phase angle error at thenth harmonics;Epfdenotes the peak value of induced electromotive force at the fundamental harmonic;θfdenotes the phase angle at force at the fundamental harmonic;Ipfdenotes the peak value of CR at the fundamental harmonic;Epfdenotes the peak value of induced electromotive force at the fundamental harmonic;Epfcdenotes the peak value of measured coil characteristic at the fundamental harmonic;θcfdenotes the corrected phase angle at the fundamental harmonic; and theθerror_fdenotes the phase angle error at the fundamental harmonic.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g008\n\nThe power system voltage phases, current waveforms, and their harmonics are tracked over time using the Kalman filter [99]. The Kalman filter is based on a state space method, where the measurement (observation) equation of noisy observation signal models is modeled by the state equation, which also models the dynamics of the signal process. If a current signalif(t) with amplitudeA, frequencyω0,θphase shift, DC decay of the amplitude denoted byB, and a time constant τ, then it can be written as follows:\n\nwherex1=Asin(θ),x2=Acos(θ), andx3=B.\n\nThe input signal can be described as follows:\n\nThe equation of measurement includes both signal and noise as follows:\n\nwherevkis the error due to noise or unmodeled harmonics.\n\nThis Kalman filter is only appropriate for the input signal specified in (15), presented in (16) and (17). The above state equations are solved using the steps in [99], to apply the Kalman filter approach. The samples available up to timekare used to predict the state. This is often stated as a linear combination of the innovation signal inkand the prediction based on samples available up tok-1. For their precise applications, like the initialization procedure vector, noise variation, and state variable covariance matrix, the characterization of state space equations and the choice of Kalman parameters are crucial challenges.\n\nThe combination of the collected trail curve of the measured samples taken at uniformly dispersed points at the appropriate time throughout a specific time window serves as the basis for the computational engine known as the least square (LS) for calculating the electrical phasors [100]. Compared to orthogonal algorithms, LS has the benefit of replicating periodic harmonic contents along with unknown fading parameters. The unknown time samples can be expressed as a function of time in the manner that follows given thenth harmonics:\n\nTaylor series can be used and expressed in the exponential partas follows:\n\nThe Taylor series terms are only taken into consideration for the first three terms, and therefore equation (18) is rewritten as follows:\n\nUsing a predetermined window length, with known samplemprofiles, is determined for the signal as follows:\n\nwherea11,a22, …. are calculated based on the known constants of (16), whilex1,x2, … are the unknown vector [x] to be estimated and are calculated for each sample as follows:\n\nThese estimated unknowns can be used to calculate the magnitudes and angles corresponding to the specified harmonics and the associated DC component.\n\nThe fundamental component of fault current signal samplesIf[K] can be extracted by applying a full-cycle DFT filter in its non-repeat form [101] according to the following formulas:\n\nwhereSandCare the sine and cosine terms of the phasor andnis the sliding number over the sampling of the discrete windows of the current with the size of the window of samplesN.θis the sampling angle equal to2π/N. The magnitude of the peak valueIf[K] is given by:\n\nDFT is a relationship between a current sliding window and a base function window, where each window hasNset to 200 samples, as depicted inFig 9. Although the error in non-recursive DFT is fixed, its output angle is rotated, as the traditional window mechanism inFig 9(a).\n\n(a)Commonly used sliding signal window, and (b) the sliding window for non-recursive DFT [56].\n\n(a)Commonly used sliding signal window, and (b) the sliding window for non-recursive DFT [56].\n\nhttps://doi.org/10.1371/journal.pone.0320125.g009\n\nThis behavior is achieved by rotating the window in advance before loading the new sample and considering that the same window uses the primary function at each step whose time reference is shifted by a time step when the signal window slides (or is updated by the new sample). Accordingly, this shift time produces an angle shiftΔθ =  2π/N, as reported in [102], resulting in a non-stationary output phasor. A stationary non-recursive DFT is introduced to achieve non-rotated angle measurement, as shown inFig 9(b). The signal window is updated by a new sample at each step, and the old sample is removed to keep the window size constant. A stationary phase angle can be attained by rotating the base function vector to achieve a base function with a fixed reference. Based on the method described above, further computations are required to rotate the base function or rotate the signal window. This is achieved by rotating the position of the new sample within the signal window. Specifically, the position of the new sample is not fixed at the first sample position as in traditional approaches. Instead, it gradually changes with each new sample, as shown inFig 9(b). This rotating sample position idea saves computational time compared to the traditional approach of performing a full window rotation before loading new samples. In order to evaluate the engine, extensive tests are performed using computer simulation through the use of MATLAB simulation software, and the algorithm’s response to the fault current signal is recorded. However, for real-time evaluation, experimental tests of engines or relays are usually performed in the laboratory using the flexibility of digital computer simulations, as recently recommended by the IEEE committee. In this simulation, the current-wave forms and voltages taken from a computer simulation or digital fault recorder are converted into analog signals, amplified and then fed by tested hardware. This procedure would overcome the difficulties involved in fault tests that are impossible to perform on a real power system. The preparation of laboratory tests is described in the next section.\n\nThe laboratory setup mainly consists of a DSP DS1003 board compatible with DS2201 multiplex board 110, as schematically shown inFig 10. The DS1003 board is based on the floating-point DSP TMS320C40 Texas Instruments. The DS2201 facilitates interaction with the real system through 20 simultaneous analog input channels (distributed over 5 A/D switches), 8 analog output channels (distributed over 2 D/A switches), and 16-bit general-purpose 110-port ports. A personal computer (PC), was used as a host device for storing and downloading the software program. It also makes it easy to monitor and plot specific variables in real time using TRACE software. Non-recurring DFT is created depending on equations (23–25), considering the instructions for the DS 1003 software environment. In which. A high-level language develops the corresponding engine. Then. The software is compiled using Texas InstrumentsTMS320C40C-compiler/Assembler/Linker and then downloaded to DS 1003 Local and Global Memories. Below is a brief description of the main parts of the implemented algorithm\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g010\n\nThe key parts of the executed real-time engine are the offline and online portions.\n\nOne or all estimation engines can be enabled to evaluate the response in a comparative way\n\nThe mathematical cores of the selected computational engine methods for detecting HIFs were constructed in MATLAB. Several fault scenarios were simulated in the simulation system to validate the effectiveness and reliability of the best-performing engine among the selected options under HIF conditions. The following illustrations showed the results when a fault occurred between buses 9–10 (at 865 m), as depicted inFig 5. The prepared test investigated the performance of each engine, including the numerical arcing model and the numerical long arc model depicted inFig 3. To visualize the performance of the selected engines, the profile of the estimated fundamental and different harmonic components of the fault current for each engine was characterized and compared with the recursive DFT approach already implemented in the protection relay mounted at the primary substation, as depicted inFig 5. This comparative analysis allowed for the evaluation of the selected computational engines against the established recursive DFT method used in the existing protection system.\n\nThe fault point voltage is shown inFig 11(a). The waveform is close to the square waveform. Accordingly, the fault point is a source of the third harmonic. Therefore, it is considered the feature extraction of the HIF case. Although it is not obvious in the voltage waveform at the measuring point, as shown inFig 11(b). However, the harmonics due to the event of the fault are inherent in the measured waveforms, as evaluated in the following results.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g011\n\nIn the first computational engine (current reconstruction), utilizing a numerical arc model, the different lumped parameters of the coils were implemented to obtain the best performance, as mentioned earlier. The parameters in this paper were selected, and the best results were given in [63], which indicates a high resonant frequency of 29 MHz. When a HIF is introduced using the numerical arc model at 0.02 seconds,Fig 12shows large variations in the estimated fundamental, 2nd, 3rd, and 4th harmonic-order components of the utilized CR-based engine compared to the estimates of the same components using the recursive DFT approach. This variation is detected after one cycle when all components reach their peak values, which is used to detect the HIF. To provide a greater verification range for the efficiency of the selected computational engines, they were tested to calculate many harmonics up to the 20th order. This was done due to the exposure of distribution networks to nonlinear loads, such asn-pulse rectifier circuits or rectifiers, IGBT inverters, and capacitors in the distribution networks to improve the power factor. These capacitors carry out separation and connection operations during maintenance or faults. Additionally, the network contains loads such as induction motors that draw high currents, and the network is also exposed to the separation and connection operations of normal loads and changes in load levels (decrease or increase).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g012\n\nSimilarly, as shown inFigs 13–16for the different harmonic orders investigated, the CR-based engine exhibited large variations in the estimated 5thto 20thharmonic order components of the fault current, compared to the recursive DFT approach. This comprehensive evaluation of harmonic components up to the 20th order further demonstrates the CR engine’s enhanced performance and detection capabilities under HIF conditions, where distribution networks are exposed to various nonlinear loads and operational scenarios.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g013\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g014\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g015\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g016\n\nThe second computational engine, the Kalman filter, utilizing the same numerical arc model, demonstrates the performance depicted inFig 17. Compared to the recursive DFT approach, the Kalman filter performance exhibits relatively small variation in the estimated fundamental frequency as well as the 2ndto 4thharmonic-order components. However, as shown inFigs 18–21>> for the different harmonic orders investigated, the Kalman filter exhibits large variations in the estimated 5thto 20thharmonic-order components of the fault current compared to the recursive DFT. Additionally, the Kalman filter’s performance is not optimal initially, as it provides incorrect results during the first cycle and struggles to track the decreasing fault current rate accurately.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g017\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g018\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g019\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g020\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g021\n\nThe third computational engine, the LS method, uses the same numerical arc model and offers good results in estimating the fundamental component. However, it does not perform equally well in calculating the 2ndto 4thharmonic-order components, as shown inFig 22. Similarly, as illustrated inFigs 23–26for the different harmonic orders investigated, the LS method exhibits large variations in the estimated 5thto 20thharmonic-order components of the fault current compared to the recursive DFT approach. This indicates that while the LS method performs well in estimating the fundamental component, it struggles to accurately capture the fault current’s higher-order harmonic content, which is crucial for robust HIF detection and classification.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g022\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g023\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g024\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g025\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g026\n\nThe fourth computational engine, the non-recursive DFT, uses the same numerical arc model and provides accurate results in estimating the fundamental component as well as the 2ndto 4thharmonic-order components, as shown inFig 27. Similarly, as illustrated inFigs 28–31for the different harmonic orders investigated, the non-recursive DFT approach exhibits precise results for the estimated 5thto 20thharmonic-order components of the fault current. This comprehensive evaluation demonstrates the superior performance of the non-recursive DFT computational engine in accurately estimating a wide range of harmonic components, which is crucial for effective HIF detection and characterization in distribution networks with diverse nonlinear loads and operating conditions.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g027\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g028\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g029\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g030\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g031\n\nThe analysis shows that using a non-recursive DFT reconstruction engine achieved accurate estimates of the fundamental and harmonic components up to the 20thorder. This engine demonstrated the best performance compared to the other computational approaches evaluated, such as the Kalman filter and LS methods. Based on these findings, the paper proposes the non-recursive DFT computational engine as an excellent approach for effective HIF detection and characterization in distribution networks. While the paper focused on testing the various computational engines using the numerical long arc model, the details of this model were not presented in the current paper. However, the authors note that all the computational engines were evaluated using this common numerical arc model as the basis for the analysis.\n\nIn this study, we evaluated the performance of several computational engines for detecting high-impedance faults (HIFs) in power distribution networks, with particular emphasis on numerical discrepancies in their effectiveness. Methods under comparison include non-recursive discrete Fourier transform (DFT), current reconstruction (CR) using Rogowski coils, Kalman filtration, and least squared computational motors\n\nThe proposed non-recursive DFT method showed a clear advantage in terms of efficiency and computational accuracy. By using a fixed error in calculating capacity, it provides consistent results across different conditions. Numerical simulations revealed that this method maintains a lower error rate in estimating both basic and harmonic amplitudes compared to conventional iterative techniques. This stability is critical during transient conditions, where traditional methods often struggle with fluctuations.\n\nThe current reconstruction method, although effective in many scenarios, showed insignificant numerical variation under different fault conditions. Simulation tests indicated that this approach is sensitive to the placement of Rogowski coils and ambient environmental factors, such as humidity and temperature. The model performance indicated a small percentage of errors in amplitude estimation, especially during active HIF conditions. This insensitivity can lead to consistency in fault detection, making it competitive and reliable compared with the proposed non-recurring DFT approach.\n\nKalman’s filtering provided a powerful framework for estimating system states, but the accuracy of initial conditions and model parameters heavily influenced its numerical performance. In scenarios with high noise levels, Kalman’s filter struggled to converge with real fault current values, resulting in greater estimation errors. Simulations have highlighted that while the filter can adapt over time, initial numerical estimates often have small skew results, particularly in transient fault conditions.\n\nThe least squares engine, although widely used for various signal processing applications, showed limitations in capturing the dynamic behavior of HIFs. Numerical assessments revealed that this technique tends to average the critical transient characteristics of fault signals, resulting in a higher overall error in the amplitude estimate. The comparative analysis indicated that although it is computationally less dense, it has less accuracy, especially in environments with rapidly changing fault conditions.\n\nNumerical differences between methods emphasize the importance of choosing a suitable engine for detecting HIF in power distribution networks. The non-recurring DFT method not only outperformed other methods in terms of accuracy and stability but also provided a more reliable solution under various fault conditions. In summary, the non-recursive DFT reconstruction engine emerged as the superior approach for harmonic estimation and HIF detection, providing a promising solution for addressing the challenges associated with HIFs in modern distribution systems.\n\nMoreover, the noise impact on the suggested engine must be evaluated. Therefore, the recorded fault signals captured in the proposed engine are contaminated with white Gaussian noise, with a signal-to-noise ratio of 30–60 dB, as depicted inFigs 32–36for the different harmonic orders investigated, utilizing the non-recursive DFT-based engine.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g032\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g033\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g034\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g035\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.g036\n\nThe results suggest that while noise introduces a certain level of distortion, its effect remains relatively small, particularly in the amplitude of signal calculated utilizing the proposed engine, as shown in Figs 32-36. The signal-to-noise ratio (SNR) refers to the preservation of the essential features of the signal despite the presence of noise, highlighting the durability of the proposed engine against minor disturbances. This flexibility is critical for applications that require precise signal processing, as it ensures that essential information remains\n\nThe proposed non-recursive DFT reconstruction engine is further validated by comparing its performance against the existing computational approaches, such as the current reconstruction, Kalman filter, and LS engines. This comparative assessment evaluates the percentage error between the reference current (obtained from the recursive DFT method) and the estimated current generated by each computational engine under consideration. The percentage error is calculated using equation (24), whereIris the reference current’s peak, andIeis the peak of the estimated current.Table 1presents the fundamental and harmonics measurement errors for all computational engines investigated.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.t001\n\nAs shown inTable 1, The CR engine exhibits a maximum error of 1.971% at the 19thharmonic order. The Kalman filter engine performs better, with a maximum error of 7.4874% at the 8thharmonic order. The LS engine demonstrates the worst performance, with a maximum error of -102.48% at the 20thharmonic order.\n\nIn contrast, using the recursive and the proposed non-recursive DFT accurately tracks the reference currents measured. As presented in the table, the errors are significantly low, with a maximum value of only 0.58415% at the 9th harmonic order. This comprehensive comparative analysis conclusively demonstrates the proposed non-recursive DFT engine’s superior performance in estimating the fundamental and harmonic components of the fault current, outperforming existing computational approaches like current reconstruction, Kalman filter, and LS methods.\n\nThe techniques discussed previously include the ML classifiers (ANN, artificial neural network; SVM, support vector machines; FLC, fuzzy logic controllers; ANFIS, adaptive neuro-fuzzy inference system; DTs, decision trees; GPR, Gaussian process regression; and others), the provided measurement signals, and feature extraction methods. All possess distinctive capabilities for the detection (DT), classification (CS), and localization (LT) of HIFs. Building upon this foundation, a comparative analysis is presented inTable 2. The comparison is based on using accuracy as a metric for the performance evaluation of these techniques. Additionally, security (S) and dependability (D) considerations are investigated, which can be quantified through the accuracy ratio of HIF fault diagnosis, an aspect often overlooked in the existing literature. Furthermore, the selected and proposed computational engines are also analyzed using these criteria.Table 2indicates that the proposed non-destructive DFT approach could offer advantages in terms of data acquisition and processing compared to other techniques. The proposed method achieves an accuracy of 99.61%, among the highest values reported in the table. This high accuracy level indicates the effectiveness of the proposed technique in accurately detecting and classifying HIFs. The proposed method’s security and dependability are reported as 99.61%. These high values suggest that the proposed technique provides a robust and reliable solution for HIF detection, with a low risk of misdiagnosis or security vulnerabilities. This means that the use of a non-destructive DFT approach in the proposed method may offer several advantages, such as reduced impact on the power system during data acquisition, as non-destructive techniques typically have minimal interference, improved computational efficiency and real-time processing capabilities, as DFT-based analyses can be optimized for faster execution, and potential for integration with existing power system monitoring and control infrastructure, leveraging the widespread use of DFT-based techniques in the industry.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320125.t002\n\nA novel computational engine using a non-recursive DFT approach was presented to measure AC currents’ fundamental and high-order harmonic components accurately. This capability is crucial for effectively modeling and detecting HIFs in power distribution networks. The paper first discussed and evaluated different HIF modeling techniques, selecting the most suitable approaches for further analysis. A selected technique, the CR engine, was implemented in MATLAB/Simulink for comparative assessment. A specialized coil sensor was also developed to assess power-frequency distorted currents with low-order and high-order harmonics. Three computational engines, the CR, Kalman Filter, and LS methods, were then utilized for comparative evaluation. All the computational engines, including the proposed non-recursive DFT approach, were implemented and evaluated using MATLAB/Simulink. The simulation study focused on measuring HIF conditions in the first section of the selected power system, which represents the most challenging scenario due to the varying power ratings at the feeder origin. The comparative analysis conclusively demonstrated the proposed Non-recursive DFT engine’s superior performance. It exhibited the lowest percentage error between the reference current (from the recursive DFT) and the estimated current, outperforming the existing computational approaches like CR, Kalman Filter, and LS methods.\n\nFurthermore, the proposed non-recursive DFT engine’s efficacy was validated against recently published HIF detection and characterization techniques, further corroborating its effectiveness in accurately estimating fault currents’ fundamental and harmonic components. Finally, the presented Non-recursive DFT computational engine provides a robust and reliable solution for HIF modelling, detection, and characterization in power distribution networks, with significant performance improvements over several state-of-the-art methods. The suggested computation engine has a wide range of consequences for fault detection. In addition to improving safety and compliance, they also result in significant cost savings and higher operational effectiveness.\n\nThis paper makes several important contributions to the field of high-impedance fault detection in power distribution networks:\n\nAddressing these limitations through targeted research and development will enhance the durability and applicability of non-recurring DFT technology for high-impedance fault detection, ultimately contributing to safer and more reliable power distribution networks.\n\nLine impedance and load power”.\n\nhttps://doi.org/10.1371/journal.pone.0320125.s001\n\n(DOCX)",
    "category": "mathematics"
  },
  {
    "title": "Development and validation of a measure of concrete and abstract thinking",
    "authors": "Hjördis Lorenz, Esther Beierl, Gabriella Tyson, Jennifer Wild, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320009",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320009",
    "content": "Abstract-analytical thinking, which characterizes rumination and worry, has been shown to be a risk and maintenance factor for psychological disorders, yet there are no accessible, reliable measures that can be easily administered to assess this cognitive process. Student paramedics are at elevated risk of developing mental health difficulties associated with rumination and worry due to the nature of their work. The current study describes the development and validation of the Concrete and Abstract Thinking measure (CAT) in a sample of student paramedics. The scenario-based CAT measure was systematically developed. An initial pool of scenarios was generated based on previous research and the Worry Domains Questionnaire. A total of 14 paramedics, inclusive of student paramedics, evaluated the content of the scenarios. Final items were determined based on best-fit using confirmatory factor analysis. Two-hundred student paramedics completed the CAT measure and associated measures and 96.6% completed it again for test-retest reliability. Abstract items of the CAT measure showed good internal consistency (α=.87), test-retest reliability (ICC = .88) and good factorial, construct and criterion validity. The CAT measure was significantly associated with measures of perseverative thinking (r= .52), rumination (r= .42), worry (r= .50), depression (r= .32), anxiety (r= .41), posttraumatic stress disorder (r= .23), self-efficacy (r= -.32) and resilience (r= -.30). Overall, the CAT measure showed robust psychometric properties, evidencing good validity and reliability. The CAT measure offers a user-friendly, valid, reliable and population-specific measure of concrete and abstract thinking whilst also providing a model of how abstract thinking could be assessed in a range of populations at risk of developing mental health disorders.\n\nCitation:Lorenz H, Beierl E, Tyson G, Wild J (2025) Development and validation of a measure of concrete and abstract thinking. PLoS ONE 20(4):\n           e0320009.\n        \n        https://doi.org/10.1371/journal.pone.0320009\n\nEditor:Runtang Meng, Hangzhou Normal University, CHINA\n\nReceived:November 17, 2022;Accepted:February 12, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Lorenz et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data cannot be shared publicly because it contains sensitive patient information and consent to publicly share this data (even as de-identified or anonymized data) was not provided by participants. Data can be provided upon reasonable request by contacting the University of Oxford Medical Science Division's research ethics committee atethics@medsci.ox.ac.ukThis is in line with the requirements and approvals set out by the Medical Sciences Inter-Divisional Research Ethics Committee at the University of Oxford.\n\nFunding:Funding for the current study was awarded to HL by The Colt Foundation () and to JW by the Wellcome Trust () (grant number 00070). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nRumination and worry are cognitive processes linked to distressing emotions [1–4]. Rumination, defined as repetitive negative thinking about past experiences, maintains low mood [e.g.5,6] and predicts the onset and persistence of posttraumatic stress disorder (PTSD; [1,3,7], whereas worry, repetitively thinking about potential negative events, has been linked to anxiety [e.g.8]. For populations at elevated risk of developing mental health disorders, such as students [9–11], paramedics [12–15], or student paramedics (paramedics in training), ruminative thinking has been tied to the onset and development of depression, anxiety and PTSD [7,16,17]. Research has identified abstract-analytical thinking as a core cognitive feature of rumination and worry that links to mental health problems [18–21]. It is associated with a concurrent reduction in concrete-experiential thinking [22,23]. There is a paucity of research on specific features of rumination, such as abstract thinking, that increase risk for mental ill health. One of the challenges impeding investigation is the lack of accessible, reliable and valid measures of abstract and concrete thinking that could be easily administered to at-risk populations. For paramedics, such a measure could facilitate the early identification of risk factors likely to increase psychopathology over the course of their careers. Assessing features of rumination could provide a better understanding of targets for intervention, and could be used during the course of treatment to evaluate changes in relevant cognitive processes. This paper describes the development and validation of a measure of concrete and abstract thinking (CAT) for student paramedics\n\nAbstract-analytical thinking is a mode of cognitive processing characterized by over-general thoughts of overall meaning as well as ‘why?’ and ‘what if?’ questions with no obvious answer. Abstract thinking often focuses on causes, meanings and consequences [24], and may include thoughts, such as “why is this always happening to me?” or “what if I never get over this?”. Concrete-experiential thinking, on the other hand, focuses on how an event is happening, on direct experience, and on means to desired ends (e.g., steps needed to achieve a goal) with ‘how?’ and ‘what?’ questions [25], such as “how can I learn from this?”, “what can I do next?”. Concrete-experiential thinking has been associated with adaptive psychological coping, including improved mood [26], better problem solving ability [27] and proactive behavior [28]. Concrete thinking may also relate to general resilience and self-efficacy, although this is yet to be tested.\n\nStudies have highlighted the association between anxiety-related worry and abstract thinking. Worries described in a clinical sample with generalized anxiety disorder (GAD) were more abstract than those of a non-clinical control group, and became significantly more concrete after cognitive behavioral therapy [19]. Abstract thinking has also been explored in relation to depressive rumination [27,29], whilst concrete thinking has been the focus of some forms of successful treatment for depression and anxiety [30,31]. Initial research has linked abstract thinking to PTSD where specific features of rumination, including ‘why’ and ‘what if’ questions appear to predict PTSD beyond trauma history [32] and beyond rumination alone [18]. Abstract processing during an analogue trauma film increased rumination [33] and abstract thinking after a trauma analogue film led to a significantly longer maintenance of negative mood and arousal, compared to concrete thinking or distraction [34]. Overall, research on abstract thinking is still in its infancy and is held back by a lack of user-friendly, psychometrically sound measures, as detailed below.\n\nThe majority of studies that assess the abstractness or concreteness of specific thoughts have administered theProblem Elaboration Questionnaire[PEQ,19]. Although the PEQ is validated and widely used, it has a number of limitations. First, the PEQ instructs participants to elaborate on two problems they are currently worried about. This wording may directly encourage participants to worry and may thereby induce a more abstract focus, thus biasing responses towards abstract content. Second, since no word or time limit is given, elaborations may vary greatly in length which again may influence scoring. One-word or short answers may bias towards abstract scoring when they could simply be a representation of writing preferences. Third, applying a 5-point scale with only two anchors at the extreme ends heightens subjectivity in scoring, as individuals could differ in their understanding of scale-points 2, 3, and 4 when these are not labelled. Fourth, the definitions of concrete and abstract thinking used in the PEQ differ from definitions adopted in more current research [e.g.,20], which may limit the comparability of results. Finally, the questionnaire can be lengthy to administer and score, as individuals need to type out responses instead of ticking multiple choice options, and scoring needs to be done by hand instead of receiving an automatic sum score. As length can add to questionnaire burden for users, and limit use for busy practitioners, this is a limitation to consider.\n\nA few studies have assessed concrete and abstract thinking using other measures, however, with considerable limitations related to the use of different definitions of abstract thinking [35], unstable factorial validity [36] or measures not validated or published in English [22,37]. Some studies asked participants to self-identify abstract or concrete thoughts [38] with items such as “my dwelling is usually very abstract” [39]. These two measures put the responsibility of understanding and identifying the concept of abstract thinking solely on participants which may increase the risk of inaccuracies and social desirability bias [40].\n\nIn summary, existing measures of abstract and concrete thinking demonstrate a number of limitations including a biased wording towards inducing worry, scoring impacted by participants’ elaboration preference, potential subjectivity in scoring, varying definitions of abstract thinking, lengthy completion time, unpublished and unvalidated measures or reliance on participants to self-identify abstract thinking.\n\nTheConcrete and Abstract Thinking measure (CAT)was developed as a scenario-based measure that includes an assessment of abstract and concrete thoughts associated with each scenario. Scenarios were chosen to address the PEQ’s limitations surrounding variations in the length of elaboration for each question, subjectivity in scoring, and differences in completion time. An initial pool of scenarios was generated, drawing on previous research of the Worry Domains Questionnaire [41,42] and examples of concrete and abstract thinking provided in published literature [20,43]. The CAT scenarios differed from previous research [41,42] in that they did not ask participants to describe a worry scenario but rather presented participants with a difficult situation likely to occur at university (e.g., submitting an essay late) or in paramedic work (e.g., trying to intervene with a patient in cardiac arrest), whichcouldtrigger worry or rumination. These initial scenarios were evaluated by 16 student and qualified paramedics and rated on a scale from 0–100% on how realistic they were and how likely they would be to cause individuals to worry or ruminate. If scenarios were rated as less than 60% realistic, they were replaced with new scenarios proposed by the paramedics and re-evaluated.\n\nFour abstract and four concrete thought responses (items) were provided for each scenario. This was designed to address previous limitations associated with social desirability bias and participants’ conceptual understanding of abstract and concrete thinking. That is, unlike previous research, there was no expectation for individuals to identify whether or not their thoughts were concrete or abstract. The concrete and abstract thoughts for each scenario were developed in collaboration with a Clinical Psychologist, a User Advisory Group, consisting of four paramedics including student paramedics, and were based on existing research. Each scenario has 8 thought responses, four of them abstract, four of them concrete. Participants are instructed to indicate (yes/no) whether they would experience each response if they were in the scenario. The final score is calculated as the overallratioof abstract to concrete thoughts for each scenario by dividing the number of abstract responses endorsed by the number of concrete responses endorsed, to give an indication of whether participants thoughtmoreconcretely ormoreabstractly.\n\nAs part of the validation, 16 scenarios were developed (8 related to paramedic work and 8 to university work). Confirmatory factor analysis was applied to determine the scenarios and to shorten the questionnaire. Confirmatory factor analysis of the original 16 scenarios led to a two-factor model. Four scenarios were selected based on factorial validity, construct and criterion validity, as well as theoretical and clinical considerations, to create the final CAT measure, resulting in two scenarios related to paramedic work and two related to university work. SeeS1 Measurefor the final CAT items.\n\nThe aims of the present study were to (1) assess the psychometric properties of the CAT measure including construct and criterion validity and to (2) investigate the relationship between the CAT measure and related concepts of worry, rumination and repetitive negative thinking, as well as measures of psychopathology (generalized anxiety disorder, depression, PTSD), self-efficacy and resilience. It was hypothesized that abstract thinking, as measured by the CAT measure, would be positively associated with measures of abstract thinking, repetitive negative thinking, worry, rumination, generalized anxiety disorder (GAD), depression and PTSD and negatively correlated with self-efficacy and resilience.\n\nAll participants were British student paramedics completing a 3-year Bachelor in Paramedic Science. Recommendations for factor analyses [44] suggest recruiting a sample size that includes 10 times as many participants as measure items. For 16 original scenarios, and adjusting for a potential 20% rate of attrition, we aimed to recruit 200 participants. The final sample included N = 205 student paramedics from 15 universities with an age range of 18–54 (M= 24.91,SD= 6.77). The majority were female (62.0%; 38% male) and White British (92.19%). Other ethnicities included 1.46% White Irish, 1.95% Eastern European, 1.95% another White Background, 0.49% Caribbean, 0.98% White and Asian, and 0.98% White and Black Caribbean. The socially constructed groupings of age, gender, and ethnicity were categorized in line with standardized recommendations by the Medical Sciences Inter-Divisional Research Ethics Committee at the University of Oxford. Age allowed for an open response of any number, gender included the options “male”, “female”, “other” and “prefer not to say,” and ethnicity provided a selection of 18 options as well as an open response option related to “other background.” The authors thereby had access to identifying information of participants during data collection. All identifiable information was stored separately to outcome data. All outcome data was anonymized immediately after data collection for analysis. A sample of 205 participants completed the set of questionnaires at time point 1 and 198 participants (96.6%) completed the questionnaires again at time point 2, two weeks later, in line with recommendations for health measurement scales [45]. The seven participants who dropped out from the first to the second time point could not be reached.\n\nThe CAT measure, as described above, was used and is the focus of this study. The current study calculated the overallratioof abstract to concrete thoughts for each scenario by dividing the number of abstract responses endorsed by the number of endorsed concrete responses, to give an indication of whether participants thoughtmoreconcretely ormoreabstractly. This will be referred to as the ‘abstract ratio’ with higher scores indicating greater abstractness.\n\nThe Problem Elaboration Questionnaire[19], described above, was used. The PEQ instructs participants to elaborate on two problems they are ‘currently worried about’ as well as on ‘three potential negative consequences’ for each problem. These elaborations are scored for concreteness using Stöber’s 5-point concreteness rating scale [46], with scores from 1–5 for each problem/consequence. Abstract thinking is defined as ‘indistinct, cross-situational, equivocal, unclear, aggregated’ and concrete thinking as ‘distinct, situationally specific, unequivocal, clear, singular.’ A total concreteness score for major worries/problems was calculated. In the present sample, a random 10% of the PEQ was scored by a second, independent rater (GT). This showed good inter-rater reliability: problem elaboration ICC = .80,p< .001, 95% CI [.49,.92] and consequence elaboration ICC = .81p< .001, 95% CI [.53,.93].\n\nThePerseverative Thinking Questionnaire[PTQ,47] is a 15-item measure of repetitive thinking independent of disorder, covering worry and rumination. Items are rated on a scale from 0 =neverto 4 =almost always,leading to a range of scores from 0–60. The PTQ has high internal consistency α=.93-.95, acceptable test-retest reliabilityr= .69-.75 [47], and good predictive validity for symptom levels of anxiety and depression [48]. For the present sample, Cronbach’s alpha was α=.96.\n\nThePenn State Worry Questionnaire[PSWQ,49] is a 16-item self-report questionnaire to assess worry which demonstrates excellent internal consistency (α=.93) and test-retest reliabilityr= .92. Questions are scored from 1–5 with 1 =not at all typical of meand 5=  very typical of me, with total scores ranging from 16–80. For the present sample, Cronbach’s alpha was α=.92.\n\nTheRuminative Response Scale[RRS,50] is divided into two subscales: brooding and reflective pondering. In the current study, only the 5-item brooding subscale was used which had adequate internal consistency, α=.77, and test-retest reliability,r= .62 [50]. Scores are rated from 1–4 with 1 =almost neverto 4 =almost always, leading to a range of scores from 5–20. For the present sample, Cronbach’s alpha was α=.78.\n\nTheGeneralized Anxiety Disorder Scale[GAD-7,51] is a 7-item questionnaire assessing the frequency of generalized anxiety symptoms over the previous week. Scores range from 0 =not at all to3 =nearly every day, with a range from 0–21. The GAD-7 showed excellent internal consistency (α=.92) and good test-retest reliability (ICC = .83). For the present sample, Cronbach’s alpha was α=.91.\n\nThePatient Health Questionnaire[PHQ-9,52] is a 9-item self-report questionnaire based on the DSM-IV [53] criteria for depression and assesses symptoms of low mood over the previous two weeks. Scores range from 0 =not at allto 3 =nearly every day, with a range of total scores from 0–27. Kroenke and team reported good internal reliability (α=.89) and test-retest reliability with a kappa of .84 after 48 hours. For the present sample, Cronbach’s alpha was α=.85.\n\nThePTSD Checklist for DSM-5[PCL-5,54] is a 20-item measure of PTSD symptoms directly corresponding to the DSM-5 PTSD criteria [55]. Symptoms are rated on a scale from 0 =not at allto 4 =extremely, with a range of 0–80. Psychometric evaluation of the PCL-5 with university students exposed to trauma showed excellent internal consistency (α=.94), and test-retest reliability (r= .82) [54]. For the present sample, Cronbach’s alpha was α=.95.\n\nTo better understand abstract thinking related to mental health and wellbeing, measures of resilience were included. TheGeneral Self-Efficacy Scale[56] is a 10-item scale that assesses the capacity to be self-reliant and effective in problem-solving. Items are rated on a1 = not at all trueto4 =  exactly truescale with total scores ranging from 10 to 40. The GSE demonstrates good internal reliability (Cronbach’s alphas α=.76-.90). It has been shown to correlate with measures of optimism and work satisfaction, and to negatively correlate with depression, stress, health complaints, burnout, and anxiety. For the present sample, Cronbach’s alpha was α=.84.Resilience. The Resilience Scale [57] is a 25-item measure of resilience with good internal consistency (α=.91) in an elderly, non-clinical sample. Items range from 0 =not true at allto 4 =true nearly all the time, with a total score range from 0–100. Test-retest reliability was assessed in a study of pregnant and postpartum women [58] as cited by [57] and ranged fromr= .67 to.84. For the present sample, Cronbach’s alpha was excellent, α=.94. TheConnor-Davidson Resilience Scale[CD-RISC,59] is a 25-item measure of resilience with good reliability and validity. Internal consistency was high with Cronbach’s α=.89 and test-retest reliability, ICC = .87, in a clinical sample with PTSD and GAD. For the present sample, Cronbach’s alpha was α=.91.\n\nThe Medical Sciences Inter-Divisional Research Ethics Committee at the University of Oxford granted approval for the study (R57540/RE002). Participants were recruited between September 2018 and January 2019. A criterion sampling method was applied which included any British student paramedics. This was deemed suitable as courses are highly regulated in their content by the UK’s National Health Service (NHS) and therefore offer similar training. Invitations to participate were emailed to 11 paramedic university courses. Some universities passed on the invitation to 4 further partnering UK paramedic courses (snowball sampling method). This led to student paramedics from 15 universities consenting to participate based on voluntary interest without a pre-determined number of participants per university. The only inclusion criteria was current enrollment in a UK paramedic course. Written informed consent was given by all participants. Participants completed an approximately 30-minute online set of questionnaires using Qualtrics software at time point 1 and two weeks later at time point 2. Upon completion of the second set of questionnaires, participants received a £20 Amazon voucher. All data were collected in 2018–19 before the Covid-19 pandemic.\n\nAnalyses were conducted using SPSS [Version 25,60], the R ‘lavaan’ package [Version: 0.6–3, [61] and Rstudio [Version 1.1.463,62]. Data are available upon individual request.\n\nTo help establish factorial validity of the four scenarios to be used in the CAT measure, confirmatory factor analyses (CFAs) were conducted for each of the 16 proposed scenarios. Sixteen CFAs were conducted, each with 8 items (4 abstract, 4 concrete). A weighted least squares means and variance adjusted (WLSMV) estimation was applied since the CAT items were binary [63,64]. As the chi-square statistic increases with sample size and leads to rejection of the hypothesized model, even with good fit [65], additional fit indices were examined: the Comparative Fit Index (CFI), the Root Mean Square Error of Approximation (RMSEA), and the Standardized Root Mean Square Residual (SRMR). Variances of the latent variables were set to one.\n\nInternal consistency was calculated for all abstract items and all concrete items using Cronbach’s alpha [44].\n\nUsing the 198 participants (96.6% of total sample) who completed the CAT measure a second time, two weeks after initial completion, the intraclass correlation coefficient (ICC) was calculated to assess test-retest reliability.\n\nTo examine construct validity, specifically convergent validity, correlations were calculated to assess the relationship between the CAT measure’s abstract ratio and measures that asses a similar or related construct. Convergent validity is understood as the extent to which two measures that theoretically should be related, are in fact related. This included the PEQ (problem elaboration and consequence elaboration) as well as repetitive negative thinking (using the PTQ), worry (using the PSWQ) and rumination (using the RRS), all of which have previously been shown to be strongly correlated with reduced concreteness.\n\nTo assess broader constructs which have been shown to correlate with rumination or worry, correlations were calculated between the CAT measure’s abstract ratio and measures of GAD, depression and PTSD. Constructs that were expected to have a negative correlation with the CAT measure’s abstract ratio were also assessed, specifically measures of self-efficacy and resilience.\n\nUtilizing the entire sample (N = 205) the CAT measure (raw scores of the 4 final scenarios) demonstrated good internal consistency of abstract items (16 items), Cronbach’s α=.87 and concrete items (16 items), Cronbach’s α=.85.\n\nThe CAT measure demonstrated good test-retest reliability as measured by intraclass correlation coefficients (ICC) between both time points. Sum scores for all abstract items were correlated with the sum scores two weeks later ICC = .88, p < .001, 95% CI [.84,.91] and the same process was applied to the concrete items, ICC = .85, p < .001, 95% CI [.80,.89]. There was also adequate test-retest reliability for the abstract ratio of the CAT measure, ICC = .75, p < .001, 95% CI [.69,.81].\n\nTable 1shows the fit indices of the confirmatory factor analyses for each scenario. Based on factor analyses, the four scenarios with the best fit (based on the CFI, RMSEA and SRMR, parameter estimation, factor loading and content of the scenarios) were selected for inclusion in the final CAT measure. The factor loading of the items of this version ranged from.33 to.95.Table 2shows the factor loadings of each item of the CAT measure (seeS2 Tablefor an extended table that includes factor loadings for all 16 original scenarios). The concrete and abstract factors were negatively correlated with each other ranging fromr= -.33 tor= -.39 although one scenario (scenario 4) had a positive correlation between the factors ofr= .51.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320009.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320009.t002\n\nFig 1represents a two-factor model, as hypothesized for each confirmatory factor analysis, where one factor (abstract thinking) loads onto 4 items (thought responses) and the second factor (concrete thinking) loads onto 4 different items.\n\nNote.Model of concrete and abstract factors loading onto items of the concrete and abstract thinking (CAT) measure. The lines with one arrow indicate factor loadings. The lines with two arrows indicate a correlation.\n\nNote.Model of concrete and abstract factors loading onto items of the concrete and abstract thinking (CAT) measure. The lines with one arrow indicate factor loadings. The lines with two arrows indicate a correlation.\n\nhttps://doi.org/10.1371/journal.pone.0320009.g001\n\nAll correlations were conducted with the abstract ratio. Concrete ratios were not described as they would have simply resulted in a correlation in the opposite direction.Table 3shows an overview of all correlations.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320009.t003\n\nThe current study describes the development and psychometric evaluation of the new Concrete and Abstract Thinking measure (CAT). It aimed to address shortcomings of existing measures and offer a focus on student paramedics, a population at higher risk for mental health problems compared to the general population [9–15,66]. Overall, the CAT measure demonstrated good validity and reliability.\n\nThe CAT scenarios and abstract/concrete thoughts (items) were developed in collaboration with paramedics, student paramedics and a clinical psychologist specializing in PTSD. The CAT scenarios demonstrated good factorial validity based on fit, parameter estimation, factor loading and scenario content. The content of the scenarios was balanced to equally represent potentially stressful scenarios related to university and paramedic training. The above experts, after reviewing the scenarios, concluded the scenarios represented good face validity. Content validity was not evaluated quantitively but was based on 1) existing theoretical knowledge, 2) existing measures in the field, 3) judgement of experts by experience (paramedics and student paramedics) and experts by training (clinical researchers). One scenario (‘Your computer crashed with your essay on it and you don’t have a back-up’) had a positive correlation between the abstract and concrete factors. This scenario is likely common among university students and may elicit abstract thoughts in the immediate aftermath followed quickly by concrete thoughts given that essays are linked to deadlines, which could lead to more active problem-solving.\n\nConsistent with the hypotheses, the CAT measure exhibited good construct and criterion validity relative to measures of related concepts. As hypothesized, abstract thinking was most strongly correlated with repetitive negative thinking followed by worry and rumination, cognitive processes thought to be characterized by abstract thinking [1,19,23,67,68]. Abstract thinking correlated moderately with depression and anxiety, disorders that feature rumination or worry in their symptomology [19,29,67]. Abstract thinking showed a weak correlation with PTSD, where rumination or abstract thinking have been shown to predict PTSD symptoms [7,32]. As hypothesized, abstract thinking correlated negatively with measures of self-efficacy and resilience. To the authors’ knowledge, this is the first study that has shown a relationship between these concepts, although correlations with other measures of adaptive coping such as problem solving have previously been reported [27].\n\nIn the current sample, the alternative measure of abstract thinking, the PEQ, failed to correlate significantly with measures of repetitive negative thinking, rumination, worry, depression, GAD, self-efficacy and resilience as well as the CAT measure. This is inconsistent with previous literature where the PEQ correlated significantly with concepts of repetitive negative thinking, rumination and worry, depression and GAD [19,27]. However, it is consistent with research by Ehring, Frank and Ehlers [1]. In their study of abstract thinking and rumination following traumatic road traffic accidents, the trauma-focused PEQ failed to correlate with rumination. While Stöber and Borkovec’s PEQ asks aboutanyworries the participant has, the trauma-focused PEQ used by Ehring, Frank and Ehlers [1] and the CAT measure refer tospecificscenarios or traumatic events. Ehring and colleagues suggest that focusing on worries related to a specific scenario could lead to fewer abstract thoughts than focusing onanyworries and could facilitate problem-solving since the scenarios may be problems the participants have experience of resolving, whereas open-ended worries might include situations where participants have limited experience to draw on to problem-solve. Additionally, the limited relationship between the CAT measure and the PEQ may be related to differing definitions of concrete and abstract thinking. According to Stöber and Borkovec [19], if thoughts are ‘cross-situational and aggregated,’, they are always scored as abstract although they could be indicative of concrete thinking. For example, according to Stöber and Borkovec’s definitions, the sentence “ensuring I pass assignments and meet clinical practice milestones”, would be scored as abstract because multiple assignments and milestones meet their definition of ‘cross situational and aggregated.’ However, this example would be scored as concrete according to the definition employed in the CAT measure because it focuses on the specific steps (passing assignments) needed to achieve a goal (meeting milestones).\n\nOur study has limitations worth noting. It is of course possible that the CAT measure did not measure the constructs of abstract and concrete thinking as intended but some different factor that correlates highly with repetitive negative thinking. However, this would seem unlikely since the CAT measure demonstrated a moderately strong relationship with the PTQ and the RRS, which measure rumination of which abstract thinking is a core feature. Other correlations, although statistically significant, were moderate in strength, meaning conclusions should be drawn with caution. However, given our sample was non-clinical, it is unsurprising that correlations between the CAT measure and GAD, depression, and PTSD symptom severity were moderate. As a next step, it would be valuable to evaluate the CAT measure in a clinical sample of student paramedics. In terms of construct validity, the CAT measure could only be compared to the PEQ, a measure with significant limitations, since there were no other validated measures of abstract thinking that could be used. This in and of itself underscores the necessity for a new, valid measure of abstract thinking. Although the use of scenarios in the CAT measure provide a good alternative to requiring individuals to self-identify abstract thinking or elaborating on problems in an open-ended response format, there are limitations to this approach. Some individuals may struggle to imagine themselves in situations while others may be prone to social desirability bias in their responses. This is an issue common to most measures. However, a strength of the CAT measure is that items are not clearly ‘right’ or ‘wrong’ and participants were not made aware that their abstract/concrete thinking was being assessed, which is the case in other measures [e.g.,39]. Content validity was not evaluated quantitatively, which may pose a limitation. Instead, it was based on theoretical knowledge, existing measures, and expert judgement. During the measure development phase, scenarios were carefully evaluated by a pilot sample for how realistic they were and how likely they would be to cause individuals to worry or ruminate. It could have been helpful to evaluate how realistic the scenarios appeared to participants in the main validation study. This might have offered insights into potential correlates between how realistic individuals found the scenarios or how vividly they were able to imagine them, and their CAT measure scores. Future research could further explore individual and overall ratings of the scenarios. Since participants only had the option of endorsing or choosing not to endorse an item, they could not select a hierarchy of thoughts, the degree to which they agreed with an item (i.e., very much, moderately), or indicate the likely frequency of the item (i.e., never, sometimes, always) on a Likert scale, which could have provided more nuanced responses. Whilst the current scoring is binary rather than continuous, it does provide a ratio of abstract to concrete thinking and a simple method for completion and scoring, which is advantageous over the PEQ. A further limitation is that a separate sample was not recruited to assess factorial validity, independently of the current sample. Due to the required sample size, the current sample was not split to create such a second sample. Overall, the study could have benefited from a larger sample for the testing of a new measure to allow for further comparisons and second factorial validation. However, the current sample was in line with recommendations on minimum sample sizes needed for factor analyses [44] and did demonstrate predictive power in a subsequent study of PTSD in student paramedics [32].\n\nCollecting self-reported data online allowed for highly efficient data collection across wide geographical regions. However, self-report measures can be affected by the participant’s self-awareness and social desirability bias. Despite this limitation, the approach of self-reported online measures for the development and evaluation of a new self-report measure is widely used and considered valid [e.g.,47].\n\nA recent study [32] assessed the potential relationship between abstract thinking assessed with the CAT measure and the subsequent development of PTSD symptoms in a sample of 89 student paramedics. Abstract thinking at assessment predicted PTSD symptoms at 6-month follow-up over and above what could be predicted from initial symptom levels. Abstract thinking as assessed by the CAT measure was moderately related to rumination in response to stressful memories, PTSD symptoms, anxiety and depression at 6-month follow-up. This study demonstrates the extent to which the CAT measure could be used as a measure for predicting the development of psychopathology and offers initial support for abstract thinking as a risk factor in the development of PTSD symptoms in student paramedics.\n\nFor university paramedic programs, the CAT measure could provide a safe, user friendly measure of mental health risk that is quick to self-administer and that is stigma-free. The scenarios of the CAT measure could be modified and evaluated for a range of high risk populations, such as students in rescue work, medical students, student nurses or students training in a range of healthcare professions. Whilst there are limits to generalizability, it is possible that the format of the CAT measure would be relevant for such roles. During the Covid-19 pandemic, it has become clear that assessing potential risk factors for mental ill health in emergency and healthcare workers is paramount for guiding the delivery of preventative and early interventions for common mental health problems.\n\nThe CAT measure provides a user-friendly, valid, reliable, and population-specific measure of concrete and abstract thinking that advances current methods of assessing cognitive features of rumination. The CAT measure demonstrates value in the assessment of abstract thinking as a risk factor for mental ill health and may offer guidance in the delivery of interventions aimed to prevent or treat common mental health problems for students in high risk occupations.\n\nhttps://doi.org/10.1371/journal.pone.0320009.s001\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0320009.s002\n\n(PDF)\n\nThe authors wish to thank Anke Ehlers for reviewing the original PhD chapter of this study and Aimee McKinnon for validating the CAT measure in a new sample of student paramedics [32]. Thank you to all the paramedic lecturers who shared the study with their students and to the student paramedics who participated.",
    "category": "mathematics"
  },
  {
    "title": "Reassigning sources of misophonic trigger sounds to change their unpleasantness: Testing alternative mechanisms with a new set of movies, paintings, and words",
    "authors": "Laurie M. Heller, Urszula Oszczapinska, Jessica M. Smith, Megan M. Julien, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0321594",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321594",
    "content": "We conducted nine experiments to determine why a sound’s pleasantness can be altered by movies, abstract paintings, and words. In Expt. 1, unpleasant sounds, such as the sound of a person sniffing, were paired either with their original video track or with video tracks depicting neutral events that could plausibly have produced the sound, such as pulling tissues out of a tissue box. While the unpleasant sounds were mildly unpleasant to an unscreened population, these sounds were expected to be more unpleasant for people who have misophonia, a condition in which certain everyday sounds are unbearable. Consistent with past literature, neutral video tracks increased the sounds’ pleasantness for the non-misophonic and misophonic populations, by 0.98 and 1.59 points, respectively (on an 11-point scale). Movies rated as having better audio-visual matches produced greater changes in pleasantness, consistent with the hypothesis that source reassignment caused the changes. Expt. 2 found a consistent result when the video tracks were replaced with written event descriptions, although the effect size was reduced. Expt. 3 inverted Expt. 1 and found that unpleasant video tracks decreased the pleasantness of neutral sounds by 2.12 points, but better-matching movies did not produce greater changes in pleasantness. In Expts. 4–6, we sought an alternative to the source reassignment explanation by obtaining ratings of audio-visual synchrony, cross-modal agreement in symbolism, source plausibility, and sound identifiability. No complete explanation was found for the effect of unpleasant videos. Furthermore, pleasant abstract paintings increased the pleasantness of unpleasant sounds by 0.37 points, correlating with cross-modal agreement but not with audio-visual match. Taken together, different types and patterns of match ratings can help discern the causal mechanisms by which visual stimuli affect sound pleasantness (e.g., source reassignment, cross-modal agreement).\n\nCitation:Heller LM, Oszczapinska U, Smith JM, Julien MM (2025) Reassigning sources of misophonic trigger sounds to change their unpleasantness: Testing alternative mechanisms with a new set of movies, paintings, and words. PLoS ONE 20(4):\n           e0321594.\n        \n        https://doi.org/10.1371/journal.pone.0321594\n\nEditor:Bruno Alejandro Mesz, Universidad Nacional de Tres de Febrero, ARGENTINA\n\nReceived:March 20, 2024;Accepted:March 7, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Heller et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Stimuli and data are publicly available. Heller, Laurie M.; Oszczapinska, Urszula; Smith, Jessica; Julien, Megan (2025). Supplementary Data: Reassigning sources of misophonic trigger sounds to change their pleasantness. Carnegie Mellon University. Collection.https://doi.org/10.1184/R1/c.7112221.\n\nFunding:This research was supported by a grant from the Misophonia Research Fund to LMH in 2021-23.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nDespite their ubiquity, everyday sounds can elicit a wide range of emotional and physiological responses. Some sounds, such as a babbling brook, will typically evoke feelings of calmness, while other sounds, such as crying, will typically evoke feelings of sadness or discomfort. Although there is general agreement about which environmental sounds are pleasant or unpleasant to most people, there are also profound individual differences that depend upon prior experiences and context. In fact, some everyday sounds that are considered relatively neutral to most people can be unbearable to others. Misophonia [1,2] is a disorder characterized by strong emotional reactions, such as feelings of irritation, rage, and/or disgust, in response to certain everyday sounds, such as chewing, sniffing, or pen clicking. Although common misophonic triggers are produced by oral and nasal regions of the human body, repetitive sounds are also a class of triggers [3]. Despite these common trends, every individual with misophonia has their own unique set of triggers. Reactions can also include physiological responses (e.g., increase in heart rate and perspiration). In severe cases, individuals avoid places where unbearable sounds are likely to be encountered, significantly affecting their overall quality of life [4]. Additionally, a similar emotional reaction can sometimes be triggered by visual images depicting (or labeling) events that would normally produce the trigger sounds [4,5]. Unfortunately, sounds and images that trigger misophonic reactions (hereafter, triggers) are difficult to avoid as they are often encountered in everyday life.\n\nThe emotional reaction evoked by a sound depends on many factors, such as the presumed source of the sound (e.g., a specific person), the presumed action producing the sound (e.g., eating), what other sounds are present, and whether the action is socially appropriate (e.g., eating in the library). Although perceptual properties of sounds can influence their pleasantness, they alone are insufficient to determine its emotional impact. For example, a single sound can be heard as either unpleasant or neutral depending on whether its source is correctly identified [6]. For misophonia in particular, reactions to triggers can be reduced by acoustic manipulations that reduce their identifiability, such as adding noise or distortion [7,8]. This motivates the question of whether intentionally changing the identification of a trigger’s source could reduce its negative impact.\n\nThere is evidence that the unpleasantness of a trigger can be reduced by the suggestion of an alternative neutral source for the sound. This suggestion has been accomplished in a number of ways: (1) specifying a non-human source of an eating action [9], (2) accompanying a sound with an image or video that implies a different source [10–12], and (3) modifying the interpretation of the source of the sound via text descriptions [11]. However, prior studies have not clarified how to generalize this approach for new sounds by outlining the requirements for an effective alternative neutral source. For example, must the unpleasant sounds be inherently ambiguous? Does the alternative source need to be believable, or even meaningful? We set out to explore the factors that make for effective alternative neutral sources by testing alternative hypotheses about the mechanisms for source reassignment.\n\nWhen a sound is accompanied by a video depicting its source event, this introduces dynamic temporal factors that can introduce audio-visual incongruence [13]. Therefore, videos designed to produce source reassignment may be more effective if they temporally align with the sound. It is also possible, although speculative, that source reassignment is aided when the visual source matches the intuitive physics of sound production (e.g., a forceful motion should accompany a loud sound [14].) Furthermore, perceptual input that is pleasant but unrelated to the sound source may still make unpleasant sounds more tolerable, such as pleasant music played during meals [15]. Therefore, it is necessary to account for both the related and unrelated accompanying input that affects the context of triggers.\n\nSamermit, Saal, and Davidenko [16] paired brief unpleasant sounds with videos depicting positive alternative sources (PAVS). They compared the pleasantness of the sound alone to a sound accompanied by a PAVS. They found that this sound-video pairing reduced the unpleasantness of the sounds for a general population. They postulated that the PAVS convinced observers that the sounds were produced by the pleasant source and therefore the sounds were perceived as more neutral. However, there are a few threats to the validity of this claim. First, the experimental design did not include a control condition of rating the sounds twice in a row without watching the PAVS, so it is not clear if the unpleasant sounds could have been rated more positively on their second appearance due to the “mere exposure” effect, in which neutral stimuli become more pleasing with repetition [17]. Second, it is possible that the presence of a video distracted attention from sounds, thereby making them less unpleasant [18]. Third, it is possible that the videos were generally pleasing to view and this may have contaminated the participants’ ratings of the sounds [19,20].\n\nFollow-on studies addressed some of these threats to the hypothesis that PAVS cause the source of the sound to be reassigned [11,12]. These studies compared the pleasantness rating of unpleasant sounds when paired either with PAVS or with their original video source. They introduced a new measure that asked how well the video and audio components of the movies appeared to match. Presumably, high match ratings indicate that the audio and video events are plausible and/or synchronous. The pleasantness of sounds paired with PAVS was rated higher when the match was rated higher. This relationship was interpreted as evidence that the better-matching movies (video + audio) were changing the source assignment of the sounds, thereby increasing the sounds’ pleasantness (which we name thesource reassignment hypothesis). Alternatively, it is possible that the better-matching movies were more pleasant to watch because congruent stimuli are typically more pleasant (cf. [21]), leading to an increase in the sound pleasantness ratings. Furthermore, the sounds that are relatively more pleasant could be more amenable to matching with the pleasant video components, which could explain why the largest benefit was seen for the most pleasant sounds. Therefore, a positive relationship between PAVS sound pleasantness and match quality does not prove that better-matching PAVS caused a greater change in the interpretations of the sounds’ sources. Thus, it is necessary to provide further evidence to estimate how much of the effect of accompanying stimuli (whether videos, words, or images) is due to an alteration in the perceived source of the sound.\n\nOur goal is to understand the beneficial causal mechanisms of viewing alternative sources while listening to unpleasant sounds. Isolating these mechanisms could assist with developing a broader set of stimuli that could potentially be applied to cognitive reframing of unbearable sounds (e.g., in the context of psychotherapy, real-time interventions, or mobile applications [22]). As a first step in accomplishing our goal, we replicated and extended prior studies [16,23] by creating a new set of alternative visual sources for an expanded set of triggers. We compared the pleasantness rating of triggers when paired either with an alternative neutral source or with their original video source. To test predictions of thesource reassignment hypothesis, we also asked how well the video and audio components of the movies appeared to match, and clarified whether the match was about plausibility, synchrony, or cross-modal sound symbolism. We compared misophonic participants to a non-misophonic control group. We then asked whether the match rating given by both groups correlated with the pleasantness of sounds and/or videos. To address whether movies withbetter-matchingneutral sources caused agreater changein the interpretations of the sounds’ sources, we asked whether match predicted thechangein sound pleasantness ratings between the two video conditions.\n\nOur second step was to ask whethersource reassignmentcould be accomplished semantically without the use of images. We used simple phrases describing neutral or unpleasant sources for the unpleasant sounds to influence their pleasantness ratings. We compared the size of this semantic effect on source reassignment to the effect from our first study that used accompanying visual input. We quantitatively evaluate how much of the beneficial effect of neutral visual sources could be accomplished by text descriptions of those same sources. Our study was conducted on both a misophonic and non-misophonic group to investigate the possibility that concurrent text descriptions could be a cost-effective alternative for source reassignment when movies are not available.\n\nWe created a third way to test thesource reassignment hypothesisby pairing neutral sounds with unpleasant visual sources. The visual sources, which were videos depicting sources of misophonic triggers, were predicted to cause the sounds to be rated as more unpleasant. These stimuli were useful for disentangling the alternative explanations for the association between pleasantness and match. If a better-matching movie makes the visual source more convincing, then a movie with a better match should have a larger negative effect on sound pleasantness. In contrast, if better-matching movies are more pleasant to watch, then a better audio-video match should increase the sound pleasantness ratings. We also investigated the meaning of a good match rating by evaluating the distinctions between matches based on event plausibility, temporal synchrony, and/or cross-modal agreement in sound symbolism. Because this and subsequent questions addressed a general cognitive mechanism, we tested an unscreened population (i.e., participants were neither included nor excluded based on misophonic status).\n\nA fourth way to test thesource reassignment hypothesisis to measure the effect of visual pleasantness which is not meaningfully related to the sounds. Because unrelated videos would have mismatched timing in audio and video, static images are the best choice for an unrelated stimulus. We asked whether simply looking at a pleasant image while listening to the misophonic triggers will cause the ratings of the sounds to be more positive than when the sound is heard alone. If so, that effect requires an explanation other than source reassignment. In two parallel experiments, we established how to discriminate between visual pleasantness and source reassignment via patterns of match ratings. Furthermore, we quantitatively compared the effect sizes of the pleasant images and source-reassigning movies.\n\nThis General methods section begins with an explanation of our movie construction method for all the movies in all the experiments reported herein. This section includes information about recording techniques and devices, editing software, as well as video and audio normalization procedures. It also includes definitions of our participant populations and our data quality procedures.\n\nTo generate a new set of movies visually showing alternative neutral sound sources for misophonic trigger sounds, we first conducted an extensive search of the misophonia literature to compile a list of common triggers. For a sound to be considered a trigger, the sound must be supported by empirical evidence or be self-reported by patients in a published hearing experiment or questionnaire. Based on our search criterion, we found 56 unique classes of misophonic triggers (seeS1 Table). The classes of trigger sounds that appeared most frequently in the literature were: general chewing sounds, human vocalizations, and repetitive sounds.\n\nNext, we created a list of alternative neutral sound sources for the unpleasant sounds. In our brainstorming sessions, we varied both the physical interaction and the material properties of the objects that produced the sounds. We created various stimuli to test out ideas, some of which were informed by misidentifications of similar sounds in previous studies in our lab. For all neutral alternatives, we used a source object and action that differed from the unpleasant sound. After in-house pilot testing of plausibility of the alternative sources, we selected the following 20 sounds from the top classes of trigger sounds:person blowing their nose, person eating chips, person chewing gum, person scratching scalp, person swishing water in their mouth, person crinkling a plastic bottle, person cracking their knuckles, person gulping water, person sucking in air through their teeth, person coughing, person wheezing, person typing on a keyboard, person sneezing, person brushing their teeth, person smacking their lips, person breathing loudly through the nose,person sniffing 1,andperson sniffing 2. In addition, we included two sounds that are typically considered unpleasant for much of the population:person scratching a blackboard,andperson scraping a fork and knife together. To encompass the variety of these 20 sounds, we refer to them asunpleasantsounds rather than trigger sounds.\n\nIn the lab, sounds were recorded with a Zoom H4N Pro microphone at a 24-bit/96kHz sampling rate in a double-walled sound attenuating chamber treated with sound-absorbing foam on the walls and ceiling. In the same chamber, the visual source of the event was recorded using a Zoom Q8 video recorder attached to a tripod (unless otherwise noted below). Using movie editing software (Lightworks [24]), each digital movie was separated into two tracks: (1) a silent video track depicting an Unpleasant (Uv) or a Neutral (Nv) visual source, and (2) an audio track containing an Unpleasant (Us) or Neutral (Ns) sound.\n\nAfter making original recordings of unpleasant sound events, we created movies of their alternative neutral counterparts. The actor making a neutral sound event was simultaneously watching the original movie of the unpleasant sound it was intended to emulate (a technique used by Foley artists [25]). This technique allowed the actor to follow the temporal pattern of the original unpleasant sound to ensure temporal alignment of the sound and visual source. The headphones and/or video screens were not visible in the framing of these movies.\n\nSeveral of our videos were not recorded in the lab. Some needed to be recorded outdoors. When the soundtrack was poor quality or missing, we replaced it with an in-lab Foley recording or a recording from freesound.org [26] (e.g.,ducks splashing,deer eating leaves,campfire burning,lawn sprinkler spraying water).The movie ofbirds chirpingwas downloaded from YouTube.com with no copyright infringement.\n\nAll audio track files were wav-format and equalized to have an equal root-mean-squared level using AudioToolbox functions in Matlab [27,28]. The sounds were between 5 and 20 seconds in duration (seeFile S2). Likewise, all the visual sources were brightness-equalized using FFmpeg [29], and had the same duration as the sounds with which they were paired.\n\nThe visual sources and sounds were recombined using Lightworks movie editing software [24]. In our naming convention, the first capital letter indicates the valence of the sound (with a subscript s), and the second capital letter indicates the valence of the video (with a subscript v). When we recombined the original unpleasant audio and video tracks, we produced unpleasantmovies(UsUv). Hereafter, “video track” refers to the visual event depicted in a movie, whereas “movie” refers to a combined auditory and visual stimulus denoted by two letters. Next, the unpleasant sounds were paired with the video track depicting a similarly timed neutral visual source (i.e.,UsNv). In this manner, we created 20UsUvand 20UsNvmovies. We also used twoUsUvand twoUsNvmovies from Samermit and colleagues [22]:person sipping through a straw, andperson tapping fingers on table. We note that our termUsNvcorresponds to the PAVS term used by Samermit et al. [16,23]; however, it was necessary to create different terminology to encompass our greater variety of stimulus conditions, which included video tracks, audio tracks, images, and text descriptions (seeTable 1for terms). Matching capital letters such asUUimply an original movie whereas mismatching letters such asUNimply that a sound was paired with a stimulus of a different valence. Next, for use in Experiment 3A, 22 complementary movies were made from films of neutral events that producedNv. We produced neutral movies (NsNv) and movies in which the neutral sound was paired with the corresponding unpleasant visual source of a trigger sound (i.e.,NsUv). Because the twoUsNvmovies from Samermit et al. [16,23] (astream flowingandperson bouncing a ball on table) did not contain the original neutral sounds, we made Foley recordings for those video tracks to create two correspondingNsNvmovies. This process resulted in a total of 44 movies available in a public repository (https://doi.org/10.1184/R1/c.7112221).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321594.t001\n\nAs part of stimulus development, we measured the baseline pleasantness ratings for individual silent video tracks and audio tracks; see SupplementaryFile S1for method details and SupplementaryFile S2(“Baseline video pleasantness” and “Experiment 4”) for pleasantness ratings.\n\nParticipant recruitment began on 01/07/2022 and ended on 23/04/2024. We recruited participants online through Carnegie Mellon University system and through Prolific [30]. At the time of recruitment, all participants completed one or more of the following questionnaires that assessed misophonia severity: MisoQuest [31], Misophonia Questionnaire (MQ) [32], Duke-Vanderbilt Misophonia Screening Questionnaire (DVMSQ) [33] and the S-Five [34]. We followed the scoring guidelines for each questionnaire to determine misophonic severity for each individual. For Experiments 1 and 2, using the tabulated scores for each individual, we categorized listeners into one of two groups: a misophonic or non-misophonic group. The misophonic group included all participants who received a subclinical or clinical misophonia score on any of the questionnaires. This umbrella criterion for misophonia [35] includes people who experience severe “misophonic reactions” without requiring that they also have a clinically relevant functional impairment in their daily lives. Note, additional recruitment for misophonic participants was conducted for individuals in the same age range as our non-misophonic population through Prolific, flyers posted in the Pittsburgh region, soQuiet.org [36], and social media (e.g., Facebook, Reddit). The non-misophonic control group included participants who received a nonclinical score on all questionnaires. For the remaining experiments (i.e., Experiments 3, 4, 5), the participants were recruited irrespective of their misophonic severity. We refer to these participants as ourunscreenedgroup, reflecting a subset of the population in whichsomeindividuals may have high misophonic severity. Allunscreenedparticipants were included in one group for data analyses. In contrast, for data analyses in Experiments 1 and 2, we compared misophonic and non-misophonic groups. Thus, our non-misophonic control group is not equivalent to ourunscreenedgroup because theunscreenedgroup may contain some misophonic participants. Across allunscreenedgroups (i.e., Experiments 3A, 4 and 5A-B;N= 154), the percentage of individuals who received a clinical or subclinical misophonia score was 11.69%, or 9.09%, respectively. Note that participant recruitment for allunscreenedgroups (Expts. 3–5) described the study as being about “judging properties of sounds and/or videos” and did not mention misophonia or unpleasant sounds.\n\nNormal hearing and corrected-to-normal vision were required. First, in all studies, participants gave written consent through an online form approved by Carnegie Mellon’s Institutional Review Board (IRB#2015_00000409). Prior to completing the experimental trials online using Qualtrics [37], each participant answered questions about their age, gender, and vision/hearing status. In some cases, optional questions about ethnicity were recorded (seeS2 Table). Subsequently, participants completed a volume calibration to ensure that all sounds and movies were played at a comfortably audible level. Next, participants completed a binaural Huggins’ pitch test [38] to verify that they were wearing a pair of quality headphones. If participants passed the headphone screening, they completed questionnaires that assessed misophonia severity. Next, participants completed one practice trial (a replica of a real trial in the upcoming condition) to orient them to the question format. Within the experimental trials, a catch-trial was implemented to ensure that participants were fully attentive throughout the duration of the study. This catch trial appeared superficially like the other trials, but the instructions were different. We excluded all responses from participants who failed to correctly answer the catch-trial. Additionally, we examined data from participants to see if they provided only one or two values for all ratings, but no problematic cases were found after the headphone screening and catch-trial criteria were applied. Numbers of excluded participants are reported within the methods section of each individual study. Experimental trials took approximately 30 minutes per study. Participants were compensated for their time with money or credit to fulfill a course requirement at CMU. In all studies involving ratings of sounds, participants were asked “How pleasant is the sound?” before selecting a response from an 11-point scale, wherein -5 indicated the sound was very unpleasant, +5 indicated the sound was very pleasant, and 0 indicated the sound was neutral [8].\n\nWe predicted that our unpleasant sounds would be more pleasant when paired with an alternative neutral visual source (UsNv) than when paired with a visual source that depicted the true cause of the sound (UsUv). To test the effectiveness of the movies we created on a misophonic population, we implemented a study design in which every trial contains a different movie, with no repetition of sounds in the first half of the experiment. Within the first half of the experiment, half the trials areUsNvand the other half areUsUv. This design allows us to measure the pleasantness of a sound upon its first exposure when it is accompanied by a visual source. The complementary visual sources are shown in the second half, which is a second exposure to each sound. By always accompanying the sound with a visual source, we can ensure the intended identification of the sound’s source in each condition, minimizing the effects of any sound ambiguity. We compare a misophonic and non-misophonic group. We examine the relationship between audiovisual match and movie effectiveness to test thesource reassignment hypothesis.\n\nEighty-two participants (Mage= 24.5 years; range = 18–36 years; 42 females, 38 males, two non-binary) were tested (after excluding 23 and 18 participants for failing catch trials and headphone screening, respectively). In total, 20 participants (Mage= 24.75 years; range = 18–36 years; 8 females, 10 males, two non-binary) met our criterion for misophonia (see General Methods).\n\nThe 22 unpleasant sounds,Us, combined with a video of an alternative neutral visual source,Nvto produce a movie,UsNv. This process created 22 movies (see General Methods). Additionally, the unpleasant sounds were combined with their original visual sources,UsUv. Our total stimulus set was 44 movies, divided equally amongst the two conditions (see Procedure below, andTable 1).\n\nEach of the 44 trials contained a unique movie. Participants saw every movie and were randomly assigned to watch them in one of two presentation orders (seeTable 1). Within each order, there were two mutually exclusive presentation halves. In the first half of order A, all 22 sounds were used in 22 movies: 11 sounds were inUsUvpairs, and the remaining 11 sounds were inUsNvpairs. In the second half of order A, the complementary 11UsNvpairs and 11UsUvpairs were presented (seeTable 1). In order B, the second half of order A was presented first. For example, in the first half of order A, the sound of aperson smacking their lipswas paired with an unpleasant visual source (UsUv), while in the second half of order A, it was paired with a neutral visual source (UsNv). In the first half of order B, the sound of aperson smacking their lipswas paired with a neutral visual source (UsNv), while in the second half of order B, the same sound was paired with an unpleasant visual source (UsUv). By this design, in the first half of the study, every unpleasant sound was heard only once, and each sound was only paired with one visual source.\n\nAfter observing a movie, participants rated the pleasantness of the sound within the movie. Specifically, participants were asked “How pleasant is the sound?” before selecting a response from an 11-point scale, wherein -5 indicated the sound was very unpleasant, +5 indicated the sound was very pleasant, and 0 indicated the sound was neutral [6]. Next, as in Samermit and colleagues [23], participants were asked to rate “How well does the sound match the visual event?” with a 5-point scale, for which 1 indicated “not a good match”, and 5 indicated an “extremely good match.” To clarify the meaning of “match,” we added that participants should rate “How likely it is that the visual sources caused the sounds to occur.” In our discussion, we will refer to this as the “plausibility” definition of match. The presentation order of the movies within their respective sections was random.\n\nExperiment 1 tested the prediction that the unpleasant sounds would be rated as more pleasant when paired with an alternative neutral visual source (UsNv) than when paired with a visual source that depicted the true cause of the sound (UsUv). To assess differences in sound pleasantness ratings, we conducted a mixed-design ANOVA with repeated measures of visual source pairing (i.e.,UsNvorUsUv) and presentation half (first or second), and between-subjects factors of order (A or B), misophonic status (misophonic or non-misophonic), and gender. Age was not included as a factor because the misophonic and non-misophonic groups were similar in age. As expected, sound pleasantness ratings depended upon pairing (F(1, 73) = 80.123,p< 0.001,ηp2= 0.523, power = 1.0). On average, the sound pleasantness ratings were reliably lower for misophonics than non-misophonics (F(1, 73) = 9.615,p= 0.003,ηp2= 0.116, power = 0.864). There was an interaction between these two factors, indicating that the difference in sound pleasantness ratings betweenUsNvandUsUvpairs was reliably larger for misophonics compared to non-misophonics (F(1, 73) = 5.709,p= 0.019,ηp2= 0.073, power = 0.655). Furthermore, we did observe a main effect of gender with females giving lower ratings (F(2, 73) = 5.398,p= 0.007,ηp2= 0.129, power = 0.830), and an interaction between gender and misophonic status (F(1, 73) = 4.992,p= 0.029,ηp2= 0.064, power = 0.597) indicating that females with misophonia gave sounds the lowest pleasantness ratings. However, gender did not interact with any of the stimulus factors.\n\nWe did not observe a main effect of presentation half (F(1, 73) = 0.143,p= 0.707,ηp2= 0.002, power = 0.066) nor order (F(1, 73) = 1.470,p= 0.229,ηp2= 0.020, power = 0.223), nor an interaction between these two factors. We did observe a three-way interaction between order, visual pairing, and presentation half (F(1, 73) = 9.741,p= 0.003,ηp2= 0.118, power = 0.869). This interaction suggests that the size of the difference betweenUsNvandUsUvpairs was, on average, smaller in the second half (as found in Samermit et al. [23]), but this pattern depended on the test order (A or B). Because of the interaction between presentation half and test order, our subsequent analyses and figures draw only from data in the first half of the study, i.e., the first exposure to each sound.\n\nAnalyzing only the first presentation effectively transforms our study into a between-subjects design, which means that each data point in subsequent figures represents a movie that was rated by 41 of the 82 participants. The average sound pleasantness rating for misophonics in the first half of the study, taken across all 22 sounds in theUsUvpairing, -2.21 (SD = 1.03), was significantly lower than the average sound pleasantness rating in theUsNvpairing, -0.63 (SD = 1.52) (t(21) = 5.91,p< 0.001). This was also true for non-misophonics (MUsUv= -1.32, SD = 0.92; MUsNv= -0.34, SD = 1.07) (t(21) = 4.65,p< 0.001). The misophonics ratedUsUvpairs as having lower pleasantness than non-misophonics (t(42) = -3.03,p< 0.004); however, they did not provide significantly lower pleasantness ratings than non-misophonics forUsNvpairs. The change in pleasantness due to visual pairing was marginally greater for misophonics (t(40) = 1.78,p= 0.082). The average match quality rating for misophonics ofUsNvpairs was 2.80 (SD = 1.05) on a scale of 1–5 with a range from 1.00 to 4.70, while the average match quality ofUsUvpairs was 4.00 (SD = 0.53) with a range from 2.40 to 4.60. The average match quality for non-misophonics ofUsNvpairs was 2.88 (SD = 0.73) with a range from 1.52 to 3.94, while the average match quality ofUsUvpairs was 3.63 (SD = 0.48) with a range from 2.26 to 4.13. The misophonics ratedUsUvpairs as having higher match quality than non-misophonics (t(42) = 2.44,p= 0.019); however, misophonics did not provide higher match quality ratings than non-misophonics forUsNvpairs. The relationship between average sound pleasantness of sound-visual pairs versus their respective match quality rating is illustrated in SupplementalS1andS2 Figsfor our two populations. More pleasant sound-visual pairs were significantly associated with higher match quality ratings forUsNvpairs (Misophonics: R2= 0.41,F(1, 20) = 13.94,p= 0.001; Non-misophonics: R2= 0.61,F(1, 20) = 30.95,p< 0.001), but no such association was seen forUsUvpairs (Misophonics: R2= 0.04,F(1, 20) = 0.85,p= 0.37; Non-misophonics: R2= 0.02,F(1, 20) = 0.42,p= 0.53).\n\nFig 1, displaying data from the first presentation half of Experiment 1, depicts achange function: the subtraction of the average sound pleasantness rating (UsUv-UsNv) as a function of the match quality rating ofUsNvpairs. The average sound pleasantness ratings for misophonics (N= 20) are represented by red squares, while the average sound pleasantness rating for non-misophonics (N = 62) are represented by gray circles. For misophonics, an increase in match quality of 1 point forUsNvpairing is associated with a benefit of 0.69 pleasantness rating points for sounds inUsNvpairs over theUsUvpairs (R2= 0.33,F(1, 20) = 9.67,p= 0.006). At the lowest match quality rating (1), the change in sound pleasantness was approximately 0.35 points whereas at the highest match quality rating (5), the change in sound pleasantness is projected to be 3.40 points. We observe that 19 of the 22 data points on thechange functionare above zero, showing a pleasantness benefit from a neutral relative to an unpleasant visual source. In particular, the sounds with the largest pleasantness change for misophonics were:person brushing their teeth, person swishing water in their mouth, and person eating chips, which changed in pleasantness by 4.00, 3.80, and 2.90 points, respectively. For non-misophonics, an increase in match quality of 1 point forUsNvpairing is associated with a benefit of 0.85 pleasantness rating points for sounds inUsNvpairs over theUsUvpairs (R2= 0.40,F(1, 20) = 13.08,p= 0.002). At the lowest match quality rating (1), the change in sound pleasantness was approximately -0.61points whereas at the highest match quality rating (5), the change in sound pleasantness is projected to be 2.77 points. Again, we observed that 19 of the 22 data points on thechange functionare above zero. The sounds with the largest pleasantness changes for non-misophonics were:person brushing their teeth, person swishing water in their mouth, andperson crinkling a plastic bottle, which changed in pleasantness by 3.12, 2.81, and 2.39 points, respectively. SupplementalS3 Figdepicts a non-significant, horizontalchange functionacross the match quality rating ofUsUvpairs for both populations (Misophonics: R2= 0.04,F(1, 20) = 0.81,p= 0.38; Non-misophonics: R2= 0.06,F(1, 20) = 1.37,p= 0.26), which provides evidence that the video sources which matched their sounds were not driving the source reassignment. In sum, the change in pleasantness due to visual pairs is related to the match quality of theUsNvmovies that reassign the source, and this change is larger for the misophonic participants.\n\nThe relationship between the change in average sound pleasantness ratings across the neutral (UsNv) and unpleasant (UsUv) pairs versus the average match quality ratings forUsNvpairs in Experiment 1. Changes were calculated by subtracting the average pleasantness rating ofUsUvfromUsNv. The averages were computed within two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The solid line represents the linear regression fit to the data. Each data point reflects the mean change for each unpleasant sound, with error bars reflecting the standard error of the mean across participants.\n\nThe relationship between the change in average sound pleasantness ratings across the neutral (UsNv) and unpleasant (UsUv) pairs versus the average match quality ratings forUsNvpairs in Experiment 1. Changes were calculated by subtracting the average pleasantness rating ofUsUvfromUsNv. The averages were computed within two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The solid line represents the linear regression fit to the data. Each data point reflects the mean change for each unpleasant sound, with error bars reflecting the standard error of the mean across participants.\n\nhttps://doi.org/10.1371/journal.pone.0321594.g001\n\nTo assess the quality of our stimuli, we plotted our results fromFig 1alongside those of Samermit et al. [23] in SupplementalS4 Fig. We used their published supplemental data to compute achange functionfor their stimuli. The data points from our two studies fall along nearly identical regression lines and the stimuli cover similar ranges of match and pleasantness ratings. This close quantitative replication of a prior study validates the effectiveness of our new movies and illustrates the generalizability of match ratings as a predictor of the effectiveness of differing stimuli.\n\nFinally, we looked for evidence that the pleasantness of the visual sources was influencing the sound ratings. However, the difference in pleasantness of the individual silent visual sources (Uv-Nv) did not correlate with the change in average sound pleasantness (UsNv--UsUv) in Experiment 1 (r= -0.26, R2= 0.07,F(1, 20) = 1.47,p= 0.238). Therefore, there is no evidence that participants were rating visual pleasantness instead of rating the sound pleasantness.\n\nExperiment 1 implies that movies can change a sound’s pleasantness by changing its attributed source. Experiment 2 tested the prediction that this same effect could be accomplished without movies. Text descriptions of the visual sources used in Experiment 1 were used in place of the video tracks. If the underlying effect of the movies is source reassignment, and if text descriptions semantically convey the same sources that movies provide, this study should show good strong agreement with Experiment 1. To the extent that the text descriptions are less convincing than movies, this study should show a smaller effect size than the comparable movie study. As in Experiment 1, we tested both misophonic and non-misophonic groups.\n\nEighty-one participants (Mage= 22.04 years; range = 18–30 years; 41 females, 34 males, five non-binary and one prefer not to say) were tested (after excluding 3 and 39 participants for failing catch trials and headphone screening, respectively). In total, 26 participants (Mage= 22.27 years; range = 18–29 years; 16 females, 6 males, four non-binary) met our criteria for misophonia. Note, there were 21 individuals who did not complete the second half of the study due to time constraints. Their data were removed from our omnibus ANOVA but were included in our analysis of the first half of the study.\n\nThe 22Uswere combined with a text description of the cause of the sound. The text descriptions of the cause of the sound either matched its original source (i.e., an unpleasant sound paired with its true, unpleasant description,UsUD), or matched the neutral visual source (i.e., an unpleasant sound paired with an alternative neutral description,UsND). The descriptions contained enough information for the listener to get a sense of the source event but lacked significant detail. For example, the text description for the trigger sound of crunchy chewing was “Person eating chips” while the text description of its neutral counterpart was “Person shaking a bottle containing beads.” SeeTable 1for descriptions of all 44 videos.\n\nParticipants completed the same sequence of experimental procedures as outlined in Experiment 1. Instead of watching short movies, participants were told that they would be listening to a short sound accompanied by a text description of its cause. As in Experiment 1, they were instructed to judge sound pleasantness and match quality. Half the participants were tested in each test order.\n\nExperiment 2 tested the prediction that the pleasantness ratings of unpleasant sounds would be higher when paired with a text description that offered a neutral cause of the sound (UsND) compared to the original, unpleasant cause of the sound (UsUD). We conducted a mixed-design ANOVA with repeated measures of description pairing (NDorUD) and presentation half (first or second) and between-subject factors of order (A or B), misophonic status (misophonic or non-misophonic) and gender. Sound pleasantness ratings for unpleasant sounds depended upon the pairing of the neutral or unpleasant description (F(1, 48) = 52.640,p< 0.001,ηp2= 0.523, power = 1.0). On average, the sound pleasantness ratings were reliably lower for misophonics compared to non-misophonics (F(1, 48) = 27.920,p< 0.001,ηp2= 0.368, power = 1.0). The mean change in sound pleasantness ratings betweenUsNDandUsUDpairs was larger for misophonics compared to non-misophonics; however, this difference was not significant (F(1, 48) = 2.383,p= 0.129,ηp2= 0.047, power = 0.328). We did not observe a main effect of gender (F(1, 48) = 2.579,p= 0.115,ηp2= 0.051, power = 0.350), nor an interaction between gender and misophonic status (F(1, 48) = 2.542,p= 0.117,ηp2= 0.050, power = 0.346), nor any of the stimulus level factors. There was no main effect or interaction for the presentation half or order.\n\nAs in Experiment 1, the remainder of our analyses exclusively use the responses from the first time each unpleasant sound was heard. The average sound pleasantness rating for misophonics, taken across all 22 sounds in theUsUDpairing, -2.40 (SD = 1.14), was significantly lower than the average sound pleasantness rating in theUsNDpairing, -1.43 (SD = 1.78) (t(21) = 3.75,p= 0.001). This was also true for non-misophonics (MUsUD= -1.38, SD = 1.52; MUsND= -0.85, SD = 1.57) (t(21) = 2.73,p= 0.013). The misophonics ratedUsUDpairs as having lower pleasantness than non-misophonics (t(42) = -2.50,p<0.02); however, they did not provide significantly lower pleasantness ratings than non-misophonics forUsNDpairs. The pleasantness change due to description pairing was marginally larger for misophonics (M = 0.97, SD = 1.21) than non-misophonics (M = 0.53, SD = 0.91) (t(21) = 1.81,p= 0.085). For misophonics, the average match quality rating ofUsNDpairs was 2.36 (SD = 0.78) with a range from 1.00 to 3.90, while the average match quality ofUsUDpairs was 3.86 (SD = 0.59) with a range from 2.33 to 4.72. For non-misophonics, the average match quality ofUsNDpairs was 2.23 (SD = 0.66) with a range from 1.08 to 3.48, while the average match quality ofUsUDpairs was 3.62 (SD = 0.67) with a range from 1.85 to 4.72. The match quality ratings did not differ depending on misophonic status forUsNDpairs (t(41) = 0.63,p= 0.53), norUsUDpairs (t(41) = 1.24,p= 0.22). The relationship between average sound pleasantness of sound-description pairs versus their respective match quality rating is illustrated in SupplementalS5andS6 Figsfor both populations. For both groups, higher sound pleasantness was significantly associated with higher match quality ratings forUsNDpairs (Misophonics: R2= 0.48,F(1, 20) = 18.38,p< 0.001; Non-misophonics: R2= 0.48,F(1, 20) = 18.55,p< 0.001), but there was no such association forUsUDpairs (Misophonics: R2= 0.04,F(1, 20) = 0.91,p= 0.35; Non-misophonics: R2= 0.06,F(1, 20) = 1.26,p= 0.28).\n\nTo illustrate the changes caused by description pairing,Fig 2depicts achange function: the subtraction of average sound pleasantness rating (UsUD-UsND) pairs versus the match quality rating ofUsNDpairs. The average change in sound pleasantness ratings for the misophonics (N = 26) and non-misophonics (N = 55) are represented by red squares and gray circles, respectively. For misophonics, an increase in match quality of 1 point forUsNDpairing is associated with an increase of 1.12 pleasantness rating points betweenUsUDandUsNDpairs (R2= 0.52,F(1, 20) = 21.47,p< 0.001). At the lowest match quality rating (1), thechange functionis at -0.55 while at the highest match quality rating (5), thechange functionis projected to be at 3.91. For misophonics, 18 data points on the misophonicchange functionsare positive (i.e., a positive change from a neutral description). In particular, the sounds with the largest pleasantness change for misophonics were:person scratching a blackboard, person crinkling a plastic bottle,andperson typing on a keyboard, which changed in pleasantness by 3.06, 2.46, and 2.38 points, respectively. For non-misophonics, we observe that an increase in match quality of 1 point forUsNvpairing is associated with a pleasantness increase of 0.71 points betweenUsUDandUsNDpairs (R2= 0.25,F(1, 20) = 7.00,p= 0.015). At the lowest match quality rating (1), the change in sound pleasantness is approximately -0.34 while at a high match quality rating (5), the change in sound pleasantness is projected to be to be 2.49. We observe that 15 of the 22 data points on the non-misophonicchange functionare positive. The sounds with the largest pleasantness change for non-misophonics were:person scratching a blackboard, person swishing water in their mouth,andperson scratching scalp, which changed in pleasantness by 2.25, 2.03, and 1.93 points, respectively. SupplementalS7 Figdepicts a non-significant, horizontalchange functionacross the match quality rating ofUsUDpairs for both populations (Misophonics: R2= 0.07,F(1, 20) = 1.47,p= 0.24; Non-misophonics: R2= 0.10,F(1, 20) = 2.19,p= 0.15), confirming that the match of the alternative source in theUsNDpairing (inFig 2) is what causes the change in sound pleasantness.\n\nThe relationship between the change in average sound pleasantness ratings across the neutral (UsND) and unpleasant (UsUD) pairs versus the average match quality ratings forUsNDpairs in Experiment 2. The changes are calculated by subtracting the average pleasantness rating ofUsUDfromUsND. The averages are calculated within two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The solid line indicates the linear regression fit to the data. Each data point represents the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nThe relationship between the change in average sound pleasantness ratings across the neutral (UsND) and unpleasant (UsUD) pairs versus the average match quality ratings forUsNDpairs in Experiment 2. The changes are calculated by subtracting the average pleasantness rating ofUsUDfromUsND. The averages are calculated within two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The solid line indicates the linear regression fit to the data. Each data point represents the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nhttps://doi.org/10.1371/journal.pone.0321594.g002\n\nComparing the effect sizes of the first two studies, the effect of the neutral text descriptions on sound pleasantness in Experiment 2 was significantly smaller than the effect of the neutral visual sources for non-misophonics in Experiment 1 (dExperiment 2= 0.75, average change = 0.58;dExperiment 1= 0.95, average change = 0.98;t(110) = -2.39,p= 0.019), but the effect was only marginally smaller for misophonics (dExperiment 2= 0.88, average change = 1.05;dExperiment 1= 1.94, average change = 1.59;t(43) = -1.80,p= 0.079).\n\nGiven that thechange functionhas a similar slope when the paired stimuli are visual sources (βMisophonics= 0.69, 95% CI = [0.23, 1.15];βNon-misophonics= 0.85, 95% CI = [0.36, 1.33]) and when they are text descriptions (βMisophonics= 1.12, 95% CI = [0.61, 1.62];βNon-misophonics= 0.71, 95% CI = [0.15, 1.27]), the match ratings appear to have similar meanings in both studies. This supports the interpretation that the same process of causal reassignment is happening in both studies (seeFig 3). Note, the change scores for each of the 22 sounds were marginally correlated between Experiments 1 and 2 (r= 0.42, R2= 0.18,F(1, 20) = 4.30,p= 0.051) for misophonics, but not for non-misophonics (r= 0.35, R2= 0.12,F(1, 20) = 2.72,p= 0.11). For misophonics, the source plausibility may be driving much of the variance, because alternative sources that have the biggest effect for movies tend to also have the biggest effect for written descriptions. This result also supports the idea that the degree of match is what determines the change in sound pleasantness. Because the match ratings are higher for the movies in Experiment 1 than for the description-sound pairs in Experiment 2 (by 0.44-points for misophonics and by 0.63-points for non-misophonics), we postulate that the visual sources increased the plausibility of the alternative source, which consequently caused a greater source reassignment. The smaller match quality in Experiment 2 would therefore explain the smaller average change in pleasantness observed in Experiment 2 than in Experiment 1.\n\nThese data are replotted fromFigs 1and2. The relationship between the change in average sound pleasantness ratings across the neutral and unpleasant alternative sources for Experiment 1 movies (unfilled symbols) and Experiment 2 descriptions (filled symbols) versus the average match quality ratings for each sound-source pairing. Panel A shows both misophonic groups with squares and Panel B shows both non-misophonic groups with circles. The solid line indicates the linear regression fit to the data. Each data point represents the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nThese data are replotted fromFigs 1and2. The relationship between the change in average sound pleasantness ratings across the neutral and unpleasant alternative sources for Experiment 1 movies (unfilled symbols) and Experiment 2 descriptions (filled symbols) versus the average match quality ratings for each sound-source pairing. Panel A shows both misophonic groups with squares and Panel B shows both non-misophonic groups with circles. The solid line indicates the linear regression fit to the data. Each data point represents the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nhttps://doi.org/10.1371/journal.pone.0321594.g003\n\nExperiment 3A was designed to test whether the valence of the visual sources is the essential component that determines the direction of the shift in pleasantness. Given that an alternative neutral visual source can increase sound pleasantness (Experiment 1), we predicted that an alternative unpleasant visual source would decrease the pleasantness of a neutral sound. To test this idea, we paired neutral sounds from the original neutral visual sources shown in Experiment 1 with visual sources of the unpleasant events that produced the unpleasant sounds used in Experiment 1 (NsUv). We also paired the neutral sounds with their original neutral visual sources (NsNv). We predicted that neutral sounds would be rated as more pleasant when paired with their original visual sources than when paired with alternative, unpleasant visual sources. Furthermore, we predicted that better-matching unpleasant movies would be more plausible and therefore cause a greater decrease in pleasantness. However, the opposite prediction is also possible: if better-matching sound-visual pairs are more pleasant, and if more pleasant sound-visual pairs increase the pleasantness of the sound, then movies with the highest match ratings should have the highest pleasantness ratings, as seen in Experiment 1.\n\nSixty-eight participants (Mage= 22.42 years; range = 18–30 years; 35 females, 31 males, two non-binary) were tested (after excluding 44 participants for failing the headphone screening). In thisunscreenedgroup that was recruited irrespective of misophonic status, six individuals (Mage= 21.83 years; range = 19–28 years; 4 females, 2 males) met our criteria for misophonia.\n\nThe 22 neutral sounds,Ns, combined with a video of an alternative unpleasant visual source,Uv, to produce a movie,NsUv. This process created 22 movies (see General Methods). Additionally, the neutral sounds were combined with their original visual sources,NsNv. Our total stimulus set was 44 movies, divided equally amongst the two conditions (seeTable 1).\n\nThis study followed the same procedure and design described in Experiment 1, but participants viewedNsNvpairs andNsUvpairs. There were 36 and 32 participants who completed the two test orders.\n\nExperiment 3A tested the prediction that the pleasantness ratings of neutral sounds would be lower when paired with an alternative, unpleasant source (NsUv) than when paired with a visual source that depicted the original, neutral cause of the sound (NsNv). In parallel with Experiments 1 and 2, we conducted analyses only on the first half of the study so that every trial was a first exposure to a sound. In contrast to Experiment 1, given that this was anunscreenedgroup, we averaged pleasantness ratings across the entire group without an analysis of misophonic status. The average sound pleasantness rating across all 22 neutral sounds in theNsNvpairing, 0.92 (SD = 1.34) was significantly higher than in theNsUvpairing, -1.20 (SD = 1.25) (t(21) = -14.60,p< 0.001). The average match quality rating ofNsUvpairs was 1.76 (SD = 0.63), range of 1.03 to 3.41, which was significantly lower than the average match quality rating ofNsNvpairs, 4.07 (SD = 0.67), range of 1.86 to 4.69 (t(21) = -12.50,p< 0.001). The relationship between average sound pleasantness of sound-visual pairs versus match rating is illustrated in SupplementalS8andS9 Figs. We observe non-significant relationships for bothNsUv(R2= 0.03,F(1, 20) = 0.62,p= 0.44), andNsNvpairs (R2= 0.01,F(1, 20) = 0.28,p= 0.60).\n\nFig 4, displaying data from the first presentation half of Experiment 3A, depicts achange function: the subtraction of average sound pleasantness rating ofNsNvpairs fromNsUvpairs as a function of the match quality rating ofNsUvpairs. There is no significant relationship between the change in sound pleasantness versusNsUvmatch quality (R2= 0.02,F(1, 20) = 0.37,p= 0.55). We observe that all 22 data points are below zero (i.e., a nearly constant negative change due to the unpleasant video). Likewise, SupplementalS10 Figshows that the change in average sound pleasantness rating betweenNsNvpairs andNsUvpairs is not related to the average match quality rating ofNsNvpairs (R2= 0.009,F(1, 20) = 0.18,p= 0.67). These comparisons show that theNsUvpairing decreases the sound pleasantness ratings relative to theNsNvpairing, but not as a function of match, in contrast to the significant slope relating changes in pleasantness as a function of the alternative source’s match in Experiment 1. The results in Experiment 3A are inconsistent with thesource reassignment hypothesis, suggesting that there is another cause for the change.\n\nThe relationship between the change in average sound pleasantness ratings across the unpleasant (NsUv) and neutral (NsNv) pairs versus the average match quality ratings forNsUvpairs in Experiment 3A. The changes are calculated by subtracting the average pleasantness rating ofNsNvfromNsUv. The averages are calculated for anunscreenedgroup. The solid line indicates the linear regression fit to the data. Each data point represents the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nThe relationship between the change in average sound pleasantness ratings across the unpleasant (NsUv) and neutral (NsNv) pairs versus the average match quality ratings forNsUvpairs in Experiment 3A. The changes are calculated by subtracting the average pleasantness rating ofNsNvfromNsUv. The averages are calculated for anunscreenedgroup. The solid line indicates the linear regression fit to the data. Each data point represents the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nhttps://doi.org/10.1371/journal.pone.0321594.g004\n\nWe looked for evidence that the pleasantness of the visual sources were influencing the sound ratings. However, the difference in unpleasantness of the individual silent visual sources (Uv-Nv) did not correlate with the change in average sound pleasantness (NsUv-NsNv) in Experiment 3A (r= 0.14, R2= 0.02,F(1, 20) = 0.42,p= 0.53). Therefore, there is no evidence that participants were rating visual pleasantness in instead of rating the sound pleasantness.\n\nExperiment 3A left open the question of how there could be a change in sound pleasantness without it having any relationship with match quality. We considered the possibility that participants were interpreting the match judgment differently between Experiment 3A and Experiment 1. In Experiment 3A, participants may have been rating the temporal alignment of the sounds and visual sources, which can be slightly misaligned due to the movie editing process. To empirically test this hypothesis, we replicated Experiment 3A with one difference: the match rating of source plausibility was followed by an evaluation of temporal match (i.e., audio and video alignment). We intended this juxtaposition of questions to isolate the factors that may have been affecting the match plausibility rating in Experiment 3A.\n\nA new set of seventeen participants were tested to replicate Experiment 3A with a modification in the procedure for match judgements (Mage= 19 years; range = 18–20 years; 10 females, seven males) after excluding seven participants who did not pass the headphone screening. Only one individual met our criteria for misophonia in thisunscreenedgroup.\n\nThe stimuli were identical to Experiment 3A.\n\nExperiment 3B followed the same procedure and design as in Experiment 3A, rating both sound pleasantness and match for 44 videos, but these participants made two match ratings in a row. The first match rating was a source plausibility match (worded identically to Experiment 3A), followed by a second match rating (0–4) that was a temporal match (“In this movie, are the audio and video aligned in time?”).\n\nFor this set of participants, the average change in pleasantness betweenNsUvandNsNvwas 1.97 points (SD = 1.05). As found in Experiment 3A, the change in pleasantness fromNsUvtoNsNvwas neither significantly related to source plausibility (R2= 0.02,F(1, 20) = 0.45,p= 0.51) nor related to temporal match (R2= 0.02,F(1, 20) = 0.41,p= 0.53). Next, we asked whether the plausibility and temporal match judgements were treated differently by participants. Because there was a significant correlation between plausibility and temporal match ratings (r= 0.63, R2= 0.39,F(1, 20) = 12.85,p= 0.002), it is possible that a temporally aligned movie makes the source more plausible. Importantly, given that 61% of the variance in ratings is unique for each rating scale (because R2= 0.39), these two definitions of matching are not synonymous. Overall, this experiment provides no evidence that the match rating in Experiment 3A was understood to be a temporal alignment rating, and there is no evidence that better temporal alignment caused a greater negative shift in pleasantness in Experiment 3A or 3B.\n\nGiven that Experiments 3A and 3B did not find any match measure that explained the variations in sound pleasantness within conditions, Experiment 3C was designed to test whether the cross-modal agreement of the movies was causing the negative shift in sound valence. Cross-modal agreement between meaningless images and words has been found experimentally to relate to sound symbolism; for example, round visual shapes tend to match better to the word “maluma” than “takete” [39]. One possibility is that movies with better cross-modal agreement between the video and audio pairs have a greater influence on the pleasantness of the sound. To investigate this possibility, a study was conducted in which participants were instructed to categorize the sounds and video tracks into one of two categories, as a means of measuring cross-modal agreement.\n\nA total of 32 participants (Mage= 21.88 years; range = 18–29 years; 15 females, 13 males, four non-binary) were tested. In thisunscreenedgroup that was recruited irrespective of misophonic status, there were six misophonic individuals (Mage= 21.83 years; range = 19–28 years; 4 females, 2 males).\n\nThere were a total of 44 silent visual tracks, and 44 sounds (22 unpleasant and 22 neutral). The two nonsense words used for cross-modal matching, “maluma” or “takete,” were chosen because they have established sound symbolism that corresponds to round or pointy shapes, respectively [39].\n\nThe experimental platform was Gorilla.sc [40]. Each sound was heard (unimodally) in random order, followed by each video source (unimodally) in random order. In subsequent data analysis, each stimulus was categorized as being either a “maluma” or a “takete” based on which name received that designation more than 50% of the time across participants. Next, everyNsUvpairing used in Experiment 3A was categorized as being either in cross-modal “agreement” if the categories of the movie and the sound were the same (i.e., a “maluma” video track with a “maluma” sound, or a “takete” video track with a “takete” sound), or in cross-modal “disagreement” (i.e., a “maluma” video track was paired with a “takete” sound, or vice versa).\n\nTo test whether the cross-modal agreement in sound and visual symbolism underlies the changes in pleasantness seen in Experiment 3A, the average cross-modal match quality ratings in Experiment 3A were computed in two separate groups: one in which the sound-painting pairing agreed cross-modally, and one in which they disagreed cross-modally.\n\nTen (out of 22) neutral visual sources and eight (out of 22) unpleasant visual sources were categorized by more than 50% of participants as “maluma.” Inter-rater agreement was high for the neutral and unpleasant visual sources, respectively, at 0.93 (ICC Alpha,F(21, 611) = 16,p< 0.001) and 0.86 (F(21, 553) = 8.03,p< 0.001). To test whether the cross-modal agreement measured in Experiment 3C underlies the match quality ratings measured in Experiment 3A, everyNsUvpairing used in Experiment 3A was designated as being either in cross-modal “agreement” or “disagreement”, respectively, depending on ratings of each video source and the sound obtained in Experiment 3C. The average change in pleasantness of sounds that were inNsUvpairs with cross-modal agreement (M = -2.14, SD = 0.53) was not reliably higher than the change in pleasantness for sounds that were inNsUvpairs with cross-modal disagreement (M = -2.08, SD = 0.93) (t(20) = -0.22,p= 0.83). Therefore, cross-modal agreement based on sound symbolism does not account for significant variation in the change produced by unpleasant visual sources in Experiment 3A. Furthermore, according to a t-test for independent samples, the mean match quality rating was not significantly higher for the group of stimuli that were in cross-modal agreement (M = 1.69, SD = 0.46), than cross-modal disagreement (M = 1.88, SD = 0.89) (t(20) = -0.68,p= 0.50). This indicates that the match quality rating was not interpreted as a cross-modal agreement rating by participants.\n\nTo further test the explanatory power of cross-modal match, we conducted a parallel analysis of cross-modal effects for the neutral source movies used in Experiment 1. Because Experiment 1 had provided evidence of source reassignment, we predicted that there would be no significant correlations with cross-modal match. We found that cross-modal agreement ofUsNvpairs in Experiment 1 had no effect: the average change in pleasantness was unaffected by cross-modal agreement versus disagreement (M = 1.17, SD = 1.02 versus M = 0.85, SD = 0.85;t(20) = 0.52,p= 0.61) and was unrelated to the match (plausibility) rating (M = 2.96, SD = 0.76 versus M = 2.19, SD = 0.87;t(20) = 1.62,p= 0.12).\n\nExperiments 1 and 2 showed that our misophonic groups rated sounds in the context of movies as more unpleasant than did non-misophonic groups. While both groups found sounds to less unpleasant when they were paired with neutral sources, this effect tended to be greater for the misophonic group (significantly in the full Experiment 1, and marginally for first exposures in Experiments 1 and 2). Although effects of the verbal descriptions were smaller than the videos, Experiments 1 and 2 were quantitatively consistent with a common mechanism of source plausibility for words and videos because they had similarchange functions. Experiment 3A appeared to result from a different mechanism, given that itschange functionshowed no relationship to source plausibility. Experiments 3B and 3C showed that the magnitude of change per video in Experiment 3A did not relate to audio-visual temporal synchrony or cross-modal agreement either, leaving open the question as to what causes the decreased pleasantness of the neutral sounds in theNsUvmovies. Taken together, Experiments 1, 2, and 3A-C constitute contrasting evidence that the neutral alternative sources caused source reassignment because variations in their pleasantness shifts correlated with match ratings based on source plausibility (but not cross-modal agreement) whereas the unpleasant visual sources did not cause source reassignment because variations in their pleasantness shifts did not correlate with match ratings.\n\nWe considered whether participants in Experiments 3A-C rate the pleasantness of the unpleasant visual sources (rather than the sounds); if so, this predicts that there should be a high correlation betweenUvvideo andNsUvsound pleasantness. This question motivates an experiment to measure the pleasantness and identification ofUsandNs(Experiment 4) and the pleasantness ofUvandNv(see SupplementaryFile S2). Experiment 4 serves two purposes. First, it asks whether inherent sound ambiguity might permit an alternative visual source to be more plausible and effective for that sound. Sound ambiguity was tested in a sound identification experiment that measured the rate at which each sound was misidentified as its alternative source. Cases of misidentification allow us to test a prediction that is made exclusively by the source-reassignment explanation and not by a visual pleasantness explanation: the ambiguous unpleasant sounds which tend to be misheard as a neutral sound should be rated as matching well to an alternative neutral visual source, while the ambiguous neutral sounds should be rated as matching well to an alternative unpleasant visual source. Second, the study design contains two measurements of sound-alone pleasantness, allowing us to test whether the sounds’ pleasantness changes upon second listening. Although the “mere exposure” effect is well-known for increasing stimulus preference, there is some evidence (e.g., Brickman et al. [41]) showing that the mere exposure effect applies differentially to positive/neutral stimuli and negative stimuli, with mildly negative stimuli becoming more negative upon repeated exposure. Experiment 4 measures both the identifiability and the “mere exposure” effect for all the neutral and unpleasant sounds used in our studies.\n\nThirty-two participants (Mage= 24.40 years; range = 18–30 years; 12 females, 20 males) were tested (after excluding 13 participants for failing headphone screening). In thisunscreenedgroup, 11 participants (Mage= 25.18 years; range = 18–29 years; five females, six males) met the criteria for misophonia.\n\nThere were 22 unpleasant sounds,Usand 22 neutral sounds,Ns(SeeTable 1and General Methods). Each of the 44 sounds were presented in isolation.\n\nDuring the first block of 44 trials, participants were asked to rate the pleasantness of one sound per trial (i.e., a first exposure). The same pleasantness scale as Experiment 1 was used. In the subsequent block of 44 trials, participants rated the pleasantness of each sound again (i.e., a second exposure) before identifying it by selecting one label from a closed set of 10 labels [42]. The labels consisted of a noun and a verb taken from a descriptive phrase (seeTable 1). The 10 labels were randomly selected on each trial from the entire set of 44 possible labels, with the restriction that two of the ten labels were always (1) the correct answer and (2) the corresponding alternative sound. The presentation order of the sounds was random.\n\nExperiment 4 tested the identification of our unpleasant and neutral sounds and tested the effects of repetition on pleasantness. We first apply this data to Experiment 1. Sound identification accuracy ofUswas 77.0% (SD = 0.20) with a range from 40.6% forperson cracking their knucklesto 100% forperson wheezingandperson scraping a knife and fork together.Table 2shows the frequency of misidentifications for each unpleasant sound. In most instances of misidentification, unpleasant sounds were misidentified as their planned neutral counterparts (Planned source, 3rdcolumn from right). The odds ratio is 3.09 for planned sources versus 0.05 for unplanned sources, which was calculated by dividing the number of misidentifications per type (planned or other source) by the number of total participants in the study. These instances should, in principle, raise the averageUspleasantness ratings. This leads to the prediction that the rate at whichUsare confused for their planned neutral counterparts should correlate with higher averageUspleasantness ratings. This prediction was upheld by a significant correlation (r= 0.20,F(1, 20) = 5.012,p= 0.036, first exposure). In effect, this result means that the true unpleasantness of ambiguousUssounds are underestimated in our sound-alone condition relative to a situation in which the source is known or strongly implied (i.e., as in Experiments 1 and 2 via visual or text input). Furthermore, we reasoned that a sound which issometimesspontaneously confused for its planned neutral counterpart shouldoftenbe considered plausible when it is paired with that visual source. This reasoning predicts the significant correlation we found between rate of confusion of eachUsand its average match rating within theUsNvpairing from all participants in Experiment 1 (r= 0.61,F(1, 20) = 12.30,p= 0.002, first exposure) as well as its change in pleasantness between theUsNvandUsUvconditions (r= 0.56,F(1, 20) = 9.36,p= 0.006, first exposure).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321594.t002\n\nSecond, we apply this data to Experiment 3A. Sound identification accuracy of theNswas 82.0% (SD = 0.20) with a range from 44.0% for sound of aperson snapping a stickto 100% for sounds ofcampfire burning, birds chirping, person pulling facialtissues out of a box,person tapping a bag that is laying on top of a tambourine, andstream flowing.S3 Tableshows that the odds ratio is 1.00 for planned sources versus 0.07 for unplanned sources. These confusions of planned neutral sounds with unplanned unpleasant sources should, in principle, lower the averageNspleasantness ratings. This leads to the prediction that the rate at which theNsare confused for their planned unpleasant counterparts should correlate withloweraverageNspleasantness ratings. However, this prediction was not upheld (r= 0.15,F(1, 20) = 0.472,p= 0.50, first exposure). There was no correlation between rate of confusion of eachNswith its average match rating within theNsUvpairing from Experiment 3A (r= 0.29,F(1, 20) = 1.83,p= 0.19, first exposure), nor with its change in pleasantness between theNsUvandNsNvconditions (r= 0.005,F(1, 20) = 0.0006,p= 0.98, first exposure).\n\nThe identification and pleasantness data permit us to quantitatively estimate how much a sound source reassignment could change the pleasantness of the sound in Experiment 1. Because the average pleasantness of correctly identified unpleasant sounds during first exposure was -1.44 (SD = 1.58), and the average pleasantness of their correctly identified neutral counterpart sounds was 0.28 (SD = 1.34), we estimated that the largest possible change in pleasantness caused purely by source reassignment would be their difference, 1.72 points. This difference provides an upper bound on the size of the effect that could be obtained in Experiment 1, assuming allUssounds were correctly identified in theUsUvtrials and fully reassigned to neutral sound sources when accompanied by neutral movies. This upper bound of the effect is large enough to account for the shifts obtained in Experiment 1 because the average change in sound pleasantness was 1.13 points (subtracting theUsNvof -0.41 from theUsUvof -1.54, first exposure across all participants). This rules out the need to appeal to any additional mechanism aside from source reassignment to account for the size of the changes in pleasantness that were observed in Experiment 1.\n\nTo examine how repeated exposure affects the pleasantness these sounds, we conducted a repeated measures ANOVA to compare sound pleasantness ratings across sound valence (UsorNs) and exposure (first or second). The average pleasantness rating for each sound was calculated by averaging the rating across all participants, irrespective of whether the sound was correctly identified. This calculation was completed separately for each sound valence and exposure. The mean pleasantness ofUs(Mfirst= -1.34, SDfirst= 1.51; Msecond= -1.48, SDsecond= 1.58) was significantly lower than the pleasantness ofNs(Mfirst= 0.24, SDfirst= 1.32, Msecond= 0.48, SDsecond= 1.41) (F(1, 42) = 16.69,p< 0.001,ηp2= 0.284, power = 0.980). We did not observe a main effect of first versus second exposure (F(1, 42) = 0.787,p= 0.38,ηp2= 0.018, power = 0.140). More importantly, we did observe a significant interaction between sound valence and exposure (F(1, 42) = 10.50,p= 0.002,ηp2= 0.200, power = 0.886). Pleasantness ratings forUswere 0.14 points lower during second exposure, whereas the pleasantness ratings forNswere 0.25 points higher during second exposure. This result agrees with our prediction that the mere exposure effect applies differentially to positive/neutral stimuli and negative stimuli, with mildly negative stimuli becoming more negative upon repeated exposure.\n\nExperiment 1 provided evidence that an unpleasant sound is rated as more pleasant when paired with an alternative neutral visual source than when it is presented with an unpleasant visual source.The source reassignment hypothesisis that the visual source changes the perceived cause of the sound, and this explains why the change is greater when there is a better match between the visual source and the sound. However, the alternative visual sources may also have the potential to change the ratings of the sounds by other mechanisms, such as contaminating the sound ratings with their visual pleasantness. Although the results of Experiment 1 did not show an effect of the pleasantness of the silent visual source on the change function, those visual sources had the same source as the sounds and therefore shared meaning. Because the meaning of the sound source is a strong factor in its emotional effect, it is possible that the visual source’s semantics (meaning of the source) overwhelmed the effect of visual pleasantness Therefore, Experiment 5A was devised to directly test the potential alternative mechanism of perceptual visual pleasantness devoid of meaning. In this study, we paired pleasant abstract paintings with our unpleasant sounds because they contained no semantic content. Furthermore, because these were static images, there was no auditory-visual temporal asynchrony introduced by showing unrelated visual input.\n\nTwenty participants (Mage= 19.76 years; range = 18–22 years; 17 females, two males, one non-binary) were tested irrespective of misophonic status (after excluding five participants for failing the headphone screening). In thisunscreenedgroup, four participants (Mage= 20 years; range = 18–22 years; 3 females, 1 male) met the criteria for misophonia.\n\nThe 22Ussounds from Experiment 1 were played simultaneously with pleasant, abstract paintings,UsPp(See General Methods andTable 1). Between participants, the pairing of unpleasant sounds to the abstract paintings was random so that each listener experienced a custom set ofUsPppairs. We used 166 abstract paintings from The Art Institute of Chicago online collection [43] and Pexels [44], a free stock photo website.\n\nIt has been shown that the perception of abstract art differs substantially across individuals [45], i.e., there is no consensus on whether an abstract piece of art is pleasant or unpleasant. Therefore, this experiment was preceded by a pretest (Part One) to select paintings that would be pleasant for each participant. In Part One, each participant rated the pleasantness of 166 abstract paintings. Each painting was viewed for 12 seconds, the average duration of the unpleasant sounds, before being given a pleasantness rating on the same 11-point scale described in Experiment 1. For each participant, the 22 abstract paintings with the most positive pleasantness ratings were selected. The preselected paintings and sounds were randomly paired and displayed throughout the duration of the sound using iMovie [46]. Approximately four days later, in Part Two, the participants completed ratings of the sounds with and without accompanying images. They first rated the pleasantness of all the unpleasant sounds in isolation, using the 11-point pleasantness scale; next, they observed theUsPppairs and rated the sound pleasantness as well as the match quality ofUsPppairs. Instructions were to rate “How well the sound matches the painting.” The presentation order of the stimuli within their respective sections was random. In an additional step after the experiment, 11 of the participants again rated the pleasantness of the silent paintings. All other procedural elements (i.e., survey via Qualtrics, volume calibration, headphone screening, and catch trials) were the same as in the common procedures in General Methods.\n\nExperiment 5A tested the alternative hypothesis that the pleasantness of an unpleasant sound,Us, would increase when it was presented simultaneously with a pleasant but semantically unrelated painting,Pp. The average pleasantness rating for eachUsPpacross the entireunscreenedgroup was calculated by averaging the sound pleasantness ratings irrespective of the painting with which the sound was paired. The mean pleasantness of the sound alone (M = -1.62, SD = 1.72) was significantly lower than the pleasantness of the sound in theUsPppairing (M = -1.25, SD = 1.73;t(21) = -4.51,p< 0.001).Fig 5Ashows that the average soundpleasantnessratings in theUsPppairing did increase as a function of the average match quality ofUsPppairs (R2= 0.43,F(1, 20) = 15.10,p< 0.001, slope of the function = 2.92). The average match quality rating was 2.00 (SD = 0.39) with a range from 1.40 to 2.65. Next, to illustrate the relationship between pairing and match,Fig 5Bdepicts achange function: the subtraction of the sound pleasantness rating when in isolation from the sound pleasantness rating when inUsPppairing as a function of the match quality ratings ofUsPppairs. Thechange functionhas a non-significant horizontal line-of-best-fit, indicating that a change in sound pleasantness is not associated with greater match quality (R2= 0.069,F(1, 20) = 1.49,p= 0.24, slope of the function = 0.25).\n\n(A) The relationship between average sound pleasantness ratings forUsPppairs versus average match quality ratings forUsPppairs in Experiment 5A. The solid line indicates the linear regression fit to the data. Each data point represents the mean rating across observers for one unpleasant sound, while the error bar reflects the standard error of the mean. (B) The relationship between the change in average sound pleasantness ratings across the two pairs (UsPporUs) versus average match quality ratings forUsPppairs in Experiment 5A. The changes are calculated by subtracting the average pleasantness rating ofUsfromUsPp. The solid line indicates the linear regression fit to the data. The 22 data points represent the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\n(A) The relationship between average sound pleasantness ratings forUsPppairs versus average match quality ratings forUsPppairs in Experiment 5A. The solid line indicates the linear regression fit to the data. Each data point represents the mean rating across observers for one unpleasant sound, while the error bar reflects the standard error of the mean. (B) The relationship between the change in average sound pleasantness ratings across the two pairs (UsPporUs) versus average match quality ratings forUsPppairs in Experiment 5A. The changes are calculated by subtracting the average pleasantness rating ofUsfromUsPp. The solid line indicates the linear regression fit to the data. The 22 data points represent the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nhttps://doi.org/10.1371/journal.pone.0321594.g005\n\nAdditionally, the pleasantness of the abstract paintings decreased significantly after viewing them with the unpleasant sound (for the 11 participants who completed that condition) (MFIRST= 3.79, SD = 0.23; MSECOND= 1.81, SD = 0.73) (paired-samplet(21) = 14.33,p< 0.001).\n\nThe pleasantness of abstract paintings (measured in Part One) did not account for variance in judgements of sound pleasantness ofUsPppairs (R2= 0.015,F(1, 20) = 0.29,p= 0.59), nor match quality (R2= 0.01,F(1, 20) = 0.24,p= 0.63), nor did it correlate significantly with pleasantness ratings when the sound was presented alone (R2= 0.002,F(1, 20) = 0.035,p= 0.85). In Part One, the pleasantness of the paintings, across all 20 participants, had a mean of 3.46 (SD = 0.19) with a range of 3.10 to 3.85, which may have increased the sound pleasantness by as much as 0.40 points.\n\nIn Experiment 5B, we predicted that our original set of movies depicting alternative neutral visual sources (UsNv) could increase the perceived pleasantness of our unpleasant sounds relative to the sounds alone. Experiment 5B uses the same procedure as Part Two in Experiment 5A to permit a quantitative comparison of effect sizes between the two studies while also serving as a replication of our findings in Experiment 1. The study design of Experiments 1–3 limits our ability to measure the direct effect of the neutral visual source because the sounds are always played with a video. The present study design allows us to test whether the entire relative effect in Experiment 1, obtained by subtracting two conditions containing different video tracks, is due to only one type of visual source (e.g., unpleasant videos).\n\nThirty-four participants (Mage = 19.70 years; range = 18–31 years; 23 females, 11 males) participated irrespective of misophonia status (after excluding 9 participants for failing the headphone screening). In thisunscreenedgroup, there were five misophonics (Mage= 19.40 years; range = 18–20 years; 4 females, 1 male).\n\nThere were 22 unpleasant sounds,Us, and 22UsNvmovies (seeTable 1).\n\nThe procedure was identical to Part Two of Experiment 5A except that neutral movies were paired with sounds instead of paintings. In the first half of the study, participants rated the sounds alone. In the second half of the study, participants observedUsNvmovies and rated both the pleasantness of the sound and the match quality of the movie. The presentation order of the stimuli within their respective sections was random.\n\nExperiment 5B tested the prediction that pleasantness of a sound in isolation (Us) would increase when it was paired with a visual source that offered a neutral causal explanation of the sound (UsNv). Averaged across theunscreenedgroup, the mean pleasantness of the sounds alone (M = -1.27) was significantly lower than the pleasantness of the sound in theUsNvpairing (M = -0.69) (t(21) = -3.58,p= 0.001).Fig 6Ashows the average sound pleasantness ratings in theUsNvpairing as a function of the average match quality ofUsNvpairs (R2= 0.60,F(1, 20) = 29.63,p< 0.001). In agreement with previous findings, the average sound pleasantness in theUsNvpairs increased with greater match quality ratings. The average match quality rating was 2.50 (SD = 1.00) with a range from 1.03 to 4.32. The means for all stimuli are available in SupplementaryFile S2.Lastly, to illustrate the relationship between the effectiveness of aUsNvpairing and its match,Fig 6Bdepicts achange function: the pleasantness rating ofUssubtracted from the sound pleasantness rating ofUsNvas a function of the match quality rating ofUsNvpairs. The best-fitting line to the data shows that a greater match quality is associated with a greater effect of the neutral visual source (R2= 0.49,F(1, 20) = 19.03,p= 0.003). At the lowest match quality rating (1), the change in sound pleasantness is approximately -0.21. Thereafter, the change in sound pleasantness increases by 0.53 points with every 1-point increase in match quality rating. We note that the sounds with the largest pleasantness change for ourunscreenedgroup were:a person smacking their lips, a person eating chips, a person cracking their knuckles,anda person sniffing 2, which changed by 1.94, 1.56, 1.38, and 1.38 points, respectively.\n\n(A) The relationship between average sound pleasantness ratings forUsNvpairs versus average match quality ratings forUsNvpairs in Experiment 5B. The solid line indicates the linear regression fit to the data. Each data point represents the mean rating across observers for one unpleasant sound, while the error bar reflects the standard error of the mean. (B) The relationship between the change in average sound pleasantness ratings across the two pairs (UsNvorUs) versus average match quality ratings forUsNvpairs in Experiment 5B. The changes are calculated by subtracting the average pleasantness rating ofUsfromUsNv. The solid line indicates the linear regression fit to the data. The 22 data points represent the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean.\n\n(A) The relationship between average sound pleasantness ratings forUsNvpairs versus average match quality ratings forUsNvpairs in Experiment 5B. The solid line indicates the linear regression fit to the data. Each data point represents the mean rating across observers for one unpleasant sound, while the error bar reflects the standard error of the mean. (B) The relationship between the change in average sound pleasantness ratings across the two pairs (UsNvorUs) versus average match quality ratings forUsNvpairs in Experiment 5B. The changes are calculated by subtracting the average pleasantness rating ofUsfromUsNv. The solid line indicates the linear regression fit to the data. The 22 data points represent the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.g006\n\nNext, the results of Experiment 5B were harnessed to assess the reliability and validity of our pleasantness ratings across studies. Ratings of sounds isolation (Us) were highly correlated between Experiments 5B and 4 (first exposure) (r= 0.94,F(1, 20) = 164.34,p< 0.001), and between Experiments 5B and 5A (r= 0.97,F(1, 20) = 311.72,p< 0.001). We also found a significant correlation between sound pleasantness ratings ofUsNvpairings in Experiment 5B and 1 (across all participants, first exposure,r= 0.93,F(1, 20) = 123.40,p< 0.001), as well as for match quality ratings ofUsNvpairings in Experiment 5B and 1 (r= 0.94,F(1, 20) = 145.88,p< 0.001). We attribute the high reproducibility of our data to our strict headphone screening process and our catch trials. The convergent validity of the unimodal ratings of each sound source was shown by the significant correlation betweenUspleasantness ratings from Experiment 5B and the baselineUvpleasantness ratings (r =0.70, F(1, 20) = 19.66, p< 0.001, SupplementalFile S2). Furthermore, conditions in study 5B provided the data needed to test whether the duration of our sounds had any effect on pleasantness (see SupplementalFile S2). Duration did not correlate with sound pleasantness in either theUsorUsNvconditions.\n\nThe abstract pleasant paintings in Experiment 5A caused a small, yet reliable, increase in pleasantness of the sounds. This could support the hypothesis that visual pleasantness influences sound ratings. Importantly, although the match quality ofUsPpis correlated to the sound pleasantness ofUsPp, its match quality does not relate to thechangein pleasantness,UsPp- Us. The size of the change in sound pleasantness produced by the paintings (0.37 points), although reliable, is smaller than the change produced by video sources in Experiment 5B (0.58 points), even though the paintings are more visually pleasant (3.46 points) than the videos (1.29 points in SupplementalFile S2). This comparison shows an advantage in the potency of source reassignment over visual pleasantness. As an aside, we note that the pleasantness of the paintings decreased in their second silent exposure, potentially indicating that the interveningUsPpcondition may have formed associations between the paintings and the unpleasant sounds. In Experiment B it was expected that there would be a significant correlation between video only and sound only pleasantness, given their common meanings in terms of source events; however, we note that withr= 0.70, half of the variance amongst stimuli is specific to the perceptual modality and individual stimulus properties rather than being entirely determined by their common source events.\n\nBoth Experiments 5A and 5B expose listeners to the same sounds twice. This leaves open the possibility that ratings could increase with visual stimuli purely due to repeated exposure. However, because Experiment 4 found that our unpleasant sounds did not become more pleasant upon second exposure, we conclude that the results of Experiments 5A and 5B reflect true increases in sound pleasantness due to the visual stimuli in the second half.\n\nThere is a substantial difference between Experiments 5A and 5B (cf.Figs 5Band6B). Plotting the relationship betweenchangein sound pleasantness and match quality removes effects of the sound’s inherent pleasantness. It shows that the mere correlation between match and pleasantness in these experiments (cf.Figs 5Aand6A) does not provide evidence that a better matchcausesa stronger source reassignment. We posit that a strong relationship betweenchangein sound pleasantness and match quality implies that the visual stimulus is reassigning the source. Therefore, a source reassignment hypothesis is supported for videos (Fig 6) whereas it is not supported it for paintings (Fig 5). This result left open the question of what caused the change in sound pleasantness for paintings.\n\nThe results of Experiment 5A led to further questions regarding the meaning of the match ratings. Firstly, why were many of the sound-painting match ratings greater than 1 (on a scale of 1–5) for randomly paired, meaningless visual stimuli? Experiment 5C tested whether the match ratings in Experiment 5A indicate the degree of cross-modal agreement between the painting and the sound. Secondly, why do the match ratings correlateat allwith the pleasantness ratings of the sounds within the painting-sound pairs? One possibility is that paintings with better cross-modal agreement in theUsPppairs have a greater influence on the pleasantness of the sound. To investigate these questions, a study analogous to the cross-modal study in Experiment 3C was conducted. Participants were instructed to categorize each of the sounds and paintings as matching the word “maluma” or “takete” as a means of measuring cross-modal agreement.\n\nAs part of the study reported in Experiment 3C, the same 32 participants (Mage= 21.88 years; range = 18–29 years; 15 females, 13 males, four non-binary) judged whether the name “maluma” or “takete” best matched the 144 paintings used in Experiment 5A. See Experiment 3C Methods for further details. After each stimulus was categorized as being either a “maluma” or a “takete,” everyUsPppairing was categorized as being either in cross-modal “agreement” (e.g., “maluma sound with “maluma” painting) or in cross-modal “disagreement” (e.g., “maluma” sound with a “takete” painting).\n\nExperiment 5C tested the prediction that the increase inUspleasantness resulting from abstract paintings would relate to their individual cross-modal agreement in sound symbolism. Seven unpleasant sounds, eight neutral sounds, and 77 pleasant paintings were rated by more than 50% of the participants as “Maluma.” Inter-rater agreement (ICC Alpha) for unpleasant sounds, neutral sounds, and paintings, respectively, was 0.85 (F(21, 650) = 7.07,p< 0.001), 0.92 (F(21, 675) = 12.50,p< 0.001) and 0.88 (F(143, 2829) = 8.82,p< 0.001). According to a t-test for independent samples, the mean match quality rating was significantly higher for the sounds and paintings that were in cross-modal agreement (M = 2.28, SD = 1.23), than cross-modal disagreement (M = 1.74, SD = 0.90), (t(366) = 4.87,p< 0.001). The mean change in pleasantness for sounds that were in pairs with cross-modal agreement (M = 0.56, SD = 1.49) was also reliably higher than the change in pleasantness for sounds that were in pairs with cross-modal disagreement (M = 0.21, SD = 1.65), (t(366) = 2.07,p= 0.039). Therefore,cross-modal agreementbased on sound symbolismdoes account for significant variationin the match ratings in Experiment 5A, which offers an explanation as to why there were modest match ratings in that study. Additionally, because cross-modal agreement did predict the size of the effect from a pleasant painting, it also offers a mechanism for how paintings increased sound pleasantness without reassigning the sound source.\n\nAs stated earlier, thesource reassignment hypothesisposits that the neutral visual sources cause the observer to reassign the source of the sound to the depicted event, thereby increasing the perceived pleasantness of the sound. Experiments 1 and 5B revealed that alternative neutral visual sources can change the pleasantness of the sound as a function of how well the neutral visual source and sound match. We did not see such achange functionin Experiment 5A; sound pleasantness increased or decreased regardless of the match of an abstract painting. The significant slope relating changes in pleasantness as a function of match in Experiment 5B is consistent with thesource reassignment hypothesis, whereas changes in intercept only, seen in Experiment 5A, are inconsistent with it.\n\nAltogether, these experiments indicate that the perceived pleasantness of a sound can be modulated by pairing the sound with visual or semantic input, but the mechanisms for this change differ between conditions. A shift in sound pleasantness can be achieved by: (1) combining a sound with a dynamic visual source, (2) combining a sound with a text description of an alternative source, and (3) combining an unpleasant sound with a pleasant but meaningless visual image. To support these and future studies, we describe and validate a new database of openly available stimuli.\n\nOur finding that neutral videos increase the pleasantness of sounds agrees with past research [12,16,23]. We found that the increase caused by neutral videos was significantly greater for a misophonic group when we looked across our entire study, which differs from [16] which found differences in bodily sensations but not a greater effect on pleasantness for their misophonic group. Testing order is a possible reason for the difference, because they used a within-participants design in which all the positive videos were seen first, whereas our design showed half the positive and half the negative videos first. As found by others [23], we found that the response to a video depended on what had preceded it. Although the effect of neutral text descriptions on the pleasantness of an unpleasant sound is smaller than the effect of videos of neutral visual sources, text descriptions do produce robust effects that are consistent with source reassignment. Our results agree with past studies using words [10,11]. An advantage of our studies is that we show that both our visual sources and descriptions exhibit the same quantitative relationship, suggesting that they are subserved by the same mechanism. Furthermore, we show that text descriptions work for misophonic participants as well as for non-misophonics. While our sounds are mostly well-identified in isolation, ambiguity tends to help an unpleasant sound to match with, and be affected by, an alternative source. This result agrees with others showing the importance of trigger identification [6–8]. A strength of our studies is that they show that the quantitative difference between the pleasantness of the unpleasant sounds and their neutral counterparts is large enough to account for the size of the pleasantness shift caused by visual sources.\n\nFurthermore, although sound pleasantness can be altered by meaningless pleasant visual input, we conclude that visual pleasantness is not the primary underlying mechanism for the beneficial effect of the neutral visual sources. This is because visual pleasantness and source reassignment have different effects on thechange function. If the visual/semantic input alters the perceived source of the sound, the magnitude of the change in sound pleasantness associated with changing the visual/semantic input should vary systematically as a function of the plausibility match between a sound and its visual/semantic input. While other studies have measured audio-visual match [12,16,23], we propose a novel way to confirm source reassignment with achange function. We observe achange functionwhen neutral visual sources and descriptions are paired with unpleasant sounds (as in Experiments 1, 2, and 5B). In contrast, if visual input does not alter the perceived source of the sound, the plausibility match ratings should be unrelated to the magnitude of the change, even if the overall mean does shift. We observe this alternative pattern when pleasant unrelated images are paired with unpleasant sounds (Experiment 5A) and when unpleasant visual sources are paired with neutral sounds (Experiment 3A).\n\nBecause the relationship between source plausibility and change in pleasantness is central evidence for source reassignment, it is important to empirically test the meaning of the plausibility match rating when source reassignment is not evident. First, we asked why there could be a match without a meaningful visual stimulus in Experiment 5A. We found evidence that the weak-moderate match ratings between the abstract paintings and sounds were attributable to cross-modal agreement. Second, we showed with Experiments 3B and 3C that the match rating based on source plausibility in Experiment 3A was not simply a rating of audio-visual temporal alignment, nor was it a reflection of cross-modal agreement. Overall, conditions that show evidence of source reassignment do not show the effects of cross-modal agreement, and vice-versa.\n\nFinally, we ask whether the pleasantness ratings reflect feelings about the sounds, or the sources of the sounds. The high agreement in the change versus match function for Experiments 1 and 2 suggest that, for a given level of match, the source reassignment process produced the same pleasantness regardless of whether visual stimuli or written descriptions depicted the event.\n\nOne limitation of this series of studies is that we included all stimuli in all studies, even after our first study indicated which stimuli were most effective. We did this for hypothesis testing, which required a wide range of movie matches and effectiveness. However, this approach is not ideal for applications which aim to maximize effect sizes. For such cases, we recommend selecting only the most effective stimuli from our publicly available stimulus set [47].\n\nMore limitations arise because these studies were not conducted in naturalistic settings. We do not know whether the effects of source reassignment would extend beyond a few seconds, or whether they would influence sounds encountered outside the lab. Future studies in clinical settings are needed. The generalizability of our studies is limited by our sample population of young adults, which should be remedied with broader sampling methods. While movies are not a practical treatment in a natural setting, descriptions of sources have the advantage of being available via memory and without any need for technology. Our stimuli were not customized triggers for each individual because custom movies are difficult to make. Addressing an individual’s unique trigger sounds may be easier with written descriptions. However, our written descriptions had a smaller effect than our movies. It is possible that further refinement of the written descriptions could improve both their matches and effectiveness.\n\nIt is worth noting that there are other factors that shift sound pleasantness. For example, self-generated perceptual input can also modulate emotional responses to sounds. Mimicking behavior (e.g., a listener sniffs in the presence of someone else who is sniffing) is observed in misophonia and it is speculated that this may reduce the severity of the negative experience from a misophonic trigger [48]. As another example, the emotional response to a soundscape, which typically involves multiple sound sources, depends upon the relative weight given to different sound sources, with unpleasant sounds being more influential than pleasant sounds [49].\n\nGiven that everyday sounds are ubiquitous, they can be difficult to avoid. A comprehensive treatment for misophonia will need to do more than block out external sounds or avoid situations that may involve triggering unpleasant sounds. The present findings could potentially be leveraged to help with everyday exposures to triggers. First, professional treatment could involve gathering a list of triggering sounds and finding plausible alternative sources for them. Alternative sources could be shown in movies such as the ones described in this research. If movies are unavailable, our data indicate that verbal descriptions of alternative sources should also be effective. This cognitive reframing could prepare the person to imagine an alternative source whenever they hear a trigger in the real world. If an individual can draw on that experience in real-time and imagine that trigger sounds are coming from a different source, this might reduce the severity of their emotional reaction to the sound in the moment.\n\nExperiments 1, 3, and 5 revealed that movies displaying a visual source with a sound can robustly change the pleasantness of that sound. In Experiment 1, when a neutral visual source is paired with an unpleasant sound (UsNv), the unpleasant sound is rated as more pleasant than when the sound is paired with its original visual source (UsUv). In Experiment 3A, the effect is nearly equal and opposite for neutral sounds; the neutral sound is rated as less pleasant when paired with an unpleasant visual source (NsUv) than when the sound is paired with its original visual source (NsNv). The results of Experiments 1 and 5B indicate that the change in sound pleasantness from neutral visual sources is strongly influenced by the source plausibility match between the visual source and the paired sound. Specifically, a high match promotes the reassignment of the sound’s causal source. As Experiment 5A showed, visual pleasantness devoid of semantic content does not account for the effect of visual sources. In contrast, Experiment 2 shows that semantic content does account for the effect, because the written description of the neutral source events produces nearly as much of a change in sound pleasantness as the corresponding movies do. The effect of neutral visual sources is even more beneficial for misophonic than for non-misophonic participants.\n\nIn conclusion, attributing an unpleasant sound to a more neutral source may make the sounds more tolerable in the moment. We propose that achange functionbe used to determine whether a given stimulus is causing a source reassignment. Because an audio-visual match can mean multiple things, we propose that judgements about matching should be very clear about the definition of a match. Although movies produce a larger effect than words or images, presumably due to being more compelling, it is possible that purely semantic descriptions could be at least half as effective, while being much simpler to make and use. In the future, perhaps combining improved text descriptions with neutral or positive pictures would come close to being as effective as movies.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321594.s002\n\n(XLSX)\n\nList of triggers includes experimental stimuli classified as Misophonic triggers, sounds and visuals with results providing they are triggers, self-reported triggers, triggers from Misophonic questionnaires, and case study triggers.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s003\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321594.s004\n\n(DOCX)\n\naMisidentification refers to confusing the sound for its planned unpleasant counterpart or for any other sound.bNumber of participants who misidentified the neutral sound for its planned, unpleasant counterpart.cNumber of participants who misidentified the neutral sound for a unpleasant source that was not the planned counterpart.dNumber of participants who misidentified the neutral sound for another neutral sound.eOdds ratio is calculated by dividing the number of misidentifications per type (e.g., planned unpleasant source) by the number of total participants in the study.fOdds ratio for the ‘other source’ category is calculated over a combined pool of the neutral and unpleasant instances.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s005\n\n(DOCX)\n\nThe relationship between average sound pleasantness ratings forUsNvpairs and average match quality ratings forUsNvpairs in Experiment 1. The averages are calculated across two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The 22 data points represent individual unpleasant sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s006\n\n(TIF)\n\nThe relationship between average sound pleasantness ratings forUsUvpairs and average match quality ratings forUsUvpairs in Experiment 1. The averages are calculated across two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The 22 data points represent individual unpleasant sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s007\n\n(TIF)\n\nThe relationship between the change in average sound pleasantness ratings between the two audio-video conditions, and the average match quality ratings forUsUvpairs in Experiment 1. The averages are calculated across two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The changes are calculated by subtracting the average pleasantness rating the sound receives inUsNvpairing from the rating the sound receives inUsUvpairing. The 22 data points represent individual unpleasant sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s008\n\n(TIF)\n\n(A) The relationship between average sound pleasantness ratings forUsNvpairs versus average match quality ratings forUsNvpairs in Experiment 1 and Samermit et al., (2022). Data from Experiment 1 (across all participants) is indicated by yellow symbols and a solid line. Note, our pleasantness ratings were transformed from an 11-point scale to a 5-point scale to be congruent with Samermit et al., (2022). Data from Samermit et al., (2022) is indicated by purple symbols and a dashed line. Yellow symbols with a purple outline reflect movies that were borrowed from Samermit et al., (2022) to be used in Experiment 1. Each data point represents the mean rating across observers for one unpleasant sound, while the error bar reflects the standard error of the mean. (B) The relationship between average sound pleasantness ratings forUsUvpairs versus average match quality ratings forUsUvpairs in Experiment 1 and Samermit et al., (2022). (C) The relationship between the change in average sound pleasantness ratings across the two pairs (UsNv-UsUv) versus average match quality ratings forUsNvpairs in Experiment 1 and Samermit et al., (2022). The 22 data points represent the mean change for each of the unpleasant sounds and the error bars reflect the standard error of the mean across participants.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s009\n\n(TIF)\n\nThe relationship between average sound pleasantness ratings forUsNDpairs and average match quality ratings forUsNDpairs in Experiment 2. The averages are calculated across two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The 22 data points represent individual unpleasant sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s010\n\n(TIF)\n\nThe relationship between average sound pleasantness ratings forUsUDpairs and average match quality ratings forUsUDpairs in Experiment 2. The averages are calculated across two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The 22 data points represent individual unpleasant sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s011\n\n(TIF)\n\nThe relationship between the change in average sound pleasantness ratings between the two description conditions, and the average match quality ratings forUsUDpairs in Experiment 2. The averages are calculated across two mutually exclusive participant groups: Misophonics (red squares), and Non-misophonics (gray circles). The changes are calculated by subtracting the average pleasantness rating the sound receives inUsNDpairing from the rating the sound receives inUsUDpairing. The 22 data points represent individual unpleasant sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s012\n\n(TIF)\n\nThe relationship between average sound pleasantness ratings forNsUvpairs and average match quality ratings forNsUvpairs in Experiment 3A. The averages are calculated across all of the listeners in thisunscreenedgroup, irrespective of misophonic status. The 22 data points represent individual neutral sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s013\n\n(TIF)\n\nThe relationship between average sound pleasantness ratings forNsNvpairs and average match quality ratings forNsNvpairs in Experiment 3A. The averages are calculated across all of the listeners in thisunscreenedgroup, irrespective of clinically significant misophonia status. The 22 data points represent individual neutral sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s014\n\n(TIF)\n\nThe relationship between the change in average sound pleasantness ratings between the two audio-video conditions, and the average match quality ratings forNsNvpairs in Experiment 3A. The averages are calculated across all listeners in thisunscreenedgroup, irrespective of misophonia status. The changes are calculated by subtracting the average pleasantness rating the sound receives inNsUvpairing from the rating the sound receives inNsNvpairing. The 22 data points represent individual neutral sounds. The error bars reflect the standard error of the mean.\n\nhttps://doi.org/10.1371/journal.pone.0321594.s015\n\n(TIF)\n\nThe authors gratefully acknowledge research assistance from Monica Qiu, Julia Hui Liu, Shangyi Zhu, Xinyi Yin, Seojun Jang, Tunger Hong, and Sungjoon Park, as well as helpful comments on a previous version of this manuscript provided by Sungjoon Park, Amogh Ayyalasomayajula, and Nicole Navolio.",
    "category": "neuroscience"
  },
  {
    "title": "Protocol to evaluate the effectiveness of the implementation of transdiagnostic cognitive behavioural therapy for emotional disorders in primary care and its mechanisms of change: a randomized step-wedge clinical trial (PsicAP-CV)",
    "authors": "Roger Muñoz-Navarro, Virtudes Pérez-Jover, Gabriel Esteller-Collado, Carlos Van-der Hofstadt Román, Monika Salgueiro, Anna Llorca-Mestre, Elisabeth Malonda-Vidal, Vera Canet-Cortell, M. José Moraga-García, Ainhoa Coloma-Carmona, María Carpallo-González, Maider Prieto-Vila, Sara Barrio-Martínez, Ángel Aguilera-Martín, Mario Gálvez-Lara, Francisco Jurado-González, Elisa Aguirre, César González-Blanch, Paloma Ruíz-Rodríguez, Juan Antonio Moriana, Paula Samper-García, María Vicenta Mestre-Escrivá, Antonio Cano-Vindel, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320857",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320857",
    "content": "Emotional disorders (ED) are highly prevalent worldwide. The PsicAP trial, conducted in Spain, demonstrated the benefits of adding transdiagnostic cognitive behavioural therapy (TD-CBT) to treatment as usual (TAU) for the attention of these disorders in primary care (PC). Here we describe the design of a stepped wedge randomized controlled trial (RCT), inspired by the PsicAP project. This RCT has two main aims: 1) to test the implementation of the PsicAP protocol in a real clinical setting, further evaluating possible mechanisms of change underlying the efficacy of TD-CBT (emotional regulation, alliance, and therapist experience and training), and 2) to assess the impact of psychotropic medication use on neuropsychological function and treatment outcomes.\n\nA single-blind multicentre RCT with a stepped wedge design will be conducted. Participants (N=320) will be randomly assigned to an experimental group (EG1) or to a waiting list group (WG). The EG1 will receive immediate treatment and the WG will remain on the waiting list for 3 months. After this time, the WG will become a second experimental group (EG2) that will receive the same treatment as EG1 (PsicAP protocol). Patients will be assessed at post-treatment, at 3 and 9 months. Before starting treatment, a random subsample of patients (n=90) will undergo a neuropsychological assessment. These patients will be assigned to three groups based on their use of psychotropic medication at the time of randomization: no psychotropic medication, short-term use (< 3 months) and long-term use (≥ 3 months). All 90 participants will undergo the same neuropsychological assessment at one year. The RCT is expected to run from 01/05/23 to 01/10/25.\n\nThe results of this trial are expected to provide further support for the efficacy of the PsicAP TD-CBT protocol, as well as insight into the mechanisms of change that lead to the positive therapeutic outcomes of this protocol. In addition, this study will help determine the effects of short- and long-term psychotropic use on neuropsychological function and therapeutic outcomes. In short, it is hoped that this RCT will help to better understand how to implement evidence-based psychological treatment in the PC setting.\n\nEURADICT 2013-001955-11/ ISRCTN58437086.\n\nCitation:Muñoz-Navarro R, Pérez-Jover V, Esteller-Collado G, Van-der Hofstadt Román C, Salgueiro M, Llorca-Mestre A, et al.  (2025) Protocol to evaluate the effectiveness of the implementation of transdiagnostic cognitive behavioural therapy for emotional disorders in primary care and its mechanisms of change: a randomized step-wedge clinical trial (PsicAP-CV). PLoS ONE 20(4):\n           e0320857.\n        \n        https://doi.org/10.1371/journal.pone.0320857\n\nEditor:Jan Christopher Cwik, University of Cologne: Universitat zu Koln, GERMANY\n\nReceived:October 22, 2024;Accepted:February 24, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Muñoz-Navarro et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:No datasets were generated or analysed during the current study. All relevant data from this study will be made available upon study completion.\n\nFunding:This RCT is part of the R+D+i project PID2021-125965OB-I00, funding from MICIU/AEI/10.13039/501100011033 and FEDER, EU. It was also supported by the projects PID2019-107243RB-C21 and PID2019-107243RB-C22 funding from MICIU/AEI /10.13039/501100011033. Finally, this project was also supported by the José Castillejo Grant (CAS2023/00397) awarded by MCIN/AEI /10.13039/501100011033. These entities only provided funding for the recruitment of research staff and did not play any role in the trial design, data collection, analysis or drafting of this manuscript. The authors declare that they have no conflict of interest.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAbbreviations:BMQ,\n            Beliefs about Medicine Questionnaire; CERQ-27,\n            Cognitive emotion regulation questionnaire-27; COWA,\n            Verbal Fluency Test; ED,\n            Emotional Disorder; EG,\n            Experimental Group; EQ-5D-5L,\n            EuroQol; ER,\n            Emotion Regulation; ERS,\n            Emotion Regulation Strategies; GAD-7,\n            Generalized Anxiety Disorder-7; GHP,\n            General Health Psychologists; GHPM,\n            General Health Psychologists recently graduated from the qualifying master’s degree; GP,\n            General Practitioner; GSRS,\n            Group Session Rating Scale; IACTA,\n            Inventory of Cognitive Activity in Anxiety Disorders; IAPT,\n            Improving Access to Psychological Therapies; MCQ-NB,\n            Metacognitions Questionnaire-Negative Beliefs subscale; NHS,\n            National Health System; PC,\n            Primary Care; PCSP,\n            Psychologists Specializing in Clinical Psychology; PD,\n            Panic Disorder; PHQ-15,\n            Patient Health Questionnaire-15; PHQ-9,\n            Patient Health Questionnaire-9; PHQ-PD,\n            Patient Health Questionnaire-Panic Disorder; PSWQ-A,\n            Penn State Worry Questionnaire-Abbreviated; QoL,\n            Quality of Life; RCT,\n            Randomized Controlled Trial; ROFC,\n            Rey-Osterrieth Complex Figure Test; SPWB,\n            Psychological Wellbeing Scale; RRS-B,\n            Ruminative Responses Scale-Brooding subscale; SDS,\n            Sheehan Disability Scale; TAU,\n            Treatment As Usual; TAVEC,\n            Spain-Complutense Verbal Learning Test; TD-CBT,\n            transdiagnostic cognitive-behavioral therapy; TMT,\n            Trail Making Test; WAI-P,\n            Working Alliance Inventory Patient Form; WAIS-IV,\n            Letters and Numbers subtest; WG,\n            Waiting Group; WHOQOL-BREF,\n            WHO Quality of Life scale-Brief version\n\nEmotional disorders (EDs), such as depression or anxiety disorders, are the most prevalent mental health problems worldwide [1]. In Spain, the prevalence of these disorders is even higher than internationally [2]. Moreover, these disorders often manifest concurrently with each other or with other health conditions, indicating that comorbidity is a very common phenomenon [3]. EDs have a substantial impact on quality of life (QoL) and represent one of the leading causes of disability worldwide [4,5]. In addition, EDs entail significant economic costs to the healthcare system, both direct and indirect [6].\n\nIn most countries, EDs are usually addressed in the Primary Care (PC) setting by GPs [7,8], as this service is usually the gateway to the National Health System [9]. However, due to short consultation times, high care burden and poor training of GPs in psychological treatments and/or psychological diagnostic tools [9], it leads to approximately 40% of patients receiving no treatment at all and only 30% receiving evidence-based treatment [10].\n\nTypically, EDs are addressed through what is known as treatment as usual (TAU), which usually consists of the pre-prescription of psychotropic medication and/or GP counselling. However, international guidelines for the treatment of these disorders is, in the first instance and for cases with mild to moderate severity, evidence-based psychological therapy, especially cognitive behavioural therapy (CBT) [11–13]. CBT has been shown to be a very effective and cost-effective alternative for the treatment of these disorders, achieving large effect sizes in both the short and long term [14,15]. In addition, some CBT approaches, such as Trandiagnostic CBT (TD-CBT), have also shown good efficacy [16] and a very interesting option for implementation in PC [17].\n\nThe first programme to implement this evidence-based psychological approach was the flagship “Improving Access to Psychological Therapies (IAPT)” project in the United Kingdom (UK), which has become an international benchmark for the treatment of these disorders. The project involves almost 11.000 therapists (both high and low intensity) providing CBT and other evidence-based psychological therapies in a stepped-care model in which specific treatment depends on the severity of symptoms [18]. A major advantage of the stepped-care approach is that it reduces overmedication and allows clinicians to select the most appropriate treatment for each case [18].\n\nThe success of the IAPT programme encouraged the PsicAP Randomized Controlled Trial (RCT) in Spain, a project to evaluate the efficacy of evidence-based psychological therapy for the treatment of mild and moderate EDs in the Spanish PC setting [17]. This trial followed a double-arm, single-blind design, where participants (n=1061) were randomized to receive either TAU (control group) or TD-CBT+TAU (experimental group). The TD-CBT protocol consisted of 7 sessions of psychological therapy in a group format of 8–10 persons, delivered by a clinical psychologist (see information in the method section). The experimental treatment was more effective than TAU alone for reducing symptoms of depression, anxiety and somatizations, with medium to large effect sizes. The experimental treatment was also superior to TAU for improving QoL and functioning, with small to medium effect sizes. All these effects were maintained at 12 months, suggesting a long-lasting therapeutic effect. Furthermore, the observed rates of reliable recovery (≈50%) and impairment (≈3%) were similar to those achieved in the IAPT programme [10,18] and in a similar programme in Norway [19], highlighting the efficacy of the PsicAP protocol.\n\nIn recent decades, transdiagnostic treatment approaches have received particular interest from the scientific community [16,19,20]. Transdiagnostic treatments for EDs typically include components that have been shown to be effective for anxiety disorders and depression, such as cognitive restructuring, behavioural activation or exposure [21,22]. A very recent meta-analysis has confirmed that TD-CBT is as effective as specific treatments in reducing anxiety and depression, both at post-treatment and at 6-month follow-up [16]. Moreover, TD-CBT can be administered in group format, obtaining a better cost-effectiveness ratio in the medium to long term compared to other traditional formats [23,24].\n\nDue to the rise of evidence-based psychological therapies, there is a growing interest in understanding what are the mechanisms or processes of change in psychotherapy that drive positive therapeutic outcomes [25,26], as despite the fact that these treatments have shown good efficacy for the improvement of various mental disorders, there is still a significant number of patients who do not respond adequately to treatment [27,28]. Therefore, understanding the processes of change that underlie positive therapeutic outcomes may help to develop more effective psychological treatments. Thus, some studies have suggested that some of these components could be emotional regulation (ER) strategies, the therapeutic alliance, the therapist’s experience and some neuropsychological functions [29–34].\n\nEmotion regulation strategies (ERS) have been shown to have a mediating role in EDs [29,30,35], which is why improved ER is an important target of TD-CBT [36,37]. According to some authors, CBT promotes improvement in certain cognitive and behavioural ERS, which in turn reduces symptoms [30,38]. Sloan et al. [37] suggested that the effectiveness of transdiagnostic therapies can be attributed to a reduction in certain maladaptive ERS (e.g., rumination, worry and suppression) and a simultaneous improvement in more adaptive strategies such as reappraisal and distraction. Other studies of transdiagnostic approaches have found that it is possible reducing comorbidities in people with anxiety disorders [39], an approach that has also proven effective when applied in a group format in PC [40].\n\nA recent study based on data from the PsicAP trial evaluated the mechanisms of change that had the greatest impact on the efficacy of TD-CBT, showing the reduction in emotional symptoms and improvements in functioning and QoL were mainly attributable to a treatment-related decrease in maladaptive strategies such as worry, rumination, and negative metacognition [41]. Although that study found that adaptive ERS did not appear play a significant role in treatment outcomes, more data are needed to determine whether adaptive ERS play a mediating and moderating role in symptom reduction, QoL, and functioning.\n\nThe therapeutic alliance has been shown to play a key role in treatment outcomes [34,42]. A meta-analysis examining the correlation between the therapeutic alliance and treatment outcomes found that the therapist’s contribution to the alliance appears to play an important role in improving patient outcomes [34]. Other studies have shown similar results [31,42]. In addition, some studies have pointed out that the therapeutic alliance is closely related to therapeutic dropout [43,44]. This is a key issue, as therapeutic dropout has been shown to be one of the main factors that reduce the effectiveness of psychological therapy [45–47].\n\nRecent meta-analyses have shown that treatment discontinuation is a serious and widespread problem in psychotherapy, affecting approximately one in five patients (20%) [48,49]. Dropout rates are even higher in patients with anxiety and depressive symptoms [50]. In the PsicAP trial, approximately 60% of randomized patients completed the treatment protocol and/or attended the post-treatment assessment. In the experimental group, patients attended on average, five of the seven sessions. However, 11% of patients attended only 0–1 session. While the reasons for this are unclear, it clearly merits further investigation [17].\n\nTherapist experience may also play an important role in treatment outcomes [51,52]. Our group has previously demonstrated the efficacy of highly trained clinical psychologists in the PsicAP trial [17]. However, in other projects such as IAPT, therapists have different levels of training (low and high intensity), showing that it is possible to safely and effectively include professionals from various health care backgrounds in mental health care, as long as they have received specialised training in evidence-based psychological treatment protocols [18].\n\nWith this in mind, in this trial we will assess the therapist-patient alliance, the alliance between patients within the group, and include therapists with different levels of training and experience. We hope that this will help to better understand positive therapeutic outcomes as well as factors leading to dropout.\n\nA recently published study on global trends in the consumption of psychotropic medication has pointed out that global sales of psychotropic drugs have increased at an average rate of 4% per year, from 28.5 daily doses per 1,000 inhabitants (DDH) in 2008 to 34.7 DDH in 2019 [53]. This has led to an overall increase in the prescription and consumption of psychotropic drugs, which in turn has led to an excessive overmedicalization of daily life [54,55]. In Spain, the latest report of theSubdirectorate General for Health Informationhas also confirmed this steady increase in the prescription of psychotropic medicines [2].\n\nThis high consumption of psychotropic drugs, as well as the resulting social, personal and economic costs, has led multiple authors to question the real efficacy of these drugs for the treatment of EDs [56–61], as although their use and prescription has increased, the overall trend of EDs has also increased [4,62]. A comprehensive meta-analysis comparing CBT against control conditions, other psychological therapies, pharmacotherapies and combination treatments for depression has recently been published [63]. Results showed that CBT and pharmacotherapy did not differ in the short term, but did differ in the long term (6 and 12 months follow-up), where CBT was more effective. Combined drug treatment was more effective than pharmacotherapies alone in the short and long term, but was not more effective than CBT alone at either time point. This has led to the suggestion that, although these medications may alleviate mood symptoms, they may also lead to emotional blunting that goes against the very essence of CBT [64]. Indeed, it is possible that withdrawal symptoms and some side effects such as increased anxiety, insomnia and agitation may make it difficult to engage in therapy [64–66]. In summary, the role of pharmacotherapy in the treatment of EDs is currently unclear.\n\nNeuropsychological impairment is a common subjective complaint in EDs patients. Objective neuropsychological testing often reveals deficits in several cognitive domains, including processing speed, attentional processes, memory, verbal learning, executive function and working memory [67]. The presence of these impairments is considered a prognostic factor for poor response to treatment and reduced functional recovery [68]. Studies involving patients treated with psychotropics have consistently shown that these patients perform worse in verbal fluency, cognitive inhibition, visuospatial memory, verbal learning, working memory and executive function [32,69,70]. Some authors have reported an increased risk of cognitive impairment, including dementia, in patients treated with antidepressants for prolonged periods, especially selective serotonin reuptake inhibitors [71,72]. Tricyclic antidepressants, in addition to their effects on serotonin and noradrenaline reuptake, also have antihistamine effects that may produce drowsiness and some degree of sedation, which may negatively affect performance in activities of daily living, as evidenced by poorer performance on neuropsychological assessment tasks [73]. Prolonged treatment with tricyclic antidepressants has been shown to negatively affect cognitive performance [33,74], and these effects persist even after depressive and/or anxious symptoms have clinically improved [75]. Anticholinergic drugs, which are sometimes prescribed to treat depressive disorders, have been associated with poorer performance on neuropsychological assessment tasks, and exhibit greater cognitive impairment [76].\n\nMany different cognitive processes are involved in the performance of CBT tasks, so medication-related cognitive impairment may negatively affect therapeutic outcomes. Although some studies have evaluated the effects of standard psychopharmacological treatments on neuropsychological processes, the results are still heterogeneous [61,77]. Despite the importance of this issue, to our knowledge no study has directly assessed the effects (especially the medium- to long-term effects) of antidepressants or anxiolytics on cognitive and psychosocial functioning in people with EDs.\n\nThe results of the PsicAP trial showed that it was possible to offer, from the PC setting, evidence-based psychological therapy in a safe and effective way to people with mild and moderate EDs [17]. However, this RCT did not analyze some variables that, as seen above, may be particularly relevant for therapeutic efficacy and dropout, such as the therapeutic alliance, the therapist’s experience and training, or the influence of the state of neuropsychological functions on the therapy process. Moreover, in the PsicAP trial, only a part of the included patients (experimental group) received the best available treatment (TD-CBT+TAU).\n\nThe PsicAP-CV trial aims to follow the path initiated by PsicAP, but adding some aspects that may help to complement and overcome the initial limitations. First, the PsicAP-CV trial will follow a Stepped Wedge design [78]. In this type of design, patients are assigned to an experimental group that receives immediate treatment (EG1) or to a waiting list group (WG) that, after a certain period of time, becomes a second experimental group (EG2) and receives the same treatment as the other group (see more details in the methods section). This allows all patients included in the RCT, either before or after, to receive the best available treatment, thus overcoming some important ethical issues. Furthermore, this design enables us to evaluate whether the effect of therapy varies based on the patient’s waiting time, as it is plausible that longer waiting periods may lead to more severe symptoms and greater impairment, thereby making recovery more challenging and complex [79,80]. This design also allows patients to be treated in a staggered manner, allowing more patients to receive treatment as time goes by, but without collapsing resources at a particular point in time. This is a fundamental aspect, as it is an effective RCT in the PC setting, where resources are very limited and there is often not enough staff or physical space to treat all patients simultaneously [9].\n\nAnother novelty of the PsicAP-CV trial is the addition of 3 extra sessions to the original PsicAP protocol (7 sessions). As previously noted, not all patients in the PsicAP trial achieved clinical recovery, so it is necessary to continue working to improve the therapeutic results. With this in mind, in the PsicAP-CV trial, only those people who have received the PsicAP therapy protocol (in group) and have not achieved clinical recovery will be offered three additional (individual) sessions on a monthly basis. It is expected that these sessions will help to work on certain specific contents that may contribute to the patient’s final recovery.\n\nFinally, as mentioned above, the PsicAP-CV trial will measure the therapeutic alliance, include therapists with different levels of training and experience (similar to IAPT), and a sub-sample of patients will undergo a study of neuropsychological function (see more details in the methods section).\n\nWe aim to conduct an effectiveness RCT to assess the effectiveness of the PsicAP protocol in real-life clinical practice. This trial has two main objectives. First, to conduct a stepped wedge RCT to replicate the findings of the PsicAP trial, which showed that TD-CBT+TAU was more effective than TAU alone, in 6 PC centres in the Valencian Region (3 in Alicante and 3 in Valencia). Results were be assessed at three time points: immediately following treatment completion (posttreatment) and at 3 and 9 months (to determine whether the posttreatment results are maintained over time). The second main objective is to perform a neuropsychological assessment (working memory, executive function and attentional control) in a subsample of patients (n=90) included in the trial to determine how the short- and long-term use of psychotropic medications prior to treatment allocation affects cognitive function. A secondary objective is to evaluate potential mechanisms of change (ERS, therapist experience, and therapeutic alliance) that may influence the effectiveness of TD-CBT. The results of this study may help health care managers and clinicians to more precisely select the optimal treatment approach for specific patients or certain subpopulations, thus reducing the use of ineffective therapies.\n\nFirstly, we expect the therapeutic outcomes (symptoms, quality of life and functioning) of the EG1to be significantly better than those obtained in the WG. We also expect the therapeutic outcomes of EG1to be significantly better than those of the EG2group. Furthermore, we expect that the improvements obtained in EG1and EG2, respectively, will be maintained at 3- and 9-month follow-up.\n\nSecond, we expect therapeutic outcomes to be better in groups led by highly experienced therapists than in groups led by less experienced therapists. In addition, highly experienced therapists will have a better therapeutic alliance, better retention rates and higher attendance rates than groups led by less experienced therapists. Finally, therapeutic outcomes are also expected to be better in groups led by therapists who achieve a higher therapeutic alliance versus those led by therapists with a lower therapeutic alliance.\n\nFinally, patients who use psychotropics for ≥ 3 months are expected to have less symptom reduction than patients who do not use psychotropics or who have taken psychotropics for <three months. Also, patients taking psychotropics for ≥ 3 months are expected to have more neuropsychological disturbances and worse ER than patients who do not use psychotropics or who have taken psychotropics for < 3 months.\n\nA single blind, multicentre RCT will be carried out at 6 PC centres in the Valencian region of Spain (Alicante and Valencia), following the same method described in the original PsicAP trial [81], but modified to perform an effectiveness trial. In this stepped wedge design, participants who meet the inclusion criteria will be assigned in one “Treatment Package” and blindly randomized to one of two groups: 1) an experimental group (EG1; TD-CBT+TAU) or 2) a waiting list group (WG; TAU alone). The treatment (EG1) will consist of seven sessions of TD-CBT delivered once per week over a three-month period. Upon completion of the treatment program in EG1, all pretreatment variables will be reassessed and both groups (EG1vs. WG) will be compared. Afterwards, patients in the WG will be allocated to receive the same treatment (TD-CBT+TAU), thus forming a second experimental group (EG2). This group will receive the same treatment as EG1, but delivered approximately three months later. Follow-up assessments will be performed in both experimental groups (EG1and EG2) at 3 and 9 months after the posttreatment assessment. Data from these assessments will be used for the within-group analyses. The final 9-month follow-up assessment will be performed approximately one year after the pretreatment assessment (Figure 1).\n\nEG1: experimental group 1; EG2: experimental group 2; WG: Waiting Group; TAU: treatment as usual; TD-CBT: transdiagnostic cognitive‐behavioural therapy.\n\nEG1: experimental group 1; EG2: experimental group 2; WG: Waiting Group; TAU: treatment as usual; TD-CBT: transdiagnostic cognitive‐behavioural therapy.\n\nhttps://doi.org/10.1371/journal.pone.0320857.g001\n\nEach Treatment Package will include several treatments and conditions:\n\nTherefore, each will have three different conditions:\n\nThe study was approved by the National Scientific Research Ethics Committee in Spain, conducted in accordance with the Declaration of Helsinki (EUDRACT: 2013-001955-11) and the study protocol was registered (ISRCTN58437086). All participants gave their written informed consent.\n\nTo determine the sample size needed for our stepped wedge trial we used the swCRTdesign package in R. Assuming a dropout rate of 20%, the study will include at least 320 patients, equally distributed in the EG1and WG groups (160 per group). With this sample size, the result will be statistically significant when making comparisons between groups, even if they differ by one point only on the subscales of the PHQ measures, with a standard deviation of 5 (83% statistical power). This will allow us to conclude that the outcome is different for each group at a 95% confidence level. As this was an RCT conducted in a medical-healthcare setting, an intracluster correlation (ICC) of.01 was assumed in the calculations [82].\n\nFor the first overall objective, we aim to include 320 patients, 160 treated by TD-CBT+TAU in EG1and 160 treated with TAU alone in the WG. Patients will be randomly assigned to EG1or WG in a 1:1 ratio. Assuming 16 treatment packages with 20 patients each (10 assigned to EG1and 10 to WG), 160 patients will be included in each group. All WG groups will be assigned to receive TD-CBT+TAU (EG2) approximately 3 months after the start of treatment in EG1. At the end, a total of 320 patients will receive TD-CBT+TAU (EG1+ EG2) (fig 2).\n\nEG1: Experimental Group 1; EG2: Experimental Group 2; TD-CBT group is plus TAU; TD-CBT: Transdiagnostic-Cognitive Behavioral Therapy; TAU: Treatment as Usual; WG: Waiting Group.\n\nEG1: Experimental Group 1; EG2: Experimental Group 2; TD-CBT group is plus TAU; TD-CBT: Transdiagnostic-Cognitive Behavioral Therapy; TAU: Treatment as Usual; WG: Waiting Group.\n\nhttps://doi.org/10.1371/journal.pone.0320857.g002\n\nThese 320 patients will be included in two different clusters, as shown infig 3. Cluster 1 will allow us to compare the EG1and WG groups to determine the most effective treatment approach (i.e., TAU alone or TD-CBT+TAU). Cluster 2 will allow us to compare the two experimental groups, EG1vs. EG2, to determine whether psychological treatment provides the same therapeutic benefits 3 months after being on the waiting list.\n\nEG1: Experimental Group 1; EG2: Experimental Group 2; TD-CBT group is plus TAU; TD-CBT: Transdiagnostic-Cognitive Behavioral Therapy; TAU: Treatment as Usual; WG: Waiting Group.\n\nEG1: Experimental Group 1; EG2: Experimental Group 2; TD-CBT group is plus TAU; TD-CBT: Transdiagnostic-Cognitive Behavioral Therapy; TAU: Treatment as Usual; WG: Waiting Group.\n\nhttps://doi.org/10.1371/journal.pone.0320857.g003\n\nFor the second overall objective, we will select 90 patients from the total sample included in the trial using a computer-generated random sequence. This subsample of 90 patients will be divided into three different groups: no psychotropic medication, short-term use (< 3 months) and long-term use (≥ 3 months). From all these patients, both prescription and use of psychotropic drugs will be collected, in order to study possible discrepancies in the results. It is expected that each group can have about 30 patients and be relatively equal. The 90 patients will undergo an additional assessment by a research psychologist with specific training in neuropsychology that will last approximately 1 hour. During this session, the patient will complete the neuropsychological test battery specified inTable 1. This subsample of patients will be assessed before the start of TD-CBT (if they belong to the WG they will be assessed 3 months after the initial screening session, as this is the established waiting time before becoming EG2) and at 12 months.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320857.t001\n\nPatient recruitment will be performed by general practitioners (GPs) at the six participating PC centres. Participating GPs who identify a patient with a suspected diagnosis of an ED will invite the patient to participate in the trial. The patient will be given an information sheet describing the trial and asked to sign an informed consent form. Once the consent form has been signed, a psychologist will contact the patient to schedule an initial appointment during which the psychologist will 1) ensure that the patient meets the inclusion criteria and 2) administer the study instruments (see below for more detailed information).\n\nPatients included who meet the criteria of any of the three groups of pharmacological treatment will be invited to participate in the neuropsychological assessment until a total of 90 patients (30 per group) have been recruited. Once the patients will be randomly assigned to the psychological therapy (EG), and before initiating the sessions, the neuropsychological assessment will then be scheduled and, at this time, the participant’s psychotropic use will be recorded.\n\nGiven the characteristics of the trial, patient recruitment dates to complete a post-treatment sample of 200 patients are expected to be between 01/05/2023 and 01/12/2024. The approximate end date of the trial, including 3- and 9-month follow-ups of the last patients recruited, is estimated to be around 01/10/2025.\n\nThe study sample will comprise patients with mild, moderate, or moderate-severe symptoms of anxiety and/or depression. For inclusion, patients must meet the pre-determined cut-off score on at least one of the two study scales: GAD-7 (≥10) or PHQ-9 (≥10)[83,84].\n\nExclusion criteria are as follows: severe mental disorder (e.g., bipolar or personality disorder); substance use disorder; recent suicide attempt; severe disability according to the Sheehan Disability Scale (≥ 25 total points on the first three items); and severe mood disorder (≥ 23 points on the PHQ-9 depression subscale). Note that patients who score 20–23 points on the PHQ-9 depression subscale may be eligible for inclusion pending a clinical interview to rule out severe depression [83]. Patients who do not reach the minimum cut-off points on the GAD-7 or PHQ-9 and those who do not meet criteria for a probable ED will be excluded. Patients who are excluded from the study but suspected to have a severe mental disorder will be referred to their GP for further evaluation and treatment, including a possible referral to specialized care.\n\nThe experimental group will receive a total of seven sessions (1.5 h/session) of TD-CBT delivered in small groups (8–10 persons). The programme will be delivered over a period of 10–12 weeks (approximately 3 months). Initially, sessions will be scheduled weekly, however, over time, the interval between sessions will be progressively increased (to see more information [85]). After the seven regular sessions of the original PsicAP protocol, those patients who do not obtain a reliable recovery in the post-treatment assessment will be eligible to receive up to three individual therapeutic sessions in the following three months (one session per month). These sessions will work on individual aspects of each patient’s situation using the transdiagnostic tools provided during the group protocol. It is hoped that in this way the person will learn to apply these tools more specifically and achieve reliable recovery.\n\nThe TAU group will receive the standard treatment prescribed by their GP in routine clinical practice [86]. The specific treatment will depend on the individual GP (usually either pharmacological treatment or observation).\n\nThree types of therapists will participate in this trial, all of them university graduates: Psychologists Specializing in Clinical Psychology (PSCP), General Health Psychologists (GHP) and General Health Psychologists recently graduated from the qualifying master’s degree (GHPM). To work as a PSCP in the Spanish National Health System (NHS), it is necessary to complete an Internal Residency Programme (IRP) in the NHS, which consists of 4 years of work and training under the supervision of a specialist. The PSCPs in this trial have more than 30 years of experience. GHP are psychologists qualified to work in the health care setting, who in our trial have at least 10 years of clinical experience. Finally, GHPMs are GHPs who are recent graduates of the qualifying master’s degree and who have 1 year of clinical experience. As can be seen, there is a hierarchy in the level of training and experience among therapists, with PSCPs being the most competent psychologists. Throughout the trial, GHPs, and especially GHPMs, will be supervised by PSCPs in regular clinical sessions.\n\nIn addition to regular training, all therapists will undergo a standardized training programme on the PsicAP protocol, conducted by a supervisor and trainer. This training consists of studying the Therapist Manual, four internet-based lessons on the content of each session and a face-to-face session with the trainer. This course must be completed before any psychologist can provide group therapy as part of the trial.\n\nGiven that the drop-out rate in this type of trial can be high (especially in medium and long-term follow-up), two strategies will be implemented. On the one hand, during the psychological treatment, during sessions 2 and 4, a small amount of time will be dedicated to reminding patients of the importance of adherence to therapy and homework tasks. On the other hand, after the post-treatment assessment, a psychologist from the project will make phone calls to patients every six weeks (approximately 10–15 minutes). The purpose of these calls is to reinforce the therapeutic strategies learned during the group sessions and to monitor the emotional well-being of the participants. It is hoped that these strategies will help reduce drop-out rates.\n\nAn overview of the assessment measures is provided inTable 1[83,84,87–109]. The sequence of data collection is shown inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320857.t002\n\nData will be analysed and coded using SPSS (v.29.0), MPLUS and R. To assess treatment efficacy, primary analyses will be conducted on an intention-to-treat (ITT) basis and compared with secondary analyses on a per-protocol (PP) basis. The ITT-based approach preserves randomization of participants and includes all initially included patients. This approach has proven to be more robust than PP approaches in RCTs, especially when wanting to assess the pragmatism and implementation of a treatment in real-world settings [110], one of the main objectives of this stepped wedge RCT.\n\nGeneral Linear Mixed Models (GLMM) will be used for the analysis of treatment effectiveness, as these models have been shown to be particularly useful when working with data that have a hierarchical or cluster structure, such as longitudinal or repeated measures data [111,112]. In all cases, time (pre-treatment; post-treatment; 3 and 9 months) and group (EG1or WG/EG2) will be included as fixed effects, and subjects, treatment package and therapist as random effects. The main interactions of each model will also be studied. In addition, pre-treatment scores for each target variable, age, level of incomes, gender and educational attainment will be introduced as covariates. In all models, fixed, random and covariate effects will be held constant and only the target dependent variable will be modified: anxiety, depression, QoL, functioning or ERS. For the analysis of neuropsychological function (attention, memory, learning, etc.) we will proceed in a similar way, but we will include the variable time of taking drugs (not taking < 3 months, ≥ 3 months) as another fixed effect to be studied. In all analyses an α level ≤.05 will be set and effect sizes will be calculated using the Morris d, which takes into account the mean and standard deviation of the sample at both the final assessment and at baseline, resulting in a more representative effect size [113].\n\nFinally, recovery, reliable recovery and deterioration rates will also be calculated. These analyses only take into account anxiety (GAD-7) and depression (PHQ-9) scores. Recovery rate can be defined as pre-treatment scores at or above the inclusion threshold on either scale (≥10) and below the threshold on both scales at post-treatment assessment (<10). The reliable recovery rate will be calculated using a change score based on the standard deviation and Cronbach’s alpha of each measure to account for measurement errors of the scales [114]. Thus, a change score ≥ 5 will be used for the GAD-7 and ≥ 6 for the PHQ-9. Thus, those patients who achieve recovery, and furthermore do so with these change scores on at least one of the two subscales, will be categorized as reliable recovery. Finally, deterioration will be defined as an increase in score on either scale compared to pre-treatment, while meeting the change score criteria described for reliable recovery on at least one of the two scales.\n\nThe results of this trial are expected to improve our understanding of evidence-based transdiagnostic psychological treatment in the PC setting. The PsicAP treatment protocol has been proven to reduce symptoms and improve functioning and QoL in patients with different EDs [17]. Studies carried out to investigated psychological processes related to transdiagnostic treatment [41,115] have identified several mechanisms of change and ERS are associated with treatment outcomes. The next step is to evaluate whether other mechanisms of change, including other adaptive ERS, therapist experience, and therapeutic alliance, play a role in improving treatment adherence and outcomes. This trial will also assess the impact of antidepressant and/or anxiolytic use on neuropsychological function and how this influences treatment effectiveness.\n\nWe expect this effectiveness trial to provide novel insights into the practicality of implementing the PsicAP protocol in PC settings in the real-world. We also hope to study the differential impact of different degrees of therapist experience and therapeutic alliance to treatment on programme outcomes. Previous studies have shown that a lack of therapeutic alliance (or within-group alliance) is an important barrier to success in psychological therapy in PC, especially in patients with symptoms of anxiety and depression [50]. In this regard, it may be possible to improve treatment adherence by obtaining a better understanding of the influence of therapeutic processes such as therapist experience and therapeutic alliance. In fact, an important aim of this project is to examine how certain factors influence treatment adherence. For example, a recent study based on IAPT data [116] found that patients who self-referred were more likely to attend their appointment. That study also found that other factors—older age, fewer previous referrals, and consenting to receive reminder messages—also increased the probability of attending the sessions. Also, there is an association between psychotropic use and adherence. A meta-analysis by Swift et al. [49] found that patients on pharmacotherapy had a higher dropout rate than patients receiving psychotherapy alone. In that study, patients with depressive disorders on pharmacotherapy were 1.26 times more likely to drop out than those receiving psychological treatment.\n\nA novel aspect of this clinical trial is the study of the impact of psychotropics (antidepressants and anxiolytics), particularly long-term use, on neuropsychological function and how these changes influence treatment outcomes. It is crucial to understand this relationship, particularly given the growing use of psychotropics in many countries, including Spain, where 8,6% of adults are taking antidepressants. Despite the widespread use of antidepressants, long-term safety and effectiveness data are scant, mainly because most studies performed to date (many with important methodological limitations) have only evaluated the short-term effects (6–8 weeks) [57,60]. In this trial, we expect to present long-term follow-up data to better elucidate the long-term neuropsychological effects of psychotropic drugs in patients with ED. This trial will help also to provide data on the effects of both short and long-term use of psychotropics on patients’ mental health and well-being, in terms of emotional symptoms, QoL, therapeutic effectiveness, and neuropsychological function. This will show how common medications used to treat depression and anxiety affect patients’ ability to participate in and benefit from psychological therapy. Preliminary data from some studies show that the prescription of psychotropics may negatively affect therapeutic outcomes [117,118]. This trial should help clarify the effects of these medications, both on cognitive function and treatment outcomes, and could help to determine whether minimizing the duration of exposure to these medications could improve well-being. If true, this would improve treatment effectiveness and QoL.\n\nThis RCT has several potential limitations. First, although the stepped wedge design allows for masked randomization, treatment outcomes can only be assessed at the posttreatment assessment, as the WG will be switched to an experimental group (TD-CBT) after that analysis. This means that follow-up at 3 and 9 months will be only comparable for within-groups analyses, which could increase the risk of bias. However, assuming that the posttreatment and follow-up results are similar to those obtained in the original PsicAP trial, we could infer that the long-term effects are explained by adding TD-CBT to TAU. There is also another component that may interfere with the results of the WG group, the expectation of receiving psychological therapy. In this sense, it is possible that patients randomized to the WG group improve their scores more before starting group therapy than a strict control group where the patient knows that he/she will not receive psychological treatment. However, this may also be a window of opportunity to compare the results with the original PsicAP data, as this could be an indication for future studies on the psychological effect of therapeutic hope. Likewise, in stepped wedge designs, there is also the possibility of a higher experimental mortality rate in EG2, as some WG patients may change their initial situation due to the effect of time and drop out or be excluded from the RCT before starting the experimental treatment. This is in addition to the fact that the drop-out rate in this type of RCTs conducted in PC is usually high [119]. To mitigate the effects of this limitation, an ITT data analysis approach will be used, which as discussed above is suitable for this type of RCT and helps to reduce potential biases related to experimental dropout.\n\nAnother important limitation is the possible difference in therapeutic alliance and adherence generated by different types of therapists, which may lead to a higher dropout rate or worse therapeutic outcomes. However, although this may be seen as a limitation, it is also one of the main study objectives of this RCT and may provide important information on the feasibility and safety of including therapists with different levels of training and experience in the PC setting. Finally, there are some limitations related to the accuracy of the data on psychotropic drug use and the neuropsychology sub-study. Firstly, there may be a difference between the prescriptions made by the general practitioner and the actual consumption by the patient. Secondly, it is possible that the sub-sample of neuropsychologically assessed patients may present a high level of heterogeneity in terms of the number of patients per subgroup of psychotropic drug use. To mitigate these limitations, we will collect both prescription and actual consumption data. We will also record the type of drug (antidepressant, anxiolytic or hypnotic); the time of use (expressed in months); and the daily dose.\n\nThe results of this trial could have several important clinical implications. First, it will demonstrate the potential impact of short- and long-term psychotropic use on cognitive function, emotional symptoms, functioning, and QoL. If, as we suspect, our results show that these drugs have a negative impact on treatment outcomes, this could provide further support for the greater use of evidence-based non-pharmacological and transdiagnostic strategies [16,17]. This is of particular relevance since, as noted in the introduction, a significant number of current patients develop a high level of dependence on psychotropic drugs, as well as a strong withdrawal syndrome at the time of treatment discontinuation [77]. Our findings could help to reduce daily overmedicalization of mild and moderate psychological problems and introduce more effective, potentially less harmful and increasingly preferred solutions for patients [120]. Furthermore, as other studies internationally have already pointed out, reducing the use of purely pharmacological strategies for the treatment of EDs in the PC setting can save large amounts of money for the NHS [18,121]. Second, the use of a stepped wedge design, together with the individualized therapy option in patients who fail to achieve a reliable recovery (even after completing TD-CBT), may provide support for the value and feasibility of implementing stepped care model for mental health treatment, similar to the offered the IAPT in the UK. In this stepped-care model, patients with mild or moderate disorders would receive the PsicAP protocol (TD-CBT in group format), while those with more severe ED would receive a “boost” in the form of up to three individual sessions. This stepped care model [122] could also help to reduce over-medication and thus reduce costs to the healthcare system [123].\n\nIn conclusion, we expect that this effectiveness trial will help to better understand how to implement an evidence-based psychological treatment protocol in the Spanish PC setting in order to improve treatment outcomes versus TAU while simultaneously reducing the costs (both direct and indirect) associated with EDs, both in the short and long term.\n\nWe thank all member of the PsicAP Research Group who participated in this large project.",
    "category": "neuroscience"
  },
  {
    "title": "Phenotypes of painful TMD in discordant monozygotic twins according to a cognitive-behavioral-emotional model: a case-control study",
    "authors": "Laís Valencise Magri, Melissa de Oliveira Melchior, Graziela Valle da Silva, Edilaine Cristina da Silva Gherardi-Donato, Christie Ramos Andrade Leite-Panissi, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320515",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320515",
    "content": "This case-control study aimed to investigate variables based on a cognitive-behavioral-emotional model related to the development of painful temporomandibular disorders (TMD) in a sample of monozygotic twins discordant for the condition.\n\nThis case-control study investigated 20 monozygotic twins (10 pairs discordant for painful TMD), aged between 18 and 55. Participants were recruited through a comprehensive strategy following ethical approval, with inclusion criteria disseminated via social media, websites, local radio, messaging apps, and physical posters in public and healthcare spaces in Ribeirão Preto.The diagnosis of painful TMD was determined according to the Diagnostic Criteria for Temporomandibular Disorders - Brazilian Portuguese (DC/TMD). The cognitive-behavioral-emotional variables analyzed were a sociodemographic profile, pain sensitivity (pain threshold to pressure, allodynia, and hyperalgesia), oral behaviors, pain vigilance and awareness, pain catastrophizing, central sensitization, stress, anxiety, depression, alexithymia, mindfulness facets, sleep quality, pain control, pain intensity and interference, trigeminal and extra trigeminal pain areas. Bivariate logistic regression models were used to identify factors associated with TMD (p < 0.20), followed by multicollinearity analysis using Spearman’s correlation to exclude highly correlated variables. The final multiple logistic regression model included independent predictors to ensure robustness and accurate estimates, with statistical significance set at α = 0.05.\n\nWhile the adjusted model did not identify statistically significant associations, variables such as increased pain sensitivity in the masseter muscle (OR = 3.29, 95% CI: 0.17–62.8, p = 0.428), higher levels of pain catastrophizing (OR = 1.08, 95% CI: 0.64–1.8, p = 0.776), difficulty in externalizing feelings (OR = 1.61, 95% CI: 0.13–2.9, p = 0.539), and higher scores on the distraction facet of mindfulness (OR = 4.65, 95% CI: 0.39–55.7, p = 0.225) were included due to their clinical relevance and their significant associations in the bivariate analysis (p < 0.20).\n\nOur study highlights the potential clinical relevance of cognitive-behavioral-emotional variables, such as increased pain sensitivity in the masseter muscle, higher levels of pain catastrophizing, difficulty in externalizing feelings, and higher scores on the distraction facet of mindfulness, in understanding painful TMD. While these variables did not show statistical significance in the adjusted model, their inclusion underscores the importance of exploring these factors in clinical practice. Further research is needed to validate these findings and clarify their role in the development and management of painful TMD.\n\nThis study underscores the importance of cognitive-behavioral-emotional factors in the context of painful TMD, suggesting that variables like pain sensitivity and emotional regulation may be valuable for clinical assessment and management strategies. Despite the lack of statistically significant associations, these findings provide a foundation for future research to better understand and address the multidimensional nature of TMD in clinical practice.\n\nCitation:Magri LV, Melchior MdO, da Silva GV, Gherardi-Donato ECdS, Leite-Panissi CRA (2025) Phenotypes of painful TMD in discordant monozygotic twins according to a cognitive-behavioral-emotional model: a case-control study. PLoS ONE 20(4):\n           e0320515.\n        \n        https://doi.org/10.1371/journal.pone.0320515\n\nEditor:Cristiano Miranda de Araujo, Tuiuti University of Parana: Universidade Tuiuti do Parana, BRAZIL\n\nReceived:July 17, 2024;Accepted:February 19, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Magri et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The data are held in a public repository 10.5281/zenodo.13851455.\n\nFunding:This study was financed by the São Paulo Research Foundation (FAPESP - 2022/05658-3, under coordination of Edilaine Cristina da Silva Gherardi-Donato). This study was also financed by the Coordination for the Improvement of Higher Education Personnel (CAPES, Brazil, Finance Code 001, under coordination of Christie Ramos Andrade Leite-Panissi). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\nTemporomandibular disorders (TMD), specifically those associated with pain, are currently understood as a set of signs and symptoms that designate a painful musculoskeletal syndrome, often linked to multisystemic changes, including alterations in behavior, emotional status, and social interactions. These manifestations are recognized as expressions of central nervous system dysregulation. Among the main predictors for the development of painful TMD are the presence of comorbidities, self-reported parafunctions, the frequency of somatic symptoms, poor sleep quality, and genetic and epigenetic factors. It is important to note that self-reported parafunctions, while not classified as orofacial or somatic symptoms, represent behavioral factors that contribute to the risk of TMD. This study focuses on the painful subtype of TMD, which is of particular clinical relevance due to its impact on quality of life and its association with chronic pain mechanisms [1,2].\n\nPainful TMD includes diagnoses such as myofascial pain, arthralgia, and headaches attributed to TMD, all of which are characterized by chronic orofacial pain and functional limitations. These painful subtypes differ from intra-articular TMD, which may present with joint noises or movement restrictions without significant painful discomfort. The specificity of diagnosing painful TMD is guided by the Diagnostic Criteria for Temporomandibular Disorders (DC/TMD), which allows for the accurate identification of patients experiencing TMD for the last month. By focusing on painful TMD, this study seeks to investigate the cognitive-behavioral-emotional factors that contribute to the onset and persistence of pain in this specific population, differentiating it from the broader spectrum of TMD presentations [3].\n\nThe involvement of aspects with a cognitive-behavioral-emotional dimension in the manifestation of painful TMD has been increasingly studied, the identification of phenotypes at higher risk of developing the condition. The perception of TMD signs and symptoms is significantly modulated by emotional and social factors, which are associated with the multidimensionality of pain. Women with high levels of anxiety and stress are at higher risk of developing myofascial pain, and personal traits of anxiety, stress, catastrophizing, and hypervigilance are strongly associated with the diagnosis of painful TMD [4–6].\n\nPain sensitivity, including thresholds for allodynia and hyperalgesia, is significantly influenced by cognitive and emotional factors such as pain catastrophizing, anxiety, and stress, which modulate pain perception at both the sensory and central levels. Similarly, oral behaviors and pain vigilance are shaped by learned behavioral responses, driven by cognitive appraisals and emotional states such as fear of pain or hypervigilance. Central sensitization, often linked to physiological mechanisms exacerbated by emotional stress and cognitive distortions, further underscores the importance of including these variables in the cognitive-behavioral-emotional model of pain perception [7,8].\n\nIdentical (monozygotic) twins have always intrigued researchers since they present the same genotype at birth and develop, throughout life, differentiated phenotypes, becoming completely different individuals. In the last decade, several studies with discordant monozygotic twins have been published because, with this methodology, It is possible to establish a case-control study design in which several variables can be controlled, as they are shared between siblings, including genetic material, social environment (if raised in the same family), age, gender, and other factors [9,10].\n\nThe influence of the social environment on the development of chronic pain, combined with the presence of specific genetic polymorphisms, has been widely studied. The OPPERA study analyzed 300 genes that could be associated with the development of painful TMD; among these, six SNPs (single nucleotide polymorphisms) were identified as risk factors for chronic TMD, while six others were associated with intermediate phenotypes for painful TMD [2,11].\n\nFew studies specifically addressing monozygotic twin populations have been conducted regarding painful TMD. These studies suggest a genetic component in the manifestation of the condition, evidenced by a higher degree of diagnostic concordance among monozygotic twins compared to dizygotic pairs. Furthermore, social interactions, individual behavioral patterns, and emotional factors play crucial roles in the development of chronic pain, contributing to phenotypes that warrant further investigation and understanding [12–15].\n\nConsidering the literature presented, the primary objective of this case-control study was to investigate the cognitive-behavioral-emotional factors involved in the development of painful TMD. Variables such as pain sensitivity, oral behaviors, and central sensitization were selected due to their well-established roles in modulating pain through cognitive and emotional pathways. Accordingly, the study aimed to achieve the following specific objectives::\n\nThis study was conducted at the School of Dentistry of Ribeirão Preto (São Paulo University, Brazil) and approved by the Research Ethics Committee of the same institution under protocol 98129918.6.0000.5407. All participants provided informed consent after receiving a detailed explanation of the study and signed the informed consent form after agreeing to participate in the research. The research was conducted by the Declaration of Helsinki and was approved by the Human Research Ethics Committee of the University of São Paulo.\n\nThe start date of recruitment period was 01/02/2020, and the end date was 15/01/2022. A comprehensive recruitment strategy was employed to ensure the inclusion of eligible participants, following ethical approval. The study and its inclusion criteria were widely disseminated through several communication channels. These included social media platforms, websites, local radio stations in Ribeirão Preto and around. Additionally, messaging apps were used to reach student and community groups, and physical posters were placed in strategic locations throughout Ribeirão Preto, such as public spaces and healthcare facilities.\n\nThrough these efforts, 38 pairs of monozygotic twins contacted the research team and were scheduled for clinical evaluations. Among these, 12 pairs met the inclusion criteria for discordance in painful TMD. However, 2 of these pairs declined to participate, leaving a final sample of 10 pairs included in the study. The extended recruitment period reflects the challenges associated with identifying and engaging a highly specific study population, highlighting the rigor and commitment involved in assembling this unique sample\n\nThe sample consisted of 20 monozygotic twins discordant for painful TMD—10 pairs (one twin with the condition and the other without)—aged 18–55 years. This age range was selected to reduce the influence of age-related changes in pain perception, comorbidities, and cognitive-emotional responses, which could introduce variability and confound the assessment of cognitive-behavioral-emotional factors in TMD. To control for hormonal differences, evaluations were conducted during the follicular phase of the menstrual cycle (days 4–10 after menstruation onset) for women with regular cycles or during the corresponding period for women using oral contraceptives.\n\nThe diagnosis of painful TMD was determined according to the diagnostic criteria of the Diagnostic Criteria for Temporomandibular Disorders - Brazilian Portuguese (DC/TMD) [3]. Inclusion criteria for participation in the study were: female monozygotic twins, aged between 18 and 55 years, presence of reported pain in the facial region lasting at least three months, and presence of a diagnosis of painful TMD according to the DC/TMD criteria for the case twin (TMD) and absence of this diagnosis for the control twin.\n\nWomen were excluded if they were using interocclusal splints or undergoing any form of TMD therapy (e.g., acupuncture, laser therapy, physical therapy, or pain medication) to avoid confounding effects from ongoing treatments, ensuring that the cognitive-behavioral-emotional factors analyzed reflected their natural pain responses without external modulation. Additional exclusion criteria included a history of tumors, trauma, or head and neck surgery, previously diagnosed neurological or psychiatric disorders (excluding anxiety and/or depression), and pregnancy.\n\nThe following clinical information associated with the identification of phenotypes, according to a cognitive-behavioral-emotional model [16], was collected:\n\nThe association of each factor with TMD was investigated by fitting pairwise conditional simple logistic linear regression models. In the simple logistic linear regression models, the factors associated with TMD at the α < 0.20 level were selected and correlated to investigate multicollinearity. During the investigation of multicollinearity, factors that showed Spearman’s correlation coefficient with p < 0.05 were correlated with each other and, therefore, were not selected for inclusion in the logistic multiple linear regression model.\n\nDuring the development of the multiple linear regression model, certain variables were excluded due to significant collinearity to maintain the model’s robustness and ensure accurate and reliable estimates. Collinearity was identified using Spearman’s correlation coefficient, with variables showing a p-value < 0.05 being excluded from the final model to avoid multicollinearity, which could distort the relationships between the predictors and the outcome. The excluded variables include right upper trapezius pain threshold (OR = 0.29, 95%CI = 0.07–1.20, p = 0.088), right temporomandibular joint (TMJ) pain sensitivity (OR = 1.15, 95%CI = 0.86–1.54, p = 0.346), and left masseter pain threshold (OR = 2.28, 95%CI = 0.82–6.31, p = 0.113). Although these variables showed associations with TMD in the bivariate analysis, their high correlation with other variables in the model necessitated their exclusion. Similarly, sleep quality total score (OR = 1.60, 95%CI = 0.88–2.93, p = 0.124), pain awareness total score (OR = 1.07, 95%CI = 0.98–1.16, p = 0.158), and daytime oral behavior score (OR = 1.33, 95%CI = 0.88–2.02, p = 0.180) were also excluded due to collinearity. Pain vigilance score (OR = 1.14, 95%CI = 0.95–1.37, p = 0.154) significantly correlated with other variables and was similarly removed from the final model.\n\nBy excluding collinear variables, we retained only those with no significant collinearity, ensuring the independence in the regression model. The retained variables—left masseter pain sensitivity, total pain catastrophizing score, difficulty in externalizing feelings, and the distraction facet of the mindfulness scale—offered a more precise and accurate representation of the factors associated with the development of painful TMD. This approach was critical for enhancing the model’s validity and ensuring robust and meaningful conclusions. All statistical tests were conducted at a significance level of α = 0.05, with associations considered statistically significant when p-values were below this threshold. The analyses were performed using SPSS 21.0 software.\n\nTable 1shows the crude bivariate associations to explain the likelihood of TMD by analyzing the odds ratios (OR) and p-values. The variables that showed a positive association (according to the OR), however, without statistical significance, were pain duration, pain threshold to pressure (body, right side, upper trapezius/face, right, TMJ/ face, left, anterior temporal), pain sensitivity (body, right side, lateral epicondyle/face, right, anterior temporal/ face, right, masseter/face, left, anterior temporal/ face, left, masseter/face, left, TMJ), daytime oral behavior score, mean daytime oral behavior score, pain vigilance and awareness, pain catastrophizing (total/hopelessness), central sensitization (total score), stress, difficulty externalizing feelings, mindfulness facets (distraction/unresponsiveness), sleep quality (subjective sleep quality domain score/ overall score), pain intensity, and pain interference.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320515.t001\n\nTable 2shows the multiple linear regression model adjusted including in the deterministic model the variables that had, in the bivariate exploration, p-value < 0.20 (Table 1) and that had, among themselves, Spearman’s linear correlation coefficient that was not statistically significant (p > 0.05), thus preventing the presence of multicollinearity in the final adjusted model.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320515.t002\n\nIn the unadjusted models, significant associations were observed between painful TMD and variables such as left-sided masseter face pain sensitivity (OR = 1.7, 95% CI: 1.2–2.6), total pain catastrophizing (OR = 2.5, 95% CI: 1.4–4.5), and difficulty in externalizing feelings (OR = 1.4, 95% CI: 1.1–2.1). However, these associations were attenuated after adjusting for confounding factors and no longer reached statistical significance. For example, the OR for left-sided masseter pain sensitivity decreased to 1.3 (95% CI: 0.9–2.1). This reduction suggests that while these factors may contribute to TMD risk, their independent effect is reduced when accounting for interrelated variables.\n\nWhile the adjusted model did not identify statistically significant associations, variables such as increased pain sensitivity in the masseter muscle (OR = 3.29, 95% CI: 0.17–62.8, p = 0.428), higher levels of pain catastrophizing (OR = 1.08, 95% CI: 0.64–1.8, p = 0.776), difficulty in externalizing feelings (OR = 1.61, 95% CI: 0.13–2.9, p = 0.539), and higher scores on the distraction facet of mindfulness (OR = 4.65, 95% CI: 0.39–55.7, p = 0.225) were included due to their clinical relevance and their significant associations in the bivariate analysis (p < 0.20).\n\nTable 3summarizes the presence or absence of a TMD diagnosis based on the DC/TMD criteria. Notably, in all cases, twins diagnosed with TMD had at least one subtype classified as painful TMD.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320515.t003\n\nThis study investigated the cognitive-behavioral-emotional variables associated with the development of painful TMD in a sample of monozygotic twins discordant for the condition. Our findings indicate that increased pain sensitivity in the masseter muscle, higher levels of pain catastrophizing, difficulty in externalizing feelings, and higher scores on the distraction facet of mindfulness were included in the final model due to their clinical relevance and their associations in the bivariate analysis (p < 0.20). Despite their lack of statistical significance in the adjusted model, these variables were selected to ensure a comprehensive exploration of cognitive-behavioral-emotional factors in painful TMD, particularly given their potential importance in clinical practice. The inclusion of these variables also reflects our effort to balance parsimony with the need to retain independent predictors while considering the limitations imposed by the sample size and the specificity of the study population. These results provide evidence that, even in genetically identical individuals, cognitive and emotional factors play a crucial role in the manifestation of chronic pain associated with TMD.\n\nThe attenuation of significance in the adjusted models is a well-recognized occurrence in multifactorial conditions like TMD, where multiple variables collectively contribute to disease risk. In our study, the adjusted logistic regression model accounted for potential confounding variables, which likely diluted the individual effects of pain sensitivity, catastrophizing, and emotional regulation. This does not negate the relevance of these factors but rather indicates that their isolated impact is less pronounced when analyzed alongside other interrelated predictors. This underscores the complexity of TMD, where psychological, emotional, and sensory factors interact dynamically to influence overall risk.\n\nIn comparison with previous studies, our findings support the notion that pain catastrophizing, a well-established psychological predictor of chronic pain, is significantly associated with TMD. For instance, research from the OPPERA study demonstrated that individuals with higher levels of catastrophizing were more likely to develop chronic TMD, aligning with our observation that this cognitive variable increases the likelihood of painful TMD [2]. However, our study adds to this body of knowledge by highlighting the specific roles of difficulty in externalizing feelings and the distraction facet of mindfulness, two variables that have been underexplored in previous TMD research. These emotional and attentional factors may serve as important targets for interventions designed to alleviate TMD-related pain.\n\nAccording to the International Association for the Study of Pain (IASP), pain is defined as an unpleasant sensory and emotional experience associated with, or resembling that associated with, actual or potential tissue damage. This comprehensive definition emphasizes the complex nature of pain, which integrates sensory, cognitive, and emotional dimensions [2]. Cognitive processes not only shape psychological outcomes, such as emotional regulation, but also directly modulate neural pathways involved in pain perception. The intricate interplay between cognition and pain underscores the need to assess these variables when investigating chronic pain conditions like TMD [18–20]. Consequently, examining cognitive-behavioral-emotional factors is essential for gaining deeper insights into the mechanisms underlying pain and for designing more effective, targeted interventions [19,20].\n\nIncluding variables such as pain sensitivity and central sensitization in the cognitive-behavioral-emotional model is supported by evidence demonstrating the role of psychological factors, like catastrophizing and stress, in amplifying pain perception. These variables interact with cognitive appraisals and emotional responses, influencing pain intensity and chronicity. The findings of our study underscore the relevance of the biopsychosocial model in understanding chronic pain, particularly in the context of painful TMD. This model emphasizes the intricate interplay of cognitive, behavioral, and emotional factors in shaping an individual’s pain experience. Our results identified pain catastrophizing, difficulty in externalizing feelings, and the distraction facet of mindfulness as key predictors of painful TMD. These findings highlight the necessity of addressing emotional and cognitive dimensions alongside the physical aspects of pain in the management of chronic pain syndromes. Consistent with prior research, these factors play a pivotal role in how individuals perceive and respond to pain, and their accurate identification can significantly enhance treatment strategies and outcomes for patients [19–22].\n\nIn line with the findings from the OPPERA study, our research corroborates those psychological factors, particularly catastrophizing, are strongly associated with the development and persistence of painful TMD. The OPPERA study’s multivariable analysis identified global psychological and somatic symptoms as robust risk factors for TMD onset [23]. Similarly, in our study, catastrophizing emerged as a significant cognitive predictor, underscoring the impact of negative thought patterns in intensifying pain and disability. The well-established association between catastrophizing and increased pain intensity reinforces our conclusion that targeting this cognitive factor could play a crucial role in mitigating TMD symptoms.\n\nMoreover, while the OPPERA study focused on broader psychosocial predictors such as stress and somatic symptoms, our study extends the understanding of TMD by identifying more nuanced emotional factors like difficulty externalizing feelings. This finding contributes to the growing evidence that emotional regulation and expression are critical factors in the chronicity of pain conditions. Individuals who struggle with emotional expression may internalize stress, thereby exacerbating their pain experience. This insight highlights a potential intervention pathway, emphasizing the development of emotional intelligence and communication skills as integral components of a holistic approach to managing TMD.\n\nOur study also highlighted the role of mindfulness, particularly the distraction facet, in modulating the pain experience. Mindfulness-based interventions have gained increasing recognition as effective tools for managing chronic pain, including TMD [21]. The ability to redirect attention away from pain and maintain a neutral stance towards bodily sensations reduces the psychological burden of pain. By training individuals to dissociate from the emotional distress associated with pain, mindfulness can reduce the intensity of the pain experienced, as our findings suggest. The implications for therapeutic interventions are significant, as mindfulness training could be integrated into conventional pain management programs to enhance their effectiveness.\n\nIn contrast to studies that emphasize the heritability of chronic pain, such as the work by Burri et al. (2018), which found a vital genetic component in chronic pain conditions [15], our study underscores the critical role of environmental and psychological factors, even among monozygotic twins. While genetic predisposition undoubtedly plays a role, as highlighted by Burri’s findings, our results indicate that cognitive and emotional variables may supersede genetic factors in the manifestation of painful TMD. This has significant implications for personalized treatment approaches, suggesting that interventions focusing on cognitive-behavioral-emotional factors could be effective even in individuals with a genetic susceptibility to pain.\n\nEpigenetics represents a key mechanism in understanding the complex interaction between genetic predisposition and environmental factors in the development of chronic pain conditions like TMD. Recent studies have shown that epigenetic modifications, such as DNA methylation and histone acetylation, can influence gene expression in pathways associated with pain sensitivity and inflammation, thereby modulating the risk of chronic pain syndromes [24,25]. By utilizing a monozygotic twin sample, our study minimized genetic variability, allowing us to focus on non-genetic influences, including potential epigenetic modifications. This approach is particularly valuable for exploring how environmental stressors and psychological factors, such as catastrophizing and emotional dysregulation, contribute to altered pain processing in TMD. Investigating epigenetic markers in this context could provide valuable insights into the biological underpinnings of TMD, as suggested by studies demonstrating the impact of epigenetic changes on central sensitization and chronic pain development [26,27].\n\nThe specificity of our sample, composed of monozygotic twins discordant for painful TMD, provides a unique advantage in examining the interaction between genetic, environmental, and psychological factors. This controlled design enables us to isolate the impact of cognitive-behavioral-emotional variables without the confounding effects of genetic differences. Additionally, the inclusion of a broad range of variables—spanning pain sensitivity, mindfulness facets, emotional expression, and central sensitization—allowed us to construct a comprehensive profile of factors contributing to painful TMD. This multifactorial approach aligns with contemporary research emphasizing the integration of psychological and biological dimensions for a holistic understanding of chronic pain syndromes [2,18,26–28]. The robustness of our model is further strengthened by the inclusion of key psychosocial factors, such as catastrophizing and emotional dysregulation, which are consistently associated with worse pain outcomes and resistance to treatment in chronic pain populations [20].\n\nIn genetically identical individuals, such as the monozygotic twins in our study, non-genetic factors- environmental, psychological, and epigenetic- emerge as particularly influential in the development of chronic pain conditions like TMD. Our findings reinforce that, even without genetic diversity, cognitive-behavioral-emotional factors such as pain catastrophizing, difficulty in emotional expression, and mindfulness play a pivotal role in pain perception and modulation. Studies have shown that environmental stressors and psychological variables can induce epigenetic changes, influencing gene expression and central sensitization mechanisms [26–28]. This underscores the notion that, in genetically identical populations, modifiable factors such as emotional regulation and cognitive patterns may exert a greater influence on pain outcomes than genetic predispositions alone. The ability to isolate these effects in monozygotic twins highlights the critical role of psychological and behavioral interventions, offering the potential for more targeted and effective treatments for chronic pain in individuals with shared genetic backgrounds.\n\nFurthermore, our results align with the growing recognition of central sensitization as a critical mechanism in chronic pain, particularly in TMD [18,29]. Central sensitization, characterized by an amplified response to pain stimuli, is thought to be modulated by both sensory and cognitive-emotional factors. In this context, our findings on pain catastrophizing and mindfulness distraction are particularly relevant, as both these factors are known to influence central pain processing [29–31]. This reinforces the idea that cognitive and emotional interventions may not only reduce the subjective experience of pain but also address underlying neurobiological mechanisms involved in TMD.\n\nIt is important to note that while our study adds to understanding the role of cognitive-behavioral-emotional factors in painful TMD, it also highlights areas for future research. Larger and more diverse samples are needed to validate these findings further and explore the potential for integrating mindfulness and emotional regulation techniques into standard treatment protocols for TMD. Furthermore, future studies could investigate how these factors interact with biological markers such as inflammatory and oxidative stress responses to provide a more comprehensive picture of the pathophysiology of TMD. Moreover, although the age criterion (18–55 years) was implemented to minimize confounding factors related to age-associated changes in pain perception, comorbidities, and cognitive-emotional responses, this restriction also represents a limitation in this study, as age could have been considered a potential confounder in the analysis, allowing for a broader understanding of its influence.\n\nOur findings underscore the importance of a multifaceted approach to the treatment and management of painful TMD, addressing not only the physical manifestations of the disorder but also the psychological and emotional factors that contribute to its chronicity. Integrating interventions such as emotional intelligence training, mindfulness practices, and cognitive-behavioral therapies holds significant promise in improving patient outcomes by targeting both pain’s sensory and affective dimensions. Future research should focus on evaluating the efficacy of these interventions through clinical trials and exploring the potential interaction between cognitive-behavioral-emotional factors and biological markers, such as inflammatory and oxidative stress responses. A deeper understanding of these interactions could pave the way for developing personalized treatment protocols aimed at effectively reducing pain and enhancing the quality of life for individuals with TMD. Future research would benefit from employing advanced statistical techniques, such as interaction or mediation analysis, to unravel the dynamic relationships between cognitive-behavioral-emotional factors and TMD development. Such approaches could provide more nuanced insights into how these factors influence disease outcomes, enabling more targeted interventions.\n\nOur study investigated cognitive-behavioral-emotional factors potentially associated with painful TMD in a unique sample of monozygotic twins discordant for the condition. While the adjusted model did not identify statistically significant associations, variables such as increased pain sensitivity in the masseter muscle, higher levels of pain catastrophizing, difficulty in externalizing feelings, and higher scores on the distraction facet of mindfulness were included due to their clinical relevance and their significant associations in the bivariate analysis. These findings contribute to understanding the potential role of these variables in painful TMD, highlighting their relevance for clinical practice and the need for further exploration. Our approach emphasizes the importance of balancing parsimony and clinical applicability, while recognizing the limitations of sample size and study specificity. Future studies with larger populations are essential to confirm these results and to further investigate the interplay between cognitive-behavioral-emotional factors and painful TMD.",
    "category": "neuroscience"
  },
  {
    "title": "Research on the dynamic evolution mechanism of disruptive technology based on the BERTopic model and Hidden Markov Model: A case study of industrial Internet technology",
    "authors": "Heng Yang, Sheng Chen, Xin Yang, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0319924",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319924",
    "content": "The development of key technologies for the Industrial Internet is a major concern for countries worldwide. This paper aims to comprehensively understand the technology of the Industrial Internet by analyzing its current application status and trends. It will dynamically examine the key technologies and development trends of the Industrial Internet, providing a valuable reference for technological advancements in this field.\n\nThis paper analyzed global patent data in the field of the Industrial Internet from 1965 to 2023. The paper applied the BERTopic model and the all-MiniLM-L6-v2 model to extract and vectorize topics related to industrial internet technology from patent texts. Based on the theory of Internet governance, the paper categorizes the topics into four categories. The paper then established the Hidden Markov Model (HMM) to investigate the evolutionary mechanism of technological topics. The paper utilized the newly divided topics as hidden states and the number of patent applications as observed states in the Hidden Markov Model (HMM).\n\nIndustrial internet technology encompasses five research directions. The physical layer focuses on interconnection platforms for equipment, as well as devices for the storage and monitoring of liquids and gases. The logical layer involves remote control systems for industrial equipment, while the data layer focuses on data processing and information services. The interaction layer included modular image processing and control methods. Among these types of technologies, the data layer technologies were the most developed and also contributed to the advancement of interaction layer technologies. The physical layer technologies were relatively more developed, while the logical and interaction layer technologies were relatively less developed.\n\nCitation:Yang H, Chen S, Yang X (2025) Research on the dynamic evolution mechanism of disruptive technology based on the BERTopic model and Hidden Markov Model: A case study of industrial Internet technology. PLoS ONE 20(4):\n           e0319924.\n        \n        https://doi.org/10.1371/journal.pone.0319924\n\nEditor:Burak Erkayman, Ataturk University, TÜRKIYE\n\nReceived:October 31, 2024;Accepted:February 10, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Yang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:This work was supported by the National Natural Science Foundation of China under Grant 72274026.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe industrial Internet, as a key driving force for the digitalization and intelligence of the manufacturing industry, has been highly valued by countries around the world. Countries have formulated relevant strategies and policies to promote the development and application of the Industrial Internet. Examples include the United States’ “Advanced Manufacturing Partnership Program,” China’s “Made in China 2025,” Germany’s “Industrial 4.0 strategic plan,” the United Kingdom’s “British Industry 2050 strategy,” France’s “New Industrial France Plan,” Japan’s “Super Intelligent Society 5.0 strategy,” South Korea’s “Manufacturing Innovation 3.0 plan,” and many others. Globally, competition in the field of industrial Internet is also intensifying. Manufacturing powerhouses, such as the United States and Germany, continue to increase policy support and financial investment to maintain their technological advantages and market share [1]. In 2020, the projected value-added scale of the Industrial Internet in the United States is $885.84 billion, making it the global leader in this sector. China followed with $566.456 billion in value-added, which is greater than the combined value added of Japan and Germany [2]. It can be predicted that the Industrial Internet will become an important field for countries to compete in the future.\n\nTo gain a comprehensive understanding of the current development status and future trends of industrial Internet technology, it is necessary to analyze its patents. A patent is a direct reflection of technological innovation. It can reveal the core content, development direction, and competitiveness of the technology. Some studies have reviewed patent texts on smart manufacturing technology [3]), edge computing for Industry 4.0 [4], and IoT technology [5,6]. While these studies have some value, they have yet to provide a comprehensive, systematic, and dynamic analysis of patents related to the Industrial Internet. Secondly, some studies in related fields have analyzed patent texts or conducted text-based topic extraction. However, conventional methods such as LDA overlook important semantic information, such as word order and syntax, and are unable to capture dynamic modeling. The final research on patent text topic modeling did not incorporate other methods for further analysis.\n\nTo address this research gap, the study proposes a research method for analyzing the dynamic evolution of technology using BERTopic and the Hidden Markov Model (HMM). This approach has three advantages. Firstly, the BERTopic model is a deep learning-based topic modeling approach. It can transform text into high-dimensional vectors, capturing semantic information and contextual relationships, and thus extract the technical topics of industrial Internet patents. Secondly, the BERTopic model is a dynamic topic model that can demonstrate the evolution process and trends of technical topics over time. This capability enables us to analyze the developmental stage and direction of technology. Thirdly, a Hidden Markov Model can be constructed based on the time-series data of technology topics obtained from the BERTopic model. By observing the changes in the number of patent applications, it is possible to infer the potential status and likelihood of technological topic transfer. This can help reveal the mechanisms and laws of technological evolution. This paper presents a novel framework for analyzing the dynamic evolution of technology. This framework overcomes the limitations of traditional text mining methods, such as the neglect of deep semantic information and dynamic modeling. It enhances the accuracy and interpretability of technology topic extraction and prediction. This paper utilizes the Derwent Patent Database, which collects 52,121 worldwide industrial Internet patent data from 1965 to 2023. This provides a comprehensive, long-term, and international perspective that broadens the scope and enhances the depth of research on industrial Internet technologies.\n\nThe paper is organized as follows: Section 2 reviews the literature on the topic-based patent analytics approach and smart manufacturing. Section 3 introduces the BERTopic and HMM models, as well as theories on Internet governance. Section 4 presents our main findings. Section 5 discusses and analyzes the results. Section 6 concludes the paper.\n\nMost of the previous studies have used patent texts to conduct descriptive and analytical reviews or to extract topics from existing patent documents. However, these studies have some limitations, such as ignoring the dynamic evolution of technology topics and the rich semantic information contained in patent texts. Jian-Qiang Li et al. analyzed the brief history of the Industrial Internet, its architecture, and supporting technologies based on existing literature. They also summarized the application of the Industrial Internet in various fields and discussed the challenges that lie ahead [7] Juite Wang et al. collected patent texts on intelligent manufacturing technology and utilized the Latent Dirichlet Allocation (LDA) method for topic modeling. They constructed three indices, namely the reference rate, claim rate, and scale rate, to evaluate the status of competition analysis within the subject field. In addition, they analyzed the number of patent documents and the growth rate of each topic to determine the level of emerging topics for each subject [8] A comprehensive analysis and overview by Amy J.C. Trappey included basic standards and patents from management standards organizations in the United States, Europe, and China, which host the majority of global manufacturing facilities. They also conducted a comprehensive review of the standards and technologies of the Internet of Things [6]. Lorenzo Ardito et al. collected 61,972 IoT patents filed under the Patent Cooperation Treaty from 2000 to 2012. They examined innovation dynamics and technological evolution by analyzing the time trend of patent applicants, transnational dynamics, and country [5]. Xiang Li et al. utilized bibliometrics to categorize Internet of Things technology into five technical subfields. Based on the De Winter patent database, they used patent metrology to conduct a comprehensive analysis of Internet of Things (IoT) technology and its different technical subfields. They used CiteSpace as an analytical tool to analyze and discuss the innovative characteristics of Internet of Things technology and its various technical subfields [9]. Through a comprehensive review of edge computing in the Industrial Internet of Things, Tie Qiu et al. elaborate on the development and integration process of the Industrial Internet of Things and edge computing. They also proposed a reference architecture for edge computing in the Industrial Internet of Things [10] Li Da Xu et al. reviewed the latest industry-related technologies in the field of Industry 4.0 by analyzing the literature [4]. The existing literature primarily focuses on analyzing patent texts or standards related to the Internet of Things. However, there has been no comprehensive analysis of patent texts specifically related to the Industrial Internet. In addition, the majority of the methods utilized were reviews or topic analyses, without any subsequent analysis of the extracted topics in conjunction with other methods, such as prediction.\n\nTopic modeling is a technique that automatically extracts topic information from a large number of documents. The core idea of topic modeling is that each document can be viewed as a mixture of multiple topics, and each topic consists of a set of words. Topic models assist in tasks such as document classification, clustering, and information retrieval. There are three phases in the order of emergence of topic models, as stated by Churchill and Singh [11].\n\nFrom 1999-2006, the main methods for topic modeling were Latent Semantic Analysis (LSA) using matrix decomposition and Probabilistic Latent Semantic Analysis (PLSA) employing probabilistic graphical modeling. LSA extracts latent semantic information by reducing the size of the document-word matrix using Singular Value Decomposition (SVD) [12]. PLSA represents documents as a mixture distribution of topics and topics as a probability distribution of words, using Maximum Likelihood Estimation (MLE) [13]. LSA and PLSA have the advantage of being able to discover implicit relationships between documents and words. However, they have the disadvantage of ignoring the prior distributions of the words and the document generation process. They also struggle to effectively handle data sparsity and polysemy, and they are prone to triggering overfitting.\n\nFrom 2006-2011, the primary approaches to topic modeling were latent Dirichlet allocation (LDA) and its extension models derived from probabilistic graphical models. LDA is a generative probabilistic model that introduces Dirichlet prior distributions to regularize the distributions of document-topic and topic-word, following PLSA [14]. The extended model of LDA includes the dynamic topic model, emotional topic model, and other models that incorporate additional information, such as time, space, emotion, and social network. The advantages of Latent Dirichlet Allocation (LDA) and its extensions include preventing overfitting, enhancing the model’s generalization, and incorporating additional semantic and contextual information. The disadvantages include the complexity of the computation and the need to utilize approximate inference methods, such as Gibbs sampling or variational inference [15].\n\nFrom 2011 to the present, the prevailing approach to topic modeling has been neural network-based topic modeling, as demonstrated by BERTopic. BERTopic is a topic modeling technique that utilizes transformers and c-TF-IDF to create dense clusters. This approach enables the creation of easily interpretable topics while preserving important words in the topic descriptions. BERTopic supports bootstrapping, (semi)supervised, and dynamic topic modeling, as well as LDAvis-like visualization. BERTopic has the advantage of being able to leverage pre-trained language models, which improves the quality and consistency of topics. Additionally, it supports multiple languages and embedded models. However, it has the disadvantage of requiring larger computational resources and storage space [16].\n\nMost topic models are static and cannot be analyzed dynamically. The LDA model is a popular topic model that can extract topics from text. However, the LDA model ignores word order and deeper semantics, such as syntax, and has limited representational capabilities [17]. To effectively address the dynamic nature of technical subjects, this paper utilizes the state-of-the-art BERTopic model and a high-capacity server to handle the extensive computational requirements for modeling.\n\nA statistical model known as the Hidden Markov Model (HMM), which is an evolution of the Markov model, is capable of describing Markov processes with hidden and unknown parameters. HMM was initially used in speech recognition within the field of natural language processing and genetic analysis in biology. Since then, it has been widely applied in various fields, such as stock prediction and bioinformatics, among others. Notably, it has also been employed in various disciplines related to text, such as literature, bibliography, and patent analysis, among others. Applications of HMM in text analysis generally fall into three categories:\n\nThe first category pertains to studies that utilize Hidden Markov Models (HMM) to examine patterns of technological growth and life cycles. These papers typically consider stages of technological growth or life cycle as hidden states, with the number of patents or citation information as observations. Transfer probabilities are calculated based on various assumptions or data sources. For instance, Lee et al. [18] divided the growth of technology into seven stages based on data from patent counts. They employed clustering analysis to examine trends and generate growth probability transition matrices using the Poisson distribution. In this analysis, the growth stages were considered as latent states. Similarly, Hyoung-joo Lee et al. [19] utilized patent citation information to identify latent factors associated with technology growth and knowledge flow. They estimated transfer probabilities by either constructing a patent network or assuming a Poisson distribution. Changyong Lee et al. employed Hidden Markov Models (HMM) to predict the dynamic patterns of technology life cycle stages. They used citation information as individual patent-level observations to generate growth probability transition matrices based on Poisson distributions [20].\n\nThe second category encompasses studies that utilize topic models and hidden Markov models (HMMs) to examine the evolution of technological topics. These studies focus on integrating topic models and hidden Markov models (HMMs). In this approach, the extracted topics from the text are used as hidden states. The probability distributions of the topics are treated as observations, and the transition probabilities are determined based on the similarities or co-occurrences of the topics. Wu et al., for instance, extracted topics from thesis data using LDA models and tracked the evolution of topics with HMM. They established hidden states with topics derived from LDA clustering and used the probability distribution of these topics as observations. Word co-occurrence frequencies were used to measure the similarity between topics, which were then utilized as the transfer probability [21]. Wei et al. selected technical topics distilled from LDA as hidden states and observed their probability distributions. They created a co-occurrence normalized matrix for hidden states and used it to calculate transition probabilities. By analyzing the distribution and evolutionary patterns of technological topics using Hidden Markov Models (HMM), the authors identified research and development opportunities in the field of 3D printing [22].\n\nThe third category involves studies that apply Hidden Markov Models (HMM) to analyze social media. These papers treat social media comments as hidden states and utilize related indicators as observations to calculate transfer probabilities from different perspectives. For example, Jang employed Latent Dirichlet Allocation (LDA) to model anchored topics from car review data and used Hidden Markov Models (HMM) to forecast hidden topics by considering the number of monthly articles as observations [23]. Suh predicted potential political risks in social media using Hidden Markov Model (HMM) patterns at the observation level. They utilized Natural Language Processing (NLP) to extract latent variables referred to as Political Risk-Related Topics (PRRT) and computed transition probabilities based on energy, sentiment, and social network metrics.\n\nDue to the lack of time-series data specific to the technology itself, existing research on technology development has mainly been conducted by constructing technology life cycles or technology indicator systems. To date, no studies have exclusively analyzed texts related to technology. Given the BERTopic model’s ability to capture temporal data of textual topics, it offers a viable approach for modeling technology topics. Additionally, since the BERTopic model relies on a deep learning-trained vectorized representation of text, it can capture semantic text features more accurately. This, in turn, enhances the precision of the extracted technology topics.\n\nBERTopic is a topic modeling technique based on deep learning that can extract topics from a large amount of unstructured text and present them in a comprehensible and interpretable manner. Compared to other topic models, such as LDA, this model has the following advantages: it utilizes a pre-trained model to convert the text into a high-dimensional vector. This approach enables the better capture of semantic information and contextual relationships within the text, resulting in more accurate and coherent topics. The c-TF-IDF algorithm is used to cluster text vectors, creating dense topic clusters while preserving important words in topic descriptions. This improves the interpretability and distinguishability of topics. The UMAP algorithm is used to reduce dimensions and visualize the identification of similarities and differences between topics. It also helps to explore and analyze the trend of topic evolution over time, aiding in the exploration and analysis of topics.\n\nBERTopic topic modeling includes the following steps: embedding, dimension reduction, clustering, bag-of-words, and c-TF-IDF. Each step can select an appropriate sample processing method to construct the corresponding topic model.\n\nHidden Markov Models (HMMs) are probabilistic models based on time series (seeFig 1). Hidden states and observation states are used to describe the dynamic process and performance of a system. Hidden states are internal states of a system and possess the Markov property, which implies that the current state is solely dependent on the preceding state. Observation states are the outputs of the system and have a probabilistic relationship with the hidden states. Each hidden state can generate an observation state. The parameters of the hidden Markov model include the initially hidden state probability matrix, the hidden state transition probability matrix, and the observation probability matrix. These matrices represent the initial state distribution of the system, the transition law between hidden states, and the generation law for outputs, respectively. The hidden Markov model can be represented by the following five parameters:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g001\n\nHMM has two hidden state parameters: the hidden state and the hidden state sequence. A hidden state is an internal variable that cannot be directly observed. The system exhibits the Markov property, which implies that the current state depends solely on the previous state. The hidden state reflects the internal state and the state transition law of the system. A hidden state sequence is a sequence of state variables with a length of T, representing the dynamic and uncertain internal state of the system at T time points. We use S to denote the set of all possible hidden states,, where N is the number of hidden states. We use I to denote a hidden state sequence of length T,, whereis the hidden state at time t,.\n\nThe HMM also has two parameters related to the observation state: the observation state and the observation state sequence. The observation state is an output variable that can be directly observed and has a probabilistic relationship with the hidden state. Each hidden state can generate an observation state. The observation state reflects the output and state. The observation state sequence is a sequence of output variables with a length of T. It represents the change process and observability of the system’s output over T time steps. We use O to denote the set of all possible observed states,, where M is the number of observed states. We use Q to represent the observation state sequence with length T,, whereis the observation state at time t,.\n\nThe hidden state transition matrix A represents the probability of transitioning from one hidden state to another at any given time point, reflecting the dynamic change pattern of the hidden state. A is the hidden state transition probability matrix:, where,,, which is the probability of transitioning to the hidden stateat time t + 1 given that the hidden stateis at time t.\n\nThe observation state probability matrix B represents the probability of observing a state in a given hidden state at any given time. It reflects the degree of correlation between the hidden state and the output of the observation state. B is the observation state probability matrix:, where,,. It is the probability of generating the observation stateunder the condition that the time t is in the hidden state.\n\nThe initial hidden state probability matrix represents the probability distribution of each hidden state at t =  1. The initial state of the hidden Markov chain affects the subsequent state transitions and observations. The setting is the initial hidden state probability vector:, where,. It is the probability of being in the hidden stateat time t = 1, which is used as the initial value of the hidden state.\n\nThe hidden state transition probability matrix A and the initially hidden state probability vectorπdetermine the hidden Markov chain and generate an unobservable sequence of hidden states. The observation probability matrix B determines how to generate the observed state from the hidden state, and combines with the hidden state sequence to determine how to generate the observation sequence.\n\nThe five major components of Internet governance include stakeholders, resources, regulations, principles, and outcomes. These components can also be summarized as the subject, object, and basic means [24]. This paper primarily focuses on analyzing the future development trends of industrial Internet technology using the theory of Internet governance. Internet governance objects refer to the physical layer, logical layer, data layer, and interaction layer [6]. The physical layer is the foundational infrastructure layer of the Internet, encompassing servers, storage, fiber optic cables, and other hardware components. The logical layer refers to the technical layer of the Internet, which is constructed with TCP and IP as the core protocols, along with hardware and interface standards. The data layer is the content layer of the Internet. It refers to the internet content stored in the physical layer and transmitted through the logical layer. This includes text, pictures, audio, and video that are displayed. The interaction layer refers to the behavior of people on the Internet, which is based on the application of the content carried by the fundamental resources of the Internet [25]. Among these four layers, the physical layer and the logical layer play the roles of carrying data transmission and facilitating interaction on the internet. However, behind these “physical” factors, the dominant role is played by human behavior. Therefore, the research focus of Internet governance is on the data layer and the interaction layer. This includes studying the behavior of individuals who use the internet to create, transmit, and access content. This study focuses on the theory of Internet governance to analyze the future development trends of industrial Internet technology.\n\nThe main components of the Internet governance model primarily consist of three sectors: government, private sector (including companies, private studios, etc.), and civil society. This division is based on the work report of the United Nations Internet Governance Working Group. The means of Internet governance models mainly include four aspects: legal norms, administrative measures, self-discipline management, and technical control. Legal norms are an important component of Internet governance models, as they regulate Internet behavior. Administrative means are the conventional methods often used by the government. Self-discipline management is divided into two parts: industry self-discipline and netizen self-discipline. Technical control mainly involves controlling and ensuring the integrity of the data layer and the presentation layer.\n\nFirstly, the Derwent Patent Database is used to gather industrial Internet patent data from 1965 to 2023. Subsequently, the data is cleaned to obtain the dataset for this study. Secondly, data preprocessing is performed on the dataset, and the BERTopic model is applied to extract topics related to patent technology. This allows for the analysis of key technologies in the field of the industrial Internet. According to the object theory of Internet governance, patent technology is classified. These classified topics are used as the hidden state in the Hidden Markov Model. The number of patent applications serves as an observational indicator for predicting the evolutionary trends of patent technology topics and exploring the mechanisms behind the evolution of industrial Internet technology (seeFig 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g002\n\nThis study utilizes the Derwent International Patent Database as the data source and analyzes technological advancements in the field of the industrial Internet using patent data. The term “Industrial Internet” refers to the seamless integration of advanced information technology with the manufacturing industry. Different countries have varying definitions of “it” but the fundamental content is generally similar. According to the key terms, core architecture, and key technologies of the industrial Internet [3], this study uses the following search terms to retrieve patent data related to the industrial Internet [26]: ‘industry internet’, ‘industry internet of things’, ‘IIoT’, ‘industrial IoT’, ‘industrial platform’, ‘industrial cybersecurity’, ‘industrial big data’, ‘industrial artificial intelligence’, ‘industrial cloud’ [27]. Finally, this study obtained 52121 patent data from October 1965 to October 2023 (seeS1 Table).\n\nThis study preprocessed the English text for topic modeling. The preprocessing steps included removing stop words using the English stop word library in the NLTK package, tagging the parts of speech such as nouns, verbs, adjectives, etc. in the text using the WordNet Lemmatizer package for lemmatization, and then converting the text to lowercase. These steps improved the clarity and consistency of the text, which facilitated the extraction of the main topic.\n\nUnlike LDA, which selects the optimal number of topics based on the perplexity and coherence index, the BERTopic model does not generate a perplexity or coherence curve. There are three approaches to determining the number of topics: automatic generation, manual specification, and deletion based on topic clustering. To ensure that no important topics were overlooked, the initial number of topics was set to 50 (seeFig 3), and then these topics were merged [28]. Finally, there were five patent topics.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g003\n\nIndustrial Internet patent data from October 1965 to October 2023 was collected in this study, as shown inFig 4. It can be seen from the figure that the development of the Industrial Internet was in a stable stage before 1999. The number of patent applications in the 34 years accounted for only 2.18% of the total, which is a very low proportion. After 1999, the development of the industrial Internet entered a stage of slow growth, which then transitioned to rapid growth. During this period, the number of patent applications exhibited a gradual increase, eventually leading to an exponential rise. This indicates that the technological innovation of the Industrial Internet experienced a gradual increase until 1999, after which it experienced a significant rise.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g004\n\nTo extract the key technical topics from the extensive patent texts, the study followed the steps outlined below. Firstly, the BERTopic model utilized the all-MiniLM-L6-v2 model, which is specifically trained for English text, to convert the text into a digital format. The sentences and paragraphs were then mapped to a dense vector space with 384 dimensions. The UMAP method was then used to map the data from the previously generated high-dimensional space to a low-dimensional space. This was done to reduce dimensionality while preserving the relationships and structure among data points. Secondly, the CountVectorizer function was used to convert the text into a matrix of word frequencies. Each row of the matrix represents a sentence, and each column represents a word. The improved c-TF-IDF method, which is based on TF-IDF, was used to extract the word frequency based on class. Finally, the processed data was visualized.\n\nThe BERTopic topic model was used to analyze the topics in the abstract text of industrial Internet patents, and several topics obtained are shown inFig 5. Finally, there were five patent topics (seeFig 5), and the keywords and their frequencies for each topic are shown inFig 6.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g006\n\nThis study took the following steps to ensure the accuracy and consistency of the topics: First, two doctoral students in the field of management collaborated to analyze the topic terms. For topics that have ambiguities, a new doctoral student was introduced to discuss and analyze the results together. Second, expert interviews were conducted to gather opinions until a final consensus was reached. Lastly, according to the categorization of objects in the theory of Internet governance, the topic terms were divided into four aspects: the physical layer, the logical layer, the data layer, and the interaction layer [29].\n\nAfter completing the aforementioned steps, this study identified four main areas of focus for industrial Internet patents (seeTable 1). These areas include: (1) Equipment interconnection platform (Topic 0), and liquid gas storage monitoring device (Topic 4) in the physical layer. (2) The logical layer includes the remote-control system for industrial equipment (Topic1_3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.t001\n\nThe equipment interconnection platform (Topic 0) serves as a cornerstone of the Industrial Internet [30]. It enables intelligent management of devices and secure data flow through cloud-based connectivity, thereby enhancing industrial production efficiency, quality, and innovation [31]. This platform is instrumental in four critical applications. First, it facilitates remote monitoring and maintenance of equipment, which reduces labor costs and increases equipment reliability and availability [32]. Second, it supports cooperative operations, flexible production, and intelligent scheduling to enhance production flexibility and efficiency [33]. Third, it collects and analyzes equipment data to improve product quality and performance. This is exemplified by the deployment of a 5G + 8K surface inspection system in the steel industry, which has improved defect detection [34]. Fourth, it enables the intelligent upgrading of equipment, which leads to the development of new products and services. This includes value-added services for equipment management, preventive maintenance, and personalized customization based on networked products [35].\n\nLiquid gas storage monitoring devices (Topic 4) utilize wireless sensor networks and cloud computing technology to enable real-time collection, transmission, analysis, and control of various parameters of liquid gas storage tanks. This allows for remote monitoring and management of liquid gas [36]. This technology has extensive applications in fields such as medicine, chemistry, and food. It optimizes the supply and utilization of liquefied gas in the chemical industry, thereby improving production efficiency and reducing energy consumption and emissions [37]. In the medical field, it ensures the quality and safety of liquefied gases, preventing shortages and waste, thereby improving medical service levels and effectiveness [38]. The food industry, regulates the consumption and loss of liquids and gases, thereby improving food quality and safety and extending shelf life [39].\n\nThe industrial equipment remote control system (Topic 3) is a technology that utilizes communication technology and artificial intelligence to gather, analyze, and manage industrial equipment and systems in various locations in real-time. This technology has three main applications: industrial automation, industrial robotics, and industrial IoT [40]. In industrial automation, this technology enables remote monitoring and control to enhance efficiency and quality, reduce consumption, enable remote upgrading and modification, and improve functionality and performance [41]. In industrial robotics, this technology extends the application scope and scenarios, promotes remote collaboration and learning, and enhances intelligence and efficiency [42]. In industrial IoT, this technology supports remote monitoring and control, provides visualization and intelligent support, enhances monitoring and management capabilities, enables remote optimization and tuning, and fosters innovation and value [43].\n\nData processing and information services (Topic 1) refer to the utilization of cloud computing, big data, artificial intelligence, and other technologies to store, analyze, and extract value from vast amounts of data generated by industrial equipment and systems. This concept is commonly applied in various areas, including industrial intelligence, industrial safety, and industrial services. In the field of industrial intelligence, these technologies enable intelligent analysis and mining of industrial data, enabling informed decision-making and control of industrial systems. Furthermore, they enable intelligent prediction and recommendation of industrial data, as well as intelligent optimization and adjustment of industrial systems [43]. In the realm of industrial security, these technologies contribute to the secure storage and protection of industrial data, thereby enhancing the security and reliability of industrial systems. They also enable security monitoring and early warning for industrial data, thereby improving security prevention and emergency response capabilities [44]. In the field of industrial services, the use of these technologies allows for the servitization and commercialization of industrial data, thereby improving the functionality and value of industrial systems. It also promotes service innovation and new service models for industrial data, thereby improving service quality and effectiveness [45].\n\nThe modular image processing and control method (Topic 2) utilizes image processing technology and control theory to enable real-time acquisition, analysis, and control of image information for industrial equipment and systems. This technology is widely used in areas such as industrial inspection, industrial robotics, and industrial vision. In industrial inspection, these methods enable the automatic detection and identification of surface defects, as well as the measurement of size, shape, color, and other characteristics of industrial products. This helps improve the quality and consistency of industrial products while reducing the errors and costs associated with manual inspection [3]. In the field of industrial robotics, these methods are utilized to automatically control and optimize functions such as vision navigation, localization, tracking, grasping, and other tasks performed by industrial robots. This increases the flexibility and accuracy of industrial robots, expanding their range of applications and scenarios [46]. In industrial vision, these techniques are used to collect, transmit, store, analyze, and apply image information from industrial scenes in real-time. This helps visualize and enhance the efficiency of industrial systems. It also improves their monitoring and management capabilities [47].\n\nThe BERTopic model was applied to the patents to extract five topics. These topics were then classified into four categories based on the theory of Internet governance objects. The topics in the same category were merged, resulting in four reclassified topics: device interconnection platform and liquid gas storage monitoring device for the physical layer (Topic 0 and Topic 4), industrial equipment remote control system for the logic layer (Topic 3), data processing and information service for the data layer (Topic 1), and modular image processing and control method for the interaction layer (Topic 2). These reclassified topics were used as the hidden state, while the monthly number of patent applications was used as the observation state in a hidden Markov model with continuous observations. The hidden topic sequence was then predicted based on the annual number of patent applications using the hidden Markov model (seeFig 7).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g007\n\nThe five parameters of HMM were determined according to the definition of HMM in Section 3.2. The maximum likelihood method was used to estimate the parameter values. The hidden state S consisted of the four reclassified topics, which were grouped according to the theory of industrial Internet governance. The initial probability of the hidden state was a uniform distribution [23]. The topics with the highest proportion of patent applications in each period and the highest frequency of topic transitions in the adjacent periods were counted. The transition frequency matrix was obtained and normalized by row to obtain the hidden state transition probability matrix A (Table 2). The patent data was divided into monthly periods, and the number of patent applications per month was used as the observation. The patent data did not fluctuate for a long time in the early years, which would affect the HMM calculation. Therefore, the data with fluctuations since 1999 was selected as the starting point for prediction [23], following the existing literature. A total of 297 months of patent application data were obtained and logarithmically normalized using min-max normalization. This was done to satisfy the HMM assumptions and to minimize the impact of data fluctuations on the prediction. The range of observations at each time step was between 0 and 1. The observation sequence Q was obtained (seeFig 8).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g008\n\nThe HMM prediction problem was solved by the Viterbi algorithm, which utilizes dynamic programming to identify the optimal path with the highest probability among the potential sequences of hidden states. The Viterbi algorithm was applied to predict the hidden states, and the predicted hidden states were compared with the actual hidden states (seeFigs 9–11). The prediction accuracy was 74.75%, which was higher than the 60% reported in a previous study [23] for the same type of data and model. The reason for the difficulty in achieving a higher accuracy than 0.9 [23] was that the topic model merged the text of some small datasets each month, resulting in data loss.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g009\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g010\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g011\n\nFive topics were extracted from the patents using the BERTopic model. The topics were analyzed by year to reveal the technology trends more clearly (seeFig 12). The technology trends were divided into three phases based on their characteristics. The following were as follows:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319924.g012\n\nPhase 1 (1965–1998): The Industrial Automation Phase. This phase spanned 33 years, accounting for 56.9% of the total time. The number of patent applications in this period accounted for approximately 2.18% of the total. The development of Internet technology was relatively smooth and unchanged. This stage was characterized by the third industrial revolution, which involved the adoption of sensors, actuators, robots, and other intelligent components and devices, as well as automated control systems. They enable automated control and data acquisition of industrial equipment, improving the flexibility and reliability of industrial production, and enhancing the management and optimization capabilities of industrial processes [48].\n\nPhase 2 (1999–2021): The Industrial Digitalization Phase. The development trend of this phase showed a gradual upward trajectory. The number of patent applications has increased significantly. The development of industrial internet technology has entered a rapid phase. This phase marked the fourth industrial revolution, which was driven by the Internet of Things (IoT) and the Industrial Internet. The development of data processing and information services (Topic 1) started earlier, reaching a small peak in 2000, and remained at a high stage for the next 10 years. Device interconnection platform (Topic 0) technology emerged later but became the leading technology in development. Modular image processing and control methods (Topic 2) had smooth development in the early stages but entered a rapid growth stage after 2020. Remote control systems for industrial equipment (Topic 3) and liquid and gas storage and monitoring devices (Topic 4) had steady development trends. The IoT paradigm was first introduced by Kevin Ashton in 1998 as a concept for connecting things or objects to the Internet. The concept of the industrial Internet was originally proposed by General Electric (GE) in 2012. It involves the integrated application of big data analytics and remote control technologies based on the Internet of Things (IoT). The goal is to optimize the operation and maintenance of industrial facilities and machines as well as improve the operational performance of assets. In July 2016, the International Society of Automation (ISA), the Process Control and Safety Forum (PCS) in Houston, Texas, and the ISA’s communications department convened a panel discussion to focus on and discuss the Industrial Internet of Things (IIoT) [49]. This was followed by a relatively rapid development of the industrial Internet of Things (IoT).\n\nPhase 3 (2022-2023): The trend in this phase declined. The number of patent applications has dropped. China accounted for approximately half of the global patent applications in the field of industrial Internet. China recently raised the threshold for patent applications to enhance the quality of patents. The overall number of patent applications declined [50].\n\nThe HMM model was used to investigate the evolutionary mechanism of industrial internet technology. The transition matrix of the HMM model reveals that the highest transition probabilities occur between the data layer to data layer, interaction layer to data layer, and physical layer to physical layer, with values of 0.763, 0.667, and 0.667, respectively. The trends of these three types of transitions were analyzed and compared with related reports to validate the accuracy of the results.\n\nThe transition from one data layer to another indicates that data layer technology is a research hotspot in the field of the industrial internet. As shown inFig 11, data layer technology was a prominent topic throughout all stages of development. The evolution of data layer technology has involved a transition from a low level to a high level, from simplicity to complexity, and from singularity to multiplicity. The evolution from low-level to high-level started with basic data collection and storage advanced to complex data processing and analysis, and finally reached intelligent data visualization and application. The data layer technology has been continuously upgraded and optimized. The evolution from simplicity to complexity began with a single data type and format, then expanded to include multiple data types and formats, and ultimately advanced to encompass the fusion and sharing of diverse data. The data layer technology has continuously evolved and become more complex. The evolution from single to multiple data applications started with single-point data applications, progressed to multi-point data applications, and eventually expanded to network data applications. The data layer technology has continuously expanded and diversified. This might be driven by the following factors: First, the demand-driven industrial internet requires more data to support intelligent decision-making and control of industrial production. This improves production efficiency and quality while reducing resource consumption and environmental impact [51]. Secondly, the technology-driven industrial internet has enhanced technical expertise and capabilities for collecting, transmitting, storing, managing, analyzing, and applying data. This has enabled the comprehensive, in-depth, and extensive use of data [52]. The policy-driven industrial internet has improved the policy environment and standard system of the industrial internet, thereby promoting the openness, sharing, and collaboration of data [53].\n\nThe transition from the interaction layer to the data layer can be influenced by various factors. Firstly, the application-driven industrial internet requires a larger volume of data to achieve interconnection, interoperability, and interaction within the industrial system. This, in turn, enhances the synergy and flexibility of the industrial system [54]. Secondly, the user-driven industrial internet requires more data to fulfill the personalized and customized needs of its users, thereby enhancing user satisfaction and loyalty [55]. The innovation-driven industrial internet requires more data to support the development and promotion of new products and services, thereby enhancing the competitiveness and impact of the industrial internet [7].\n\nThe transition from one physical layer to another, which ranks third in terms of significance, indicates ongoing innovation and progress in physical layer technology. As shown inFig 11, physical layer technology emerged as the most popular topic in the second and third stages, with a higher frequency. The physical layer technology includes 5G, 6G, edge computing, software-defined networking, network slicing, blockchain, and more. These technologies have addressed the issues of network congestion, delay, interference, and attacks, while also meeting the demands for real-time data, reliability, and security in industrial settings. They improved the performance and efficiency of the industrial internet [56]. The development of physical layer technology has undergone the following evolution: It started with the development of fiber optic communication technology, followed by wireless communication technology, 5G technology, and satellite communication technology. The communication mode was continuously innovated and optimized. The evolution from single-point to multi-point communication technology began with single-point communication technology and progressed to multi-point communication technology, and eventually to network communication technology. The communication range was continuously expanded and diversified. The evolution from single to diversified sensing technology began with a limited measurement range. It then developed into diversified sensing technology capable of measuring a variety of things and finally advanced to intelligent sensing technology. The sensing function has been continuously improved and enhanced. The evolution from passive control technology to active control technology, and finally to autonomous control technology, has occurred. The control mode was continuously innovated and optimized. The technical applications of the Industrial Internet have been continuously expanded and deepened, encompassing various fields including manufacturing, energy, agriculture, transportation, and medical care [57].\n\nThe Derwent Innovations Index was used to collect patent application data from around the world between 1965 and 2023. The BERTopic method was applied to extract the topic of industrial internet patent technology. The extracted topics were then reclassified according to the theory of Internet governance. The reclassified topic was used as the hidden state in the hidden Markov model, while the number of patent applications served as the observation. The hidden Markov model predicted potential technical topics and explored their potential evolutionary mechanisms. The main conclusions of this study were as follows: The development of the world’s industrial internet technology can be categorized into five main types, which align with four categories of Internet governance theory. The physical layer category includes device interconnection platforms and devices for monitoring liquid and gas storage. The logic layer category includes the remote-control system for industrial equipment. The data layer category includes data processing and information services. The interaction layer category includes modular image processing and control methods. The data layer technology underwent the greatest change, followed by the physical layer technology.\n\nThis study proposes a novel approach that combines the BERTopic model with the hidden Markov model and incorporates Internet governance theory to develop a framework for analyzing the dynamic evolution in the field. This hybrid approach overcomes the limitations of traditional text mining techniques, thereby enhancing the accuracy and interpretability of technology topic extraction and prediction. Moreover, the study collects a comprehensive dataset of global industrial Internet patent data from 1965 to 2023, utilizing the Derwent Patent Database. This extensive dataset provides a long-term, comprehensive, and international perspective on research in industrial Internet technology, thereby enhancing the scope and depth of the study.\n\nThe paper also provides managerial implications by uncovering the evolutionary patterns and underlying mechanisms of industrial Internet technology. This information is of considerable value to both corporate and government entities, as it provides insights that can help them effectively understand trends and opportunities in technological development. This, in turn, enhances the efficiency and impact of their innovation efforts. Additionally, the study presents an analysis methodology based on patent data that proves to be effective in identifying the key technologies within the field of the Industrial Internet. Future enterprises can utilize this approach to predict emerging technology trends based on the number of patent applications. This, in turn, provides a valuable reference for devising strategies and policies for technological innovation.\n\nThis study explores the extraction and prediction of topics related to industrial Internet technology using patent data as the primary source. However, it is essential to acknowledge the limitations of the study, which could benefit from further improvement and refinement. Firstly, the paper solely relies on patent data, neglecting other forms of data such as literature and software works. This may result in a lack of diversity in technology types and an incomplete representation of the overall development of the industrial Internet industry. Future research can address this by expanding the types of data and incorporating diverse data sources to improve data coverage and representativeness. The study, secondly, utilizes a first-order hidden Markov model, neglecting to account for the intricate connections among hidden states. This could lead to a reduction in prediction accuracy and an inability to effectively uncover the mechanism of the technology’s evolution. Subsequent research can explore higher-order hidden Markov models or combine the model with other techniques to enhance its expressive and fitting capabilities.\n\nThis table provides the raw data collected during the study.\n\nhttps://doi.org/10.1371/journal.pone.0319924.s001\n\n(XLSX)",
    "category": "neuroscience"
  },
  {
    "title": "Protein hydrolysates from fish wastes: nutritional characteristics and its inclusion in diets forOctopus maya",
    "authors": "Honorio Cruz-López, Cristina Pascual, Magalli Sanchez, Pedro Domingues, Carlos Rosas, Pedro Gallardo, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0321572",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321572",
    "content": "The utilization of fish waste protein as an alternative to crab and squid protein presents an important alternative for octopus fattening. During this study, nutritional characteristics of fish protein hydrolysate (FPH) and its inclusion in prepared diets were evaluated on growth performance and enzyme activity of digestive gland ofO. mayajuveniles. FPH were prepared using fish waste and their nutritional properties were evaluated. Four diets with different levels of FPH (0%, 10%, 15%, and 20%) in substitution for crab meals were fed to octopuses (mean body weight 100 mg) individually distributed for 70 days. Regarding yield, at the end of the hydrolysis period (day 15) the FPH fraction constitutes 67% of the total silage (dried powder). Small peptides were recorded in FPH (< 2.12 DA). Altogether, 17 amino acids were identified on FPH, encompassing nine essential amino acids (EAAs; 182 mg g-1) and eight non-essential amino acids (NEAAs; 427 mg g-1). Also, the free amino acids (FAAs) content was 8.3% of the total amino acids content with the predominance of taurine. Octopuses fed with FPH15 had the highest weight gain (3.06 g), SGR (4.76% day-1), and survival (90%) compared to FPH0. Total alkaline protease activity of octopuses digestive gland was lower in FPH20 (3550 U mg of protein−1) than in the control (5277 U mg of protein−1). Incorporating protein hydrolysate derived from fish waste into prepared diet may offer unique advantages in promoting optimal growth and general physiological well-being forO. maya.\n\nCitation:Cruz-López H, Pascual C, Sanchez M, Domingues P, Rosas C, Gallardo P (2025) Protein hydrolysates from fish wastes: nutritional characteristics and its inclusion in diets forOctopus maya. PLoS ONE 20(4):\n           e0321572.\n        \n        https://doi.org/10.1371/journal.pone.0321572\n\nEditor:Lee Seong, Universiti Malaysia Kelantan, MALAYSIA\n\nReceived:December 2, 2024;Accepted:March 8, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Cruz-López et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper.\n\nFunding:- PAPIIT IT201621 (DGAPA-UNAM) to Pedro Gallardo. - PAPIIT IN203022 (DGAPA-UNAM) to Carlos Rosas - Postdoc scholarship to Dr. Honorio Cruz López (no.404 523.01/2782DFA/FA/2022) from DGAPA-UNAM The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nGrowing interest in fish consumption has produced an increase in fish production. Therefore, valorization of fish by-products is becoming increasingly relevant, as marketing moves from selling whole fish to filleting [1]. By-products account for around 60–70% of the live fish weight of most commercially processed fish; without the right management, environmental problems may occur [2]. Furthermore, these wastes provide a useful source of bio-functional and nutritional compounds, such as protein, lipids, minerals, vitamins, and enzymes [2]. They contain high-quality protein (15–30% wet base) with all essential amino acids and can be used as feed ingredients, and especially as a substrate for hydrolysates production [3,4]. Due to its low cost and environmental friendliness, ensiling is one of the best methods to produce FPH. Silage is produced by endogenous proteases existing in fish waste which allows separation into phases; solid, fat and an aqueous phase with a high content of soluble protein, peptides, and free amino acids [5,6]. FPH is a mix of peptides, making them more digestible and attractive to animal feeds. They also play a significant role in metabolic regulation, modulation, and facilitate the molecules absorption by intestinal epithelial cells [4,7,8]. These hydrolysates are used as a protein supplement forChanna striata(45%),Lates calcarifer(5–10%),Pseudosciaena crocea(10%),Paralichthys olivaceus(2.3–11%), andPenaeus vannamei(6%), and boosted growth, feed efficiency, immune parameters, intestinal health, and disease resistance [9–12]. In cephalopods, Le Bihan et al. [13] used protein hydrolysates (< 6.5 DA) in diets for juvenile cuttlefish (Sepia officinalis), with supplementation contributing to healthy, fast growth and higher survival.\n\nThe four-eyed octopus (Octopus maya) is an integral part of food security, supporting human health and socio-economic development in the Yucatan Peninsula, Mexico. Owing to its direct development, fast growth, short life cycle, easy adaptation to captivity and high international market value,O. mayais recognized as an innovative species for aquaculture [14,15].O. mayais a carnivorous species and large protein and amino acid contents in the diet are needed to fulfill energy demands [16]. Therefore, protein is the most important and costly component in octopus feeds. Previous studies have focused on the nutritional effect of several protein source in diets forO. maya; concerning growth and feed conversion, the best performances were obtained with diets composed of crab (Callinectes sapidus) or mixed (squid/crab) [17–23]. Thus, diets with 70% squid meal (Dosidicus gigas) and 30% blue crab meal are currently the best forO. maya, regarding costs [19]. However, there are some concerns about using squid/crab protein in octopus diets, mainly related to costs and availability. Therefore, it is necessary to find ingredients or food additives that improve the performance and functionality of diets to obtain higher production of octopus at a commercial level.\n\nCurrently, the “Moluscos del Mayab” cooperative farmers octopuses on a pilot scale in the port of Sisal, Yucatán. Consequently, this farmer currently demands sustainable protein ingredients that can compete with crab and squid meals regarding nutritional quality and economic feasibility; therefore, the exploration of feed ingredients from marine biowastes plays a pivotal role for octopus fattening. In our previous study, silage from fish by-products showed a high protein content with an adequate balance in amino acids, which makes it an attractive source of not only protein, but also functional peptides (unpublished data). Therefore, fish hydrolysate derived aqueous phase could have peptides with different molecular weight that promoteO. mayagrowth and health. To our knowledge, no information on the effects of FPH supplementation onO. mayajuveniles, whose digestive features suggest the need for easily digestible food, has been reported. Thus, the present research could provide information for a potential solution to problems of the ingredients supply for octopus. Therefore, the main goals of this study were to determine the nutritional composition of fish protein hydrolysate and subsequently, the effects of the inclusion of protein hydrolysates in diets forO. mayajuveniles on growth and physiological condition.\n\nThis research was conducted under the Ethics and Scientific Responsibility Commission (CEARC) of the Facultad de Ciencias at Universidad Nacional Autonoma of Mexico, permit approval no. 25102021. No specific collection permits were required given that octopus juveniles were provided by Laboratorio de Ecofisiología Aplicada of the Unidad Multidisciplinaria de Docencia e Investigación (UMDI-UNAM). The octopuses were sedated with cold seawater (15 °C) and euthanized by brain puncture [24,25]. Moreover, a strong effort was directed to minimize animals killing, and the minimum necessary number of animals involved in the experiments.\n\nFish wastes were obtained from the Tigres del Mar Fishermen Cooperative, (Sisal, Yucatan, Mexico) from September-October 2023. They consisted of white grunt (Haemulon plumierii) heads, frames, trimmings, and guts. Fish protein hydrolysate was produced by autolytic hydrolysis process facilitated by the action of the endogenous enzymes present in the fish waste. The wastes were mixed with water at the rate of 30% (w/v) and homogenized using an industrial blender (LM-12, Torrey, Mexico) [26]. The minced samples were then divided into three portions (5 kg each part) and placed in plastic containers (20 L) followed by the addition of formic acid (88%) at the rate of 20 mL kg-1to reduce the pH to 3.8–4.0 according to Gallardo et al. [26]. Butylated hydroxytoluene (BHT) was added at a rate of 0.02 mg 100 g of fat as an antioxidant and kept at room temperature (30–33 °C). The samples were homogenized daily, and the pH was measured with a digital pH meter and adjusted to pH 3.8–4.0Fig 1. After 5 days of ensiling the samples were filtered through two layers of cheesecloth to remove undigested material (bones). The hydrolysis process was monitored, and samples were collected for protein and SDS-PAGE analysis. After 15 days, the hydrolysate obtained was used for the separation of fractions by centrifugation at 7000 × g at 20 °C for 30 min. The water-soluble fraction collected after centrifugation was categorized as FPH. Finally, the FPH was freeze-dried (Labconco FreeZone 12, Labcono Corporation) and stored at −20 °C. The degree of hydrolysis estimation was determined by formal titration according to Noman et al. [27]. The total nitrogen was determined following the Kjeldahl method.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321572.g001\n\nGel electrophoresis analysis was done according to the method of Haider et al. [28]. The samples was mixed at a 1:2 (v/v) ratio with sample buffer (0.1 M Tris-HCl, pH 6.8, containing 1% SDS, 20% glycerol, 4% β-ME and 0.02% Coomassie blue) and heated to 100 °C for 5 min and samples were run on a acrylamide gel (4% stacking and 10% separating) using Tricine-SDS-PAGE until the dye front reached the end of the gel. The gel was stained with Coomassie solution for one hour and then destained with water until clear bands were visible.\n\nThe dried sample was dissolved in ultrapure water at 30 mg mL-1and fractionated through membrane of molecular weight cutoff (MWCO 30 DA) to separate small peptides. The filtrate was recovered, and the molecular weight distribution was analyzed by gel permeation chromatography (GPC) using the column (Phenomenex-Yarra 3 μm SEC-2000 145 Å SEC 300 × 7.8 mm). The acetonitrile/water/trifluoroacetic acid 10/89.9/0.1(v/v) was used as the mobile phase at a flow rate of 1.0 mL min for 20 min, and the column temperature was 25 °C. The 20 μL of sample was injected into the liquid chromatography system and the absorbance was monitored at 215 nm. The average molecular weight of protein hydrolysate was calculated from the standard curve drawn of the standards, ovalbumin (45000 Da), ribonuclease (13700 Da), bacitracin (1420 Da), and dipeptide GG (132 Da), and the data were analyzed using the Agilent galaxies software.\n\nChemical composition was determined by the standard official methods of the A.O.A.C. (Association of Official Analytical Chemists) [29]. The total nitrogen content was determined by the Kjeldahl method (method 928.08). The protein content of silage was obtained using the standard nitrogen to protein conversion factor of N × 6.25. Determination of moisture in silage was quantified using the gravimetric method (105 °C for 12 h) (method 950.46), and ash content was measured by combustion in a furnace at 550 °C (method 920.153). Total lipids were measured by modifying the Folch extraction method [30].\n\nSamples were hydrolyzed with 6 N hydrochloric acid and 0.06% phenol and incubated in a nitrogen atmosphere at 113 °C for 18 h [31]. After hydrolysis, samples and standards were derivatized with OPA and FMOC (O-phthaldehyde: Fluorenylmethyloxycarbonyl) reagent and reconstituted in a sodium phosphate buffer. Finally, amino acids content was analyzed by HPLC system (Agilent Technologies, Santa Clara, CA, USA). Amino acid quantification was done using a standard amino acid mixture as reference and expressed as g 100g-1dry sample.\n\nThe diet formulation was done following Gallardo et al. [19]Table 1. FPH0 (basic diet, 0% of FPH), FPH10 (10% of FPH), FPH15 (15% of FPH), and FPH20 (20% of FPH) were done to replace an equal percentage of crab meals. All ingredients were grinded into a fine powder, passed through a 250 µm mesh, and mixed in a kitchen Aid K45ss blender. The mixture was then pelletized with a meat grinder (Torrey M-12-FS, Mexico), dried at 55 °C for 1 h, packed in sealed bags, and kept at 4 ºC until use. Proximate analysis was performed as described previously.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321572.t001\n\nA total of 80 octopuses (0.103 ± 0.004 g) were used and placed individually in plastic containers (1 L capacity) with mesh walls to allow adequate seawater circulation. A 1/2“ PVC elbow was placed in each plastic container as a shelter. Individualized octopuses were then randomly distributed in 4 rectangular tanks (1.5 x 1.2 x 0.4 m) (20 octopuses experimental diet). Octopus were fed with experimental diets for 70 days. Ammonia, nitrite, and nitrate concentrations were determined once a week in each tank using a kit AQ-4 (LaMotte, 363504). Temperature, salinity, pH, and dissolved oxygen were also recorded daily using a YSI Pro20 (Yellow Spring Instruments, Yellow Spring, OH, USA). Sea water quality parameters were recorded daily and maintained within the adequate ranges for this species [14]. In these conditions, dissolved oxygen was maintained between 5 and 6 mgL‐1, salinity at 36 ups, and temperature between 25 and 27 °C. Nitrate, nitrite, and ammonia were always lower than 10, 0.15 and 0.6 mg L‐1respectively. Light was maintained at 75 lux cm2.\n\nAt the end of the feeding trial, octopuses were weighed in a glass container with seawater 5 seconds after being removed from the water, to allow more accurate measurements. The weight gain (WG), specific growth rate (SGR), average daily gain (ADG), survival rate, hepatosomatic index (HSI) were calculated using the following formulas:\n\nTo obtain the different tissues, octopuses were sedated with the cold seawater bath (15 °C) for 1–2 min and euthanized by brain puncture [24,25]. The digestive gland (DG) and arms were removed, frozen in liquid nitrogen and stored at –80 °C until analysis. Glycogen in tissues was determined using the method described by Carroll et al. [32]. DG and arms (20–30 mg) were homogenized with trichloroacetic acid (TCA 5%) using Minilys-Personal Homogenizer (Bertin Technologies, Paris, France) and centrifuged at 4500 × g for 5 min. Subsequently 100 μL of supernatant was piped into a tube and mixed with 500 μL of ethanol 95%. Tubes were mixed and placed in an oven at 37 °C for 3 h. After, the tubes were centrifuged at 4550 × g for 15 min at 25 °C. The supernatant was discarded, leaving the glycogen as a pellet. By adding 1 mL concentrated sulfuric acid and 200 μL phenol 5%, glycogen was dissolved. From the mix, 200 μL was transferred to a microplate and read at 490 nm in microplate reader.\n\nDG sample was homogenized with cold pyrogen-free water (1:20, w/v) using a Minilys-Personal Homogenizer for extraction of enzymes. The samples were centrifuged at 10000 × g for 20 min at 4 °C. The supernatants (DG extracts) were stored at −80 °C and used for all enzyme analysis. Total soluble protein was measured by the method Bradford [33] using a commercial chromogen reagent (Bio-Rad, #500–0006). The activity of total proteolytic enzymes was determined as described by Anson [34]. Acid protease activity was assayed using hemoglobin (1% dissolved using Stauffer solution pH 3) as substrate. The enzyme extract and substrate were mixed (1:10), and then the tubes were incubated for 10 min at 37 °C. The reaction stopped with trichloroacetic acid at 20% and cooled for 15 min at 4 °C to allow protein precipitation. The extracts were centrifuged at 10000 × g for 15 min. The absorbance of the supernatants was measured by a spectrophotometer at 280 nm. The same procedure was used to determine alkaline peptidases activity, with casein at 1% as substrate at pH 8. All enzyme activities were calculated in the same way to unify units and thus expressed as U mg-1protein, where one unit of enzyme activity was defined as the change of absorbance per min.\n\nData were tested for normality (Kolmogorov–Smirnoff test) and homogeneity of variance (Levene’s test) at a significance level of 5% prior to further analysis. One-way analysis of variance (ANOVA) was performed, followed by Duncan’s test to compare mean values between treatments at (p < 0.05) using Statistica software® (version 10.0). All results are presented as mean ± standard deviation (SD).\n\nThe soluble protein was measured to monitor the progress of hydrolysis during ensiling over time. As seen inFig 2A, after 24 h of hydrolysis (D1), the soluble protein content showed a sharp increase. This could be explained by sarcoplasmic proteins released during the proteolytic breakdown of tissue cells, which increases the concentration of proteins in the water-soluble fraction [6]. Subsequently on D3, a slight decrease was observed, indicating breakdown of the peptide bonds of polypeptides to yield smaller peptides and/or free amino acids. The degree of hydrolysis (DH) observed for the fish hydrolysate was 49.6 ± 2.0%, indicating the presence of enzymes naturally found in fish waste with high activity at acidic pH (e.g., pepsin). Fish pepsins are generally stable at low pH and their optimum activity is in the range of 2.0–4.0 [35]. In this study, during the whole hydrolysis period, the pH and temperature were maintained in the range of 3.3–3.8 and 29–33.9 °C, respectively. Different studies have reported the application of commercial enzymes (e.g., alcalase, flavourzyme, neutrase, papain, and bromelain) to produce protein hydrolysates with a high DH [36–38]. However, Opheim et al. [39] concluded that the addition of papain and bromelain only slightly enhanced DH compared to the hydrolysate produced with only endogenous enzymes (48.6 vs. 48.0%). Also, autolysis is regarded as an economical and simple process to obtain FPH [40].\n\nLane M: protein marker; lane 0, 3, 5, 8, 10, and 15 days of hydrolysis; unused lanes are marked with an X.\n\nLane M: protein marker; lane 0, 3, 5, 8, 10, and 15 days of hydrolysis; unused lanes are marked with an X.\n\nhttps://doi.org/10.1371/journal.pone.0321572.g002\n\nElectrophoretic analysis was used to visualize formation of lower molecular weight proteins (S1 Fig). The protein pattern of day one (D0) showed mainly fragments with molecular sizes above 50 DA. On the D3, new bands appear in 40 and 30 DAFig 2B. These bands began to disappear gradually after D5 hydrolysis, except for bands >60 DA. At the end of hydrolysis (D15), the bands >60 DA disappeared while the 40 and 30 DA bands persisted. Several types of proteases (including pepsin, trypsin, chymotrypsin, and collagenase, etc.) are present in fish waste, of which pepsin is the main acid protease in fish viscera with a molecular weight ranging from 27 to 42 DA [35,40]. This may indicate that the persistent bands could be endopeptidases such as pepsin. In addition, bands with molecular sizes below 15 DA predominated during the whole hydrolysis period. The yields of fraction were > 30 DA (13%) and < 30 DA (87%). Potential applications of FPH are wide, covering its use as food ingredients and additives in aquaculture feed, but positive effects depend largely on the molecular weight of peptides [41]. The FPH had a high content in peptides with a molecular weight above 2000 Da (Table 2). Similar values (1–10 DA) was also observed in hydrolysates produced from fish wastes [41]. This molecular weight is advantageous for the discovering of bioactive peptides such as antibacterial, inflammatory, and antioxidant peptides [4,37].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321572.t002\n\nHydrolysis of fish raw material resulted in four fractions after centrifugation: sediment, oil, emulsion, and water-soluble compounds.Fig 1Cshows the evolution of fractions distribution during the 5, 10 and 15 days of hydrolysis. The oil content did not change while water-soluble increased and sediment decreased. During hydrolysis, it is generally desired to optimize the hydrolysate yield while minimizing emulsion and sediment fractions [6]. In terms of yield, at the end of the hydrolysis period (D15) the water-soluble fraction (protein hydrolysate) was 67% of the total hydrolysate (dried powder). The hydrolysate yield in D5 was lower than the yield achieved in D10 and D15. The difference in the yield was related to the decrease in sediment content, which is expected, as more proteins in the raw material are cleaved to smaller soluble peptides during hydrolysis and recovered in the soluble fraction, while insoluble materials are recovered in the sediment. This is in accordance with previous reports for other fish hydrolysates [6,42].\n\nThe proximate composition of the FPH is shown inTable 2. In terms of moisture content, the FPH contains lower levels than the silage. Ash content, representing the mineral fraction, showed lower content in protein hydrolysate. As expected, the FPH contained a higher protein concentration and lipid low value compared to silage. The protein content is also comparable to other studies, with values which ranged from 60 to 90% depending on which raw material was included for the hydrolysis [6,37,43]. Low lipid content in FPH was expected due to the silage centrifugation to separate insoluble and undigested substances. The low lipid content in protein hydrolysate is generally desirable to reduce lipid oxidation, in fact high-quality hydrolysates are characterized by a high protein content [37], but the content and type of amino acids is usually the primary determinant of nutritional quality of protein. Other authors have also reported comparable results in fish hydrolysates composition [37,43,44].\n\nTable 3shows free and total amino acids in the FPH. In the present study, we identified seventeen amino acids, encompassing nine essential amino acids (EAA´s; 182 mg g-1) and eight non-essential amino acids (NEAA´s; 427 mg g-1). At the same time, the free amino acids (FAA´s) content was 8.3% of the total amino acids content. FAA´s contents of 30% were previously reported for protein hydrolysates obtained from waste products ofGadus morhua[45]. The FAA`s content depends on the enzymes, the time of hydrolysis, and the DH, as FAA´s is liberated during proteolytic hydrolysis of peptide bonds [6]. It is important to note that taurine was the only amino acid found in a higher concentration in the FAA´s when compared to the total amino acid fraction. It is known that taurine, a free amino acid, is not part of the protein polypeptide chain and hence is found in a greater proportion in the free amino acid fraction [46]. In terms of NEAA´s, FPH contains high amounts of glutamic acid (Glu) and aspartic acid (Asp) 157 and 86 mg g-1, respectively. These amino acids contribute to palatability. In fact,O. mayadiets contain high amounts of these amino acids [19]. Also, Glu plays a critical role in amino acid metabolism because of its role in transamination reactions and is necessary for the synthesis of key molecules, such as glutathione, and Asp is the precursor of methionine (Met), threonine (Thr), isoleucine (Ile), and lysine (Lys) [47].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321572.t003\n\nThreonine (Thr), histidine (His), leucine (Leu), and Phe (phenylalanine) are EAA´s dominant in the muscle ofO. mayajuveniles [19], therefore play a crucial role for muscle development and these must be obtained through diet to support the high growth rate of cephalopods, seeFig 3. In cephalopod species, Glu, Asp, glycine (Gly), Lys, Leu, and Arg are the six key amino acids from a nutritional viewpoint, promoting growth, regulation of immune systems, and overall health [16,48]. These amino acids represent 70% of the total amino acids in FPH. Furthermore, in octopus it was demonstrated that Phe, Ile, alanine (Ala), Glu, and serine (Ser) are used as metabolic fuel [16,49]. In general, the amino acids are biomolecules that play important roles in cell signaling, nutrient transport, metabolism, and they precursors for synthesis of a wide range of biologically important substances such as phosphatidylserine, sphingomyelin, and cerebrosides, all related to growth and development [50].\n\n[19] (A). Growth ofO. mayajuveniles fed FPH diet (B).\n\n[19] (A). Growth ofO. mayajuveniles fed FPH diet (B).\n\nhttps://doi.org/10.1371/journal.pone.0321572.g003\n\nThe knowledge of FPH composition provided information on nutritional quality and potential nutritive value forO. maya.The protein requirements ofO. mayain captivity, which range between 60–70%, have been effectively met using blue crab and squid meal [19]. Consequently, these ingredients have become crucial in advancingO. mayaaquaculture. Although FPH is high in protein and low molecular weight peptides (oligopeptides), it contains lower levels of essential amino acids (EAA), such as His, Ile, Phe, Leu, Arg and Thr, compared to crab or squid meal (Fig 3). Therefore, this aspect was considered when designing the experimental diets in this study (crab substitution) and ensuring the essential amino acid requirements for optimal growth ofO. maya.\n\nResults on growth performance and body indices ofO. mayaafterad libitumfeeding for the experimental diets are shown inTable 4. All diets were well accepted and there was no sign of rejection of the pellets. The octopuses showed clear growth in all groupsFig 3B. However, the highest final weight (p < 0.05) was detected in FPH15 fed octopuses; indeed, weight was 29-fold of the initial body weight. By the end of the experiment, significant differences in survival rate were observed among the diets (Table 4). It is noteworthy that a higher survival rate was found in the treatment FPH15 (90%), whereas the octopuses fed as FPH0 showed the lower survival rate (72%). Indeed, a 10% decline in survival was observed in octopuses fed FPH15 diet at 60 days. These results are in line with our previous study in octopus, in which survival was related to silage-based diets (unpublished data). Weight gain and SGR showed significant differences among experimental diets (p < 0.05). Octopuses fed with FPH15 had the highest WG and SGR compared to other treatments (Table 4). However, octopuses fed with diets containing the highest level of FPH (20%) had the lowest values of WG. These results are in accordance with previous studies inDicentrarchus labrax[51],L. vannamei[11], andRhamdia quelen[52], where the moderate inclusion of FPH had positive effects on nutritional indices and immune parameters leading to better gut health and survival rate. InO. maya, several studies have shown that the formulated diets using crustaceans and squid meals are still better compared to alternative protein sources [19–23]. Aguila et al. [21] found lower growth rate (SGR, 0.86% day-1) inO. mayafed the diet with soluble fish protein concentrate (CPSP: 0, 5, 10, 15, and 20%) against a crab diet (SGR, 3.71% day-1). Also, Martínez et al. [22] reported marginal (0.36% day-1) and negative (−0.73% day-1) SGR values in octopuses fed a silage-based diet.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321572.t004\n\nGenerally, protein hydrolysates are composed of small fragments of peptides, typically containing 2–20 amino acids [37]. They have quicker absorption and digestion rates than intact proteins [41]; as a result, can be rapidly absorbed by intestinal cells and enter the body more rapidly than larger nutrients, potentially generating signals that stimulate appetite. Indeed, certain free amino acids (such as Leu, Glu, Lys, and Tau) are known to have chemo-attractive properties for olfaction and/or ingestion in carnivorous species [52]. Le Bihan et al. [13], used marine by-product silage as a diet enrichment for feeding juvenile cuttlefish, the results show that peptide-enriched diets can improve growth and feed conversion ratio compared to non-enriched diets. They also point out that the fish silage contains mainly small peptides (< 6.5 DA), which can possess bioactive properties. Bioactive peptides are amino acid chains derived from proteins that, in addition to providing nutritional benefits, perform specific biological functions in the body. These molecules are characterized by having a molecular weight within the range of 0.2 to 2.0 DA [4,37]. In the present study, higher growth performance obtained with FPH inclusion may potentially be attributed to bioactive components in the hydrolysate such as small peptides (< 2.12 DA,Table 2); these nutrients could play a crucial role in enhancing diet taste and palatability and consequently its consumption. However, the relationship between small peptides and physiological benefits remains unclear.\n\nThe effects of diets on digestive enzymes activity are shown inTable 5. The study of digestive enzymes contributes to a better understanding of the digestion and assimilation of formulated feeds [53]. No significant differences in acid enzymes activities were observed among octopuses fed all experimental diets. These results agree with those previously reported forO. maya[19,21–23,54]. Protein hydrolysates have been studied in several aquatic animals, particular in fishes [4,10–12,55]; consistently, the results suggest that dietary inclusion of protein hydrolysates can stimulate protease activity and increase digestibility of protein. Also, they suggest that FPH contains peptides with the ability to stimulate production of insulin-like growth factors which may enhance fish growth. The positive effects recorded seem to depend on the rate of inclusion, usually an appropriate level [4,41]. In the current study, acid enzymatic activity showed an increase trend from lowest to highest inclusion levels, meanwhile, the alkaline enzymatic activity decreased. Similar findings were reported by Aguila et al. [21] who reported that general proteases and trypsin activity in the diets of wild octopuses (O. maya) fed with 15% CPSP were significantly higher, and lower values in octopuses fed 20% CPSP. The decrease in alkaline activity can be explained by the fact that the proteins in the FPH are already partially or fully digested. In this sense, the low molecular weight peptides in FPH may have reached the intestine faster, with a consequent decrease in secretion of alkaline protease. Research conducted by Nikoo et al. [55] showed that trypsin and pepsin activity inSparidentex hastaandAcanthopagrus arabicusjuveniles fed with FPH diets were lower than the control treatment, which may be due to the lack of metabolic energy expenditure to secret digestive enzymes by fish due to the high digestibility and absorption of di-, tri- and oligopeptides in FPH.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321572.t005\n\nOn the other hand, higher HSI values were observed in octopuses fed with FPH15 compared to FPH0. In general, HSI is used as indicators of physiological condition and nutritional status [19]. A higher HSI could indicate that octopuses have a better capacity to digest and store nutritional reserves such as glycogen in the digestive gland. However, the glycogen content (3.84 mg g-1) was high (p < 0.05) in the digestive gland of octopuses fed FPH0 compared to the other diets (average, 3.22 mg g-1). Glycogen in arm muscle (average, 0.55 mg g-1) was high (p < 0.05) in octopuses fed diets with FPH (Table 5). Rosas et al. [20] reported that muscle glycogen concentration was affected by the type of diet, with high values in animals fed clam (> 2 mg g-1) compared with the fresh crab (< 1.5 mg g-1). In general, glycogen content obtained here agrees with those previously reported for wild and farmed octopuses [19,21,22,54]. Research indicates thatO. mayajuveniles with higher SGR have higher glycogen content in the arm muscle [19,22]. InParoctopus digueti, the increasing glycogen content in the arm muscle reflects better use of the prey captured and therefore better body condition [56]. Arg is among the most metabolically active amino acids in cephalopods [50] and is highly used with source of glycogen production. In this sense, the Arg content could affect glycogen levels in octopus tissues fed protein hydrolysate diets, in fact the Arg content in FPH is lower compared to crab and squid mealFig 2.\n\nFinally, this study focused on the use of FPH as a component in diets for juvenile octopus, since feed costs inO. mayaaquaculture can represent a significant portion of the costs of production ≈50% (personal communication); the average price of fresh crab is ≈3 USD/kg respectively and may vary depending on factors such as regional availability. In this context, the use of FPH-based foods can improve the viability ofO. mayaaquaculture. The use ofH. plumieriiby-products to produce FPH is a practice that promotes a circular economy by closing the material cycle. The creation of small hydrolysis units for FPH production in coastal communities could generate economic benefits for small-scale fishers and processors, reduce pressure on blue crab, and decrease octopus feed costs.\n\nThis study demonstrates the nutritional potential of a fish by-product hydrolysate with a high protein content (61.8%) but a low concentration of essential amino acids (182 mg g⁻¹). Molecular weight distribution profiling of FPH demonstrated that 85% of the protein content comprised a peptide mixture, with molecular weights below 2.12 DA. Our study demonstrated that replacing up to 15% of crab meals in the diet ofO. mayawith FPH, does not compromise growth performance and survival. Hence, incorporating FPH into diets formulation may offer unique advantages in overall physiological well-being forO. maya; this is promising for the future of octopus farming. Although the current findings are promising, it is necessary to conduct studies aimed at determining the most appropriate level of inclusion of FPH in feeds and analysis of nutritional profiles in octopuses. Finally, the use of FPH provides a good option for increasing circularity and sustainable waste management solutions for the fishery industry.\n\nhttps://doi.org/10.1371/journal.pone.0321572.s001\n\n(TIF)\n\nThe authors thank DGAPA, UNAM for financial support a postdoc scholarship to Dr. Honorio Cruz López. The authors appreciate Dr. Sergio Rodrigues for gel permeation chromatography analysis and technical support from UMDI-Sisal staff: Ariadna Sánchez, Claudia Caamal, and Karla Escalante.",
    "category": "nutrition"
  },
  {
    "title": "Investigating the application of IoT mobile app and healthcare services for diabetic elderly: A systematic review",
    "authors": "Jinglong Li, Rosalam Che Me, Faisul Arif Ahmad, Qisen Zhu, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321090",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321090",
    "content": "As the prevalence of diabetes increases among the elderly population, effective management becomes increasingly crucial. IoT mobile applications offer promising solutions for diabetes care by providing real-time monitoring, medication management, and lifestyle support. This paper aims to investigate the potential applications and challenges of IoT mobile applications in managing diabetes among elderly patients. Three databases including Scopus, Web of Science, and IEEE were systematically searched; 29 articles were screened in the final analysis process. Key results indicate that the application of mobile apps includes blood glucose monitoring, medication adherence, promotion of physical activity, and dietary control. Devices such as continuous glucose monitors and smart pill dispensers significantly improve glycemic control and medication adherence rates, these technologies enable real-time tracking, personalized feedback, and timely interventions, which enhance self-management and communication with healthcare providers. However, technical challenges like interoperability, data security and privacy, usability and involvement of policymakers pose significant barriers to their effective implementation. Collaborative efforts from healthcare providers, device manufacturers, and policymakers are essential to overcome these barriers and fully leverage the benefits of IoT technologies in diabetic elderly care. This review highlights the need for collaborative efforts to develop standardized frameworks that ensure device compatibility and seamless data integration in IoT solutions for diabetic elderly care, enhance data privacy with advanced technology, and design user-friendly apps for the diabetic elderly to improve the generalization and adoption of IoT IoT mobile applications in healthcare fields for elderly.\n\nCitation:Li J, Me RC, Ahmad FA, Zhu Q (2025) Investigating the application of IoT mobile app and healthcare services for diabetic elderly: A systematic review. PLoS ONE 20(4):\n           e0321090.\n        \n        https://doi.org/10.1371/journal.pone.0321090\n\nEditor:Vishal Sorathiya, Parul University, INDIA\n\nReceived:August 20, 2024;Accepted:February 28, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Li et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:This research was funded by a grant from Universiti Putra Malaysia Geran Putra grant (GP-IPS). NO: [GP-IPS/2023/9772400]. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:NO authors have competing interests.\n\nOver the decades, the growing number of diabetes has become a public health concern, particularly among the elderly population due to their high development of diabetes [1]. The increasing prevalence of diabetes in the ageing population is caused by several factors such as ageing, sedentary lifestyles, and unregular dietary habits [2]. Managing diabetes in the elderly population presents huge challenges, including multiple complications, age-related physiological changes, and the need for continuous healthcare services to prevent complications [3]. Hence, diabetic elderly patients suffer serious issues in their daily lives such as medication adherence, regular blood glucose monitoring, and maintaining a healthy lifestyle [4]. Cognitive decline and physical limitations among diabetic elderly would further complicate self-management. Therefore, special healthcare for the diabetic elderly is urgent and important [5].\n\nIn recent years, the development of Internet of Things (IoT) technology has experienced a soar revolution and developed into various sectors, including healthcare [6]. IoT mobile applications, equipped with sensors and connected devices, can offer innovative solutions to improve chronic disease management [7]. These applications facilitate real-time data collection, remote monitoring, and personalized feedback, making them particularly suitable for managing conditions like diabetes in the elderly population [8]. IoT mobile applications enable to solution those of challenges faced by elderly diabetic patients. For instance, IoT-enabled glucometers and continuous glucose monitors (CGMs) can provide real-time tracking of blood glucose levels, alerting patients and healthcare providers to any abnormal readings. Medication management apps can remind patients to take their medications and track adherence [9]. Fitness trackers and dietary monitoring apps can help patients maintain a healthy lifestyle by providing personalized recommendations and feedback [10].\n\nDespite the potential, IoT applications for diabetic elderly management still face several issues nowadays [11]. Technical challenges such as interoperability between devices, data security and privacy concerns, and the need for reliable wireless connectivity are significant barriers [12]. Additionally, diabetic elderly often find it difficult to use and accept these new mobile applications due to their cognitive and physical limitations and declines, necessitating user-friendly designs and comprehensive training and support [13].\n\nThe purpose of this systematic review paper is to investigate the current and development status of IoT mobile applications and healthcare services designed for diabetic elderly patients and to explore the benefits, challenges, and potential future directions of these technologies, emphasizing their impact on patient outcomes and quality of life. By identifying and addressing the current issues and status, this paper seeks to highlight how IoT applications can be optimized to better provide healthcare to serve the needs of the diabetic elderly as well as an insight review result for researchers.\n\nThis research adopted a systematic review of related articles that focus on a specific topic and organizes a review framework rather than a sample of (mainstream) journals and conferences during a limited time: the IoT mobile applications for diabetic elderly in the healthcare service context [14]. A systematic review was searched through those databases of Scopus, Web of Science (WoS), and IEEE Xplore (IEEE), and related articles were searched according to keywords in this search strategy (Terwee et al., 2009). Adopting the person, exposure (intervention), comparison, outcome (PECO/ PICO/ PIO) format search approach [15], articles were searched through the search terms: P: “diabet* old*”, “diabet* elder*”, “diabet* aged”, “diabet* senior*”; I: “mobile app*”, “IoT”, “application*”, “mobile”, “app*”, “smart technolog*”, “digital solution*”; O: “healthcare”, “health care”, “service*”, “chronic disease management*”.\n\nThrough the PIO search terms, keywords ((“diabete* old*” OR “diabete* elder*” OR “diabete* aged” OR “diabete* senior*”) AND (“mobile app*” OR IoT OR application * OR mobile OR app*) AND (healthcare OR “health care” OR service*)) are keyed in to search for specific research in databases (Scopus, WoS, and IEEE). The search period time was set to cover the publications from 2014 to 2024. As a search result listed inTable 1, a total of 147 articles were found.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321090.t001\n\nIn the process of selecting the articles, the 147 articles will be carefully selected and removed according to the criteria listed inTable 2. Before proceeding to the next screening process, duplicate articles were removed. For those articles that go through the screening process, the full-text article of each study was independently examined by the author.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321090.t002\n\nAlthough the purpose of this systematic review is descriptive, we assessed the risk of bias using the Cochrane risk-of-bias tool for randomized trials version 1 (RoB 1) [17]. Cochrane risk-of-bias tool is a commonly used tool to assess studies. The tool evaluates six domains, namely: random sequence generation, allocation concealment, blinding of participants and personnel, blind of outcomes assessment, incomplete outcome data and selective reporting. –,? and +  represents either a high, unknown or low risk of bias, respectively. Within each domain, assessments are made for one or more items, which may cover different aspects of the domain, or different outcomes. If any domain was not rated “low”, the overall risk of bias was considered “high”. The assessment is attached toS2 File, (Sheet: Cochrance RoB1) includes the risk of bias assessment.\n\nEach article’s quality was assessed by the Critical Appraisal Skills Programme (CASP)’s Quality Appraisal Tool systematic review checklist, and the result is presented in the form of a table. CASP is a tool that assists researchers in critically evaluating the quality of research studies. It provides a structured framework for assessing various aspects of study design, methodology, analysis, and reporting, helping users determine the trustworthiness, relevance, and validity of research findings [18]. The following part will emphasize the application and usage of CASP to evaluate each article in the screen section.\n\nThe PRISMA screen flow is presented inFig 1. Through a systematic search, a total of 147 articles were identified, later 33 of those articles were found to be duplicates and were eliminated. As a result, 114 articles still needed to be screened. The first screening process was the title screening, unrelated title articles were removed in this process, accounting for 56 articles; abstracts that did not focus on topics were also removed. Therefore, a final 10 articles were removed. The remaining articles were further screened according to inclusion and exclusion criteria; therefore, another 19 articles were removed. The remaining 29 articles were assessed for eligibility and extracted for literature review.Table 3recorded the quality evaluation results of the CASP appraisal for all included articles, the quality of those total 29 articles was systematically assessed using the CASP checklist. The CASP tool focuses on key aspects such as study aims, recruitment methods, exposure and outcome measurement, and the handling of confounding factors. In this table, 29 articles are rated using a color-coded system: green indicates the criterion was met, orange suggests uncertainty or incomplete information, and red signifies the criterion was not fulfilled. Most articles demonstrated strong methodological rigor, with green markings across most evaluation criteria. However, a few articles were found lacking in addressing confounding factors, as seen by red or orange marks in the “Identified confounding?” and “Addressed confounding?” columns. Despite some variation in addressing confounding factors, all 29 papers ultimately met the necessary qualifications for inclusion, as they demonstrated sufficient methodological rigor and relevance across the key CASP criteria. This evaluation highlights the overall quality of the research while identifying specific areas of methodological concern, providing a clear basis for assessing the reliability and applicability of the findings in the context of a systematic review.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321090.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321090.g001\n\nSeveral attributes were coded and analysed under this study’s research aims. These characteristics are as follows: The remaining research articles were subjected to quality screening based on the various inclusion and exclusion criteria mentioned inTable 2. Therefore, the final articles were reviewed down to 29 articles as shown inFig 1. These articles were incorporated into the final step of data coding and analysis. According to the final screened articles, three themes can be classified, they were: (a) Health problems among diabetic elderly; (b) The application of IoT mobile app for diabetic elderly healthcare services; (c) The challenges of IoT mobile app for diabetic elderly healthcare services.\n\nMissing data can arise at various stages in a systematic review, including missing studies, outcomes, or summary data, and addressing these issues is crucial for ensuring the reliability of the findings. To minimize the risk of missing studies, we conducted an extensive literature search across multiple databases. Additionally, contacting authors directly was employed as a strategy to retrieve unpublished work or additional data. For missing summary data, methods such as extracting data from figures, using available online tools, or calculating results from raw data were applied when feasible. These approaches helped mitigate the impact of missing data and ensured a more comprehensive analysis.\n\n7 studies focused on talking about the health problems among diabetic elderly. The synthesis and details of these 7 studies are presented inTable 4, including publication year, thematic focus, research objectives, geographical context, and methodological data particulars in each article.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321090.t004\n\nAs a widespread chronic disease among the elderly population, diabetes is often neglected by the elderly population in their daily care. Diabetic elderly are facing health problems, against which they have specific characteristics and demands [27]. According to the screened articles, four serious and common diabetic-related issues are concluded suffered by diabetic elderly, including complications, hypo glycaemia, frailty and disability, and cognitive impairment.\n\nFirstly, complications are common issues popular in the diabetic elderly. They are at higher risk of suffering microvascular and macrovascular diseases compared to younger people [39]. Complications will have a serious influence on diabetic elderly’s living independence, self-care capability and daily life quality. Especially the episodes of cardiovascular and hypoglycemics are at the highest occurrences. According to the International Diabetes Federation worldwide guideline, “all diabetics over the age of 60 are considered to have a high risk of suffering cardiovascular [16].”\n\nAnother common diabetic-related disease is hypo glycaemia, which is an overlooked medical problem that is popular among the diabetic elderly. It is reported that a high risk of serious hypo glycaemia episodes has a high connection with a long duration of type 2 diabetic elderly. Frequent hypo glycaemia will increase the possibility of frailty among the diabetic elderly [20]. A quantitative number of diabetic elderly who need to inject insulin can be frail, decline in vision or suffer from cognitive issues. Hence, diabetic elderly must arrange insulin dose injections depending on daily and hourly glucose fluctuations, which can benefit the hypo glycaemia prevention for diabetic elderly [20].\n\nAdditionally, as diabetic elderly age, type 2 diabetes also has an increasing impact on functional autonomy [29]. Long-term diabetes accelerates the loss of skeletal muscle mass and its function, both of which are essential to preventing frailty, sarcopenia, and incapacity from happening. While losing both can result in a decrease of mobility and quickness of movement. Hence, sarcopenia is regarded as a significant indicator to measure the development of limb impairment and frailty in diabetic elderly [26].\n\nFinally, one of the major health issues for elderly individuals with diabetes is that prolonged diabetes can be linked to mild cognitive impairment and brain cortical abnormalities, leading to challenges in daily activities. This condition is associated with slowed mental, motor, and cognitive functions. Diabetes and dementia, including vascular dementia and Alzheimer’s disease, are highly prevalent and often coexist in the elderly population [25].\n\n12 studies focused on the application of IoT mobile app for diabetic elderly healthcare services. The synthesis and details of these 12 studies are presented inTable 5, including publication year, thematic focus, research objectives, geographical context, methodological data particulars, and variables analyzed in each article.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321090.t005\n\nDiabetes is a widespread chronic disease among the elderly population, presenting significant health challenges. The application of IoT mobile applications in healthcare offers promising solutions to enhance diabetes management for elderly patients. This section identified the findings on the application of IoT mobile apps in diabetic elderly healthcare services, then categorised the contributions into four fields: blood glucose monitoring, medication management, physical activity, and dietary monitoring.\n\nBlood glucose monitoring is a critical component of diabetes management, especially for elderly patients [32]. IoT-enabled devices, such as smart glucometers and continuous glucose monitors (CGMs), facilitate real-time tracking and management of blood glucose levels. These devices enable continuous monitoring of glucose levels, alerting patients and healthcare providers to any abnormal readings, which is crucial for preventing severe hypoglycemia and hyperglycemia. Data collected by these devices can be integrated with mobile applications for comprehensive analysis and trend identification. This integration aids in personalized treatment adjustments and better diabetes management [46]. Additionally, IoT devices can send real-time alerts and notifications to patients and caregivers, ensuring timely interventions and reducing the risk of complications. Studies have shown that using IoT-enabled glucose monitoring devices significantly improves glycemic control among elderly patients [38]. For instance, a study by Toschi and Munshi [30] found that elderly patients using CGMs experienced fewer episodes of severe hypoglycemia compared to those using traditional monitoring methods. The use of IoT-enabled mobile applications for diabetic elderly healthcare services has been explored as a promising solution to improve care outcomes and enable more effective monitoring. Another prominent example comes from Makan’s research, who present the case of MyDiaCare, a mobile application specifically designed for diabetes management in South Africa. The app combines real-time glucose monitoring with automatic alerts sent to caregivers and healthcare professionals, allowing for timely interventions. The study found that this approach significantly reduced hospital admissions for elderly patients by facilitating better glycemic control, even in remote areas with limited healthcare access [40].\n\nMedication adherence is another critical aspect of diabetes management for elderly patients. IoT applications for medication management offer various features to enhance adherence and ensure timely medication intake. These applications can send reminders to patients to take their medications as prescribed, reducing the likelihood of missed doses [30]. Smart pill dispensers and connected apps track medication intake, providing data on adherence patterns that can be shared with healthcare providers for better management [42]. IoT apps can also notify caregivers if a patient misses a dose, allowing for prompt intervention and support. Research indicates that IoT-enabled medication management tools improve adherence rates among elderly diabetic patients. A study by Baumgartner et al [33] found that elderly patients using smart pill dispensers had a 20% higher medication adherence rate compared to those using traditional methods. The integration of mobile apps into routine care has also been shown to improve patient self-management. For instance, Benis evaluated how the communication behavior between patients and healthcare providers changed when IoT mobile apps were introduced. The study indicated that elderly patients with access to mobile health apps experienced improved communication with their healthcare team, resulting in more personalized care plans and a higher rate of medication adherence. This was particularly effective in cases where patients were provided with simplified interfaces and training to overcome the initial technological barriers [31].\n\nMaintaining a healthy lifestyle through regular physical activity is essential for diabetes management. IoT devices such as fitness trackers play a crucial role in monitoring and promoting physical activity. Fitness trackers monitor physical activities, providing data on steps taken, calories burned, and active minutes. This data helps patients and healthcare providers assess and adjust activity levels to improve diabetes management [21]. Studies support the efficacy of IoT applications in promoting physical activity among elderly diabetic patients. A study by Chen et al [36] found that elderly patients using fitness trackers increased their physical activity levels by 30%. A notable empirical example is the collaboration between health services and tech companies to deploy mobile apps in large-scale trials. Karandeep illustrate how a pilot program in the UK incorporated IoT mobile apps to track health metrics of diabetic elderly patients. The study showed that after six months of continuous use, patients reported improved quality of life, and healthcare providers noted a significant reduction in emergency visits related to diabetic complications. This case underlines the practical applicability of IoT mobile apps in improving the quality of life for diabetic elderly patients, while also reducing healthcare costs by preventing complications [22].\n\nA balanced diet is crucial for diabetes management, and IoT devices like smart scales and dietary monitoring apps assist in this area. Mobile applications track food intake, provide nutritional information, and offer personalized dietary recommendations, helping elderly patients maintain a balanced diet and control blood glucose levels. By integrating data from various sources, IoT applications provide a comprehensive view of a patient’s health, facilitating more effective management strategies. Studies demonstrate that dietary monitoring apps help patients reduce their HbA1c levels by providing personalized feedback and support [37]. Makan et al. detail how the Diabetic App was deployed in a South African pilot study targeting elderly diabetic patients. The app integrates with wearable devices to monitor physical activity and blood sugar levels, providing real-time insights into the impact of dietary choices. For example, after meals, the app offers feedback on whether the user’s blood glucose level has stayed within an optimal range, helping patients to make immediate adjustments to their diet. Over a six-month period, users of the Diabetic App showed significant improvement in their blood glucose control and reported higher adherence to a balanced diet plan. The study highlighted a 15% reduction in HbA1c levels, reflecting better long-term glucose management. The Diabetic App also includes educational features that guide patients in making healthier food choices. By using machine learning algorithms, the app predicts the potential impact of various meals on a patient’s blood sugar, providing alternative meal suggestions to reduce spikes in glucose. This balanced diet management system, supported by real-time feedback, made a substantial difference in the quality of life of elderly diabetic patients, many of whom faced challenges in adhering to strict dietary plans prior to using the app [40]. This example demonstrates the practical applicability of IoT-based mobile apps in facilitating better diet management for diabetic elderly patients, contributing to improved health outcomes and long-term disease management.\n\nIn conclusion, the successful implementation of IoT mobile applications has significantly improved diabetic care for elderly patients across multiple areas, including blood glucose monitoring, medication management, physical activity, and dietary monitoring. These technologies enable real-time tracking, personalized feedback, and timely interventions, which enhance self-management and communication with healthcare providers. Studies consistently show improved health outcomes, including better glycemic control, higher medication adherence, increased physical activity, and better diet management, all of which contribute to a higher quality of life and reduced complications for elderly diabetic patients.\n\n10 studies focused on the challenges of IoT mobile app for diabetic elderly healthcare services. The synthesis and details of these 10 studies are presented inTable 6, including publication year, thematic focus, research objectives, geographical context, methodological data particulars, and variables analyzed in each article.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321090.t006\n\nDiabetes, as a pervasive chronic disease among the elderly population, demands continuous and meticulous management, which can be particularly difficult for senior patients. While IoT mobile applications provide innovative solutions, significant challenges still impede their effective use and integration into elderly healthcare services. This section delves into the most critical challenges identified in the literature, addressing both technical and non-technical barriers, and explores potential solutions for overcoming these issues. This part investigated the current challenges and barriers to the application of IoT mobile apps in diabetic elderly healthcare services, then classified them into four fields: interoperability, data security and privacy, usability, and involvement of policymakers.\n\nInteroperability remains a critical barrier in the deployment of IoT applications for diabetic care. Devices from different manufacturers often use incompatible communication protocols, leading to difficulties in integrating data across platforms. This lack of standardization hinders the seamless sharing of health data between healthcare providers, apps, and patients [24]. For instance, Ramesh emphasized the need for uniform communication standards to ensure that patient data such as glucose levels and medication information can be accurately transmitted and interpreted across different devices and platforms. Without interoperability, the risk of incomplete or inaccurate data increases, which could compromise patient safety and the quality of care provided [34]. To address this, future research could focus on developing frameworks that standardize data formats and communication protocols, ensuring compatibility between various IoT devices. Additionally, policy interventions led by healthcare regulators could mandate specific standards for interoperability, thus reducing the risk of fragmented healthcare data. Healthcare professionals and device manufacturers should collaborate to develop unified systems that prioritize patient safety and data accuracy, a step critical for long-term IoT integration [35].\n\nData security and privacy stand as central concerns in the adoption of IoT mobile apps for elderly diabetic care. These devices gather sensitive health information such as blood glucose readings, medication schedules, and lifestyle habits, making them prime targets for potential data breaches. Li et al. highlighted that elderly patients often lack the technical knowledge to assess the security risks associated with IoT apps [28]. Moreover, many patients expressed concern about who has access to their data and how it is stored, particularly in cases where app developers might not fully comply with healthcare data regulations [23]. Addressing these concerns requires more than technical fixes like encryption; it involves educating elderly users on the risks and benefits of IoT health services. Benis Bourke suggested that one way to increase user confidence is by developing clear, easy-to-understand consent protocols that inform patients of how their data is used and protected. Furthermore, introducing regulatory frameworks that ensure strict compliance with data protection standards can build trust among elderly users and their caregivers, making them more likely to adopt these technologies. Future research could explore the development of decentralized systems, such as blockchain technology, to further enhance data security and user transparency [41].\n\nUsability issues also pose a major barrier to the successful deployment of IoT mobile apps among elderly patients. The elderly population often struggles with complex interfaces and lacks the technical literacy needed to navigate advanced applications [44]. Shimokihara reported that 30% of the elderly participants in their study required assistance to use the MyDiaCare app. This reflects a broader issue where elderly patients find it difficult to engage with apps that are not tailored to their cognitive and physical needs [43]. To overcome this challenge, developers need to co-design mobile apps with elderly users in mind, ensuring that the interface is simplified, intuitive, and responsive to their limitations. For example, incorporating voice commands or larger, easily readable fonts could help address these usability barriers. Moreover, healthcare professionals play a key role in facilitating user adoption by offering training sessions and ongoing support to elderly patients. Personalized onboarding experiences that familiarize patients with the app’s functions can significantly improve user adoption and engagement over time [19].\n\nHealthcare professionals and policymakers play crucial roles in overcoming the challenges of IoT adoption. Benis et al. emphasized that healthcare providers should be trained to guide elderly patients through the use of mobile health applications, ensuring they feel comfortable with the technology and understand its benefits. Additionally, policymakers need to implement guidelines that promote the standardization of IoT devices, enforce data privacy regulations, and ensure that elderly patients are adequately supported in their use of mobile healthcare apps [45].\n\nIn conclusion, while IoT mobile applications offer promising solutions for diabetic care in the elderly, significant challenges such as interoperability, data security, usability, and policy involvement remain. Future research should delve deeper into developing standardized frameworks for device compatibility and data integration, as well as explore advanced security measures, such as blockchain, to enhance data privacy. Addressing usability issues requires co-designing apps with elderly users to improve accessibility and support. Additionally, involving healthcare professionals and policymakers in promoting training, standardization, and regulatory oversight will be critical for the successful and widespread adoption of these technologies.\n\nIoT mobile applications hold significant promise for enhancing diabetes management in elderly patients through improved monitoring, medication management, and lifestyle support. These technologies offer innovative solutions that can facilitate real-time tracking of blood glucose levels, ensure timely medication adherence, and promote healthy lifestyle choices. The potential benefits include better glycemic control, reduced complications, and improved overall quality of life for diabetic elderly individuals.\n\nHowever, several challenges must be systematically addressed to fully realize the potential of IoT mobile applications in diabetic elderly healthcare services. Technical issues such as interoperability, data security, and reliability remain significant barriers. To overcome these challenges, future research should focus on developing standardized frameworks for device compatibility, ensuring seamless communication between different devices and platforms. In terms of data security, regulatory compliance should be prioritized to protect sensitive health information, with solutions such as blockchain or decentralized systems offering potential ways to enhance data protection and transparency. Additionally, maintaining consistent connectivity and device accuracy is essential for effective diabetes management.\n\nUser adoption and usability also present considerable challenges. Elderly patients often face cognitive and physical limitations that can hinder their ability to effectively use IoT technologies [47]. Future solutions must prioritize designing user-friendly interfaces with simplified device operations, larger text, and voice commands [48]. Moreover, providing adequate training and support for elderly patients, as well as healthcare professionals guiding them, is essential to ensure long-term engagement and motivation. Personalized onboarding experiences, as well as ongoing support, can improve adoption rates and usage [49].\n\nFurthermore, managing and analyzing the vast amounts of data generated by IoT devices is a complex task. Healthcare providers need robust systems to store, manage, and analyze this data to provide actionable insights and personalized care. Future research should explore frameworks that ensure both technological advancements and user-centered design are prioritized in the development and deployment of IoT solutions for elderly care. Policymakers and healthcare professionals must play an active role in ensuring that these systems are not only compliant with privacy regulations but also designed to enhance patient autonomy and care outcomes.\n\nThis paper comprehensively investigated the current development and application of IoT mobile technologies in healthcare services for diabetic elderly patients, highlighting both the benefits and the challenges. The findings demonstrate that IoT mobile applications have the potential to transform diabetes management for elderly individuals by improving monitoring, medication adherence, and lifestyle management. However, addressing the challenges related to interoperability, data security, usability and involvement of policymakers is crucial for effective implementation. To fully harness the potential of IoT technologies in diabetic care, collaborative efforts from device manufacturers, healthcare providers, and policymakers are essential. Developing standardized communication protocols to ensure seamless integration across platforms, implementing robust data protection measures, and designing user-friendly interfaces tailored to elderly patients will mitigate the technical barriers. Providing comprehensive training and support for elderly patients and caregivers will further enhance user adoption and sustained engagement. However, the findings of this systematic review were limited by the inclusion of only 29 articles, which may restrict the generalizability of the conclusions. Future research and continued development in these areas will ensure that IoT mobile applications can significantly improve the health and quality of life for diabetic elderly patients as well as generalizability.\n\nhttps://doi.org/10.1371/journal.pone.0321090.s001\n\n(ZIP)\n\nhttps://doi.org/10.1371/journal.pone.0321090.s002\n\n(ZIP)",
    "category": "nutrition"
  },
  {
    "title": "Bioconversion of food waste byChrysomya megacephala(Diptera: Calliphoridae) larvae: Potential for sustainable waste management and antimicrobial applications",
    "authors": "Pluemkamon Phuwanatsarunya, Nophawan Bunchu, Worasak Kaewkong, Tongjit Thanchomnang, Ketsarin Thipphet, Sophit Khanthawong, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0320747",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320747",
    "content": "Addressing global food waste requires innovative and sustainable solutions. This study investigates the potential ofChrysomya megacephala(Diptera: Calliphoridae) larvae to convert food waste into valuable byproducts, while evaluating the antimicrobial properties of larval extracts. Under controlled laboratory conditions, the larvae reduced the weight of food waste by 21.87%, demonstrating their effectiveness in waste degradation. The optimal food waste-to-sawdust ratio was identified as 10:1. The bioconversion process resulted in 111.60-fold increase in larval biomass when reared on food waste and a 153.20-fold increase on fresh pork liver, highlighting their efficiency in converting protein-rich substrates. Larval extracts demonstrated significant antimicrobial activity againstBacillus subtilisandPseudomonas aeruginosa, with minimum inhibitory concentrations (MICs) of 100 µg/ml. Proteomic analysis revealed proteins with potential antimicrobial and antioxidative properties. Furthermore, the extracts promoted cell growthin vitrowithout showing cytotoxic effects on HaCaT cell lines, suggesting potential applications in wound healing and infection control. These findings highlight the capacity ofC. megacephalalarvae to reduce food waste while generating antimicrobial agents, offering a sustainable approach to waste management with promising implications in medical applications.\n\nCitation:Phuwanatsarunya P, Bunchu N, Kaewkong W, Thanchomnang T, Thipphet K, Khanthawong S (2025) Bioconversion of food waste byChrysomya megacephala(Diptera: Calliphoridae) larvae: Potential for sustainable waste management and antimicrobial applications. PLoS ONE 20(4):\n           e0320747.\n        \n        https://doi.org/10.1371/journal.pone.0320747\n\nEditor:Naji Arafat Mahat, Universiti Teknologi Malaysia - Main Campus Skudai: Universiti Teknologi Malaysia, MALAYSIA\n\nReceived:November 14, 2024;Accepted:February 23, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Phuwanatsarunya et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfile.\n\nFunding:We are grateful for the financial support from Naresuan University (NU) and the National Science, Research and Innovation Fund (NSRF) (Grant No. R2565B053).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe growing global population and rapid urbanization have led to an exponential increase in food waste, presenting significant environmental, economic, and public health challenges. The Food and Agriculture Organization (FAO) estimates that approximately 1.3 billion tons of food are wasted annually, accounting for nearly one-third of global food production [1]. Conventional food waste disposal methods, such as landfilling and incineration, contribute to greenhouse gas emissions, environmental degradation, and public health risks, including exposure to particulate matter (PM2.5) [2,3]. Furthermore, improper food waste management exacerbates issues such as water pollution, pathogen proliferation, and the inefficient use of valuable organic resources [4]. These challenges underscore the urgent need for sustainable and innovative waste management solutions.\n\nSimultaneously, the rising demand for animal feed, driven by increasing global meat consumption, emphasizes the need for alternative and sustainable protein sources. Traditional animal feed production is constrained by limited arable land, water scarcity, and the high environmental impact of crop cultivation [5]. Insects have emerged as a promising alternative, offering an efficient and resource-conscious method for waste bioconversion and the generation of high-quality protein for animal feed. Among these, blow fly larvae, including those ofChrysomya megacephala(Diptera: Calliphoridae), present an alternative with distinct advantages. UnlikeMusca domestica(Diptera: Muscidae) andHermetia illucens(Diptera: Stratiomyidae), which have been extensively studied for waste bioconversion,C. megacephalaremains underexplored despite its natural adaptation to decomposing protein-rich organic waste [6,7].\n\nIn this context,C. megacephala, a blow fly species with a global distribution, presents a unique and underexplored opportunity for sustainable food waste management. Known for its adaptability to diverse environments, including urban and rural settings,C. megacephalanaturally thrives on protein-rich organic waste [8], making it a suitable candidate for bioconversion applications. Beyond its role in organic matter decomposition, this species also exhibits biomedical potential, particularly in antimicrobial compound production. Previous research has confirmed the production of antimicrobial peptides (AMPs) byC. megacephalalarvae, which exhibit promising applications in wound treatment and infection control [9–11]. This dual utility in waste management and antimicrobial compound production positionsC. megacephalaas a valuable resource in addressing global challenges related to waste and public health.\n\nDespite its potential, research on the bioconversion capabilities ofC. megacephalalarvae remains limited. This study evaluates the efficiency ofC. megacephalalarvae in reducing food waste and explores the antimicrobial properties of their extracts. By addressing these dual benefits, this research contributes to the development of sustainable, environmentally friendly, and economically viable strategies for food waste management, while showcasing the potential biomedical applications ofC. megacephala-derived products.\n\nTheC. megacephalaadults used in this study were obtained from a laboratory-maintained strain. The larvae were reared in a controlled environment at 24–28 ±  0.5°C, 60–70% relative humidity, and a 12-h light/dark cycle, at the Department of Microbiology and Parasitology, Faculty of Medical Science, Naresuan University, Phitsanulok, Thailand. All animal experiments were conducted in strict accordance with the guidelines and regulations approved by the Naresuan University Animal Care and Use Committee (NUACUC, Protocol No. NU-AI670603). For maintaining the fly colony in the laboratory, adults were fedad libitumwith fresh pork liver and a 10% (w/v) sugar solution supplemented with 5% (v/v) multivitamin syrup (SEVEN SEAS, Thailand), while larvae were reared with fresh pork liver as previously described [8].\n\nFor the bioconversion experiment, an optimized culture medium was prepared with slight modifications to the method described by Niu et al. to support larval development in a cylindrical rearing box with a lid (diameter: 11 cm, height: 12 cm) [6]. The food waste used in this study primarily consisted of carbohydrate- and protein-rich materials (e.g., rice, meat, and vegetable scraps) sourced from a university cafeteria. The waste was initially drained using strainers and then left to settle at room temperature for 2 h. Fresh pork liver or food waste (200 g per group) was used, with 20 g of sawdust added as an adjuvant based on preliminary studies (unpublished data), and 0.15 g ofC. megacephalaeggs was added to each group. Negative controls (without fly eggs) consisted of fresh pork liver or food waste mixed with sawdust in the same ratio (10:1). After the eggs hatched, the culture medium was mixed approximately every 24 h. After five days, the larvae and culture medium were separated, and their weights were measured. Third-instar larvae were then collected for subsequent experiments.\n\nThe ES products were prepared using a modified method based on van der Plas et al. [12]. Third-instar larvae were collected from the rearing box, washed with 70% ethanol, and rinsed three times with sterile water. The larvae were distributed into 20 sterile 50 ml centrifuge tubes, each containing 100 larvae in 100 µl of sterile water. The tubes were incubated for 60 min at 24–28°C in the dark. After incubation, the ES products from all 20 tubes were pooled into a sterile centrifuge tube. A protease inhibitor cocktail (AMRESCO, OH, USA) was added to prevent protein/peptide degradation, and the pooled ES products were centrifuged at 1,300×  gfor 5 min at 4°C to remove particulate matter. The supernatant was filtered through a 0.45 µm syringe filter for sterilization, aliquoted into sterile microcentrifuge tubes, and stored at -20°C.\n\nThe whole-body extracts were prepared using a modified version of the method described by Choi et al. [13]. First, 400 inactivated third instars were homogenized in 200 ml of absolute methanol at a ratio of 2:1. The homogenate was incubated overnight at room temperature with continuous orbital shaking. The mixture was then transferred to centrifuge tubes and centrifuged at 4,000×  gfor 30 min at 4°C. The supernatant was collected and transferred to a flask, where it was concentrated using a Hei-VAP Core rotary evaporator (Heidolph, Korea). To further remove residual methanol, the concentrated extracts were subjected to centrifugal evaporator CVE-2200 (Eyela, Japan). The final concentrated extracts were resuspended in 5% DMSO, sterilized through a syringe filter, and 100 µl of the larval extracts were applied to blood agar and brain-heart infusion agar plates. These plates were incubated at 37°C for 48 h to ensure sterility before conducting antimicrobial assays.\n\nThe protein concentration in the extracts (ES and WE) was determined using the Bradford assay (Bio-Rad, CA, USA), with bovine serum albumin (BSA) as the standard. A 5% DMSO solution was used as the blank for WE, while dH₂O was used as the blank for ES. A series of sample dilutions was prepared, and 160 µl of each dilution was transferred into separate tubes. Subsequently, 40 µl of Coomassie Brilliant Blue reagent was added to each tube. The absorbance of each sample was measured at 595 nm, using SpectraMax®ABS and ABS Plus absorbance microplate readers (Molecular Devices, CA, USA). Protein concentrations were calculated by comparing the absorbance values to a standard curve generated from BSA.\n\nThis study employed a variety of microorganisms, including bacteria, yeast, and filamentous fungus, which were provided by the Department of Microbiology and Parasitology, Faculty of Medical Science, Naresuan University, Thailand. The bacterial strains includedBacillus subtilisDMST 5871,Pseudomonas aeruginosaTISTR No. 1467,Escherichia coliTISTR No. 887,Staphylococcus epidermidisDMST 15505,Staphylococcus aureusTISTR No. 1466, andStreptococcus pyogenesDMST 4369. The yeast strains includedCandida albicansDMST 8684 andMalassezia furfurCBS 1878, while the filamentous fungus includedAspergillus flavusDMST 22950. Bacterial cultures were grown on nutrient agar, except forS. pyogenes, which was cultured on blood agar. All bacterial cultures were incubated at 37°C for 24 h prior to use. Yeast strains were cultured on Sabouraud Dextrose Agar (SDA) at 37°C for 24 h, while filamentous fungus was grown on SDA and incubated at room temperature for 48-72 h. The study was approved by the Naresuan University Institutional Biosafety Committee (NUIBC, Protocol No. MI 66-12-54) to ensure adherence to biosafety standards.\n\nThe modified Kirby-Bauer method was employed to evaluate the susceptibility of bacteria and yeast to the larval extracts [14]. Bacterial suspensions were prepared at a McFarland standard 0.5 (108cells/ml), while yeast suspensions were prepared at a McFarland standard of 1 (106cells/ml). The suspensions were evenly spread onto Mueller-Hinton agar plates. Subsequently, 100 μg of the tested extracts (ES products or whole-body extracts) was applied to 6.0 mm blank paper disc (Schleicher & Schuell BioScience GmbH) and placed on the agar surface. The plates were incubated at 37°C for 24 h for bacterial cultures and at 30°C for 48 h for yeast cultures. Zones of inhibition were measured using a digital vernier caliper. Antibacterial (tetracycline 30 μg, penicillin 10 μg, ciprofloxacin 5 μg) and antifungal discs (fluconazole 1 μg, zinc pyrithione 20 μg) served as positive controls, while sterile 5% DMSO was used as a negative control. All assays were performed in triplicate, and the procedures were repeated to ensure reliability.\n\nThe agar toxicity testing protocol for filamentous fungi (A. flavus) was adapted from the methodologies of Armengol et al. and Elizabeth et al. [15,16]. In this test, 20 ml of sterile, warm SDA was mixed with the larval extracts to achieve a final concentration of 100 µg/ml. The mixture was thoroughly vortexed for uniform distribution and then poured into a Petri dish. A colony ofA. flavus, cut using a 6 mm cork borer, was placed at the center of the SDA plate containing the larval extracts. A growth control ofA. flavuswas placed on a separate SDA plate without the larval extracts, while SDA containing 10 mg of cycloheximide served as the positive control. The plates were incubated at room temperature for 2 to 6 days. After incubation, the growth and morphological characteristics of theA. flavuscolonies were measured and observed. The percentage of inhibition (% inhibition) was calculated using the formula:\n\nThe resazurin-based turbidometric (TB) assay was used to evaluate the inhibitory effects of ES products and whole-body larval extracts ofC. megacephalaonP. aeruginosaandB. subtilis. This assay was adapted from the method described by Teh et al. [17]. Broth dilutions were prepared according to the Clinical and Laboratory Standards Institute (CLSI) protocol. The extracts were diluted in Mueller-Hinton Broth (MHB) to obtain final concentrations ranging from 400 to 50 µg/ml. A bacterial suspension, diluted to 106cells/ml, was added to all tubes except for those designated as broth sterility and larval extracts sterility controls. Each bacterial species was tested in duplicate. Following overnight incubation at 37°C, resazurin solution (6.75 mg/ml) was added to each tube, and the tubes were incubated for an additional 4 h at 37°C. Color changes were monitored and recorded. The Minimum Inhibitory Concentration (MIC) was determined as the lowest concentration at which no color change was observed. To determine the Minimum Bactericidal Concentration (MBC), one microliter of each bacterial dilution was inoculated into nutrient agar plates by using a calibrated loop. After an additional 24 h incubation, the plates were examined for bacterial growth.\n\nProteins were purified using a Clean-up kit (GE Healthcare, IL, USA) and dissolved in 8 M urea. Protein concentration was determined using the Bradford method (Bio-Rad). For each sample, 30 µg of protein was diluted with 100 mM dithiothreitol in 100 mM TEAB for 30 min at 24–28°C, followed by alkylation with 100 mM iodoacetamide in 100 mM TEAB for an additional 30 min in the dark. The reaction was quenched with the reduction buffer for 15 min, and the proteins were digested with Trypsin Gold (Promega, WI, USA) at 37°C for 16 h. The mixture was dried using a nitrogen evaporator (Organomation, MA, USA), resuspended in 0.1% formic acid, and subsequently purified with a C18 Zip tip. The peptides were dried and stored at -80°C. To measure peptide concentration, the peptides were resuspended in 0.1% formic acid and measured using a NanoDrop 1000 (Thermo Fisher Scientific, Germany).\n\nPeptides were analyzed using a Nano-LC-MS/MS system, which consisted of a Dionex Ultimate 3000 RSLCnano System (Thermo Scientific) and a CaptiveSpray source/Quadrupole ion trap mass spectrometer (Q-ToF Compact, Bruker, Germany). One µg of peptides was enriched on a Nano trap column and separated on a PepMap100 C18 LC column. Elution was performed with a 2-95% Solvent B gradient over 90 min at a flow rate of 300 nl/min and at 60°C. The mobile phases used were A) 0.1% FA in water and B) 0.08% FA in 80% acetonitrile. The gradient for mobile phase B was as follows: 2% (5 min), 30% (60 min), 50% (10 min), 70% (5 min), 95% (5 min), followed by a rapid decrease to 2% and re-equilibration (5 min). The drying gas was set to 5 l/min at 150°C, with a nebulizer gas pressure of 0.2 bars. MS acquisition was carried out in positive ionization mode at 6 Hz, with a mass range of m/z 150-2200. AutoMSn CID fragmentation was performed at low (4 Hz) and high (16 Hz) rates for the top 2 precursor ions, with a 3-second dynamic exclusion. Peptide sequences were matched against the UniProt-Calliphoridae database using MASCOT (version 2.3). Search parameters included carbamidomethylation of cysteine (fixed modification), oxidation of methionine (variable modification), peptide tolerance of ± 1.6 Da, and MS/MS fragment tolerance of ± 0.8 Da. Proteins with MASCOT scores above the threshold andp-values <  0.05 were considered for analysis. This study specifically investigated proteins with molecular weights below 20 kDa, emphasizing their antimicrobial properties.\n\nThe cytotoxicity test was performed using a modified method based on Siriwath et al. [18]. Cytotoxic activity was evaluated against HaCaT (immortalized human keratinocyte cells) cells, which were provided by the National Center for Genetic Engineering and Biotechnology (BIOTEC), Thailand. The HaCaT cells were cultured in Dulbecco’s Modified Eagle Medium (DMEM) supplemented with 10% (v/v) fetal bovine serum (FBS) and an antibiotic solution containing 100 units/ml of Antibiotic-Antimycotic (Gibco, Thermo Fisher Scientific, MA, USA). The cells were maintained at 37°C with 5% CO2. The effect of ES products and whole-body extracts on cell proliferation was measured using an MTT assay (3-[4,5-dimethylthiazole]-2,5-diphenyltetrazolium bromide). HaCaT cells were seeded in 96-well plates at a density of 2 × 103cells/well for 24 h before being treated with various concentrations of ES products and whole-body extracts (0, 0.1, 1, 10, and 100 µg/ml). The cells were then incubated for 24 h. A 30% dimethyl sulfoxide (DMSO) solution was used as a positive control. After the incubation periods, 10 µl of MTT was added to each well to achieve a final concentration of 0.5 µg/ml, and the plates were incubated for an additional 3 h at 37°C. Following this, the medium containing MTT was removed, and the formazan crystals were dissolved in DMSO (Sigma-Aldrich, MO, USA). Absorbance was measured at 540 nm, and cytotoxicity was calculated using the formula:\n\nThis formula provided a quantitative measure of cell viability in response to the treatments.\n\nThe data are expressed as the mean ±  standard deviation (SD) derived from biological triplicate experiments. Statistical analysis was performed using Microsoft Excel for Mac (version 16.6.1, 22101101). The statistical significance of the differences between two different groups was determined with Student’s t-test using GraphPad Prism (version 8).p< 0.05 was considered to indicate a statistically significant difference. The significant indicators are *  =p< 0.05, ** =p< 0.01 and *** =p< 0.001.\n\nThe optimal culture medium ratio was determined to be 10:1 for food waste to adjuvant (sawdust). Under these conditions, 220 g of culture medium (comprising 200 g of food waste or fresh pork liver and 20 g of sawdust) was effectively processed by 0.15 g ofC. megacephalaeggs within five days. The larval survival rate was 85-95% in both groups, with no difference observed between the group fed with food waste and the control group fed with fresh pork liver. The reduction in culture medium and the larval production were compared among four groups. The results indicated that the experimental groups exhibited significantly greater reductions than the negative control groups. The larvae reduced food waste or fresh pork liver approximately three times more effectively than natural decomposition. The bioconversion process yielded an increase of 111.60-fold in fly larvae from food waste and a 153.20-fold increase from fresh pork liver. Additionally, the decomposition of food waste was assessed over a five-day period, both with and withoutC. megacephalalarvae. The results demonstrated that the weight of food waste treated with larvae decreased by approximately 21.87%, while the weight of fresh pork liver decreased by 24.82% (Table 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320747.t001\n\nThe yield of larval extracts is presented inTable 2. The results indicated that the rearing substrates significantly affected the yield and protein concentration ofC. megacephalalarval extracts. When comparing fresh pork liver and food waste as substrates, it was observed that larvae reared on food waste yielded a greater amount of whole-body extracts (0.80 g or 3.40%) compared to those reared on fresh pork liver (0.60 g or 2.50%). In terms of protein concentration, the total protein content from the whole-body extracts derived from food waste (WE-W) was 15.40 mg/ml, which was markedly higher than that from fresh pork liver (WE-L), at 3.98 mg/ml. Conversely, the ES products exhibited an opposite trend, larvae reared on fresh pork liver produced products (ES-L) with a protein concentration of 4.99 mg/ml, whereas those reared on food waste (ES-W) had a protein concentration of 2.82 mg/ml (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320747.t002\n\nThis figure displays the protein concentrations measured in milligrams per milliliter (mg/ml) for ES products and whole-body extracts derived fromC. megacephalalarvae. The larvae were reared using two different substrates: fresh pork liver (WE-L, ES-L) and food waste (WE-W, ES-W).\n\nThis figure displays the protein concentrations measured in milligrams per milliliter (mg/ml) for ES products and whole-body extracts derived fromC. megacephalalarvae. The larvae were reared using two different substrates: fresh pork liver (WE-L, ES-L) and food waste (WE-W, ES-W).\n\nhttps://doi.org/10.1371/journal.pone.0320747.g001\n\nThe antimicrobial activities of larval extracts fromC. megacephalawere evaluated using the disc diffusion method and the resazurin-based turbidimetric (TB) assay. The disc diffusion method demonstrated that the extracts were effective againstB. subtilis(Gram-positive bacteria) andP. aeruginosa(Gram-negative bacteria) but exhibited no inhibitory effects on yeast and filamentous fungus. This specificity suggests that the extracts may contain components primarily active against bacterial pathogens (Table 3). Further analysis using the broth dilution method, as shown inTable 4, determined that the minimal inhibitory concentration (MIC) for the larval extracts againstB. subtiliswas 100 µg/ml for both extracts derived from larvae reared on food waste and fresh pork liver. Interestingly, the extracts from larvae reared on food waste inhibitedP. aeruginosaat the same MIC of 100 µg/ml, whereas extracts from larvae fed with fresh pork liver required concentrations exceeding 400 µg/ml, indicating lower efficacy. The ES products from both feeding conditions also inhibitedB. subtilisat 100 µg/ml but were ineffective againstP. aeruginosaat 400 µg/ml, as confirmed by the color change from blue to pale pink in the TB assay, indicating bacterial growth. However, the extracts did not demonstrate bactericidal effects, as none of the tested concentrations resulted in complete bacterial elimination (minimum bactericidal concentration >  400 µg/ml). These findings suggest that the extracts exhibit bacteriostatic rather than bactericidal properties.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320747.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320747.t004\n\nThe proteomic analysis of ES products and whole-body extracts fromC. megacephalalarvae reared on fresh pork liver revealed a detailed protein profile using LC-MS/MS. In the ES products, 80 proteins were identified, of which 74 (92.50%) were characterized and 6 (7.50%) were uncharacterized. Meanwhile, the whole-body extracts contained 42 proteins, with 39 (92.86%) characterized and 3 (7.14%) uncharacterized. These findings indicate a high level of protein characterization in both sample types, with most identified proteins having molecular weights under 20 kDa.Fig 2illustrates the distribution of characterized and uncharacterized proteins in both sample types. Additionally,S1 Tablepresents a detailed list of the identified proteins, including their names and sources. These findings indicate the diverse protein composition in both ES products and whole-body extracts, indicating their biological significance and potential applications in further studies.\n\nThe pie charts represent the analysis results obtained using liquid chromatography-tandem mass spectrometry (LC-MS/MS), combined with data from the NCBI and UniProt-Calliphoridae databases. The charts display the proportions of characterized (dark grey) and uncharacterized (pale grey) proteins in ES products and whole-body extracts fromC. megacephalalarvae.\n\nThe pie charts represent the analysis results obtained using liquid chromatography-tandem mass spectrometry (LC-MS/MS), combined with data from the NCBI and UniProt-Calliphoridae databases. The charts display the proportions of characterized (dark grey) and uncharacterized (pale grey) proteins in ES products and whole-body extracts fromC. megacephalalarvae.\n\nhttps://doi.org/10.1371/journal.pone.0320747.g002\n\nThe effect of larval extracts on the viability of HaCaT cells was evaluated using a range of concentrations (0.1, 1, 10, and 100 µg/ml) in toxicity assays. An MTT proliferation assay was employed to assess the cytotoxicity of the peptides derived from both ES products and whole-body extracts. As depicted inFig 3, the extracts maintained cell viability above 90% across all tested concentrations, showing no significant cytotoxicity. The analysis showed that while the amount of formazan produced by living cells varied, there was no significant cytotoxic activity observed, even at the highest concentrations of ES products and whole-body extracts. Remarkably, WE-L extracts significantly increased cell viability at all concentrations (p< 0.001) compared to the control, while WE-W, ES-L, and ES-W showed no significant increases.\n\nThe graph presents the effects of varying concentrations (0.1, 1, 10, 100 µg/ml) of excretory-secretory (ES) products and whole-body extracts (WE) fromC. megacephalalarvae on HaCaT cell viability for 24 h, measured using the MTT assay. The treatments include: WE-L (♦): whole-body extracts from larvae reared on fresh pork liver. WE-W (▲): whole-body extracts from larvae reared on food waste. ES-L (■): excretory-secretory products from larvae reared on fresh pork liver. ES-W (●): excretory-secretory products from larvae reared on food waste. The graph shows the percentage of cell viability, and the error bars represent standard errors within the experimental replicates. The significant indicator is *** =p< 0.001.\n\nThe graph presents the effects of varying concentrations (0.1, 1, 10, 100 µg/ml) of excretory-secretory (ES) products and whole-body extracts (WE) fromC. megacephalalarvae on HaCaT cell viability for 24 h, measured using the MTT assay. The treatments include: WE-L (♦): whole-body extracts from larvae reared on fresh pork liver. WE-W (▲): whole-body extracts from larvae reared on food waste. ES-L (■): excretory-secretory products from larvae reared on fresh pork liver. ES-W (●): excretory-secretory products from larvae reared on food waste. The graph shows the percentage of cell viability, and the error bars represent standard errors within the experimental replicates. The significant indicator is *** =p< 0.001.\n\nhttps://doi.org/10.1371/journal.pone.0320747.g003\n\nThis study demonstrates the potential ofC. megacephalalarvae for sustainable food waste bioconversion and production of antimicrobial compounds. These bioactive compounds, identified in both ES products and whole-body extracts, enhance the potential applications of larvae in waste management. Despite being widely recognized for its medical significance particularly in its adult stage as a mechanical vector of pathogens, a cause of myiasis, and a valuable species in forensic entomology [8], the bioconversion capabilities ofC. megacephalahave remained largely unexplored. The house fly (M. domestica), another medically important species, has been extensively studied for its ability to convert organic waste into high-value biomass [6,19–22]. This study aims to bridge the gap by positioningC. megacephalaas a promising alternative, offering new insights into its potential for sustainable waste management and antimicrobial production.\n\nThe findings of this study confirm the efficiency ofC. megacephalain reducing food waste, aligning with previous research demonstrating its ability to alter microbiota, reduce pathogenic bacteria, and stabilize microbial communities during composting [23]. These changes, particularly involving genera such asPseudomonasandPrevotella, underscore the complex ecological interactions facilitated byC. megacephalalarvae. Furthermore, the observed reduction in greenhouse gas emissions, including CH₄ and N₂O, highlights the species’ potential in mitigating climate impacts, particularly during the critical early phase of composting [23]. Moreover,C. megacephalalarvae have been recognized as a potential biodiesel resource [24]. IntegratingC. megacephalainto waste management systems, there is an opportunity to enhance resource efficiency while contributing to broader sustainability goals. However, addressing challenges such as scalability, odor control, larval escape, and biosecurity concerns in diverse settings will be essential for fully realizing this potential. Recent studies have proposed integrating larval bioconversion into circular economy frameworks, where this process not only reduces food waste but also generates valuable byproducts like protein-rich biomass and fertilizers [25–28]. Such approaches could enhance the economic and environmental viability of waste management systems.\n\nIn addition to its bioconversion potential,C. megacephalaexhibits exceptional adaptability to diverse climates and habitats, thriving in both urban and rural areas. Its widespread distribution across tropical and subtropical regions, combined with its ability to utilize various organic substrates, makes it a versatile species for waste management [8]. Despite these advantages, the large-scale application ofC. megacephalain waste management systems remains underdeveloped. Addressing the challenges of scalability through targeted research and innovation is essential for unlocking its full potential. One of the limitations of bioconversion of food waste by insects is high moisture [6,22]. To address these challenges, low-cost adjuvants such as agricultural waste can be used to improve substrate texture and aeration [7]. In our study, sawdust was used to improve rearing conditions by enhancing substrate porosity and oxygen availability, which facilitated larval activity and accelerated waste degradation. This approach demonstrates the potential of bioconversion systems for sustainable food waste management, effectively processing organic waste while optimizing conditions for larval development. Using food waste as a substrate not only supports waste reduction but also improves biomass conversion efficiency, making it a valuable option for resource utilization. The integration of sawdust further enhances the system’s performance, showing how simple adjustments can significantly advance waste management and sustainability.\n\nLarval extracts show strong potential in medical applications, particularly in promoting cell growth and aiding wound healing. Their antimicrobial activity againstB. subtilisandP. aeruginosaunderscores their applicability in developing novel treatments for bacterial infections. The lack of bactericidal effects in the larval extracts may be attributed to their mode of action, which primarily inhibits bacterial growth rather than directly killing bacteria. Despite this limitation, the bacteriostatic activity could still hold significant potential in applications where growth suppression is sufficient, such as preventing bacterial colonization in wounds or serving as a supplementary treatment alongside other antimicrobial [29]. To further expand their utility, future studies could explore modifications or combinations of these extracts to enhance their bactericidal properties. Consistent with expectations, the larval extracts revealed no inhibitory effects on fungi, includingA. flavus,C. albicans, andM. furfur, highlighting the specificity of their active compounds for bacterial pathogens. This observation aligns with previous findings by Suriyakan et al., which reported no antifungal activity of excretory and secretory products fromC. megacephalalarvae [11]. In addition to their antimicrobial activity, larval extracts also offer promising opportunities in agricultural and livestock industries. Lee et al. demonstrated that defattedH. illucenslarvae extracts serve as natural antibiotics and feed additives for livestock, reducing reliance on conventional antibiotics and addressing the pressing issue of antibiotic resistance [30]. Moreover, feeding the larvae organic waste not only enhances their sustainability as an agricultural resource but also highlights their economic viability. For instance, crude-oil-extractedH. illucenspowder could act as a cost-effective alternative to synthetic antimicrobials like melittin, making it a practical solution for large-scale use.\n\nLarval extracts fromC. megacephalashow strong potential for maggot debridement therapy (MDT) due to their wound-healing, antimicrobial properties, and non-toxic effects on HaCaT cells, human keratinocytes commonly used to study skin biology. These findings align with previous research, such as the study by Suriyakan et al., which demonstrated the antimicrobial properties ofC. megacephalaexcretions and secretions againstP. aeruginosa, a key pathogen in chronic wounds and antibiotic resistance [11,31]. Similarly, the sarconesin II fraction fromSarconesiopsis magellanica(Diptera: Calliphoridae) exhibited a lack of cytotoxicity [32], further supporting the potentail use of blow fly-derived extracts in wound healing therapies [33]. In addition to their non-toxic profile,C. megacephalalarval extracts promote cell growthin vitro, a regenerative property critical for MDT, where rapid tissue repair is essential. This observation is consistent with studies by Lu et al., which identified an ATPase inhibitory peptide fromC. megacephalalarvae that effectively inhibitsP. aeruginosagrowth. These findings establish the therapeutic potential of specific larval peptides in targeting resistant bacterial strains and advancing wound healing therapies, addressing the urgent need for new antimicrobial agents [34,35].\n\nLarval extracts fromC. megacephalaare rich in proteins, including those under 20 kDa, involved in detoxification and antimicrobial defense (S1 Table). Among these is a potential multidrug resistance-associated protein that may enhance the larvae’s antimicrobial properties [9]. The protein composition varies between ES products and whole-body extracts, reflecting differences in both their composition and function. ES products contain a broader array of proteins specialized for interacting with the larvae’s external environment, such as thioredoxin domain-containing proteins. Thioredoxins inC. megacephalaexhibit diverse roles in detoxification, oxidative stress protection, antimicrobial defense, and reproductive development with their structural diversity and functional specificity underscoring their potential as targets for antimicrobial agents or therapeutic interventions [36]. Additionally, heat shock protein 70 (Hsp70) inC. megacephalais known for its roles in protein stabilization, folding, oxidative stress protection, and modulation of immune pathways, supporting cellular resilience under environmental stress [37]. In contrast, whole-body extracts are rich in structural proteins that play essential roles in maintaining cellular integrity and supporting various biological functions. Among these proteins, a putative aminoacyl tRNA synthase complex-interacting multifunctional protein was also identified. InDrosophila melanogaster, these proteins, particularly members of the phosducin-like protein (PhLP) family, exhibit multifunctional roles, share structural similarities with thioredoxins, and perform chaperone-assisted functions in protein stability and cellular integrity, contributing to cellular resilience under stress conditions [38].\n\nThe bioconversion process byC. megacephalalarvae, as shown in the diagram (Fig 4), represents an innovative approach to managing food waste by converting it into valuable byproducts within only five days. This system not only effectively reduces the volume of food waste but also recycles it into useful products such as organic fertilizer and protein-rich larvae, which can be used in animal feed or further processed for pharmaceutical applications, where larval extracts serve as antimicrobial agents and growth promoters. The incorporation of sawdust as an adjuvant is hypothesized to optimize conditions for larval growth and enhance waste reduction efficiency, suggesting its potential to contribute to sustainable waste management and support circular economy initiatives. This approach not only addresses environmental issues related to waste disposal but also creates economic value by converting waste into value-added products, demonstrating a practical application of waste-to-value strategies.\n\nThis diagram illustrates the efficiency ofC. megacephalain transforming food waste into valuable products. Within a five-day period, food waste mixed with sawdust supports larval development, producing ES products and whole-body extracts. These byproducts have potential applications as growth promoters and antimicrobial agents, while the remaining residue can be further processed into organic fertilizer. Potential applications, marked in the grey box, represent areas for future research not explored in this study. This bioconversion process underscores the potential ofC. megacephalaas a sustainable solution for waste management and biotechnological applications.\n\nThis diagram illustrates the efficiency ofC. megacephalain transforming food waste into valuable products. Within a five-day period, food waste mixed with sawdust supports larval development, producing ES products and whole-body extracts. These byproducts have potential applications as growth promoters and antimicrobial agents, while the remaining residue can be further processed into organic fertilizer. Potential applications, marked in the grey box, represent areas for future research not explored in this study. This bioconversion process underscores the potential ofC. megacephalaas a sustainable solution for waste management and biotechnological applications.\n\nhttps://doi.org/10.1371/journal.pone.0320747.g004\n\nThis study demonstrates that bioconversion of food waste byC. megacephalalarvae is an effective method for managing protein-based waste. The use of larvae significantly reduces the weight and volume of food waste, providing an environmentally friendly alternative to traditional disposal methods. The inclusion of adjuvants such as sawdust is crucial for optimizing rearing conditions by reducing moisture content and improving the aeration of the waste substrate. Larval extracts fromC. megacephalaexhibit antimicrobial properties and promote cell growth, suggesting potential applications in the pharmaceutical, agricultural, and animal feed industries. These bioactive byproducts offer opportunities for the development of new antimicrobial agents and nutritional supplements for livestock. Despite these advantages, several challenges must be addressed for large-scale application. Issues such as odor control, preventing larval escape, and maintaining process efficiency require further research. Enhancing the efficiency and safety of the bioconversion process is essential for its broader adoption as a sustainable waste management strategy. The large-scale implementation ofC. megacephalalarvae in food waste management could play a crucial role in circular economy models, reducing reliance on landfills and enhancing resource sustainability.\n\nCharacterized proteins identified in excretory-secretory products and whole-body extracts fromChrysomya megacephalalarvae (UniProt-Calliphoridae database, MASCOT analysis).\n\nhttps://doi.org/10.1371/journal.pone.0320747.s001\n\n(PDF)\n\nWe would like to acknowledge Mr. Olalekan Israel Aiikulola, for his feedback on our manuscript.",
    "category": "nutrition"
  },
  {
    "title": "Developmental trajectory of voluntary alcohol consumption in adolescent mice using finite mixture modeling and Bayesian posterior probability analysis",
    "authors": "Nathan Yu, Derek Gordon, Hong Zou, Yingying Chen, Lei Yu, (PLOS)",
    "publish_date": "2025-04-11",
    "doi": "https://doi.org/10.1371/journal.pone.0321506",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321506",
    "content": "Alcohol use disorders (AUDs) pose a significant public health challenge, with adolescence representing a critical period of vulnerability for the initiation of alcohol consumption. Variability in drinking behaviors among individuals complicates efforts to characterize developmental trajectories, limiting our understanding of underlying biological mechanisms.\n\nThis study aimed to identify and characterize distinct patterns of voluntary alcohol consumption in adolescent mice, using advanced statistical methods to model behavioral heterogeneity.\n\nThirty-five male CD-1 outbred mice were monitored for alcohol consumption using a two-bottle free-choice paradigm from early adolescence to young adulthood (4–11 weeks of age). Finite mixture modeling, using the method implemented in the software SAS Proc Traj, was applied to categorize individual drinking behaviors into trajectory groups based on Bayesian Information Criterion (BIC) and Bayesian Posterior Probabilities (BPP).\n\nThree distinct drinking trajectory groups were identified: non-drinkers, late drinkers, and early drinkers. Non-drinkers exhibited consistently low alcohol consumption throughout the study, late drinkers showed a significant increase in alcohol intake during adolescence-to-adulthood transition, and early drinkers maintained high levels of consumption from the start. Notably, the late and early drinkers converged on similarly high consumption levels by the end of the observation period. These findings highlight the heterogeneity of drinking behaviors during adolescence and its developmental implications.\n\nThis study demonstrates the utility of finite mixture modeling in characterizing developmental trajectories of voluntary alcohol consumption in adolescent mice. The identification of distinct behavioral trajectory patterns provides a foundation for future investigations into the genetic, molecular, and neural mechanisms underpinning susceptibility to alcohol use disorders.\n\nCitation:Yu N, Gordon D, Zou H, Chen Y, Yu L (2025) Developmental trajectory of voluntary alcohol consumption in adolescent mice using finite mixture modeling and Bayesian posterior probability analysis. PLoS ONE 20(4):\n           e0321506.\n        \n        https://doi.org/10.1371/journal.pone.0321506\n\nEditor:Herb Covington,, SUNY Empire, UNITED STATES OF AMERICA\n\nReceived:December 7, 2024;Accepted:March 6, 2025;Published:April 11, 2025\n\nCopyright:© 2025 Yu et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper.\n\nFunding:This work was supported by the National Institutes of Health of the United States (DA020555 to L.Y.). The funders did not play any role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAlcohol use disorders (AUDs) pose a significant public health challenge, contributing to substantial societal and personal costs [1–4]. Adolescence represents a pivotal developmental stage characterized by heightened susceptibility to risk-taking behaviors, including alcohol consumption [5,6]. Early exposure to alcohol during adolescence development is a critical factor of AUD development in adulthood [7–11], emphasizing the need for a better understanding of drinking behaviors in adolescence.\n\nIn this study, we investigated voluntary alcohol consumption in adolescent mice, spanning early-adolescence to young adulthood, using an outbred mouse strain to model genetic diversity similar to that in humans. By employing the statistical approach of finite mixture modeling, we categorized individual drinking trajectories. Specifically, each mouse has a set of longitudinal data, consisting of days on which alcohol consumption measurement were taken, and the value of that measurement. In finite mixture models, the trajectory curves (longitudinal data) are approximated by polynomials of order up to 4. Among the benefits of finite mixture model approaches are that they can handle missing data, unequally spaced measurements, and multiple different non-monotonic trajectory curves.\n\nAn important component of the finite mixture model is that the set of alcohol consumption curves is comprised of unique groups. As noted above, each group of similar trajectory curves (group being made up of mice with analogous curves) is described by a polynomial whose coefficients are estimated by maximum likelihood using the EM algorithm. The probability that each mouse’s growth curve belongs to a group is determined by its Bayesian Posterior Probability (BPP).\n\nWith regards to the current study, this methodology allowed us to characterize the heterogeneity in drinking patterns and identify distinct developmental trajectory curves. Our findings provide valuable insights into the biological basis of adolescent alcohol consumption and establish a framework for future studies on the mechanisms underlying AUD susceptibility.\n\nThirty five male CD-1 (ICR) outbred mice, three weeks old, were obtained from Shanghai Laboratory Animal Center, Chinese Academy of Sciences, Shanghai, China. Animals were housed in temperature controlled animal facilities on a 12 h:12 h light-dark cycle with food and water available ad libitum. At the beginning of the chronic alcohol drinking experiment, mice were singly housed for seven days of acclimation before the start of the alcohol drinking study. At the end of the study, all mice were euthanized by cervical dislocation. All procedures were approved by the IACUC, and were performed in accordance with the Guide for the Care and Use of Laboratory Animals (Institute of Laboratory Animal Resources, 1996), the PRC National Standards for Laboratory Animal Quality, and the Guidelines for the Use of Experimental Animals.\n\nVoluntary alcohol consumption in mice employing a two-bottle free-choice paradigm followed a published procedure [12]. Three weeks old mice were acclimated in single-housing cages for seven days with food and water. At four weeks of age, two-bottle free-choice procedure began with the mouse having free access to both a water-only sipper tube and an ethanol-containing sipper tube. The positions of the alcohol and water sipper tubes were counter-balanced and randomized across days. Two concentrations of alcohol solution, 5% and 10%, were used, and mice were randomly assigned to one of the alcohol solutions for the duration of the study. Mice assigned to the 5% alcohol solution regimen (Day 1–5: water only; Day 6–10: 2% alcohol; Day 11 onward: 5% alcohol) were numbered 1–18, and mice assigned to the 10% alcohol solution regimen (Day 1–5: water only; Day 6 onward: 10% alcohol) were numbered 19–35. To account for evaporation, separate tubes containing alcohol and water solutions were placed in an empty cage in the same room that housed the mice under study, and the amount of evaporation was recorded daily. Evaporated amount was subtracted from the amount of water or alcohol consumption, respectively.\n\nFinite mixture modeling was used to test for heterogeneity of mouse alcohol consumption values, by implementing the method Proc Traj in SAS, a procedure for group-based trajectory modeling [13,14]. This methodology has been applied to other mouse-longitudinal data studies [15]. A reliable method to determine which candidate chemotherapeutic drugs effectively inhibit tumor growth in patient-derived xenografts (PDX) in single mouse trials [15].\n\nInputs were mouse alcohol consumption data, specification of the number of groups (k), and specification of the order of each of the k polynomials. Outputs were coefficient estimates and the corresponding p values for each of the polynomials, estimate of the standard deviation (sigma), estimated group membership percentages with corresponding p values, BIC values corresponding to the input values, and the k Bayesian Posterior Probabilities (BPPs) for every mouse and every group. Each p value was for the t-test where the null hypothesis was that the relevant parameter was 0. Also, the BPPs were the probabilities that a given mouse is a member of group k. We called the polynomials with the estimated coefficients the trajectory polynomials, and we called each of the groups the trajectory groups.\n\nData based on mouse groups were evaluated by two-way analysis of variance (ANOVA) with Tukey’s post hoc tests, using GraphPad Prism software (version 9.5, GraphPad Software, San Diego, CA, USA). Significance levels were noted using an alpha level of 0.05.\n\nTo set up a mouse model for individual patterns of voluntary alcohol consumption during adolescence, we used outbred mice, and evaluate innate tendency of voluntary alcohol consumption.\n\nA two-bottle free-choice paradigm was employed, to measure voluntary alcohol consumption, without food or water restriction. At the beginning of the study, mice were 4-weeks old, somewhat comparable to pre-adolescence in human development [5,6,16–19]. Except for daily weighing, no other handling or behavioral tests were performed during the voluntary alcohol consumption period, lasting 57 days, from mouse age 4 weeks to 11 weeks.\n\nAs shown inFig 1, there was substantial variation of voluntary alcohol consumption among different mice, with some mice consuming considerably more alcohol solution than other mice.\n\nThirty five male CD-1 outbred mice at age 4 weeks, were singly housed and given two-bottle free choice of either water or alcohol solution at the start of study. Daily voluntary alcohol consumption data (averaged over 5 day period) were shown for each of the 35 mice as grams of alcohol consumed per kg body weight per day.\n\nThirty five male CD-1 outbred mice at age 4 weeks, were singly housed and given two-bottle free choice of either water or alcohol solution at the start of study. Daily voluntary alcohol consumption data (averaged over 5 day period) were shown for each of the 35 mice as grams of alcohol consumed per kg body weight per day.\n\nhttps://doi.org/10.1371/journal.pone.0321506.g001\n\nGiven the heterogeneous nature of voluntary alcohol consumption among adolescent mice, we applied the method implemented in the method Proc Traj in SAS, a procedure for group-based trajectory modeling [13,14], to test our null hypothesis that the data comes from a homogeneous drinking group.Table 1shows the results of testing on various quadratic models (polynomials up to order 2), to determine the most parsimonious group number.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321506.t001\n\nThe most parsimonious model among all groups (k) needs to satisfy the following criteria:\n\nThe model that meets the above criteria and has the largest BIC for all observed data is the most parsimonious model.\n\nOur null hypothesis is that the data comes from a homogeneous drinking group (that k = 1). We reject this hypothesis if the following two conditions are met: the most parsimonious model is for k >1, and the difference (the BIC score for the most parsimonious model minus the BIC score for the model with k equals 1 group) is greater than 10 [20].\n\nFromTable 1, we observe that groups 1–3 are all candidates for being the most parsimonious model based on our criteria (1. Estimated group membership probabilities are all greater than 10% with all corresponding P values less than 0.1; and 2. For each mouse, there is a greater than 95% BPP for being in one of the k groups). When k equals 4 groups, one group membership percentage is not significantly different from 0 based on the P-value. Hence, the model of group equaling 4 is excluded from further consideration.\n\nStudyingTable 1further, we note that k equaling three groups has the largest BIC value and it is substantially larger than the BIC values for k equaling either one or two (by a difference of 693.8 and 139.5, respectively). Based on this result, we specify that k equaling three groups is the most parsimonious model. This finding indicates that we reject the null hypothesis that there is only one group, in favor of the alternate hypothesis that mouse alcohol consumption over time for this dataset is a mixture of three groups each with their own unique trajectory. From this point forwards, we will focus our consideration of results for k equaling three groups.\n\nThe SAS Proc Traj results for three groups are presented inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321506.t002\n\nTable 3shows the Bayesian Posterior Probabilities (BPPs) for all mice when k equals three groups. We note that every mouse is placed into a unique trajectory group with a high degree of certainty. This conclusion is based on the fact that every BPP is either below 0.001 or above 0.999. These result indicate that three groups is a potentially parsimonious model for the mouse alcohol consumption dataset. Thus, finite mixture modeling with Proc Traj produced unequivocal results of a three-group quadratic model.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321506.t003\n\nFollowing the three-group membership assignments based on mouse alcohol consumption dataset, we examined the developmental patterns of alcohol consumption in these three groups. As shown inFig 2(mean ± SEM, n = 4 for Group 1, 26 for Group 2, and 5 for Group 3), each of the three groups displayed a distinct pattern of developmental trajectory. Group 1 mice consumed low levels of alcohol during the early part of the study (from the beginning of the study through Day 34), then increased their alcohol consumption appreciably (Day 41 and 48), until they reached their highest levels of alcohol consumption by Day 55. Group 1 mice were thus termed ‘late drinkers,’ to indicate the rising pattern of their alcohol consumption. Group 2 mice showed consistently low levels of alcohol consumption, and were termed ‘non-drinkers’ (due to the fact that the positions of the water and alcohol solution tubes were randomly assigned each day in the mouse home cage, a mouse would need to take a few licks from a solution tube to figure out which one was which; thus it would not be able to completely avoid consuming a low level of alcoholic solution). Group 3 mice started consuming high levels of alcohol as soon as alcoholic solutions were made available to them at the beginning of the study, and they sustained such high consumption levels throughout the study. Group 3 mice were therefore term ‘early drinkers.’\n\nDaily voluntary alcohol consumption data (grams of alcohol consumed per kg body weight per day, averaged over 5 day period) of the mice in each group are shown as mean ± SEM. * Significant difference from non-drinkers (Group 2). # Significant difference from both non-drinkers (Group 2) and early drinkers (Group 3).\n\nDaily voluntary alcohol consumption data (grams of alcohol consumed per kg body weight per day, averaged over 5 day period) of the mice in each group are shown as mean ± SEM. * Significant difference from non-drinkers (Group 2). # Significant difference from both non-drinkers (Group 2) and early drinkers (Group 3).\n\nhttps://doi.org/10.1371/journal.pone.0321506.g002\n\nStatistical analysis (two-way ANOVA, with Tukey’s post hoc tests) indicated three phases, mostly due to the changing behavior of Group 1 (‘late drinkers’), as Group 2 (‘non-drinkers’) and Group 3 (‘early drinkers’) displayed relatively consistent alcohol consumption patterns. During the early phase of the study (from the beginning of the study through Day 34), Group 1 and Group 2 mice consumed low levels of alcohol, and their alcohol consumption were statistically indistinguishable from each other during this early phase. Their low levels of alcohol consumption were both significantly different from Group 3 (‘early drinkers’). During the transition phase (Day 41 and 48), alcohol consumption for each group was significantly different from any other group. Toward the end phase of the study, Group 1 and Group 3 showed similar levels of high alcohol consumption, which were significantly different from the low levels of alcohol consumption by Group 2.\n\nTo observe through the perspective of the 3-group membership assignments based on mouse alcohol consumption, we examined mouse body weight growth and feeding behaviors (mean ± SEM, n = 4 for Group 1, 26 for Group 2, and 5 for Group 3). As shown inFig 3, the body weight of the three groups of mice were comparable throughout the duration of the study. The three groups of mice displayed comparable levels of food intake for the duration that food intake was measured (seven weeks from the beginning of the study, seeFig 4).\n\nBody weight data (g, averaged over 5 day period) of the mice in each group are shown as mean ± SEM.\n\nBody weight data (g, averaged over 5 day period) of the mice in each group are shown as mean ± SEM.\n\nhttps://doi.org/10.1371/journal.pone.0321506.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321506.g004\n\nLiquid intake displayed a different pattern than that of food intake. As shown inFig 5A, intake of alcoholic solution closely followed a pattern similar to that of alcohol consumption (Fig 2). Interestingly, water intake data (Fig 5B) showed that Group 3 (‘high drinkers’) had lower levels of water intake than the other two groups. When the total liquid intake was examined, the three groups displayed comparable levels (Fig 5C).\n\nShown are mean ± SEM (n = 4 for Group 1, 26 for Group 2, and 5 for Group 3).(A)Daily intake of alcohol-containing solution (mL of alcohol solution consumed per kg body weight per day).(B)Daily water intake (mL of water consumed per kg body weight per day).(C)Total liquid intake (the sum of mL of alcohol solution consumed and mL of water consumed, per kg body weight per day).\n\nShown are mean ± SEM (n = 4 for Group 1, 26 for Group 2, and 5 for Group 3).(A)Daily intake of alcohol-containing solution (mL of alcohol solution consumed per kg body weight per day).(B)Daily water intake (mL of water consumed per kg body weight per day).(C)Total liquid intake (the sum of mL of alcohol solution consumed and mL of water consumed, per kg body weight per day).\n\nhttps://doi.org/10.1371/journal.pone.0321506.g005\n\nAdolescence represents a critical developmental period marked by significant behavioral and neurobiological changes [5,6,21], including susceptibility to and experimenting with alcohol consumption [7–11,22,23]. Understanding the developmental trajectories of alcohol consumption during adolescence is important, as early exposure to alcohol is a known risk factor for alcohol use disorders in adulthood [24,25]. In this study, we utilized a two-bottle free-choice paradigm to assess voluntary alcohol consumption in adolescent mice. We chose to use an outbred mouse strain CD-1, which has a diverse genetic makeup comparable to human populations [26]. By studying voluntary alcohol consumption in mice starting at 4 weeks old and continuing across a 7-week time span, we covered the development period of early adolescence-to-adulthood equivalent to that in humans [5,6,16–19]. By using advanced statistical modeling, we were able to characterize distinct patterns of voluntary alcohol consumption, gaining insights into the heterogeneity of alcohol drinking behaviors in adolescent mice.\n\nOur results showed considerable variability in alcohol consumption among individual mice, highlighting the complexity of behavioral phenotypes associated with alcohol use (Fig 1). Using the SAS Proc Traj finite mixture modeling approach [13,14], we identified three distinct trajectory groups: non-drinkers, late drinkers, and early drinkers (Table 1). The selection of the three-group model as the most parsimonious was supported by Bayesian Information Criterion (BIC) values and Bayesian Posterior Probabilities (BPPs) (Table 2), which confirmed high certainty in group membership for all mice (Table 3). These statistical methods provided an objective framework to categorize individual consumption behaviors.\n\nEach group exhibited a unique developmental pattern of alcohol consumption (Fig 2). The non-drinkers (Group 2) displayed consistently low levels of alcohol consumption throughout the adolescence-to-adulthood developmental stage. The late drinkers (Group 1) showed low levels of alcohol consumption at the beginning of the study (Fig 2, start through study day 34), with levels comparable to those displayed by non-drinkers. As mice in Group 1 transitioned from adolescence to young adulthood (Fig 2, study days 41–48), significantly notable difference emerges from that of non-drinkers, reflecting a marked increase in alcohol consumption, thus suggesting a delayed but robust engagement with alcohol. Toward the end of the study (Fig 2, study day 55), Group 1 mice reached high levels of alcohol consumption similar to those by the early drinkers (Group 3), which began consuming high levels of alcohol immediately upon its availability, maintaining this pattern throughout the study (Fig 2). Notably, the late drinkers and early drinkers converged on comparable high levels of consumption by the end of the study, indicating that these groups may represent distinct developmental pathways leading to high alcohol intake. As outbred mice, the high levels of alcohol consumption achieved by both Group 1 and Group 3 are comparable to several of the inbred mouse strains [27], although still below those by C57BL/6 [27–29], as C57BL/6 mice are known to show higher ethanol intake than many other mouse strains [30].\n\nThe voluntary alcohol consumption paradigm in our study compared two regimens of alcohol solution: 5% (mouse 1–18) and 10% (mouse 19–35). As shown inTable 3, it appears that there was no difference between the two regimens – half of the mice in Group 1 (late drinkers) were from the 5% regimen (mouse 1 and 18), and the other half were from the 10% regimen (mouse 29 and 31); similarly, Group 3 (early drinkers) membership was also relatively evenly distributed – three mice were from the 5% regimen (mouse 7, 13 and 14), and two were from the 10% regimen (mouse 24 and 30). This suggests that regardless of the alcohol concentration of the regimens, mice in a group consumed similar amounts of alcohol (as reported in g/kg/day, seeFig. 2).\n\nBased on the 3-group membership assignments, the body weight of the three groups of mice were comparable throughout the duration of the study (Fig 3). The three groups of mice also displayed comparable levels of food intake for the duration that food intake was measured (seven weeks from the beginning of the study, seeFig 4). It should be pointed out that the increase of alcohol intake of Group 1 started around the time of seven weeks, which may have an effect on food intake. We did notice that, however, for the high alcohol consumption of Group 3, their food intake levels were comparable to that of the other groups during the first seven weeks of the study, despite Group 3 mice consuming more alcohol during this period.\n\nThese findings have significant implications for understanding the developmental process of alcohol consumption. The distinct patterns of drinking behavior observed here are likely influenced by the underlying genetic and neurobiological processes, and innate factors at molecular and cellular levels that modulate these processes. Future studies may help unravel the molecular mechanisms driving these distinct patterns of voluntary alcohol consumption in adolescent mice.\n\nOur study also highlights the utility of finite mixture modeling for analyzing complex behavioral data. Specifically, this approach enabled precise categorization of individual trajectories of behavior during development, providing a way for robust and reliable behavior phenotyping. The application of such an approach extends beyond the study of alcohol consumption, offering a powerful tool that may be utilized to study other developmentally regulated behaviors in biomedical research.\n\nIn summary, the present study provides an example and a framework for categorizing developmental patterns of alcohol consumption in adolescent mice, enabling a more ordered pattern interpretation of heterogeneity in individual study subjects. The identification of distinct trajectory groups of voluntary alcohol consumption during adolescence development suggests the existence of specific molecular and neurodevelopmental mechanisms that underlie such patterns. Future studies leveraging these findings could investigate the genetic, molecular, and neural correlates of drinking patterns, contributing to a better understanding of the biological mechanisms associated with alcohol use disorders.\n\nThe authors would like to thank Qinglian Xie for technical assistance.",
    "category": "nutrition"
  },
  {
    "title": "Revealing the ancient origins of blonde beers: Phylogeography and phylogenetics of cryotolerant fermentative yeastSaccharomyces eubayanusfrom pre-Hispanic pottery in Northwestern Patagonia, Argentina",
    "authors": "Alberto E Pérez, Jacobo Hernandez-Montelongo, Melisa González Flores, María Eugenia Rodríguez, Christian A Lopes, José Luis Lanata, (PLOS)",
    "publish_date": "2025-04-11",
    "doi": "https://doi.org/10.1371/journal.pone.0319938",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319938",
    "content": "This study presents an analysis of residuals and the identification of the oldest cryotolerant fermentative yeast Saccharomyces eubayanus, absorbed in the walls of ceramic vessels. The samples were dated between 920 and 750 years before present (BP) from the Meliquina Lake site in northwest Argentine Patagonia. This study provides more solid evidence supporting the hypothesis of a pre-Hispanic development area for fermented beverage production at the southernmost region betweenandsouth latitude on the continent. The isolation and subsequent phylogenetic and phylogeographic analysis of this yeast strain confirm its primitive nature, predating the previously known European hybrids. The associated context and chronology of its use, predating European-Indigenous contact, provide evidence of its management and utilization in native or autochthonous fermentative processes. Subsequently, for reasons still unclear, the strain migrated to Europe, where it hybridized with Old World strains, culminating in the emergence of blonde beers or lager in 16thcentury Bavaria. The deliberate or unintentional nature of this migration remains speculative, but it underscores the significant role this yeast strain played in the development of one of today’s most popular fermented beverages, which necessitate fermentation at low temperatures.\n\nCitation:Pérez AE, Hernandez-Montelongo J, Flores MG, Rodríguez ME, Lopes CA, Lanata JL (2025) Revealing the ancient origins of blonde beers: Phylogeography and phylogenetics of cryotolerant fermentative yeastSaccharomyces eubayanusfrom pre-Hispanic pottery in Northwestern Patagonia, Argentina. PLoS ONE 20(4):\n           e0319938.\n        \n        https://doi.org/10.1371/journal.pone.0319938\n\nEditor:Edwin Hlangwani, University of Johannesburg, SOUTH AFRICA\n\nReceived:September 20, 2024;Accepted:February 10, 2025;Published:April 11, 2025\n\nCopyright:© 2025 Pérez et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data are available under accession numbers PP31932 in the linkhttps://www.ncbi.nlm.nih.gov/nuccore/ PP319392, and the access data for all the genetic samples presented in this study are available in theSupporting Information.\n\nFunding:This work was financed by the Secretariat of Planning and Sustainable Development of the Municipality of San Martín de los Andes and the Honorable Legislature of the Province of Neuquén, through the efforts of Deputy Guillermo Carnagui and Governor Rolando Figueroa for the dating of several of the samples analyzed. It was also supported by grants PICT initiation 2019-0034, PI04-A143 (UNCo) and PICT 2020-03104 from the Republic of Argentina, for chemical, biotechnological and genetic studies, FONDECYT regular 1230553 for physicochemical and bio-element analyses and FONDECYT Regular 1231127 for historiographic material and historical cartography, from the Republic of Chile. The funders had no involvement in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:No authors have competing interests.\n\nThe production of fermented alcoholic beverages has played an essential role in the history of our species during the Holocene period, serving as a significant source of nutrition, drinking water, medication, and practices that stimulated the consolidation of intra- and intergroup social relationships through the act and ritual of drinking [1,2]. Simultaneously, it was intertwined with emerging technologies and various economic and social practices such as pottery, trade, the promotion of individuals and lineages, and the adoption of sedentary lifestyles [3–5].\n\nThe archaeological evidence of the production and consumption of alcoholic beverages is complex. While it is an integral part of a society’s material culture, involving the management and transformation of natural resources and the transmission of knowledge about the structure of plant resources [3], alcoholic beverages are perishable overtime [4]. As such, the identification of these beverages in archaeological contexts is challenging [4], not only due to the evaporation of alcohol but also because the non-volatile residues (both organic and inorganic) undergo alterations during the processing stages, leading to limited survival of macro (carpological) and microfossil evidence (such as silico-phytolithic, pollen), among others [4,6,7]. However, when these residues preserved in pottery and dental calculus [4], characteristic fermentation attributes can be sought [4,6], in both the residues and the containers themselves. Attributes such as thread enlargement, damage to the edges, gelatinization, fissures, perforations, birefringence, fractures, and rough texture of the pollen, for example, can be used to postulate fermentation [6,7]. Nevertheless, these attributes are general derivatives of exposure to heat, roasting, dehydration, and grinding of grains and seeds, and thus can also result from food preparation processes, not exclusively linked to the production of fermented beverages, unless supported by other evidence. For this reason, it becomes necessary to identify known alteration patterns in potential containers, such as chipping on the edges and detachment of the interior surfaces of ceramic vessels, resulting from erosion produced by acidification during the fermentation process [4,8]. These patterns may also be associated with treatments to improve the alkalinity of maize, for example, used in the production of fermented beverages [9].\n\nFermented beverages represent a distinct type of material culture [3] linked to the development of other materialities, such as the diversity of pottery technology [10]. Vessels serve as potential containers for grain, legume, and fruit ferments, enabling storage and preservation for deferred consumption, especially for a wide range of foods that are abundant but only seasonally available [1,11,12]. As Hayden [1] postulates, technological innovations such as ceramics are closely related to feasts in resource-rich areas that exploit abundant resources and are less vulnerable to overexploitation [10].\n\nSince 1550, historical sources from the region [13–15] have described the practice of annual meetings and/or gatherings among the Reche-Mapuche populations in the south-central region of Chile. These events were translated by Hispanics and Dutch conquerors as “Indian boards,” “leagues” and “congregations,” directly alluding to the significant consumption of alcoholic beverages, often referred to as ‘bebederos.’ These ceremonial feasts could last between 15 and 20 days, involving a large number of people and goods manufactured in ceramics, frequently serving as containers for service fermented drinks and food [16].\n\nFurthermore, ethnographic sources from the earlycentury mention the native production of fermentative drinks among the Mapuche population, considered an ancestral practice of great ritual value [17]. These sources describe the production sequence, including grinding, boiling, and fermentation of fruits and grains in ceramic vessels [18,19]. The documentary sources also mention that women primarily undertook the preparation of these beverages, often in the context of domestic production. However, their service typically occurred during collective public events, such as ceremonial feasts [5,6].\n\nUntil now, the possible production of fermented beverages atSouth in the western Andean sector has been just suggested [6]. This hypothesis was based on the identification of attributes or superficial and structural modifications of microfossil residues of pollen from wild and domesticated plants (including corn) found in El Vergel ceramics dating between 1,000 and 1,300 AD, from sites in the insular contexts of Mocha Island (Fig 1). However, the results of the microfossil analysis were previously solely compared with morphological/functional typological characteristics of containers such as vessels, pots, jars, etcetera [6]. These analyses have not yet incorporated attributes or modifications on the surfaces associated with fermentation, as described in the archaeological literature [4]. To be more precise, maltose residues were recently identified in the walls of El Vergel ceramics at the Quillén 1 site, located in the middle Cautín river basin atsouth, within the central valleys of the continental sector (Fig 1).\n\nImage was builded from USGS database.\n\nImage was builded from USGS database.\n\nhttps://doi.org/10.1371/journal.pone.0319938.g001\n\nBased on the initial archaeological works conducted at the Lago Meliquina site [10,20], it was postulated that the quantity and diversity of morphological groups of ceramics at this site align with the expectations for complex hunter-gatherer societies that employ pottery in rituals or feasts [1,21]. These societies typically leave behind a pottery record consisting of vessels not only intended for containment and food processing (pots) but also used for serving food and beverages, such as pitchers, bowls, glasses, bottles, plates, among others [5,10], during ceremonies similar to those previously described in historical sources from the region. In our study area, the ceramic samples are primarily characterized by utilitarian wares, such as medium-sized pots, pitchers, and cups with polished surfaces. These ceramics are sparsely decorated, featuring black-on-red reserve painting, linear designs, and, to a lesser extent, punctate incisions. The forms are predominantly closed, meaning the mouths are smaller than the largest diameter of the bodies [22], with polished external surfaces and smoothed interiors. This context reflects a subsistence strategy still dominated by hunting and gathering, complemented by food production, which remains under-researched and minimally represented [23]. In this setting, the potential fermentation of fruits and seeds may have been an efficient way to utilize abundant but seasonally available plant resources [23]. Such practices likely emerged within complex hunter-gatherer societies that began to store and process resources for delayed consumption or special occasions, possibly serving as prestige goods for ceremonial use or for the promotion of social status.\n\nRecently, evidence of alterations in silico-phytolithic residues and internal rims of monochrome vessels associated with the containment of fermented beverages has emerged from lower archaeological levels dated 938 ± 45 BP at the Angostura 1 site (Fig 1), located in the upper basin of the Negro River atsouth [7]. These findings pertain to pottery hunter-gatherer societies, suggesting the potential fermentation of locally available carob (Neltuma sp.) seeds and pehuén (Araucaria araucana) pine nuts from the Andean Cordillera sector (our study area).\n\nYeasts belonging to the genusSaccharomyces, particularly the speciesSaccharomyces cerevisiae, are associated with various food processes worldwide, including baking, distillation, and the production of wines, beers, ciders, and other fermented foods [24]. In the case ofSaccharomyces cerevisiae, in Patagonia, is currently linked to wine and cider production environments [25]. Another species of the genus, such asSaccharomyces uvarum, is also involved in fermentative processes and has been isolated from natural habitats in Patagonia [2,26] as well as apple chichas [26] and ciders fermented at low temperatures [27] in the region.\n\nThe classification and analysis of fermentative yeasts involved in the production processes of some of the most commercialized alcoholic beverages, such as lager beer, have sparked interest in investigating the selective processes worldwide [2,26,28]. In 2011, an interdisciplinary team discovered a previously unknown cryotolerant yeast species atsouth latitude in Patagonia, Argentina (Fig 1) in Nothofagus forests (Nothofagus pumillo,Nothofagus antartica) and fungusCyttaria spparasitizing these Nothopagus species. Previous studies had recognized that, when this combined withSaccharomyces cerevisiae, this yeast species gave rise to the hybrid yeast allotetraploidSaccharomyces pastorianus, a species that does not occur naturally and is directly involved in the production process of lager beer [2]. This new species was namedS. eubayans[2].\n\nSubsquently, Rodríguez et al. 2014 extended the natural distribution ofSaccharomyces eubayanusto parallelsouth latitude and to other host species, specificallyAraucaria araucana. More recently, Chilean researchers, alerted by these discoveries, successfully searched for and identified the yeast in the western Andean sector, specifically in the south-central area of Chile [28]. Moreover, new fieldworks led to the establishment that two previously registered cryotolerant species,S. eubayanusandS. uvarum, seemingly coexist in sympatry in southern Nothofagus forests. However, these species are genetically isolated due to intrinsic and ecologically potzygotic barriers, and determined by host preference [2]. Nevertheless, this data is partially refuted by the subsequent record of these species in the bark and pinion ofAraucaria araucana[26]. This discovery raised the hypothesis of their involvement in the fermentative process of traditional native beverages based on pine nuts, known as “Mudai” [17]. However, the results of the respective investigation showed that currently, their production among the Mapuche indigenous peoples is exclusively associated with commercial species such asS. cerevisiae, which is also used in domestic and commercial bakery at the regional level [26].\n\nOn the other hand, in a recent study conducted by our group, we successfully isolated and characterized various strains and genomic populations of the speciesS. eubayanus[29]. These strains were discovered in fermentative environments closely associated with apples; a fruit introduced to America by the Spanish in thecentury. Ethnohistorical records suggest that since thecentury, fermentation of apples became popular among the Mapuche populations, gradually replacing other native fruits and seeds in preference [17]. This work included isolation sites such as apple chichas, an ancestral beverage produced by indigenous communities, as well as feral apple trees, both located in Aluminé city (Neuquén, Argentina). This groundbreaking discovery marked the first isolation of the species in a fermentative environment [30].\n\nIn that sense, this study aims to connect the ancient origins of blonde beers by investigating the phylogeography and phylogenetics of the cryotolerant fermentative yeastSaccharomyces eubayanusfrom pre-Hispanic pottery in Northwestern Patagonia, Argentina. For that, we identify evidence of pottery used for processing, containing, and/or serving fermented beverages, shedding light on the diversity of ceramic containers in the early pottery history of the region. It also provides empirical insights into indigenous fermentative beverage production processes. These processes may have contributed to the transmission of cryotolerant fermentative yeasts to Europe through interactions between indigenous populations and European conquerors, potentially facilitating hybridization. Such interactions, whether intentional or not, could have played a role in the development of beverages fermented at lower temperatures, such as blonde or lager beers.\n\nThe consumption of fermented beverages in the extreme south of the American continent has been inferred indirectly, suggested by the presence of abundant service ceramics and alterations in the internal surfaces of ceramic vessels. Additionally, adhered substances, such as pollen microremains, offer further clues. The ceramics, including pots, pitchers, and cups, found in the study area, are likely associated with the production, containment, and/or serving of fermented beverages. This could be evidenced by the presence of specific indicators, such as cryotolerant yeasts linked to low-temperature fermentation processes. Further support may come from residues showing alterations, such as changes in pollen and phytoliths, which are also linked to these fermentation practices.\n\nThe samples were collected from surface archaeological sites and forested stratigraphic contexts containing ceramic remains, including Lake Meliquina, Cave Parque Diana, Los Radales 1, Catritre, Siete Manzanos, and Newen Antug (Fig 1). These sites, where native fermentative yeasts were recently identified [31], were analyzed to evaluate the preservation of organic material. The research employed a two-pronged approach: first, exploratory analyses were performed in forested sites with abundant pottery to test the conservation of yeasts using reagents; second, samples were carefully selected based on their archaeological context and preservation state, enabling more detailed investigations, including genetic analyses. The artifacts were collected using a stratigraphic intervention method involving grids measuring 1 × 1 m, and the excavation reached a sterile level of archaeological artifacts between depths of 0.10 and 0.30 m and 0.60 and 0.70 m. Exactly 100 samples of different layers were extracted of a total of more than a thousand ceramic artifacts in the sites, protected to preserve potential organic residues, such as fatty acids and DNA. These samples were analyzed at the microbiology laboratory of PROBIEN, CONICET-UNCo. Samples were recovered and separated in sterile conditions in the field, protected, unaltered (not washed or labeled) and stored under controlled light, temperature, and humidity conditions to avoid compromising the integrity of any organic residues for future analysis, including fatty acids, stable isotopes, genetic/molecular, radiocarbon, toxicological, among others.\n\nAll samples consist of fragments from containers classified as pots and jars, including sections of body segments, bases, and rims. A subset of 43 fragments was selected for detailed analysis (Table 1). Perimeter cuts were made under sterile conditions and biomolecular laboratory protocols to reduce the samples to 1 cm2fragments. This process involved discarding edge sectors, which are more exposed to natural contamination factors during both stratigraphy and archaeological recovery. Subsequently, the samples underwent surface disinfection through exposure to UV light for 5 min. Control samples were collected from surfaces in direct contact with sediments, then the ceramic surface was removed to a depth of 2 mm using a scalpel.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0313772.t001\n\nThe analyzed artifacts are housed in the repository of the Municipality of San Martín de los Andes (Gral. Roca and Juan Manuel de Rosas -8370- San Martín de los Andes, Neuquén Province, Argentina) under registration numbers LAE-NQ-NA, Alf: 009/51 (Ceramics). Research in the region began between 2008 and 2012 within the framework of projects conducted by the National Parks Administration (DRP-APN Nº834) and the University of Buenos Aires (PRI-UBA 840162), focusing on the archaeology of the southern Neuquén forest and its connections with sites in the Paso Limay area, the Río Negro steppe, and transitional sectors. From 2012 to 2015, the work was carried out by archaeologists and technical staff from the Laboratory of Archaeology and Ethnohistory (LAE) under the Secretariat of Planning and Sustainable Development of the Municipality of San Martín de los Andes (Neuquén Province, Argentina). The artifacts are stored in the annex repository of the municipal facility for registering and conserving heritage assets, in compliance with Article 24 of Law 2184 on the Historical, Archaeological, and Paleontological Heritage of the Province of Neuquén. Additionally, sacred objects of the local Mapuche community are protected under Law 25.517. As the local enforcement agency, all necessary permits for the study of the ceramic materials were obtained through Municipal Decree 1131/12, ensuring full compliance with applicable regulations.\n\nThe pottery associated with the studied sites and the Pitren tradition, in general, is well-fired, though not necessarily at high temperatures. As a result, the pottery tends to be relatively soft and of low hardness. Typically, the external surfaces are polished, while most of the closed forms feature irregularly smoothed and porous internal surfaces. This characteristic allows obtaining powdered ceramic material was extracted from the interior of the ceramic cores by friction using another scalpel blade. This material was placed in sterile tubes containing glucose-yeast-peptone (GPY) culture medium (% w/v: 2 glucose, 0.5 peptone, 0.5 yeast extract)-sorbitol 1 M with chloramphenicol (100 mg/L). The tubes were incubated atC under shaking. Microbial development (turbidity) was observed in some of the tubes, confirming the presence of yeasts through microscopic observation.\n\nTo identify the presence of fermentative beverages, we aimed to detect specific attributes, such as the presence of native yeasts associated with fermentation in cold environments (cryotolerant). These yeasts can be directly linked to the production, storage, or serving of fermentative beverages. In that sense, to perform taxonomic analysis, aliquots of yeasts suitable dilutions (0.1 mL) were spread onto GPY agar (g/L: 0.05 yeast extract; 0.05 peptone; 0.2 glucose; 0.2agar-agar) supplemented with chloramphenicol (200 mg/L). After incubation for 2–5 days, colonies were picked and stored in a glycerol 20% v/v solution atC. Colonies were taxonomically classified on the basis of the sequences obtained for the D1/D2 domain in the 26S rDNA region following the methodology proposed by [32]. PCR products were submitted to a sequencing service (Macrogen Korea) and subsequently compared using BLASTn with sequences of the type strains available in the NCBI database.\n\nThe analysis of theS. eubayanusstrain isolated from Lake Meliquina was carried out with theintFRpartial sequences. PCR product was cleaned using the AccuPrep PCR purification kit (Bioneer, Inc, USA) and subsequently submitted to a sequencing service (Macrogen Korea) under accession numbers PP31932 (Fig 4a,https://www.ncbi.nlm.nih.gov/nuccore/PP319392). The access data for all the genetic samples are available in the his region was previously described as highly variable intergenic region [33] and has been utilized to characterize different subpopulation relationships by [29]. A total of 71 strains isolated from Patagonia (Chile and Argentine) in both natural [28,29] and fermentative [30] environment were included to the analysis. The complete set of homologous sequences was aligned with the ClustalW program [34].\n\nThe best evolutionary models were selected using JModelTest 2.1.10 [35], and the Tajima-Nei model (1984) [36] was identified as the best-fitting model for our dataset. The Tajima-Nei model is particularly appropriate as it accounts for differences in nucleotide substitutions and base pair frequencies, which aligns well with the moderate sequence divergence observed in yeast populations. Phylogenetic trees were reconstructed using the Neighbor-Joining (NJ) method [37] with 1000 bootstrap replicates for branch support, performed in MEGA7 [38]. This methodological approach effectively highlights the spatial and temporal relationships of the yeast..\n\nHaplotype classification was conducted using DnaSP v5 [39]. Median-joining (MJ) networks were obtained using Network 4.5 [40].\n\nOur results demonstrated the preservation of yeasts in this type of pottery samples recovered from these forested archaeological sites. Consequently, yeast strains were isolated using GPY-agar plates and identified through molecular techniques, including PCR-RFLP and sequencing. The analysis revealed the presence of 11 yeast species (Table 1), including the speciesSaccharomyces eubayanus, which was isolated in two sites, namely, Mirador de Bello and Lago Meliquina (Fig 1). Subsequently, intraspecific characterization of the isolates was performed using mtDNA-RFLP [25]. The results indicated the presence of a majority strain (with identical molecular profiles) in isolates obtained from both sites. One colony, isolated from Lago Meliquina, was selected for phylogeographic and phylogenetic analysis.\n\nMirador de Bello is a single-component site with multiple open-air activities, situated on the north slope of the Chapelco range, near the Maipú Valley. This newly discovered site is currently in its initial stages of study and exhibits lithic artifacts, including stalked projectile points, and utilitarian pottery typical of the pre-Hispanic Late Pottery Period (1,000 to 1,550 AD) [5]. The second site, Lago Meliquina, is a unicomponent open-air settlement dated between 92060 BP, 750 ± 60 BP, 730 ± 50 years AP [20]. Since the sample from Lago Meliquina was the sole specimen acquired through stratigraphic excavation, our primary focus was on this sample. Additionally, we provided descriptions of other organic and inorganic evidence that could have been linked to the production of fermented beverages and the potential utilization ofSacharomyces eubayanus, as these pieces of evidence originated from the same ceramic sample.\n\nIn the ceramic sample No. 3: LM-FM-S1, BIV, P2 inFig 2, which also corresponds to No. 42 and 43 inTable 1, dated at 730 ± 50 years BP,Saccharomyces yeastembedded within the vessel wall was identified [5]. Other samples from the same vessel underwent various physical-chemical and taxonomic analyses of microfossils, which revealed the exclusive presence of fatty acids from seeds and berries (Fig 2). Additionally, residues adhered to the internal surface of the vessel were examined, and silico-phytolitic structures similar to those ofZea mayzmarlo and spike, along with heat-altered pollen of the same species (Fig 3), were identified, alongside other indeterminate plants [31,41].\n\nSample No. 3: LM-FM-S1, BIV, P2 corresponds to No. 42 and 43 inTable 1.\n\nSample No. 3: LM-FM-S1, BIV, P2 corresponds to No. 42 and 43 inTable 1.\n\nhttps://doi.org/10.1371/journal.pone.0319938.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319938.g003\n\nThe identification ofS. eubayanusbroadened the spectrum of species involved in the domestication processes of nature, including microbes, and raised the hypothesis of an early exchange of products and technologies between America and Europe [2]. In the first case, the importance of domesticating micro and macro species has had significant implications for humanity’s transition from nomadic to sedentary lifestyles. It has expanded the human demography and broadened and complicated both technological and social aspects [42]. However, most domestication studies tend to focus on only a few animal and plant species. Regarding the second implication, historical studies conducted over half a century ago estimated that lager beer production emerged in Bavaria during thecentury [43]. This development was preceded by lighter or blonde beers, which had evolved in Europe since the Middle Ages, particularly Ale-type beers produced usingSaccharomyces cerevisiae, a yeast also utilized in wine and bread production [43]. However, recent genetic research by Libkind et al. (2011) [2] suggests a later chronology, placing the development of lager strains in thecentury. This aligns with the possibility of an early contribution from the Americas during the period of European conquest. These microbiological findings have sparked debates about the feasibility of such early hybridization with strains of South American origin, challenging traditionally recognized areas of origin [8,33]. As a result, researchers sought alternative explanations, including contributions from other regions on the American continent. Recent records ofS. eubayanusin trees of the genus Fagus and Acer in Wisconsin, USA, as well as in different species of oaks on the Tibetan plateau, have expanded the geographic distribution of the species’ natural habitat [33,44]. All of these locations were considered potential candidates for hosting cryotolerant strains, a crucial selective factor in the hybridization process ofS. pastorianum(as discussed in [26]. The initial response was to downplay the hypothesis of a South American contribution proposed by Libkind and collaborators [2]. Instead, researchers considered closer regions, particularly the northern hemisphere, and favored an Asian origin due to historical commercial connections between Europe and the East during the early presence of lager beer. However, studies of nuclear genes (BRE5 and EGT2) and mitochondrial gene (COX2) confirmed the significant contribution of the Patagonian strain ofS. eubayanus, outweighing the alternatives from the Northern hemisphere of America and Asia [26]. Furthermore, the innovative genetic studies carried out by researchers from the Austral University of Chile confirmed that most of the wildS. eubayanusstrains collected worldwide belong to the Patagonian group [28].\n\nThe Patagonian hypothesis has a significant ethnohistoric information in its favor, along with novel archaeological evidence [5–7]. Firstly, it is incorrect to consider that commercial circulation between the North Patagonian Andean Forest and Europe was limited to the end of thecentury, as this argument is used to undermine the South American hypothesis. The North Patagonian Andean Forest is an extensive area spanning both sides of the Andes Mountain range, with a long sequence of human occupation dating back to around 14 thousand years BP on the eastern slope and 11,400 years BP in the eastern sector.\n\nAmong the earliest dated interactions with forest plant resources during the Pleistocene-Holocene transition, more than 70 plant species were collected, including medicinal plants and others not directly linked to food, such as several species of the genusNothofagus sp.[45]. The use of the North Patagonian Andean Forest environments and La Araucanía in general presents important evidence of human activity, suggesting a specialized way of life in the exploitation of forest resources with a significant component of plant gathering [17,46] and the experimentation of cultigens around the second millennium BP, including the presence of domestic species likeZea maysaround 1,000 years BP [23,47–49] as well as camelids, widely described in historical sources [48,50]. These pieces of evidence in the western Andean sector, or South Central Area of Chile, have led to the characterization of the southernmost formative societies of the American continent [50], regardless of their Andean roots or lack thereof (see synthesis in Adán et al. 2016 [48]).\n\nIt is important to clarify that the Andean Forest and lakes were among the earliest areas explored in the interior of continental Argentine Patagonia by the Hispanic conquistadors. They moved from the Pacific coast and occupied strategic enclaves on the eastern mountain range, establishing forts such as Imperial, Concepción, and Valdivia to the south of the Bío Bío river. However, these forts were repeatedly destroyed by the Reche-Mapuche indigenous people. Despite this, they were reoccupied on different occasions by European conquerors, including a two-year Dutch occupation before being displaced again by Hispanics [51].\n\nThe Hispanic chronicles of thecentury described aggregation ceremonies across extensive territories that included the eastern Andean slope. These ceremonies involved large amounts of food and fermented drinks, often driven by the search for sources of gold and silver.\n\nIt is essential to highlight that the “Wallmapu” or Mapuche ancestral territory, which occupied both slopes of the mountain range, has a long history identified through the archaeological record [52]. The first pottery occupations of the North Patagonian Andean forest and lake area date back around 2,000 years BP [10,48]. This territory is the natural habitat of the species of Nothofagus andAraucaria araucana, hosts of the cryotolerant yeast species that are the focus of the present work (Fig 1). Recent archaeological evidence suggests [7] that pots containing potentially fermentative residues ofAraucaria araucanapine nut seeds from the Cordillera forests were transported more than 600 km eastward, reaching sectors of the upper Río Negro basin approximately 1,000 years ago. This indicates that five centuries prior to the arrival of Europeans, fermented drinks made from resources of the Cordilleran forests were highly valued by various native societies. These drinks traveled great distances, likely as prestige and ceremonial goods, as well as food exchanged between producer societies and hunter-gatherer-potter eastern neighbors.\n\nBoth the phylogeographic (Fig 4a) and phylogenetic (Fig 4b) analyses, obtained from the analysis of theIntFRregion, separate the two genomic populations and the five subpopulations described for the speciesS. eubayanus[28,29,53]. The strain isolated from the vessels belongs to the PA-1 subpopulation and has a different haplotype from all the other strains analyzed. This indicates that there was no contamination with current strains, at least when considering those used in this analysis (Fig 4). All these strains were isolated from Alumine in apple chichas or feral apple trees (with the exception of the strain CRUB2011 isolated from natural environment in Nahuel Huapi).\n\n(a) Median Joining (MJ) network net reconstructed using theIntFRpartial sequences. Circles represent individual haplotypes, and the circle size is correlated with the number of strains of each haplotype. The legend of the strains belonging to each haplotype is in the upper right box. The colors of each haplotype indicate the sampling area where they were isolated. Boxes outlined with a black border represent strains isolated from fermentative environments. (b) Neighbor-Joining (NJ) phylogeny of 72 strains based on (441pb positions in the final dataset)IntFRregion. The tree is drawn to scale, with branch lengths in the same units as those of the evolutionary distances used to infer the phylogenetic tree. The evolutionary distances were computed using the Tamura-Nei model [36] method and expressed as the number of base substitutions per site. The two clades are marked by letters PA and PB. NCBI accession numbers are included in the Data availability statement.\n\n(a) Median Joining (MJ) network net reconstructed using theIntFRpartial sequences. Circles represent individual haplotypes, and the circle size is correlated with the number of strains of each haplotype. The legend of the strains belonging to each haplotype is in the upper right box. The colors of each haplotype indicate the sampling area where they were isolated. Boxes outlined with a black border represent strains isolated from fermentative environments. (b) Neighbor-Joining (NJ) phylogeny of 72 strains based on (441pb positions in the final dataset)IntFRregion. The tree is drawn to scale, with branch lengths in the same units as those of the evolutionary distances used to infer the phylogenetic tree. The evolutionary distances were computed using the Tamura-Nei model [36] method and expressed as the number of base substitutions per site. The two clades are marked by letters PA and PB. NCBI accession numbers are included in the Data availability statement.\n\nhttps://doi.org/10.1371/journal.pone.0319938.g004\n\nRegarding the geographic data, the PA-1 population has only been described in the regions that make up the Nahuel Huapi Park and its surroundings. These data are correlated with the strain isolated in vessels, since its sampling site (Lake Meliquina) falls between the two geographical locations of the strains CRUB1974 (Ñirihuau, Argentina)and CRUB1966 (Piedras Blancas, Argentina) with which it presents the greatest genomic similarity (Fig 4a).\n\nOn the other hand, the PA population is the one that presents the least similarity with the isolated populations from the rest of the world (United States, Tibet, and New Zealand), and it could be said that its distribution is completely restricted to Patagonia [54]. This fact, added to the observation that it is systematically more basal than the PB population [53], reinforces the hypothesis that the strains of the PA population were those involved in the fermentative processes 920-750 years ago.\n\nRegarding the fermentative capacity of these subpopulations, previous studies in malt extract wort have reported a lower attenuation capacity for strains of the PA-1 genomic subpopulation compared to other subpopulations. However, this difference is less evident when evaluating CO2production and fermentation rates, suggesting that these strains are indeed fermentative [29]. The authors attribute the lower attenuation to the inability of PA-1 strains to metabolize maltotriose. Nevertheless, since maltotriose is not a carbon source typically present in corn, these strains could still perform effectively as fermenters when utilizing corn-based substrates, such as those found in the pottery samples from Lake Meliquina (Figs 2and3).\n\nIn a recent study, we investigated the fermentative capacity of these subpopulations and discovered that they exhibit higher ethanol tolerance compared to other subpopulations. Moreover, strains belonging to this subpopulation demonstrated the highest implantation percentage in natural fermentations of apple must [30].\n\nThe discovery of an identical haplotype in the strain isolated from vessels and others isolated from fermentative environments strengthens the hypothesis that this strain may have played a role in fermentations dating between the years 920–750. However, this finding also motivates us to investigate other genomic regions in search of variations that could be used to demonstrate the evolutionary divergence between this strain and contemporary ones. One potential avenue for exploration is the utilization of theIntFRregion. Future research should consider conducting whole genome sequencing analyses for this strain to further support our theories.\n\nOn the other hand, the absence of internal surface alterations, such as acid etching or pitting, is linked to the typological groups of pottery found at the sites, particularly in the analyzed samples. These vessels appear to be more closely associated with the containment and serving of liquids rather than the production of fermented beverages. This suggests limited access to fermentative drinks or their containment and serving in a small number of vessels, such as the pot analyzed in LM-FS, S1. These ceramics, from hunter-gatherer societies, contain traces of food products but are considered a minority. In that sense, fermentation could be had used by these societies as a potential method for utilizing seasonally abundant plant resources [23].\n\nThe identification of cryotolerant fermentative yeasts through phylogeographic and phylogenetic analyses conducted on yeast remnants found within the walls of ceramic vessels, dating between 920 and 750 years BP at Lago Meliquina, coincides with indirect records indicating the fermentation practices involving grass and fruit at Mocha Island and Angostura 1. Therefore, the identification and context of theS. eubayanusstrain in Lago Meliquina constitute another proxy that reinforces the hypothesis about the southernmost pre-Hispanic development area of the continent for the production of fermented beverages, betweenandsouth latitude.\n\nTogether withS. eubayanus, silico-phytolithic residues and heat-altered starches ofZea mays[23,31] were identified, similar to findings on Mocha Island [6]. As demonstrated by the residues previously identified in the ceramics of Lago Meliquina (Table 1,Figs 2and3). Additionally, potentially fermentative seeds and fruit fatty acids were also absorbed in the walls of some vessel [31]. Based on these multiple evidences, the presence ofS. eubayanusyeast is postulated as a by-product of at least the consumption and/or serving of fermented beverages among ceramic vessels at the site.\n\nThis finding confirms thatS. eubayanus wasused for the fermentation of various seeds and/or native fruits in our study area before the incorporation of the commercial baker’s yeasts registered by Rodríguez et al. (2014) [26], and that traditional fermentations of apple must [30] continue to dominate today.\n\nThe isolation ofS. eubayanusfrom pre-Hispanic ceramic samples at Lake Meliquina (Table 1), along with its identification as a primitive strain (PA1) through phylogeographic and phylogenetic analyses (Fig 4), and its direct association with silico-phytolithic residues and heat-altered corn remains (Figs 2and3), support the hypothesis that this yeast was part of the residual material absorbed by the walls of ceramic containers prior to European-Indigenous contact. This provides evidence of the potential management or domestication ofS. eubayanusfor its role in the fermentation of native seeds and berries, even before its later hybridization for beer production in Europe. As a result, we hypothesize that this yeast may have been introduced into Europe from South America during the early circulation of people and various material objects in the first half of thecentury. According to the findings of Libkind et al. (2011) [2], genetic adaptations likely enabledS. eubayanus—which exists as a predominantly pure lineage in natural conditions in Patagonia—and laterS. pastorianus, which shares 99.5% genetic similarity, to thrive in cold fermentation conditions, a key feature of lager brewing. The strain could have circulated as contamination of containers that contained fermented native drinks, but these same drinks could also have been part of the rations of the conquerors for consumption during the sea voyage or in their place of origin, among other exotic goods that circulated from America to Europe.\n\nThis research confirms, through genetic studies on pottery residues, the pre-Hispanic use of the cryotolerant fermentative yeastSaccharomyces eubayanusin the fermentation of native fruits and seeds. Additionally, phylogenetic and phylogeographic evidence highlights the involvement of ancient strains of this yeast from the southern cone of America in the hybridization processes in Europe during the mid-sixteenth century. These processes, whether intentional or not, contributed to the development of blonde or lager beers.\n\nhttps://doi.org/10.1371/journal.pone.0319938.s001\n\n(XLSX)\n\nThe authors wish to express their gratitude to the Municipality of San Martín de los Andes and the Honorable Legislature of the Province of Neuquén, and especially to Congressman Guillermo Carnaghi and Governor Rolando Figueroa for their invaluable support. Finally, our special recognition and gratitude to the Mapuche Curruhuinca Community for their Free, Prior and Informed Consent (http:// www.fao.org/3/a-i3496s.pdf).",
    "category": "nutrition"
  },
  {
    "title": "The relationship between triglyceride-glucose index and serum neurofilament light chain: Findings from NHANES 2013–2014",
    "authors": "Tong Chen, Wei Zheng, Yan Zhang, Qian Xu, (PLOS)",
    "publish_date": "2025-04-10",
    "doi": "https://doi.org/10.1371/journal.pone.0321226",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321226",
    "content": "The Triglyceride-Glucose (TyG) index has become a reliable indicator for evaluating the level of insulin resistance, a pivotal factor in both metabolic and neurodegenerative disorders. Serum neurofilament light chain (sNfL) serves as a responsive biomarker for detecting neuroaxonal injury. Despite this, the interplay between the TyG index and sNfL levels has not been sufficiently investigated. The aim of this research is to scrutinize the correlation between TyG index and sNfL levels across a substantial, population-based cohort.\n\nOur study involved an examination of the dataset from the 2013–2014 round of the National Health and Nutrition Examination Survey (NHANES), encompassing a total of 2029 enrolled subjects. The TyG index was calculated using fasting triglycerides and glucose levels. Multivariable linear regression models were conducted to evaluate the relationship between TyG index and sNfL levels, adjusting for potential confounders such as age, sex, race, BMI, hypertension, stroke, congestive heart failure, alcohol consumption and NHHR (Non-High-Density Lipoprotein Cholesterol to High-Density Lipoprotein Cholesterol Ratio). Nonlinear associations were investigated using regression models based on restricted cubic splines (RCS).\n\nBoth the unadjusted and adjusted regression analyses revealed a substantial positive correlation between the TyG index and ln-sNfL levels. After accounting for all covariates, each unit increase in the TyG index was associated with a 0.15 (95% CI: 0.02–0.27, p =  0.04) increase in ln-sNfL levels. RCS analysis revealed a nonlinear relationship, with a threshold around a TyG index value of 9.63, beyond which ln-sNfL levels increased more rapidly. The association was consistent across subgroups.\n\nOur study links higher TyG index with increased sNfL levels, indicating insulin resistance’s role in neuroaxonal injury. The nonlinear relationship implies a heightened risk of neurodegeneration beyond a certain insulin resistance threshold. This underscores the need for early metabolic interventions to prevent neurodegenerative processes.\n\nCitation:Chen T, Zheng W, Zhang Y, Xu Q (2025) The relationship between triglyceride-glucose index and serum neurofilament light chain: Findings from NHANES 2013–2014. PLoS ONE 20(4):\n           e0321226.\n        \n        https://doi.org/10.1371/journal.pone.0321226\n\nEditor:Shaghayegh Khanmohammadi, Tehran University of Medical Sciences, IRAN, ISLAMIC REPUBLIC OF\n\nReceived:December 4, 2024;Accepted:March 3, 2025;Published:April 10, 2025\n\nCopyright:© 2025 Chen et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All NHANES data for this study are publicly available and can be found here:https://wwwn.cdc.gov/nchs/nhanes\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nThe triglyceride-glucose (TyG) index is increasingly acknowledged as a reliable proxy for assessing insulin resistance [1,2], a metabolic disorder associated with a range of illnesses, encompassing type 2 diabetes and heart and blood vessel diseases [3–5]. The role of insulin resistance in the development of neurodegenerative conditions, such as Alzheimer’s disease and Parkinson’s disease, is increasingly recognized [6–8]. Although there is a burgeoning interest in the nexus between metabolic dysregulation and neurodegeneration [9,10], the association between the TyG index and biomarkers indicative of neuroaxonal injury has not been extensively investigated in population-based research.\n\nSerum neurofilament light chain (sNfL) is a well-established biomarker indicative of neuroaxonal injury, capturing neuronal injury across a spectrum of neurodegenerative and neuroinflammatory conditions [11,12]. Increased sNfL levels concentrations are frequently detected in individuals suffering from conditions such as Alzheimer’s disease, multiple sclerosis, and brain trauma, in addition to various other neurological afflictions [13–15]. Although sNfL is instrumental in tracking disease progression and therapeutic efficacy in these scenarios, the correlation with metabolic markers, including the TyG index, within the general population remains largely uncharted. Considering the pivotal role of insulin resistance in the genesis of both metabolic and neurodegenerative diseases, elucidating the link between the TyG index and sNfL levels may offer valuable insights into the early stages of neurodegenerative processes.\n\nIn this study, we intend to scrutinize the correlation between the TyG index and sNfL levels within a substantial, population-based dataset from the National Health and Nutrition Examination Survey (NHANES) for the 2013–2014 period. Our hypothesis posits that elevated TyG index values, signifying heightened insulin resistance, will correlate with increased sNfL levels, thereby reflecting augmented neuroaxonal damage [16,17]. Given the non-normal distribution of sNfL, a natural logarithmic transformation was implemented to normalize the data for statistical analysis [18,19]. The findings from this cross-sectional investigation may yield novel perspectives on the metabolic factors contributing to neurodegenerative pathways and facilitate the identification of preemptive biomarkers for therapeutic intervention.\n\nOur research utilizes information from the 2013–2014 round of NHANES, a comprehensive, cross-sectional study aimed at evaluating the health and nutrition of the U.S. population. NHANES uses a stratified, multistage sampling approach to generate data that reflects the health status of the civilian, non-institutionalized segment of the United States. For this analysis, we included data on the TyG index and sNfL levels, as well as several covariates, including gender, age, race/ethnicity, alcohol consumption, hypertension, stroke, congestive heart failure, body mass index (BMI) and NHHR (Non-High-Density Lipoprotein Cholesterol to High-Density Lipoprotein Cholesterol Ratio). Of the initial 10,175 participants, we meticulously excluded those with missing TyG index or sNfL data, those with sNfL levels exceeding detection limits, and additionally, we systematically omitted participants diagnosed with neurodegenerative diseases to ensure the accuracy and relevance of our study’s findings. The final analysis included 2,029 participants, representing the adult U.S. population (Fig 1). The National Children’s Health and Human Development Study Ethics Review Board has authorized all protocols for the National Health and Nutrition Examination Survey (NHANES), and each survey participant has signed an informed consent form. The general public has access to comprehensive NHANES study designs and data at the official website:www.cdc.gov/nchs/nhanes/. This cross-sectional study adheres to the reporting requirements and follows the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE)\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321226.g001\n\nThe TyG index, a surrogate marker for insulin resistance, was calculated using fasting triglyceride and fasting glucose levels. The formula used to calculate the TyG index is:\n\n\n\nThe outcome variable, sNfL levels, was measured using a highly sensitive Siemens Healthineers immunoassay on the Atellica platform. The assay involves the use of acridinium ester (AE) chemiluminescence and paramagnetic particles. NfL-specific antibodies tagged with AE bind to the NfL antigen in the serum sample. Paramagnetic particles coated with capture antibodies are used to form antigen-antibody complexes, while unbound antibodies are removed to avoid interference. Chemiluminescent signals are generated by adding acid and base, with light emission proportional to the concentration of NfL in the sample. The Atellica system’s automation ensures precision and accuracy in measurements, and quality control (QC) samples at low, medium, and high concentrations were processed every 8 hours to ensure data reliability [20]. For statistical analysis, sNfL values were log-transformed (ln-sNfL) to correct for non-normal distribution.\n\nSeveral covariates were included in the analysis, such as gender, age, race/ethnicity, body mass index (BMI), hypertension, stroke, congestive heart failure, alcohol consumption and NHHR (Non-High-Density Lipoprotein Cholesterol to High-Density Lipoprotein Cholesterol Ratio). Hypertension was defined based on both on-site blood pressure measurements and self-reported questionnaires. On-site blood pressure was determined by averaging three measurements. Participants were classified as hypertensive if they had a systolic blood pressure of ≥ 130 mmHg or a diastolic blood pressure of ≥ 80 mmHg. Self-reporting was ascertained through question BPQ020 (“Ever told you had high blood pressure?”). Stroke was defined using the questionnaire item MCQ160f (“Ever told you had a stroke?”). Congestive heart failure was ascertained through the questionnaire item MCQ160b (“Ever told had congestive heart failure?”). Alcohol consumption was assessed through the ALQ101 question (“Have you had at least 12 alcoholic drinks in the past year?”). NHHR was calculated as the ratio of non-high-density lipoprotein cholesterol (total cholesterol minus high-density lipoprotein cholesterol) to high-density lipoprotein cholesterol, which is used to reflect lipid levels. We categorized NHHR values into two groups based on the median: Low NHHR and High NHHR, for subsequent statistical analysis. These variables were incorporated into the analysis to control for potential confounding effects on the relationship between TyG and sNfL levels.\n\nData analysis was conducted using DecisionLinnc 1.0, a comprehensive software platform designed for data processing, statistical analysis, and machine learning within a graphical user interface. Categorical variables were reported as percentages, while continuous variables were assessed for adherence to a normal distribution and are reported as average values along with their standard deviations (SD). To account for the complex sampling design of NHANES, we employed a weighted nested survey design approach in our statistical analysis, incorporating survey weights and design variables. Specifically, we utilized the sample weight variable ‘WTSSNH2Y’ associated with the sNfL biomarker to conduct weighted analyses. Additionally, “SDMVPSU” was used as the sampling ID variable, and “SDMVSTRA” served as the stratification variable. This approach ensures that the estimates are reflective of the broader U.S. population, accounting for the variability and distribution of sNfL levels within the sample. The association between the TyG index and ln-sNfL levels evaluated through multiple linear regression analyses, with adjustments for possible influencing factors. Model 1 examined the crude relationship between TyG index and ln-sNfL levels. In Model 2, adjustments were made for age, sex, and race/ethnicity. In Model 3, additional adjustments were made for factors such as BMI, hypertension, stroke, congestive heart failure, and alcohol consumption to control for extra variables that could confound the results. The use of restricted cubic splines (RCS) in regression analysis allowed us to investigate possible non-linear associations between the TyG index and ln-sNfL levels, allowing for the detection of any threshold effects. Stratified analyses were performed to determine if the relationships varied among different demographic and behavioral subgroups. All analyses considered a P-value of less than 0.05 to indicate statistical significance, and 95% confidence intervals (CI) were reported for all estimates.\n\nThe baseline characteristics of the study participants, stratified by quartiles of the TyG index, are presented inTable 1. A total of 2,029 participants were included in the analysis. The mean age of the participants was 45.39 ± 15.10 years. Participants in the highest TyG index quartile (Q4) were older, with a mean age of 49.45 ± 13.57 years, compared to 40.90 ± 15.04 years in the lowest quartile (Q1). The mean BMI was 29.30 ± 7.31. ln-sNfL levels were higher in participants in the highest TyG index quartile (2.74 ± 0.70) compared to those in the lowest quartile (2.41 ± 0.60) (p <  0.001). In terms of sex distribution, 51.26% of the participants were female, with a higher proportion of females in the lowest TyG index quartile (61.62%) compared to the highest quartile (41.24%) (p <  0.001). In terms of lifestyle factors, 73.46% of participants reported alcohol consumption in the past year, with no significant differences across TyG index quartiles (p =  0.744). Regarding hypertension, 43.57% of the participants were hypertensive, with a significant difference across the quartiles (p <  0.001). The prevalence of hypertension was lowest in the first quartile (29.69%) and highest in the fourth quartile (63.40%). For stroke, 2.47% of the participants reported a history of stroke, with no significant difference across the quartiles (p =  0.188). Regarding congestive heart failure, 2.31% of the participants reported a history of congestive heart failure, with no significant difference across the quartiles (p =  0.102). The proportion of High NHHR increased significantly with increasing TyG index values. Specifically: Q1 (Low NHHR: 85.84%, High NHHR: 14.16%); Q4 (Low NHHR: 13.59%, High NHHR: 86.41%). A significant difference in NHHR values across quartiles was observed (p <  0.001).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321226.t001\n\nIn Model 1 (unadjusted), the TyG index was positively associated with ln-sNfL levels, with a regression coefficient (β) of 0.18 (95% CI: 0.12–0.25, p <  0.001), indicating that higher TyG index values were associated with elevated ln-sNfL levels. Once Model 2 accounted for age, gender, and racial/ethnic background, the observed relationship was modestly reduced yet continued to be statistically meaningful (β =  0.10, 95% CI: 0.04–0.15, p <  0.01). With additional considerations for BMI, hypertension, stroke, congestive heart failure, alcohol consumption and NHHR in Model 3, the significant positive relationship continued to hold (β =  0.15, 95% CI: 0.02–0.27, p =  0.04). Furthermore, trend analysis revealed a significant dose-response relationship between TyG index and ln-sNfL levels (All P for trend < 0.05) (Table 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321226.t002\n\nTo further delve deeper into the potential non-linear associations between the TyG index and ln-sNfL levels, we utilized a restricted cubic spline (RCS) analysis (Fig 2). The plot shows that the association between TyG index and ln-sNfL levels remained minimal and close to null when the TyG index was below approximately 9.63. However, beyond the threshold of 9.63, a sharp increase in ln-sNfL levels was observed with increasing TyG index values, suggesting that higher TyG index values, indicative of greater insulin resistance, were associated with significantly elevated neuroaxonal damage, as reflected by ln-sNfL levels. This result highlights a threshold effect, where neuroaxonal injury becomes more pronounced once the TyG index exceeds 9.63.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321226.g002\n\nSubgroup analyses assessed the association between the TyG index and ln-sNfL levels across various demographic, lifestyle, and chronic disease factors (Fig 3). Age subgroups were divided into four equal-width groups: 20–33 years, 34–47 years, 48–61 years, and 62–75 years. The thresholds for BMI were defined as follows: Low weight (BMI <  18.5), Healthy weight (18.5 ≤  BMI <  24.0), Overweight (24.0 ≤  BMI <  28.0), and Obesity (BMI ≥  28.0). Overall, the significant positive association between TyG index and ln-sNfL levels was consistent across multiple subgroups, and no significant interactions were found for any of the analyzed variables, indicating that the relationship between TyG index and neuroaxonal injury, as measured by ln-sNfL levels, does not differ substantially across these demographic, lifestyle, and chronic disease factors.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321226.g003\n\nThe current study evaluated the link between the TyG index, acting as a proxy for insulin resistance, and sNfL levels, a biomarker sensitive to neuroaxonal damage, based on the dataset from the 2013–2014 round of NHANES. Our findings demonstrated a strong positive correlation between the TyG index and sNfL levels, suggesting that increased insulin resistance, as signified by a higher TyG index, correlates with more extensive neuroaxonal damage. This correlation retained statistical significance after accounting for multiple potential confounding factors, such as age, sex, ethnicity, body mass index (BMI), hypertension, stroke, congestive heart failure, alcohol consumption, and NHHR. Furthermore, we discerned a nonlinear relationship between the TyG index and sNfL levels, with an inflection point at a TyG index value of approximately 9.63, above which the association between the TyG index and sNfL levels intensified.\n\nThe observed association between the TyG index and sNfL levels indicates the potential involvement of insulin resistance in the process of neuroaxonal damage, a finding consistent with prior studies that have implicated metabolic dysregulation in neurodegeneration [21–23]. One plausible mechanism underlying this association is insulin resistance’s propensity to induce chronic, low-grade inflammation [24–26]. This condition is known to activate inflammatory signaling pathways, this leads to the production and release of inflammatory signaling molecules like tumor necrosis factor-alpha (TNF-α) and interleukin-6 (IL-6) [27–29]. The presence of these inflammatory factors is associated with the development of neurodegenerative conditions, including Alzheimer’s disease and Parkinson’s disease [30–33], both characterized by elevated sNfL levels [13–15]. The persistent neuroinflammatory response elicited by insulin resistance could precipitate increased neuronal injury, as evidenced by the heightened sNfL levels in individuals presenting with higher TyG index values. An additional mechanism may involve oxidative stress and mitochondrial dysfunction. Insulin resistance has been correlated with heightened oxidative stress, which can compromise cellular components and impair mitochondrial function [34–36]. Neurons, due to their high metabolic activity, are particularly vulnerable to oxidative stress, which may precipitate neuroaxonal injury [37,38]. This mechanism could account for the positive correlation between TyG index and sNfL levels, with oxidative stress-induced neuronal damage potentially driving the observed increase in sNfL levels in individuals with elevated TyG index values. The association between the TyG index and sNfL levels could also be influenced by vascular elements. Insulin resistance is a recognized risk factor for cardiovascular disease [39–41], which shares several pathways with neurodegeneration [8,42,43]. Vascular dysfunction, including diminished cerebral blood flow and microvascular damage, may lead to neuroaxonal injury [44,45]. Elevated TyG index levels could signal subclinical vascular alterations that predispose individuals to neuronal damage, manifesting as increased sNfL levels. This highlights the possible role of vascular elements in the neurodegenerative pathways for people experiencing metabolic disorders. Lastly, blood-brain barrier (BBB) dysfunction may represent another mechanism linking insulin resistance to neuroaxonal injury. Insulin resistance has been associated with heightened BBB permeability, which typically shields the brain from detrimental circulating substances [46,47]. When the BBB’s integrity is compromised, neurotoxic agents may infiltrate the central nervous system, leading to neuronal injury [48–50]. This disruption in BBB function may partially explain the observed association between higher TyG index values and increased sNfL levels, as elevated TyG index may reflect compromised BBB function, thereby contributing to neuroaxonal damage.\n\nOur findings have important clinical implications. The biomarker sNfL, recognized for its reliability in indicating neuronal damage, is frequently utilized to track the advancement of neurodegenerative conditions. The observed correlation between the TyG index and sNfL levels in our analysis implies that metabolic disturbances, particularly insulin resistance, may contribute to early neurodegenerative processes. The nonlinear relationship, with a threshold at a TyG index value of 9.63, suggests that the risk of neurodegeneration may accelerate once insulin resistance reaches a certain level. Regularly tracking the Triglyceride-Glucose index may assist in recognizing people who are more susceptible to neuroaxonal injury, especially in those with preexisting metabolic conditions. Moreover, strategies targeting insulin resistance reduction, including behavioral changes and medication, could potentially lessen the likelihood of neurodegenerative conditions through decreased neuroaxonal damage.\n\nDespite the strengths of this study, such as the use of a large, nationally representative sample from NHANES and robust statistical methods, there are limitations to consider. First, The study’s cross-sectional design restricts our capacity to confirm a causal link between the TyG index and sNfL levels. Longitudinal studies are needed to confirm whether insulin resistance precedes neuroaxonal injury. Additionally, while sNfL is a sensitive marker of neuroaxonal damage, it is not specific to any particular neurodegenerative disease. Subsequent studies ought to concentrate on exploring the association between the TyG index and sNfL levels within the framework of particular neurologic disorders.\n\nOur study links higher TyG index with increased sNfL levels, indicating insulin resistance’s role in neuroaxonal injury. The nonlinear relationship implies a heightened risk of neurodegeneration beyond a certain insulin resistance threshold. This underscores the need for early metabolic interventions to prevent neurodegenerative processes.",
    "category": "nutrition"
  },
  {
    "title": "Assessing the cardioprotective effects of exercise in APOE mouse models using deep learning and photon-counting micro-CT",
    "authors": "Alex J. Allphin, Rohan Nadkarni, Zay Y. Han, Darin P. Clark, Ketan B. Ghaghada, Alexandra Badea, Cristian T. Badea, (PLOS)",
    "publish_date": "2025-04-10",
    "doi": "https://doi.org/10.1371/journal.pone.0320892",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320892",
    "content": "The allelic variations of the apolipoprotein E (APOE) gene play a critical role in regulating lipid metabolism and significantly impact cardiovascular disease risk (CVD). This study aimed to evaluate the impact of exercise on cardiac structure and function in mouse models expressing different APOE genotypes using photon-counting computed tomography (PCCT) and deep learning-based segmentation.\n\nA total of 140 mice were grouped based on APOE genotype (APOE2, APOE3, APOE4), sex, and exercise regimen. All mice were maintained on a controlled diet to isolate the effects of exercise. Low dose cardiac photon counting micro-CT imaging with intrinsic gating was performed using a custom-built micro-PCCT system and data was reconstructed with an iterative algorithm incorporating both temporal and spectral dimensions. A liposomal-iodine nanoparticle contrast agent was intravenously administered to uniformly opacify cardiovascular structures. Cardiac structures were segmented using a 3D U-Net deep learning model that was trained and validated on manually labeled data. Statistical analyses, including ANOVA, post-hoc analysis, and stratified group comparisons, were used to assess the effects of genotype, sex, and exercise on key cardiac metrics, including ejection fraction and cardiac index.\n\nThe PCCT imaging pipeline provided high-resolution images with enhanced contrast between blood compartment and myocardium allowing for precise segmentation of cardiac features. Deep learning-based segmentation achieved high accuracy with an average Dice coefficient of 0.85. Exercise significantly improved cardiac performance, with ejection fraction increasing by up to 18% and cardiac index by 46% in exercised males, who generally benefited more from exercise. Females, particularly those with the APOE4 genotype, also showed improvements, with a 31% higher ejection fraction in exercised versus non-exercised mice. Stratified analyses confirmed that both sexes benefited from exercise, with males showing larger effect sizes. APOE3 and APOE4 genotypes derived the greatest benefit, while APOE2 mice showed no significant improvement.\n\nThis study demonstrates the utility of PCCT combined with deep learning segmentation in assessing the cardioprotective effects of exercise in APOE mouse models. These findings highlight the importance of genotype-specific approaches in understanding and potentially mitigating the impact of CVD through lifestyle interventions such as exercise.\n\nCitation:Allphin AJ, Nadkarni R, Han ZY, Clark DP, Ghaghada KB, Badea A, et al.  (2025) Assessing the cardioprotective effects of exercise in APOE mouse models using deep learning and photon-counting micro-CT. PLoS ONE 20(4):\n           e0320892.\n        \n        https://doi.org/10.1371/journal.pone.0320892\n\nEditor:Paul-Adrian Calburean, George Emil Palade University of Medicine Pharmacy Science and Technology of Targu Mures: Universitatea de Medicina Farmacie Stiinte si Tehnologie George Emil Palade din Targu Mures, ROMANIA\n\nReceived:October 4, 2024;Accepted:February 25, 2025;Published:April 10, 2025\n\nCopyright:© 2025 Allphin et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Statistical data and sample code needed to recreate all segmentation results and are available at the public Gitlab repository:https://gitlab.oit.duke.edu/aja54/pcct-cardiac-pipeline.\n\nFunding:All work was performed at the Quantitative Imaging and Analysis Lab and was supported by R01AG070149, R01 AG066184, RF1 AG057895. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nCardiovascular disease (CVD) and Alzheimer’s disease (AD) risk are associated with aging, and modifiable lifestyle factors such as sedentary behavior and diets high in fats and sugars. These diseases are further influenced by genetic factors, notably the apolipoprotein E (APOE) gene, which plays a crucial role in lipid metabolism [1–3]. Understanding the interplay between genetic predisposition, environmental factors, and lifestyle choices such as exercise is critical for developing effective therapeutic and preventive interventions. Among the various imaging modalities, x-ray computed tomography (CT)-based quantitative imaging stands out for its ability to produce high-resolution, anatomical and functional multi-dimensional images, which are crucial for studying disease mechanisms and evaluating therapeutic interventions. In particular, photon-counting CT (PCCT) represents a significant advancement in imaging technology, offering superior image quality and enhanced quantitative capabilities compared to traditional CT methods. PCCT’s benefits include higher spatial resolution, improved tissue contrast, and reduced radiation dose, making it a promising tool for both preclinical and clinical applications [4]. Photon-counting CT has demonstrated promising results in cardiovascular imaging, particularly for detecting coronary calcifications [5], assessing stents [6], and evaluating myocardial perfusion [7]. The technology’s ability to reduce electronic noise and artifacts, combined with its multi-energy capabilities, allows for superior tissue characterization, making it highly suitable for complex cardiac imaging tasks.\n\nPreclinical research, especially in mouse models, is an essential precursor and companion to clinical research because it allows precise control over genetic and environmental variables [8]. Our group has previously demonstrated the value of preclinical PCCT imaging in cancer and cardiac studies in mice, emphasizing its potential for detailed phenotypic characterization [9,10]. Despite these advances, the application of PCCT in preclinical cardiac imaging, particularly for evaluating the impact of exercise as a therapeutic intervention, remains underexplored and warrants further investigation.\n\nPrevious preclinical research has focused on quantitatively comparing the cardiac anatomy and function of different APOE mouse models using only 3D left ventricle segmentations [11,12]. This left ventricle segmentation has enabled calculation of key cardiac metrics such as stroke volume, ejection fraction, and cardiac output, providing a quantitative representation of cardiac health. The different APOE genotypes used in these studies served as key models for varying degrees of risk for Alzheimer’s disease and cardiovascular disease, offering valuable insights into the genetic predisposition and progression of these conditions [1–3].\n\nIn our previous study, we developed a cardiac photon-counting CT (PCCT) pipeline to phenotype APOE mouse models and investigated the effects of high fat diet on cardiac performance across different APOE genotypes [12]. In the current study, we expanded upon our previous work by incorporating additional cardiac metrics derived from a larger set of cardiac features and by introducing exercise as an experimental variable. While exercise is known to provide significant cardiovascular benefits, its effects across different APOE genotypes remain poorly understood. To address this, we employed a deep learning-based approach for full heart segmentation, which offers greater speed, reliability, and effectiveness compared to previously used atlas-based methods limited by their reliance on predefined anatomical templates and manual corrections, leading to slower processing times and potential inaccuracies [13]. By utilizing these advanced techniques, we aim to deliver a more detailed and comprehensive assessment of the benefits of exercise in APOE mouse models genetically predisposed to cardiovascular disease.\n\nFig 1illustrates the cardiac photon-counting CT (PCCT) pipeline developed in our previous work [12] and highlights the modifications introduced in the current study [12].\n\nWe have bold-faced the items that relate to new aspects unique to this work (compared to our previous study [12]).\n\nWe have bold-faced the items that relate to new aspects unique to this work (compared to our previous study [12]).\n\nhttps://doi.org/10.1371/journal.pone.0320892.g001\n\nThe pipeline integrates advanced imaging and deep learning techniques to quantitatively assess cardiac function. The core imaging methods, including contrast-enhanced cine-PCCT, intrinsic cardiac gating, and multi-energy iterative reconstruction, were adapted from our previous work [12] to additionally evaluate exercise as a group factor.\n\nImaging was conducted using our custom-built micro-PCCT system [14] at the Duke Quantitative Imaging and Analysis Lab. Each of the imaging datasets was reconstructed using a 5D joint iterative reconstruction algorithm, incorporating regularization along both time and energy dimensions as described previously [10,12,15]. The resulting PCCT data were then used for deep learning-based cardiac segmentation and statistical analysis. Detailed explanations of these techniques are provided in the following sections.\n\nAll animal procedures were approved by the Duke Institutional Animal Care and Use Committee (IACUC, protocol registry number: A173-20–08). The study utilized a cohort of 140 mice bred and maintained at Duke University Medical Center’s facilities in the Bryan Research Building for Neurobiology. At the end of the study, the mice were euthanized using an intraperitoneal injection of 250 mg/Kg pentobarbital, as approved by our institution’s animal care and use committee. We ensured that all actions were carried out humanely, and with the utmost regard for the welfare of our animals. The experimental design incorporated variation in APOE genotype (APOE2, APOE3, APOE4), sex (male, female), and exercise regimen. We also used some APOE mouse models that possess a component of humanized innate immune system through the inclusion of the human (h)NOS2 gene as described in previous work [12]. The presence or absence of this humanized component is abbreviated as “HN factor” throughout this work. The average age of all animals was 14.5 months with a standard deviation of 3.3 months. All animals were maintained on the same normal diet to eliminate dietary effects, allowing us to isolate the impact of exercise. The exercised mice were provided with running wheels for 1 hour per day, 5 days a week, over a period of 3 months. Each mouse was housed individually during the designated time, ensuring unrestricted access to the wheel. Exercise activity was monitored using the Wheel Manager software (Med Associates Inc., St. Albans, VT, USA), and the distance run was recorded at the end of each session.Table 1details the distribution of mice across these experimental variables, andTable 2provides percentages of exercised mice, and HN factor within each genotype. While the distribution of animals across genotypes and sexes appears relatively balanced in terms of total numbers, there is some variability in exercise participation within each group, particularly when broken down by sex.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320892.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320892.t002\n\nMice were imaged using our custom PCCT system, which features a Varian G297 x-ray tube and a Santis 1604 PCD (Dectris, Inc.), configured with 4 energy bins and a CdTe sensor [14]. The system provides a field of view of 12.9 cm x 4.3 cm and captures high-resolution images with a pixel size of 150 µm. During imaging, mice were anesthetized with 2–3% isoflurane delivered via a nosecone, and vital signs were monitored throughout the procedure using a pneumatic pillow for respiration and electrodes for ECG. To enhance blood-pool contrast, long-circulation liposomal iodine (Lip-I) nanoparticle contrast agent was administered via retro-orbital injection. A volume of 0.012 mL (equaling 1.2 mg of I [9,16]) was injected per gram of body weight for each mouse. Scanning parameters included an 80 kVp tube voltage, 4 mA tube current, and 10 ms/exposure, resulting in a total scan time of 70 seconds and an absorbed radiation dose of approximately 118 mGy. This dose is 55 to 76 times less than the lethal dose of 6.5–9 Gy, known as LD50/30 [17]. The PCD energy thresholds were set at 25, 34, 50, and 60 keV, with the second energy threshold positioned near the K-edge of iodine (33.2 keV) to optimize iodine contrast enhancement. As in our previous studies, a semi-automated intrinsic gating approach [12] was employed to sort the projections into 10 cardiac phases during the R-R interval of the cardiac cycle, enabling high-fidelity assessment of cardiac function.\n\nReconstruction of the PCCT data was performed using a multi-channel iterative algorithm with an isotropic voxel size of 125 µm. The reconstruction process involved joint regularization across both the temporal and spectral dimensions using rank-sparse kernel regression (RSKR) [15,18].\n\nReconstruction iteratively computedthat is the solution to the following equation:\n\nThe reconstructed data (columns of X) at each energy (e) and time (t) minimizes the reprojection error (R representing the system projection matrix) relative to log-transformed projection data (Y). Projections are temporally selected based on the intrinsic gating procedure previously discussed. To reduce noise in the reconstructed results, the data regularizer () RSKR reduces bilateral total variation (BTV) jointly across the spectral dimension and patch-based rank across the time dimension.\n\nReconstruction resulted in 5D volumes with 4 energies, 10 cardiac phases, and 3 spatial dimensions with 125 µm isotropic voxels. Iterative reconstruction times ranged from 5–9 hours depending on the volume size.\n\nSince our reconstructed volumes have 4 energies, we could use material decomposition to generate I, photoelectric effect (PE), and Compton scattering (CS) maps. Material decomposition was performed using a variation of the method described by Alvarez and Macovski [18,19].\n\nIn essence, material decomposition was performed via matrix inversion, solving the following linear system at each voxel:\n\nIn this equation, X is the reconstructed PCCT image vectorized as columns by energy, C represents the concentrations of our basis materials (e.g., I, PE and CS or I, Ca, and H2O) for each voxel, and M is a matrix of material sensitivities at each energy. An orthogonal subspace projection approach was used to prevent negative concentrations [18]. Post-decomposition, the material maps were assigned colors and combined in ImageJ for visualization.\n\nThese material maps were used to distinguish between blood (containing iodine contrast agent) and other structures such as soft tissue and bone, potentially facilitating a more precise analysis of cardiac features.\n\nThe goal of quantitative imaging is to extract useful, interpretable, and repeatable markers of biological performance. To quantitatively assess cardiac anatomy and function using micro-PCCT, we used segmentations of cardiac features at ventricular diastole and systole to calculate metrics such as ejection fraction and cardiac output. In this study, we expanded our previous approach which used segmentation of the left ventricle to further include segmentations of both ventricles, both atria, the myocardium, and several peripheral vessels, including the pulmonary artery and aorta. High-throughput imaging requires a robust and rapid segmentation approach, making deep learning an ideal choice. Consequently, we trained a deep learning-based segmentation network using an initial subset of user-labeled data.\n\nThese training labels were created using the seed-growing and painting tools in 3D Slicer [20]. Initially, seeds were placed in each of the cardiac structures, which were then grown to generate relatively accurate segmentations [21]. Finally, the labelers manually refined the segmentations using the 3D painting tools. A total of 46 sets of manual labels were created to train and validate the segmentation network. The creation of these labels was a collaborative effort among four researchers, each with at least two years of cardiac imaging experience. Involving multiple individuals in label creation helped increase throughput and mitigate the risk of the network learning a specific individual’s bias, given the user discretion involved in both seed placement and refinement.\n\nFor this segmentation task, we selected the 3D UNet CNN architecture [22], adapted from previous work [23]. We trained two separate networks using different input data types to assess potential differential benefits. For one network, the input was a cropped (128³ voxels) 3D view of the lowest energy threshold CT image. For the other network, the input was the same cropped region but from the decomposed iodine map. The 46 manual labels (comprising both diastole and systole of 23 mice) were used for training. These labels were randomly shuffled, independent of phase, and split into dedicated training (36 segmentations), validation (5 segmentations), and test (5 segmentations) sets. To maximize network generalizability and avoid overfitting, we employed multiple data augmentation strategies, including random cropping, random rotation, and random intensity shifts. We trained the models for 200 epochs at a learning rate of 0.001 using the Adam optimizer [24]. This training process took approximately two hours on a single RTX 5000 GPU. We used cross-entropy loss as the training cost function and evaluated network performance on the dedicated test set by calculating voxel-by-voxel accuracy, Jaccard index, Dice coefficient, precision, and recall. As shown later in the results section, due to its superior performance, the CT-input model was used for cardiac metric calculation and statistical analysis.\n\nUsing the segmentations, we calculated the following key cardiac metrics: stroke volume (SV), ejection fraction (EF), cardiac output (CO), cardiac index (CI), and myocardial mass (MM). Equations 3–6 show how these metrics were calculated. The heart rate (HR), used in Equation 5, was measured during the intrinsic gating procedure and thus represents the anesthetized heart rate. The mouse body mass (m) used in Equation 6 was measured using a digital scale at the start of the day in which imaging occurred.\n\nSV was calculated as the difference between end-diastolic volume (EDV) and end-systolic volume (ESV):\n\nEF, representing the percentage of blood ejected from the left ventricle, was calculated as:\n\nCO, representing the volume of blood pumped per minute, was calculated as:\n\nCI which represents the weight-normalized version of CO, was calculated as:\n\nMM was approximated using the average volume of the segmented myocardium across both the diastolic and systolic phases. This myocardial volume was converted to MM using an assumed tissue density of 1.053 g/mL [25].\n\nBy default, the EDV and ESV were derived from the segmentation of the left ventricle. We have also included some metrics that were calculated using the right ventricle segmentation. In these cases, we have added the prefix “RV” to indicate this distinction. For example, EF is the ejection fraction calculated from the left ventricle; RVEF is the ejection fraction calculated from the right ventricle.\n\nWe first assessed the normality of each cardiac metric using the Shapiro-Wilk test [26]. Homogeneity of variance was checked using Levene’s test to evaluate whether variances were equal across groups [27]. Three metrics (mass, ejection fraction and myocardial mass) did not satisfy the normality test. Mass did not satisfy either test.\n\nFor metrics that passed the normality and homogeneity tests, we applied multi-factor ANOVA to evaluate the main effects and interactions of exercise, sex, genotype, and HN factor. More explicitly, we used linear models for each cardiac measure (e.g., Cardiac output ~ Genotype*Exercise*Sex*HN), where Genotype represents APOE2, APOE3, and APOE4, Exercise indicates exercised or non-exercised groups, and HN is 0 for mouse lines with mNos2 background and 1 for those with mNos2-/- hNOS. These results are presented both numerically and visually, providing a clear understanding of the genotype, exercise, sex, and HN factor interaction effects on cardiac performance. We applied the Benjamini-Hochberg procedure for False Discovery Rate (FDR) correction to adjust p-values for multiple comparisons [28]. The effect size was measured using eta-squared [29] to estimate the proportion of variance explained by each factor.\n\nMetrics that failed the normality and/or homogeneity of variance tests were analyzed using other applicable methods. For mass, which failed both assumptions, we used the Kruskal-Wallis test [30] with Dunn’s post hoc test [31] for basic multifactor comparisons. For ejection fraction and myocardial mass, which failed only the normality assumption, we used generalized linear models (GLMs) for full analysis of factors and their interactions. Specifically for the metrics in this work, we employed GLMs with the Gamma distribution family and log link function, as recommended for skewed continuous data [32].\n\nWe also performed a series of stratified group comparisons to examine the influence of exercise within specific subgroups, such as sex and genotype, using the Mann-Whitney U test for non-parametric comparisons. This approach was chosen to account for potential violations of normality in smaller subgroups. For example, we compared exercised and non-exercised male mice separately. We extended these stratified comparisons across combinations of sex and genotype to explore how exercise manifests differently in these subgroups. We once again applied FDR corrections to all p-values in these stratified group comparisons to reduce the likelihood of Type I errors. All analyses were performed using Python including thestatsmodelsandscipypackages. A significance threshold of 0.05 was used for all statistical tests.\n\nTable 3contains the segmentation performance metrics calculated on the test set. We have included calculations of accuracy, Jaccard index, Dice coefficient, precision, and recall for each anatomical segment as well as an average across all segments. For example, the average Dice coefficient across all segmented structures when trained using CT images was 0.85 which is considered acceptable for most medical images. We note that the segmentation performance for CT images is better than for I maps (average Dice: 0.72). This is most likely due to the higher noise in I images which leads to increased uncertainty along feature boundaries. We also note that the left ventricle has the lowest overlap scores (Dice and Jaccard) likely due to the ambiguity present in separating the aorta from the left ventricle. That region required the most discretion on the part of the label creator. Theoretically the network prediction represents an unbiased result, but further work would be required to verify that claim.Figure 2shows a representative example indicating qualitative segmentation performance.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320892.t003\n\nWithin the images labelled “Label” and “Prediction,” the outline of each segmentation is shown as an overlay on either a CT image (upper half of figure) or a decomposed I image (bottom half of figure). The CT images are shown as attenuation maps with units of 1/voxel size while the I images represent concentrations with units of mg/mL. Each segmentation color represents a different anatomical region. We reiterate that the segmentations are voxelated 3D semantic segmentations; we show only the 2D outline of the segmentations in these images for visual simplicity.\n\nWithin the images labelled “Label” and “Prediction,” the outline of each segmentation is shown as an overlay on either a CT image (upper half of figure) or a decomposed I image (bottom half of figure). The CT images are shown as attenuation maps with units of 1/voxel size while the I images represent concentrations with units of mg/mL. Each segmentation color represents a different anatomical region. We reiterate that the segmentations are voxelated 3D semantic segmentations; we show only the 2D outline of the segmentations in these images for visual simplicity.\n\nhttps://doi.org/10.1371/journal.pone.0320892.g002\n\nTable 4provides the average and standard deviation of the cardiac metrics, categorized by sex, genotype, and exercise factor. Values are presented as means with standard deviations in parentheses. The raw volumetric measurements for each heart chamber can be found in the supplementalS1 Table 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320892.t004\n\nTable 4offers a general overview of the sample measurements of key cardiac metrics within our cohort grouped by sex, genotype, and exercise. Most relevant to this work, we measured differences between the mean values of exercised mice and nonexercised mice within some sex and genotype groups. For example, exercised mean EF values were 31% higher in APOE3 males, 18% higher in APOE4 males, 16% higher in APOE3 females, and 31% higher in APOE4 females. Similarly, exercised mean SV values were 27% higher in APOE2 males, 44% in APOE3 males, and 65% higher in APOE4 males, but 14% in APOE3 females and 33% in APOE4 female. Mean CO values also improved with exercised CO values being 51% higher in APOE3 males and 75% higher in APOE4 males, compared to 24% in APOE3 females and 41% in APOE4 females. This suggests a possible sex- and genotype-specific improvement in the heart’s ability to pump blood.\n\nGenotype-specific responses showed that APOE4 mice had the most pronounced improvements in cardiac function. Exercised mean CO values were 75% higher in APOE4 males and 30% higher in females from the same genotype highlighting a strong cardioprotective effect of exercise in this genotype. APOE2 mice exhibit more modest improvements with 27% higher mean SV values in males and 12% higher mean SV values females suggesting a weaker but still positive response to exercise.\n\nSex differences were apparent, with males generally having higher baseline CO and MM compared to females. Despite this, exercise improved cardiac efficiency, measured as mean CI, in both sexes. APOE4 males showed a 46% improvement in CI, while APOE4 females displayed a similar 44% improvement, demonstrating that the benefits of exercise are not exclusive to one sex.\n\nExercise had to have little to no impact on body mass or MM. These findings suggest that exercise predominantly enhanced cardiac function rather than inducing changes in size or structure.\n\nTo summarize, within our cohort, the clearest measured differences were in the cardiac performance metric between exercised and nonexercised mice. These differences were most pronounced in APOE4 females, APOE4 males, and APOE3 males. However, statistical analysis presented in the following section is required to understand the significance of these differences.\n\nMass failed both the normality and homogeneity of variance assumptions and was therefore analyzed using the Kruskal-Wallis and Dunn’s tests. As shown inFig 3, significant mass differences were observed in our cohort between genotype levels and between sexes but notably not between exercise groups.\n\nThe lines with asterisks indicate significant differences (p<0.05) identified by the Kruskal-Wallis test and (when needed) Dunn’s post hoc test. These plots coupled with other findings indicate that mass differences in our cohort can be attributed to sex and genotype but nottoexercise.\n\nThe lines with asterisks indicate significant differences (p<0.05) identified by the Kruskal-Wallis test and (when needed) Dunn’s post hoc test. These plots coupled with other findings indicate that mass differences in our cohort can be attributed to sex and genotype but nottoexercise.\n\nhttps://doi.org/10.1371/journal.pone.0320892.g003\n\nEF and MM each failed the assumption of normality and were analyzed using GLMs. For EF, no main effects were found to be significant but there were significant interactions between genotype and exercise as well as sex and exercise. Specifically, APOE4 mice without exercise showed a significant (p=0.014) reduction in EF compared to baseline. Additionally, males without exercise also showed a significant (p=0.017) reduction in EF. For MM, sex was found to be a highly significant (p<0.0001) main effect with males showing an overall larger MM than females. Interestingly, the interaction term between sex and HN factor was significant (p=0.009), demonstrating a potential difference in how the human Nos2 gene effects male and female mice. Specifically, males with the HN factor showed a decrease in MM.\n\nAll other metrics outside of mass, EF, and MM passed the relevant assumptions and were analyzed as part of a multi-factor ANOVA. As shown inTable 5, exercise was a significant predictor with very large effect sizes for nearly all key cardiac metrics including SV, CO, CI, RVSV, and RVEF. Sex was also a significant predictor for almost all cardiac metrics; however, CI was an exception. This indicates that some sex differences, such as those for CO, may be attributed to sex differences in body mass rather than sex differences in exercise response. Genotype was shown to be a significant predictor with a small to medium effect size for SV and CI. The exercise-sex interaction was also significant with small to medium effect sizes for SV and CO.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320892.t005\n\nWithin our stratified analysis of exercise group differences, we focused only on EF, CI, and RVEF. EF is a normalized measure that accounts for baseline differences in heart size. CI is a normalized measure that accounts for differences in body mass. These normalized metrics were chosen to reduce the impact of the mass differences (Fig 3) which are not exercise related.Figs 4and5contain key violin plots demonstrating the stratified group differences our study revealed between exercised and nonexercised mice.Table 6gives a summary of all significant stratified group differences. Across the board, exercise has a marked positive impact on EF, CI, and RVEF. This improvement is especially pronounced in males, as indicated inFig 4, where both EF and RVEF are significantly higher in exercised males compared to their non-exercised counterparts (p < 0.0007 for EF and RVEF, Cohen’s D of 1.16 and 1.08, respectively). The effect is also observed in females, but to a lesser degree, with significant improvement in CI (p = 0.0142, Cohen’s D of 0.89).Fig 5highlights that the response to exercise is genotype dependent. APOE3 and APOE4 mice show significant improvements in EF, CI, and RVEF with exercise. In particular, the APOE4 group shows the most robust response, with EF increasing significantly (p = 0.0028, Cohen’s D of 1.27) and CI showing the largest effect size (Cohen’s D of 1.64). Conversely, the APOE2 group exhibits no significant improvements with exercise, indicating a less responsive phenotype to exercise interventions in this genotype. The large effect sizes (Cohen’s D ranging from 0.89 to 1.64) reported for different metrics and subgroups highlight the importance of exercise in enhancing cardiac function, particularly in the APOE3 and APOE4 genotypes and in males.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320892.t006\n\nThe bars with asterisks indicate statistically significant differences revealed by a Mann Whitney U test (P<0.05).\n\nThe bars with asterisks indicate statistically significant differences revealed by a Mann Whitney U test (P<0.05).\n\nhttps://doi.org/10.1371/journal.pone.0320892.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320892.g005\n\ngenotype. The bars with asterisks indicate statistically significant differences revealed by a Mann Whitney U test.\n\nOur results confirm that automated segmentation allows for fast and accurate quantitative measurements. Qualitative assessment of the segmentations provides added confidence in the accuracy of this work. The segmentation performance (as shown inTable 3) using CT images as input generally outperformed the results when using I maps. This confirms previous findings that segmentation with CT input offers higher accuracy and overlap metrics, such as the Dice and Jaccard coefficients, reflecting clearer tissue boundaries [12]. In contrast, segmentation with I maps as input shows a notable decline in these metrics, reflecting the challenge of segmenting images with enhanced noise or less distinct tissue boundaries. Precision remains high for both inputs, indicating that the model avoids false positives, but recall is somewhat lower, suggesting it misses some boundaries, especially with I maps.\n\nThe multi-factor statistical analyses highlight clear differences in cardiac performance in our cohort. For nearly all cardiac functional metrics, exercise was revealed to be a significant predictor with a large effect size (Table 5). This confirms the beneficial influence of exercise on cardiac performance across the cohort. In addition to exercise, sex and genotype were also significant factors, although their effects were smaller. Notably, the interaction between exercise and sex suggests that males benefit more from exercise, as supported by the stratified subgroup analysis. This interaction aligns with the stronger exercise-induced improvements in males observed for EF, CI, and RVEF, as shown inFigs 4and5.\n\nInterestingly, the results reveal no significant impact of exercise on overall mass, as demonstrated by the Kruskal-Wallis and Dunn’s post hoc analyses inFig 3. Mass differences in our cohort are driven primarily by sex and genotype, rather than by exercise. This reinforces the idea that exercise predominantly affects cardiac function rather than structural metrics like heart mass. The analysis also revealed an interaction between sex and the HN factor influencing right ventricular stroke volume, suggesting that the humanized innate immune component might modulate sex-specific responses to cardiovascular stimuli like exercise.\n\nThe stratified group comparisons showed that exercise significantly enhances cardiac metrics, including EF, CI, and RVEF. Male mice generally exhibit greater improvements than females (as seen inFig 4), reflecting sex-specific responses likely driven by physiological factors such as hormonal differences, as males typically exhibit a greater capacity for exercise-induced cardiac hypertrophy and functional improvement. Furthermore, cardiac function of APOE2 genotypes was unaffected by exercise while both APOE3 and APOE4 mice showed a significant improvement with exercise (Fig 5). These findings suggest that the APOE4 genotype is particularly responsive to exercise, consistent with previous studies [33,34] showing that the increased disease risk in this genotype can be mitigated by exercise.\n\nThese findings underscore the importance of personalized approaches when considering exercise as a therapeutic intervention, especially for cardiovascular conditions. The variability in responses, as indicated by the standard deviations, suggests underlying biological mechanisms that may differ across individuals, warranting further exploration. Exercise stands out as a strong determinant of cardiac performance, particularly for male mice with APOE3 and APOE4 genotypes, reinforcing the potential of targeted exercise regimens for those with genetic predispositions. Differences between genotypes and sexes also provide practical insights for lifestyle interventions tailored to specific genetic backgrounds, particularly in males, where exercise consistently improves multiple cardiac metrics, while female benefits are genotype restricted. Still, within sex differences indicate that APOE4 females benefit more than APOE3 and APOE2 females.\n\nThe observed differences in exercise benefits between male and female mice can likely be explained by the distinct biological effects of sex hormones on cardiovascular function. Estrogen, which is more prevalent in females, offers cardioprotective effects such as improved endothelial function, anti-inflammatory properties, and enhanced lipid metabolism. This protective baseline could reduce the additional benefits of exercise, as female cardiovascular health is already supported by hormonal protection, particularly premenopausal females with higher estrogen levels [35,36]. In males, testosterone promotes cardiac hypertrophy and enhanced cardiovascular performance, which could amplify the effects of exercise. Additionally, APOE4 males typically exhibit a more pro-inflammatory and pro-atherogenic profile, which exercise helps to improve, aligning with previous findings on the cardiovascular risks associated with the APOE4 genotype [2]. These results are consistent with the broader understanding that sex-specific responses to exercise are complex and heavily influenced by genetic background.\n\nIn our previous study [12], we found that high-fat diet negatively affects cardiac performance, especially in APOE4 and APOE2 genotypes, leading to increased left ventricular volumes and reduced ejection fractions. In contrast, the current study demonstrates that exercise significantly enhances cardiac function, particularly in male APOE3 and APOE4 mice, suggesting that exercise serves as a robust cardioprotective intervention. The findings highlight the contrasting impacts of high-fat diet and exercise, underscoring the importance of lifestyle modifications in managing genetic predispositions to cardiovascular disease. Specifically, exercise not only mitigates the cardiovascular risks associated with APOE genotypes, but also offers a targeted intervention to improve cardiac function in susceptible populations. While exercise was evaluated independent of diet in this work, future work may include joint evaluation of diet and exercise.\n\nWhile this study demonstrates significant findings regarding the cardioprotective effects of exercise across APOE genotypes using photon-counting CT and deep learning, several limitations should be acknowledged:\n\nThese limitations highlight areas for improvement in future studies, such as incorporating longitudinal designs, expanding subgroup sizes, and exploring molecular mechanisms. Despite these constraints, the study provides valuable insights into genotype- and sex-specific exercise responses and underscores the utility of advanced imaging technologies in preclinical cardiovascular research.\n\nThese findings underscore the complex interplay between APOE genotype, sex, and exercise in modulating cardiac function. The significant improvements in cardiac metrics due to exercise, particularly in male and female APOE3 and APOE4 mice, suggest that targeted lifestyle interventions could have differential benefits depending on sex and genetic background, potentially mitigating cardiovascular risks associated with specific APOE genotypes.\n\nhttps://doi.org/10.1371/journal.pone.0320892.s001\n\n(DOCX)",
    "category": "nutrition"
  },
  {
    "title": "Exploring the dietary changes and support required for healthy eating with female students at UK universities: Findings from focus group discussions",
    "authors": "Eve F. A. Kelly, Merve Guney-Coskun, Michelle Weech, Rosalind Fallaize, Faustina Hwang, Julie A. Lovegrove, (PLOS)",
    "publish_date": "2025-04-10",
    "doi": "https://doi.org/10.1371/journal.pone.0319388",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319388",
    "content": "Students’ diets often change when leaving home and starting university due to increased responsibility for their diet and finances. However, there is limited qualitative research with students at UK universities about how their diets change during the transition to, and whilst at university and the reasons for these changes. The aim of this study was to qualitatively explore three topics: 1) specific dietary changes reported by students at UK universities, 2) reasons for these dietary changes and 3) how students can be supported to eat more healthily. Fifteen students (100% female, 54% white) across different academic years (60% undergraduate and 40% postgraduate) from the Universities of Reading and Hertfordshire were recruited. Four online focus groups were conducted, ranging from groups of 2 to 6 participants, using a semi-structured topic guide. Discussions were recorded and professionally transcribed. Transcripts were coded and themes derived for each research topic using qualitative analysis software. After joining university, dietary changes commonly reported by the students included either increased or decreased fruit and vegetable intake, increased snacking behaviour, and increased alcohol and convenience food consumption. Common reasons for changes included limited budget, time management struggles, a lack of cooking skills, and peer influence. Students suggested that reduced cost of healthy foods on campus and cooking classes to learn new skills could help them to adopt a healthier diet. These suggestions could be used to guide future healthy eating interventions for university students.\n\nCitation:Kelly EFA, Guney-Coskun M, Weech M, Fallaize R, Hwang F, Lovegrove JA (2025) Exploring the dietary changes and support required for healthy eating with female students at UK universities: Findings from focus group discussions. PLoS ONE 20(4):\n           e0319388.\n        \n        https://doi.org/10.1371/journal.pone.0319388\n\nEditor:Habiba I. Ali, United Arab Emirates University, UNITED ARAB EMIRATES\n\nReceived:August 28, 2024;Accepted:February 2, 2025;Published:April 10, 2025\n\nCopyright:© 2025 Kelly et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and Supporting Information files.\n\nFunding:This study was supported with funding from the University of Reading’s Institute for Food, Nutrition and Health (IFNH) IDRF grant, for participant reimbursement and professional transcription of the focus groups [IFNH003 to MW]. EK’s PhD research was funded by FNS-Cloud, which has received funding from the European Union’s Horizon 2020 Research and Innovation programme (H2020-EU.3.2.2.3. – A sustainable and competitive agri-food industry) under Grant Agreement No. 863059 –www.fns-cloud.eu. Neither funding sources played a role in the study design, collection, analysis, and interpretation of the data, in writing of the report or in the decision to submit the article for publication.\n\nCompeting interests:I have read the journal's policy and the authors of this manuscript have the following competing interests: Julie A. Lovegrove is Deputy Chair of the UK governments Scientific Advisory Committee on Nutrition (SACN). The other authors have declared that no competing interests exist. This does not alter our adherence to PLOS ONE policies on sharing data and materials.\n\nStudent numbers at UK universities have steadily increased since the 1990s, reaching 2.86 million students in the 2021-22 academic year [1]. Notably, the proportion of 18 year olds remaining in higher education and going to university has risen from 25.0% to 35.8% in just over a decade [1]. Starting university is a time of large adjustment for most students, many of whom leave home for the first time. This period is associated with increased independence and responsibility for their own health and wellbeing [2]. A key aspect of optimal health and wellbeing is favourable dietary behaviour, which requires university students to effectively manage their grocery budget and take responsibility for purchasing healthy food and drink options [3]. However, research suggests that this population may have other priorities and face barriers to healthy eating [3–5]. Whilst there have been studies conducted in university populations worldwide, including the US and some European countries, there is a need for further research in students at UK universities due to cultural differences and the recent UK cost-of-living crisis.\n\nEmerging evidence suggests a shift in dietary behaviours during the transition to university. These changes are often maintained by students during their time at university and can continue into later life [6]. Studies around the world report increased alcohol consumption [7,8], reduced fruit and vegetable intake [9] and a higher consumption of fast and convenience foods [10] in university students compared with their pre-university diet. Unfavourable dietary behaviours such as these whilst at university can lead to weight gain [7,11–14], lower academic performance [15], poorer mental health [16], sustained unfavourable dietary behaviours throughout life [6,17] and an increased longer-term risk of non-communicable diseases (NCDs) [18].\n\nSpecifically, a systematic review of the association between diet quality and mental health of university students demonstrated that unhealthy diets were associated with poorer mental health including depression, anxiety, and stress [16]. Additionally, poor dietary behaviours whilst at university are associated with lower academic performance in first year university students, particularly in males [15]. On the other hand, favourable dietary behaviours (e.g., breakfast consumption) and higher diet quality have been linked to improved academic performance [19,20].\n\nA number of factors can influence students’ dietary choices including time constraints, social influence, a lack of nutrition/cooking knowledge, and/or limited kitchen facilities [3,4]. Limited budget also acts as a barrier to healthy eating, with around 1.5 million UK university students relying on student loans [21]. The current cost-of-living crisis in the UK (which started in 2021) is having an additional impact on many students’ dietary choices and includes students missing meals to keep food costs down [22]. A recent analysis of UK food prices reported that “less healthy” foods (classified using a nutrient profiling model) typically cost £0.33/100 kcal, whereas “more healthy” foods were almost 2.5 times more expensive (£0.81/100 kcal) [23]. Likewise, a meta-analysis suggested the daily cost of consuming a healthier dietary pattern was approximately US$1.50 (£1.17) more per 2000 kcal than a less healthy dietary pattern [24]. As such, students may opt for less healthy foods (such as those higher in salt, sugar and saturated fat) due to their lower cost compared with healthier food and drink items (such as fruit and vegetables, fish and poultry) [25].\n\nTherefore, the aim of this study was to better understand any dietary changes that students experience when starting university in the UK, the reasons for these changes, and finally, how students can be supported to eat more healthily. These were qualitatively explored via discussions with students from UK universities to provide in-depth conversations and the sharing of experiences and ideas.\n\nFavourable ethical opinion for conduct was given by the University of Reading’s School of Chemistry, Food and Pharmacy Research Ethics Committee (study number: 41/2022). After reading the Participant Information Sheet outlining the purpose of the study, what would be required of them if they took part, and any risks and benefits associated with the study, all participants provided digital consent by ticking each consent statement when registering for the study. At the start of each focus group, participants were reminded about the study procedure and given an opportunity to ask questions. They were then asked to re-confirm their consent verbally, which was captured on the Microsoft Teams recording and witnessed by the researchers.\n\nThis study aimed to conduct three focus groups each consisting of between 6-8 participants, which was in line with recommended sample sizes for focus groups [26–28]. Participants were recruited between the 5thand 14thof June 2023 from two UK universities, University of Reading and University of Hertfordshire, both of which offer a range of degree programmes to both undergraduate and postgraduate students. Students were informed of the study via university student mailing lists and advertising distributed around these campuses.\n\nEligibility criteria included being aged 18 years and over, studying full time in any academic year on a taught or research programme at the Universities of Reading or Hertfordshire, solely responsible for their own meal preparation and/or food purchases (fully catered students were also eligible on the basis they had freedom of choice in university canteens), and willing to discuss the focus group topics in a group setting. Both males and females were eligible to take part. Exclusion criteria included being pregnant, having a self-reported medical condition which significantly affected food choices or a diagnosed eating disorder, following a restrictive or weight loss diet, receiving dietary advice from a nutritionist or healthcare professional and/or being unable to contribute to a discussion spoken in English.\n\nStudents interested in taking part in the focus group were invited to complete an online screening form (Online Surveys, Jisc, UK) to determine study eligibility. Participants were also asked to provide their ethnicity, year of study, degree course, and to rate how important a healthy diet was to them on a scale of 0 to 10 (with 0 being “not important” and 10 being “very important”). Students were not asked whether they were a home or international student at screening; however, some mentioned this during the discussions.\n\nTo encourage participants to share their opinions and perspectives with their group and feel at ease, they were allocated to a focus group with participants in a similar year of study. We used a qualitative exploratory approach [29] to gain further insight and understanding into the dietary behaviours of students since starting at a UK university. The researchers created a semi-structured topic guide for the focus groups (Table 1), with the topics, questions, and structure of the focus groups guided by previous literature, [4,30,31] which was used as a framework to develop the overarching research topics. Questions were designed to cover three main research topics (RT): 1) changes to students’ diets since starting university in relation to their pre-university diet (such as when living at home with their families), 2) reasons for these dietary changes and 3) support that could encourage the students to eat healthier. The latter included the type of support that the universities could provide, the optimal time to provide support, and barriers that may prevent student engagement with any support offered. This initial exploratory research aimed to develop ideas and find solutions to encourage healthier eating in university students. These could be used to direct the design of quantitative dietary studies and interventions.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319388.t001\n\nThe focus groups took place after the end of the summer term (late June 2023) and were conducted online via Microsoft Teams. Discussions were led and moderated by one of two female researchers (MG (PhD student) or MW who was experienced conducting online discussions (Postdoctoral researcher)). The first author (EK), a female PhD student, acted as an observer who took summary notes for each discussion point and benefitted from familiarisation of the focus group discussions prior to data analysis. EK was muted during the focus groups to avoid overwhelming the discussion with multiple researchers. This study is part of her doctoral thesis. Video recording was used to facilitate conversation among the groups, to show non-verbal cues from participants (e.g., nodding in agreement), and to aid transcription (e.g., to identify which participant was speaking). The researchers did not know the participants prior to the study and therefore introduced themselves to each group, which included their role within the study and at the university. Participants were reminded that the researchers were keen to hear their honest opinions and experiences, including both positive and negative.\n\nFurthermore, participants were asked to introduce themselves to the group (icebreaker), after which the three main RT were asked in turn, with the moderator introducing each individual question and asking the participants to share their thoughts (Table 1). Questions were open-ended to prevent researchers from influencing the participants responses. Participants who were not forthcoming with responses or who provided behavioural responses (such as nodding their head in agreement with another participant’s comments) were prompted to share their opinions. Occasionally, the moderator asked additional questions and/or provided prompts to obtain further insight and detail about the topics covered. At the end of each focus group, participants were asked whether there was any further information they would like to provide or expand upon. No repeat interviews were conducted. After completion, participants were given £10 for participating in the study.\n\nThe team of authors brings diversity of academic expertise, cultural and ethnic backgrounds, and individual university experiences to the study. The team collaborated closely throughout the study, so all stages of the research were shaped by these diverse perspectives. All authors had particular research interests in designing interventions to support individuals to eat more healthily.\n\nMicrosoft Excel was used to calculate descriptive statistics from data collected at screening to characterise the focus group samples. All focus group recordings were sent to an independent professional company (Way With Words Limited, UK) for transcription. Transcripts were not returned to participants for comment or correction. Each transcript was read in full to re-familiarise the lead researcher (EK) with the content prior to analysis. The transcripts were then uploaded to the qualitative software NVivo 12 Pro (QSR International, 2017). Inductive and deductive thematic analyses were used to analyse the data by developing the themes based on the three RTs from the discussions. Firstly, each RT within each focus group transcript was individually coded (by EK) with codes assigned to recurring instances of similar quotes. For each RT, codes from all four focus group transcripts were combined into a single dataset. Codes with similar meanings were grouped together to form sub-themes which were further grouped to form overarching themes. As no new themes were derived by the end of the coding process, it was determined that data saturation had been reached and additional focus groups would not draw out new themes. Before being finalised, the proposed themes were discussed between all authors who all feel comfortable sharing their ideas between the group and come from a range of cultural backgrounds and prior university experiences. This brought diverse perspectives to the discussion. Quotations from the transcripts are presented in the results illustrating the themes within each RT. The Consolidated Criteria for Reporting Qualitative Research (COREQ) checklist [32] and a guide to reporting thematic analysis [33] directed the reporting of results.\n\nA total of 23 students registered their interest for the study; however, 8 participants failed to respond after screening or were unable to commit to the study. Therefore, four semi-structured discussions were conducted involving a total of 15 participants. The final size of the discussion groups ranged from 2 to 6 participants. All participants were university students from the Universities of Reading and Hertfordshire. Participant group characteristics are described inTable 2. Even though both males and females were eligible to participate and registered for the study, all participants who took part were female (n= 15). In line with the student body populations at the Universities of Reading and Hertfordshire (63%/61% undergraduates, 37%/39% postgraduates, respectively [34,35], these focus groups included a similar ratio of 1styear undergraduates (UG1, 33%), 3rdyear undergraduates (UG3, 27%), and postgraduate students (40%). The majority of participants were studying a Psychology (60%) or Nutrition/Food (27%) related course. The mean self-rated importance of a healthy diet was 7 out of 10 (SD ± 1, range: 5-10), with 10 being “very important”.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319388.t002\n\nThe mean focus group length was 89 minutes (SD ± 11, range: 76–102). The themes that emerged from each RT are summarised inFig 1. Themes under RT2 were categorised by the researcher, based on the findings, into individual, environmental and social factors. Participants were not asked to provide feedback on these findings.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319388.g001\n\nThe healthiness and variety of students’ whole diet changed:Compared with their pre-university diets (e.g., when living at home), students considered their overall diets to be less healthy whilst at university: “I wouldn’t really eat as healthy as I would at home.”(P7, UG1). They also reported eating less varied and simpler meals at university:“I’d have a lot more variety of food at home, because we have a lot more ingredients and my parents are cooking for four people”(P9, UG1).\n\nChanges in fruit and vegetable intake differed amongst students:It was noted that fruit and vegetable consumption decreased for some participants whilst at university:“So, I ate a lot more healthier at home, and then when I was at uni, I found it harder to eat vegetables and stuff because they go off so quick.” (P9, UG1). In contrast, others experienced increased consumption:“I’d just buy vegetables and just fry them up. So, I eat more healthy when I was at university than [when] I was at home.”(P6, UG1).\n\nStudents engaged in more snacking behaviour at university:Some students mentioned an increase in snacking behaviour during their time at university:“I think a lot of snacky things as well, because sometimes, at the end of the day, after university, you don’t want to come home and cook for yourself.”(P6, UG1) and“I’d always just be snacking all the time.”(P7, UG1).\n\nConsumption of convenience food varied amongst students:Some students discussed consuming more convenience foods such as takeaways, fast food, and ready meals at university: “When you go out clubbing, it’s a tradition to get a takeaway afterwards, so I think a lot of people do that.”(P6, UG1). However, some students said they avoided such foods due to their cost and portion size:“I mostly avoid takeaway food because it’s very expensive and the quantity is less.”(P14, PG).\n\nStudents started drinking more alcohol at university:Increased alcohol consumption was also experienced by some students whilst at university:“I didn’t really start drinking socially until I came to university”(P3, UG3) and“At home I wouldn’t really drink…but with uni, especially in the UK, there’s a drinking culture. I definitely drank a lot more.”(P4, UG3).\n\nIndividual factors:\n\nIncreased independence.The increased independence and freedom experienced by many students at university was linked to changes in their dietary behaviour. Some students highlighted the positive effect of increased independence on their diet:“I think, at the beginning, at university, I started eating healthier because at home I can’t really choose what to eat, and sometimes when I want something light I go for a salad.”(P4, UG3). However, other students reported that increased independence negatively affected their diet:“Being at university it kind of meant that I went a bit crazy with freedom and I’d order lots of takeout food a bit more often.”(P3, UG3).\n\nLimited cooking skills.Some students acknowledged that they did not cook much before starting university:“I was living with my family and I was not cooking much.”(P5, PG). Others suggested that many students lack cooking knowledge and skills:“Most of my flatmates didn’t know how to cook…If you’re in halls and they’re not catered, you’re going to be cooking frozen pizzas because you don’t know how to cook.”(P1, PG).\n\nPsychological wellbeing.Extra pressure and stress from university and exams also contributed to changes in the students’ dietary behaviours. For some students, stress resulted in decreased appetite:“I noticed that I lost a lot of weight since I came here because I tend to lose a lot of weight when I get stressed, and I tend to lose my appetite as well.”(P12, PG). Others described how they noticed their friend’s diets had changed during exam periods:“I know some of my friends, they said that they started eating more because there were snacks during revising and stuff like this, and that they gained weight, perhaps, or stuff during exam season, and were stressed about that.”(P8, UG1).\n\nEnvironmental factors:\n\nCultural change.Some participants mentioned they had moved to the UK for their studies and spoke of dietary changes due to the lack of availability of foods that were familiar to them:“I’m from a different country, so when I started, obviously, it was basically changing the whole diet because what is readily available in my country is not what’s readily available in the UK.”(P15, PG). Additionally, the change in culture enabled students to adapt their food choices and preferences:“At home I would mainly have an East Asian diet. Meaning, rice as the main source of carbs but I’m not actually a huge fan of rice, I like pasta more. So when I came to uni, actually, my whole taste becomes a lot more European. And I think also the groceries available here in this country is very different to things available at home.”(P4, UG3).\n\nTime constraints.Students spoke about struggling to balance the time required to prepare and eat regular meals alongside their university and employment commitments:“But nowadays because the lecture times are at different times or I might have work at a certain time, I find it a lot harder to regulate how to have three meals a day.”(P3, UG3) and“Before my PhD I had more of a nine to five job, so it was easier to plan meals as well.”(P1, PG). Limited time to prepare and eat meals became more of a problem when students were stressed or had exams:“The time when there is a lot of exams and deadlines is the time where I give more importance to that, so it’s not really my choice of what I want to eat.”(P12, PG) and“Especially during studying for exams as well, I would say that I felt like I had less time to eat and was more focused on my exams.”(P10, UG3).\n\nLimited budget.Participants across the academic year groups spoke about the impact of a limited budget in relation to buying healthier foods, eating three meals a day, and food choice. P8 (UG1) stated that“Sometimes healthier foods are more expensive. Even fruits and vegetables can be more expensive than [instant noodle brand], which can be 40p, do you know what I mean? So, I think some people would just prefer to eat something cheaper and eat something than pay two, three times more to eat something healthier.”This was supported by others:“Also, just affording three healthy meals a day is something that is quite expensive and can be considered a luxury, I think, to many students... The cost-of-living crisis is huge right now and a lot of people are struggling to figure out how to eat healthily.”(P3, UG3),“I think there’s definitely a drive that some students have to make an effort to have healthy meals and prepare those things, but ultimately, you’re kind of bound by your student budget.”(P10, UG3) and“I tend to go for the food that is most convenient as well as cheap”(P12, PG). One student also mentioned the cost of foods they would typically have in their home country were less expensive than in the UK and described the subsequent impact this had on their diet,“Here, the vegetables that are from India are very expensive, so we started eating vegetables that are available here and the variety of vegetables reduced.”(P14, PG).\n\nRestricted storage space.Some students mentioned limited food storage space in their shared accommodation influenced the quantity of food they bought.“Because we’d obviously only have one fridge shelf. So, it was limited what you could get, because obviously otherwise you couldn’t store it.”(P7, UG1). Limited storage space also influenced the type of food bought, such as buying fresh vs frozen fruit and vegetables:“I might choose to buy a bag of frozen vegetables rather than having fresh vegetables in my fridge because I need space for butter and bread and other things in my fridge.”(P3, UG3). In accommodation where there was more food storage and cookware space enabled students to have more choice over what they cooked: “I’ve actually been living with just one other person, and I’ve just really noticed that I have been making better decisions. And I have been able to buy bulk and store it and make meals for the week and take my time in the kitchen and have more than one saucepan.” (P10, UG3).\n\nSocial factors:\n\nCooking for one person.Many participants spoke about the challenges of cooking for one person:“Cooking for one person can be really annoying and difficult because you can’t really buy that amount of food.”(P11, UG3). This also had an impact on the variety of both the undergraduate and postgraduate students’ diets:“I’d cook one meal, and then I’d have that same meal every day for the whole week.”(P7, UG1) and“Whereas because now I live by myself, I normally batch cook which means that I end up eating the same meal, for example, the same lunch for a few days in a row.”(P1, PG). Food waste when buying food and cooking for one person was also mentioned:“If I’m just buying for me, then I’m not going to buy as much veg because it won’t get used and then it’s a waste of money.”(P9, UG1).\n\nSocial influence.Participants reflected on the impact of peer influence and university culture on their increased alcohol intake and fast-food consumption:“I definitely drank a lot more… and sometimes it just helps with the social situation.”(P4, UG3) and“Especially after the Student Union Wednesday, you would literally leave, and they [popular takeaway pizza company] would be right there with pizzas you could get. And obviously everyone’s leaving drunk so you’re just going to it then without thinking.”(P8, UG1).\n\nUniversity students are in favour of support methods to encourage them to eat healthier:Participants identified methods of promoting and engaging university students in healthier eating. One method was increasing the amount of healthier food options on campus:“Maybe, a store with ready-to-make healthy food, maybe like sandwiches that are healthier or stuff like that.”(P15, PG) and“The food that they serve on campus, they could just incorporate more healthy options.”(P13, PG). Other participants suggested lowering the cost of healthier food options:“The healthier options are a bit more expensive for students. Maybe that could change, if they have any power on it, they could make more healthier options available and cheaper.”(P5, PG)and “Maybe, a grocery shop inside the uni, a cheap grocery shop. We do have one in the uni, but when we compare it to [budget supermarket chain] it’s expensive.”(P14, PG). The idea of group cooking classes for students to learn new skills was also viewed favourably by participants:“I think that would be super helpful for so many people, because I think so many people go, obviously, living at home for 18 years, having all their meals cooked for them, to then going to uni where you have to make every food for yourself.”(P8, UG1). Providing students with recipes was also supported by many students:“I think that is a very good idea, to have easier recipes with less ingredients, but are still healthy and incorporating a good balanced diet into them.”(P9, UG1) and“I think there’s a lot information around uni about alcohol consumption and being smart and safe about that. So, I think the same could be used for food and definitely recipes for people who have just started uni and maybe don’t know what’s cheaper and quick and easy to make.”(P11, UG3).\n\nStudents feel the timing of healthy eating support is important when supporting them to eat healthier:The start of university was identified by many participants as a good time to educate and support university students with healthy eating behaviours:“It’s probably good to do it right at the beginning, because everyone’s a bit clueless.”(P6, UG1) and“The start of uni because it can set a good foundation. So, I really made an effort to eat healthily when I first started uni. And that helped me to build up from it for the rest of the uni years.”(P4, UG3). In addition, students felt continued support throughout their time at university would be beneficial as well as during more stressful periods such as exam season:“I just think it needs to be a constant message and it applies to all years at all stages of your course.”(P10, UG3) and“In exam season, it’s very easy to just get lost and forget what you’re doing.”(P7, UG1).\n\nUniversity students are concerned there are barriers which may prevent them from taking up healthy eating support offered:Although students recognised the need for healthy eating support whilst at university, some identified barriers which may prevent them from taking up support offered, such as a lack of time and potential costs associated with the support offered.“I feel like the classes are a great idea. But there’s a few things that the uni runs that are good ideas but because there’s so much else going on, it’s hard to find the time to actually join them and partake in them.”(P7, UG1) and“So, as students, the cost is another thing, so if we’re having to pay an amount that’s quite expensive to learn to make one portion of meal I think that might kind of take away the point of it.”(P4, UG3). One student mentioned that some students may feel ashamed to attend cooking classes:“There could be people who might be a bit more shy and don’t want to go these sessions or might feel a bit ashamed.”(P3, UG3). Another student mentioned their individual food preferences would affect their engagement with cooking classes:“If it’s going to be something that I’m not used to eating, then I think I would not really participate.”(P13, PG).\n\nThe focus group participants highlighted a variety of changes in their dietary behaviour since starting university and offered several explanations for these changes. They also identified barriers which prevented them from adopting healthier dietary behaviours; however, they were open to receiving healthy eating support.\n\nStudents mentioned changes to their whole diet since starting university and, for some, there was less variety in their diet. Reasons for these included difficulties in cooking for one person because ingredients are usually enough for more than one portion. Therefore, some students were eating the same meals multiple times a week to avoid food wastage although this may lead to a lack of diversity in the diet. Since diverse diets are generally more expensive [23–25], this may discourage students from increasing variety in their diets. For example, consuming five food groups a day (dairy, fruit, vegetables, meat, and grains) is associated with an 18% higher food cost than consuming three or less food groups a day [36]. A lack of diet variety has been found in other student populations such as in Mexico and Brunei [9,37], and particularly in those with specific dietary patterns such as snackers [38].\n\nSome students reported eating fewer fruits and vegetables whilst at university. This is consistent with a self-reported health behaviours study in UK university students that found 86% of participants did not consume the UK’s recommended intake of 5 fruit/vegetable servings a day [8]. Since fresh foods, such as fruit and vegetables, have short shelf-lives, participants in the current study were cautious about how much food they were buying to avoid food wastage. Additionally, limited storage space in communal kitchens (e.g., university halls of accommodation) meant that students prioritised space for other fresh food products, with some choosing to buy frozen varieties instead. A lack of facilities and limited storage space in university accommodation has been well documented in other research looking at barriers to healthy eating in university students in the United States and Spain [39,40].\n\nSome participants also reported increased alcohol consumption at university. Whilst alcohol consumption was not quantified in this study, other studies have also reported high alcohol intakes in university students, including UK students [41,42]. Although students’ alcohol consumption can be high across all years of study, this tends to reduce as students progress through university [43]. Students’ living environments, such as living on campus and having numerous room-mates, are also linked to drinking more alcohol [44]. Frequently consuming alcohol has been linked to lower academic performance in first year university students [15]. Concerningly, a systematic review of cohort studies identified that elevated consumption of alcohol during adolescence may continue into adulthood and lead to dependency [45], both of which increase the risk of cancer, diabetes, cardiovascular, liver and pancreatic diseases [46]. University culture and social influence were identified as contributors to increased alcohol consumption in this study, which supports other studies reporting peer pressure, a desire to enjoy an evening and social events centred around alcohol act as contributors to increased alcohol consumption in university students [43,47].\n\nOther dietary changes included increased snacking and increased consumption of convenience foods, sometimes arising from limitations in cooking abilities. Sprake, et al. [48] found that students with limited cooking ability were less likely to have a healthier diet (defined as vegetarian or health-conscious dietary patterns) than students who could cook. Interventions targeting cooking ability could be interesting and worthwhile because better cooking ability is also associated with greater adherence to the Mediterranean diet [49], which is known for its health-promoting effects [50–52]. Therefore, improving cooking skills could positively impact dietary intake [53] and health outcomes in later life. Time constraints were also a barrier to eating healthily, where students reported challenges with time management to prepare meals alongside other pressures, such as socialising, coursework and exams. When these other factors took priority over healthy eating and spending time preparing meals, this sometimes resulted in students relying on foods that required little preparation. This supports previous research in other European countries which has consistently found time pressures at university negatively influence dietary choices, such as relying on fast and convenience foods [3,4,40].\n\nThe current cost-of-living crisis in the UK is considered “very concerning” for over 50% of university students, with 32% being very concerned about paying for groceries and food costs [54], and this was also a worry for our participants. Reports suggest that 1 in 4 UK students cannot afford food and regularly go without [55], which is supported by a Times Higher Education report that highlighted 63% of students spent less money on food, with 28% going to extreme measures, such as skipping meals, to save money [22]. Therefore, it was unsurprising that students in this study discussed the considerable influence their budget has on their dietary choices. They would also generally purchase cheaper less healthy options than more expensive healthier alternatives, supporting previous research that reported students relied on cheaper food with poorer nutrition [55].\n\nCulture changes were also responsible for dietary changes in students who had relocated to the UK to study. Foods that international students would typically consume in their home country were either not available in UK food stores or more expensive, which meant that for some students, their whole diets changed. This has been identified by other groups investigating the dietary experiences of international students in the UK and US [56,57] and can lead to international students adopting the dietary practices of the host country (dietary acculturation) [58].\n\nInterestingly, some students mentioned that their psychological wellbeing (e.g., high stress) negatively affected their dietary behaviour. However, poor diet quality has been shown to negatively impact mental health, which may subsequently reinforce poor dietary choices and poorer diet quality affecting their mental health even further [16]. For example, higher perceived stress in students has been significantly associated with infrequent fruit and vegetable consumption; however, consumption of such foods may protect against stress and anxiety [59], leading to a cyclical detrimental effect between mental health and dietary behaviour. Therefore, university students who have poor dietary behaviours and low diet quality may be negatively impacting their mental health, which is important given 57% of students in the UK reported having a mental health issue and 30% said their mental health had worsened since starting university [54].\n\nWhilst many dietary changes were not conducive to a healthy lifestyle some students thought their diet was healthier after starting university because they were free to choose which foods to eat and in what quantities, such as wanting to eat more fruits and vegetables than what was available to them at home pre-university. This is consistent with previous research which found that not all students at UK universities had unhealthy dietary patterns and this was particularly likely in female students and those who had greater self-reported cooking ability [48].\n\nOverall, the dietary changes discussed by the students should be confirmed in studies which accurately assess dietary intake to compare how university students’ diets have changed since starting university.\n\nThe student feedback highlighted that there are several opportunities to provide healthy eating support for university students. For example, a lack of cooking skills was identified as a barrier to healthy eating and students were in favour of introducing cooking classes to teach them new skills. The benefits of cooking skills were demonstrated in previous research which found that although individuals may wish to cook healthy meals, a lack of cooking skills can act as a key barrier to eating healthily [60]. Evidence also suggests that frequent food preparation and cooking in young adults is associated with a higher likelihood of meeting the dietary recommendations for fruit, vegetables and wholegrain intakes and decreased consumption of fast-food [61] as well as greater adherence to a Mediterranean diet [53]. Cooking skills interventions with various populations, including university students, have successfully improved efficacy and confidence in cooking ability and influenced positive dietary behaviours [62–64]. Therefore, motivating students to develop cooking skills may improve their confidence following a recipe, encourage them to prepare their own meals and improve diet quality [65].\n\nWhilst introducing cooking classes may be beneficial, it is important to acknowledge that there are other factors which may influence student engagement with the support. Students mentioned that the cost and timing of support on offer may impact whether they are available to make use of it, particularly if they have other priorities. Therefore, alternative interventions, such as online courses, which are cheaper and allow students to engage with the material in their own time may be beneficial. This could also ensure the interventions are accessible to students who may feel ashamed about lacking cooking skills and would benefit from indirect healthy eating support. Educational interventions could include providing budgeting tips and recipe booklets to students to teach them how to eat well on a budget. Other suggestions from the students include improving storage space and cooking facilities in student accommodation and for universities to lower the cost of healthy food items on campus, which was also proposed by Sprake, et al. [48].\n\nStudents also considered the timing of support to be important as they have other commitments which may take priority. Some students felt that healthy eating support should be offered continuously throughout their time at university, whilst others felt it was most important during exam seasons and other stressful times of the year with deadlines. In general, research suggests that implementing dietary interventions during the transition of late adolescence to young adulthood could be beneficial to university students as leaving home is associated with poorer diet quality [66]. For example, students living away from home may be more likely to have unfavourable dietary behaviours (such as lower fruit and vegetable consumption) compared with students still living at home [67]. Therefore, supporting the transition of leaving home with healthy eating advice may be beneficial.\n\nHowever, it is important to note that postgraduate students have typically been responsible for their dietary intake for longer than other students, such as first year undergraduates. Evidence suggests that older students may become more aware of the impact of their dietary choices on their health and positively change their eating behaviours to reflect this [48,68]. Therefore, the type of healthy eating support required by postgraduate students may differ from undergraduate students.\n\nOverall, improving students’ dietary behaviour could have many potential benefits, including improved academic performance [19,20], reduced risk of poor mental health linked to dietary choices [16], and reducing the likelihood of sustained poor dietary behaviours throughout life [6].Therefore, given the importance of eating healthily at university, studies that evaluate student engagement with any form of dietary intervention and accurately assess changes in diet quality in response to these interventions are warranted.\n\nThis study is one of few to qualitatively explore the changes that students at UK universities make to their diets and the reasons for these changes. The findings are valuable for identifying opportunities for interventions that target these areas and are welcomed by the end-users. The study recruited British as well as international students and students from a range of academic years (including undergraduate and postgraduate), which resulted in a rich discussion amongst the participants. Additionally, the study was designed to group students in similar academic years together which can help encourage participants to feel confident voicing their opinions and experiences [69] and promote group interaction [70].\n\nA limitation of this study is that, although both males and females were eligible to take part, all participants were female, so the results may have differed if male university students were included. For example, research suggests that women tend to be more concerned about making healthy dietary choices than men [71–74], which could also explain why this study received greater interest from women than men. Some of the discussions were small, consisting of two participants due to restrictions with participant availability as the academic term had finished for many students. However, there were beneficial insights from all discussions. Additionally, participants were not asked about their understanding of the term ‘healthy eating’ nor provided with a reliable definition during the discussions. Although most participants were enrolled on a health-related degree (psychology or a food/nutrition-based course), it could be assumed that these students had a greater interest and/or knowledge about diet and nutrition than the general student population; however, the focus groups showed these students still faced barriers with eating healthily whilst at university and were also open to receiving support. Assuming greater nutrition knowledge in this group, this may also explain why nutrition knowledge deficit was not identified as a barrier to healthy eating, contrary to other studies with university students [39,75].\n\nFinally, the students were from one of two UK universities (Universities of Reading and Hertfordshire) and from a limited range of degree programmes on offer at both universities so the generalisability of this study’s findings to other UK student populations may be limited. Nevertheless, the results from this study still identify potential opportunities for improving dietary support for students at UK universities which could apply regardless of their sex, degree course or university location.\n\nIn this study, the students reported a variety of dietary changes since starting university, including increased alcohol and convenience food consumption, less variety in their diet and a mixture of both increased and decreased fruit and vegetable intake. They identified that a lack of time, limited budget, cultural changes, and/or psychological wellbeing are some of the reasons responsible for these changes. The students were open to being offered support from their university to encourage them to eat healthier suggesting cooking classes and reducing the cost of healthy food options on campus. Future healthy eating interventions should target the barriers students face in following a healthy diet whilst at university, such as limited budget and time constraints. Finally, interventions should be optimally timed, such as when starting university and/or during exam periods, to encourage student engagement and provide support when it is most beneficial to them.\n\nThe authors would like to thank the students for their participation in the study.",
    "category": "nutrition"
  },
  {
    "title": "Burnout syndrome and healthy lifestyle among Egyptian physicians: A cross-sectional study",
    "authors": "Nehal Mohamed Eisa, Mohamed A. M. El-Tabakh, Nourhan M. Kamal, Sara M. Gharbia, Mahmoud M. Samir, Wajid Syed, Mahmood Basil A. Al-Rawi, Ahmed Essam Abou Warda, Abdelrahman S. H. Refaee, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0320146",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320146",
    "content": "The phenomenon of burnout and the lifestyle of physicians significantly influence the delivery of healthcare. Over time, burnout intensifies, negatively impacting professional performance, which in turn leads to decreased quality of treatment, patient satisfaction, and productivity. Additionally, it increases the occurrence of medical mistakes and turnover among physicians. In addition to the direct influence of lifestyle on those components.\n\nThe purpose of this study is to assess burnout syndrome among Egyptian physicians, as well as to investigate factors that contribute to burnout, especially demographic characteristics, lifestyle patterns, and health habits.\n\nA cross-sectional study examined burnout prevalence and determinants among 502 Egyptian physicians in different governorates. An electronic questionnaire was used to collect data for the study. Questionnaire covered socio-demographics, The abbreviated Maslach Burnout Inventory (aMBI), and The Health Lifestyle and Personal Control Questionnaire (HLPCQ).\n\nYounger physicians under 30 showed higher burnout on emotional exhaustion and depersonalization scales, with significant findings (P = 0.047), (P <  0.01) respectively. Male physicians showed stronger depersonalization than females (P <  0.01). Burnout was higher among residents and fellowship trainees, with significant differences in depersonalization (P = 0.021). PhDs showed decreased burnout with significant outcomes (P = 0.002). Longer-working doctors had increased burnout in depersonalization (P = 0.005). Single doctors were more depersonalized than married ones (P = 0.025). Depersonalization was higher in childless people (P = 0.002). However, non-chronic illness physicians were more emotionally exhausted (P = 0.042).\n\nThese findings highlight the intricate relationship between burnout and lifestyle among physicians. A healthy lifestyle, including diet, routines, social support, and physical activity was linked to reduced burnout, while dietary harm avoidance was negatively correlated. This suggests opportunities to enhance the well-being of medical professionals through lifestyle interventions.\n\nCitation:Eisa NM, El-Tabakh MAM, Kamal NM, Gharbia SM, Samir MM, Syed W, et al.  (2025) Burnout syndrome and healthy lifestyle among Egyptian physicians: A cross-sectional study. PLoS ONE 20(4):\n           e0320146.\n        \n        https://doi.org/10.1371/journal.pone.0320146\n\nEditor:Marwa Ramadan, The World Bank Group, CANADA\n\nReceived:June 28, 2024;Accepted:February 13, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Eisa et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Our data are subject to strict confidentiality agreements due to the sensitive nature of the information collected, and therefore, we cannot share it publicly; access requests must be directed to the principal investigators under the oversight of the Prime Ministry of Health in Egypt via the following email address:giza.clinical.research@gmail.com.\n\nFunding:This study was supported by the Research Supporting Project, King Saud University, Saudi Arabia, (RSP2025R378) which provided funding for this work )\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nAbbreviations:COVID-19,\n            Coronavirus Disease of 2019; EE,\n            Emotional Exhaustion; DP,\n            Depersonalization; PA,\n            Personal Accomplishment; QoL,\n            Quality of Life; aMBI,\n            abbreviated Maslach Burnout Inventory; HLPCQ,\n            Healthy Lifestyle and Personal Control Questionnaire\n\nThe health and well-being of healthcare providers are essential for delivering high-quality patient care. Healthcare provider burnout is an unintended consequence of chronic workplace stressors, which can be emotional or interpersonal [1].\n\nBurnout syndrome has emerged as one of today’s most serious psychosocial occupational disorders, resulting in significant costs for both healthcare providers and organizations [2]. Burnout is a syndrome of serious emotional exhaustion with poor work adaptation due to prolonged occupational stress [3]. Christina Maslach described it in terms of emotional exhaustion (EE), depersonalization (DP), and personal accomplishment (PA) [4]. EE manifests in feelings and sensations of being exhausted by the psychological efforts made at work, while DP is a response of detachment, indifference, and unconcern toward the work being performed and/or the people who receive it. PA is reflected in a negative professional self-evaluation and doubts about the ability to perform the job effectively [5].\n\nBurnout syndrome has many negative effects on both the individuals who suffer from it and the organizations where these providers work. These effects are initially psychological in nature, but they later affect physical, biological, and behavioral health, which will have unfavorable organizational consequences [6]. Burnout can affect patient care by leading to poor care quality, medical errors, longer recovery times, and lower patient satisfaction [4]. There is an increased need to construct a plan for action to restore healthcare provider well-being: aligning personal and organizational values and allowing providers to practice different self-care strategies [1].\n\nPrevious studies concerning burnout among healthcare providers investigated a wide range of burnout predictors. These included demographic factors, professional and clinical practice characteristics, and workplace factors such as workload, work/life balance, job autonomy, and leadership issues. Mental health factors such as anxiety, as well as physical health factors, lifestyle patterns and habits, and psychosocial variables, may all increase the risk of burnout [1].\n\nLifestyle is an important factor that can influence healthcare providers’ burnout. For stress management, there is a need to improve health by empowering people to take control over their lives through daily health-related lifestyle choices [7]. A healthy lifestyle is significantly correlated with maintaining health and preventing disease [8]. According to WHO guidelines, a healthy lifestyle can lower the risk of preventable health problems and improve quality of life (QoL) [9]. Also, the occurrence of the COVID-19 pandemic exacerbated healthcare providers’ burnout, adding several physical and emotional stressors on frontline healthcare providers [10].\n\nIn order to effectively avoid or reduce the complex phenomena of burnout, this study intends to contribute to the existing literature on the subject by evaluating burnout syndrome among Egyptian physicians. The study will take into account a wider variety of factors that are known to predict and cause burnout.\n\nA cross-sectional, descriptive observational study was designed to assess the prevalence and factors related to burnout among Egyptian physicians working in all health facilities in different governorates in Egypt. The study population includes Egyptian physicians of both sexes who were between 25-80 years old and exclude who were above 80 years old.\n\nThe sample size was calculated to be 390 subjects, we evaluated the present study on 502 participants taking into consideration that the total number of Egyptian physicians (governmental and private physicians) is 98,000, provided by the Central Agency for Public Mobilization and Statistics [11], the prevalence of burnout syndrome in Egypt is 36.4% [12], the power was 80%, the statistical level of significance was 0.05, and 10% expected non-response. The sample size was calculated using the Open Epi, Version 3, open-source calculator.\n\nThe study was conducted over six months, starting in January 2023. The study included physicians from 10 governorates out of a total of 27 governorates. The physicians were selected using non-probability sampling techniques, specifically convenience sampling, to capture a diverse range of participants across different regions.\n\nPhysicians were invited to participate through electronic communications via social media platforms, including WhatsApp and Facebook medical groups, as well as private accounts. The data was collected using a pre-designed, electronic, self-administered questionnaire, which was distributed through Google Forms.\n\nThe study utilized three questionnaires: (a) A socio-demographic, occupational, and health-related characteristics questionnaire (16 questions). (b) The abbreviated Maslach Burnout Inventory (aMBI) (9 questions) [13]. (c) The Healthy Lifestyle and Personal Control Questionnaire (HLPCQ) (26 questions) [7].\n\nThe questionnaires were most likely distributed in the Arabic language to ensure clarity and understanding among participants. The translation process was carefully conducted following established procedures. Initially, the questionnaires were translated from English to Arabic by two independent bilingual experts. The translations were then compared and synthesized into a single version. A back-translation to English was performed by a separate bilingual expert to ensure the accuracy and equivalence of the content. Any discrepancies were resolved through discussion among the translators to achieve a final version.\n\nIn addition, an official approval from MindGarden was obtained to allow the use of the abbreviated Maslach Burnout Inventory (aMBI). This approval is mandatory for the usage of the questionnaire and was secured before the study commenced to comply with publication requirements.\n\nThe aMBI is a nine-item scale used for assessing burnout. It has three subscales: emotional exhaustion (EE), depersonalization (DP), and personal accomplishment (PA). Each subscale is assessed by three items. For each item, there is a seven-point Likert scale that ranges from never (0) to every day (6). The score for each item was summed up for each doctor. For emotional exhaustion and depersonalization, a higher score means greater burnout; this is the inverse for personal accomplishment. The score of each subscale could range from a minimum of 0 to a maximum of 18. A high score of EE and DP and a lower score of PA indicate a higher level of burnout [13]. The aMBI defined burnout as the presence of two or more ‘moderate’ scores: EE ≥  7, DP ≥  4, or PA ≤  14. The scores of each subscale are reported separately and cannot be added up as a total score.\n\nThe Healthy Lifestyle and Personal Control Questionnaire (HLPCQ): The HLPCQ consists of 26 items. It asks individuals to rate their lifestyle habits on a Likert-type scale (1 =  never or rarely, 2 =  sometimes, 3 =  frequently, and 4 =  always). There are 12 items about diet, 8 about daily time management, 2 about organized physical exercise, and 4 about social support and positive thinking. The reliability and internal consistency of the HLPCQ were satisfactory [7].\n\nEthical approval for the study was obtained from the “Research Ethics Committee” in the Central Directorate for Research and Health Development in MOHP (REC No. 19-2022/22). The study was conducted in accordance with the ethical guidelines and principles outlined by the Declaration of Helsinki and the World Health Organization. Participants’ informed consent was obtained prior to their participation in the survey. The consent process included a clear explanation of the study’s purpose, procedures, potential risks, benefits, and the voluntary nature of participation. Participants were assured of the confidentiality and anonymity of their responses. Consent was actively obtained by requiring participants to indicate their agreement by clicking a consent button before proceeding to the survey.\n\nDescriptive statistics, including means, standard deviations (SD), minimums, maximums, absolute frequencies, and percentages, were used to summarize the data. Chi-square (χ²) tests were performed using MiniTab V14 to determine whether the actual burnout survey response rates matched the expected rates. Principal component analysis (PCA) was employed to extract the elements of the Healthy Lifestyle and Personal Control Questionnaire (HLPCQ). Bartlett’s test was conducted to assess the adequacy of correlations between items, and a determinant value was calculated to check for multicollinearity (with the determinant close to zero indicating potential multicollinearity). The Kaiser-Meyer-Olkin (KMO) measure was used to evaluate the sample size adequacy. The correct number of derived components was determined using the scree plot method (identifying inflexion points) and Kaiser’s criterion of eigenvalues greater than 1. An orthogonal varimax rotation was applied to maximize the loadings of each item on the resulting factors, with items having loadings greater than 0.3 being considered significant for further analysis. Cronbach’s alpha values were calculated to assess the internal reliability of the variables. Following this, a multiple linear regression analysis was conducted to examine the relationship between burnout (as measured by the abbreviated Maslach Burnout Inventory) and the various predictors, including demographic data, HLPCQ scores, and other relevant variables. The regression model was adjusted for potential confounding factors to provide a more precise understanding of the determinants of burnout. The results from the regression analysis, including B values, p-values, and 95% confidence intervals, were reported to highlight the strength and significance of these relationships. Pearson’s rho correlation coefficient was also used for between-group comparisons where appropriate. Statistical significance was set at p <  0.05, and all analyses were conducted using SPSS version 28 for Windows.\n\nFive hundred and two Egyptian physicians participated in this study who were mostly (49%) in the age group (30-40) years with more female participants (65.73%); specialists compose 25.4% and significant participation of rheumatologists (18.52%). Most participants (38.04%) were holding a master’s degree regarding their level of education and also worked in the same governorate of residence (79.08%) for (8-12) hours (39.6%). The majority of participants were married (73.3%). Most of the participants weren’t smokers (92.4%) and didn’t suffer from chronic disease (71.7%) but were also overweight (37.84%). There was no significant difference in family size regarding to children’s number and suffering from non-chronic disease. (Table 1andFig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.g001\n\nTable 2andFigs 2,3, and4demonstrate the prevalence of low, moderate, and high burnout across various demographic factors and lifestyle characteristics among 502 Egyptian physicians. Notably, higher burnout was observed in younger physicians below the age of 30 on the emotional exhaustion (EE) and depersonalization (DP) scales, with significant findings (P = 0.047), (P <  0.01) respectively. Burnout levels declined with advancing age categories. Male physicians exhibited significantly higher depersonalization than females (P <  0.01). Residents and fellowship trainees showed a greater tendency toward burnout, with significant differences in depersonalization (P = 0.021) while in emotional exhaustion had higher burnout (P = 0.082). Burnout levels did not vary substantially across different specialties, as indicated by non-significant findings (P = 0.84). However, those with higher degrees, such as PhDs, had lower burnout levels with significant results (P = 0.002). But in emotional exhaustion showed lower exhaustion than other degrees (P = 0.363). Physicians working longer hours reported significantly higher burnout, depersonalization being notably elevated while decreased in emotional exhaustion (P = 0.076). Single physicians experienced more depersonalization compared to their married counterparts (P = 0.025). Additionally, those without children showed significantly higher depersonalization (P = 0.002). In contrast, in emotional exhaustion, married physicians had lower exhaustion than single ones (P = 0.061). Having children was associated with lower emotional exhaustion (P = 0.197). Chronic disease, smoking, and BMI did not significantly impact burnout prevalence, as indicated by non-significant findings (P = 0.892), (P = 0.711), (P = 0.773) respectively. However, physicians with non-chronic illnesses exhibited higher emotional exhaustion (P = 0.042).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.g004\n\nDescriptive statistics were calculated for each variable in the dataset to characterize the answers of the participants. A 4-point Likert scale, from 1 (Never/Rarely) to 4 (Always), was used to evaluate how often individuals engaged in different health-related activities posed in the survey. There were reports of frequency distributions. (Fig 5).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.g005\n\nWith the use of principal component analysis (PCA) in PAST V4.12, the underlying dimensions of the lifestyle questions were determined. The data was checked to make sure it was suitable for factor analysis before the PCA was run. Bartlett’s Test of Sphericity showed that the correlation matrix was not an identity matrix and that there were sufficient linear correlations between the variables (χ2(4005) =  21514.37, p 0.001). The sample size was sufficient for PCA, as measured by the Kaiser-Meyer-Olkin (KMO) criterion of sampling adequacy, which was 0.756.\n\nAfter applying PCA, we found that 62.47 percent of the total variance could be explained by five components with eigenvalues greater than 1. The scree plot showed that there was a distinct split after the fifth component, confirming that these five should be kept. To improve their readability, the five components were rotated using a Varimax algorithm. Most variables loaded significantly on just one component in the rotated solution, indicating a straightforward structure (Fig 6, i & ii).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320146.g006\n\nItems with loadings higher than or equal to 0.3 were used to assign labels to the components. Labels included “Criteria 1: good dietary choices” and “Criteria 2: dietary harm avoidance,” “Criteria 3: daily routine,” “Criteria 4”: structured physical activity,” and “Criteria 5”: social and mental equilibrium.\n\nCronbach’s alpha coefficients were determined for the items loading on each component to evaluate the consistency of the criteria. All criteria were found to have strong internal consistency, with alpha values above the universally accepted 0.6 threshold ranging from 0.683 to 0.850.\n\nUsing the regression approach, factor scores were calculated for each participant in order to analyze the associations between the criteria and other variables in the dataset. Next, Pearson’s or Spearman’s correlation coefficients were used to find associations between the factor scores and demographic characteristics.\n\nCriteria 1 (Good dietary choices) had a negative correlation with age, indicating that older people and those reporting lower levels of happiness tended to have fewer healthy eating habits. There may be a correlation between participants’ reports of lesser fatigue and their adherence to routines and schedules (Criteria 2: Dietary harm avoidance). The third criteria, “Daily Routine,” was positively correlated with both gender and professional status, suggesting that participants women had more regular daily routines. Participants who fulfilled criteria 4 (Organized physical activity) tended to have more orderly, predictable lives. With regards to Criterion 5, male participants were shown to be more cautious than female ones (Social and Mental Balance).\n\nThe present study investigated the risk factors or predictors that may cause physicians’ burnout syndrome by first indicating the demographic characteristics of the study participants that may had an impact on the level of burnout, Maslach Burnout Inventory (aMBI) which assesses three dimensions of burnout and finally the Healthy Lifestyle and Personal Control Questionnaire (HLPCQ), which measures the effectiveness of potential health-promoting treatments to improve people’s lifestyles and well-being.\n\nOur study found that lower scores of personal accomplishments, higher scores of depersonalizations, and higher scores of emotional exhaustions were significantly observed among individuals aged 30-40 years. Similar to our results, a cross-sectional study was conducted among physicians working at Ankara Hospital, noticing that the 20-29 age group of young doctors had the highest levels of emotional burnout and depersonalization, and had the lowest personal success scores [14].\n\nAnother study was performed in Zagazig University Hospital with a selected sample representing the four different major specialties working in the hospital, supporting that emotional exhaustion and depersonalization were much greater in the 29-year-old age group than in the older age groups (more than 50 years). This can be explained by the fact that as people become older, they become more mature and more skilled in handling stressful situations without burning out [15].\n\nSimilarly, Christina Maslach “The American social psychologist” mentioned in a review article that Age is the demographic factor that has most consistently been linked to burnout among all those that have been researched. According to reports, younger workers experience more burnout than workers over the age of 30 or 40 as age and work experience are muddled, thus burnout seems to be a greater risk early in one’s career [16].\n\nRegarding gender, we did not find significant differences, although a performed study in 2006 on general practitioners observed higher burnout levels among female physicians due to the conflict between professional and domestic tasks that female physicians are required to do [17]. However, the previous Croatian study we discussed before, found no significant differences regarding gender in burnout scores [14].\n\nTo our surprise, no significant observations were noticed regarding the levels of burnout in many different specialties of the study participants. However, another study observed a severely high level of emotional exhaustion and depersonalization among emergency department professionals compared to other specialties like paramedics. Many reasons make burnout more common among ED staff like nighttime work, job stress, and of course sleep issues [18].\n\nThe study was performed in Zagazig University Hospital and determined that different burnout levels are common between different specialties. They found that pediatricians had the highest mean scores for emotional exhaustion when compared to other specialties like internal medicine, general surgery, and gynecologists. A large percentage of pediatricians reported high emotional tiredness levels. On the other hand, only a small minority of them felt they had little personal accomplishment [15].\n\nEven though, another study at Suez Canal University Hospital realized that hospital physicians had a considerably greater prevalence of burnout than family doctors. The highest prevalence was recorded among participants who work in the internal medicine division, followed by surgeons and emergency physicians. Pediatricians, on the other hand, had the lowest prevalence. Being married and working in a teaching hospital are both reliable indicators of burnout [19].\n\nAnother study confirmed the hypothesis that burnout scores may differ regarding the physician specialty, one performed in a Chinese cancer center found a high level of burnout among 21.1% of the oncology staff [20]. Meanwhile, the results among oncologists in the United States were nearly 45% of them experiencing symptoms of burnout and this is explained by the amount of hours per week spent working from home and concentrating on a particular type of cancer in clinical practice, both independently linked to the likelihood of burnout [21].\n\nConcerning, marital status and the number of children, our study significantly observed lower scores of personal accomplishments among physicians with two or fewer children and higher scores of depersonalizations among married participants and individuals with two or fewer children. Although we did not find similar results regarding marital status from searching the literature review, a study among Croatian physicians observed no significant differences in burnout levels regarding marital status or even the number of children [22]. However, the study conducted at Zagazig University Hospital found that low scores of personal accomplishments were significantly higher among non-married when compared to married and this could apparently be due to the absence of the husband’s social support, which could act as a buffer against the consequences of stressful life events [15].\n\nThe burnout predictor we should pay attention to is the working hours, we significantly observed lower scores of personal accomplishments (high burnout) and higher scores of depersonalizations among participants working for an average of 8-12 hours per day. According to the World Health Organization (WHO), “Long working hours led to 745, 000 deaths from stroke and ischemic heart disease in 2016, a 29 percent increase since 2000, according to the latest estimates by the World Health Organization and the International Labour Organization” [23].\n\nThe study conducted among physicians working at Ankara Hospital confirmed that emotional burnout and depersonalization scores were higher among physicians who worked more than 8 hours [14].\n\nOur study also examined the effects of residency, specialty, and master’s degrees on the levels of burnout to find lower scores of personal accomplishments between residents and those with master’s degrees and higher scores of depersonalizations among resident physicians and specialists.\n\nSimilarly, that study at Ankara Hospital confirmed that there were significant levels of emotional exhaustion with the greatest depersonalization levels among residents, and higher emotional burnout scores were significantly found among physicians who believed that the criteria of academic promotion were overpowering [14].\n\nTo our knowledge, this is the first study to investigate the lifestyle of Egyptian physicians by using the Healthy Lifestyle and Personal Control Questionnaire (HLPCQ) and resulting in five criteria. Our study presented the relationship between the physicians’ lifestyle or daily habits and other variables like their gender, age, and even their professional status.\n\nIt was observed that older participants and those who reported feeling less happy already have fewer healthy eating habits and that is criteria 1 “Good dietary choices”. The participants reported feeling less fatigued are adhered to routines and schedules and that is criterion 2 “Dietary harm avoidance”. The third criterion is “Daily routine” which showed a positive relationship between gender and professional standing, indicating that female participants had more consistent daily routines. Participants who fulfilled criteria 4 “Organized physical activity” tended to have more orderly, predictable lives. Regards criterion 5 “Social and Mental Balance”, it was found that male participants were more circumspect than female participants.\n\nOther studies presented the lifestyle habits and well-being of the physicians in different patterns like the study performed in Bahrain. They found a clear pattern of unfavorable lifestyle habits and obesity among primary healthcare physicians. The authors reported percentages of the participants’ health conditions like hyperlipidemia, hypertension, BMI, and sleep time [24].\n\nAnother study performed in Pakistan presented the mental health well-being and work-life balance of the physicians using the Warwick Edinburg Mental Wellbeing Scale (WEMWBS) [25].\n\nAnother self-administered questionnaire was applied among primary health physicians in Saudi Arabia. The questionnaire included demographic information, medical history, physical activity, and stress levels. and food and smoking habits [26].\n\nOur study recommends controlling burnout symptoms and searching for the factors that may contribute to improving physicians’ satisfaction with their careers. Also, in order to combat burnout, organizational leadership is crucial. Physician satisfaction and burnout are directly impacted by leadership traits, characteristics, and management approaches. The highest levels of physician satisfaction are produced by transformational traits and abilities like mentoring, coaching, establishing pride, talking about values and purpose, applauding achievements, and discovering unique needs and talents [27,28].\n\nIt’s important to note that these are learnable abilities. Organizational leadership must show a commitment to fostering a culture of well-being, set an example for change, and address the issue of burnout at the systemic and organizational levels in order to achieve sustained and significant reductions in burnout [29].\n\nThe study by Safiye, et al., [30] explored the moderating role of resilience in the relationship between burnout and subjective well-being among medical workers in Serbia during the COVID-19 pandemic, finding that higher resilience levels significantly mitigate the adverse effects of burnout on well-being. Similarly, to our findings was also, the study by Safiye et al., [31] who examined burnout-related factors among healthcare professionals during the COVID-19 outbreak in Serbia, identifying high workload, emotional exhaustion, and inadequate support systems as key contributors to burnout. Both studies underscore the importance of resilience and targeted interventions in protecting the well-being of healthcare workers during crise.\n\nThis study has some limitations that should be considered when interpreting the findings. First, the use of a cross-sectional design limits the ability to establish causal relationships between burnout and its associated factors. Second, the reliance on self-reported data may introduce response biases, including social desirability bias, which could affect the accuracy of the findings. Additionally, the study was conducted among Egyptian physicians, which may limit the generalizability of the results to other healthcare settings or regions. Finally, while efforts were made to ensure a diverse sample, the use of non-probability sampling techniques may have led to a sample that is not fully representative of the broader physician population.\n\nThese findings highlight the intricate relationship between lifestyle factors and physician burnout. This study provides valuable insight into the correlation between the mental health of doctors and their physical health. Several outcomes are inversely correlated with harm avoidance, while burnout indicators are positively correlated with good eating, routine, social support, and exercise. These results point to the need for initiatives to improve the mental health of healthcare professionals and to establish initiatives to encourage healthy lifestyles. Medical personnel’ health can be improved by lifestyle adjustments.",
    "category": "oncology"
  },
  {
    "title": "The red blood cell distribution width is associated with all-cause and cardiovascular mortality among individuals with non-alcoholic fatty liver disease",
    "authors": "Yingxiu Huang, Ting Ao, Yinying Wang, Peng Zhen, Ming Hu, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321789",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321789",
    "content": "Identifying reliable prognostic indicators is essential for the appropriate management of non-alcoholic fatty liver disease (NAFLD).\n\nRed blood cell distribution width (RDW) has been established as an inflammatory marker associated with cardiovascular outcomes. This study aimed to evaluate the association between RDW and both cardiovascular and all-cause mortality in individuals with NAFLD.\n\nData from 7,438 participants with NAFLD were analyzed, collected between 2005 and 2016 through the National Health and Nutrition Examination Survey (NHANES). Mortality data were retrieved from the National Death Index (NDI). Restricted cubic spline (RCS) analysis was used to illustrate the relationship between RDW and mortality risk, Weighted Cox proportional hazards models were used to assess the independent relationship between RDW and mortality risk. Receiver operating characteristic (ROC) curves were generated to evaluate the predictive ability of RDW for survival outcomes.\n\nDuring a median follow-up period of 124 months, 1,269 deaths were recorded, including 335 from cardiovascular causes. RDW positively correlated with both cardiovascular and all-cause mortality according to the RCS analysis. Participants were categorized into quartiles based on RDW levels. Those in the highest RDW quartile (Q4) demonstrated a significantly higher risk of cardiovascular mortality (HR 3.61, 95% confidence interval [CI]:2.17–6.02, P=0.009) and all-cause mortality (HR 2.29, 95% CI:1.72–3.06, P < 0.0001), according to the weighted Cox hazards models. Additionally, the area under the curve (AUC) for all-cause mortality at 3, 5 and 10 years was, 0.69, 0.67, and 0.66, respectively. For cardiovascular mortality, the AUCs were 0.70, 0.68, and 0.68, respectively.\n\nAmong patients with NAFLD, RDW was identified as an independent predictor of increased cardiovascular and all-cause mortality risk.\n\nCitation:Huang Y, Ao T, Wang Y, Zhen P, Hu M (2025) The red blood cell distribution width is associated with all-cause and cardiovascular mortality among individuals with non-alcoholic fatty liver disease. PLoS ONE 20(4):\n           e0321789.\n        \n        https://doi.org/10.1371/journal.pone.0321789\n\nEditor:Kovuri Umadevi, Niloufer Hospital, Institute of Child Health, India\n\nReceived:October 13, 2024;Accepted:March 11, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Huang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All original data could be publicly available at the NHANES database:https://wwwn.cdc.gov/nchs/nhanes/Default.aspx. The data supporting the conclusions of this article have been uploaded to the Zenodo database (https://doi.org/10.5281/zenodo.14862447), without undue reservation.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nNon-alcoholic fatty liver disease (NAFLD), a widespread metabolic disorder, is characterized by substantial hepatic fat accumulation, systemic inflammation, and insulin resistance [1]. NAFLD is the most prevalent chronic liver disease affecting up to 40% of the general population [1,2]. It progresses through stages of steatosis, fibrosis/cirrhosis, and steatohepatitis, potentially leading to liver failure or hepatocellular cancer, both of which have poor prognosis and low survival rates [3,4]. Extensive research has consistently demonstrated a strong association between cardiovascular disease (CVD) and NAFLD [2]. Independent of traditional cardiovascular risk factors, NAFLD is closely linked to an increased risk of severe cardiovascular events and comorbidities [3]. NAFLD is strongly associated with diabetes, chronic renal disease, and cardiovascular disease [5], and is especially frequent in individuals with hepatocellular carcinoma [6], posing a considerable potential health and economic cost to society. To improve the monitoring of NAFLD and its associated mortality, identifying an affordable and readily available prognostic metric is crucial.\n\nRed blood cell distribution width (RDW), a routinely measured parameter in a complete blood count (CBC), assesses the variation in the size of red blood cells (RBCs). RDW is calculated by determining the standard deviation of RBC volume relative to mean corpuscular volume (MCV). The normal range for RDW is typically 11–15% [7]. While low RDW values are generally not clinically significant, elevated RDW levels can be associated with increased levels of inflammatory markers such as erythrocyte sedimentation rate (ESR), C-reactive protein (CRP), and interleukins (IL) [7]. Numerous studies have demonstrated that RDW can serve as a prognostic marker for various diseases, including acute myocardial infarction[8], COVID-19[9], heart failure [10], sepsis [11], and hepatocellular carcinoma [12]. Although several studies have explored the association between RDW and various conditions, fewer have focused on its relationship with NAFLD, Yanget al. [13]reported that patients with NAFLD tended to exhibit elevated RDW levels in a Chinese hospital cohort. However, in the United State, the relationship between RDW and mortality in patients with NAFLD remains unclear.\n\nTo address this gap, this study used a comprehensive population-based survey to evaluate the association among RDW, all-cause mortality, and cardiovascular mortality in individuals with NAFLD, thereby providing valuable insights into the health status of the US population.\n\nThis study used data from the NHANES database, which is conducted by the National Center for Health Statistics (NCHS) of the Centers for Disease Control and Prevention (CDC)[14]. Information on the general nutritional condition and state of health of Americans who were not in institutions was gathered using nationally representative NHANES survey [15]. All participants provided informed consent, and the NHANES dataset does not contain any individually identifiable patient data. The NHANES protocols were approved by the National Center for Health Statistics’ Institutional Review Board. This study included data collected between 2005 and 2016. The study sample comprised adults aged 20 years and older with available data to determine NAFLD status (n = 5,872). Participants were excluded if they had evidence of secondary causes of liver disease, such as excessive alcohol intake[16] (≥4 drinks per day for men and ≥3 drinks per day for women; one drink is defined as a 12 ounce beer, a 5 ounce glass of wine, or 1.5 ounces of liquor, including whiskey, gin, beer, wine, wine coolers, and any other alcoholic beverage, viral hepatitis B or C, or were pregnant (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321789.g001\n\nRDW (percentage) was measured using a Coulter analyzer at mobile examination centers (MEC), using peripheral blood samples [17].\n\nA Fatty Liver Index (FLI) of ≥ 60 indicated the existence of NAFLD, provided that the following conditions were absent: (1) hepatitis B infection (indicated by a positive hepatitis B surface antigen) or hepatitis C infection (evidenced by a positive hepatitis C antibody or HCV RNA); (2) excessive alcohol consumption (for women, three alcoholic drinks per day, and for men, more than four). The FLI was calculated using the following formulae [18]:\n\nMortality status was determined by integrating information obtained from the National Death Index, which may be reached athttps://www.cdc.gov/nchs/data-linkage/mortality-public.htm, with the NHANES data. Participants were classified as either alive or deceased based on NDI data. The follow-up period was calculated by subtracting the date of the NHANES examination from the date of death (December 31, 2019). Cardiovascular and all-cause mortality were retrieved and analyzed using the 10th Revision of the International Classification of Diseases (ICD-10). Cardiovascular mortality was defined as death due to cardiac conditions, which were categorized under the codes I00–I09, I11, I13, and I20–I51. The median follow-up period was 124 months (interquartile range: 100–147).\n\nPotential confounding factors were considered based on previous research and clinical judgment, including age, gender, educational level, marital status, body mass index (BMI), smoking status, CVD, diabetes, alcohol intake, and hypertension. Age was treated as a continuous factor, while gender was divided into male and female categories. Race/ethnicity was categorized as Mexican American, non-Hispanic Blacks, non-Hispanic Whites, and other. Marital status was classified as married or living with a partner, or living alone. Educational level was classified into three groups: less than 9 years, 9–12 years, and more than 12 years. Smoking status was classified as never, former, or current smoker. Alcohol use was categorized as never, former or current [14]. Diabetes was defined using a comprehensive approach that included a hemoglobin A1c level of 6.5%, a fasting blood glucose level of 126 mg/dL, use of oral hypoglycemic agents or insulin, or a self-reported history of diabetes [19]. Hypertension was defined as systolic blood pressure ≥140 mmHg or diastolic blood pressure ≥90 mmHg, or by a self-reported history of hypertension or the use of oral antihypertensive medications [19]. Self-reported information regarding cardiovascular disease (CVD) history included prior diagnoses of heart failure, coronary heart disease, angina, heart attack, or stroke [14].\n\nThis analysis accounts for the complex NHANES sample design by incorporating appropriate sample weights, stratifications, and clustering. Sample weights were calculated by dividing the 2-year MEC weight by six. Categorical variables were presented as proportions (%), while continuous variables were presented as mean (standard deviation, SD) or median (interquartile range, IQR), as appropriate. Categorical variables were compared using the survey-weighted chi-squared test, whereas continuous variables were compared using survey-weighted linear regression.\n\nBaseline characteristics were grouped according to RDW quartiles (Q1 (≤12.2), Q2 (12.3–12.7), Q3 (12.8–13.4), and Q4 (≥13.5)). To investigate possible nonlinear correlations between all-cause and cardiovascular mortality among NAFLD patients, RCS with four knots (5th, 35th, 65th, and 95th percentiles) were employed.\n\nSurvey-weighted Cox proportional hazards models were used to assess the independent association between RDW and all-cause and cardiovascular mortality in patients with NAFLD. The results were displayed across three models: Model 1, unadjusted; Model 2, which was modified for race, sex, age, marriage; and Model 3, additionally adjusted for BMI and smoking, diabetes, hypertension, and history of CVD.\n\nKaplan–Meier survival analysis employed the log-rank test to examine the odds of survival for individuals with NAFLD who were categorized by RDW quartile group. Variables including smoking status, sex, BMI (< 30 and ≥ 30 kg/m2), diabetes, age (< 65 and ≥ 65 years), and CVD history, were the basis for the stratified and interaction analyses.\n\nA time-dependent receiver operating characteristic (ROC) curve was used to evaluate how well RDW predicted survival outcomes at various time intervals.\n\nData analysis was conducted using R software version 4.2.2, R survey package version 4.2.2, and Free Statistics software version 1.9.2 [20]. Statistical significance was asset at a two-tailed P value < 0.05. This cohort study was conducted according to the guidelines outlined in the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement [21].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321789.t001\n\nDuring a median follow-up period of 124 months, 1,269 deaths occurred, including 335 cardiovascular deaths. A positive nonlinear correlation between RDW and all-cause mortality was shown by RCS analysis (P for nonlinear < 0.001) (Fig 2A).\n\n(A) and cardiovascular mortality (B) in individuals with NAFLD is depicted using restricted cubic splines. The hazard ratios were adjusted for various factors, including age, sex, race, BMI, smoking status, education level, diabetes, history of CVD.\n\n(A) and cardiovascular mortality (B) in individuals with NAFLD is depicted using restricted cubic splines. The hazard ratios were adjusted for various factors, including age, sex, race, BMI, smoking status, education level, diabetes, history of CVD.\n\nhttps://doi.org/10.1371/journal.pone.0321789.g002\n\nIn Model 1, higher RDW values were associated with a substantial increase in the risk of all-cause death (HR 1.30, 95% confidence interval [CI] 1.24–1.36, p < 0.001) (Table 2). After multivariate correction, every unit increase in RDW was linked to a 24% increase in mortality risk in Model 2 (HR 1.24, 95% CI 1.16–1.33, p < 0.001) and a 22% increase in risk in Model 3 (HR 1.22, 95% CI 1.14–1.31, p < 0.001) (Table 2). When analyzed as a categorical variable in Model 3, individuals in the highest RDW Q4 group had a markedly elevated risk of all-cause mortality (HR 2.29, 95% CI 172–3.06, p < 0.001) was higher than that of the Q1 group (table 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321789.t002\n\nAccording to the survival curve analysis, those in the higher RDW Q4 group had a significantly lower survival rate than those in the lower RDW group (P<0.001) (Fig 3A).\n\n(A) and cardiovascular mortality (B).\n\n(A) and cardiovascular mortality (B).\n\nhttps://doi.org/10.1371/journal.pone.0321789.g003\n\nSubgroup examining the association between RDW and all-cause and mortality across age, sex, BMI, diabetes, smoking status, and history of CVD revealed no significant interactions (P for interaction > 0.05) (Fig 4A).\n\n(A) and cardiovascular mortality (B). subgroup analysis across various factors, including smoking status, age, BMI, sex, CVD, and diabetes.\n\n(A) and cardiovascular mortality (B). subgroup analysis across various factors, including smoking status, age, BMI, sex, CVD, and diabetes.\n\nhttps://doi.org/10.1371/journal.pone.0321789.g004\n\nIn Model 1, a notable increase in cardiovascular mortality was observed with increasing RDW (HR 1.33, 95% CI 1.27–1.39, p < 0.001) (Table 2). After extensive adjustments, each unit increased in RDW corresponded to a 23% increase in cardiovascular mortality risk (Model 3, HR 1.23, 95% CI 1.14–1.33, p < 0.001) (seeTable 2). When analyzed as a categorical variable, individuals with the highest RDW Q4 group had a notably higher risk of cardiovascular mortality (HR 3.61, 95% CI 2.17–6.02, p <0.001) compared to Q1 group in model 3 (Table 2). RCS analysis showed a linear correlation between RDW and cardiovascular mortality (P for nonlinearity = 0.145) (Fig 2B).\n\nSurvival curve analysis further indicated a marked reduction in survival rates in the greater Q4 RDW group compared to the lowest group (P < 0.001) (Fig 3B).\n\nThe relationship between cardiovascular mortality and RDW was investigated using a subgroup analysis across various factors, including smoking status, age, BMI, sex, CVD, and diabetes. The primary findings were consistently observed across these subgroups, with no significant interactions detected (P > 0.05) (Fig 4B).\n\nTime-dependent ROC curve analysis showed that the AUC for RDW in predicting 3-, 5-, and 10-year all-cause mortality was f 0.69, 0.67, and 0.66, respectively (Fig 5Aand5B). The AUC for RDW in predicting 3-, 5-, and 10-year cardiovascular mortality was 0.70, 0.68, and 0.68, respectively (Figs 4Cand4D). These findings suggest that RDW has reliable prognostic potential for mortality throughout a range of time periods.\n\n(A, B) and cardiovascular mortality (C, D).\n\n(A, B) and cardiovascular mortality (C, D).\n\nhttps://doi.org/10.1371/journal.pone.0321789.g005\n\nSensitivity analysis was conducted by including other serum markers (total cholesterol (TCHO), alanine aminotransferase (ALT), glucose (GLU), serum creatinine (SCr), and high-density lipoprotein (HDL-C)) in the multivariate analysis model. The results of weighted multivariate Cox regression analysis indicated that RDW was independently associated with all-cause and cardiovascular mortality (Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321789.t003\n\nThis study thoroughly examined the association between RDW and all-cause and cardiovascular mortality in a population with NAFLD using various methodologies. Analysis of data from 7,438 adult participants with NAFLD in the NHANES revealed a significant association between RDW and increased risk of all-cause and cardiovascular mortality.\n\nRDW is a measure of the size distribution of red blood cell in circulation. An increase in RDW can be caused by any physiological mechanism that alters red blood cell shape and releases immature cells into circulation early. Previous studies have demonstrated that RDW can serve as a prognostic indicator of various diseases, including acute myocardial infarction [8], COVID-19 [9], heart failure [10,22], sepsis [11], hepatocellular carcinoma [23], acute respiratory failure [24], acute pancreatitis [25]. RDW has also been linked to all- cause mortality and specific mortality in the general population [26–28]. Consistent with these findings, this study demonstrated a positive association between RDW and all-cause mortality in individuals with NAFLD.\n\nPrevious research has demonstrated that elevated RDW is associated with cardiovascular mortality [29]. Katamreddyet al.[30] reported that an elevated RDW was associated with cardiovascular mortality in the intermediate ASCVD group in a study of 8884 subjects from NHANES III. Liaoet al.[31] found that RDW was an independent predictor and showed a linear association with 1-year cardiovascular mortality in patients undergoing percutaneous coronary intervention (PCI). Linet al.[32] identified RDW as an independent predictor of cardiovascular mortality in 181 STEMI patients (OR = 1.288, 95% CI, 1.126–1.472; P = 0.0005). This studys findings indicate that RDW is associated with cardiovascular mortality in the NAFLD population, aligning with the results reported above.\n\nHowever, the reason for the association between increased RDW and poor outcomes in patients with NALFD is not been fully understood. Based on the literature, we propose the following potential mechanisms: A plausible pathway is the stimulation of proinflammatory cytokines, which are associated with NALFD [19]. An increase in RDW might result from the inhibition of erythropoietin-driven erythrocyte maturation caused by the rise of interleukin-1β, TNFα, and interleukin 6 [33]. In addition, increased RDW reflects a range of underlying metabolic problems, including inflammation and malnutrition, which can lead to decreased erythropoiesis and aberrant red blood cell survival [34]. Consequently, we postulated that RDW may represent inflammation, malnourishment, and other lifetime anomalies may be linked to both cause-specific and all-cause mortality [7]. Further research is needed to fully elucidate the underlying biological mechanisms linking between higher RDW to adverse outcomes.\n\nThis study had several strengths. First, it is the first large-scale study to evaluate the relationship between RDW and mortality in adults with NAFLD living in the United States. Second, the research categorized RDW into distinct variables, which helped mitigate confounding factors and strengthened the reliability of the findings. However, this study also has limitations. First, some potential confounding factors that might influence the association between RDW and mortality may have been omitted from the analysis. Second, because the study data were from participants in the US, further research is needed to confirm whether the results can be generalized to populations with NALFD in other countries. Third, as judging RDW based purely on a single laboratory test may not be indicative of patient immunity, more clinical randomized controlled studies are required to verify our findings.\n\nIn patients with NAFLD in the US, RDW is an independent predictor of increased risk of cardiovascular and all-cause mortality. Importantly, RDW demonstrated good predictive ability for both short-term and long-term mortality. Further prospective studies are required to confirm these findings and elucidate the underlying mechanisms.\n\nThe authors sincerely thank the Physician Scientist Team for their enthusiastic and meticulous teaching and guidance on NHANSES study.",
    "category": "oncology"
  },
  {
    "title": "Anticancer properties of peptides and protein hydrolysates derived from Asian water monitor (Varanus salvator) serum",
    "authors": "Jitkamol Thanasak, Sittiruk Roytrakul, Rudee Surarit, Waraphan Toniti, Wanna Sirimanapong, Janthima Jaresitthikunchai, Narumon Phaonakrop, Siriwan Thaisakun, Sawanya Charoenlappanit, Surasak Jittakhot, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321531",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321531",
    "content": "This study investigated the anticancer efficacy of <3 kDa fractions derived from native peptides and protein hydrolysate ofVaranus saltatorserum. The inhibitory effects of these fractions were evaluated against a panel of cancer cell lines (A375, CaCO2, CAL27, NCI-H460, HeLa, HCT8, HT29, HepG2, KATO III, MCF-7, MDA-MB-231, Raw264.7, SKOV-3, SW620, T47D, and U937) and normal cell lines (HaCaT, MRC5, and Vero). Native peptides demonstrated higher anticancer activity compared to protein hydrolysates, inhibiting 16 cell lines and exhibiting high efficacy (≥70% inhibition) against CaCO2, CAL27, HaCaT, HT29, HepG2, MCF-7, MRC5, and U937. These native peptides were further fractionated by stepwise reverse-phase column chromatography. The hydrophilic (C18 unbound) peptide fraction exhibited greater anticancer activity than the hydrophobic (C18 bound) fraction. In addition, by LC-MS analysis, the peptide sequences were screeningin silico. The predictions showed that 159 of the 432 Varanus peptides had the potential to be anticancer peptides (ACPs), of which the top twenty had a probability of more than 75%. The anticancer mechanism of peptides may be explained by the mechanism of cell entry or action. Further peptide synthesis and modification should be the next step to enhance the anticancer efficacy of these peptides with less toxicity to Vero cells. This finding sets the way for the development of new anticancer drugs originating fromVaranus salvatorserum peptides.\n\nCitation:Thanasak J, Roytrakul S, Surarit R, Toniti W, Sirimanapong W, Jaresitthikunchai J, et al.  (2025) Anticancer properties of peptides and protein hydrolysates derived from Asian water monitor (Varanus salvator) serum. PLoS ONE 20(4):\n           e0321531.\n        \n        https://doi.org/10.1371/journal.pone.0321531\n\nEditor:Ruo Wang, Fujian Provincial Hospital, CHINA\n\nReceived:November 19, 2024;Accepted:March 7, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Thanasak et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The research project was supported by Mahidol University (Award number: NDFR 45/2565 Recipient: Jitkamol Thanasak). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nCancer remains a leading global health concern, with both incidence and mortality rates continuing to increase. In 2022, there were an estimated 20 million new cancer cases and 9.7 million cancer-related deaths worldwide. This reflects a significant increase from previous years, highlighting the growing burden of cancer globally [1]. Lung cancer is the most commonly diagnosed cancer and the leading cause of cancer death overall and in men worldwide, with almost 2.5 million cases and 1.8 million deaths. In females, breast cancer is the most commonly diagnosed cancer and the leading cause of cancer death, followed by lung, colorectal, and cervical cancers [2].\n\nConventional cancer treatments, such as surgery, chemotherapy, and radiation therapy, are often effective but come with significant limitations. Chemotherapy and radiation often cause side effect such as damage to healthy cells, metastatic, recurrence, drug toxin, organ damage etc. So, the studies on antimicrobial peptides and anticancer peptides have become popular in recent years. Anticancer peptides are thought to be an alternative treatment that are likely to be more efficient than chemical agents and cause fewer side effects. Peptides are a new group of biomolecules that are effective at inhibiting the growth of resistant and nonresistant pathogenic bacteria, including various types of cancer cells [3–12]. Previous reports indicate that antimicrobial peptides can be useful for anticancer therapeutic purposes. For example, an antimicrobial peptide synthesized from CAMEL (KWKLFKKIGAVLKVL-NH2) has anticancer potential for B16-F10 murine melanoma tumors [13]. Warnericin RK (WRK) and its derivatives (WarnG20D and WarnF14V) were found to be cytotoxic to leukemic cells (Jurkat, KG1, KS62), prostate and glial cancer cells, prostate healthy cells and astrocytes [14].\n\nNatural sources of bioactive peptides with anticancer effects have been reviewed in plants and animals. It has been reported that the anticancer potential of natural compounds such as coumarin may modulate various signaling pathways, including those involved in cell cycle regulation, apoptosis, and angiogenesis. In addition, some studies highlight the synergistic effects of combining coumarins with anticancer peptides or other therapeutic agents to enhance cancer treatment efficacy [15–20]. Animal sources of bioactive peptides with anticancer effects including terrestrial mammals and byproducts, milk and dairy products, marine animals, amphibians, animal venoms and reptiles have been reported [21,22]. The anticancer potential of reptile-derived components has been reviewed for several species, such as geckos, turtles, snakes, scorpions, crocodiles and Asian water monitors [21]. For example, two HPLC-separated mucous fractions (F2 and F5) derived from giant African snails (Achatina fulica) showedin vitrocytotoxicity against a breast cancer cell line (MCF-7) [23]. A peptide extracted from scorpion venom, BmKn2, has been shown to inhibit bacterial and cancer cell growth [10,24]. The anticancer properties of Siamese crocodile (Crocodylus siamensis) blood have been investigated bothin vitroandin vivo. The modified cationic antimicrobial peptides KT2 and RT2 derived fromCrocodylus siamensisLeucrocin I exhibited anticancer activity against human colon cancer HCT-116 cells, in which RT2 peptide upregulated proteins, including CFTR, Wnt7a, TIA1, PADI2, NRBP2, GADL1, LZIC, TLR6, and GPR37, within the tumor, resulting in suppressed tumor growth in mice [25–27].\n\nIn addition, investigations of reptilian serum samples indicated that the presence of Asian water monitor (Varanus salvator), python (Malayopython reticulatus) and tortoise (Cuora kamaroma amboinensis) inhibited the viability of Henrietta Lacks cervical adenocarcinoma cells (HeLa), prostate cancer cells (PC3) and human breast adenocarcinoma cells (MCF7 cells). The potential anticancer peptides (ACPs) were 123/883 peptides fromV. salvator, 306/1074 peptides fromMalayopython reticulatusand 235/885 peptides fromC. kamaroma amboinensis[28,29].\n\nThe Asian water monitor (Varanus salvator) is a large varanid lizard native to southern and southeastern Asia. It is one of the most common monitor lizards in Asia. These varanids feed as both scavengers and predators [30,31]. Because these animals can survive in poor environmental conditions, research into the immune and digestive systems of these animals has attracted increasing interest [32,33]. Moreover, the growing population of Varanus has led to much debate about managing the exploitation of this species. These reptilian-derived compounds have long been widely used for traditional treatments in Asia. Several components derived from reptiles have been experimentally proven, and anticancer research has been performed on different sources, including extracts, crude peptides, serum, bile, and venom [21]. Bioactive peptides are increasingly being considered good drug candidates for cancer therapeutic application because protein and functional peptides have excellent cell permeability, minimal potential to elicit an immune rejection response, low toxicity and are easy to synthesize and modify [21,26,34,35]. Thus, a growing number of antimicrobial peptides (AMPs) and anticancer peptides (ACPs) derived from the bioactive components of monitor-lizards are being investigated [29,36–38]. However, there is still little related research, and research on this topic is at an early stage. Therefore, the objective of this study was to examine the inhibitory effect of protein hydrolysate and peptide extracted fromVaranus salvatorserum on cancer cellsin vitro. This investigation identified novel anticancer bioactive molecules for the future treatment of human cancer.\n\nThe Asian water monitor (Varanus salvator) (n=21), which weighed more than 5 kg and had a length of more than 100 cm on the snout to anus, was randomly selected. The sex distribution was not restricted. All Varanus individuals had no clinical signs and had good physical condition. The sampling procedure was carried out at the Khao-zon Wildlife Breeding Station in Ratchaburi Province, Thailand. Animal use was approved by the Faculty of Veterinary Science, Mahidol University-Institute Animal Care and Use Committee (FVS-MU-IACUC). (COA. No. MUVS-2020-11-52). The experiments were performed in accordance with approved guidelines.\n\nPeripheral blood samples (10 ml.) was collected from the caudal tail vein of eachVaranus salvatorusing an 18-gauge needle into a plain blood collection tube. Whole blood can coagulate by leaving the blood undisturbed at room temperature for 30 minutes. All the samples were handled in the laboratory at 2–8°C. All blood samples (n=21) were centrifuged at 1,526 x g for 10 minutes in a refrigerated centrifuge (4°C). The clot blood was removed, and the serum was collected and stored at -20°C until further analysis.\n\nThe <3 kDa peptide fraction was isolated fromVaranus salvatorserum by diluting the serum five-fold with 10 mM sodium acetate buffer (pH 4.0). Fifteen milliliter aliquots of this diluted serum were then centrifuged at 3000 xgfor 30 minutes at 4°C through a 3 kDa molecular weight cutoff (MWCO) membrane (Vivaspin 20, GE Healthcare, Chicago, USA). The flow-through fraction, containing peptides with a molecular weight of <3 kDa, was collected.\n\nThe retentate (>3 kDa) was collected, and its protein concentration was determined using the Lowry method with bovine serum albumin (BSA) as a standard [39]. This >3 kDa fraction, dissolved in 10 mM sodium acetate (pH 4.0), was then subjected to enzymatic hydrolysis using porcine pepsin (Sigma-Aldrich, St. Louis, MO, USA) with an activity exceeding 250 units/mg. Hydrolysis was performed at a 1:20 (w/w) enzyme/substrate ratio at 37°C for 16 hours. The reaction was terminated by heating at 100°C for 10 minutes, and the resulting hydrolysate was filtered through a 3 kDa MWCO membrane to obtain the <3 kDa hydrolysate fraction.\n\nTen milliliter aliquots of the <3 kDa native peptide fraction, previously centrifuged at 5000 xgfor 15 minutes at 4°C, were purified by reverse-phase chromatography using a Delta-Pak C18 column (100 Å, 3.9 mm × 150 mm; Interlink Scientific Services Ltd., Kent, UK). The column was equilibrated with 0.1% trifluoroacetic acid (TFA) in water at a flow rate of 1 mL/min. Following sample loading and a wash with 0.1% TFA in water, the unbound (hydrophilic) fraction was collected. The bound (hydrophobic) fraction was then eluted with 0.1% TFA in 100% acetonitrile. All resulting fractions were concentrated using a SpeedVac vacuum concentrator, resuspended in phosphate-buffered saline, and stored at -20°C until evaluation of anticancer activity.\n\nProtein concentrations of all fractions, reconstituted in phosphate-buffered saline, were determined using the Lowry method with bovine serum albumin (BSA) as a standard. The cytotoxicity of all fractions at 100 µg/mL was evaluated against eighteen culture cell lines (A375, CaCO2, CAL27, NCI-H460, HaCaT, HeLa, HCT8, HT29, HepG2, KATO III, MCF-7, MDA-MB-231, MRC5, Raw264.7, SKOV-3, SW620, T47D, and U937), with Vero cells serving as a normal control.\n\nThe tested cell lines derived fromHomo sapiensinclude: A375 (malignant melanoma), CAL27 (tongue squamous cell carcinoma), NCI-H460 (lung carcinoma, large cell lung cancer), HeLa (cervical cancer caused by HPV-18), HepG2 (hepatocellular carcinoma), KATOIII (gastric carcinoma), CaCO2, HCT-8, HT-29, SW620 (colorectal adenocarcinoma), MCF-7, MDA-MB-231, T47D (mammary gland/breast adenocarcinoma), SKOV-3 (ovarian adenocarcinoma), U-937 (histiocytic lymphoma), HaCaT (immortalized keratinocyte) and MRC-5 (normal lung fibroblast cell line). The tested cell lines derived from murine was Raw264.7 (Abelson murine leukemia virus-induced tumor monocyte/macrophage). The Vero cells (control) was normal kidney cell line fromCercopithecus aethiops.\n\nAll cell lines were obtained from the American Type Culture Collection (ATCC; Manassas, VA, USA). They were cultured in minimum essential medium (MEM) (Sigma) supplemented with 10% heat-inactivated fetal bovine serum (FBS) (Gibco), 0.01 bovine insulin, 100 U/ml penicillin and 100 µg/ml streptomycin. The medium was sterilized by passing through a 0.22 µm filter and stored at 4°C until use. The cells were maintained in a humidified incubator with 5% CO2and 95% air at 37°C as described previously [40]. Cell viability was determined by the MTT assay (Sigma 1350380). Briefly, 10 µl of MTT solution (5 mg/ml in phosphate-buffered saline) was added to each well, and the plates were incubated at 37°C for 2 h. The formazan crystals were dissolved in 100 µl of dimethyl sulfoxide (DMSO), and the absorbance was measured at 590 nm.\n\nThe hydrophobic fractions of the <3 kDa native peptide were analyzed using an Ultimate 3000 Nano/Capillary LC System (Thermo Scientific, UK) coupled to a Hybrid Quadrupole Q-Tof Impact II™ mass spectrometer (Bruker Daltonics) equipped with a nanocapture spray ion source. The 100 ng of each sample was loaded onto a µ-Precolumn C18 Pepmap (300 µm i.d. x 5 mm, 5 µm, 100 Å) and separated on a nanoViper Acclaim PepMap RSLC C18 column (75 μm I.D. × 15 cm, 2 μm, 100 Å) at 60°C. A 30-min linear gradient of 5–55% mobile phase B (0.1% formic acid in 80% acetonitrile) in mobile phase A (0.1% formic acid in water) was applied at 0.30 μL/min. Mass spectra (MS) and tandem mass spectra (MS/MS) were acquired in positive-ion mode (m/z 150–2200) at 2 Hz with 1.6 kV electrospray ionization voltage and ~50 L/h nitrogen drying gas flow. Collision energy was 10 eV (m/z-dependent), and nitrogen was the collision gas for CID. Analyses were performed in triplicate. The amino acid sequence of each peptide in individual samples was determined using MaxQuant 2.1.0.0 and the UniProtVaranus salvatordatabase [41]. Then the peptide sequences were studiedin silico.\n\nThe FASTA files of 432V. salvatorpeptides were submitted to the web server Anti-Cancer Peptide and Anti-Hypertensive Peptide Prediction (ACHP athttp://118.178.58.31:9801/). The ACHP algorithm includes three algorithms, namely, support vector machine (SVM), K-nearest neighbor (KNN) and random forest (RF), to train the model, and redundant features are removed using a support vector machine based on the recursive feature elimination method (SVM-RFE). The predicted functional peptides were classified as anticancer peptide (ACP) or antihypertensive peptide (AHP) [42].The various physicochemical properties, such as molecular weight, isoelectric point (pI), hydrophobicity, and hydrophilicity, were also calculated using thehttps://web.ExPASy.org/cgi-bin/compute_pi/pi_tooland Peptide2.com for the Peptide Hydrophobicity/Hydrophilicity Analysis Tool (https://www.peptide2.com/). Some selected peptides were modeled using the PEP-FOLD Peptide Structure Prediction Server (https://bioserv.rpbs.univ-paris-diderot.fr/services/PEP-FOLD3/) followed by PyMOL (https://pymol.org/) for 3D structure visualization.\n\nAllVaranus salvatorserum samples in this study were obtained from randomized animals of different sexes, ages and sizes (n=21). The data were checked for a normal distribution and homogeneity of variance. Therefore, nonparametric statistical analysis should be appropriate for this experimental design, in which the central tendency of the dependent variables is presented as medians. The median inhibition values of freely distributed continuous variables between peptides and protein hydrolysate, as well as between the C18-bound fraction (hydrophobic) and the C18-unbound fraction (hydrophilic), were compared using the Wilcoxon rank-sum test. For the continuous variables, a one-sample t test was used to compare the inhibition mean values with a hypothetical cutoff value (k = 70). PASW Statistics for Windows, version 18.0 [43] was used for all analyses. A p value < 0.05 was considered to indicate statistical significance.\n\nNative peptides and protein hydrolysates derived from Varanus serum produced some results on tested cell lines. The 16 out of 18 cell lines, including A375, CaCO2, CAL27, HaCaT, HeLa, HT29, HepG2, KATO III, MCF-7, MDA-MB-231, MRC5, Raw264.7, SKOV-3, SW620, T47D and U937 cells, were inhibited but Vero cells (control) were less inhibited. However, NCI-H460 and HCT8 were not affected (Table 1). The inhibitory effects of native peptides derived from the serum of 21Varanus salvatorstrains on 18 types of culture cell lines and Vero cells (control) are shown inS1 Table.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321531.t001\n\nThe protein hydrolysates produce a slightly inhibitory effect on CaCO2, CAL27 and SKOV-3 cells. Nine tested cell lines had got 0% inhibition and Vero cells (control) were less inhibited (Table 1). The inhibitory effects of protein hydrolysates derived from the serum of 21Varanus salvatorstrains on 18 types of culture cell lines and Vero cells (control) are shown inS2 Table.\n\nExcept for NCI-H460 and HCT8 cells, which were unaffected by native peptides and protein hydrolysates, native peptides had a significantly greater inhibitory effect on 17 culture cell lines than protein hydrolysates (p value = 0.00) (Table 1).\n\nWhen the inhibition-mean values were compared with a hypothetical cutoff value (k = 70), the Varanus serum peptides were found to be highly effective against 8 of the 18 culture cell lines (CaCO2, CAL27, HaCaT, HT29, HepG2, MCF-7, MRC5, U937) at this threshold (Fig 1).\n\nThe mean inhibition ± SE are presented in addition to the data distribution. The mean inhibition values, which are represented by graphical gray boxes, were significantly greater than or within the inhibition threshold (one sample t test, p value < 0.05).\n\nThe mean inhibition ± SE are presented in addition to the data distribution. The mean inhibition values, which are represented by graphical gray boxes, were significantly greater than or within the inhibition threshold (one sample t test, p value < 0.05).\n\nhttps://doi.org/10.1371/journal.pone.0321531.g001\n\nNative peptides exhibited greater anticancer activity than protein hydrolysates and were subsequently fractionated by stepwise reverse-phase column chromatography. The anticancer activities of the C18 bound fraction (hydrophobic) and C18 unbound fraction (hydrophilic) are presented inTable 2,S3 Table, andS4 Table. Most of the hydrophilic fractions (C18 unbound) had greater inhibitory effects than the hydrophobic fractions (C18 bound) on the culture cell lines.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321531.t002\n\nThe prediction of ACHP activity indicated that 159 out of 432 Varanus peptides exhibited potential anticancer efficacy, with probabilities ranging from 86.92% to 50.10%. Notably, one-fourth of these ACPs had a probability exceeding 70%. The top 20 ranked ACPs are listed inTable 3, while their structural representations are shown inFig 2. Most peptides consisted of 20 or more residues, except for MQLSDNFTKIMLTT, which contained 14 residues. However, peptide length did not influence their secondary structure. The majority of these peptides had low isoelectric points (pIs), with the exception of PLFQKWLLHMLQDYRFRPYSARIW (10.27), GSTDKSPWCATTSNYDRKWKPCA (8.82), ATWQKMAPMALLLATWNLIPT (8.8), FGFKFYNRENFWSQIGSSWT (8.59), and AAIMNWKLCAQLAAFCWGSSFM (8.1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321531.t003\n\nThe predicted peptides were divided into two conformations: a random coil (blue alphabet amino acid sequence) or an α-helix (red alphabet amino acid sequence).\n\nThe predicted peptides were divided into two conformations: a random coil (blue alphabet amino acid sequence) or an α-helix (red alphabet amino acid sequence).\n\nhttps://doi.org/10.1371/journal.pone.0321531.g002\n\nVaranus salvator, an Asian water monitor adapted to harsh environments and known to contain bioactive serum components. This study investigated the in vitro anticancer effects of <3 kDa fractions derived from native peptides and protein hydrolysate ofV. salvatorserum. Small peptides obtained fromV. salvatorserum demonstrated greater anticancer potential than protein hydrolysates. Hence, the peptides were purified and studiedin vitro. Compared to those of the C18 Bound fraction, the Unbound fractions exhibited superior efficacy against cancer cell growth. These findings imply that the physicochemical properties of these peptides play roles in anticancer peptide mechanisms [44–49]. However, Unbound fractions show toxicity to Vero cells in this experiment.\n\nTo search as much as possibility, the peptide sequences from LC-MS analysis were screeningin silico. Based on the calculations, several ACPs exhibited high hydrophobicity. These findings might be associated with ACP-cell membrane interactions as well as cell penetration. The predicted ACPs exhibited higher hydrophobicity, whereas the native peptides were hydrophilic. However, some ACPs are hydrophilic or positively charged and might interact well with glycans and the hydrophilic side of phospholipid bilayers on the cell surface, allowing them to more easily penetrate into the cell. Therefore, we plan to synthesize and modify the selected peptides and conductin vitroin further studies. Moreover, our ACPs had α-helical or random coil structures, similar to the findings of previous studies [49] (Fig 2). These highly flexible secondary structures might assist in cell entry of ACPs and consequently enhance their anticancer properties. This finding is consistent with previous studies on positively charged antimicrobial proteins called cationic antimicrobial peptides (CAMPs) derived from Komodo dragon (Varanus komodoensis) serum [36].\n\nFrom this experiment, the native peptides derived from Varanus serum show highly evidence against colorectal adenocarcinoma, squamous cell carcinoma, hepatocellular carcinoma, mammary gland/breast adenocarcinoma and histiocytic lymphoma. However, the mechanism of action is still unknown. The anticancer peptide mechanisms might be classified based on the mechanism of cell entry or their actions. Pore-forming peptides, cell-penetrating peptides, or tumor-targeting peptides could be useful [44]. The ACPs are divided into three types according to their actions: 1) molecular targeted peptides, 2) ‘guiding missile’ peptides or binding peptides, and 3) cell-stimulating peptides [49]. Moreover, two mechanisms of action of ACP models have been proposed: i) the ‘barrel-stave’ model proposed by Ehrenstein and Lecar in 1977 and ii) the ‘carpet’ model proposed by Pounyet al. in 1992 [48]. Taken together, the efficacy of these anticancer peptides seems to rely on their intrinsic and extrinsic factors, such as their secondary structure, mode of action against cancer cells, physicochemical properties, and cell entry capacity. Future prospects, additional studies of the ACP candidates and their modifications will improve their anticancer efficiency and should focus on the underlying mechanism and clinical application of ACPs.\n\nIn conclusion, native peptides derived from Asian water monitor (Varanus salvator) serum seem to have high anticancer potential for many cancer cells, such as those of colorectal adenocarcinoma, squamous cell carcinoma, hepatocellular carcinoma, mammary gland/breast adenocarcinoma and histiocytic lymphoma. Twenty potential anticancer peptides (ACPs) were identified with a high ACP ranking (more than 75%). The next step is to synthesize these peptides and subsequently study themin vitroto identify the most effective ACPs. Further modifications may be required to enhance the anticancer efficacy and reduce toxicity to Vero cells. This study serves as a starting point for the future development of novel anticancer drugs derived from Varanus serum peptides.\n\nhttps://doi.org/10.1371/journal.pone.0321531.s001\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321531.s002\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321531.s003\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321531.s004\n\n(PDF)\n\nThe author would like to thank Mr. Pakpoom Aramsirirujiwet for sampling assistance at Khao-zon Wildlife Breeding Station and the Department of National Park Wildlife and Plant Conservation for providing various facilities.",
    "category": "oncology"
  },
  {
    "title": "Temporal effect of docetaxel on bone quality in a rodent model of vertebral metastases",
    "authors": "Margarete K. Akens, Mohammedayaz Rangrez, Allison Tolgyesi, Thomas L. Willett, Cari M. Whyne, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0320134",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320134",
    "content": "This study investigates the effects of the anticancer drug docetaxel (DTX) and its timing of administration on tumor development and resultant bone quality in a rodent model, considering both healthy animals and those with osteolytic bone metastases secondary to intra-cardiac injection (d0) of HeLa cells. Healthy and tumor-bearing rats were treated with DTX on d7 or d14 and compared to the control (no treatment) and an additional cohort treated with Zoledronic acid (ZOL). Notably, DTX administration on d7 markedly curtailed tumor growth, as evidenced by bioluminescence and histological analysis, indicating its effectiveness in reducing bone metastases. Bone metastases were more established in animals treated with later DTX administration and ZOL, but still reduced compared to no treatment. When considering bone quality, we found that both the organic and mineral phases of bone are impacted by DTX treatment. Tumor-bearing animals exhibited decreased hydroxyproline/proline ratios reflecting change in collagen metabolism compared to healthy controls, but these decreases were only significant with no treatment or DTX administration on d14. This suggests a positive impact of early DTX treatment similar to ZOL on bone quality from an organic perspective. As well, increased CaMean and CaPeak reflecting the degree of calcification was found in healthy rats treated early with DTX, similar to that seen with ZOL compared to the tumor-bearing treated groups. Overall, early docetaxel administration reduced tumor formation and improved bone quality, suggesting its potential benefit in managing bone metastases.\n\nCitation:Akens MK, Rangrez M, Tolgyesi A, Willett TL, Whyne CM (2025) Temporal effect of docetaxel on bone quality in a rodent model of vertebral metastases. PLoS ONE 20(4):\n           e0320134.\n        \n        https://doi.org/10.1371/journal.pone.0320134\n\nEditor:Lu Zhang,, Shanghai Jiaotong University: Shanghai Jiao Tong University, CHINA\n\nReceived:July 17, 2024;Accepted:February 14, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Akens et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data files have been uploaded to University of Toronto Dataverse (Akens, Margarete, 2025, \"Data files to manuscript 'Temporal Effect of Docetaxel on Bone Quality in a Rodent Model of Vertebral Metastases'\",https://doi.org/10.5683/SP3/MTHK1O, Borealis, V1).\n\nFunding:The Canadian Institutes of Health Research (CIHR) (#156175) provided funding. Principal Investigator: Cari Whynehttps://cihr-irsc.gc.ca/e/193.htmlThe sponsor did not play any role.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nSpinal metastases occur at high frequency in advanced prostate (90%), breast (75%), lung (45%), and renal (30%) cancer [1]. It can present as bone-destructive (osteolytic), bone-generating (osteoblastic), or a combination of both [2]. Osteolytic lesions are initiated by the interaction of the tumor cells with the bone matrix. It leads to activating the TGFß – PTHrP axis, stimulating osteoclast activity via RANKL[2]. Increased bone resorption leads to decreased bone mass and the weakening of trabecular structures, resulting in skeletal-related events in patients, such as fractures. Treatment outcomes and patient survival vary greatly depending on the progression of the metastases, with poor outcomes in advanced stages [3]. Advancing therapies that target spinal metastases requires understanding both effects on tumors and remaining bone quality. Systemic treatments include osteoclast inhibitors and chemotherapy to kill tumor cells [4].\n\nTaxanes (paclitaxel and docetaxel) are a group of chemotherapeutic agents that inhibit microtubule functioning, leading to altered mitosis and cell death. Docetaxel, a second-generation taxane, is an antimitotic drug interfering with microtubulin assembly by stabilizing polymers against depolymeriztion, causing cell cycle arrest in the G2 phase and increasing apoptosis [5]. Docetaxel is widely used for a range of malignancies, including lung, breast, prostate cancers and bone metastases [4,6]. Taxanes generally activate mitogen-activated protein kinases (MAPKs) and cyclooxygenase-2 mRNA expression, increasing prostaglandin E2 (PGE2) production [7] and indirectly activating osteoclasts. However, taxanes inhibit osteoclast activation more than PGE2 indirect activation [8] affecting ruffled border formation and resorption vesicle transport, thus inhibiting bone resorption [9,10]\n\nBisphosphonates, drugs that impede bone resorption by osteoclasts, are classified into two main types: non-nitrogen-containing (simple) and nitrogen-containing bisphosphonates. The latter, including risedronate and zoledronic acid, contain nitrogen in its heterocyclic ring structure. These nitrogen-containing bisphosphonates inhibit farnesylpyrophosphate (FPP) synthase in the mevalonate pathway. Zoledronic acid is over 10,000 times more potent than simple bisphosphonate etidronate [11,12], making it a widely used treatment for spinal metastases [13].\n\nWhile preclinical and clinical studies show docetaxel’s impact on cancer treatment and bone metastases, little attention has been given to its effects on bone quality. These effects should be considered in the context of bisphosphonates, which are widely used clinically. Bone-tumor interaction differs during early and advanced metastasis stages. This study will evaluate docetaxel’s impact on bone quality in early and advanced osteolytic bone metastases using an in vivo preclinical model and compare its effects on bone and tumor to bisphosphonate treatment.\n\nIn compliance with ethical standards, all animal studies were performed with institutional approval (University Health Network, Toronto, Canada; AUP 6044) and ARRIVE guidelines were followed. The animal protocol outlines humane endpoints, which include 20% weight loss and decreased overall well-being accessed by reduced grooming, lethargy, and hunched posture, among others. Five to six-week-old female Hsd:RHFoxn1rnurats (Envigo, Indianapolis, IN, USA) weighing 100±10gm were injected intra-cardiac with 1.8x106HeLa cells in 200µl medium under general inhalation anaesthesia (2% isoflurane in oxygen at 1.5l/min) on d0 [14,15]. The HeLa cells (originally mislabeled as MT-1 cells) were obtained from Dr. Engebraaten, Oslo, Norway [16]. Sixty-three rats were randomly allocated to tumor injection, control, and treatment groups (Table 1). Docetaxel Injection USP 10 mg/ml (Pfizer, Kirkland, QC, Canada) was diluted 10 times with 0.9%NaCl before the injection into the rat tail vein at 5mg/kg on d7 or d14. Zoledronic acid (Zometa®, Novartis, Montreal, QC, Canada) was injected subcutaneously in a single dose at 60µg/kg diluted in 0.9%NaCl on d7. Rats were anesthetized for all procedures (intracardiac injection, bioluminescence imaging, intravenous injections) and received analgesics after cell injection (Metacam®, Boehringer Ingelheim, Burlington, ON, Canada; 2mg/kg subcutaneously). They were monitored daily for food and water intake, overall well-being, and weighted weekly.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320134.t001\n\nBioluminescentin vivoimaging was performed on d14 and d21 post-tumor cell injection to visualize the establishment of metastases and treatment effects (Fig 1(A-D)). Luciferin (XenoLight D-Luciferin, PerkinElmer, Woodbridge, ON, Canada) was dissolved in 0.9%NaCl (40mg/ml) and injected intraperitoneally at 90mg/kg. Thirteen minutes post-injection, the bioluminescent signal was acquired using a Xenogen IVIS 200 Imaging System (PerkinElmer) and analyzed with Living Image®analysis software (PerkinElmer). A region of interest was drawn around the thoracolumbar spine, and results were expressed as photon/second/square cm per steradian (p/s/cm²/sr).\n\n(a: tumor, no treatment;b:TDTX d7;c:TDTX d14;d:TZOL d7). The tumour burden in theTDTX d7 rat is so low that a signal could not be detected (note: in addition, the black skin underneath the black hair blocks photons from being detectable(d)). Backscatter electron microscopy images of the bone (e: tumor, no treatment;f:TDTX d7;g:TDTX d14;h:TZOL d7). TheTDTX d7 (f) bone shows the highest Ca distribution (CaWidth) variation reflected by the shades of gray. However, no statistically significant difference was found between the other groups.\n\n(a: tumor, no treatment;b:TDTX d7;c:TDTX d14;d:TZOL d7). The tumour burden in theTDTX d7 rat is so low that a signal could not be detected (note: in addition, the black skin underneath the black hair blocks photons from being detectable(d)). Backscatter electron microscopy images of the bone (e: tumor, no treatment;f:TDTX d7;g:TDTX d14;h:TZOL d7). TheTDTX d7 (f) bone shows the highest Ca distribution (CaWidth) variation reflected by the shades of gray. However, no statistically significant difference was found between the other groups.\n\nhttps://doi.org/10.1371/journal.pone.0320134.g001\n\nAnimals were sacrificed on d21 by CO2asphyxiation. Thoracic vertebrae 11 (T11) and lumbar vertebrae (L5) were fixed in 10% buffered formalin for histological analyses and backscatter electron microscopy (BSE). Motion segments from T13 to L4 were frozen at -20°C for µCT imaging and microstructural analyses. L4 was used for high-performance liquid chromatography (HPLC).\n\nAs described in [17], excised T13–L4 segments were µCT scanned adjacent to hydroxyapatite (HA) calibration phantoms (µCT-100, Scanco Medical AG, Bruettisellen, Switzerland; Scan Parameters: 55kVp, 200μA, 11W, 34.9μm resolution). Trabecular bone within L2 vertebra was segmented using a validated semi-automated algorithm (AmiraDev 5.2.2; TGS, Berlin, Germany) [18]. The following structural parameters were analyzed from the vertebrae: Trabecular bone volume ratio (bone volume/total volume, BV/TV); %), Trabecular number (TbN; #/mm2), Trabecular spacing (TbS; µm), and Trabecular thickness (TbTh; µm), Trabecular volumetric bone mineral density (BMD; mg hydroxyapatite (HA)/cm3calculated based on a HA phantom) and trabecular tissue mineral density (TMD; mg/cm3).\n\nFormalin fixed vertebrae were cut sagittal into two halves. One half was decalcified in 10% EDTA, and the other was embedded in resin for BSE analyses. Five-micron sagittal sections were stained with hematoxylin and eosin (H&E) to evaluate cell and tissue morphology. Human cytokeratin antibody staining the HeLa cell was used to evaluate tumor burden (Anti-wide spectrum Cytokeratin antibody (ab9377), Abcam, Waltham, MA) using HALO®Image Analysis Platform (indica labs, Albuquerque, NM) and expressed in the % positively stained area of the analyzed section.\n\nHPLC measured mature lysyl oxidase-catalyzed collagen crosslinking in the L4 vertebrae tissue [15,19,20]. Briefly, all soft tissue was removed by blunt dissection and the L4 vertebrae were subjected to papain digestion to remove residual soft tissues. Samples were defatted and hydrolyzed with 11M HCl for 24hours at 110°C. The solution was diluted and added to a buffer with 10% acetonitrile, 1% HFBA, water, and an internal standard (pyridoxine). Pyridinoline, deoxy-pyridinoline, and pentosidine were quantified against standards of pentosidine (PolyPeptide Group, Strasbourg, France) and pyridinoline (Qiagen, Hilden, Germany). Agilent Zorbax Eclipse XDB-C18 Reversed-Phase C18 HPLC columns were used (150X4.6mm, 5mm particle size, 80Å pore size, end-capped; Agilent Technologies, Mississauga, Canada). The mobile phase included buffer A: 26%methanol + 0.1%HFBA, buffer B: 85%acetonitrile + 0.1%HFBA, and buffer C: 38%methanol + 0.08%HFBA, run at different elution times (A: 0–18min, 40–50min, B: 18–30min, C: 30–40min).\n\nA separate HPLC method using a column of the same type measured collagen content via hydroxyproline quantification using hydroxyproline and amino acid standards (Sigma Aldrich, St. Louis, MI, USA). Samples were diluted with borate buffer with homoarginine (internal standard) and derivatized via the cycled addition of fluorenylmethyloxycarbonyl chloride (FMOC-Cl) + acetone, pentane, and extraction of the waste top layer. An elution profile measuring fluorescence versus elution time was obtained for each sample run. The areas under the peaks were measured and compared to a standard curve to calculate the concentration of each crosslink and the amino acids, hydroxyproline and proline. Crosslink concentration was normalized to collagen content and the extent of proline hydroxylation was determined by the hydroxyproline/proline ratio.\n\nQuantitative BSE (qBSE) imaging was used to measure the distribution of calcium in bone tissue, indicative of mineral content. One-half of each L5 vertebrae (preserved in 10% buffered formalin solution) was subjected to sequential dehydration (acetone concentrations of 70%, 90%, 100%) and embedded in Spurr’s epoxy resin. The vertebrae were halved, and the surface microtomed and polished (paper grades of 400, 600 and 1200 grit size and diamond suspensions of 6 and 1µm). After carbon-coating the polished surface of each block, BSE microscopy was performed using a scanning electron microscope (SS BSE detector, FEI, Hillsboro, Oregon, US and FEI/Philips XL30, FEI, Hillsboro, Oregon, US). BSE grey levels were converted to calcium weight percentage [21,22] (Fig 1(E-H).\n\nData with normal distribution were analyzed using a one-way ANOVA with Šídák’s multiple comparisons (GraphPad Prism, GraphPad Software San Diego, CA, USA). Data from bioluminescence and histological analyses were unequally distributed and analyzed using Kruskal-Wallis with Dunn’s multiple comparison test. The level of significance was set at p<0.05.\n\nTumor cell injection was generally well tolerated in 60 rats. One rat in each of the three tumor cell injected groups died before the experiment’s end (T-DTX d7: died 7d post tumor cell injection of unknown cause, T-DTX d14: died 13d post tumor cell injection of tumor development in the heart, and T-untreated: died after the injection with a wrongly diluted analgesic). Weight changes depended on tumor cell injection, tumor burden, and treatment time-point. The highest weight gain (36±5.2g) occurred in healthy untreated rats between d7 and d14 (2nd week), slowing to 9±4.4g between d14 and d21 (3rd week). Tumor-injected untreated rats gained 20±2.4g in the second week and lost 23±8.3g in the third week. Notably, docetaxel injection caused a reduced weight change within one week of injection (Table 2). Increasing tumor burden negatively influenced weight changes.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320134.t002\n\nTumor development was confirmed in 88.2% of the injected rats. A high photon count within the ROI, indicating tumor development in the spine, was observed in 9/10 rats in the T untreated group (median: 1.29E+07p/s/cm²/sr). A very low photon count (median: 3.70E+03p/s/cm²/sr) was measured in the T DTX d7 group in 8/9 rats, suggesting limited tumor involvement and lower tumor burden compared to the T untreated tumor group (p≤0.01). A medium-high photon count (median: 1.48E+06p/s/cm²/sr) in 7/8 rats was seen in the T DTX d14 group, suggesting less tumor suppression with later DTX administration. In the T ZOL d7 group, high photon counts (median: 5.08E+06p/s/cm²/sr) were seen in 6/7 rats.\n\nIn the histological evaluation of the T9 and L5 vertebrae, tumor cells occupied a median of 39.4% (range: 0–57.7%) of the analyzed area in the T untreated tumor-bearing control group. In contrast, only a few tumor cells were found in the T DTX d7 group (median: 0.2%, range 0.0–1.7%). Tumor cells occupied a median of 7.3% (range 0–41.8%) in the T DTX d14 group and 24% (range: 0–46%) in the T ZOL d7 group (Fig 2). These findings align with the bioluminescent imaging results. Tumor burden varied widely between vertebrae, and only two vertebrae per rat underwent histological analyses. Significant differences were found between the T untreated and T DTX d7 groups (p=0.0053) and the T untreated and T ZOL d7 group (p=0.0152).\n\n(a,b: tumor, no treatment; c,d,e,f:TDTX d7; g,h:TDTX d14; i,j:TZOL d7).\n\n(a,b: tumor, no treatment; c,d,e,f:TDTX d7; g,h:TDTX d14; i,j:TZOL d7).\n\nhttps://doi.org/10.1371/journal.pone.0320134.g002\n\nThe hydroxyproline/proline ratio was significantly higher in H untreated rats vs. H DTX d7 (9%; p=0.0001) and H ZOL d7 (8%; p=0.0005) (Fig 3). This ratio was consistently higher in healthy rats than tumor-injected counterparts, with significant differences in the untreated and DTX d14 groups (7.9% and 11.2%, respectively). A significant decrease was also seen in tumor-bearing animals comparing T untreated to T DTX d14 (5.2%). Compared to the bone of healthy rats (H untreated), significant increases in hydroxyproline and proline concentrations were observed in the T untreated group indicating a change in collagen metabolism (note: increases in hydroxyproline (significant) and proline (not significant) with the presence of tumors were previously reported [15]). In contrast, hydroxyproline and proline concentrations were significantly lower in the bone of the T DTX d14 group compared to H DTX d14 (44% and 46%, respectively). A significant effect was seen only in Pentosidine (Pen) concentration when comparing the healthy and tumor groups receiving zoledronic acid treatment, where much higher pentosidine levels were observed in T ZOL d7 compared to H ZOL d7 (~400% increase).\n\nSignificant differences between healthy and treated rats were also observed in the d14 DTX groups. In addition, healthy animals treated on d7 with either DTX or ZOL had a significantly lower ratio compared to healthy, untreated rats.\n\nSignificant differences between healthy and treated rats were also observed in the d14 DTX groups. In addition, healthy animals treated on d7 with either DTX or ZOL had a significantly lower ratio compared to healthy, untreated rats.\n\nhttps://doi.org/10.1371/journal.pone.0320134.g003\n\nCaMean measurements, representing the average degree of mineralization, increased in healthy animals with zoledronic acid delivery (H ZOL d7 vs. H untreated, 26.5%; p=0.021). A trend of increased mineralization was also observed with DTX on d7 (H DTX d7 vs. H untreated, 20%; p=0.084), but no effect was seen with DTX on d14 (H DTX d14, p=0.99). CaMean significantly decreased in T ZOL d7 vs. H ZOL d7 (21.2%; p=0.0036) and T DTX d7 vs. H DTX d7 (19.7%; p=0.019).CaPeak, the highest calcium content, increased in H ZOL d7 compared to H untreated rats by 31.8% (p=0.0057). D7 treatment groups showed lower CaPeak in tumor-bearing animals (H DTX d7 vs. T DTX d7, 17.8%; p=0.036 and H ZOL d7 vs. T ZOL d7, 23.9%; p=0.0057), but no differences were seen in untreated or d14 treated groups. CaWidth, the measurement of Ca content heterogeneity, showed no significant differences among groups. CaMean, CaPeak and CaWidth were not significantly affected by the treatments when comparing untreated tumor-bearing animals to tumor-bearing treated rats.\n\nIn addition to microstructural differences reported in [17], this analysis focused on changes specific to docetaxel. We previously reported changes with ZOL treatment in tumor bearing vertebrae with significant increases in BV/TV, TbN and BMD and lower TbS compared to T untreated animals [17]. TMD was significantly higher in T DTX d7 vs. T untreated (12.2%). No other TMD differences were significant. BMD followed the TMD results, except T ZOL d7 had significantly higher BMD than T untreated (27.0%). BV/TV decreased with the establishment of osteolytic tumor. Higher BV/TV was observed in T DTX d7 (8.3%) vs. T untreated. TbN was higher in T DTX on d7 (9.7%) and d14 (11.1%) compared to T untreated. TbS decreased in T DTX d7 (15.1%) and d14 (13.2%) compared to T untreated. No significant TbS differences were found between healthy and tumor-injected animals treated with DTX at d7 or d14. TbTh decreased in T DTX d14 vs. H DTX d14 (5.0%) and untreated tumor group (6.1%). No differences were found comparing healthy DTX d7 or d14 groups with their tumor-injected counterparts. As reported [17], no morphological parameter differences among healthy animals were found across docetaxel treatment groups.\n\nDocetaxel is often administered to patients with bone metastases. This study evaluated the effect of DTX on healthy rats and those with osteolytic metastases. The impact of DTX was further compared to the bisphosphonate Zoledronic acid, which is also widely used in patients with bone metastases. Docetaxel injection reduced weight gain in all treated rats—healthy and tumor-injected—for ~7 days post-injection. After this period, their weight changes re-aligned with their respective groups (healthy or tumor-bearing). This may be due to taxane-induced arthralgia and myalgia, typical side effects of docetaxel and paclitaxel in human patients [23]. Docetaxel stabilizes microtubules in cancer cells but also disrupts axonal transport in nerve cells, causing inflammation and oxidative stress [24]. It also increases COX2 expression, leading to higher prostaglandin E2 (PGE2) levels, which cause pain [7]. PGE2 interacts with osteoblasts and osteoclasts, either promoting bone formation via BMP2 activation or increasing resorption with increased osteoclast differentiation [7].\n\nTumor development, confirmed by bioluminescence, varied based on treatment type and timing post-inoculation. Photon counts, indicative of tumor size, were lowest in the T DTX d7 group, increased in the T DTX d14 and T ZOL d7 groups, and were highest in the untreated group. Histology confirmed these results. While these findings suggest early docetaxel treatment (d7) reduces bone metastases, a local tumor injection study (Luc CaP 23.1 injected into the tibia) found that higher and more frequent DTX doses showed no antitumor effect [25]. This difference may arise from immediate tumor establishment due to the local route of administration. Docetaxel given later (d14) had limited impact, indicating the importance of early treatment. Similarly, only a limited impact on tumor burden was seen with ZOL.\n\nMicrostructural parameters were influenced by tumor burden and treatment, as shown by Tolgyesi et al. [17]. In the T DTX d7 group, reduced tumor burden led to higher TMD, BMD, BV/TV, TbN, and TbTh (with lower TbS) in tumor-injected rats. Although the T DTX d14 group had more tumors than the T DTX d7 group, the tumor burden was lower than in untreated rats, resulting in higher TbN and lower TbS, but the trabeculae were thinner (lower TbTh). This indicates ongoing but slower degradation in the T DTX d14 group compared to untreated tumor-bearing animals.\n\nCollagen changes in the bone due to treatment and tumor burden were assessed using HPLC [26]. The hydroxyproline/proline ratio was lower in all tumor-cell injected groups than in healthy controls, with significant decreases in untreated and DTX d14 cohorts. This contrasts with earlier findings of a slight (~6%) increase in this ratio in untreated samples with osteolytic tumors [15]. An increased rate of remodelling typically increases the hydroxyproline/proline ratio, only observed in the T untreated and T DTX d7 groups. The results indicate that DTX and ZOL treatments affect collagen metabolism. Like Olejnik et al., we found a decreased hydroxyproline/proline ratio in healthy rats treated with ZOL, possibly due to reduced proline hydroxylation [27]. ZOL’s effect on osteoblasts may involve post-translational modification of collagen, separate from its osteoclast inhibition. DTX influences the tumor microenvironment and upregulates the MMP1 gene, increasing collagenolytic MMPs [28,29]. In healthy animals, the hydroxyproline/proline ratio decreased with DTX on d7 but not on d14, suggesting a transient effect on MMP1 upregulation. Oxidative stress raises pentosidine (an advanced glycation end product (AGE)) levels, a negative bone quality marker released during high turnover. Pentosidine is a non-enzymatic cross-link that forms between adjacent collagen type I molecules [30]. ZOL inhibits pentosidine release by reducing osteoclast activity in healthy rats, but this effect is diminished by tumor presence due to reduced bone in ZOL-treated rats with osteolytic metastases [17].\n\nThe effects of treatment on hydroxyapatite (Ca5(PO4)3OH), the mineral phase of bone, were assessed using BSE. Increased calcification, indicated by higher CaMean and CaPeak, was observed in rats treated on d7, likely due to DTX and ZOL inhibiting osteoclasts, reducing bone resorption, and increasing calcium deposition [10]. Unlike Olejnik et al., we found significant increases in CaMean and CaPeak in healthy rats treated with ZOL, possibly due to differences in rat age, sex, and dosing regimens [27]. The H DTX d7 and H ZOL d7 groups showed higher CaMean and CaPeak than the H untreated group (significant for ZOL and trending for DTX at p=0.084), while H DTX d14 had similar values to H untreated, suggesting a time-dependent effect on bone remodeling. These differences were not seen in tumor cell-injected animals.\n\nOur ZOL findings, consistent with previous reports, showed its effects on healthy and tumor-bearing bone. BSE analysis in H ZOL d7 rats revealed positive correlations between CaMax, CaMean, CaWidth, and TMD, BMD, TbS, TbTh, and negative correlations with TbN. These correlations were absent in tumor-bearing rats treated with ZOL. Adding to previously reported effects of ZOL on load to failure, microdamage, and tumor burden [17,31], this study showed ZOL’s impact on collagen metabolism and calcium deposition, more pronounced in healthy treated animals than in tumor-bearing ones. Unlike DTX, ZOL treatment did not cause weight changes related to neurological effects.\n\nA limitation of this tumor cell injection model is the short timeframe between tumor establishment and the observation of treatment effects. Tumors take ~14 days to establish, and humane endpoints are reached by d21 post-injection. In addition, we only describe the effects of DTX on bone in rats with osteolytic metastases caused by HeLa cells, not in bone with osteoblastic or mixed metastases or those caused by other cancer cell lines. Initially mislabeled as a breast cancer cell line (MT-1), these HeLa cells reliably produce clinically relevant osteolytic bone lesions [16]. This model allowed us to examine the impact of early (d7) and later (d14) DTX treatment on tumour and osteolytic bone quality. Early DTX treatment reduced tumor development and improved bone properties, but its effectiveness diminished with a higher established tumor burden.\n\nMultiple animal models exist to study vertebral metastases, including mice, rats and rabbits. Rat models provide a good balance between larger animals (rabbits) in which local treatments (such as radiation or thermal ablation) can be more easily applied and mouse models which are limited in the size of tissues available for analysis. The intracardiac injection model provided multiple vertebrae with metastases for analysis using different techniques (i.e., HPLC, BSE, histology). The rat vertebrae are sufficiently sized to enable sagittal cross-sectioning allowing histological analysis and BSE to be performed on adjacent sections. This allows for a reduction in the total number of animals required for study [32].\n\nPrevious research has considered the combination of high-dose ZOL and DTX in the context of a local mouse bone tumor model [25] showing it to be more effective in controlling tumor volume than ZOL or DTX alone. While we evaluated ZOL and DTX at clinically relevant doses in the current study, we did not consider combination treatments. While such combinations are used clinically, this is less common; ZOL is often used prophylactically or in metastatic disease to reduce osteoclast activity and bone loss, whereas DTX is used primarily to treat active disease. ZOL and DTX administration schedules often do not align clinically creating barriers with respect to scheduling and overburdening patients with clinical visits. Future studies may consider potential additive or synergistic effects of DTX and ZOL at clinically relevant doses and under conditions of longer-term administration with aligned dosing schedules.\n\nDTX treatment affects the organic and mineral phases of bone, with the impact varying by treatment timing and tumor burden. Early DTX administration reduces tumor formation and maintains bone quality despite temporary weight loss. While bone quality was improved in animals treated with ZOL delivered at d7, tumor cells remained within the marrow space. Although not as beneficial to bone quality as ZOL, DTX none-the-less reduces osteoclastic activity. This is essential information for patients already at risk of fragility fractures. Later DTX administration provided modest improvements with respect to tumor burden (similar to ZOL) and ongoing but slower degradation of the bone compared to untreated tumor-bearing animals, thus motivating early clinical consideration of DTX administration for maintenance of bone quality as well as tumor management. Overall, this study shows the potential of early DTX treatment on bone quality in the management of patients with or at risk of bone metastases.\n\nhttps://doi.org/10.1371/journal.pone.0320134.s001\n\n(JPG)\n\nThe authors would like to thank the Animal Research Centre (ARC), the Spatio-Temporal Targeting and Amplification of Radiation Response (STTARR) and the Advanced Optical Microscopy Facility (AMOF) for their assistance with the project.",
    "category": "oncology"
  },
  {
    "title": "Assessing gastric cancer risk through longitudinal health check-up data: Insights from a national cohort study in South Korea",
    "authors": "Juwon Park, Do-young Kim, Mina Suh, Yeong-Hwa Kim, Sungho Won, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0312861",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0312861",
    "content": "Gastric cancer (GC) is the fourth most prevalent cancer and a leading cause of cancer-related fatalities in South Korea. Although periodic screening policies are in place, the early detection and prediction of GC remain challenging. This study evaluated the risk of GC incidence by utilizing longitudinal health check-up data from the National Health Insurance Service-Health Screening Cohort spanning from 2009 to 2019. The criteria selected for this study are general health examination candidates aged 40 or older who have been eligible for health insurance since 2009. The exclusion criteria included individuals diagnosed with cancer prior to 2009 or before their examination date, as well as those who did not complete the examination questionnaire. A time-dependent Cox proportional hazards model was employed to analyze the time from health examination to the first GC diagnosis, comparing our results with previous cohort studies that evaluated the GC risk through general check-up parameters. Significant risk factors for GC incidence in both genders were age, high levels of AST and γ-GTP, low levels of ALT and hemoglobin. Among males, dyslipidemia, smoking and physical activities were also significantly associated with GC risk. Although further evidence is needed, low hemoglobin levels emerged as a promising potential risk factor for GC, ascertainable through routine general health check-ups.\n\nCitation:Park J, Kim D-y, Suh M, Kim Y-H, Won S (2025) Assessing gastric cancer risk through longitudinal health check-up data: Insights from a national cohort study in South Korea. PLoS ONE 20(4):\n           e0312861.\n        \n        https://doi.org/10.1371/journal.pone.0312861\n\nEditor:Patricia Khashayar, Gent University, BELGIUM\n\nReceived:March 17, 2024;Accepted:October 14, 2024;Published:April 17, 2025\n\nCopyright:© 2025 Park et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:Data are available from the NHIS (https://nhiss.nhis.or.kr/) for researchers who meet the criteria for access to confidential data. This data cannot be shared publicly due to NHIS regulations. We received approval for data usage following a review by the Institutional Review Board of the affiliated institution, as well as an independent review conducted by the NHIS.\n\nFunding:This work was supported by the National Research Foundation of Korea (NRF) grants funded by the Korean government (MSIT) (RS-2024-00346850, RS-2021-NR060088), and by the Korea Health Technology R&D Project through the Korea Health Industry Development Institute (KHIDI), funded by the Ministry of Health & Welfare, Republic of Korea (RS-2024-00403700).\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nGastric cancer (GC) is a malignant type of upper digestive tumor that originates in the lining of the stomach [1]. In 2020, over a million new cases were diagnosed with GC, with incidence rates approximately twice as high in men compared to women [2]. Those suffering from GC experience a significantly reduced quality of life, marked by digestive disturbances, pain and poor emotional well-being due to its unfavorable prognosis. GC is the fourth leading cause of cancer-related death [3,4]. Moreover, the economic burden of curing GC in the United States (US) was estimated by the National Cancer Institute to be $2.31 billion in 2020 [5].\n\nAccumulating evidence suggests that the causes of GC are multifaceted, including stomach infections, dysbiosis, dietary habits, obesity, smoking, alcohol consumption, and genetic factors [6]. Specifically, infection withHelicobacter pylori(H. pylori) has been primarily considered a leading cause of atrophic gastritis, accounting for over 75% of GC cases [7]. The widespread adoption ofH. pylorieradication treatment in clinical settings has led to a gradual decrease in global GC incidence rates, a trend that is expected to continue [8]. Nevertheless, the high prevalence of GC, particularly in eastern Asia where over 60% of new cases are diagnosed, combined with the challenge of achieving a cure at advanced stages, underscores the need for developing of new strategies for early detection [9].\n\nIn South Korea, adults are entitled to national health check-ups every 2 years, while manual laborers receive these examinations annually [10]. These check-ups typically include a physician’s interview, anthropometry, basic physical examinations, and blood/urine analysis for systemic biomarkers, offering preventive care by managing potential risk factors [11]. Although upper endoscopy is the most accurate method for detecting GC, evidence supporting routine gastroscopy practice is limited, particularly in the absence of symptoms, which often do not appear until the cancer has advanced beyond its early stages [12]. Additionally, the widespread and frequent use of endoscopy across the entire population could lead to a significant societal burden [13]. Therefore, identifying high-risk groups for GC using general information becomes crucial as a preliminary step before proceeding to more invasive endoscopy procedures.\n\nTo facilitate further evidence to GC screening research, we aimed to predict GC incidence and evaluate risk factors using longitudinal health examination data from a nationwide retrospective cohort. Additionally, we conducted a review of cohort studies that have assessed GC risk using general check-up parameters. Studies analyzing GC incidence using data from large-scale general population health check-ups are limited, which hinders direct comparison of our findings with those from previous research.\n\nThe National Health Insurance Service-Health Screening Cohort (NHIS-HEALS) is based on information obtained through the national health screening programs in Korea since 1995. The NHIS has provided biennial health screening (annual for manual workers) aimed at improving the health of Koreans through disease prevention and early detection [14]. The study cohort consists of health insurance subscribers and medical aid recipients as of 2002, who were in the age range of 40 to 79 years old in 2002-2003 and who received general health check-up provided by the National Health Insurance Corporation. The data comprises 514,866 individuals, randomly extracted from those who underwent health check-up, and is considered nationally representative, sampling approximately 10% of the entire Korean population. This dataset contains socioeconomic variables, health resource utilization status, disease type, clinical status and death records. Cohort participants were followed from 2002 until December 31, 2019, with no additional participants enrolled after 2002.\n\nInformation on medical examinations, blood tests, urinalysis, lifestyle check-ups such as cigarette smoking, alcohol consumption, physical activity, history of diseases, and family history of diseases was collected based on self-reported questionnaires. Smoking habits were categorized into non-smokers (individuals who had never smoked, or had smoked less than 100 cigarettes in their lifetime) and ever-smokers (individuals who had smoked in the past and who currently smoke). Alcohol consumption was classified into 3 groups: non-drinking, mild, and heavy drinking groups (defined as males consuming more than 4 drinks per week and females consuming more than 2 drinks per week). Physical activity was stratified into 3 groups based on weekly exercise frequency: non (individuals who do not work out), rare (individuals who rarely do physical activity), and active (individuals who exercise over 5 per week). To select appropriate features for building the development model, features with more than 30% missing values across all cases were removed. Additionally, subjects with missing values or outliers were eliminated from the data. Final input features are presented inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0312861.t001\n\nThe criteria for this study included individuals aged 40 or older from NHIS-HEALS who were eligible for health insurance and had undergone general health examinations since 2009. This year was chosen because major examination guidelines and questionnaire format in Korea were changed due to the reorganization of the health check-up system [14]. For example, variables such as triglyceride, HDL (high density lipoprotein) cholesterol, LDL (low density lipoprotein) cholesterol, creatinine, past daily smoking dose, current daily smoking dose, days of drinking per week, and the amount of drinking per day were collected only after 2009. A total of 461,046 individuals who received health examination after 2009 were selected as health insurance subscribers.\n\nThe exclusion criteria included (1) individuals diagnosed with cancer before 2009, (2) individuals diagnosed with cancer before the examination date or as a result of the examination, and (3) those who did not complete the examination questionnaire. After applying these exclusion criteria, 358,658 individuals remained eligible for the study.\n\nCancer incidence was the primary outcome of this study during the follow-up period following the initial health examination date. GC, identified by the International Classification of Disease 10thedition (ICD-10) code C16, was considered the first cancer detected in either the main or sub-diagnosis. The selection process for study subjects is shown inFig 1. The study population was divided into 2 groups randomly – 70% training and 30% test dataset. The training cohort datasets were used to make a development model and fit the parameters, while the test cohort was used to assess the performance of the final models.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0312861.g001\n\nThis study was approved by the institutional review board in Seoul National University (IRB No. E2309/002-006) and the National Health Information Data Review Committee (NHIS-2023-2-247). The requirement for informed consent was waived since the NHIS-HEALS database is anonymized administrative data.\n\nThe time-to-event was defined as the duration from the health examination date to the date of the first event diagnosis and Cox regression was performed. For individuals with multiple health check-up records, the differences between observations were accounted for using a time-dependent Cox regression model [15]. The variables selected through time-dependent Cox proportional hazard analyses, using backward selection based on AIC, are listed inTables 2and3for males and females, respectively. The general characteristics of the individuals are presented as mean ±  standard deviation for continuous variables, and as numbers (%) for categorical variables. P-values were calculated using Student’s t-test and chi-square test. A prediction model was constructed using the variables that were chosen on the training cohort datasets, and its performance was evaluated using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve, where a higher AUC value indicates a better performance. Time-dependent AUCs were used to summarize predictive accuracy at specific time points, focusing on event occurrence at 1,3,5, and 7 years. All statistical analyses were performed using SAS Enterprise Guide version 7.1 (SAS Inc., Cary, NC), R version 4.3.0 (http://www.r-project.org/) software and Rex version 3.6.1.0 [16].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0312861.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0312861.t003\n\nThe literature survey was conducted across three electronic databases: PubMed, Embase, and Medline, up to January 2024. Search terms included health or health check-up, examination, gastric or stomach cancer, risk, incidence, and cohort. The search was restricted to cohort studies reporting hazard ratios (HR), and only articles in English were considered.\n\nFor literature screening, the following inclusion criteria were applied: (1) cohort studies assessing GC incidence, (2) studies involving the general population, (3) studies reporting HR with statistical analysis, and (4) independent variables comprising general check-up items such as anthropometric measures, physician’s interviews or questionnaires (e.g., medical history, smoking habit and physical activity), as well as blood, urine, and imaging tests [10]. The exclusion criteria included: (1) duplicate or incomplete articles, (2) articles not classified as cohort studies, and (3) studies not focused on evaluating the risk of GC incidence.\n\nData extraction encompassed the country and examination period, participant numbers, recruitment age range, variables used in the multivariate adjusted analysis, and result data from the original articles, including the statistical analyses of HR for GC incidence.\n\nWe assessed the statistical significance of the risk evaluation based on the original articles’ data presentations. The significance of the multivariate adjusted analysis was determined by non-overlapping 95% confidence intervals (CI) for the adjusted HR for GC, with a p-value below 0.05.\n\nThe data of 358,658 individuals were selected after excluding individuals meeting the exclusion criteria. During the study period, 5,618 cases (1.57%) of GC were identified with a median follow-up time of 8.87 years. The individuals were categorized into 2 groups: those with GC and those without GC, at any point during the follow-up period. The study population was divided into 2 groups randomly – 70% training and 30% test dataset. The training cohort comprised 251,061 individuals, among whom 3,920 GC cases were identified (2,816 male and 1,104 female). The test cohort included 1,598 GC cases (1,228 male and 470 female) out of 107,597 individuals. The baseline general characteristics of individuals in both the training and test cohorts are presented inS1andS2 Tables.\n\nIn order to identify the possible risk factors for the incidence of the GC, time-dependent Cox proportional hazard analyses were conducted using backward selection.Tables 2and3present the HR and 95% CI for each of the potential risk factor in males and females respectively.\n\nFor males, significant risk factors for GC included age, high diastolic blood pressure (DBP), low high-density lipoprotein cholesterol (HDL), high triglyceride, low hemoglobin, high aspartate aminotransferase (AST), low alanine transaminase (ALT), high γ-glutamyl transpeptidase (γ-GTP), not having history of dyslipidemia, and having smoking habits. Conversely, being active in physical activities was associated with a reduced risk of GC. The identified significant risk factors for GC in females were age, low hemoglobin, high AST, low ALT and high γ-GTP. Individuals who have family history of hypertension (HTN) showed a decreased risk of developing GC.\n\nUsing the variables selected from the Cox regression model in training cohort, the model was applied to the test cohort.S1andS2 Figs. showed the ROC curves for cancer incidence prediction at 1,3,5, and 7 years for males and females, respectively. The AUC values for prediction years 1,3,5, and 7 were 0.667, 0.666, 0.676, and 0.673 for males, and 0.6, 0.594, 0.599, and 0.596 for females.\n\nA total of 706 initial references were identified from three databases; PubMed, Embase and Medline, 18 articles were included in this review (S3 Fig). With the exception of 3 studies, the majority of the included articles were published after 2010. Half of the total studies were conducted in South Korea (5 articles) and the United States (4 articles), followed by the United Kingdom (UK) and Norway (2 articles each). The number of participants ranged from 18,244 to 6,272,367, and 10 studies (55.6%) recruited only middle-aged and older participants (≥40 years) (Table 4).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0312861.t004\n\nAmong the 18 studies, six categories of independent variables were utilized to assess the risk of GC. Notably, anthropometric data such as body mass index (BMI) and waist circumference (WC) were the most frequently evaluated (11 articles, 61.1%), followed by lifestyle factors (6 articles), blood tests (3 articles), and body composition and reproductive factors (2 articles each).\n\nOf the 11 studies incorporating anthropometric measurements, nine reported statistically significant associations between GC incidence and body characteristics, including BMI [17,19,21,24,29,32], WC [19,21,23,27,29], hip circumference [29], waist-hip ratio (WHR) [20,23], weight, and height [23], in relation to at least one subtype of GC or sex. Lifestyle variables in the included studies encompassed physical activity, salt preference, drinking, and smoking. Statistical significance was observed for smoking [31,34] and salt preference [30], while drinking [31] did not show significance, and inconsistent results were noted for physical activity [26,28,33]. In the context of blood analysis, all studies evaluating glucose metabolism-related markers found significant associations with GC when levels were above [18,27] or below [25] the normal range of blood glucose. Notable attempts of recent studies, published since the 2020s, such as body composition [19,22] and reproductive factors [22,23] did not yield consistent results with statistical significance (Table 4).\n\nThrough this study, we confirmed previously established risk factors for GC, such as age and smoking habits, and identified the potential of basic blood markers, such as liver function tests and hemoglobin levels, as promising risk factors. Given the asymptomatic nature or vague signs of early-stage GC, screening tests have been advocated as a secondary preventive measure, alongside risk management strategies, for early detection [35]. Countries with high prevalence and incidence rate of GC, such as South Korean and Japan, have implemented screening programs since the 2010s [36], which include periodic gastric endoscopy for middle-aged individuals and screening forH. pylori[37,38]. However, the societal burden of widespread screening and increase inH. pylori-negative cases [39,40] highlight the need to improve early detection strategies for GC, emphasizing the importance of effective risk management. This study aimed to assess the efficiency of early detection and prevention of GC by evaluating risk incidence using data from general health check-ups and conducting a comprehensive review of pertinent literatures.\n\nAs expected, the incidence of GC was significantly correlated with aging and was more predominant in males (male 4,044: 1,574 female) during 10-year follow-up period (Tables 2and3,S1andS2 Tables). Similar to other types of cancer, the degeneration of cells due to accumulated stresses, such as oxidative metabolites, is believed to contribute to the development of GC [41]. Occupational environments and smoking habits have shown a high incidence rate in males, which has recently decreased with advancements in industrial medicine and anti-smoking perceptions [42]. While the exact pathophysiology remains unclear, there has been suggestion of a risk-suppressing effect of female hormones on the incidence of GC [43]. According to two studies that evaluated reproductive factors as independent variables in our review, obstetrical history or hormone therapy use failed to consistently demonstrate an association with GC (Table 4). Although one study reported that a history of bilateral ovariectomy and early pregnancy increases the risk of non-cardia gastric cancer (NCGC), hormonal effects on GC incidence remain controversial [23].\n\nObesity and metabolic syndrome have long been recognized as significant risk factors for gastric dysplasia, often associated with an unhealthy diet and lack of exercise [44,45]. A preventive effect of physical activity was shown in male; however, our analysis of cohort data found that neither BMI nor WC demonstrated a significant association with GC development in our cohort (Tables 2and3). Previous cohort studies examining the risk of anthropometry have yielded inconsistent results, varying depending on factors such as gender, GC subtype, and high/low BMI (Table 4). Based on the need for multidimensional approaches, a recent pooled analysis of cohorts in Japan indicated that while there is no clear association between BMI and NCGC, there may be with cardia gastric cancer (CGC) or esophageal cancer [46]. Similarly, recent studies published since the 2020s have attempted to analyze factors such as body composition, persistent obesity, and reproductive factors but have failed to consistently replicate significant results (Table 4).\n\nHyperglycemia, dyslipidemia and HTN are recognized markers of metabolic syndrome [47]. Hypothesized mechanisms linking metabolic syndrome to GC include insulin resistance-related increased insulin-like growth factor-1 availability and obesity-derived chronic inflammation [48]. However, our analysis of cohort data did not find support for an association between a history of DM or HTN and blood glucose levels with GC (Tables 2and3). Additionally, while our review revealed statistical significance regarding glucose levels, they were inconsistently specific to postmenopausal women, low level of fasting, and non-fasting glucose, respectively (Table 4). Similar to BMI, this variability may be attributed to GC subtypes, as it has been observed that DM is not significantly associated with overall GC but is related specifically to CGC [49]. Regarding dyslipidemia, our cohort study exhibited a notable gender-specific pattern, with a significant association observed between HDL and triglycerides in males (Table 2). Although few studies have explored the association between dyslipidemia and GC, some evidence suggests a potential role for triglycerides in the differentiation of the intestinal type of GC, which is the most common subtype and is predominant in males [50].\n\nDue to the functions of organic metabolism and interaction with the microbiome, liver health significantly impacts both eating behaviors and gastrointestinal functions, and vice versa [51]. Our study findings indicate that elevated levels of AST and γ-GTP, along with reduced levels of ALT, are significantly correlated with the risk of GC in both males and females (Tables 2and3). Although the underlying pathophysiology remains incompletely understood, a poorer prognosis of GC was observed in cases where the ALT/AST ratio was ≤  0.80 compared to cases where it was >  0.80 [52]. Similarly, elevated γ-GTP levels have been identified as an unfavorable prognostic factor for liver and genitourinary cancers, as well as for DM and metabolic syndrome [53]. These findings suggest the possibility of a predictive role for liver function test not only in disease progression but also in etiology.\n\nIn our cohort data, a low hemoglobin level was associated with an increased incidence of GC in both genders (Tables 2and3). Pernicious anemia, a rare autoimmune disease targeting gastric parietal cells, is a well-established risk factor for NCGC [54]. However, the association of other causes of anemia with GC remains unclear. Findings from a cohort study conducted in South Korea demonstrated that anemia increases the risk of cancer in the esophagus and stomach [55]. Additionally, one study indirectly supports the role of anemia by showing the preventive effect of total iron intake for GC [56]. These findings suggest that anemia could serve as a potential marker for predicting GC risk, as it is a relatively inexpensive and readily applicable measurement.\n\nOverall, as advancements in prevention and risk management interventions progress, the dynamics and trends of GC, including histological and demographic characteristics, become evident. For instance, a seven-fold increase in the incidence of CGC over recent decades has been attributed to heightened eradication ofH. pylori[6]. Our findings highlight that risk factors for GC incidence are diverse, spanning gender, comorbidities, serum biomarkers, and lifestyles. This diversity underscores the importance of establishing cancer prevention strategies tailored to individual-specific characteristics. Although our AUC data for the prediction of GC may not be directly applicable to disease prediction, we believe the insights gained are invaluable. They serve as a preliminary screening tool to guide endoscopic procedures and support further investigations into GC risk factors (S1andS2 Figs).\n\nThis study has several limitations. First, the dataset lacked information on dietary habits, such as consumption of vegetables, meats, and fried foods, which are known to be related to GC risk. The questionnaire did not contain rigorous data on eating habits. Second, we did not differentiate between GC subtypes, potentially leading to ambiguous outcomes. Third, the generalizability of our predictive results to other ethnic groups remains uncertain. Collaborative efforts involving multicenter research and external validation are imperative for further investigation. Nevertheless, this study holds significance as it comprehensively analyzed health examination questionnaires spanning the entire South Korean population. To our knowledge, studies that have assessed risk factors for GC using health check-up data, especially with blood markers, from large-scale general populations are rare. The strength of our findings lies in demonstrating the potential of basic screening parameters as early indicators before the implementation of confirmatory procedures, such as biopsy or endoscopy, for GC diagnosis.\n\nhttps://doi.org/10.1371/journal.pone.0312861.s001\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0312861.s002\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0312861.s003\n\n(TIF)\n\nhttps://doi.org/10.1371/journal.pone.0312861.s004\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0312861.s005\n\n(DOCX)",
    "category": "oncology"
  },
  {
    "title": "Translation and validation of the Chinese version of EORTC QLQ-SWB32 assessing the spiritual wellbeing of women with gynecological cancer",
    "authors": "Yue Feng, Jiangshan Luo, Tangwei Lin, Xingcan Liu, Xiujing Guo, Jing Chen, Bella Vivat, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321790",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321790",
    "content": "This study aimed to translate the internationally developed and validated European Organization for Research and Treatment of Cancer measure of spiritual wellbeing (EORTC QLQ-SWB32) into Chinese, validate the translation with women with gynecological cancer, and examine associations between demographic variables and the scales of the measure.\n\nThe study followed EORTC translation guidelines. After pilot testing with sixteen gynecological cancer patients, we validated the final measure with another 200 patients. We analyzed reliability using Cronbach’s alpha coefficients. Exploratory factor analysis (EFA), confirmatory factor analysis (CFA), and exploratory graphic analysis (EGA) were used to analyze the construct validity. A multiple linear regression model analyzed the relationship of the factors to spiritual well-being.\n\nCronbach’s alpha coefficients showed good reliability, ranging from 0.885 to 0.907 in each dimension. The EFA (KMO = 0.876, χ2= 2865.036, df = 231,P< 0.001) and EGA produced a four-dimension structure. CFA fit statistics indicated adequate fit to a four-dimension solution (χ2/df = 2.178, RMESA = 0.077, GFI = 0.973, SRMR = 0.057, CFI = 0.915, TLI = 0.902), which matched the dimensions and constituent items from the original measure. Regression analysis indicated that higher education levels correlated with higher scores on the Relationships with Others (RO) and Existential (EX) scales; unemployment with lower Relationship with Self (RS) scores, and lower incomes with lower EX scores; patients with religious beliefs scored higher on Relationship with God (RG).\n\nThe Chinese EORTC QLQ-SWB32 exhibits good reliability and validity among gynecological cancer patients, with dimensions aligning with those found in the original validation. This approved, validated instrument is now available for Chinese medical staff to use to assess the spiritual wellbeing of Chinese cancer patients and help improve understanding of the relevance of spiritual wellbeing to people from Chinese cultural backgrounds.\n\nCitation:Feng Y, Luo J, Lin T, Liu X, Guo X, Chen J, et al.  (2025) Translation and validation of the Chinese version of EORTC QLQ-SWB32 assessing the spiritual wellbeing of women with gynecological cancer. PLoS ONE 20(4):\n           e0321790.\n        \n        https://doi.org/10.1371/journal.pone.0321790\n\nEditor:Boshra A. Arnout, King Khalid University, EGYPT\n\nReceived:September 4, 2024;Accepted:March 11, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Feng et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and itsSupporting Informationfiles. The EORTC QLQ-SWB32 is free for academic use; however, potential users must sign a user agreement with the Group to obtain permission for its use. The agreement and the full content of the Chinese version can be requested through the website:https://qol.eortc.org/questionnaire/qlq-swb32/.\n\nFunding:1. Initials of the authors who received each award: Jing Chen 2. Grant numbers awarded to each author: 21PJ056 3. The full name of each funder: Health Commission of Sichuan Province, China 4. Did the sponsors or funders play any role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript? No.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nGynecological cancers pose serious and potentially fatal risks. In 2020, around 250,000 women in China were newly diagnosed with gynecological cancer [1]. Among these, cervical, ovarian, and endometrial cancers were among the top ten cancers diagnosed in Chinese women [2]. As females with cancer have been reported to be more adversely affected than men [3], it’s vital to help gynecological cancer patients improve their quality of life and mental health.\n\nSpiritual wellbeing (SWB) is an essential dimension of health-related quality of life for cancer patients [4]. It has been defined in various ways, including ‘meaning, wholeness, transcendence, connection, joy, and peace, that does not rely on one’s participation in an organized religion’ [5]. Studies report that SWB correlates with clinically relevant outcomes such as anxiety, depression, end-of-life coping, and physical health [6–8].\n\nThere has been increasing clinical and research interest in SWB in the past decades. Spirituality has been conceptualized as an aspect of quality-of-life and spiritual well-being instruments such as Functional Assessment of Chronic Illness Therapy-Spiritual Well-Being (FACIT-Sp) [9], and Mental, Physical, and Spiritual Well-Being Scale (MPS) [10] have been developed. However, a meta-analysis has argued that spirituality is best seen as a distinct, although related, concept from quality of life [11]. There is as yet no “gold standard” measure of SWB, and some of the most widely used measures have been developed and validated in single cultural contexts, or a religious framework [12–14], so translating and applying these instruments in different cultures may not be simple [15]. It has been argued that measures of spiritual wellbeing should be developed and validated cross-culturally, and in the languages in which they are likely to be used. This means that any linguistic and conceptual difficulties can be resolved during development, rather than in later field-testing and validation [16,17].\n\nMembers of the European Organization for Research and Treatment of Cancer (EORTC) Quality of Life Group recently completed international validation of a stand-alone measure of spiritual wellbeing for people receiving palliative care for cancer: the EORTC QLQ-SWB32 (SWB32) [17]. The SWB32 was developed based on relevant literature, expert opinions, and interviews with palliative cancer patients [12,16,17] and validated in a multilingual and cultural context involving 14 countries, including China [17]. It has four main scoring dimensions, or scales: Relationship with Self, Relationships with Others, Relationship with Someone or Something Greater, and Existential. It was designed to suit people with various religious faiths or spiritual beliefs and those with none [17].\n\nChinese culture traditionally lacks a formalized religious structure, but philosophies such as Buddhism, Taoism, and Confucianism have significantly influenced both spiritual development and secular culture in China. Consequently, the boundaries between Chinese philosophical beliefs, religions, notably Buddhism and Taoism, and local folk religious practices blur considerably [18]. While many Chinese people claim no formal religious beliefs but, nevertheless, influenced by the context of traditional Chinese culture and philosophies [19], exhibit religion-like beliefs and behaviors [18].A notable manifestation of this is evident in the narratives of numerous Chinese patients who invoke Karma to rationalize their hospitalization experiences, attributing their diseases to a predetermined fate orchestrated by higher cosmic forces at the moment of their birth [20]. Taoists include veneration of ancestors and local gods in seeking resolutions to life’s challenges [21]. However, it is noteworthy that many Chinese individuals also pray to deities rooted in Taoism, aligning their petitions with specific desires. These desires encompass a diverse spectrum, from seeking the favor of Gods associated with wealth, health, academic success, environmental harmony, pregnancy, and culinary pursuits [21]. This multifaceted spiritual background confers a spiritual dimension akin to conventional religious systems upon the Chinese [22].\n\nChinese culture traditionally emphasizes harmony, collectivism, and moral ethics, which significantly influence spiritual perceptions [23]. Unlike Western conceptions of spirituality that often center on personal relationships with a transcendent deity, Chinese spirituality is deeply rooted in the concepts of interconnectedness and balance [23,24]. This is reflected in Confucianism’s emphasis on social harmony, Taoism’s pursuit of unity with nature, and Buddhism’s focus on inner enlightenment. These philosophical traditions contribute to a holistic worldview where spirituality is integrated into everyday life rather than confined to organized religious practices [25]. Consequently, spirituality in Chinese culture is more likely to be expressed through ethical living, social roles, and relational harmony rather than explicit religious beliefs [25].\n\nResearchers have recognized the importance of spirituality within Chinese contexts, defining it as a relationship with self, others, nature, and Higher Being(s) [26,27]. These dimensions align with the four key scoring areas of SWB32. The international validation study included Chinese participants, but at that time, the Chinese translation of the SWB32 had not yet been approved by the EORTC Translation Unit [28,29]. We conducted this later study to produce an approved Chinese translation, explore its reliability and validity with Chinese gynecological cancer patients, and explore associations between spiritual well-being and demographic characteristics for these patients. This approved, validated instrument is now available for Chinese medical staff to use to assess the spiritual wellbeing of Chinese cancer patients, and help improve understanding of the relevance of spiritual wellbeing to people from Chinese cultural backgrounds.\n\nThe translation from English to Chinese was performed in collaboration with the EORTC Translation Unit, following the standard EORTC translation procedure [30]: two forward translations, initial linguistic reconciliation by our research group, two backward translations of the reconciled version, and then EORTC Translation Unit review of the translation report. Following several rounds of review, discussion, and revisions, our Chinese translation was approved for pilot testing.\n\nWe conducted two rounds of pilot testing with cancer patients in March 2023. Patients completed the questionnaire and were then interviewed face-to-face about their feelings and experiences to check their understanding. The questions were: “Do you understand these items? Is the item confusing? Are there any difficult words? Is the item upsetting? If the answer is yes, how would you ask this question?” We amended any problematic items as necessary and tested the new translation with a new group of patients. The final version, approved by the EORTC Quality of Life group as the official Chinese version of the EORTC QLQ-SWB32, went forward to larger-scale validation.\n\nFor the validation study, we continuously recruited patients from April 1st, 2023, to August 31st, 2023, in a women’s and children’s medical center in western China. Patients were enrolled if they 1) had been diagnosed with gynecological cancer, such as ovarian, cervical, endometrial, and fallopian tube cancer; 2) could understand and answer relevant questions. Patients were excluded if they 1) refused to participate in this study or 2) had cognitive impairment. We collected relevant demographic information, including age (years), ethnicity, marital status, employment status, educational background, and monthly household income (Yuan). Clinical data, such as diagnosis and cancer stage, were extracted from patients’ medical records. Additionally, we inquired whether patients held religious beliefs or actively engaged in religious practices. We helped patients fill in the questionnaires, along with an explanation of the concept of spiritual well-being. ‘Spiritual’ was described as a relation to people’s thoughts, beliefs, faith, and connections between self and one’s outlook on life. ‘Wellbeing’ refers to being in a good state. ‘Spiritual wellbeing’ means being content with oneself according to one’s own beliefs. It could be finding meaning and purpose in life through a connection with oneself, other people, art, music, literature, nature, prayer, meditation, or a power greater than oneself; harmony between mind, body, and soul; the affirmation of life in a relationship with God, the self, the wider environment and a good balance between one’s beliefs and one’s actions.\n\nThis study was performed following the principles of the Declaration of Helsinki. The Ethics Committee of West China Second University Hospital of Sichuan University approved the study protocol (No. 2019-13). Written informed consent was obtained from all the patients included in this study.\n\nThe SWB32 has 32 items, with 22 of them comprising its four main scoring scales: Existential (6 items), Relationship with Self (5 items), Relationships with Others (6 items), and Relationship with Someone or Something Greater (5 items). These items are scored from 1 (not at all) to 4 (very much). Items 22 and 23 are non-scoring items that serve to identify respondents with a belief for whom the single-item scale Relationship with God (item 26) is applicable. Only these individuals should respond to that item. The remaining items are six further non-scoring but clinically relevant items, plus a single item for overall spiritual wellbeing, or Global SWB, which is scored from 1 (very poor) to 7 (excellent), with an additional choice of 0 (cannot reply or don’t know) [14]. The Relationship with Self scale is reverse scored. Total scores of the multi-item scales are transformed into centesimal scores (the score/possible highest score * 100). All scales then range from 0 to 100, with high scores representing positive outcomes.\n\nWe present our study data as frequencies (percentages) and means plus standard deviations. The distribution of included SWB32 scores was skewed, so we used the Spearman correlation coefficient to calculate correlations between scores on each SWB32 scale and patients’ ages. We assessed relationships between spiritual wellbeing and countable variables using the Nonparametric Test. Mann-Whitney U tests were used for comparisons between two groups; Kruskal- Wallis H tests were used for more than two groups. We included all variables withP< 0.1 in the correlation analysis in the multi-linear regression analysis to investigate possible factors associated with spiritual well-being. Statistical tests, all conducted using SPSS 27.0, were two-tailed, with statistical significance set at an alpha level of 0.05.\n\nWe assessed the internal consistency of the SWB32 using Cronbach’s alpha coefficients (recommended value > 0.7) and split-half reliability (recommended value > 0.8). We conducted item analysis using Spearman correlation coefficients to assess the correlations between each item and the total score of scales (recommended value > 0.4) [31].\n\nSix healthcare practitioners in palliative and cancer care assessed the questionnaire’s clarity and semantics. They should have a master’s degree or above, at least 5 years of experience in this research field, and good command of English. They provided suggestions for any modifications they thought necessary.\n\nWe conducted Exploratory Factor Analysis (EFA) to help determine the underlying theoretical structure of the scale, excluding the non-scoring items and the single Global SWB item. We applied Bartlett’s test of Sphericity and Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy before the EFA, to verify the appropriateness [32]. We used principal axis factoring and oblique rotation for all responses. After the EFA, we conducted a confirmatory factor analysis (CFA) to confirm the EFA-suggested factor structure. We used JASP 0.17.2.1 [33] for both the EFA and CFA. We evaluated goodness of fit using the following indices [34]: chi-squared value to degrees of freedom ratio (χ2/df) < 3, the Goodness of Fit Index (GFI) > 0.9, the root mean squared error of approximation (RMESA) < 0.08, the standardized root mean squared residual (SRMR) < 0.08, the Comparative Fit Index (CFI) > 0.9, and Tucker-Lewis Index (TLI) > 0.9.\n\nWe applied EGA, using R software 4.3.1 and R packages EGAnet [35], to inspect SWB32 dimensionality. EGA estimates a Gaussian graphic model with LASSO and then uses the Walktrap algorithm [36]. It produces a visual network plot to indicate the number of dimensions of SWB32, which items cluster together, and their level of associations [35]. Each node in the network represents each SWB32 item, while edges present the partial correlation between two items. The magnitude of the correlation is represented by the thickness of the edges [37]. This plot can discover the dimensionality of the SWB32 by identifying the number of item clusters [38], and we investigated whether the clusters generated by the network were consistent with the dimensions of the English version of the measure.\n\nAdditional information regarding the ethical, cultural, and scientific considerations specific to inclusivity in global research is included in the Supporting Information.\n\nWe conducted preliminary pilot testing with ten cancer patients: three with ovarian, four cervical, and three with endometrial cancers (mean age 50.80 ± 12.20 years, ranging from 31 to 70). Four patients reported difficulty understanding Q2, ‘I have felt at peace with myself,’ so we revised the Chinese translation following their comments and suggestions. This item can be understood as feeling free from emotional or mental agitation, a sense of calm or feeling untroubled, so it was described as ‘平和’ in Chinese (back translation to English: calm and peace). The second round of pilot testing involved six other cancer patients (39 to 59 years old). These patients’ responses indicated that they well understood the final translation. Four female and two male healthcare professionals in palliative and cancer care (ranging from 30 to 47 years old) assessed content validity.\n\nOur final validation involved 200 patients, with no missing data. Their mean age was 50, (SD 12). Most (85%) were married, and half (50%) were unemployed. 41.5% of the patients had cervical cancer, with 22.5% ovarian/fallopian tube cancer, and 28.5% endometrial cancer. Most (59%) had Stage I cancer, with 10.5% stage II, 13.0% stage III, and 5.5% stage IV. 96.5% of the patients declared that they had no religious beliefs and were not actively engaged in religious practices; one (0.5%) was Christian, and six (3.0%) were Buddhist.Table 1presents patients’ demographic characteristics.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321790.t001\n\nTable 2shows the means and SDs for each item. Correlation coefficients between each item and the total score ranged from 0.726 to 0.883 (P< 0.05). The Cronbach’s alpha values (RO 0.888, RS 0.885, RSG 0.907, EX 0.897) and Guttman split-half coefficients (RO 0.829, RS 0.839, RSG 0.890, EX 0.814) indicated good internal reliability.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321790.t002\n\nAll healthcare professionals interviewed found the language easy to understand and the content appropriately relevant to palliative and cancer care.\n\nThe KMO value (0.876) and the Barlett Sphericity test results (χ2= 2865.036, df = 231,P< 0.001) were suitable for factor analysis.Table 3presents item loading results, indicating four factors of SWB32. The exploratory graph analysis (EGA) produced a four-dimensional structure of the SWB32 (Fig 1), showing the connectedness of the factors and item clusters as a network, with the width of the lines indicating the strength of the relationships between items. The EGA-identified dimensions and the items in each cluster were equivalent to the scales in the internationally validated SWB32. The fit statistics in the confirmatory factor analysis (CFA) indicated an adequate fit for a four-factor solution (χ2/df = 2.178, RMESA = 0.077, GFI = 0.973, SRMR = 0.057, CFI = 0.914, TLI = 0.902). The single Relationship with God item was not included in CFA as the model couldn’t be estimated with one observed variable in one factor.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321790.t003\n\n† Colored cluster: Red (group 1), Relationships with Others; Blue (group 2), Relationship with Self; Green (group 3), Relationship with Someone or Something Greater; Orange (Group 4), Existential. ‡ Nodes (circles) represent the items in SWB32. Each node corresponds to a specific item measuring different aspects of spiritual wellbeing. Edges (lines) represent partial correlations between items. The thickness of the edges represents the magnitude of the correlation; the thicker the edge, the stronger the correlation. Green edges = positive correlations, red edges = negative correlations. § The RG scale was answered only by the patients who responded 2-4 on items 21 and 22 (n = 122).\n\n† Colored cluster: Red (group 1), Relationships with Others; Blue (group 2), Relationship with Self; Green (group 3), Relationship with Someone or Something Greater; Orange (Group 4), Existential. ‡ Nodes (circles) represent the items in SWB32. Each node corresponds to a specific item measuring different aspects of spiritual wellbeing. Edges (lines) represent partial correlations between items. The thickness of the edges represents the magnitude of the correlation; the thicker the edge, the stronger the correlation. Green edges = positive correlations, red edges = negative correlations. § The RG scale was answered only by the patients who responded 2-4 on items 21 and 22 (n = 122).\n\nhttps://doi.org/10.1371/journal.pone.0321790.g001\n\nWe analyzed the association between SWB32 scale scores and respondents’ demographic characteristics (Table 4).Table 5presents the results from the multiple linear regression analysis, including variables withP< 0.1 in the single-factor analysis seeking to identify factors associated with spiritual well-being. We found that high Relationships with Others scores were associated with college and higher education (B = 6.860,P= 0.016). Employed or retired respondents had higher Relationship with Self scores than unemployed respondents (B = 5.594,P= 0.037 v.s B = 6.036,P= 0.040). Higher Existential scores were associated with senior or college and above education (B = 6.970,P= 0.027 v.s B = 8.668,P= 0.009), family income more than 5000 per month (B = −7.807,P= 0.023) compared to junior and below, and income less than 3000. As for Relationship with God score, patients with religious beliefs (B = 30.315,P< 0.001), were less educated (B = −10.969,P= 0.019), and those living in urban areas had higher RS scores (B = −10.221,P= 0.009). The independent variables in this multiple regression analysis explained 4.9% of the variance in RO, 4.1% in RS, 10.1% in EX, and 15.6% in RG.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321790.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321790.t005\n\nWe translated the EORTC QLQ-SWB32 to Chinese following EORTC translation guidelines, and our translation was approved by the EORTC Translation Unit. We then tested it on Chinese gynecological cancer patients, confirming internal reliability and validity. We identified some factors, including level of education, employment status, and religious beliefs, which are associated with our gynecological cancer patients’ scores on the SWB32 scales.\n\nThe internal consistency and split-half reliability were generally strong for four factors, and the results were similar to the internationally validated version [17]. The four-factor structure identified from EFA, CFA, and EGA in our study aligns closely with the international study’s principal component and Rasch-derived scales: Relationships with Others (RO), Relationship with Self (RS), Relationship with Someone or Something Greater (RSG), and Existential (EX). EFA loaded all the items on the same factors as in the internationally validated version. For the Relationship with God (RG) single-item scale, the two non-scoring “skip” items that determine whether patients should respond to the RG item were not included in the EFA. The single RG item didn’t load on any factor and was separate from the four main dimensions. The CFA and EGA both also confirmed the structure of four dimensions.\n\nTwo previous studies employing the Chinese translation that had not been approved by the EORTC Translation Unit, reported on levels of spiritual well-being among their cancer patients (all palliative patients) [28,29,39]. Sun’s study [29,39] did not convert the total scores of the multi-item scales into centesimal scores, prompting us to compare the raw scores across these studies. The other study, involving members of our group [28], and also using the unapproved translation version, exhibited scores on each scale that were notably akin to the findings in our current study, both of which explored SWB with gynecological cancer patients. In contrast, Sun et al. [29,39] included both male and female patients with a diverse range of cancer types, and reported lower scores across most dimensions than our study found, except for Existential.\n\nSun used principal component analysis, and identified four dimensions for the SWB32. The items comprising each dimension identified did not precisely match the original English version, and Sun therefore modified the items included in each scale, including expanding the RO scale from six to seven items and reducing the RS scale from five to four items. Discrepancies therefore exist between outcomes from our current study, the main validation study [17], and Sun’s study [29,39]. In contrast, Feng et al. [28] used the original scale’s scoring methodology, yielding results similar to our present study’s findings.\n\nThere are some distinctions in content between our authorized translation and the preceding one. These variances are evident in the interpretation of certain items. For example, item 13, ‘valued as a person,’ was translated as ‘一个有价值的人(back translation in English: a valuable person) in the unapproved version. However, according to the EORTC Translation Unit, the intended meaning should convey that the patient feels respected by others or thinks that they are important and special;’ the respondent’s view of how other people regard them. We therefore translated it as ‘作为人被重视,’ aligning with this explanation, so our approved translation is closer to the precise meaning intended in the English SWB32.\n\nThe mean scores for the main EORTC QLQ-SWB32 scales: RO, RS, RSG, EX, and also for Global-SWB in our study were similar to previous studies using the version in other languages [40–42], indicating that our approved Chinese translation equates well to what the scales in the original version seek to measure. Our 122 study participants’ mean RG scores were the lowest (44.06) of all their SWB32 mean scale scores. Previous studies in other countries have reported higher mean RG scores: 74.9 in Cyprus [41], and 67.7 in Finland [42]. Notably, neither of the two earlier studies in China [28,29,39] reported RG scale scores.\n\nRG is only answered by those with faith, so RG scores in different countries cannot be simply, directly compared. Religion, and religious faith and belief, also mean different things in different countries and cultures. China is generally less religiously oriented than many other countries, but Chinese people may also be different from people from cultures with no religion at all, because of the influence of aspects of Chinese traditional culture such as Confucianism, Taoism, and Buddhism [28]. This particular cultural background provides a religion-like spiritual function [22]. Many Chinese people identify themselves as nonbelievers but still hold religious-like beliefs and behave in ways that can be similar to religious behaviors [18]. However, these cultural influences do not correspond to the concept of ‘God’ as understood in monotheistic religions prevalent in Western cultures. The concept of ‘God’ in Chinese culture tends to be more abstract, often associated with ideas such as heaven, fate, or ancestral spirits, rather than a personal deity [23,43]. Therefore, when asked about a ‘Relationship with God,’ Chinese participants may interpret the question differently, leading to lower scores. In fact, this reflects cultural differences in spirituality rather than a lack of spiritual wellbeing. This cultural background may result in different interpretations and response patterns to RG items. Although 96.5% of our participants identified as non-religious, contrasting sharply with the international validation sample (34.6% non-religious; 41.7% Christian, 11.1% Muslim) [17], 61% of our respondents answered the RG single item, similarly to the international validation study of SWB32 finding that over a half self-declared non-religious individuals still responded to the skip items on the SWB measure [17]. However, those patients who had identified themselves as religious scored higher on RG than those who had not. A previous study, also with Chinese gynecological cancer patients, found that explicit religious beliefs correlated with spiritual well-being [44]. This may be related to the belief that God, or a greater power will give strength and help inner peace.\n\nOur study also identified several other socio-demographic variables that could impact spiritual well-being in gynecological cancer patients. Patients with a higher level of education scored higher on RO and EX, similar to the findings of Wang et al. [45], who investigated spirituality in Chinese stroke patients. More educated patients may be better at maintaining physical, spiritual, and social wellbeing, and adept at utilizing all available resources for positive psychological suggestions and adjustments to maintain overall spiritual wellbeing and peace of mind[38]. As for employment and economic status, we found that patients who were unemployed or had lower incomes had lower scores on RS and EX, respectively. The results were consistent with a previous study by Dabo et.al [40] in Croatian cancer patients. Unemployed patients may have low incomes. During anti-cancer treatment, these patients may be constrained and limited by their financial difficulties, face related stresses and other difficulties [40]. We found no significant differences for cancer stage for our participants’ scores, similar results were found in previous studies that cancer stage was not associated with spiritual wellbeing[46,47]. Even in the early stages of the disease, healthcare professionals should assess the spiritual wellbeing of cancer patients and provide appropriate spiritual care.\n\nSpiritual well-being and the provision of spiritual care are integral components of cancer care. Our validation study has contributed to confirming that the EORTC QLQ-SWB32 is a valid and reliable measurement of spiritual wellbeing in Chinese cancer patients. This measure could help identify cancer patients with lower spiritual wellbeing and unmet spiritual needs. Healthcare professionals can also use this tool to initiate discussions surrounding spiritual concerns and to evaluate responses to spiritual care interventions in China.\n\nIt is important to note that all our participants were gynecological patients, so female, and more than half with stage I cancer, whereas other studies have involved patients of mixed sexes, and with a variety of cancers and cancer stages. Rohde et al. [15] found differences related to the sex of the main validation study participants. Nevertheless, the demographic characteristics identified in our study of this group which were associated with variations in spiritual wellbeing can serve as valuable indicators for healthcare providers. These findings underscore the potential benefits of intensified spiritual care for patients with lower educational attainment, individuals who are unemployed or with lower incomes, and those without religious beliefs. Strategies for enhancing spiritual wellbeing include meaningful/existential interventions [48] and psychosocial interventions such as creative arts and yoga [4]. Additionally, integrating the EORTC QLQ-SWB32 into routine monitoring of treatment and care warrants consideration. Healthcare professionals must fortify their spiritual care competencies, acquiring profound knowledge and expertise in assessing patients’ spiritual concerns and the skills to address them effectively. This endeavor will comprehensively enhance the quality of spiritual care delivery within cancer care [49].\n\nGiven the absence of recommended cut-off scores by the original validated literature and a definitive ‘gold standard’ in this domain, establishing which scale scores denote high spiritual wellbeing remains to be discovered. We therefore call for a broader adoption of the EORTC QLQ-SWB32 by researchers, so as to explore this and other questions further, including sex differences.\n\nOur study had some limitations. As noted, the absence of established cut-off scores for the EORTC QLQ-SWB32 poses a challenge in categorizing scores as indicative of high or low levels of spiritual wellbeing. Our study is constrained to score comparisons with existing studies identifying scale score minima within the measure. Furthermore, our regression analysis yielded a limited interpretation of the impact of demographic characteristics on spiritual wellbeing. This suggests that our study might have recorded other variables, encompassing additional demographic, clinical, and psychosocial dimensions, which may impact spiritual wellbeing. Our cross-sectional design also limited the possibility of identifying any causal associations between the variables we included. In contrast to the main international validation study [14], and the studies in Cyprus [35] and Finland [36], but similar to the Croatian study [34], more than half of our study participants had a stage I cancer, which prevented comparisons of scores by cancer stage. Last but not least, our validation study was conducted only with gynecological cancer patients, i.e., women only. Whether the SWB32 is suitable for male patients and other cancer patients in China requires future research. One additional limitation of this study is the absence of effect size calculations. While statistical significance was assessed, effect size measures were not reported due to software constraints and the need for additional manual calculations. Future studies should include effect size to provide a more comprehensive understanding of the practical significance of the findings.\n\nIn conclusion, our translation of the EORTC QLQ-SWB32 into Chinese demonstrated high reliability and validity among gynecological cancer patients. The dimensions of this Chinese version are consistent with the original tool. Higher spiritual wellbeing was associated with higher education levels, higher incomes, work or retirement, and religious beliefs. Conversely, patients with lower education levels, unemployed or with lower incomes, and those who said they had no religious faith scored lower on several of the SWB32 scales. Healthcare providers should consider these factors when providing spiritual care to cancer patients.\n\nThe EORTC QLQ-SWB32 was developed to facilitate the measurement of spiritual wellbeing in multiple linguistic and cultural contexts, and enable comparisons between them, so it is undoubtedly beneficial for different studies worldwide to use the same measure. Nevertheless, results from studies in different countries and cultural contexts need to be examined and compared with caution because various aspects of spirituality may be present in every culture, although they may not be explicitly defined as such. An in-depth understanding of traditions and social networks and connections is needed to fully contextualise and understand results from studies in this field.\n\nhttps://doi.org/10.1371/journal.pone.0321790.s001\n\n(CSV)\n\nhttps://doi.org/10.1371/journal.pone.0321790.s002\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321790.s003\n\n(PDF)\n\nhttps://doi.org/10.1371/journal.pone.0321790.s004\n\n(DOCX)\n\nThe authors thank all the medical professionals involved in our study for their help and support in this study. Thanks to all the patients who participated in this study.",
    "category": "oncology"
  },
  {
    "title": "The impact of ischemic reperfusion injury on contralateral kidneys and the determinants of renal prognosis after robot-assisted partial nephrectomy",
    "authors": "Mitsunori Matsuo, Kensei Taguchi, Yunosuke Yokota, Kei Fukami, Tsukasa Igawa, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321769",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321769",
    "content": "Robot-assisted laparoscopic partial nephrectomy (RAPN) is a safe and effective option for renal cell carcinoma (RCC). However, clamping of renal artery during RAPN sometimes causes ischemic reperfusion (IR) injury (IRI), which affects renal function at some later time. In the present study, we inserted catheters into the bilateral ureters from before RAPN until 24 hours after and analyzed urine biomarkers of renal injury excreted from both resected and contralateral kidneys to determine and investigated which biomarkers predict the future decline in renal function in patients with RCC and rodent IR model. Twenty-three patients diagnosed with RCC (66.4 ± 10.8 years old, eGFR: 73.6 ± 15.3 mL/min/1.73m2) were enrolled and ureteral catheters were inserted in both ureters. Urinary neutrophil gelatinase-associated lipocalin (NGAL), beta-2-microglobulin (β₂MG), N-acetyl-β-D-glucosaminidase were measured at several time points. Gene expression of injury markers in contralateral kidneys were analyzed in unilateral IR rodents. All the urinary markers were elevated 30 minutes after the clamping and sustained high until 24 hours in resected kidneys. Meanwhile, urinary NGAL and β2MG excreted from contralateral kidneys increased at 6 and 24 hours after the clamping. Warm ischemic time, estimated blood loss, and excised kidney weight were not associated with renal dysfunction; however, only contralateral urinary β2MG at 6 hours was correlated.NgalandIl-6mRNA in contralateral kidneys were upregulated in unilateral IR rodents. RAPN-related IRI induces contralateral kidney injury. Contralateral urinary β2MG can become a potent biomarker to predict the onset of kidney injury after RAPN.\n\nCitation:Matsuo M, Taguchi K, Yokota Y, Fukami K, Igawa T (2025) The impact of ischemic reperfusion injury on contralateral kidneys and the determinants of renal prognosis after robot-assisted partial nephrectomy. PLoS ONE 20(4):\n           e0321769.\n        \n        https://doi.org/10.1371/journal.pone.0321769\n\nEditor:Peter R. Corridon\n\nReceived:December 9, 2024;Accepted:March 11, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Matsuo et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The data underlying the results presented in this study are available in the uploadedS2 File.\n\nFunding:This work was supported, in part, by Grants-in-Aid for Welfare and Scientific Research (C) (no.22K08370) (K.F) and from the Ministry of Education, Culture, Sports, Science and Technology of Japan. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:I have no competing interests regarding this paper.\n\nThe incidence of renal cell carcinoma (RCC) has increased in recent years. Although nephrectomy has been considered one of the standard surgical treatment for RCC regardless of tumor size, EORTC-30904 trial recently reported that partial nephrectomy for small-diameter RCC showed no significant difference in overall survival compared to radical nephrectomy [1,2]. Further, partial nephrectomy was shown to reduce the future incidence of chronic kidney disease (CKD) and cardiovascular events reported by the National Comprehensive Cancer Network, the European Association of Urology, and the American Association of Urology guidelines. Thus, partial nephrectomy has drawn the attention as the first-line surgical option for small-diameter RCC [3–6]. Also, robot-assisted laparoscopic partial nephrectomy (RAPN) can save the time to perform hemoperfusion when compared to laparoscopic partial nephrectomy (LPN) [3–7], suggesting that RAPN can be considered a safe and effective therapeutic option for patients with RCC. However, RAPN sometimes causes transient kidney injury due to ischemia-reperfusion (IR) in resected kidneys because RAPN requires warm occlusion by renal artery clamping during removing RCC. Therefore, evaluation of biomarkers and mechanisms regarding IR-associated kidney injury may be necessary to improve the postoperative renal outcome.\n\nUrinary injury biomarkers such as β2-microglobin (β2MG), N-acetyl-β-D-glucosaminidase (NAG), and neutrophil gelatinase-associated lipocalin (NGAL) has been widely used for the early diagnosis of acute kidney injury (AKI) [8]. Indeed, Akpinal et al. have reported that ischemic AKI after nephron-sparing surgery can be detected early by urinary NGAL measurement [8]. However, postoperative renal prognosis and predictive markers by the IR injury (IRI) during RAPN and its effect on the contralateral kidney remain unknown. In the present study, we inserted ureteral catheters in both resected and contralateral ureter and collected urine at several time points to determine the effect of IR by the renal artery clamping on renal dysfunction, and investigated which urinary biomarkers can predict postoperative decline in kidney function in patients receiving RAPN. To confirm whether contralateral kidneys would be impaired when another kidney undergoes IRI, the gene expression of renal injury markers in the contralateral kidneys were analyzed in rodent unilateral IR model.\n\nTwenty-three patients with clinically diagnosed RCC between 1stAugust 2019 and 31thMarch 2020 were prospectively enrolled in this study. All patients were placed ureteral catheters in the ureter on the resected and contralateral sides before the start of RAPN and confirmed urethral patency during tumor resection. In standard RAPN procedures, a ureteral catheter is inserted transurethrally in all cases. In this study, after providing patients with explanations regarding potential side effects, such as bleeding, ureteral catheters were inserted into the resected and contralateral kidneys. All catheters on both sides were removed 24 hours after IR. No significant disadvantages or adverse effects from this procedure were observed in the patients. Tumor resection was performed with total renal artery clamping, and after tumor dissection, an inner suture was performed on the resected surface including the open ureter, and renal parenchymal suture (renorrhaphy) was performed after removal of the occlusion. All ureteral catheters were removed after the final specimen collection on the following day.\n\nUrine was collected from bilateral catheters before occlusion and at 30, 60 minutes, 6 and 24 hours after IR. Serum was also collected at the same time. Urinary NGAL (chemiluminescent immunoassay), NAG (colorimetric method), and β2MG (latex agglutination immunoassay) were measured to evaluate renal impairment, and all were corrected by urinary creatinine (Cr). Serum blood urea nitrogen (BUN), Cr, and cystatin C (CysC) were also measured as markers of renal function. These parameters were analyzed by commercially available laboratories. Data on the clinical characteristics of the participants, including age, body weight, body mass index, mean systolic blood pressure, and R.E.N.A.L Nephrometry Score (RNS) were obtained from the electronic medical records of Kurume University Hospital. eGFR was calculated using a previously described [9]. The same hydration protocol procedure before and after the RAPN was performed. In all patients, written preoperative consent for ureteral catheterization and the use of data was obtained. The study was approved by the Ethics Committee of the Kurume University School of Medicine for human research (Ethical No. 19093) and animal research (2023–163) and was performed in accordance with the Declaration of Helsinki. The data for this study obtained from the patients’ medical records were anonymized so that the patients could not be identified. Human rights are well-protected.\n\n10-week-old C57BL/6J mice (The Jackson Laboratory Japan, Yokohama, Japan) were anesthetized by the injection with Medetomidine hydrochloride (0.3 mg/kg; Cat No. SMB01393, Sigma-Aldrich), midazolam (4 mg/kg; Cat No. 10385, Fuji Film-Wako), and butorphanol tartrate (5 mg/kg, Cat No. B9156, Sigma-Aldrich). After cutting the ventral median line skin and muscle layer, the upper and lower poles of the kidney was dissected free from surrounding tissue. After liberating the kidney from surrounding tissue, the left kidney pedicle was clamped for 30 minutes using a clamp holder. After removal of the vascular clamp, the muscle layer was closed by using absorbable suture and then skin was closed by using monofilament nylon non-absorbable suture. For creating sham mice, we cut the ventral median line skin and muscle layer, and then close the skin and muscle layer in a same way as IRI mice. We closely monitored the mice of both groups and administrated with 150 μL of Buprenorphine (0.15mg/kg, Nissin Pharmaceutical Co., Ltd) every 12 hours until day 2 for pain and discomfort. For sacrifice, the mice were anesthetized after the exposure to isoflurane and both kidneys were removed 24 hours and seven days after the induction of IR.\n\nMice were sacrificed on days 1 and 7 after the IR surgery. The collected right kidney (contralateral side) was homogenized after removing the capsule. Total RNA extracted from each kidney cortex was used to synthesize cDNA with iScript™ cDNA Synthesis Kit (Bio-Rad, 170891). Real-time PCR was performed with iTaq Universal SYBR Green (Bio-Rad, 1725121). Glyceraldehyde-3-phosphate dehydrogenase was used as an internal control. The relative mRNA expression of each gene was calculated using the ΔΔCt method. Primers for targeted genes were purchased from Applied Biosystems (MA, USA).\n\nTo compare the urinary renal injury markers before and after the IR, one-way analysis of variance followed by post hoc multiple comparison analysis (Steel-Dwass test) was used to assess the differences among the groups. To determine the correlation with the changes in eGFR at a month, univariate regression analysis was performed. Human data are presented as mean ± standard deviation. Animal data are presented as mean ± standard error of the mean. A p-value < 0.05 was considered statistically significant. All statistical analyses were performed using JMP Pro ver. 16 Software (SAS Institute Inc.).\n\nClinical background of the enrolled patients is shown inTable 1. The mean age was 66.4 ± 10.8 years and the mean body mass index was 25.6 ± 3.5. The tumor was detected in right kidneys in 8 patients and in left kidneys in 15 patients. The mean tumor diameter was 26.4 ± 6.2 mm, and the mean R.E.N.A.L Nephrometry Score was 7.2 ± 1.1 points. Preoperative renal function was BUN: 15.5 ± 5.9 mg/dL, Cr: 0.78 ± 0.18 mg/dL, eGFR: 73.4 ± 15.2 mL/min/1.73m2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321769.t001\n\nThere were no differences in NGAL, β2MG, and NAG in urine collected from both resected and contralateral kidneys before renal artery clamping (Table 2).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321769.t002\n\nThe results of surgical procedure were as follows: total operative time: 191 ± 37.8 minutes; console time: 101.3 ± 31.5 minutes; warm ischemic time: 15.4 ± 3.6 minutes; total blood loss: 21.6 ± 29.4 ml. Postoperative complications were postoperative hemorrhage and hydronephrosis in one patient each (4.3%), and no inter-allogeneic blood transfusion or laparotomy surgery was performed. Histopathological results showed clear cell RCC in 20 patients (87.0%), chromophobe RCC in 2 patients (8.7%), and angiomyolipoma in 1 patient (4.3%) with no positive margins (Table 3).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321769.t003\n\nAll of the renal injury markers in urine from the resected kidneys were significantly elevated from 30 minutes to 24 hours after renal artery clamping. The increase in urine concentration of NGAL and β2MG continued until 24 hours (NGAL: 30 min; p=0.0001 vs pre, 60 min; p<0.001 vs pre, 6 hrs; p<0.01 vs pre, 24 hrs; p<0.001 vs pre, β2MG: 30 min; p<0.0001 vs pre, 60 min; p<0.05 vs pre, 6 hrs; p<0.01 vs pre, 24 hrs; p<0.0001 vs pre) (Table 4,Fig 1). NAG was elevated only 30 minutes after IR (NAG: 30 min; p=0.0003 vs pre, 60 min; p=0.129 vs pre, 6 hrs; p=0.999 vs pre, 24 hrs; p=0.165 vs pre) (Table 4,Fig 1). Urine NAG was lower at 24 hours than before IR (Table 4,Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321769.t004\n\nNGAL/Cr ratio(a), β2MG/Cr ratio(b), and NAG/Cr ratio(C).***p<0.001,**p<0.01 vs pre,###p<0.001,#p<0.05 vs post 30 min. IR, ischemic reperfusion; RAPN, robot-assisted partial nephrectomy; NGAL, Neutrophil gelatinase-associated lipocalin; Cr, creatinine; β2MG, β2-microglobulin; NAG, N-acetyl-β-D-glucosaminidase.\n\nNGAL/Cr ratio(a), β2MG/Cr ratio(b), and NAG/Cr ratio(C).***p<0.001,**p<0.01 vs pre,###p<0.001,#p<0.05 vs post 30 min. IR, ischemic reperfusion; RAPN, robot-assisted partial nephrectomy; NGAL, Neutrophil gelatinase-associated lipocalin; Cr, creatinine; β2MG, β2-microglobulin; NAG, N-acetyl-β-D-glucosaminidase.\n\nhttps://doi.org/10.1371/journal.pone.0321769.g001\n\nWith respect to the urine from the contralateral kidney, NGAL was elevated only 24 hours after renal artery clamping (NGAL: 30 min; p=0.333 vs pre, 60 min; p=0.412 vs pre, 6 hrs; p=0.075 vs pre, 24 hrs; p<0.05 vs pre). Further, urine β2MG was markedly elevated at 6 and 24 hours (β2MG: 30 min; p=0.998 vs pre, 60 min; p=0.373 vs pre, 6 hrs; p<0.0001 vs pre, 24 hrs; p<0.001 vs pre) (Table 4,Fig 2). The increase in NAG was not observed in the contralateral urine. Transient kidney injury assessed by serum Cr was found at 30 and 60 minutes after renal artery clamping (p<0.05 vs pre, respectively), whereas BUN and CysC were not. While serum BUN and Cr returned to the baseline at 6 hours; CysC was slightly lower at 6 and 24 hours than before IR (Table 4).\n\nNGAL/Cr ratio(a), β2MG/Cr ratio(b), and NAG/Cr ratio(C).***p<0.001,*p<0.05 vs pre,###p<0.001,##p<0.01 vs post 30 min. IR, ischemic reperfusion; RAPN, robot-assisted partial nephrectomy; NGAL, Neutrophil gelatinase-associated lipocalin; Cr, creatinine; β2MG, β2-microglobulin; NAG, N-acetyl-β-D-glucosaminidase.\n\nNGAL/Cr ratio(a), β2MG/Cr ratio(b), and NAG/Cr ratio(C).***p<0.001,*p<0.05 vs pre,###p<0.001,##p<0.01 vs post 30 min. IR, ischemic reperfusion; RAPN, robot-assisted partial nephrectomy; NGAL, Neutrophil gelatinase-associated lipocalin; Cr, creatinine; β2MG, β2-microglobulin; NAG, N-acetyl-β-D-glucosaminidase.\n\nhttps://doi.org/10.1371/journal.pone.0321769.g002\n\nAmong the urinary injury biomarkers, the contralateral urine β2MG at 6 hours after renal artery clamping is associated with the decline in renal function at 1 month (r=−0.458, p<0.05) (Fig 3). Meanwhile, none of the injury markers in urine excreted from the resected kidney, blood loss, and kidney excised weight were not associated with postoperative renal dysfunction.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321769.g003\n\nIn unilateral IR rodents, we identified an increase in NGAL gene levels in the contralateral kidneys on day 1 when compared to the sham mice, which continued until day 7 (Fig 4a). IL-6, an inflammatory cytokine, showed a similar trend as NGAL mRNA expression (Fig 4b) in spite of no difference in renal function before and after the IRI (Fig 4c).\n\n***p<0.001 vs sham,*p<0.05 vs Day 7. NGAL, Neutrophil gelatinase-associated lipocalin; lcn2, lipocalin 2; IL-6, interleukin-6; BUN, blood urea nitrogen; Gapdh, glyceraldehyde-3-phosphate dehydrogenase; UIRI, unilateral ischemic reperfusion injury.\n\n***p<0.001 vs sham,*p<0.05 vs Day 7. NGAL, Neutrophil gelatinase-associated lipocalin; lcn2, lipocalin 2; IL-6, interleukin-6; BUN, blood urea nitrogen; Gapdh, glyceraldehyde-3-phosphate dehydrogenase; UIRI, unilateral ischemic reperfusion injury.\n\nhttps://doi.org/10.1371/journal.pone.0321769.g004\n\nInterception of renal blood flow is a prerequisite process for RAPN; but, kidney injury is likely to occur immediately after interception of renal blood flow [10]. There have been no reports investigating whether contralateral kidney would be impaired when another kidney undergoes IR injury. Thus, we collected urine from resected and contralateral kidney separately during surgery of RAPN. We identified that renal artery clamping-induced IR injury cause contralateral kidney injury, which may be associated with the new onset of chronic injury.\n\nNGAL, a 25 kDa protein secreted from secretory granules of human neutrophils, was known to be secreted from distal tubular epithelial cells in very early stages of AKI [11]. In an investigation of urinary biomarkers for kidney injury associated with RAPN, urinary NGAL concentration in the resected kidney can predict postoperative renal dysfunction in the patients receiving RAPN [12]. In our study, while urine NGAL was elevated in the resected kidney, tubular injury markers including NAG and β2MG were also increased in the urine from the contralateral kidney. Recently, Rooij et al. reported that kidney function significantly decreased and urinary β2MG levels increased 24 hours after unilateral nephrectomy in healthy kidney donors [13]. The unilateral nephrectomy-induced reduction in kidney mass increases blood pressure in the contralateral kidney, leading to elevated urinary β2MG levels. Considering that kidney function returned to baseline 24 hours postoperatively in our cases, the continuous increase in contralateral tubular injury markers is possibly attributable to IRI of the resected kidney rather than the reduction in kidney mass due to tumor removal. Akpinal et al. demonstrated that urinary NGAL levels increased significantly 3 hours after intraoperative total or renal artery clamping [8]. In contrast, in our cases, urinary NGAL and NAG levels were elevated 30 min after IR, but only from the resected kidney, indicating that IR-induced tubular injury due to renal artery clamping might occur immediately after IR rather than after 3 hours in the resected kidney. There was a time lag regarding the elevation of injury markers between resected kidney and contralateral kidney, suggesting that some humoral or neurogenic factors may extend renal damage to the contralateral kidney. Recently, multiple organ crosstalk has been reported. For instance, IR-induced AKI causes lung injury through increased infiltration, vascular permeability, and inflammatory cytokines and chemokines [14]. Our unilateral IR mice demonstrated that gene expression of renal NGAL and IL-6 in the contralateral kidney was upregulated in spite of no change in renal function. Thus, IRI-induced inflammatory cytokines and chemokines from the resected kidney (IRI kidney) cause tubular damage in the contralateral kidney as an organ crosstalk. Further, only acute elevation of contralateral urinary β2MG after clamping renal artery, but not the resected kidney-related injury markers and RAPN-related clinical parameters including blood loss, was correlated to chronic changes in renal function at 1 month after RAPN. Our finding indicates that renal prognosis after RAPN might depend on contralateral kidney’s tubular damage. Focusing on contralateral kidneys should be required to prevent chronic kidney injury after RAPN.\n\nRegarding surgical treatment for small-diameter renal cancer, the only RCT by EORTC-30904 in 2011 showed that partial nephrectomy did not significantly differ from radical nephrectomy in overall survival in terms of cancer control [1]. Also, 26% of patients with small-diameter renal cancer are reported to have CKD even if their preoperative serum creatinine levels are within normal range; thus, there have been concerns regarding nephrectomy-induce additional renal damage [15]. However, partial nephrectomy has been shown to reduce the risk of CKD [16], all-cause and non-cancer related mortality[17], the prevalence of cardiovascular events [18], and other factors associated with mortality when compared to nephrectomy[3]. In addition, RAPN is a surgical assist device that can compensate for the weakness of manual manipulation in LPN, including tumor removal and parenchymal suture, and is comparable to LPN in terms of radical cure, shorter WIT, and lower complication rate [19]. The perioperative results of our study showed no conversion to laparotomy or grade 3 or higher complications, all of which were comparable to the previous report [20]. As demand of RAPN will continue to rise, further investigation will be necessary to create the precautions and therapeutic interventions to halt RAPN-related chronic kidney injury.\n\nThere are several limitations to this study. First, the number of patients is small, and further study is needed to accumulate more cases. Second, the mechanism of the effect of IRI on the contralateral kidney and the long-term effect of RAPN on renal function are unknown. Thirdly, it is generally difficult to collect urine from the healthy kidney in standard RAPN. However, since no increase in β2MG was observed in the urine collected from the resected kidney, measuring β2MG in bladder urine may reflect the urinary β2MG levels of the contralateral kidney. Fourthly, to acquire adequate statistical power (1-β >0.8), our clinical study was supposed to include 34 patients by using a sample size calculation tool [21]. However, it was difficult to collect the number of patients who received RAPN for RCC in a single center, the point of which is one of our limitations. Finally, this study did not include healthy individuals as controls, which may introduce potential bias. Therefore, large-scale, longitudinal, and prospective placebo-controlled studies should be conducted in the future.\n\nIRI after renal artery clamping during RAPN occurs in the resected kidney, which, in turn, extend the kidney damage to the contralateral kidney. Urinary β2MG excreted from the contralateral kidney after clamping renal artery may become a potent biomarker to predict the new onset of chronic kidney injury after RAPN.\n\nhttps://doi.org/10.1371/journal.pone.0321769.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321769.s002\n\n(XLSX)\n\nWe thank all patients for participating in this study.",
    "category": "oncology"
  },
  {
    "title": "Gama rays mediated improvement of catalytic efficiency and thermostability of glucoamylase by replacing active site leucine to isoleucene from super koji (Aspergillus oryzae)",
    "authors": "Anam Saqib, Saif -ur-Rehman, Hazrat Ali, Noor Hassan, Asad Ali, Muhammad Hamid Rashid, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0319261",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319261",
    "content": "Glucoamylase is considered as an essential enzyme in food industry. However, lowere catalytic efficiency and weak thermostability confine its application in food industry. Therefore, the current study was aimed to improve catalytic efficiency and thermostability of glucoamylase by replacing active site leucine to isoleucene from Super Koji (Aspergillus oryzae) using gama rays mediated point mutation. High catalytic efficiency and thermostability of glucoamylase from mutantAspergillus oryzaeM-60(5) (screened from 51 mutants) was achieved due to a point mutation, i.e., Leu203 → lle in active site. The SDS-PAGE molecular mass of parent and mutant glucoamylase was 63.1 kDa, while mutant glucoamylase showed; productivity =  9.7 U ml‒1, kinetic constantskcat= 118 (1.62 fold), (kcat/Km) = 1899 (4.75 fold) and half-life at 55 °C for 45 min (1.92 fold). Thermodynamics parameters for starch hydrolysis of parent glucoamylase were; ΔH*= 47.755 kJ mol‒1and ΔG*= 67.975 kJ mol‒1while for mutant ΔH*= 44.263kJ mol‒1and ΔG*= 66.514 kJ mol‒1. The ΔG* of irreversible thermostability for parent and mutant at 55 °C was 104.95 kJ mol‒1and 101.52 kJ mol‒1respectively. The point mutation altered the conformation of the glucoamylase active site that contributed to improve the functional energy (ΔG*), resulted the stabilization of transition state which made it thermostable and highly efficient in starch hydrolysis.\n\nCitation:Saqib A, -ur-Rehman S, Ali H, Hassan N, Ali A, Rashid MH (2025) Gama rays mediated improvement of catalytic efficiency and thermostability of glucoamylase by replacing active site leucine to isoleucene from super koji (Aspergillus oryzae). PLoS ONE 20(4):\n           e0319261.\n        \n        https://doi.org/10.1371/journal.pone.0319261\n\nEditor:Habibullah Nadeem, Government College University Faisalabad, PAKISTAN\n\nReceived:November 24, 2024;Accepted:January 30, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Saqib et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nGlucoamylase (GA) is the most widely used enzyme [1] and has distinctive properties of hydrolyzing starch into subunits of oligosaccharide and commonly used for production of high corn, glucose and fructose syrups as well as for alcohol production [2–4]. The GA produces glucose directly by scarification of α-1,3, α-1,4 and α-1,6 glycosidic bonds present at non-reducing end of starch molecule [5,6].Aspergillus oryzaeis the main focus of food industries for hydrolytic enzymes production such as α-amylase, GA and other food grade enzymes. Different fungal species, e.g.,Aspergillus niger,Rhizopus niveusandRhizopus delemar, are used to produce GA commercially [7]. However, their lower catalytic activity leads to consume high energy and restrictions in starch processing and fermentation [8]. Hence, it is a dire need to develop novel fungal GA suitable for evolving industrial applications.\n\nTheA. oryzaeis considered as Generally Recognized As Safe (GRAS), therefore their enzymes are safe for food and feed industry [8,9]. In recent era, strain improvement by site directed and random mutagenesis of fungi is being used widely for industrial applications. Strain improvement usually targets for elevated yields of the enzymes and biomass production, broad spectrum uses of industrially suitable substrates and efficient physiological properties [10]. Implementation of various molecular methods like recombinant DNA technology and γ-rays dependent mutagenesis is being carried out to evolve strains in order to meet increase industrial demands for food grade enzymes [11].\n\nThe complete open reading frame ofA. oryzaeGA contained 612 amino acids residues and GA protein is composed of carbohydrate binding module (CBM) of 106 amino acid residues from 506–612 [12]. TheA. oryzaeGA showed 67% and 30% homology withA. nigerandR oryzae, respectively [13,14]. Five highly conserved regions were reported in GA enzyme ofA oryzaeandA. nigerwith 78–95% similarity, whereas, the active site ofA. oryzaewas homologous toA. niger[15].\n\nRandom mutagenesis induced by γ-rays may contribute in enhancement of industrial enzymes production; hence γ-ray mediated mutagenesis ofA. nigermade the mutant GA highly efficient in substrate hydrolysis (Aleem et al. 2018). Kinetics and thermodynamics of GA suggested that the mutated enzyme have potential for commercial scale glucose production in starch processing as well as in the food industry [16,17]. Previously, we developed novelAspergillus oryzaemutants by γ-rays’ mutagenesis for the enhanced production of thermostable α-amylases, which were also highly specific in the α-amylase production [18]. The increase in production, catalytic efficiency and thermostability of α-amylases proved that the γ-rays might have altered the α-amylases conformation [18]. In the current study, we further have screened the previously generated koji mutants for the thermostable GA hyper producer strains. Consequently, mutant M-60(5) was identified as the potent hyper producer of thermostable GA.\n\nNovelty of current report is as it for the first time explains about effect of point mutation, i.e., replacement of catalytic center leucine to iso-leucine on the active site conformation; kinetics and thermodynamics of stability-function of the GA. Moreover, mutation’s effect on the GA was further attributed through evaluation of active site microenvironment by determining the heat of ionization of active site residues.\n\nThe super Koji (A. oryzaecmc1) and its mutant derivative M-60(5) strain (hyper producer of thermostable GA) were obtained from Industrial Enzymes & Biofuels Group, Industrial Biotechnology Division, National Institute for Biotechnology and Genetic Engineering (NIBGE), Faisalabad. The Koji M-60(5) mutant was screened from the mutants of super Koji, which were previously developed by γ-rays treatment [18]. Briefly, the mutants were generated by preparing fresh inoculum ofA. oryzaein six 15 ml falcon tubes and irradiated with Caesium-137 (Cs-137) γ-ray and γ-rays source fitted in gamma cell radiation chamber (Mark-IV Irradiator/Gamma Cell-220). Main stock of mutants (51 variants) was exposed to various level of γ-ray exposure, e.g., 60, 80, 100, 120 & 140 kRad (0.6, 0.8, 1.0, 1.2 & 1.4 kGray). The potato dextrose agar was used to maintain culture at 30 °C as described by Aleem et al. [18].\n\nThe GA from parent and mutant M-60(5) strains was produced in 10L bioreactor. Briefly, six liter of liquid fungal growth medium (LFGM) containing Rafhan starch (2% w/v) with pH 6.5 was prepared. The media was autoclaved for 40 min at 121 °C, 30 psi. Afterwards, the temperature was lowered down to 30 °C and stirred continuously at 150 rpm. The inoculum was grown in 500 ml flask as described [18]. The cell density of inoculum in triplicate was measured and transferred to bioreactor aseptically (0.3% w/v pack cells). The fermenter was run for 72 hrs and aliquots were taken from the bioreactor after every 6 hrs and centrifuged (25,900 ×g) for 10 mints to clear the sample. Afterwards, the total cell mass and GA activity was determined in the samples. The muslin cloth (maximum pore size 2 mm) was used to filter growth medium and the filtrate was centrifuged (25,900 ×g) for 20 min at 4 °C. Finally, the supernatant was lyophilized using Benchtop Freeze Dryers, (Labconco™ FreeZone™, 115V US Models) to concentrate the enzyme as described [19].\n\nThe GA was purified by fractional precipitation. Briefly, the solid ammonium sulphate was added steadily to 1.0 ml of concentrated crude GA to achieve saturation ranging from 10–90% at 4 °C. The GA preparations containing ammonium sulfate were then placed overnight at 4 °C and centrifuged (25,900 ×g) for 20 min. The pallet was discarded and GA activity was checked in the supernatants. Salt concentrations relating to onset and the complete precipitation of GA were selected. Hence, for large scale purification of GA, solid ammonium sulfate was added slowly to achieve 40% saturation and placed overnight at 4 °C and centrifuged as described above. After that pellet was discarded and 75% saturation was achieved by adding more salt. Again, supernatant was discarded and pellet containing GA was kept for next step. Distilled water was added to pellet and dialyzed for removing salt at 4 °C for 24 hrs.\n\nThe freshly grown mycelia of parent and mutant strain M-60(5) were used for genomic DNA extraction, which was extracted as reported [20]. The PCR fragments were obtained by using 5′ATGCGGAACAACCTTCTTTTTTCC3′ and 5′CTACCACGACCCAACAGTTGGG3′ as primers, according to thermo profile of 94 °C for 5 min; 35 cycles of 94 °C for 60 s; 61 °C for 1 min, 30 s; 72 °C for 2 min and 72 °C for 10 min. The amplified DNA fragment was applied on poly acrylamide gel for the gene identification and PCR product was purified by using PCR purification kit (GeneJET PCR Purification Kit, Catalog number: K0701, Fermentas, Thermoscitific®) and sequenced by Macrogen, Republic of Korea.\n\nThe nucleotide sequence alignment of mutant M-60(5) was performed by Clone Manager 10 tool [21] against parent koji strain. The local and global protein alignment tools at European Molecular Biology Open Software Suite (EMBOSS) was used for converting cDNA to amino acid [22]. The InterPro at European Molecular Biology Laboratory- European Bioinformatics Institute (EMBL-EBI) and National Center for Biotechnology Information (NCBI) conserved domain database were utilized for deducing mutant domain information [23]. After domain localization, 3D structure was constructed by Swiss modeling [24] and superimposing of parent and mutant M-60(5) structures was done by PyMol [25] to observe mutational change in active site of the GA encoding protein.\n\nThe GA activity was determined using soluble starch (1% w/v) as substrate. The assay reaction consisting 100 µl enzyme extract, 1.0 ml of soluble starch (1% w/v) in sodium acetate buffer pH 5.0 and incubated at 50 °C for 40 min. The quenched reaction mixture (QRM) in 1.0 ml of Glucose oxidase/Peroxidase kit (Fluitest® GLU, Biocon, Bangalore, India) was used to determine released glucose [20,26]. One unit of GA activity was defined as the amount of GA required to release one μmol of glucose min‒1from soluble starch under defined assay conditions of temperature and pH. The GA activity units were calculated by using the formula as described by Aleem et al. [18].\n\nThe extracellular proteins released were estimated by using Bradford assay and bovine serum albumin was used as a standard [27].\n\nThe purity of purified GA and their subunit molecular mass was determined by 10% sodium dodecyl sulphate denaturing-renaturing polyacrylamide gel electrophoresis (SDS-DR-PAGE). Protein markers from Thermoscientific®ranging in size between 10–180 kDa were used and run as standard. Coomassie brilliant blue R-250 solution (0.1%) was used to stain gel containing enzyme and molecular markers. Apparently pure GAs (0.5 μL of 0.6 mg mL ‒1) was spotted separately on SDS-PAGE gel and incubated at 50 °C for 90. Later, replica copy of the SDS-PAGE gel was cut and stained with Iodine solution [28]. A transparent band appeared after 20 min of staining with blue back ground.\n\nThe purified GA extracted from mutant M-60(5) was checked against various pH using different buffer systems, e.g., Citrate buffer: pH 3.0–6.2, Sorenson’s buffer: pH 5.8–8.0 & Glycine-NaOH buffer: pH 8.6–10.6. Variable temperatures (40–55 °C) were used to find the optimum pH of GA. In addition, Dixon and Webb [29] protocol was used to determine the dissociation constants (pKa1and pKa2) of active site ionizable residues of GA forming ES-complex. Finally, the ΔHIwas calculated by using the equation below:\n\nGA activity was checked against different temperature ranging from 45–60 °C. The assay was conducted at pH 5 (50 mM Na-acetate buffer) for 45 min. The activation energy (Ea) was calculated using Arrhenius plot, while temperature quotient (Q10) was calculated as described [29].\n\nDifferent defined amount of GA with various conc. of substrate (soluble starch) ranging from 0.025% to 0.25% (w/v) were used to determine the Michaelis Menten kinetic constants (Km, Vmax,kcatandkcat/Km) for soluble starch hydrolysis by Koji’s GAs at 50 °C, pH 5. The graphpad prism version 7.04 was used to fit date to non-linear regression. Furthermore, Eyring’s absolute rate equation was used to calculate the thermodynamic parameters for substrate hydrolysis usingformula described by Eyring and Stearn [30].\n\nTo determine irreversible thermal inactivation of Koji’s GAs 15 ml of the parental and mutated GA solutions were taken in falcon tubes and incubated at various temperatures like: 45, 50, 55 and 60 °C in a water bath. The GA aliquots were taken from each sample after regular time intervals, i.e., 0, 5, 10, 15, 20, 25, 30, 35, 40, 45 & 50 min, which were then placed in ice cold water for 30 min for the refolding. Afterwards, the withdrawn GA aliquots were assayed for % residual activity of the GA. The data was fitted to first order plot and rate constants for irreversible thermal inactivation (Kd) of GAs were calculated.\n\nThe activation energy for irreversible thermal inactivation [Ea(d)] of GA was determined by using the Arrhenius plot. Rearranged Erying’s absolute rate equation was applied to determine the thermodynamics of irreversible inactivation of GAs as mentioned above with the difference thatkcatwas replaced withKd(denaturation constant). Moreover, in entalphy change (ΔH*) determination theEawas replaced withEa(d).\n\nThe sample was prperaed by taking equal volume of mutant GAs and 100% chloroform and mixed in a separating funnel. The chloroform was evaporated in rotary evaporator and 2 ml methanol was used to disolve the residues. After that, the mixture was filtered through 0.45 µm nylon membrane and subjcted to analysis by Quadrupole Linear Ion Trap Mass Spectrometer Finnegan LTQ XL hyphenated with Surveyor Plus LC system (LC-MS) (Thermo Fisher Scientific, USA) using the protocal described by [18] and [31] with slight changes. The parameter were set as capillary temperature 335 °C, voltage 45 V, spray voltage 5 kV, sheath gas flow rate 70 and auxiliary gas flow rate 20 arbitrary units. Different aflatoxins ml‒1(B1, B2, G1 and G2) were used as standards.\n\nIn the current study, parent super Koji (A. oryzae) and its mutant derivative M-60(5) strain were screened based on the hyper production of thermostable GA were grown under submerged conditions on raw maize starch in 10L fermenter. The GA produced by mutant M-60(5) was 9.7 U ml‒1which was 2.6 fold higher than the parent (3.6 U ml‒1). Whereas, the specific activity of the mutant was 1.83 fold increased (54.9 U mg‒1) as compare to parent. The GA produced by super koji parent and mutant strains was subjected to single step purification. Fractional precipitation of GAs by ammonium sulfate gave single band on 10% SDS-PAGE, which confirmed the GAs had purity apparently at homogeneity level. The precipitation trend of the mutant enzyme was slightly faster than the control depicting that the γ-rays might has changed the surface of the glubular protein. After purification, the specific activity of the purified GAs from parent and mutant M-60(5) Koji strains was increased to 51.8 and 96.2 U mg‒1, respectively.\n\nThe sequenced data analysis revealed the size of genomic DNA and cDNA of GA genes as 2,039 bp and 2,241 bp, respectively, with the difference of four introns varying in sizes of 49 bp, 52 bp, 45 bp and 56 bp. The open reading frame (ORF) of mutant and parent GA genes consisted of 2,039 bp encoding 612 amino acid residues. The multiple sequence alignment of amino acid sequences from parentA. oryzaeand mutant M-60(5) along withA. nigerandA. Awamorias a reference has shown that γ-rays treatment resulted into a point mutation at nucleotide position 703, where the cytosine was replaced by adenine that resulted in a change of amino acid in catalytic site, i.e., Leu at position 203 into Isoleucine (Fig 1).\n\nAwamori,A. nigar,A.oryzaeparent and Mutant M-60(5) amino acid sequences. The point mutation is highlighted in a red colored rectangle pointed by red triangle at the bottom.\n\nAwamori,A. nigar,A.oryzaeparent and Mutant M-60(5) amino acid sequences. The point mutation is highlighted in a red colored rectangle pointed by red triangle at the bottom.\n\nhttps://doi.org/10.1371/journal.pone.0319261.g001\n\nFurthermore, the 3D structure of parent and mutant M-60(5) GA enzyme showed that replacement of single amino acid has made a slight change in the microenvironment of the active site (Fig 2).\n\n(A) Active site of parent GA with Leucine at 203 position, (B) Active site of Mutant M-60(5) GA with Ile at 203 position and (C) superimposition of the predicted GA model of Parent (green) and the structure of GA from Mutant M-60(5) (yellow). Residues involved in substrate recognition and in catalytic site are shown in magenta and red, while the replacement of Leucine in parent into Isoleucine in mutant are shown in cyan and yellow and indicated with the arrow (white). (D) The schematic diagram to point out the mutation with yellow color.\n\n(A) Active site of parent GA with Leucine at 203 position, (B) Active site of Mutant M-60(5) GA with Ile at 203 position and (C) superimposition of the predicted GA model of Parent (green) and the structure of GA from Mutant M-60(5) (yellow). Residues involved in substrate recognition and in catalytic site are shown in magenta and red, while the replacement of Leucine in parent into Isoleucine in mutant are shown in cyan and yellow and indicated with the arrow (white). (D) The schematic diagram to point out the mutation with yellow color.\n\nhttps://doi.org/10.1371/journal.pone.0319261.g002\n\nSimilar subunit molecular mass (63.1 kDa) of GAs from Parent and M-60(5) strain was found on 10% SDS-DR-PAGE, which was further confirmed by activity staining of GA. Moreover, the accuracy was maintained by a standard curve between molecular mass and Rfvalues of the protein ladder (Fig 3,S1 Fig). The calculated subunit mass was nearly same as 65 kDa predicted from the deduced amino acid sequences of GA mutant M-60(5) and parent strain.\n\nA): Zymographic analysis: Lane-1 Parent GA, Lane-2 M-60(5) GA. B): Lane-3 purified parent GA, Lane-4 M60(5) GA, Lane-5 protein markers [130, 100, 70(Red band), 55, 40, 35, 25 kDa] stained by Coomassie brilliant blue R-250 stain. C): Standard curve for protein markers ladder to determine the subunit molecular mass of GAs produced byA. oryzaestrains.\n\nA): Zymographic analysis: Lane-1 Parent GA, Lane-2 M-60(5) GA. B): Lane-3 purified parent GA, Lane-4 M60(5) GA, Lane-5 protein markers [130, 100, 70(Red band), 55, 40, 35, 25 kDa] stained by Coomassie brilliant blue R-250 stain. C): Standard curve for protein markers ladder to determine the subunit molecular mass of GAs produced byA. oryzaestrains.\n\nhttps://doi.org/10.1371/journal.pone.0319261.g003\n\nThe similar optimum pH (6.0) for GA activity was observed for bothA. oryzaeparent and mutant M-60(5), while optimum pH range with about 70% activity for mutant was 3.4–6.5, whereas for the parental enzyme it was 5.0–6.5. The ionizable groups of active side residues involved in the maximum velocity (Vmax) were determined by applying Dixon plot (Fig 4). The pKa values define as ionization constant which describes the effect of pH on chemical shift or of an enzyme’s activity in a reaction. The present study revealed the pKa1of proton-donating ionizable group of parent and mutant were 4.5 and 4.55, respectively, while pKa2of proton-receiving group for the parent was 6.5 and for mutant M-60(5) was 6.7. Carboxylic acid and imidazole were acting as ionizable groups for acidic and basic limbs, respectively in active site of both the parent and mutated Koji GA at 50 °C.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.g004\n\nFurthermore, effect of γ-rays on the conformation of GA active site was assessed indirectly by evaluating the heat of ionization (ΔHi) of ionizable groups of active site residues (Fig 5). The ΔHiof proton donating residue for parent and mutant GA was 1054 cal mol‒1and 1461 cal mol‒1, while for the proton receiving residue was 6576 cal mol‒1and 6581 cal mol‒1, respectively. Therefore, we considered the conformational change in active site of mutant’s GA might be due to the π MO ionization of aromatic histidine and NH2nitrogen lone pair ionization of Glu/Asp residues.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.g005\n\nThe GA fromA. oryzaeparent and mutant M-60(5) exhibited similar optimum temp, i.e., 50 °C with optimum temp range of 45–55 °C (~80% of optimal activity). The working ability of an enzyme at elevated temperature is referred as its thermophilicity, while the resistance against unfolding at higher temperature is termed as thermostability of an enzyme. The activation energy (Ea) determined by Arrhenius plot for the soluble starch hydrolysis for parent GA was 50.4 kJ mol‒1, while for the mutant M-60(5) it was 46.9 kJ mol‒1(Fig 6). Lower energy requirement by the mutant GA indicated that it was better as compared to the parent GA. Hence, we considered the mutation due to γ-rays treatment might have changed the microenvironment of the active site, resulting into improved conformation, which made the mutant M-60(5) GA more efficient in making the transition-state complex (ES*).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.g006\n\nEffect of mutation on the Michaelis Menten kinetics constants (Km, Vmax,kcat&kcat/Km) of soluble starch hydrolysis by the Koji GAs were analyzed by fitting the data to non-linear regression using the Graphpad Prism software (Fig 7). The kinetics of soluble starch hydrolysis by mutant GA was drastically improved due to replacement of Leu203 with Ile203. TheKm, which is the measure of binding affinity of substrate with the enzyme, of mutant M-60(5) GA for soluble starch hydrolysis at 50 °C, pH 5.0 was lower (0.06 mg ml‒1) than the parental GA having 0.17 mg ml‒1. Hence, the γ-rays induced mutation in Koji mutant M-60(5) has changed the conformation of active site and made it 2.8 folds more efficient to make the ES complex (Table 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.g007\n\nTheKcat(turn over) catalytic events performed by active site of mutated GA were 1.7 fold higher than the parent GA, i.e., 118 s‒1(Table 1). Furthermore, substrate specificity constant (kcat/Km) of mutated GA was 1899 and was 4.7 fold higher than control. Since it gives information about substrate specificity when its concentration is extremely low (<<Km), the results pointed towards the alternation in active site conformation. We concluded that mutation in active site residues made the mutant GA highly specific for starch hydrolysis. The catalytic efficiency of GA produce ofA. oryzaemutant M-60(5) was extremely higher by havingKmof GA (Km=  0.062 mg ml‒1).\n\nThe Gibbs free energy for soluble starch hydrolysis (ΔG*) of M-60(5) GA was decreased as compared to parental GA, hence, confirmed that it required lower amount of functional energy to convert the transition complex (ES*) into products. Moreover, reduction in ΔH* of mutated GA with 3.492 kJ mol‒1also confirmed that it required lower energy to make the activated transition complex (ES*). On the other hand, ΔS* for starch hydrolysis of mutant GA was decreased, which confirmed that the activation in substrate hydrolysis was not entropically driven (Table 1).\n\nThe thermostability of mutant GA was increased about two fold at 55 °C than the parental enzyme, while at 45 °C & 50 °C a modest increase in the stability was observed (Fig 8). The increase in thermal stability of M-60(5) GA was due to higher Gibbs free energy, which was increased with a difference of 3.43 kJ mol‒1. The higher free energy helped the mutated GA to resist against thermal unfolding of its transition state (U*) into an inactive enzyme.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.g008\n\nMoreover, activation energyEa(d)to make the transition state ‘U*’ of mutant GA was also higher than the parental one, pointing towards higher stability of the mutated GA (Fig 9). The change in entropy (ΔS*) of mutated GA at temperatures ranging from 45°C–60°C was higher than the parental GA, which indicated towards the increase in disorder of its active site conformation (Table 2). It was concluded that the increase in thermostability of mutant GA was due to higher ΔG* and was not entropically driven.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.g009\n\nThe Mutant M-60(5) GA was analyzed for toxin analysis on LC-MS against standard and already reports control values. It was confirmed that the M-60(5) GA did not produce any aflatoxins (Fig 10).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319261.g010\n\nA. oryzaeis used in food processing industries for centuries. Therefore, numerous attempts have been made to improve theA. oryzaestrains for making process more feasible. Various methods are used for strain improvement, e.g., random mutagenesis [18]. Hence, in the current study, point mutation, i.e., replacement of catalytic center leucine to iso-leucine on the active site conformation was introduced inA. oryzaefor improving catalytic efficiency and thermostability of Glucoamylase (GA) by γ-rays induced random mutagenesis.\n\nIn the current study, the GA was produced 2.6 fold higher (9.7 U ml‒1) by mutant M-60(5) as compared to parent (3.6 U ml‒1). Whereas, the specific activity of the mutant was 1.83 fold increased (54.9 U mg‒1) as compare to parent. The increase in GA enzyme activity inA. oryzaeby γ-rays mutagenesis is confirmed in an already reported study [32]. The mutant M-60(5) strain produces much higher GAs than already reported strains, i.e., the maximum units of GA under optimum conditions are reported as 3.5 U ml‒1fromA. wentii[33], 8.23 U mL‒1fromA. Oryzae[34] and 5.9 U mg‒1fromA. Awamori[35]. The crude GAs fromA.oryzaeparent and Mutant M-60(5) were purified by ammonium sulphate precipitation as described [26,36,]. After purification, the specific activity of the purified GAs from parent and mutant M-60(5) Koji strains was increased to 51.8 and 96.2 U mg‒1, respectively which are much higher than the specific activity of purified GA fromA. niger, i.e.,16.2 U mg‒1by three steps purification [17], however the specific activity of purified GA fromA. fumigatuswas reported as 94 U mg‒1[37].\n\nIn addition, the multiple sequence alignment of amino acid sequences from parentA. oryzaeand mutant M-60(5) along withA. nigerandA. Awamorias a reference has shown that γ-rays treatment resulted into a point mutation at nucleotide position 703, where the cytosine was replaced by adenine that resulted in a change of amino acid in catalytic site, i.e., Leu at position 203 into Isoleucine. In previous studies, a single replacement of leucine to isoleucine in active site has drastically effect the enzyme activity of Taq polymerase by converting it into highly cold sensitive enzyme [38], whereas as a result of mutagenesis, a single conserved amino acid replacement, i.e., leucine to isoleucine has affected the ‘g’ protein signals mechanism [39]. Hence, based on the above report we concluded that the replacement of leucine203 into isoleucine in M-60(5) Koji GA might have drastically changed the conformation of its active site, resulting into an efficient and stable mutant GA enzyme. We believe that improvement in catalytic efficiency of GAs in mutant was linked with the change in a Leu203 to Ile203 at active site of GA Mutant M-60(5).\n\nIn the present study, the molecular mass of GAs was determined and fund subunit molecular mass (63.1 kDa) of GAs from Parent and M-60(5). Moreover, the accuracy was maintained by a standard curve between molecular mass and Rfvalues of the protein ladder. Mutant M-60(5) showed almost similar molecular mass as of GA fromAspergillus oryzaefrom Luzhou-flavour Daqu [40] andA. Fumigatus[37]. Already reported studies supports our finding of similar subunit molecular mass of parent and mutant strains fromAspergillus oryzae[41] and fromA. flavus[42]. These findings are in accordance with other published results, where the GA fromA. flavonusshown protein size of 78 kDa which varied from the calculated size of 55.1 kDa [34].\n\nFurthermore, optimum pH range with showing 70% activity for mutant was between 3.4–6.5. The more acidic pH range of mutant GA indicated that the γ-rays mediated point mutation has slightly changed the microenvironment of the active site of mutant GA. Previous studies showed the fungal GA remains more active at acidic pH [43,44]. The maximum catalytic activity of this enzyme has also been reported at pH 5 to 6, whereas inA. Nigerthe optimum reported as pH 4.8 [45]. The present study revealed the pKa1of proton-donating ionizable group of parent and mutant were 4.5 and 4.55, respectively, while pKa2of proton-receiving group for the parent was 6.5 and for mutant M-60(5) was 6.7. The difference in pKa values of acidic and basic limbs of the active site residues of mutated GA confirmed about the changed configuration of the active site due to random mutagenesis resulting into more efficient catalytic activity of mutant M-60(5). Literature confirms that the change in microenvironment around the catalytic domain resulting into improvement in catalytic efficiency and protein stability at low pH [46]. The reported ionizable groups values of amino acids located in proteins indicated the presence of glutamic/aspartic acid as the proton donating residue, while histidine as the proton receiver [29].\n\nThe ΔHiof proton donating residue for parent and mutant GA was 1054 cal mol‒1and 1461 cal mol‒1, while for the proton receiving residue was 6576 cal mol‒1and 6581 cal mol‒1, respectively. Similar findings regarding proton donating residues were presented by [15], where three Glutamic acid (Glu) and one Aspartic acid (Asp) residues participated as the electron donor in GA active site. Effect of temp on pKa1& pKa2and enthalpy or heat of ionization (ΔHi) of active site residues ionizable groups was determined as described by Dixon and Web [29] (Fig 5). The amino acid composition of mutant’s active site was not changed, however, the increase in ΔHiof proton donating (407 cal mol‒1) and receiving (5 cal mol‒1) residues evidenced about the change in conformation of active site. Dehareng and Dive [47] evaluated the ionization energies (IE) as a function for the conformation of α-L-amino acids and optimized three to five conformations for the arginine, lysine, isoleucine, tyrosine and tryptophan in their study.\n\nSimilarly, the GA fromA. oryzaeparent and mutant M-60(5) exhibited similar optimum temp, i.e., 50 °C with optimum temp range of 45–55 °C (~80% of optimal activity), which is considered as much higher optimal activity at given range than already reportedA. flavus, which showed a decline in optimal activity above 50 °C, pH 5.5 [42]. The optimum temp of GA for soluble starch was reported as 55 °C fromGymnoascella citrina[44], whereas, the purified intracellular GA fromA. tritic iWZ99 gave temp optimum of 45 °C [48].\n\nMichaelis Menten kinetics constants (Km, Vmax,kcat&kcat/Km) of soluble starch hydrolysis by the mutant and parent Koji GAs were determined in the current study. TheKmof mutant M-60(5) GA for soluble starch hydrolysis at 50 °C and pH 5.0 was lower (0.06 mg ml‒1) than the parental GA having 0.17 mg ml‒1. Previous studies reported lesser km values of naïve and modified enzyme, i.e., 0.34 and 0.29, respectively [49] and 2.1mg/ml of glucoamylase GA-LZ2 than the km values reported in this study [40]. TheKcat(turn over) catalytic events performed by active site of mutated GA were 1.7 fold higher than the parent GA, i.e., 118 s‒1. Moreover, turnover of the mutant GA was higher than that of recently reported novel mesophilic GA having 67.15 s‒1[48] and GA ofA. oryzaewith 20.3s‒1from Luzhou-flavour Daqu [40]. We believed that the mutation has altered the conformation of active site of mutant GA and made it more flexible and efficient to convert the transition ES * -complex into products. Furthermore, substrate specificity constant (kcat/Km) of mutated GA was 1899 and was 4.7 fold higher than control. Similar findings are reported in literature that γ-rays based mutagenesis ofA. nigersignificantly improved the kinetic properties of GAs from mutant strains for starch hydrolysis [17]. Similar trend in kinetic parameters due to the γ-rays mediated mutagenesis inA. nigerfor lignocellulose hydrolysis by β-glycosidase was reported by Javed et al [58]. In another report Karim et al. [34] reportedKmandVmaxfor soluble starch as 5.84 mg ml‒1and 153.85 U mg‒1respectively for GAs fromA. flavusNSH9. The current report indicates that mutant M-60(5) is highly substrate specific as compare to the already reported studies.\n\nIn addition, the catalytic efficiency of GA produce ofA. oryzaemutant M-60(5) was extremely higher than the salt tolerantA. flavus, which hadKmof 0.72 mg ml‒1withVmaxof 12.48 μ mol min‒1mg‒1. TheKmof mutated GA (Km=  0.062 mg ml‒1) highlighted that its affinity to soluble starch was about 11.6 fold higher, while maximum velocity (Vmax=  112 μmol min‒1mg‒1) was about 9.0 fold higher than that ofA. flavusGA [42]. Hence, in comparison to previous studies, the kinetic properties of GA from mutant M-60(5) exhibited excellent catalytic activity in terms of starch hydrolysis that make efficient use of enzyme in industry. Similarly, we already reported γ-rays mutagenesis-based improvement in kinetic properties on thermodynamics of starch hydrolysis, where ΔH* (kJ mol‒1), ΔG* (kJ mol‒1), ΔS* (J mol‒1K‒1) for parent and mutant were 41.50, 46.12; 65.69, 63.62; ‒72.65, ‒52.53, respectively [17]. Hence, we concluded that the mutated GA was thermodynamically more efficient in conversion of soluble starch into products.\n\nIn the current study, the thermostability of mutant GA was increased about two fold at 55 °C than the parental enzyme, while at 45 °C & 50 °C a modest increase in the stability was observed (Fig 8A, B). The GA fromA. brasiliensisshowed half-life of 22 min at 55 °C [50], while half-life of mutant GA ofA. awamoriat 55 °C was 48 min [51], which is less than that of mutant GA M-60(5). Previously, it was reported that γ-rays mutagenesis has affectedA. nigerin terms of thermodynamic parameters for cellobiose hydrolysis and improved the thermal stability of mutant enzyme. Where energy of activation (Ea(d)) of parent strain was 274 kJ mol‒1, while for mutant strain it was 240 kJ mol‒1. The ΔH* reported for mutant was as 237.02 kJ mol‒1, while for parent was 271.44 kJ mol‒1, whereas ΔG * was 105.67 kJ mol‒1for mutant and 105.49 kJ mol‒1for parent. The change in entropy (ΔS*) for mutant was 407.90 J mol‒1K‒1, while for parent 515.35 J mol‒1K‒1[52].\n\nRandom mutagenesis ofA. oryzaeby γ-ray treatment simultaneously enhanced the productivity, catalytic efficiency and thermostability of GA. The improvement in stability and function of GA was due to a point mutation in active site of GA encoding gene, resulted in replacement of amino acid Leu to Ile at position 203. Hence, the mutation changed the microenvironment of GA active site, resulting into alteration in active site conformation of mutant M-60(5) GA. The changed pKa values, ΔHiof acidic & basic limbs of the active site residues of mutated GA evidenced about the alteration of active site conformation. We concluded conformational change in active site of mutant GA was due to π MO ionization of aromatic histidine and NH2nitrogen lone pair ionization of Glu/Asp residues. Thermostabilization of mutant GA was due to higher ΔG* . We concluded stability-function of enzymes might be simultaneously enhanced by strain improvement through γ-rays treatment. The mutated GA due to its high catalytic efficiency and thermostability proved that it has great potential for application in food industry such as beverages, baking and starch saccharification.\n\nhttps://doi.org/10.1371/journal.pone.0319261.s001\n\n(PDF)\n\nWe are thankful to Mr. Zubair Nawaz Chattha, the Chief Executive of Gourmet Pvt. Limited, Pakistan and Ms. Fatima Nawaz, the Director of QuinTech Center for Applied Sciences (QCAS), Lahore for providing technical support for the research work. Also, Mr. Ghulam Ali Waseer (late) is gratefully acknowledged for providing his assistance toward the conducted research.\n\nThe final version of the submitted manuscript has read and approved by all authors. It is hereby confirmed that this manuscript is in original form and not submitted for publication elsewhere.",
    "category": "physics"
  },
  {
    "title": "Identification of visible and near-infrared signature peaks for arboviruses andPlasmodium falciparum",
    "authors": "Brendon Goh, Ricardo J. Soares Magalhães, Silvia Ciocchetta, Wenjun Liu, Maggy T. Sikulu-Lord, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321362",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321362",
    "content": "Arbovirus and malaria infections affect more than half of the world’s population causing major financial and physical burden. Current diagnostic tools such as microscopy, molecular and serological techniques are technically demanding, costly, or time consuming. Near-infrared spectroscopy has recently been demonstrated as a potential diagnostic tool for malaria and Dengue virus and as a screening tool for disease vectors. However, pathogen specific absorption peaks that allow detection of these infections are yet to be described. In this study, we identified unique visible and near-infrared peaks from existing laboratory strains of four major arboviruses including Barmah Forest virus, Dengue virus, Ross River virus, Sindbis virus andPlasmodium falciparum. Secondly, to determine the diagnostic ability of these peaks, we developed machine learning algorithms using artificial neural networks to differentiate arboviruses from media in which they were grown. Signature peaks for BFV were identified within the visible region at 410, 430, 562 and 588 nm and the near-infrared region at, 946, 958, 1130, 1154 and 1780 nm. DENV related peaks were seen at 410nm within the visible region and 1130 nm within the near-infrared region. Signature peaks for Ross River virus were observed within the visible region at 410 and 430 nm and within the near-infrared region at 1130 and 1780 nm, while Sindbis virus had a prominent peak at 410 nm within the visible region. Peaks at 514, 528, 547, 561, 582, and 595 nm and peaks at 1388, 1432, 1681, 1700, 1721, 1882, 1905, 2245, 2278, 2300 nm were unique forP. falciparum. Near-infrared spectroscopy predictive sensitivity defined as the ability to predict an arbovirus as an infection was 90% (n=20) for Barmah Forest virus, 100% (n=10) for Ross River virus and 97.5% (n=40) for Dengue virus, while infection specificity defined as the ability to predict media as not-infected was 100% (n=10). Our findings indicate that spectral signatures obtained by near-infrared spectroscopy are potential biomarkers for diagnosis of arboviruses and malaria.\n\nCitation:Goh B, Soares Magalhães RJ, Ciocchetta S, Liu W, Sikulu-Lord MT (2025) Identification of visible and near-infrared signature peaks for arboviruses andPlasmodium falciparum. PLoS ONE 20(4):\n           e0321362.\n        \n        https://doi.org/10.1371/journal.pone.0321362\n\nEditor:Raquel Inocencio da Luz,, Institute of Tropical Medicine: Instituut voor Tropische Geneeskunde, BELGIUM\n\nReceived:September 23, 2024;Accepted:March 5, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Goh et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and itsSupporting Informationfiles.\n\nFunding:This research was funded by NHMRC (National Health and Medical Research Council) (APP1159384) awarded to M.T.S.-L., Advance Queensland Industry Research Fellowship (AQIRF2018019) awarded to M.T.S.-L. and the University of Queensland earmarked Ph.D. scholarship awarded to B.G. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nArboviruses persist in nature through a life cycle involving a vertebrate host, an organism that carries the virus and an infected arthropod, usually mosquitos or ticks [1]. Vector borne diseases have been on the rise due to increased geographical distribution and abundance of arthropod vectors mainly because of concurring factors such as climate change, migration and urbanization [2]. For instance, infection due to Dengue virus (DENV) is now considered the most common vector-borne infection globally as it affects more than half of the world’s population [3]. In 2023, over 6.5 million cases of DENV were reported, resulting in around 6,800 fatalities. The highest incidence was observed in areas of South America and Southeast Asia [4]. Malaria is a mosquito-borne disease caused by thePlasmodiumparasite which is transmitted to humans through bites of infected femaleAnophelesmosquitoes. In 2023, an estimated 263 million malaria cases and 597,000 malaria related deaths were reported by the World Health Organisation highlighting malaria as a major public health concern [5]. Traditionally, malaria is diagnosed using microscopy and Giemsa-stained blood smears [6]. However, with a limit of detection of >50 parasites/μL of blood, it requires a well-trained microscopist [7]. Rapid diagnostic tests are also common for malaria diagnosis because they are very easy to use and do not require qualified personnel, but their sensitivity and specificity is low in detecting low parasitaemia [8,9].\n\nCurrent diagnosis of arboviruses include molecular methods such as reverse transcriptase-polymerase chain reaction (RT-PCR) [10] and serological techniques such as Enzyme-linked immunosorbent assay (ELISA) [11,12]. Molecular methods are the most accurate and sensitive. For example, RT-PCR for DENV has detection limits that vary between 10–100 copies/reaction depending on the DENV serotype being tested. ELISA assay for detection of DENV-2 specific antibodies has been reported to be 90% (n=20) specific and 100% sensitive (n=20) in 40 human serum samples [13]. Despite high sensitivity, these methods are restricted to the laboratory settings, can be time consuming and costly for programmatic diagnosis and surveillance purposes. Molecular diagnosis techniques for malaria such as Polymerase Chain Reaction (PCR), quantitative-PCR, nested PCR and ELISA have been developed [14–16] but they are time consuming, costly and require trained personnel. Rapid diagnosis tests for malaria are based off the detection for HRP2 antigens as recommend by the World Health organisation [17]. In a recent study, rapid diagnosis test (CareStart™ Malaria HRP2 AccessBio kit) and microscopy both failed to detect more than 40% of infections identified by varATS qPCR [18]; indicating the necessity of novel tools to ensure accurate and prompt diagnosis of clinical malaria cases.\n\nNear-infrared spectroscopy (NIRS) is a potential novel diagnostic/surveillance tool for arboviruses. It involves the interaction of near-infrared light with biological samples to produce a reflectance spectrum [19]. Based on chemical and structural differences between biological samples, unique spectra are produced. The spectra reflect the amount and type of biochemical composition of the sample and can be used to typify those samples. NIR spectra can provide insights into functional groups of samples, such as C–H, O–H, and N–H. Any molecule that contains hydrogen will exhibit a detectable NIR spectrum, making a wide variety of biological substances appropriate for NIR analysis [20]. NIRS can therefore be used as a biomarker for biological samples. Moreover, NIRS is rapid, non-invasive, and does not require skilled personnel to operate, enhancing its effectiveness in the field and in areas lacking scientific equipment.\n\nTo date, four studies have shown the ability of NIR technique to detect DENV, Chikungunya,Wolbachiaand Zika inAe. aegyptimosquitoes with accuracies above 90% [21,22]. However, only one study has demonstrated absorbance frequencies in the visible region for arboviruses. Firdous and colleagues reported that NIR peaks at 533 and 580 nm are indicative of the presence of the DNA mixture of DENV2 and DENV3 in human blood samples [23]. The application of NIRS for the detection of theplasmodiumparasite has been reported in several studies [24–26]. These studies identified prominent peaks at 650 nm (mice whole blood) [24], 930–1660 nm (human skin) [25] and 1503–2306 nm (human whole blood) [26]. In this study, we identified NIR biomarkers for Barmah Forest virus (BFV), DENV, Ross River virus (RRV), Sindbis virus (SINV) and purifiedP. falciparum. These signature peaks provide a valuable foundation for diagnosing arboviruses and malaria using NIRS, serving as a basis for future analysis of human or vector samples.\n\nDENV prototype strains DENV-1 Hawaii (1944), DENV-2 NGC (1944), DENV-3 H-87 (1956) and DENV-4 H241 (1956) were used in this study. DENV was propagated in C6/36Aedes albopictuscells, maintained at 28°C in RPMI and supplemented with 10% FBS and 1% PSG. Following three passages in C6/36 cells, virus stocks were concentrated using Ultracel-100k filters (Amicon, Tullagreen, Cork Ireland) [27] and frozen at -80°C until further use.\n\nBFV QML and BFV WEN 1631 and RRV QML1 strain (GenBank No. GQ433354) were used in this study. The virus strains were passaged three times in Vero cells, maintained at 37°C in RPMI and supplemented with 10% FBS and 1% PSG. Following three passages in Vero cells, virus stocks were concentrated using Ultracel-100k filters (Amicon, Tullagreen, Cork Ireland) [27] and frozen at -80°C until further use. One vial of the viral stocks was thawed to determine virus titre using 50% tissue culture infectious dose (CCID50/ml) on Vero cells as described [28]. Briefly, virus stocks were 10-fold serially diluted and 100 µL of diluted virus was inoculated onto monolayers of Vero cells grown in 96 well plates in cell culture media and maintained at 37°C, 5% CO2. Ninety-six hours later, cells were fixed with 3.7% formaldehyde, stained with 1% crystal violet for 1 hour, washed in tap water and dried. The cell culture infectious dose 50% was determined from titration endpoints as described elsewhere [29] and expressed as the Vero cell CCID50/mL.\n\nSINV strain (SINV 18953) was propagated in C6/36Ae. albopictuscells, maintained at 28°C in RPMI and supplemented with 10% FBS and 1% PSG. Following three passages in C6/36 cells, virus stocks were concentrated using Ultracel-100k filters (Amicon, Tullagreen, Cork Ireland) and frozen at -80°C until further use. One vial of the viral stocks was thawed to determine virus titre by 50% tissue culture infectious dose (CCID50/ml) on Vero cells as described by Sudeep et al [30]. Briefly, virus stocks were serially diluted 10-fold and 100 µL of diluted virus was inoculated onto monolayers of Vero cells grown in 96 well plates in RPMI 1640 supplemented with L-glutamine, 5% FBS, 1% PSG and maintained at 30°C, 5% CO2. After 4 days of incubation, cells were fixed with 3.7% formaldehyde, stained with 1% crystal violet for 1 hour, washed in tap water, dried, and counted. The CCID50/ml were calculated according to published Reed-Muench method [31].\n\nVirus free cell culture media used in this study consisted of sterilised Roswell Park Memorial Institute Medium (RPMI), 1640 Medium (Sigma Life Sciences, USA) with 10% heat-inactivated fetal bovine serum (FBS) (Thermo Fisher Scientific, USA) and 1% Penicillin-Streptomycin Glutamine solution (PSG) (Thermo Fisher Scientific, USA).\n\nAll arboviruses used were passaged in 3 separate batches. Samples from each batch were used as a single biological replicate (Table 1). Virus stocks were titrated using a modification of the Enzyme-linked immunosorbent assay procedure of Broom et al. [32]. Briefly, virus stocks and samples were serially diluted 10-fold and inoculated onto monolayers of C6/36 cells grown in C6/36 cell culture media which consisted of RPMI, 1640 Medium (Sigma Life Sciences, USA) with 5% heat-inactivated FBS (Thermo Fisher Scientific, USA) and 1% PSG (Thermo Fisher Scientific) and maintained at 30°C, 5% CO2. After 7 days of incubation, cells were fixed in acetone: methanol (1:1) for 1 hour at 4°C. Plates were air-dried and antigen was detected using a cocktail of anti-flavivirus monoclonal antibody hybridoma supernatants; 4G2 [33] 6B-6C1:3H5 [34], at a ratio of 1:1:1, followed by horseradish peroxidase (HRP-) conjugated goat anti-mouse polyclonal antibody (DAKO, Carpinteria, CA, USA) (1:2000 in PBS-Tween 20). Antibodies bound to the cell mono-layers were detected by the addition of 3,3’,5,5’-tetramethylbenzidine liquid substrate system for membranes (Sigma-Aldrich). The CCID50 was determined from titration endpoints as described elsewhere [29] and expressed as C6/36 CCID50/mL. This experiment was repeated three times at three separate time points to create three independent biological replicates (Table 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321362.t001\n\nFive biological replicates of serum samples each consisting of 150 mL of pooled human serum samples were obtained from Australian Red Cross Lifeblood using human ethics protocol approved by The University of Queensland (Ethics approval number 2020001077, from 10 July 2020 to 31 August 2023). Participants were recruited beginning on 8 June 2023 to 22 June 2023. Following collection from donors, all samples were routinely tested for Hepatitis B and C, HTLV I/II, Syphilis HIV 1/2, and ABO/Rh antigens. Human serum was stored at -25°C for 3–4 days prior to running the described experiments to preserve proteomic profile integrity and was thawed fully at room temperature before use. All samples supplied by the Australian Red Cross Lifeblood were fully anonymized before handover.\n\nBase media prepared forP. falciparum Welchwas ATCC medium 2196 - Malaria medium (American Type Culture Collection, USA) which consist of a sterilized mixture of RPMI-1640 (Sigma R-0883), HEPES buffer (1 M), Gentamicin (50 mg/ml), L-glutamine (100 mM), Hypoxanthine (100 mM), Glucose (20%) and NaOH (1 N). The mixture was sterilised by filtering through 0.22 μM Millex® filter (Millipore, USA). Complete medium was made by adding the heat-inactivated (at 56°C for 1 hour) human serum to 10% (vol/vol) to the base medium and was used to culture parasites as previously described [35].P. falciparum Welchstrain FCR-3/FMG (American Type Culture Collection, USA) had an initial concentration of 255 parasites/mL. The base media alone was used as the control.\n\nLabSpec 4 near-infrared spectrometer (ASD Malvern Panalytical, Malvern, United Kingdom) was used to scan all samples. Details of the spectrometer used is published elsewhere [36]. RS3software (Malvern ASD Panalytical) was used for NIRS spectra collection. Baseline calibration and optimization were done at the beginning of each experiment and every 30 minutes by scanning an empty space on the glass slide placed on a white Spectralon plate. Five µL of each arbovirus,P. falciparum, and respective media were aliquoted onto glass microscope slides to obtain a sample. A total of 10 technical replicates were scanned for each biological replicate of arbovirus,P. falcipariumand media. Samples were scanned at approximately 2 mm from the light source by pointing the probe down to the centre of the sample for approximately 3–5 seconds. Full visible and NIR spectra was collected in the 350–2500 nm range of which 350–750 nm and 751–2500 nm belong to the visible light and NIR light regions, respectively.\n\nReflectance spectra were converted to absorbance using the formular Log. All spectral signatures were converted from txt to csv in ViewSpecPro software (Analytical Spectral Devices Inc, Boulder, CO, USA). To identify arbovirus andPlasmodiumpeaks of importance, raw spectra was converted into 2ndderivative using the Savitzky–Golay [37] with 2ndorder smoothing by combining 10 neighbouring data points. 2ndderivative spectra graphs were visualised in GraphPad Prism 9 (GraphPad Software, Inc, California, USA). In the 2ndderivative graph, the difference between pathogen positive and negative samples is shown and unique absorption peaks for pathogens are identified. Model screening and data analysis were conducted in JMP Pro 16 software on raw data (SAS Institute Inc., Cary, NC, USA). Spectra of DENV1, DENV2, DENV3 and DENV4 were combined into a single identifier referred to as DENV. Likewise, spectra of BFV QML strain and BFV WEN 1631 strain were combined into a single identifier referred to as BFV. This is because no differences were observed between strains of these arboviruses (Table S1). SINV data was analysed separately due to spectral outliers that misclassified other arboviruses. Unsupervised learning using principal component analysis and discriminant analysis (PCA-DA) were conducted on all raw spectra as an initial differentiation step for visualisation.\n\nThe spectral data was first split into two groups: model training/validation (consisting of 16 biological replicates) and an independent test set (consisting of 8 biological replicates). The training (T), validation (V) and test sets (t) were separate biological replicates grown and analysed at different time points. Appropriate machine learning algorithm for each raw spectral data underwent model screening where the following model types were screened for preliminary accuracy: Bootstrap Forest [38], Naïve Bayes [39], Artificial Neural Network (ANN) [40] and Support vector machines [41] (Table S2). ANN produced the most accurate preliminary results and was therefore selected for further analysis. Spectral signatures from 410 to 2140 nm were used. This region was exclusive of spectral noise between 350–409 and 2141–2500 nm and NIR transition filters at 995–1100 and 1795–1810 nm. Spectra were used as model predictors whereas infection status (positive or negative) was used as the response factor. ANN model was developed using random K-Fold cross-validation (n=5 samples). The Neural Networks consisted of one layer with three TanH activation nodes boosted at a learning rate of 0.1 iteratively for 100 tours. Models were built to differentiate arboviruses from media. A summary of sample distribution between training, validation and independent test set is shown inFig 1.\n\nThe flow of information from data collection to analysis including the number of samples used for training, validation and test sets. Training and validation sets were split based on biological replicates. ‘T’ represents training set, ‘V’ represents validation set and t represents the test set.\n\nThe flow of information from data collection to analysis including the number of samples used for training, validation and test sets. Training and validation sets were split based on biological replicates. ‘T’ represents training set, ‘V’ represents validation set and t represents the test set.\n\nhttps://doi.org/10.1371/journal.pone.0321362.g001\n\nSignature peaks for DENV are seen at 410 nm within the visible region and at 1130 nm within the NIR region. A DENV peak is observed to have lower absorbance than media at 410 nm but a higher absorbance value than media at 1130 nm (Fig 2A).\n\nPeaks of importance are shown with black arrows.\n\nPeaks of importance are shown with black arrows.\n\nhttps://doi.org/10.1371/journal.pone.0321362.g002\n\nA total of 10 prominent peaks were identified for BFV. These prominent peaks are within the visible region at 410, 430, 562 and 588 nm and within the NIR region at 946, 958, 1130, 1154, 1287–1331 and 1780 nm. Absorbance peaks within the visible region at 430 and 588 nm and within the NIR region at 946, 1130 nm have higher absorbance values than media while peaks at 410 and 562 nm in the visible region and 958, 1154 and 1780 nm in the NIR region have lower absorbance values than media (Fig 2B).\n\nProminent peaks for RRV were identified at 410 and 430 within the visible region and at 1130, 1154, 1447, 1464 and 1780 nm within the NIR region. Overall, RRV was observed to have 7 prominent peaks (Fig 2C).\n\nThe 2ndderivative NIR spectra of SINV 18953 showed prominent peaks at 410, 1447 and 1463 nm. SINV had the lowest number of specific prominent peaks (3 peaks) compared to the other arboviruses (Fig 2D).\n\nFour pathogen related wavelengths fell within the visible light region. Two of which (410 and 430 nm) are within the blue visible region and the other two (562, 588 nm) are seen within the green visible light spectrum. BFV prominent peaks at 946 and 958 nm were observed in the 3rdovertone region. Three pathogen related prominent peaks (1130, 1154 and 1780 nm) were seen in the 2ndovertone region. Peaks at 410, 430, 1130 and 1780 nm were observed in BFV, DENV, RRV and SINV. Only one signature peak was identified for SINV which fell within the visible light region, the single signature peak was also identified in all the other arboviruses. Based off this result, we excluded SINV in the analysis. A summary of unique peaks identified for all arboviruses relative to published literature is shown inTable 2.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321362.t002\n\nFor initial differentiation of BFV, DENV, RRV and Vero media, we attempted to use PCA-DA using the 350–2500 nm region. PCA-DA differentiated arboviruses and media with a misclassification rate of 15.1% and R square value of 0.676 (n= 430) (Fig 3). The canonical plot grouped DENV and RRV more closely with almost half the data points overlapping. DENV had slight overlaps with Vero media. BFV was distinct from all other tested categories.\n\nCrosses in the plot represent the average while larger circles represent the standard deviation of data points.\n\nCrosses in the plot represent the average while larger circles represent the standard deviation of data points.\n\nhttps://doi.org/10.1371/journal.pone.0321362.g003\n\nTo identify if supervised machine learning could differentiate arboviruses from Vero media samples using raw spectra, a model using ANN was applied on the raw spectra between 410–2140 nm (Table 3). Overall, the ANN model differentiated BFV, DENV, RRV and Vero media from each other with an R square value of 1 for both training (n=128) and validation (n=32) set (Table 3). The independent test set consisting of 80 NIR spectra was predicted using the training model. Overall, positive predictive rate defined as the proportion of samples predicted as positive out of those that were truly positive was 100% indicating all infected samples were predicted as infected. The negative predictive rate defined as the proportion of samples predicted as negative out of all those that were truly negative was 76.9% (n=13) meaning some negative samples were predicted as postive. Specificity defined as the proportion of samples predicted as negative out of all negative samples was 100% (n=10) meaning all media samples were predicted as not infected. A summary of technical replicates for the training, validation and test set is shown inTable 3. And a summary of positive prediction rate, negative prediction rate, sensitivity, and specificity of BFV, RRV and DENV for the test set is shown inTable 4.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321362.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321362.t004\n\nUnique NIR peaks ofP. falciparumwere observed in the 350–650nm visible region and 1450, 1960 nm NIR region (Fig 4A). Relative to media, a unique peak forP. falciparumwas observed at 440 and 543 nm. P. falciparumalso showed a higher absorbance than media at both 1450 and 1960 nm. To further investigate the spectra, we plotted the 2ndderivative of the average spectra ofP. falciparum. Peaks related to pureP. falciparumwere seen at 514, 528, 547, 561, 582 and 595 within the visible region 1388, 1432, 1681, 1700, 1721, 1882, 1905, 2245, 2278 and 2300 nm within the NIR region (Fig 4B). Some of the wavelengths observed to be unique toP. falciparumwere found within the visible light region at 514, 528, 547, 561, 582 and 595 nm. The highest peaks forP. falciparumin this region were at 582 and 595 nm (Fig 4B). Comparatively, no peaks were observed for media used to growP. falciparumin the visible region.\n\nPeaks of importance are indicated with black arrow.\n\nPeaks of importance are indicated with black arrow.\n\nhttps://doi.org/10.1371/journal.pone.0321362.g004\n\nSix peaks observed forP. falciparumbelong to the visible light region, two within the NIR 2ndovertone region, five in the 1stovertone region and 3 in the combination band region. The majority of the peaks identified belong to the visible light region and the 1stovertone region (Table 5).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321362.t005\n\nThe aim of this study was to identify visible and NIR peaks that are unique to DENV, RRV, BFV SINV andP. falciparumwhich could serve as potential diagnostic biomarkers for these pathogens. A total of 9 peaks of interest were identified for these arboviruses (Table 2). Distinct signature peaks for BFV were seen at 562, 588, 946, 958 and 1154 nm. Peaks at 562 and 588 nm are within the visible region and could be useful for identification of BFV. Peaks at 946, 958 and 1154 nm represent lipid molecular structures. The lipids could be due to the presences of a bi-lipid membrane anchored on the surface of BFV by proteins E1 and E2 [49].\n\nBesides BFV, the rest of the peaks observed were all shared among the three arboviruses and a peak at 410 nm was observed in all arboviruses. This peak at 410 nm is commonly used for assays that require fluorescent excitation such as ELISA and microscopy [50–53]. DENV and RRV have been identified using this peak previously using a spectrofluorometer [54] and ELISA [55], respectively. A peak at 430 nm was observed for BFV strains and RRV but not DENV and SINV indicating the likelihood that visible light could possibly be used to distinguish between these arboviruses. Peaks at 1130 and 1780 nm were present in BFV strains and RRV. The peak at 1130 nm represents CH3functional group whereas the peak at 1780 nm represents C=O functional group. Both wavelengths indicate the presence of lipid biomolecules [42–47]. For BFV, this peak could be due to the presence of the bi-lipid membrane [49]. RRV uses lipid droplet biogenesis for viral replication [56] and lipid rafts for infection [57] thus these lipids could be the residue from these processes. The peak at 1130 nm was also observed for DENV. Lipids present in DENV could be a by-product from cellular passaging of DENV in C6/36Ae. albopictuscells which use lipid metabolism for efficient replication [58–60]. In addition, we identified this peak in a previous study that detected DENV1 in human blood plasma [61].\n\nTo further evaluate if the NIRS spectra could be used to differentiate between arboviruses and media, machine learning algorithms were run on the visible-NIR spectral signatures collected. Using the ANN model, the sensitivity and specificity of ≥90% and 100%, respectively were achieved for the independent test set when samples were grouped as infected or not infected. Sensitivity for predicting arboviruses into their actual group was 100%, 80% and 70% for RRV, DENV and BFV, respectively. Seven out of 40 DENV samples were predicted as BFV. Similarly, 3 out of 20 BFV samples were predicted as DENV (Table 3). This indicates a slight confusion by the training model in differentiating DENV and BFV which could be due to the shared absorption peaks at 410 and 1130 nm.\n\nA total of 16 peaks were identified forP. falciparum.Six of those peaks belong to the visible region. This is not surprising as the parasite can be detected via light microscopy. Three of the 6 peaks within the visible region (547, 561 and 582 nm), were also identified at 540, 560 and 579 nm in the ring stage ofP. falciparumin whole blood as reported by Adegoke and colleagues [62]. Of the 10 remaining wavelengths, 3 in the NIR region (1388, 2245 and 2300 nm) represent C-H bond vibrations [42–47]. C-H bonds are basic chemical building blocks of life and could be responsible for numerous structures within theP. falciparumparasite. Four wavelengths of interest (1681, 1700, 1721, 1905 nm) represent lipids [42–48]. Lipids have been found inP. falciparumand have been shown to play several roles such as toxicity [63], gametocytogenesis [64], and parasite development [65–68]. In addition, peaks at 1388 and 1432 nm are within the same range as those recently identified (1377 and 1431 nm) in malaria infected patients non-invasively using a handheld spectrometer [25]. The remaining 3 wavelengths; 1432, 1882, 2278 nm represent aromatic amine, water and polysaccharides, respectively [42–48].\n\nThe peaks for arboviruses andP. falcipariumidentified in this study will be useful biomarkers for the surveillance/diagnosis of these pathogens in the real world either in humans hosts, animal hosts or mosquito vectors. However, a further assessment in the field using naturally infected blood samples is required to validate the biomarkers identified under this study. With this additional tool in hand, NIRS has the potential to rapidly identify infections to stop an outbreak by facilitating timely isolation and treatment of patients and rapid identification of infected mosquitoes.\n\nWe have identified several novel visible and NIR biomarkers for BFV, DENV, RRV, SINV andP. falciparum. To our knowledge, this is the first investigation to report NIR biomarkers for arboviruses. The findings of this study provide insights into the potential future application of these peaks as diagnostic biomarkers for these pathogens. Future work should evaluate the capability of NIRS spectrometers coupled with machine learning to detect these pathogens, using these biomarkers, in human, animal and mosquito species. This would facilitate rapid, non-invasive, and cost-effective diagnosis and surveillance of these pathogens particularly in large-scale setting that require programmatic surveillance to stop outbreaks.\n\nOverall, a misclassification rate of 0.4778 (n=90) was obtained indicating a low overall accuracy. Numbers in the table represent the number of technical replicates allocated to the prediction count for each arbovirus and media.\n\nhttps://doi.org/10.1371/journal.pone.0321362.s001\n\n(DOCX)\n\nStatistical models are ranked in order of most accurate to the least. Accuracy is determined by the model having values: lowest for misclassification rate, highest for entropy RSquare, highest for area under the curve, lowest for root average square error, and highest for generalized RSquare.\n\nhttps://doi.org/10.1371/journal.pone.0321362.s002\n\n(DOCX)\n\nProminent NIRS peaks for DENV can be observed in the 1450 nm and 1950 nm regions and water peaks were identified at 1450 and 1950 nm. Generally, the absorbance value of DENV was lower than that of media (A). All spectra of BFV QML and BFV WEN1631 were averaged to identify prominent absorbance peaks for BFV. Generally, BFV was observed to have higher absorbance values than media (B). The absorbance value of RRV within the visible and NIR regions was generally higher than media except for the water peak around 1940 nm (C). SINV 18953 generally absorbed less light than media from the visible through to the NIR region between 350–2500 nm. Absorbance values for water molecules at 1450 and 1950 nm of SINV 18953 was lower than media (D).\n\nhttps://doi.org/10.1371/journal.pone.0321362.s003\n\n(DOCX)\n\nThe 2ndderivative of the average visible and NIR spectra for DENV/media (A), BFV/Media (B), RRV/Media (C) and SINV (D) from 350–2500 nm.\n\nhttps://doi.org/10.1371/journal.pone.0321362.s004\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321362.s005\n\n(XLSX)",
    "category": "physics"
  },
  {
    "title": "Scaling-basis chirplet extracting transform and its application in bearing fault diagnosis",
    "authors": "Junzhu Zhang, Yating Hou, Liming Wang, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0319497",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319497",
    "content": "In this paper, we propose a new time-frequency analysis (TFA) method, namely scaling-basis chirplet extracting transform (SBCET). Based on the time-frequency representation (TFR) results obtained by scaling-basis chirplet transform (SBCT), the method introduces a new “extraction operator” to extract the time-frequency (TF) energy associated with the signal to portray the TF energy distribution information of the signal with high accuracy. SBCET can also obtain a TFR with concentrated energy and high resolution for non-stationary signals with close frequency intervals and intense background noise. The effectiveness and superiority are proved by numerical signal processing and experimental verification.\n\nCitation:Zhang J, Hou Y, Wang L (2025) Scaling-basis chirplet extracting transform and its application in bearing fault diagnosis. PLoS ONE 20(4):\n           e0319497.\n        \n        https://doi.org/10.1371/journal.pone.0319497\n\nEditor:Ke Feng, The University of British Columbia, AUSTRALIA\n\nReceived:July 25, 2024;Accepted:February 2, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Zhang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The bearing vibration data used in this paper are publicly available from the Ottawa University dataset (DOI:10.1016/j.dib.2018.11.019).\n\nFunding:The manuscript was funded by State Key Laboratory of Dynamic Measurement Technology, North University of China (No. 2023-SYSJJ-06), the grant recipient is Yating Hou.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nMany natural and synthetic signals are typically non-stationary [1]. Examples include speech, music, and mechanical vibrations. Traditional analysis methods, such as the Fourier Transform (FT) [2], are used to describe the global characteristics of the signal. However, the analysis of non-stationary signals tends to ignore the local information and fails to explain the time-varying characteristics of the signal. TFA addresses this property by transforming a one-dimensional signal into a two-dimensional function, extending the time to a TF property, and describing in detail the signal’s frequency content and its variation with time [3,4]. TFA methods are now widely used in many applications, including the study of seismic signals [5,6], vibration signals [7], biomedical signals [8], and radar signals [9].\n\nTraditional TFA methods such as the short-time Fourier transform (STFT), wavelet transform (WT), and Wigner-Ville distribution (WVD) can diagnose non-stationary signals. However, all of them still have some limitations. For example, the STFT [10,11] cannot achieve high resolution at both low and high frequencies due to the fixed length of the Gaussian window function. WT [12] overcomes the disadvantage of a fixed window size in STFT. However, finding a suitable wavelet basis function is complex, and the method suffers a high degree of redundancy. WVD [13] introduces unwanted additional cross-terms in multi-component signal analysis.\n\nTherefore, a series of parametric time-frequency analysis methods are proposed. For example, the Chirplet Transform (CT) [14] better matches the linearly transformed modulating signal by introducing an additional parameter called chirp rate. However, its window rotation angle is fixed. It cannot achieve ideal results for nonlinear frequency-modulated (FM) and multi-component signals. Several extended versions have been proposed for CT to represent signals with nonlinear FM better. Polynomial CT (PCT) [15] uses a polynomial function instead of the linear FM kernel in the original CT, which can fit the FM law of nonlinear FM signals. Still, the frequency concentration decreases when analyzing multi-component signals, and it is not suitable for analyzing multimode signals. Synchrosqueezing Polynomial Chirplet Transform(SPCT) [16], a synchronous compression PCT for multi-mode amplitude modulation (AM) and FM signals, achieves a highly energy-concentrated TFR by constructing a multikernel operator and an IF estimator. However, it cannot be separated accurately when dealing with signals with similar frequency components. The Generalized Linear Chirplet Transform (GLCT) [17] does not require pre-estimation of parameters and can better handle multi-component signals. However, it produces severe interrupt components when processing signals with small frequency intervals. The velocity synchronous linear chirplet transform (VSLCT) [18] uses a linear chirp basis whose frequency is synchronized with the shaft rotational speed and uses a time-varying window length to respond to changes in signal conditions, improving the time-frequency resolution. Still, the choice of parameters strongly influences it. The scaling-basis chirplet transform (SBCT) [19] extends the CT by scaling the basis at and around the time center in a range of window lengths so that the multi-component signal over the entire window length matches the slope of each instantaneous frequency(IF) trajectory. However, it is subject to high noise interference and some degree of energy dissipation.\n\nIn addition, a series of time-frequency post-processing methods have been developed to improve the TF resolution of conventional TFA methods. The spectrogram-based Reassignment Method (RM) [20] redistributes the energy of the signal points to the computed center of gravity position. Recovering the original component from the signal is impossible because it has been redistributed in both the time and frequency domain. Synchrosqueezing Transform (SST) [21,22] based on WT differs from RM because the method compresses and distributes the signal energy only in the frequency direction. However, when analyzing signals with rapidly changing frequencies, SST cannot accurately estimate the true IF of the signal, resulting in signal energy dispersion. Second- and higher-order versions of SST [23,24] have been proposed to address this problem. Still, the Taylor unfolding of the phase comes with a higher time complexity, which increases the computational burden. Multisynchrosqueezing Transform (MSST) [25] based on SST preserves the reconstruction capability of the signal by updating the TF spectrogram to concentrate the ambiguous TF energy through multiple iterations. Synchroextracting Transform (SET) [26] is different from SST theory. SET retains only the TF information related to the IF of the signal and removes most of the surrounding ephemeral energy, which can effectively reduce the influence of noise. A higher-order SET version [27,28] is also proposed to estimate strong frequency modulation signals better.\n\nAlthough TF post-processing methods have been widely used to analyze non-stationary signals, such TFA methods rely on linear TFA, which is limited by the Heisenberg uncertainty principle. The time resolution and frequency resolution of the linear time-frequency transform cannot be optimized at the same time, so it is required that the constituent components of the multicomponent signal should be sufficiently spaced in the time-frequency plane, i.e., the components have good separability. Therefore, a time-frequency analysis method with good characterization capability must be chosen for multicomponent signals with small frequency intervals. SBCT constructs a new kernel function that allows the chirp rate to vary with frequency and time by scaling the TF basis at and around the corresponding time center. In this way, the corresponding chirplet can precisely match the target slopes of arbitrary window lengths for each trajectory of the multi-component signal, resulting in an accurate TF characterization. However, the frequency resolution of the results is insufficient. It is also susceptible to noise interference. Therefore, inspired by the post-processing method, this paper extends SET to SBCT and proposes a new TFA method called scaling-basis chirplet extracting transform(SBCET). This method outperforms existing TFA methods in analyzing multi-component signals with close frequency intervals and substantial noise interference. It is capable of obtaining TFR results with more concentrated energy.\n\nThe paper is structured as follows. Section 2 briefly describes the principles of SBCT and SET and derives the SBCET method principle by formula derivation. Sections 3 and 4 demonstrate the effectiveness of the proposed method by applying it to simulated and experimental signals, respectively, and comparing it with other TFA methods. Conclusions are presented in Section 5.\n\nSBCT is based on CT and is realized by constructing a new phase function. The CT of the signalcan be expressed as\n\nwheredoes the Hilbert transform generate the analyzed signal;is a non-negative, symmetric, and normalized real window function, usually a Gaussian function;is the phase function,,denoting time and frequency centers, respectively;is the chirp rate.\n\nFor multicomponent signals where the IF trajectory varies nonlinearly with time, CT has three limitations. First, the IF trajectory changes over time and requires different chirp rates to match the slopes at different moments (as shown by points A and B inFig 1). Second, the TF basis cannot match the IF trajectories of all components simultaneously at any given moment (as shown by points A and C inFig 1). The third limitation is the inability of the TF basis to accurately match the instantaneous frequency trajectories of all targets at each moment of each window length (as shown inFig 1at points A and D within 0.5-2s).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.g001\n\nTo break the three limitations, a new phase functionis constructed\n\nwherethe parameter must be determined. The corresponding first and second derivatives can be written as\n\nwhereis the IF trajectory of the phase function.\n\nTaking the time centeras a specific window, whereuobeys, whenuis equal to the time center, equation (4) can be written as\n\nwhereθis the rotating angle of the TF basis at the time center. Starting from this equation, the value ofθvaries with the frequency centerfinstead of remaining constant.\n\nCombining the above equations, the SBCT can be expressed as\n\nSET is a post-processing procedure of the STFT, which retains only the TF information in the STFT results most relevant to the time-varying characteristics of the signal, thus obtaining a time-frequency representation with a higher concentration of energy. The STFT expression of functionis\n\nwheredenotes a moving window.\n\nWe let, equation (7) can be rewritten as\n\nWheredenotes complex conjugation;andrepresent the results obtained after the FT of signaland window function, respectively..\n\nLetto get the STFT after the correction\n\nThe STFT of the signalgives the following result\n\nTo calculate the IF estimation factorin the STFT result, it is first necessary to bias the STFT result.\n\nFrom equation (11), one can derive the IF after the short-time Fourier transform1\n\nThe SET expression is then obtained as follows\n\nThe SET algorithm is a post-processing method providing more centralized time-frequency characterization and resolution. However, the results of the time-frequency analysis of this method depend heavily on the quality of the original time-frequency characterization obtained through conventional methods. Therefore, we consider first obtaining the TFR of the signal through SBCT and then estimating the true IF of the signal on that TF domain. In this way, the time-frequency energy distribution information of the signal is portrayed with high precision, and the time-frequency characterization concentration of the signal is improved.\n\nHere, consider the signal, whereis IF. The analytic signalcan be written as\n\nwheredenotes the amplitude andis the phase function, whoseorder Taylor expansion is given by.\n\nThe SBCT expression of the signal is\n\nWhere.\n\nFor the convenience of subsequent calculations, let, equations (14) and (15) can be written as\n\nThus, there is:\n\nThe equation in (18) holds when the following two equations, (19) and (20), are satisfied; andtakes the maximum value, i.e., the highest energy concentration is obtained.\n\nWhere.\n\nNext, we need to find the IFof the signal corresponding to the moment, so we first take the derivative of the signal. According to equation (16), the signalis derived from timeas:\n\nThen, according to equation (17), the SBCT results for timeare derived as follows\n\nSo there is the following equation\n\nwheredenotes the SBCT result calculated under the window function.\n\nObserving the above equation, we can see that to find the IF, we first need to find. Thus, according to equation (15), the following equation can be derived\n\nwheredenotes the SBCT result calculated under the window function.\n\nSubstituting equation (24) into equation (23) and simplifying, the IFbecomes\n\nTherefore, here, we define the estimator of the IF of the signal as\n\nUsing the mathematical delta function, the SBCT TFR of the signal is used to “extract” the TF energy associated with the IF characteristics of the signal, and the SBCET of the signal is defined as\n\nwhereis the unit pulse function andsatisfies the following equation:\n\nSo there is the following expression\n\nThe SBCET algorithm proposed in this paper can obtain TFR with higher energy concentration for multicomponent signals with close frequency intervals and intense background noise. This section will verify its validity by using single-component signals, frequency-compact, and noise-laden multicomponent simulated signals, respectively, and comparing it with other TFA methods.\n\nThis section explores the concentration of energy in the SBCET proposed in the article. The simulated signals are as follows:\n\nThis section compares STFT, SST, SET, PCT, GLCT, SPCT, VSLCT, and SBCT with SBCET. The window length is set to 128, and the result is shown inFig 2. It can be seen that the TF plot obtained with the STFT (Fig 2(a)) has the highest energy concentration at the highest point. The energy diverges at the remaining moments. The energy concentration of the PCT and GLCT shown inFigs 2(b)and(c)is improved, but there is still energy dispersed around the signal trajectory (blue-green parts of the figure). The improved SPCT method (Fig 2(d)) based on PCT solves the energy dispersion problem. However, the energy concentration is not high near the peak of the signal. The VSLCT (Fig 2(e)) has a better energy concentration than any of the previous methods. Still, the results present a segmented situation, where it is clear that the overall trajectory of the signal consists of many small segments. The STFT-based post-processing methods SST (Fig 2(f)) and SET (Fig 2(g)) exhibit the same TF distribution as STFT. The results obtained by SBCT (Fig 2(h)) are better than those of the above methods. However, the problem of energy dispersion is still evident, especially in the first and last parts of the signal. SBCET results are shown inFig 2(i)with smooth trajectories. High energy aggregation is achieved, and the problems of SBCT are solved.\n\n(a) STFT, (b)PCT,(c)GLCT,(d)SPCT. (e) VSLCT, (f) SST, (g) SET, (h) SBCT, (i) SBCET.\n\n(a) STFT, (b)PCT,(c)GLCT,(d)SPCT. (e) VSLCT, (f) SST, (g) SET, (h) SBCT, (i) SBCET.\n\nhttps://doi.org/10.1371/journal.pone.0319497.g002\n\nIn this section, the multicomponent signals are constructed as:\n\nWhere,,,,,,,,is the 0.87, 1.2, 1.5, 1.9, 2.2, 2.8, 3.3 times. The sampling frequency is 200Hz, and the signal length is 4s. The time domain diagram of the simulated signal is shown inFig 3(a). The FT of the signal to find its frequency domain result is shown inFig 3(b). It can be seen that for components whose frequency varies with time, the FT does not capture the change in frequency.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.g003\n\nThis section uses the methodology used in section 3.1 for comparisons, with the window length set to 220. The TFA results of each method for the simulated signals are shown inFig 4.Figs 4(a)and(b)show the results obtained by the STFT and PCT, where the energy is scattered around the IF, forming a wide band and not effectively separated for closely spaced frequency components. The PCT only has a high concentration of energy near 3s. The results obtained from the SPCT (Fig 4(c)) show an increased concentration of energy compared to the PCT. The distribution is consistent with the PCT. The energy concentration of GLCT (Fig 4(d)) is further improved, but it is susceptible to interference. The time-frequency plot shows frequency overlap. It is not possible to separate the close frequency components.Figs 4(e)and(f)show that the SST and SET methods have greatly improved the energy aggregation compared to the STFT method, but they are still unable to separate the components with similar frequencies. The VSLCT method inFig 4(g)can roughly separate the individual components with closer frequencies, but the energy aliasing phenomenon occurs in 0-0.3s, and the segmentation phenomenon occurs with inconsistent energy concentration in each segment.Fig 4(h)shows that the SBCT method can effectively separate each component near the frequency spacing, but there is some energy divergence in the first and last sections of the signal with lower energy concentration compared to the SBCET method shown inFig 4(i). In summary, the SBCET method proposed in this paper can separate multicomponent signals with close frequency intervals and achieve high energy concentration.\n\n(a) STFT, (b)PCT,(c)SPCT,(d)GLCT. (e) SST, (f) SET, (g) VSLCT, (h) SBCT, (i) SBCET.\n\n(a) STFT, (b)PCT,(c)SPCT,(d)GLCT. (e) SST, (f) SET, (g) VSLCT, (h) SBCT, (i) SBCET.\n\nhttps://doi.org/10.1371/journal.pone.0319497.g004\n\nThe Rényi entropy is a generalization of the Shannon entropy and can quantify the stochasticity and uncertainty of the system. In TFA, Rényi entropy is often used as an essential measure of the energy concentration of an algorithm. Lower Rényi entropy indicates that the algorithm has a more energy-focused time-frequency result; thus, a more accurate TFR can be generated. The expression is\n\nwhereαis usually taken as 3 andis the result of the TFA. To quantify the energy concentration of the results of the TFA of each method, the Rényi entropy is given inTable 1, where the SBCET has the smallest value of Rényi entropy. This also demonstrates that SBCET produces TF distributions with the highest concentration of energy compared to other methods.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.t001\n\nTo better observe the aggregation of the signal energy, the time slices of the TF results at t = 3s for the traditional STFT and the extended pre- and post-paper methods (including SET, SBCT, and SBCET) are plotted inFig 5. As can be seen in the figure, the spacing of the eight frequency components is different in the four methods. The IF estimated by the STFT is somewhat biased due to interference from cross terms, and the signal’s energy is dispersed around the IF. The SET has noise components other than the signal components. The SBCT gives more concentrated TF results, but little energy is dispersed around both ends of the signal, and the amplitude is relatively small at the IF. The method proposed in this paper provides a centralized TFR that accurately describes the amplitude and frequency information of the signal. Therefore, the SBCET offers the best representation of the TF characteristics of the signal.\n\n(a) STFT, (b) SET, (c) SBCT, (d) SBCET.\n\n(a) STFT, (b) SET, (c) SBCT, (d) SBCET.\n\nhttps://doi.org/10.1371/journal.pone.0319497.g005\n\nIn this section, the effect of noise on the proposed method is explored, and the simulation signals are set up as follows:\n\nWhere,,,.ζis the additional Gaussian white noise, set the signal-to-noise ratio(SNR) to 10 dB. Its time-domain plot and theoretical IF trajectory are shown inFig 6, with a sampling frequency of 100Hz and a signal length of 6s.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.g006\n\nThe signals were analyzed using the same methods as in section 3.1, and the results are shown inFig 7, where the window length is set to 90.Fig 7(a)indicates that the STFT has severe energy divergence at the IF and serious noise pollution within the TF diagram. The results obtained by PCT (Fig 7(b)) are highly affected by noise. It cannot show the signal trajectory accurately. There is energy dispersion in 0-3s and high energy concentration in 3-6s. The results of the time-frequency analysis of the SPCT (Fig 7(c)) are relatively good in terms of noise resistance. However, the energy concentration and time-frequency resolution are not high. The energy overlaps in the part where the frequencies are close. The TF energy concentration of GLCT, SST, and SET inFigs 7(d),(e)and(f)is higher than that of the first three methods, but there is an aliasing phenomenon. The SST is reflected in 0-3.5s. The GLCT and SET are reflected in 3-6s. FromFigs 7(g)and(h), it can be seen that the SBCT and VSLCT TF energy is more concentrated compared with the STFT, but all of them still have the phenomenon of energy dispersion and are affected by noise. The SBCET method proposed in this paper is shown inFig 7(i), it can be seen that compared to other algorithms, SBCET eliminates most of the noise disturbances within the TF diagrams and improves its readability while maintaining a very high accuracy of the IF estimation.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.g007\n\nTo explore the effect of noise on the proposed method, Gaussian white noise with varying degrees of SNR (1-30 dB) was added to the simulated signals. The simulated signal is then processed using each of the above TFA methods. Since the TFR obtained by the SET and SST are insufficient to show the exact frequency trajectory of the signal, a comparison of the Rényi entropy of the results processed by the remaining TFA methods is shown inFig 8. As can be seen from the figure, as the SNR increases, the corresponding Rényi entropy values all become smaller. This indicates that the energy concentration of its TFR becomes higher, and the Rényi entropy value of the SBCET is always minimized under the same conditions. The results show that the Rényi entropy value calculated using the method proposed in this paper is minimized regardless of the level of noise pollution. This confirms that the method proposed in this paper has higher energy concentration when dealing with noisy signals.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.g008\n\nAs an essential part of rotating machinery, bearings can significantly impact production if they fail during actual operation. The current identification of bearing faults still relies on extracting the characteristic frequency of bearing faults. To verify the effectiveness of the proposed method, rolling bearing vibration signals at time-varying speeds are analyzed. Data from publicly available datasets from the Ottawa University [29]. The experimental setup was the SpectraQuest machinery fault simulator (MFS-PK5M). Vibration data is collected by an ICP accelerometer placed on the housing of the experimental bearing. The specific experimental setup is shown inFig 9.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.g009\n\nThe entire unit is driven by an electric motor, and the speed is regulated by an AC drive. Two ER16K ball bearings are located at each end of the shaft. It should be noted that on the left are healthy (normal) bearings, and on the right are replaceable bearings, which usually correspond to faulty bearings.Table 2clearly shows the structural parameters of the studied rolling bearings. According to the parameters of the bearing, the ball-pass frequency (BPFI) of the inner race of the bearing is equal to the product of the fault characteristic frequency (FCF) coefficient (5.43) and the shaft rotational frequency, i.e.,. Similarly, the ball-pass frequency of the outer-race(BPFO) of the bearing. The sampling frequency was set to 200kHz, and the sampling duration was 10s throughout the test.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319497.t002\n\nTo verify the method’s validity, the inner ring failure data I-C-2 is selected for analysis in this section. The rotational speed increases from 14.1 Hz to 23.5 Hz and then decreases to 18.0 Hz. A downsampling operation must be performed since the high sampling rate results in too much data. The sampling rate after downsampling is 5000 Hz. Its time-domain diagram is shown inFig 10(a).Fig 10(b)shows the result of the fast Fourier transform(FFT) performed on it. From the figure, it can be seen that the fault characteristic frequency component and rotational frequency component cannot be accurately identified at variable speeds.\n\n(a) time domain plot (b) FFT result.\n\n(a) time domain plot (b) FFT result.\n\nhttps://doi.org/10.1371/journal.pone.0319497.g010\n\nThe TF diagram obtained by processing using the TFA method mentioned in Section 3 is shown inFig 11. The window length is set to 200 in each of these methods. The two kernel functions in SBCT are set to 50 and 10. The normalization angle in VSLCT is set to 20. The TF diagrams obtained by the STFT, PCT, SPCT, and SBCT methods shown inFigs 11(a),(b),(c)and(g)can roughly show the frequency characteristics of the vibration signals, but there is a lot of interference from noise in the TF plane. It needs to improve its time-frequency resolution to enhance the ability to portray and characterize time-varying signals. The results of the GLCT analysis (Fig 11(d)) improved the energy concentration but caused the absence of some frequency components. It is not possible to derive the failure frequency correctly. FromFigs 11(e)and(f), it can be seen that the frequency characteristics of the TF diagrams obtained by the SST and SET are very weak, and cannot form a continuous frequency trajectory. Rolling bearing fault signals are typically accompanied by significant noise, especially vibration noise from mechanical systems. SET and SST algorithms are sensitive to noise. In the presence of high noise levels, they cannot effectively suppress the noise, which results in the fault features being blurred or masked by the noise, affecting the display quality. Therefore, the fault characteristic frequency cannot be identified. The TF diagram obtained by the VSLCT is shown inFig 11(h), and its TF resolution is improved compared to the previous methods. However, the energy aliasing phenomenon occurs at 3.5-5.5s and 7.5-8.2s, which cannot distinguish the closely spaced frequency components and effectively extract the fault characteristic frequency. The vibration signal is processed using the SBCET proposed in this paper, and the analysis results are shown inFig 11(i). The time-varying fault characteristic components (FCF, 2 * FCF) and the speed profile() can be accurately identified.\n\n(a)STFT, (b) PCT, (c) SPCT, (d) GLCT, (e) SST, (f) SET, (g) SBCT, (h) VSLCT, (i) SBCET.\n\n(a)STFT, (b) PCT, (c) SPCT, (d) GLCT, (e) SST, (f) SET, (g) SBCT, (h) VSLCT, (i) SBCET.\n\nhttps://doi.org/10.1371/journal.pone.0319497.g011\n\nThis section selects the outer ring failure data O-B-2 for analysis. The operating speed decreased from 24.7 Hz to 10.2 Hz. The downsampling process is first performed, and the sampling frequency after downsampling is 6000 Hz.\n\nFig 12illustrates the TF results of the vibration signals with the methods used in Section 3. The window length of various TFA methods is set to 200Hz. The two kernel functions in SBCT are set to 40 and 10. The normalization angle in VSLCT is set to 20. The STFT (Fig 12(a)), PCT(Fig 12(b)), and SBCT (Fig 12(g)) can identify most of the fault characteristic frequency components. Still, these two methods are interfered with by noise, and the energy is not concentrated. The SPCT (Fig 12(c)) is minimally disturbed by noise but at the cost of missing some frequency components. The results obtained by GLCT are shown inFig 12(d). There is energy crossover in the parts with close frequency intervals, and many frequency components are missing. The TF diagrams obtained by the SST, SET, and VSLCT methods are shown inFigs 12(e),(f)and(h), which provide high resolution. Still, they show weakly in the TF diagrams and cannot extract the characteristic frequency effectively. The VSLCT showed severe frequency aliasing in the 0-4s. The analysis results of the SBCET presented inFig 12(i)portray the fault characteristic frequencies of the vibration signals (including the shaft rotation frequencies, FCF, and 2 * FCF). In summary, the SBCET method can effectively perform bearing fault diagnosis.\n\n(a) STFT, (b) PCT, (c) SPCT, (d) GLCT, (e) SST, (f) SET, (g) SBCT, (h) VSLCT, (i) SBCET.\n\n(a) STFT, (b) PCT, (c) SPCT, (d) GLCT, (e) SST, (f) SET, (g) SBCT, (h) VSLCT, (i) SBCET.\n\nhttps://doi.org/10.1371/journal.pone.0319497.g012\n\nIn this paper, we propose a new TFA method, the SBCET, based on the problems of insufficiently clear identification and poor aggregation in multicomponent non-smooth, nonlinear complex signals that occur in the SET and SBCT. The method firstly obtains the time-frequency spectrum of the signal by SBCT, then estimates the real instantaneous frequency of the signal in the time-frequency domain, uses the frequency immobility point to “extract” the time-frequency energy that is closely related to the time-frequency characteristics of the signal from the original time-frequency spectrum, and removes many fuzzy time-frequency energies, to portray the time-frequency energy distribution information of the signal precisely. Subsequently, simulated signals were used to demonstrate its feasibility. The SBCET can obtain higher TF resolution and noise robustness than other TFA methods. It was successfully applied to rolling bearing fault vibration signals, providing a referenceable technical means for bearing fault detection.",
    "category": "physics"
  },
  {
    "title": "Enhanced DWT-OFDM communication system using wavelet domain equalizer with Co-CFO",
    "authors": "Khaled Ramadan, Emad S. Hassan, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0317097",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0317097",
    "content": "For the design of Orthogonal Frequency Division Multiplexing (OFDM), the Discrete Wavelet Transform (DWT) offers significant benefits over the classic Discrete Fourier Transform (DFT). This article proposes a Joint Low Complexity Regularized Zero Forcing-Wavelet Domain Equalizer (JLCRLZF-WDE) as substitute to a Frequency Domain Equalizer (FDE) for improving the Multiple-Input-Multiple-Output (MIMO) DWT-OFDM. The results have been assessed using the Co-Carrier Frequency Offset (Co-CFO) Rayleigh fading channel. The proposed scheme’s relevance is demonstrated by a comparison of its Bit-Error-Rate (BER) and simulated time with those of conventional schemes. The obtained results showed that the proposed JLCRLZF-WDE outperforms conventional equalizers, requiring only 0.82 dB additional SNR to match the BER performance of Linear Minimum Mean Square Error (LMMSE)-WDE at BER =  10-3, and 0.27 dB at BER =  10-4. In comparison, other equalizers, such as Linear Zero Forcing (LZF)-FDE and LMMSE-FDE based on DWT and DFT, require significantly higher SNR values to reach the same performance benchmarks, with differences ranging from 0.31 dB to over 15.35 dB. Additionally, the proposed scheme achieves a simulated time reduction of 3.17% and 12.4% compared to LMMSE-WDE based on DWT and DFT, respectively.\n\nCitation:Ramadan K, Hassan ES (2025) Enhanced DWT-OFDM communication system using wavelet domain equalizer with Co-CFO. PLoS ONE 20(4):\n           e0317097.\n        \n        https://doi.org/10.1371/journal.pone.0317097\n\nEditor:Mohammad Reza Ghavidel Aghdam, Ozyegin University: Ozyegin Universitesi, TÜRKIYE\n\nReceived:October 17, 2024;Accepted:December 11, 2024;Published:April 17, 2025\n\nCopyright:© 2025 Ramadan, Hassan. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:The data is available in a Figshare repository at the following link: (https://doi.org/10.6084/m9.figshare.28288001.v1).\n\nFunding:The authors gratefully acknowledge the funding of the Deanship of Graduate Studies and Scientific Research, Jazan University, Saudi Arabia, through Project Number: GSSRD-24.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nBecause of its effective use of spectrum and resilience to multipath interference, orthogonal frequency division multiplexing, or OFDM, is a crucial technology found in many contemporary wireless communication networks, including Wi-Fi, 4G, and 5G. By partitioning the whole bandwidth into many orthogonal subcarriers, each one is assigned to transmit a segment of the data, OFDM considerably lowers Inter-Symbol Interference (ISI) in wireless situations that is brought on by signal reflections. In contrast to conventional Frequency Division Multiplexing (FDM), OFDM guarantees interference-free frequency overlap between subcarriers, enhancing spectral efficiency [1]. The primary advantage of OFDM is its ability to effectively handle frequency-selective fading, which makes it perfect for wireless broadband applications. Since each OFDM subcarrier is modulated individually, the system is more robust to channel impairments when the data is distributed over a large number of subcarriers. Moreover, OFDM employs a Cyclic Prefix (CP), a duplicate of the signal’s last segment to lessen the impact of multipath delay spread and provide resilience against ISI [1]. OFDM is very helpful in the context of 4G and 5G networks as it allows for huge interconnection and high data rates [2]. Additionally, its ability to handle multipath fading and provide efficient spectrum utilization makes OFDM an ideal candidate for enhancing the performance of Wireless Sensor Networks (WSNs), particularly in scenarios requiring reliable and scalable communication [3]. Moreover, OFDM performs much better when combined with MIMO technology, which multiplexes data spatially. Another advantage is that, in comparison to time-domain equalization techniques, it has a very straightforward equalization procedure in the FD, greatly reducing receiver complexity.\n\nNevertheless, there are several drawbacks to OFDM, such as a large Peak-to-Average Power Ratio (PAPR) that may result in power amplifier performance that is not very efficient. Many methods are employed to lower PAPR, including filtering and clipping, although these can cause signal distortion. Despite these difficulties, OFDM is a popular technique in wireless networks because its benefits in multipath situations exceed its disadvantages [2]. To further highlight OFDM’s adaptability, it is the foundation for several contemporary broadcasting technologies, such as Digital Audio Broadcasting (DAB) and Digital Video Broadcasting (DVB). The fact that OFDM can handle reflections and signal interference to ensure dependable data transmission is one of the reasons it works so well in crowded, metropolitan settings. Furthermore, OFDM can optimize throughput by adjusting data rates in response to channel circumstances thanks to its adaptive modulation and coding techniques.\n\nApplications for 5G and other wireless communication technologies can also make advantage of this technology. Additionally, the Inverse Discrete Fourier Transform (IDFT) and DFT can used to build a standard OFDM system [1]. The OFDM system may be built utilizing an orthogonal transform such as Inverse DWT (IDWT) at the transmitter and DWT at the receiver [4]. Wavelet-based MIMO-OFDM is increasingly recognized for its potential in wireless communication due to its ability to provide high spectral efficiency, cost-effectiveness, and reduced phase noise [5]. Studies highlight that the DWT enhances system performance compared to the DFT by reducing PAPR, improving non-linearity [6], and overcoming limitations of traditional Multi-Carrier Modulation (MCM) systems [7]. Research demonstrates the effectiveness of DWT in applications such as MIMO-OFDM for wireless communication [8], improving system performance [9], millimeter-wave systems [10], and image transmission over correlated channels [9], with benefits including extended battery life [11], enhanced performance, and robust diversity techniques for future networks [10]. The capacity to extract both local spectral and temporal information is the fundamental benefit of the Wavelet Transform over the Fourier Transform in OFDM based on the DWT [12]. Wavelet transform is benefit for identifying signals, de-noising, and compression due to its superior energy compaction capabilities. Scaling and translation of a short wave are used to represent a signal. This wave is sometimes referred to as a wavelet. The wavelets’ average value is consistently zero, and the interval is always bounded [13]. Wavelet families include Haar Wavelet [14], Daubechies Wavelekt (DW) [15], Symlets Wavelet (SW) [16], Coiflet Wavelet (CW) [17], Biorthogonal Wavelet (BW) [18], Reverse Biorthogonal Wavelet (RBW) [19], Discrete Meyer (DM) [20], Embedded Zerotree Wavelet (EZW) [21], Spatial Orientation Tree Wavelet (SOTW) [22], Wavelet Difference Reduction (WDR) [23]. We are interested in the Haar wavelet type [14] in this study since it is one of the most prominent in mathematics and engineering due to its simplicity and compact support. The Haar Wavelet divides a discrete signal into two equal-sized components. The first section is called the trending section, while the second section is known as the fluctuation section. In this paper, we focus on the Haar wavelet type. The authors of [3] present many ways for quickly implementing various types of wavelet transformations. Because of its strong performance in high-noise and multi-path situations, the DWT is being used more and more in wireless communication systems [24]. By improving spectrum efficiency and lowering BER, DWT-based systems can perform better in 5G than conventional DFT-based techniques, particularly in Non-Orthogonal Multiple Access (NOMA) systems [24]. In MIMO-OFDM systems, DWT is also utilized to maintain high data rates while lowering power consumption and computational complexity [24]. Furthermore, modulation and coding performance in contemporary communication channels are improved by DWT’s capacity to manage multi-resolution signal analysis [24].\n\nRecent advancements in OFDM systems have seen significant use of FDE to counteract the impacts of multipath fading. In DFT-OFDM systems, one of the key advantages is the straightforward implementation of FDE, which enhances system performance by simplifying the process of handling channel distortions. Several studies have focused on improving the efficiency of FDE-based OFDM systems. In [25] FDE-based OFDM systems with index modulation (OFDM-IM) have been explored for their ability to enhance spectral efficiency by employing subcarrier activation patterns and reducing the active subcarrier count. These innovations aim to maximize data throughput while maintaining the reliability of communication channels, making them suitable for 5G and beyond.\n\nA recent study in [26] proposes an iterative decision feedback channel estimation (IDFCE) method for DFT-Spread OFDM (DFT-S-OFDM) systems, aimed at improving channel estimation and error correction. The method integrates a time-division multiplexing reference signal into a turbo FDE. In this approach, channel responses, which are used in both feedforward and decision-feedback equalizers, are iteratively updated during each iteration of the turbo FDE, enhancing the accuracy of the estimation process. A novel FDE scheme designed for one-bit uplink multi-user massive MIMO systems is presented in [27]. This scheme employs a pseudo-random quantization (PRQ) method with non-zero threshold quantization to mitigate the effects of quantization distortion, which typically limits the system’s ability to handle high-order modulation. The proposed equalizer, based on Newton’s method (NM), is specifically tailored for OFDM transmissions under frequency-selective fading conditions by leveraging the inherent benefits of massive MIMO. To reduce computational complexity, a low-complexity FDE algorithm is developed using a quasi-Newton approach. However, despite its effectiveness, FDE in DFT-OFDM introduces additional computational complexity due to the requirement for extra DFT and IDFT operations during the equalization process. This extra step not only increases processing time but also limits the system’s efficiency, particularly in high-speed communication scenarios where real-time performance is crucial.\n\nThe study presented in [28] focused on the multilevel redundant DWT-OFDM (ML-RDWT-OFDM) system. This system incorporates Low-Density Parity-Check (LDPC) coding and Soft Decision (SD) decoding based on the belief propagation algorithm to enhance the overall system performance. Simulation results demonstrated that incorporating LDPC coding significantly improves the performance of ML-RDWT-OFDM systems.\n\nA comparative study analyzed the BER performance of signals transmitted using DWT and DFT in various channel environments was presented in [29]. It was observed that DWT-OFDM and DFT-OFDM perform similarly in AWGN channels, but DFT-OFDM exhibits better performance in Rayleigh channels. A recent study in [30] proposed an adaptive decision feedback equalizer with interference reconstruction and cancellation for OFDM systems. This method minimizes the symbol error rate (MSER) by performing adaptive filtering in the delay dimension, mitigating inter-symbol interference (ISI), and compensating for cyclic convolution and phase flipping.\n\nThe limitations of traditional FDE implementations have sparked interest in exploring alternative approaches, such as the use of wavelet-based OFDM systems. DWT-OFDM, for instance, offers improved spectral efficiency and better time-frequency localization compared to DFT-OFDM. However, conventional FDE implementations in DWT-OFDM still suffer from the same computational drawbacks due to the additional DFT/IDFT operations required for equalization. This has highlighted the need for more advanced equalization techniques. The proposed JLCRLZF-WDE addresses these challenges by eliminating the need for the extra DFT/IDFT steps, reducing computational complexity, and improving BER performance, making it a more efficient solution for modern wireless communication systems. The proposed equalizer can execute both equalization and co-CFO compensation operations at the same time without requiring extra blocks of DFT/IDFT. Moreover, research on DWT-OFDM is still in its early stages, and there is a lot of scope for additional performance enhancement. For the MIMO-OFDM system, this paper’s contributions are summarized below:\n\nFig 1depicts the main transceiver topology of ani × jMIMO-DWT-OFDM system employing WDE over a Rayleigh fading channel. The proposed JLCRLZF-WDE is used to accomplish the equalization and co-CFO compensation operations in the WD.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g001\n\nFirstly, a polar NRZ is generated via a random that de-multiplexed via each stream in accordance to antennas number at the transmitter side. A Serial-to-Parallel (S/P) converter is used to route each group of lengthN. IDWT comes after that. As a result, the transmitted data vector before the IDWT block associated with theithvector may be written as:\n\nwhereis the matrix transpose,Nis the sub-carrier number, and. Currently, eachNvector has the IDWT block applied to it. The IDWT block is now applied to each of theNvectors. As a consequence, theithvector’s IDWT output may be stated as follows:\n\nwhere,represents the up-sampling matrix, which is defined as follows:\n\n(3)\n\nrepresents the filter Impulse Response Matrix (IRM) of the IDWT at the transmitter side, which consists of the Low Pass Filter (LPF) and the High Pass Filter (HPF). It is a composite of two filters as:, which is defined as:\n\n(4)\n\nand\n\n(5)\n\nIn fact, the termmatrix refers to the IDWT matrix.is the IRM of LPF at the transmitter and receiver sides andis the RM of the HPF at the transmitter side. The CP is now appended to the beginning of each vector. As a result, theithmodulated vector with CP is written as follows:\n\nwith\n\nwhereis the matrix related to CP insertion,,represents the CP length,denotes andiagonal unity matrix, andis anmatrix of all zero elements. The data is then sent via the Rayleigh fading channel once each stream’s Parallel-to-Serial (P/S) stage has been employed. The Rayleigh fading channel and co-CFO are included in the received data vector at thejthantenna, and noise after the Serial-to-Parallel (S/P) stage, is represented as follows:\n\nwhereindicates thejthvector before the ignoration of the CP vector,is the complex AWGN vector with zero mean. The co-CFO can be expressed as a diagonal matrix asthat given by:\n\nThe co-CFO among the transmitting antenna numberiand receiving antenna numberjisthat expressed as:\n\nwhere the sub-carrier spacing is represented byand the frequency shift byf. Additionally, the size of transform, carrier frequency, oscillator misalignment, all have an effect on the normalized co-CFO value. The channel IRM among thejthreceiving antenna and theithsending antenna is denoted by, which is defined as:\n\nThe channel impulse response coefficient is represented by, while the number of Rayleigh fading channel taps is indicated by. Such ignores the head of each data vector that represents the CP. Additionally, the output ofjthvector’s CP removal stage is written as:\n\nwheredenotes a composite of both the co-CFO and Rayleigh fading channel. Meanwhile,denotes the CP removal matrix. The above equation can be expressed using Eq. (2) as follows:\n\nThen, anN-point DWT is applied, comprising two key operations: combination of LPF and HPFand the down-conversion matrixd. Hence,,, where\n\n(14)\n\nwhereis the RM of the HPF at the receiver side. Now, the down-sampling matrixis applied, which is defined as follows:\n\n(15)\n\nNow, Eq. (13) will be modified to include DWT as follows:\n\nThis part discuss the mathematical representation of the proposed JLCRLZF-WDE. In the case of 2 × 2 MIMO-DWT-OFDM system, Eq. (16) will be re-written as:\n\nLet’s define,. In general,is a composite transmission matrix, representing the signal transformation up to the point of equalization and excluding the equalization process between theithtransmitting antennas, andjthreceiving antenna. Now, Eq. (17) will be re-written as:\n\nwhere,.is the processed noise vector, which corresponds to the noise vector after applying processing steps like CP removal, down-sampling, and filtering (e.g., LPF and HPF). 2a illustrates the magnitude of the Interference Matrix (IM) in the case of DWT, providing insight into the distribution of interference among subcarriers. In contrast, 2b depicts the corresponding phase angles of each element in 2a, offering a comprehensive view of the IM’s complex structure. The diagonal elements in 2a represent the desired subcarriers, which are free of interference, while the off-diagonal elements correspond to interference contributions from other subcarriers. To further clarify, 3a focuses on a specific instance by presenting the magnitude of the IM for row 20, enabling a more detailed examination of the interference pattern. Additionally, 3b complements this by illustrating the corresponding phase angles for the same row, as shown in 3a, thereby highlighting the interplay between magnitude and phase in the IM structure. This detailed visualization underscores the characteristics of interference in the system and aids in understanding its impact on the overall performance.\n\nSimilarly,Fig 4aillustrates the magnitude of the IM for the case of DFT, providing a detailed representation of interference across subcarriers. Correspondingly,Fig 4bshows the phase angles for each element inFig 4a, offering a comprehensive understanding of both magnitude and phase in the DFT-based IM. For a more focused analysis,Fig 5apresents the magnitude of the DFT IM for row 20, isolating the interference pattern for this specific subcarrier. In parallel,Fig 5bdisplays the corresponding phase angles for the same row, as shown inFig 5a, enabling a deeper examination of the IM’s characteristics. When compared to the results shown inFig 2, andFig 3, it is evident that the DWT approach exhibits significantly lower interference from neighboring subcarriers to the desired subcarriers, as reflected in the diagonal elements of the IM. This demonstrates the superior ability of the DWT to mitigate interference when contrasted with the DFT, especially in systems experiencing co-CFO effects. The IM for the case of DFT under co-CFO conditions can be mathematically expressed as [32]\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g005\n\nThe IM in the case of DWT with co-CFO is written as:\n\nSo, we can takthe number of sub-carriers into consideration and ignore the remaining as:\n\nwhereis the relative sub-carrier distance, andis the BMA of thematrix.\n\nThe proposed JLCRLZF-WDE general matrix solution is:\n\nIn Eq. (22), α represents the regularization parameter, which is a constant value used to mitigate noise amplification, andis the BMA. In the case ofMIMO configuration, we have:\n\nUsing the JCLRLZF-WDE matrix solution stated in Eq. (19) and the BMA defined in Eq. (20). The optimal value of α, which correlates to the inverse value of the SNR, is required for the proposed equalizer. The BMA bandwidth (τ) must be accurately provided in order to satisfy reduced complexity implementation.\n\nThe simulation results for the proposed JLCRLZF-WDE based on DWT-OFDM systems will be analyzed. The analysis will utilized a 6-tap Rayleigh fading with carrier frequency 2 GHz, modeled according to the Jakes model [33,34] and vehicle A model [35] using the simulation parameters indicated inTable 1. According to the preceding section’s analysis, the value of α should be specified with minimal BER performance and τ should be as small as feasible to reduce computational complexity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.t001\n\nFig 6ashows the normalized magnitude plotted against the indices for thematrix in the case of DWT, providing a clear visualization of how the interference distribution varies across subcarriers.Fig 6bcomplements this by presenting the corresponding phase angles for each element inFig 6a, offering a comprehensive representation of both magnitude and phase characteristics. In this scenario, each normalized co-CFO is treated as a random variable with a uniform distribution in the range, wheredenotes the maximum normalized co-CFO. This assumption captures the variability introduced by different co-CFO values in practical systems. To provide additional clarity,Fig 7afocuses on row 20 of thematrix shown inFig 6a, illustrating the normalized amplitude for this specific row. Meanwhile,Fig 7bpresents the corresponding phase angles for the same row, as depicted inFig 7a. These figures together offer a detailed insight into the behavior of the matrix for individual subcarriers, facilitating a deeper understanding of the DWT’s response to co-CFOs.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g007\n\nFig 8apresents the normalized magnitude plotted against the indices for thematrix in the context of the DFT. This graphical representation provides a clear visualization of how the magnitude varies across the elements of the matrix. In contrast,Fig 8billustrates the corresponding angles for each of the elements shown inFig 8a, offering insights into the phase relationships within the matrix. From these figures, it becomes evident that the BMA approach is effective when applied to DFT, as it shows a clear and interpretable structure in both magnitude and phase. However, when considering the case of the DWT, the BMA appears to be less effective, which is something that will be further explored in the subsequent simulations. To provide additional clarity,Fig 9azooms in on row number 20 fromFig 8a, presenting its normalized amplitude specifically.Fig 9b, in turn, displays the corresponding angle values for this row, offering a more detailed understanding of the phase information for a particular subset of the matrix. The analysis in these figures highlights the differences in how the BMA handles DFT versus DWT, pointing to the need for alternative methods in wavelet-based analysis. This will be examined in greater detail in the following sections.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g008\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g009\n\nFig 10aillustrates the BER performance as a function of the regularization parameter (α) for various SNR values, providing a detailed analysis of how (α) impacts system performance. To offer a different perspective,Fig 10bpresents an elevation view ofFig 10a, specifically forallowing for a more nuanced examination of the parameter’s behavior. The LMMSE equalizer, as a benchmark, is represented by the final vector value of α=1/SNR, which helps to contextualize the proposed adjustments. FromFig 10b, it is clear that the best BER performance occurs at specific values of α, namely 10-2, 10-3, and 10-4. This indicates that selecting an optimal α is critical for achieving minimal BER. To determine the most effective value of α for subsequent simulations, the BER performance across SNR values must be thoroughly evaluated at these candidate levels.Fig 10cprovides further insights by plotting BER versus SNR for different α values. The results indicate that α=10-2consistently delivers optimal performance across a range of SNR conditions, particularly when used with LMMSE equalization. This robustness makes α=10-2the ideal choice for the remaining simulations, ensuring stable and reliable system performance under varying conditions. Moving forward, our primary focus shifts to evaluating the BMA parameter (τ) with the aim of simplifying the equalization design. This analysis will contribute to a more efficient and practical implementation of the equalization process, potentially enhancing overall system usability.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g010\n\nFig 11aillustrates the BER performance as a function of the BMA parameter (τ) for various SNR levels, highlighting the relationship between τ and system reliability.Fig 11bprovides an elevation view ofFig 11a, offering a three-dimensional perspective that helps visualize how τ interacts with SNR to influence BER. This dual representation enhances the understanding of the trade-offs associated with different τ settings. The last two vector values inFig 11aand11bcorrespond to two critical scenarios: the BMA condition (τ= 15) and the full compensation scenario (τ=N, whereNrepresents the total number of subcarriers). A clear disparity is observed in BER performance between these scenarios, with τ=Nsignificantly outperforming. This difference underscores the importance of selecting an optimal τ value for maintaining low BER and achieving robust system performance. For subsequent simulations, the full compensation scenario (τ=N) will be employed, as it consistently demonstrates superior BER performance under varying conditions. This decision is further validated byFig 11c, which presents BER performance as a function of SNR across different compensation scenarios. The results clearly show that robust BER performance is only achieved under the full compensation condition, where. This analysis emphasizes the critical role ofτin system design. While partial compensation (e.g., τ=15) offers computational simplicity, it introduces a significant degradation in BER performance. In contrast, the full compensation scenario ensures maximum reliability, making it the optimal choice for high-performance applications. This finding will guide the remaining simulations and provide a foundation for future investigations into the trade-offs between complexity and performance in compensation mechanisms.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g011\n\nFig 12aillustrates the BER performance of the proposed JLCRLZF-WDE as a function of the normalized co-CFO (ε) at various BMA levels (τ). This representation highlights the impact of different compensation levels on the system’s ability to mitigate co-CFO effects. To provide a more comprehensive perspective,Fig 12bpresents an elevation view ofFig 12a, focusing on the performance under two key compensation scenarios: partial compensation () and full compensation (). At a normalized co-CFO value of ε = 0.1,Fig 12coffers a side view ofFig 12a, further emphasizing the differences in performance between these scenarios. These visualizations collectively reveal that the proposed JLCRLZF-WDE achieves reliable BER performance only when full compensation () is employed. Partial compensation () results in a noticeable degradation, indicating that insufficient compensation that cannot adequately handle the interference caused by co-CFOs.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g012\n\nThis analysis highlights the critical interplay between the compensation strategy (τ) and the robustness of the JLCRLZF-WDE. While partial compensation may reduce computational complexity, it fails to provide the level of interference mitigation necessary for acceptable performance, especially in scenarios with significant co-CFO effects. Conversely, full compensation ensures that the JLCRLZF-WDE effectively minimizes interference and achieves optimal BER performance across the tested range of normalized co-CFO values. Based on these findings, the following simulations will adopt a full compensation strategy (), paired with a regularization parameter of α = 10− 2. This configuration reflects the optimal balance between interference mitigation and algorithmic robustness, ensuring that the proposed JLCRLZF-WDE performs reliably under various operating conditions. These insights also pave the way for future studies into the trade-offs between computational complexity and performance in advanced equalization techniques.\n\nFig 13presents the BER performance as a function of SNR for various linear equalizers operating in both the Frequency Domain (FD) and the Wavelet Domain (WD), providing a comprehensive comparison of their efficiency under different scenarios. The analysis inTable 2uses the LMMSE-WDE as the reference benchmark, which is widely recognized for its robust performance in mitigating interference and achieving low BER. A closer examination reveals significant differences in the additional SNR required by each equalizer to match the BER performance of the LMMSE-WDE at a target BER of 10− 3. Specifically:\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g013\n\nThis analysis underscores the critical role of domain choice (DWT vs. DFT) and equalization strategy (LZF vs. LMMSE) in determining system performance. The wavelet domain provides significant advantages, as evidenced by the closer alignment of DWT-based equalizers to the LMMSE-WDE benchmark. Among all the tested equalizers, the proposed JLCRLZF-WDE emerges as a highly efficient solution, offering near-parity performance with the LMMSE-WDE while maintaining a balance between computational complexity and robustness. This finding highlights the potential of JLCRLZF-WDE for advanced communication systems, particularly in environments where interference and noise present significant challenges.\n\nTable 2offers a comparative analysis of the SNR requirements for achieving a BER of 10-3using different equalizer types across the DWT and DFT transform domains, with both FDE and WDE approaches. The insights derived from this table reveal significant performance differences based on the choice of equalizer, transform type, and compensation strategy.\n\nKey Observations\n\nThus,Table 2demonstrates the clear advantages of the DWT over the DFT for both FDE and WDE approaches. Equalizers operating in the DWT domain consistently require lower SNR values to achieve the target BER of 10− 3, showcasing the wavelet transform’s superior ability to localize interference and noise in time and frequency. The LMMSE equalizers outperform the LZF counterparts across all configurations, highlighting the effectiveness of LMMSE in leveraging optimal weighting strategies for interference mitigation. Among all configurations, the proposed JLCRLZF-WDE stands out as a near-optimal solution, offering performance that closely matches the LMMSE-WDE while maintaining design simplicity and computational efficiency. This analysis underscores the critical role of choosing the appropriate domain (DWT vs. DFT) and equalizer type to optimize system performance. The findings also validate the use of the proposed JLCRLZF-WDE as a practical and efficient solution for scenarios requiring robust BER performance with minimal additional SNR.\n\nAdditionally, asTable 3provides critical insights into the performance of various equalizers in achieving a BER of 10−4. The LMMSE-WDE in the DWT domain stands out as the optimal benchmark, requiring the least SNR (17.97 dB). This demonstrates its ability to effectively suppress interference and manage noise in high-precision communication scenarios. Among the other equalizers in the DWT domain, the LMMSE-FDE and the proposed JLCRLZF-WDE perform remarkably well, with SNR requirements of 18.28 dB and 18.24 dB, respectively. Their minimal SNR differences (0.31 dB and 0.27 dB) from the benchmark highlight their potential as robust alternatives, especially the JLCRLZF-WDE, which balances performance and simplicity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.t003\n\nIn contrast, the LZF-based equalizers (LZF-WDE and LZF-FDE) and all DFT-based equalizers exhibit significantly poorer performance, requiring SNR values exceeding 30 dB. This large disparity underscores the limitations of both the LZF strategy and the DFT transform in achieving low BER levels, particularly in scenarios demanding high precision. These results strongly advocate for the use of DWT-based equalizers, as they consistently deliver better performance due to the wavelet domain’s superior time-frequency resolution and its ability to localize interference effectively.\n\nOverall, the proposed JLCRLZF-WDE emerges as a practical and efficient solution, offering near-optimal performance with a minimal SNR penalty compared to the LMMSE-WDE. This makes it a compelling choice for low-BER communication systems that require high robustness with manageable computational complexity. The findings further emphasize the importance of selecting appropriate equalization strategies and transform domains to optimize system performance in demanding communication environments.\n\nFig 14provides a detailed comparison of the BER performance for the proposed JLCRLZF-WDE and the LMMSE-FDE (based on DFT) under varying estimation error levels and SNR conditions. Each subfigure (i.e.,Fig 14a,Fig 14b, andFig 14c) illustrates the performance at SNR levels of 15 dB, 20 dB, and 25 dB, respectively. The analysis incorporates estimation errors ranging from 0% to 100%, which simulate inaccuracies in co-CFO and Rayleigh fading channel coefficients. These errors are critical in real-world scenarios, where imperfect channel estimation and synchronization often degrade system performance. By including these factors, the results offer a practical evaluation of the robustness of the equalizers. The proposed JLCRLZF-WDE consistently demonstrates superior performance across all scenarios, particularly at higher SNR levels and larger estimation errors (50%-100%). This resilience stems from its WDE, which provides better time-frequency localization and more effective interference mitigation than the frequency domain used by the LMMSE-FDE. The JLCRLZF-WDE shows remarkable stability at SNRs of 20 dB and 25 dB, maintaining low BER despite significant estimation errors, which highlights its adaptability for high-quality communication systems. In contrast, the LMMSE-FDE performs reasonably well at low estimation error levels (0%-20%) but suffers a steep decline as errors increase, particularly at lower SNRs like 15 dB, where noise and interference are more prominent. Overall, these results underscore the effectiveness of the proposed JLCRLZF-WDE compared to the conventional LMMSE-FDE. The JLCRLZF-WDE is a robust and versatile solution, capable of maintaining low BER across a wide range of SNRs and estimation error scenarios, even under extreme conditions. Its resilience to channel imperfections and frequency offset errors makes it a strong candidate for modern communication systems, where reliability and high performance are essential. Conversely, the LMMSE-FDE’s performance limitations, especially in high-error environments, highlight the need for more advanced equalization strategies like those employed in the JLCRLZF-WDE.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g014\n\nThe complexity estimations of various equalizers are presented in this section. Half flops can be used to execute real multiplication, addition, and division in a single operation [36]. The quantity of floating-point operations completed in a second is measured in “flops”. The total count of operations and floating-point operations (flops) related to different mathematical operation situations is shown inTable 4. Meanwhile,Table 4outlines the computational steps involved in basic mathematical operations, such as addition, multiplication, and division, for both real and complex numbers. It highlights how the complexity increases when dealing with complex arithmetic due to the need for additional operations, such as handling real and imaginary components. This table serves as a foundation for understanding the computational cost of individual operations used in more extensive processes.Table 5shifts focus to full-matrix computations, covering operations like matrix-matrix multiplication, matrix inversion, and matrix-vector multiplication. It distinguishes between operations on real and complex matrices, emphasizing how the type of matrix and the operation performed influence the overall computational cost. This table is particularly useful for evaluating the efficiency of matrix-based algorithms in various applications. So, for each of the subsequent equalizations, compute the total number of operations and flops for a 2 × 2 MIMO-OFDM network. It should be noted that all equalizers are implemented for complete matrix implementations (i.e.,).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.t005\n\nHowever, the complexity analysis aims to estimate the number of flops required, beginning with the generation of the polar-NRZ bits and continuing through to the estimation of the recovered bits. The overall processing is quite consistent, but differences arise based on the type of equalizer used (i.e., LZF, LMMSE, or JLCRLZF) and the domain of the equalizer (i.e., FDE or WDE).\n\nThe following analysis estimates the flop counts for various common processes at both the transmitter and receiver sides\n\nAt the transmitter, the generated polar-NRZ bits are multiplied by the IDWT or the IDFT matrix [38].\n\nAt the receiver, the flops count depends on the equalization method used:\n\nNow, let’s compute the total number of flops for each system, considering the respective equalizer and equalizer domain:\n\nTotal flops:\n\nIn each case, the constants. andrepresent the additional flops involved in solving the WDE and FDE algorithms. These constants (i.e.,or) depend on the specific algorithm and its implementation (i.e., the BMA bandwidth).\n\nThe LZF general solution matrix may be expressed as follows:\n\nwherecontains the IRM in the case of WDE, or Fourier transform of the IRM in the case of FDE. According to Eq. (24), entails the production of two complex matrices via matrix multiplication and matrix inversion. For simplicity, we start with. Multiplying two complex matrices requiresoperations, according toTables 4and5. Complex matrix inversion necessitatesoperations. The matrix inversion may be validated using the Singular Value Decomposition (SVD) concept [37]. The LZF solution matrix is multiplied by the received complex vector after the removal of the CP. This step involves a vector-matrix multiplication (complex-complex), which requiresoperations. Consequently, the total number of operations to construct the LZF equalizer solution matrix and multiply it by the received vector amounts to, corresponding toflops. Note that, the primary general challenge of LZF equalization is the noise increase problem produced by direct matrix inversion.\n\nThe LMMSE’s solution matrix may be expressed as follows:\n\nwhere the SNR value is represented by the term, the AWGN covariance matrix is represented by, the expectation of  #  is represented by, and the transmitted signal power is represented by. The discrepancy between Eqs. (24,25) represents an estimate of the SNR values, that might have caused a processing time delay in comparison to LZF besides the addition of the SNR to the identity matrix. As a result, the LMMSE needsflops in addition to the SNR computation.\n\nNow, let’s calculate the number of operations/flops for various equalizer types for a generalMIMO configuration as follows:\n\nAs previously mentioned, at the transmitter side, each branch requiresflops. Therefore, fortransmitted branches, the total number of flops isflops. On the receiver side,branches are needed at the receiver side, which requiresIDFTs,DFTs, andDWTs, in addition to the solution matrix for the LZF equalizer. The computational cost of the requiresIDFTs,DFTs, andDWTs isflops. The solution matrix of the LZF equalizer requiresflops. Therefore, for anMIMO configuration, the total number of flops is.\n\nThe number of the flops for the case of LMMSE-FDE based on DWT is similar than that of the LZF-FDE based on DWT in addition to the SNR value calculation andflops. Thus, this corresponds toflops.\n\nThe LZF-WDE requires the same number of flops as the LZF-FDE, but without the need for DFT and IDFT processing. This is because the LZF-WDE uses the DWT instead. Therefore, the total computational cost is given byflops.\n\nSimilarly, the LMMSE-WDE requires the same number of flops as the LMMSE-FDE, but without the need for DFT and IDFT processing, as it uses the DWT instead. Therefore, the computational cost isflops, in addition to the processing time required for SNR estimation.\n\nSimilarly, the JLCRLZF-WDE needs the same number of flops as that of the LMMSE-WDE, whichflops with no SNR calculation required.\n\nAt the transmitter side, each branch requiresflops. Therefore, fortransmitted branches, the total number of flops isflops. On the receiver side,branches are needed at the receiver side, which requiresDFTs, in addition to the solution matrix for the LZF equalizer. The computational cost of the requiresDFTs isflops. The solution matrix of the LZF equalizer requiresflops. Therefore, for anMIMO configuration, the total number of flops is.\n\nLikewise,flops are needed for the LMMSE-FDE based on DFT in addition to the SNR value calculation.\n\nTable 6presents the computational requirements, expressed as the number of flops, for various equalization methods in anMIMO system configuration. The table compares different combinations of equalizers (e.g., LZF, LMMSE, JLCRLZF), transform methods (e.g., DWT or DFT), and equalization domains (e.g., WDE or FDE). It provides a detailed breakdown of the complexity associated with each approach, highlighting how the choice of equalizer, transform, and domain affects the overall computational demand. This comparison is essential for evaluating the trade-offs between computational efficiency and system performance in different MIMO equalization schemes.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.t006\n\nAs shown inTable 6, all the systems presented exhibit a computational complexity of order, which implies that their computational demands become comparable for large values ofN. To better understand the impact of MIMO configuration and data lengthNon the computational load, we analyze the proposed JLCRLZF-WDE system.Fig 15illustrates the number of flops for variousMIMO configurations and different lengths of the transmitted data vectorN, assumingfor simplicity. The figure highlights a clear trend: the number of flops increases asN,i, orjgrows. This increase is expected, as larger data lengths and more complex MIMO configurations demand greater computational resources for processing. The analysis underscores the importance of balancing computational efficiency and performance when scaling MIMO systems, particularly for scenarios involving high data rates or large-scale antenna arrays.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.g015\n\nThe percentage reduction in simulated time for each type of equalizer compared to the proposed JLCRLZF-WDE is as follows:\n\nwhererepresents the simulation time of the proposed JLCRLZF-WDE andrepresents the simulation time of the comparable equalizer. The negative value of the simulation time inTable 7indicates that the comparative equalizer takes less time than the reference, which is the proposed JLCRLZF-WDE.Table 7compares various equalization methods for a 2 × 2 MIMO configuration, focusing on simulation time, efficiency, and the inclusion of SNR estimation. The methods are categorized by the type of equalizer (e.g., LZF, LMMSE, JLCRLZF), the transform method (DWT or DFT), and the equalization domain (WDE or FDE). LZF with DWT and WDE demonstrates one of the shortest simulation times (21.58 ms), while LMMSE with DWT and FDE has the longest (24.83 ms), indicating that the choice of equalizer and domain significantly impacts processing speed. Regarding efficiency, LZF with DWT and FDE shows the lowest (-4.98%), whereas LMMSE with DWT and FDE achieves the highest (12.4%), showcasing the trade-offs between computational cost and performance. Additionally, some methods, such as LMMSE with DWT and WDE or JLCRLZF with DWT and WDE, incorporate SNR estimation, offering better adaptability to changing channel conditions. Overall, for a 2 × 2 MIMO configuration, the selection of an equalization method depends on balancing computational demands, efficiency, and the need for SNR estimation.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0317097.t007\n\nAfter discussing the complexity analysis, we believe that certain modifications related to the concept of BMA could be implemented to reduce the computational complexity of the proposed JLCRLZF-WDE in some way as many zeros are present in the matrix to be used for equalization process. Incorporating BMA techniques may lead to more efficient computations, optimizing the overall performance. Additionally, there are several other limitations in the current approach that could be addressed and optimized in future work as Adaptive techniques. The proposed JLCRLZF-WDE could benefit from adaptive algorithms that adjust to the specific conditions of the channel or signal environment. For example, an adaptive approach could dynamically adjust the degree of approximation in the BMA or the size of the matrix, depending on the SNR or the channel conditions, leading to a more efficient computational approach in varying environments.\n\nThe practical relevance of the proposed JLCRLZF-WDE can be seen in its potential applications in real-world wireless communication systems. For instance, in millimeter-wave communication scenarios, such as 5G and beyond, the JLCRLZF-WDE’s ability to mitigate co-CFO and ISI while reducing computational complexity makes it highly suitable for high-frequency, high-speed networks with dense deployments. Similarly, in WSNs, where energy efficiency and reliable communication are critical, the proposed approach enhances spectral efficiency and reduces power consumption, aligning with the operational constraints of such networks. Furthermore, its simplicity and computational efficiency make it feasible for hardware implementation on devices like Field-Programmable Gate Arrays (FPGAs) and Digital Signal Processors (DSPs). By addressing challenges like imperfect channel estimation and high Doppler effects, the JLCRLZF-WDE demonstrates robust performance under practical conditions, as highlighted in updated simulations. These capabilities make it a strong candidate for applications in vehicular communication systems, scalable massive MIMO systems, and other next-generation wireless technologies, where low latency and resilience to interference are essential.\n\nIn this study, we introduced the JLCRLZF-WDE for MIMO-DWT-OFDM systems and compared its performance against various equalizers through multiple evaluations. The proposed JLCRLZF-WDE effectively integrates the equalization and co-CFO compensation processes. It is specifically designed to address challenges such as co-CFO, ISI, co-channel interference, and noise. To achieve a BER of 10-4, the traditional LMMSE-FDE based on DWT necessitates an additional SNR of approximately 12.03 dB. Notably, the JLCRLZF-WDE demonstrates a significant reduction in simulation time, approximately 12.4% less than the conventional LMMSE-FDE based on DWT. Furthermore, computer simulations indicate that the JLCRLZF-WDE offers improved computational efficiency compared to other equalizers. This balance between complexity and BER performance presents a viable option for future advancements in MIMO-DWT-OFDM systems.\n\nFor future work, the proposed JLCRLZF-WDE can be extended and optimized for other types of fading channels, such as Rician or Nakagami, to further validate its performance in diverse communication environments. Future work on the JLCRLZF-WDE method could explore several optimizations to enhance its performance. These include integrating advanced channel estimation algorithms to improve equalization accuracy, especially in challenging wireless environments with severe impairments. Additionally, refining the BMA by exploiting matrix sparsity could reduce computational complexity while maintaining accuracy. The inclusion of adaptive algorithms would allow the method to dynamically adjust to varying channel conditions, improving efficiency across diverse environments. Future research could also evaluate alternative wavelet transforms, such as biorthogonal or symlet wavelets, for better time-frequency localization. Expanding the method to support Non-Orthogonal Multiple Access (NOMA) would enable its application in next-generation communication systems. Investigating non-linear equalization techniques, such as decision-feedback equalization or neural network-based approaches, could further enhance performance in highly non-linear channels. Finally, extending the framework to accommodate higher-order MIMO systems and considering its performance under 5G or beyond networks would offer insights into its scalability and relevance to next-generation systems.\n\nThe authors gratefully acknowledge the Deanship of Graduate Studies and Scientific Research, Jazan University, Saudi Arabia, Project Number: GSSRD-24.",
    "category": "physics"
  },
  {
    "title": "Validity and reliability of the Critical-Care Pain Observation Tool (CPOT) for critically ill pediatric patients",
    "authors": "Haruhiko Hoshino, Mitsuki Ikeda, Yujiro Matsuishi, Yuki Enomoto, Nobutake Shimojo, Misaki Kotani, Shunsuke Kobayashi, Takahiro Kido, Satomi Hayashi, Yoko Furuya, Yoshiaki Inoue, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0320373",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320373",
    "content": "In some regions, critically ill pediatric and adult patients are cared for in the same intensive care unit, complicating pain assessment due to mixed age groups. To address this, it is essential to use pain scales that are applicable to a wide age range. The Critical-Care Pain Observation Tool (CPOT) was developed to assess pain in both intubated and non-intubated adult patients. However, its applicability in pediatric patients has not been confirmed. The purpose of this study was to evaluate CPOT for critically ill pediatric patients.\n\nWe conducted a prospective observational study in an eight-bed open PICU from January 2022 to March 2023. Three research nurses independently assessed pain using CPOT, the Face, Legs, Activity, Cry, Consolability (FLACC) scale, and an Observational Visual Analog Scale (VAS obs). Criterion-related and construct validity were examined using Spearman’s rank correlation coefficients between CPOT, VAS obs, and FLACC. Diagnostic performance was evaluated via ROC analysis using a FLACC score ≥ 4 as the reference. CPOT scores with and without medical interventions were compared using the Mann–Whitney U test, and inter-rater reliability was assessed with Cohen’s weighted κ.\n\nNinety-one patients were observed 165 times. CPOT strongly correlated with VAS obs (Spearman’s ρ =  0.87, p <  0.01) and FLACC (Spearman’s ρ =  0.84, p <  0.01). At a CPOT cut-off score of 3, sensitivity was 100% and specificity was 96.7%. CPOT effectively reflected pain levels during medical interventions (p <  0.01), and inter-rater reliability was high (weighted κ =  0.89, 95% CI: 0.799–0.941).\n\nThis study suggests that CPOT may be a useful tool for pain assessment in pediatric patients.\n\nCitation:Hoshino H, Ikeda M, Matsuishi Y, Enomoto Y, Shimojo N, Kotani M, et al.  (2025) Validity and reliability of the Critical-Care Pain Observation Tool (CPOT) for critically ill pediatric patients. PLoS ONE 20(4):\n           e0320373.\n        \n        https://doi.org/10.1371/journal.pone.0320373\n\nEditor:Robert Jeenchen Chen, Stanford University School of Medicine, UNITED STATES OF AMERICA\n\nReceived:August 17, 2024;Accepted:February 18, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Hoshino et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:His research was funded by the Japan Society for the Promotion of Science (JSPS) under the Grant-in-Aid for Research Activity Start-up (Research Activity Start-up). The grant number for this project is 21K21146, also identified by the systematic task number JP21K21146. The total allocation for this project was ¥2,990,000. The research titled “Development of a Foundation for the Management of Pain, Sedation, Drug Withdrawal Symptoms, and Delirium in Critically Ill Pediatric Patients” was supported by the funder to develop non-verbal assessment tools for evaluating symptoms such as pain, agitation, drug withdrawal symptoms, and delirium in pediatric patients admitted to intensive care units. These patients often cannot verbally express their symptoms due to developmental stages, intubation, or other physical constraints. Currently, there are no validated assessment tools available in Japan for these purposes. This research aimed to accurately measure and adapt existing symptom assessment tools for critically ill pediatric patients to the domestic context. The funding organization, Japan Society for the Promotion of Science, had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript. The URL for the funder ishttps://www.jsps.go.jp/english/.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nManaging pain in pediatric patients in the Pediatric Intensive Care Unit (PICU) presents complex challenges that are influenced by various factors. Critically ill children in the PICU frequently undergo invasive procedures that are inherently painful, necessitating meticulous pain management approaches [1]. One of the primary challenges is the accurate assessment of pain, which is particularly problematic in critical care environments [2]. Various assessment tools and scales have been validated to evaluate pain levels in critically ill pediatric patients, including the Face, Legs, Activity, Cry, Consolability (FLACC) scale and COMFORT-B [3,4]. The indications for these tools for pediatric patients are also recommended in the guidelines [5].\n\nHowever, it is important to note that not all critically ill pediatric patients are treated in dedicated PICUs, and in some facilities—both in Japan and elsewhere—pediatric and adult patients may share the same unit [6–8]. Caring for critically ill pediatric patients requires specialized skills; however, pediatric patients with critical conditions are not always managed exclusively in a PICU. In these mixed-age units, the requirement to appropriately assess patients of all ages can increase the workload of medical staff and potentially lead to inadequate pain assessment. Age-inclusive pain scales are essential for effective management. The Behavioral Pain Scale (BPS) has been evaluated in pediatric patients [9]. However, as this tool is primarily designed for intubated populations, its use in non-intubated children is limited, highlighting the need for more versatile pain assessment tools.\n\nThe Critical-Care Pain Observation Tool (CPOT) was originally validated in adult patients [10]. The tool evaluates four specific criteria that could conceivably be applicable to pediatric patients: facial expression, body movements, compliance with the ventilator for intubated patients, and vocalization for extubated patients. Despite its widespread use in adult ICUs, its applicability in critically ill pediatric patients remains underexplored [11].\n\nThis study aimed to evaluate the validity and reliability of the Critical Care Pain Observation Tool (CPOT) in pediatric patients in a critical care setting.\n\nThis study was a prospective observational research project conducted between January 2022 and March 2023. The subjects were pediatric patients admitted to the eight-bed open PICU at the University of Tsukuba Hospital. Patients with central nervous system diseases, a history of neurological conditions such as hypoxia and cerebral palsy, and those receiving muscle relaxants were excluded from this study because of the potential difficulty in accurately assessing pain levels. Demographic and clinical data were collected from participants. A detailed explanation of the study was provided both verbally and in writing. As all participants in this study were minors, written informed consent was obtained from their parents or guardians. This consent process was documented, and written records were retained by the research team. In accordance with the ethical standards of the responsible committee on human experimentation (institutional or regional) and the 2013 version of the Helsinki Declaration, this study was approved by the Ethics Committee of the University of Tsukuba Hospital on August 8, 2016 (approval #H28-085, study title: The Study on Delirium, Pain, Sedation, and Withdrawal Symptoms in Pediatric Intensive Care Unit). As additional tools, including the CPOT, were incorporated into the study, amendments were submitted to the ethics committee and subsequently approved. All procedures performed in this study involving human participants complied with the ethical standards of the institution.\n\nTo assess the validity and reliability of the CPOT in measuring children’s pain, a team comprising three research nurses independently, blindly, and simultaneously employed three different pain measurement scales: CPOT, FLACC scale, and the observational Visual Analog Scale (VAS obs). To minimize potential bias, the VAS obs was administered prior to the CPOT and FLACC assessments. Multiple raters were employed to enhance inter-rater reliability testing.\n\nThe CPOT was designed to assess pain in critically ill adult patients who are unable to communicate verbally due to conditions such as sedation, intubation, or their underlying diagnosis [10]. CPOT consists of four distinct categories: facial expression, body movements, compliance with the ventilator (intubated patients) or vocalization (extubated patients), and muscle tension—each rated on a three-point scale (0–2), with a total score of 0 to 8. A back-translated Japanese version of the CPOT was used in this study [12]. The FLACC scale is a behavioral assessment tool designed to quantify postoperative pain intensity in children [4]. Each of its five categories—face, legs, activity, cry, and consolability—is rated on a scale from 0 to 2, resulting in a total score ranging from 0 (no pain) to 10 (severe pain), with a threshold value of 4. This scale is also recommended by guidelines as a pain assessment tool for critically ill patients [5]. Our previous research has confirmed the validity and reliability of the Japanese version of the FLACC scale [13]. The FLACC scale is the approved tool currently employed to evaluate pain in the PICU of our hospital. The visual analog scale (VAS), first introduced in 1921, was a unidimensional tool for quantifying subjective pain intensity using a 10 cm line labeled from “no pain” to “worst imaginable pain” [14]. However, since younger pediatric patients cannot self-report their pain, we utilized the observational VAS (VAS obs) instead. The VAS obs is a unidimensional tool in which healthcare professionals assess and pain based on observed patient symptoms, using a 10 cm line ranging from ‘no pain’ to ‘worst imaginable pain’ similar to the VAS. The use of VAS obs for assessing the validity of pain scales in neonates and children has been reported in previous studies [15,16].\n\nThe sample size was calculated using the Spearman’s correlation coefficient. Because the required number of participants decreases as Spearman’s ρ increases (e.g., 0.7 =  18, 0.6 =  24, 0.5 =  33, 0.4 =  51), we chose ρ =  0.3 as the minimal threshold for detecting a “low” correlation. According to previous definitions, |ρ| <  0.3 indicates a negligible correlation, whereas 0.3 ≤  |ρ| <  0.5 represents a low correlation [17]. We aimed to detect this threshold at a significance level (α) of 0.05 and a power (1−β) of 0.8. From these calculations, we determined that we needed at least 89 participants.\n\nPatient characteristics, including demographics such as age, sex, mortality risk, intubation status, and diagnoses, were obtained from clinical charts. Criterion-related validity of the CPOT was assessed through its correlation with the VAS obs, while construct validity was evaluated via its correlation with the FLACC scale, using Spearman’s rank correlation coefficient (ρ). Receiver Operating Characteristic (ROC) curve analysis was used to determine the diagnostic performance of the CPOT, with an FLACC score of 4 or higher as the threshold. The Mann–Whitney U-test was used to compare differences in CPOT scores during medical interventions, such as intravenous catheterization, suctioning, and bathing. The inter-rater reliability for CPOT scores was assessed using Cohen’s weighted κ test.\n\nData analysis was conducted using Python programming language (version 3.8) and EZR (Saitama Medical Center, Jichi Medical University, Saitama, Japan), a graphical user interface for R (The R Foundation for Statistical Computing, Vienna, Austria) [18]. All statistical tests were two-sided, and a p-value of less than 0.05 was considered statistically significant. Bootstrap methods with 1,000 resamples were used to calculate 95% confidence intervals (CIs). Data manipulation was performed using the pandas library (version 1.2.3), and statistical computations were executed using the scikit-learn library (version 0.24.1).\n\nIn total, 135 patients were enrolled in this study. After excluding 20 patients with central nervous system diseases and an additional 24 patients with a history of neurological conditions, 91 pediatric patients were included in the study (Table 1). As shown inTable 2, these 91 patients were observed a total of 165 times (each subject was evaluated between one and five times). The median age of the included patients was 13 months (range: 0–214 months).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320373.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320373.t002\n\nAs demonstrated inTable 3, criterion-related validity was assessed using CPOT and VAS obs scores, while construct validity was examined using Spearman’s rank correlation coefficient (ρ) between CPOT and FLACC. The correlation coefficients were high, with all values exceeding 0.7, indicating a strong and significant relationship (p <  0.01). This finding underscores the robust validity of CPOT in diverse patient groups.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320373.t003\n\nThe optimal cut-off score for CPOT was greater than 3, as demonstrated by the Receiver Operating Characteristic (ROC) curve (Fig 1). The AUC (Area Under the Curve), sensitivity, specificity, PPV (Positive Predictive Value), and NPV (Negative Predictive Value) at cut-off scores of ≥ 2, ≥ 3, and ≥ 4 are shown inTable 4. In particular, the CPOT cut-off of ≥ 3 yielded excellent diagnostic performance, with an AUC of 0.98, sensitivity of 100%, and specificity of 96.7%. The positive likelihood ratio was 30.2 and the negative likelihood ratio was less than 0.01 at this threshold, highlighting the clinical significance of this cut-off score. CPOT scores were significantly higher in patients who were undergoing medical interventions than in those who were not (p <  0.01).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320373.t004\n\nThe blue line represents CPOT ≥  2 (AUC =  0.95), the yellow line represents CPOT ≥  3 (AUC =  0.98), and the green line represents CPOT ≥  4 (AUC =  0.89). The optimal CPOT cut-off score was identified as 3, with a sensitivity of 100% and a specificity of 96.7%.\n\nThe blue line represents CPOT ≥  2 (AUC =  0.95), the yellow line represents CPOT ≥  3 (AUC =  0.98), and the green line represents CPOT ≥  4 (AUC =  0.89). The optimal CPOT cut-off score was identified as 3, with a sensitivity of 100% and a specificity of 96.7%.\n\nhttps://doi.org/10.1371/journal.pone.0320373.g001\n\nThe inter-rater reliability of the CPOT scores across observers, as assessed by two nurses, was greater than 0.8, as demonstrated inTable 5, indicating strong agreement between nurses in evaluating pain using the CPOT scale. Weighted κ values ranged from 0.74 to 1.0 across different patient subgroups, further confirming the reliability of CPOT in this pediatric critical care setting.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0320373.t005\n\nWe evaluated the validity and reliability of the CPOT in critically ill pediatric patients. CPOT was originally developed to measure pain in critically ill adult patients who were unable to communicate verbally because of their diagnosis, sedation, or intubation [10]. Given its widespread international adoption and high regard for its validity and reliability in adult patient populations [11], we investigated whether this tool, initially conceived for adults, could also be applied in pediatric settings. The results of our study indicate that CPOT items were observable in pediatric patients, providing new insights its potential application and suggesting that it can be adapted effectively to younger populations.\n\nIn this study, CPOT scores exhibited a high correlation with VAS obs scores, as evaluated by the attending nurses. The VAS obs is a unidimensional tool designed to quantify pain intensity, utilizing a 10 cm line with endpoints labeled ‘no pain’ and ‘worst imaginable pain.’ This scale is widely used to compare pain between patients and to monitor the course of pain in individual patients. Previous research has employed the VAS obs to evaluate the validity of pain scales in pediatric populations [19,20]. Additionally, CPOT scores were highly correlated with the FLACC scale. This is particularly significant because the FLACC scale is frequently used to assess critically ill pediatric patients [21]. Our research team has extensive experience with the FLACC scale, which evaluates its domestic version [13]. CPOT demonstrated a high correlation with both the VAS obs and FLACC scales in a pediatric setting. Moreover, the strong correlation and the significant difference in CPOT scores during medical interventions collectively underline the scale’s capacity to capture fluctuations in pediatric pain states.\n\nIn addition, this study found that when using the FLACC scale as a benchmark for pain assessment, a CPOT positive threshold score of three or higher yielded the highest AUC. This differs from the original CPOT, which typically uses a cut-off score of 2 (ranging from 0 to 8 across four categories). However, it is important to note that the cutoff value may vary depending on the population and situation, and past reports have shown cutoff values ranging from 2 to 3 in adults [22]. This suggests that there is a high likelihood of multiple cut-off values being reported for pediatric populations in future studies.\n\nThe higher the value of weighted kappa, the stronger the agreement, with values ranging from 0 to 1. Values between 0.81 and 1.00 indicate “almost perfect” agreement, whereas those between 0.61 and 0.80 are considered “substantial” [23]. In our study, weighted kappa values for CPOT—including all observations and subgroups—fell within these ranges, demonstrating high levels of inter-rater reliability. The four dimensions of the CPOT demonstrated moderate to excellent inter-rater reliability. However, for ‘body movement’ the agreement was only ‘substantial’ likely because of differing assessments of subtle movements in children. Compared with adults, children tend to move more restlessly, and this characteristic may have impacted the consistency of the evaluations. Therefore, special attention may be needed when assessing ‘body movement’ in pediatric patients. In prior research, the agreement among nurses for scoring CPOT has also been reported to be ‘moderate’ [24,25]. Considering these results, the inter-rater reliability obtained in our study could indicate the reliability of CPOT in pediatric patients.\n\nPain assessment is limited in some areas [26–28], and we believe that one of the reasons is the inconvenience of switching between assessment tools depending on each patient’s age. Implementing CPOT in mixed-age intensive care units could address this issue by allowing both pediatric and adult patients to be evaluated with a single tool, thereby promoting consistency in pain assessment across different age groups. Furthermore, CPOT’s applicability to both intubated and extubated patients simplifies the measurement process, making it feasible to monitor pain continuously throughout the course of critical care. Such a unified approach may not only streamline clinical workflows but also foster more integrated pain management protocols. Taken together, these advantages underscore the value of exploring CPOT’s broader adoption in settings where patient demographics and ventilation status frequently vary.\n\nThis study had several limitations. First, patients with neurological conditions were excluded. Previous studies have used the FLACC and CPOT scales to assess these patient populations [29,30]. The evaluation of pain in this group is very important, and it is necessary to investigate whether CPOT can be used for assessment in the future. We are considering an evaluation of this group in future research. Excluding these patients might introduce a selection bias, as neurological impairment can significantly alter pain perception and expression. Second, the assessment data were analyzed only by a single pair of nurses. Therefore, it should be considered that this pair could have unconsciously assigned favorable VAS scores to the still unestablished CPOT and FLACC scales. In future studies, it will be important to include a larger number of nurses to confirm continued inter-rater reliability. Third, this study was conducted as an initial validation test in a single ICU with a relatively small number of pediatric patients and limited associated clinical diagnoses. Future trials involving a larger cohort, multiple PICU, and a wider spectrum of primary clinical diagnoses (e.g., surgeries other than cardiovascular, primary pulmonary disease, acute infection) are required for further validation and foundational data collection. To address these limitations, we recommend a multi-center approach to enhance generalizability, alongside refining the scoring criteria to better account for varied neurological and developmental statuses. Moreover, it is crucial to validate CPOT among patients receiving high flow nasal cannula oxygen and non-invasive positive ventilation, as these methods of respiratory support are increasingly being utilized on a consistent basis.\n\nOverall, this study contributes to the existing literature by offering an initial demonstration that CPOT is both valid and reliable in critically ill pediatric populations, thereby expanding its known scope from adult-only usage. While our findings highlight CPOT’s feasibility and potential to unify pain assessment across age groups, future research will be critical for corroborating and refining these observations through larger and more diverse patient populations.\n\nThe results of this study suggest that the CPOT could be a useful tool for pain assessment in pediatric patients. Further studies are urgently required to validate these findings.\n\nhttps://doi.org/10.1371/journal.pone.0320373.s001\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0320373.s002\n\n(XLSX)\n\nThe research team acknowledges the use of ChatGPT (GPT-4 September 25 version) for pre-peer review emulation. The final manuscript revisions were entirely completed by human editors and reviewers.",
    "category": "psychology"
  },
  {
    "title": "Burden of Chronic obstructive pulmonary disease in China: an analysis based on the GBD 2021 compared with the United States",
    "authors": "Rong Li, Yu Li, Chan Xiong, Wei Gao, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0321470",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321470",
    "content": "Chronic obstructive pulmonary disease is an important disease affecting physical health worldwide, and the burden of this disease has been growing since 1991 for both China and the US.\n\nTo examine the changes in the burden of COPD in both China and the US between 1990–2021.\n\nThe joinpoint analysis, age-Period-Cohort analysis, decomposition analysis, predictive analysis methods were used to describe prevalence, incidence, death, and disability-adjusted life years for COPD in China and the US.\n\nCompared with China, all four measures of the US COPD burden were higher than they had been in 1990. The burden of COPD increases with age in China. Conversely, in the US, the burden of COPD is getting younger. The epidemiological changes have contributed to an increasing burden of COPD in the US, but have led to a decline in the burden of COPD in China. By 2042, the number of cases in both countries will rise, especially the death rate in the US.\n\nThe burden of COPD will not rapidly decline in the short term, both China and the US, as well as the global community, must take this disease seriously.\n\nCitation:Li R, Li Y, Xiong C, Gao W (2025) Burden of Chronic obstructive pulmonary disease in China: an analysis based on the GBD 2021 compared with the United States. PLoS ONE 20(4):\n           e0321470.\n        \n        https://doi.org/10.1371/journal.pone.0321470\n\nEditor:George Kuryan, Christian Medical College, INDIA\n\nReceived:November 14, 2024;Accepted:March 6, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Li et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All the original data comes from the GBD database(VizHub - GBD Results (healthdata.org).\n\nFunding:The Sichuan Province Traditional Chinese Medicine Research Project (2024MS597), which played a role in the decision to publish. Additionally, the Science and Technology Project of Sichuan Province (2021YFS0039) provided support for this work, contributing to data collection and analysis.\n\nCompeting interests:None.\n\nChronic obstructive pulmonary disease (COPD), a heterogeneous pulmonary condition characterized by breathlessness, coughing, and expectoration, is caused by persistent airflow obstruction resulting from bronchitis, bronchiolitis, or lung abnormalities [1]. Its morbidity and mortality are on the rise due to a number of reasons, including air pollution caused by industrialization, COVID-19 outbreak, increasing aging, and smoking. Among them, smoking can destroy the lung functional barrier and further aggravate COPD complications. Previous smoking history increases the risk of COPD in both China and the US [2,3]. COPD is characterized by a high prevalence, high rate of disability, and high mortality [4]. Due to industrialization-induced air pollution, the COVID-19 outbreak, and the aging population, its incidence and mortality rates have been on the rise. The prediction that COPD would become the third leading cause of death globally has indeed proven accurate [5]. A study reports that 90% of COPD-related deaths occur in middle- and low-income countries [6]. As the largest developing country, China’s COPD cases account for approximately 25% of the global total, with a COPD mortality rate of around 13.7% among individuals aged 40 and above [7]. And COPD is now the fourth leading cause of death in the US [8]. The US Healthcare Cost Institute forecasts that the medical costs associated with COPD will soar to $60.5 billion in 2029 [9]. For both nations, the disease burden of COPD is significant.\n\nThere exist significant disparities between China and the US in various dimensions such as economic development levels, lifestyle habits, and medical management systems. There have already been many analyses assessing the burden of COPD in both China and the US [7,10–12]. However, the databases for these studies are GBD 2019, which has a relative lag in terms of data availability. Secondly, they have not included prevalence, incidence, mortality, and disability-adjusted life years (DALYs) in their analyses, nor have they employed a comprehensive model. As the GBD database information is updated, it necessitates further data mining to gain a clearer understanding of the latest trends in COPD between the two countries. The inadequacy of such comparative analyses may hinder China and the US in identifying their respective shortcomings in public health policies and practices, as well as limit their learning of effective strategies and experiences for COPD. A comparative analysis of the trends and characteristics of COPD burden in both countries can provide directional guidance for future interventions, as well as crucial insights into identifying areas that require improvement and adopting successful practices from other nations.\n\nIn summary, this paper aims to use different kinds of model to analysis distinct characteristics of two countries of COPD burden to provide guidance on reducing COPD burden in both China and the US, and focus on different age groups, gender, occupation, rural population, urban population and other factors on the impact of disease burden, thereby fostering the overall health of their respective populations.\n\nOur study employed the Joinpoint 5.2.0 software developed by the American Cancer Center for segmental local non-linear regression analysis of disease trends between 1990 and 2021 (Download Joinpoint Desktop Software (cancer.gov)). Segmented regression analysis is particularly useful in analyzing trend changes or explaining the variations in the impact of predictors on the response variable. These remarkable shifts are represented by inflection points, which divide the overall trend line into several sub-sections, each indicated by an annual percentage change (APC) that denotes the degree of variation. We also estimated average annual percentage changes (AAPC) from 1990 to 2021 to gain a clearer understanding of trend changes. When APC/AAPC values and their upper 95% CI exceed zero, it indicates that the response variable is trending upwards over a certain period; Conversely, when APC/AAPC values fall below zero, it suggests a descending trend [13].\n\nThe Age-period-cohort (APC) model can investigate the impact of these factors on changes in the burden of COPD from three dimensions: age, period, and birth year. APC model can analyze the influence of these factors on COPD burden from three independent time dimensions: age effect, time effect and cohort effect. The general form of its model can be expressed as:\n\nrepresents the response variable, and μ is the population mean. is an age effect (i denotes age group). is the period effect (j denotes period). is the queue effect (k stands for queue). represents random error term.\n\nHowever, the APC model itself has a collinearity problem, that is, there is a complete linear dependence relationship between the three factors of age, cohort and period (cohort = period − age), so the traditional regression method cannot uniquely estimate the independent effects of age, period and cohort. Therefore, the intrinsic estimator (IE) algorithm is used in this study to eliminate collinearity by limiting parameter space with linear constraints, so as to provide unique, stable and small deviation estimation results [14]. Given the specificity of the IE algorithm, we have reclassified the data into consecutive five-year age groups (15–20, 25–30, etc.). The periods were also divided into consecutive five-year periods (1992–1997, 1997–2002…2017 to 2021), and thus generating five consecutive birth cohorts (1897–1901, 1902–1906…2002 to 2006). Subsequently, the disease burden for specific ages, periods, birth cohorts was represented relative to the average composite level for all ages, periods, and birth cohorts, utilizing the Relative Risk (RR) index and the 95% confidence space(95%CI).\n\nDecomposition analysis is a quantitative method for determining the extent to which differences in a single factor contribute to overall value differences, which helps reveal major heterogeneity in population and epidemiological trends [15]. To discern the factors that shaped the trend changes in COPD burden between 1990 and 2001, we performed a decomposition analysis on age structures, population sizes, and epidemiological shifts, grouping by gender [16]. All figures are done by R 4.3.3 software. The change of age structure is mainly manifested as aging. If the elderly population increases, the decomposition analysis shows the contribution rate of age structure change after controlling the other two factors. Similarly, it can show the contribution of population growth and epidemiological factors such as smoking, air pollution, and policy changes to the burden of COPD.\n\nWe employed Bayesian age-period-cohort (BAPC) analysis to predict the COPD burden in China and the US from 2021 to 2046, providing data support for future planning in terms of COPD prevention and treatment. BAPC and INLA (Integrated Nested Laplace Approximation) software packages within R 4.3.3 software for the BAPC model predictions and graphical illustrations.\n\nIn China from 1990 to 2021, the age-standardized incidence rate (ASIR), age-standardized prevalence rate (ASPR), age-standardized death rate (ASDR), and age-standardized disability-adjusted life-years rate (A-DALYs) all exhibited a downward trend, particularly for ASDR and A-DALYs, which showed a more significant decrease compared to the previous two periods (Fig 1). The AAPC of ASIR dropped 0.741% (95% CI: -0.741, -0.712) in the period between 1990 and 1996. ASIR was consistently higher in men than in the general population, and lower in women. However, the trend has been on a decline since 2001, particularly between 2010 and 2018, with a faster pace of decrease. Female infertility rates as measured by the ASIR showed a steady decline since 1990 until 2010, after which a third inflection point emerged and a rising trend persisted, with a subsequent decrease observed only after 2015. Men exhibit persistently higher ASIRs compared to the overall population. The ASPR trend as a whole appears to be on a downward trajectory, with an overall decline of 0.322% (95% CI: -0.36, -0.283) over a span of 31 years, with six turning points observed in total since the beginning of 2015. Two major peaks of ASPR were observed among males, one during the years 1990–1995 and another between 2006–2010, which contradicted the overall trend. Not until after 2010 did ASPR begin to decline rapidly, with a total AAPC drop of 0.203% (95% CI: -0.246, -0.159). A spike in the female ASPR occurred during this 31-year period, specifically between 2010 and 2015. Only after 2015 did the trend begin to reverse. Over the years, the ASDR and A-DALYs for COPD have shown a downward trend in both aggregate trends as well as by gender, all having traversed through five critical junctures. The overall ASDR’s AAPC (3.693%, 95% CI: -4.002, -3.382) showed a slightly higher decrease compared to A-DALYs (3.667%, 95% CI: -3.942, -3.409). In men, ASDR and A-DALYs were consistently higher than the overall averages, while in women, they were lower. Gender disparities in changes have shown a consistent downward trend.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.g001\n\nUnlike in China, the burden of COPD in the US has consistently risen over the past three decades, particularly between 1996 and 2004 (Fig 2). AAPC rose by 0.407% (95% CI: 0.386, 0.429), with women exhibiting a higher increase compared to the overall population (AAPC: 0.611%, 95% CI: 0.545, 0.677), especially in ASIR and A-DALY. ASPR experienced a general increase across four milestones, with rapid growth from 1996 to 2004, after which it began to decline swiftly. Over the past 31 years, the AAPC rose by 0.226% (95% CI: 0.198, 0.254), which is not a particularly rapid pace compared to China’s growth and decline in ASDR. Male ASDR has experienced three peaks since 1999, with a continuous decline since then. The AAPC decreased by 0.437% (95%CI: -0.762%, -0.11%) over time. But ASDR remains above the average. Similar to ASDR trends, the overall and female A-DALYs exhibited a rapid increase from 1997 to 2000 before stabilizing until gradually declining after 2016. The incidence of A-DALYs among males increased rapidly from 1997 to 2000, before declining sharply afterwards. The AAPC over the entire period showed an overall decrease of 0.405% (95% CI: -0.638%, -0.17%). AAPC value can be seen inTable 1.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.g002\n\nFig 3illustrates the impact of age-period-cohort factors on the incidence, prevalence, death, and DALYs for COPD in China from 1990 to 2021. Age differences have a relatively greater impact on the disease burden of COPD. The overall and female prevalence, as well as their risk of developing a disease, exhibit an escalating trend. Conversely, men’s risk of contracting COPD decreases after the age of 85–89 (RRages 85–89= 4.06, 95% CI: 1.39–1.4). Both sexes attained peak incidence rates in the age of 95–99, with an elevated RR for males (RRaged 95–99 years= 5.46, 95% CI: 1.68–1.72) compared to females (RRaged 95–99 years= 4.37, 95% CI: 1.46–1.48). Only female’s RR values of mortality and DALYs continued to rise, while the RR values of all and men decreased after 90–94 years of age, especially the RR values of male mortality decreased by about 62% after 90–94 years of age. The period effect on China’s COPD incidence and prevalence continued to show an upward trend. During the period from 1992 to 2021, the overall incidence and prevalence rates respectively rose by approximately 28% and 33%. Mortality and DALYs have remained relatively stable, with a slight downward trend in DALYs. The cohort effect on the incidence, prevalence, mortality, and DALYs of COPD in China exhibited a stable downward trend, with a smaller burden of COPD occurring among those born later.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.g003\n\nCompared with China’s APC effect, the overall prevalence trend in the US exhibited an initial increase followed by a decrease during the control period and among birth cohorts (Fig 4). The overall incidence rate rose by approximately 86% from ages 35 to 55, and then rapidly increased from 55 to 80 years old, with an RR value increase of about 63%. From the age of eighty, there is a decline trend in place. In terms of the trend influenced by age factors on the prevalence of COPD in the US, it parallels that of China. However, mortality rates increase with age, without experiencing a decline. And in the US, the age effect on DALYs for COPD is growing steadily, with no decline observed among males, which contrasts with China’s pattern. Period effects in the US burden of COPD showed an upward trend. However, the birth cohort effect on US COPD burden shows a declining trend, similar to China. Taking a comprehensive view, the APC effect on male and female COPD burden in the US is relatively minor.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.g004\n\nThe most obvious outcome is that epidemiological changes contribute negatively to China’s COPD burden. Compared to population changes, aging is the primary driver behind the increase in China’s COPD burden. Aging has led to an approximate 115% increase in the mortality rate of COPD in China. Gender groups also exhibit similar changes in trend. Aging, demographic changes, and epidemiological shifts all contribute positively to the burden in the US, particularly in terms of demographic changes. Only epidemiological changes brought about a 21% decrease in the mortality rate among American men. The trend amongst women is similar to that of the overall population.Table 2to be included in the document. (Fig 5)\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.t002\n\nFor each component, the size of the positive value indicates an increase in the corresponding burden of COPD attributed to that component; The size of a negative value indicates a reduction in the corresponding burden of COPD attributed to the component).\n\nFor each component, the size of the positive value indicates an increase in the corresponding burden of COPD attributed to that component; The size of a negative value indicates a reduction in the corresponding burden of COPD attributed to the component).\n\nhttps://doi.org/10.1371/journal.pone.0321470.g005\n\nIt can be discerned that the overall COPD burden among Chinese men showed a downward trend from 2021 to 2046, with females’ change more balanced. However, women’s ASIR and ASPR will exceed those of men, with A-DALYs projected to surpass males post-2024. In general, the US forecasts changes in trends with more stability than China, but the caseloads will continue to climb, with significantly higher mortality rates for both men. Specific caseloads and ASR values are as follows. (Table 3,Table 4,Fig 6)\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321470.g006\n\nThis paper is based on GBD 2021 high-end database, examining the COPD burden of the specific changes from 1990 to 2021. The changes in COPD burden in both countries from 2022 to 2046 were predicted. In 2021, we observed that in the US, COPD burden increased compared to 1990, while China experienced a sustained decrease. Despite the fact that the incidence and prevalence of COPD in the US were higher than those in China in 2021. China had a higher mortality rate and DALYS for COPD compared to the US. By 2046, the overall burden of COPD in China for males is expected to gradually decline, with minimal changes in the disease burden in the US; however, the mortality rate is predicted to show a mild increase.\n\nThe incidence and prevalence in the US have experienced overall growth trend, ultimately remaining higher than that of China. As evidenced by trends and decomposition analyses, ASIR and ASPR in the US saw rapid increases in 1996 but then declined swiftly in 2004. The most significant impact is demographic changes. A salient feature of the US is its racial diversity, with Latinx, Hispanic, and African Americans having a higher likelihood of developing COPD, largely due to environmental factors and unequal access to healthcare [17]. And yet, one must account for genetic defects that differentiate populations, such as the increased risk of α-1 antitrypsin deficiency in African Americans for developing COPD [18]. We infer the rise in prevalence and incidence in 1996 was due to changes in the racial composition of the US population and total population growth. Of course, demographic aging and epidemiological changes also contributed positively to its growth [19]. Following the US industrial research and development renaissance of 1996, there was a further 15% increase in occupational exposure risks. In 2004, the American economy had entered a mature phase of full-fledged growth. President George W. Bush proposed to establish a comprehensive health-care network to facilitate the sharing of health information across institutions, promoting resource sharing among medical facilities nationwide. This not only enhanced medical standards but also fostered the proliferation of multiple medical establishments, which undoubtedly reducing the prevalence of COPD. However, the COPD prevalence and incidence in the US remain higher than those in China, an observation that contrasts with Perret JL’s finding that COPD prevalence is relatively high in middle-income and low-income SDI countries [20]. Due to different national conditions, there are differences in the healthcare systems between the two countries. As of 2023, China’s medical insurance coverage rate has reached 95%, achieving “universal medical insurance” [21]. This will increase the enthusiasm of COPD patients to seek medical treatment and thereby reduce the incidence of the disease. In contrast, the healthcare system in the US adopts a mixed public-private model, and the probability of rehabilitation for those with public insurance and the uninsured will be lower.The reasons for this lie predominantly in changes to population size. Notwithstanding this, one must also consider that the US has a more comprehensive healthcare system, which leads to better documentation of COPD cases. Moreover, diagnostic criteria for COPD in China and the US may differ due to regional peculiarities. The findings of this study also suggest that the US must re-examine its efforts to reduce the prevalence and incidence of COPD.\n\nThe US COPD ASIR stands out in its specificity compared with that in China. In the US, the age group most affected by COPD is 55–80 years old, while in China, it is those aged 79 and above. The incidence of COPD in the US is showing a trend of younger onset. In recent years, the usage rate of e-cigarettes among young people in the US has been relatively high. By 2020, the rate of e-cigarette use among teenagers had reached 19.2%. E-cigarettes can exacerbate cardiopulmonary toxicity and increase the risk and incidence of COPD in adulthood. Of course, the impact of an aging population and epidemiological changes cannot be ignored [22]. Another prominent feature is that the ASIR of American women increased more than that of men from the mid-20th century to the early 21st century. This was because tobacco companies heavily promoted cigarettes to women in the mid-20th century, and cigarettes were regarded as a symbol of women’s liberation. This led to an increase in the smoking rate among women. Secondly, due to the inherent social concept of “men are superior to women”, women tended to conceal their smoking history and missed the opportunity for medical consultation. Low-income women had more opportunities for occupational exposure. Low-quality women delayed seeking medical treatment until they developed symptoms of COPD, which were all reasons for the increase in the incidence of COPD among women [23].\n\nDespite China’s overall decline in COPD prevalence and incidence, gender disparities exhibit a peculiar pattern in terms of disease rates. The disparity in prevalence between men and women has been substantial, with this difference only gradually reducing post-2015. In the male population, the incidence rates plummeted post-2010, while in females, it rose sharply post-2010 before declining gradually until after 2015. Moreover, the incidence among men appears to have fallen since 2015. Of these factors, population size changes made the greatest contribution, which we analyzed was due to the severe gender imbalance in China, with more men than women but an increasing number of those affected [24], causing the female prevalence and incidence rates to surpass those of males. Of course, demographic shifts and epidemiological changes have significant implications. Pathological changes contribute negatively. We speculate that since the implementation of gender employment equality policies in 2010, the employment rates among middle-aged and young women have increased, thereby heightening their occupational exposure risks. Subsequent policies adopted in 2012 and 2019 to protect women’s employment, among others, led to another decline in the incidence rate [25]. Certainly, female exposure to secondhand smoke and kitchen pollutants cannot be ruled out, but males have seen a lower prevalence rate post-2015, speculated to be linked to the nation’s efforts in treating COPD among males, with further investigation required. This also suggests that China must address disparities in COPD incidence between men and women. Following China’s implementation of its National Plan for Chronic Disease Control and Prevention in 2015 [26], the ASPR for COPD has seen a rapid decline. For instance, establishing an integrated cross-departmental coordination mechanism, specifying the division of responsibilities among grassroots health institutions, realizing resource sharing, and implementing tiered, targeted interventions in line with a three-tiered prevention strategy. A range of measures were employed to decrease the prevalence of COPD. Secondly, in 2015, the “most stringent” Environmental Protection Law was enacted, which rigorously tackled environmental issues and reduced the threat to public health posed by pollution.\n\nIn 2021, the burden of COPD data between China and the US showed that the majority of COPD deaths occurred among individuals aged 60+ years. As the age advances in China, the ASDR for COPD rises rapidly after 59 years, with an estimated 97% increase by the time one reaches 99. The results revealed that the mortality rate of COPD was positively proportional to age. The decomposition analysis has proven that aging is the most crucial reason for the increasing burden of COPD in China. All this underscores the direct impact of population aging on COPD mortality. China has entered a deeply aging society [27], with 21% of its total population aged 60 or above, a growing labor force, and declining fertility rates. While America’s population of those aged 60 and above constitutes only 16% of its total [28], this figure is significantly lower than that in China. There are more basic diseases in the elderly, the course of disease is long, and the use of multiple antibiotics during hospital admission causes multiple drug resistance. As one ages, their muscle composition decreases, leading to sarcopenia in many older individuals, which exacerbates the severity of COPD [29]. All these factors underscore the need to focus on the senior population as a means to reduce mortality rates.\n\nCOPD can be diagnosed and treated in its early stages to prevent later exacerbations [30]. According to studies, China’s actual diagnosis rate for COPD is 26.8%, significantly lower than the US’ 68.3% [31]. The specific procedure for diagnosing COPD in China is by no means comprehensive. This can be attributed to partial inadequacy of medical facilities in primary healthcare institutions, insufficient proficiency of medical personnel, unequal distribution of healthcare resources, and an imbalance between population size and available medical resources. This is in contrast to the comprehensive COPD diagnostic, therapeutic, and prognostic systems in place in the US [32]. At present, the revision of GOLD 2023 upgrades the COPD screening assessment tool with the addition of diagnostic measures such as chest CT scans [33]. These measures contribute to an earlier diagnosis of COPD, thereby reducing mortality rates. But achieving satisfactory results will take much longer [34]. Given China’s slower economic development compared to the US, residents’ base salaries cannot meet individual needs, thus impacting the early detection rate of COPD. Early undertreatment of COPD can lead to irreversible lung function damage, thereby increasing the risk of death [35]. The US has a higher level of public awareness regarding COPD healthcare, with residents more readily recognizing the importance of early treatment. And while the US has built out its healthcare system to ensure lost workdays and sleep hours are accounted for, residents have a much more secure foundation upon which to seek medical attention [36]. A series of measures adopted by the US could offer guidance for China in reducing COPD mortality rates.\n\nSubgroup analyses revealed that the male mortality rates were consistently higher in both China and the US. This is closely tied to male lifestyle and occupational environments. Tobacco smoke is known to be a perilous factor contributing to COPD, with males smoking at a rate 31% higher than females [37]. According to GBD 2021, China’s male population had a 44% higher mortality rate due to COPD caused by tobacco smoke inhalation compared to females [38]. According to research, one of the reasons for the growing COPD mortality rate in the US is the increase in smoking rates. In order to reduce mortality, smoking must be controlled. Professional exposure factors are the leading cause of global COPD mortality [39]. Especially in male-dominated work environments, COPD is more prevalent than in female-dominated ones, with a 34% increased risk of mortality due to underlying respiratory system diseases caused by occupational environments. In the US, the professional exposure risk contributes significantly less to COPD mortality than in China, approximately 58%. This can be attributed to differences in the industrialization processes and sector types between China and the US. Professional exposure to COPD primarily occurs during work when inhaling dust, smoke, or toxic gases. This is often observed in industrial settings. China was lagging behind advanced economies like the US in terms of technology and economic development during the first three industrial revolutions, which led to an industry dominated by agriculture and manufacturing. Consequently, an abundance of cheap labor engaged in factory occupations has led to respiratory diseases. In the Fourth Industrial Revolution, China has emerged as a leader in artificial intelligence and chip technology innovations, reducing occupational exposure risks through the conversion of industries, and, of course, more significantly, applying technological innovations to healthcare to enhance medical standards and reduce mortality rates [40].\n\nWhile China’s A-DALYs show a downward trend, they remain higher than those in the US. For China, the threat to A-DALYs growth for COPD is environmental pollution. The rapid industrialization has brought about negative impacts in the form of pollution, yet China is actively tackling this issue with multiple measures, resulting in significant progress as witnessed by the sustained decrease in A-DALYs. Population aging contributes to an approximately 88% increase in A-DALYs, thus highlighting the need to address the threat posed by aging to DALYs. While the US’s A-DALYs have consistently lagged behind China, their trend has not been one of constant decline. There is a marked change, manifested by a rapid decline in A-DALYs among males since 2000. Decomposition analysis suggests that the negative contribution of epidemiological changes to A-DALYs for males is approximately 18%. Therefore, it is inferred that this improvement in male smoking prevalence is closely linked with the series of anti-smoking policies enacted in the US around the year 2000. China should further learn from America’s tobacco-control policies, as a comprehensive smoke-free policy could reduce COPD mortality [41]. Various measures combining traditional Chinese and Western medicine treatments are adopted to assist in quitting smoking. But the US’s COPD burden is not showing a sustained downward trend, which suggests that more efforts are needed to change the status quo in the country.\n\nFor the prediction of future burden of COPD, for the US, the key point is the increase in mortality rate. To control the mortality rate, early prevention of COPD can be carried out. Not only should health education be provided to the public, but pulmonary function tests should also be included in the essential items of physical examinations. The medical insurance system can learn from China and expand the coverage of medical insurance and improve the visit rate. Big data models can be used to monitor the condition of COPD patients. For China, the disease burden of Chinese men will show a downward trend, but it is not obvious for women. This suggests that China should pay more attention to women. The main influencing factors for Chinese women to suffer from COPD are air pollution, second-hand smoke, and occupational exposure. Promote the use of clean fuels, educate women to ventilate more when cooking to reduce the impact of air pollution. Reduce exposure to second-hand smoke through smoking policies, enhance self-protection awareness for women in high-risk occupations, and reduce exposure to harmful gases and dust.\n\nIn conclusion, COPD burden is severe in both countries and worldwide, yet it will not witness significant changes in the next two decades. China should study the measures employed by the US in controlling mortality and DALYs, while the US should learn from China’s approach to reducing prevalence and incidence rates. Countries should work together to reduce the burden of COPD.\n\nWe appreciate the works by the Global Burden of Diseases (GBD) collaborators. We also thanks to Xiao Ming (Xiaoming_room@hotmail.com) for his help in our exploration of GBD database.",
    "category": "psychology"
  },
  {
    "title": "An innovative randomized response model based on a customizable random tool",
    "authors": "Ahmad M. Aboalkhair, Mohammad A. Zayed, Tamer Elbayoumi, Abdullah Alnefaie, Mahmaod Alrawad, Ahmed M. Elshehawey, (PLOS)",
    "publish_date": "2025-04-18",
    "doi": "https://doi.org/10.1371/journal.pone.0319780",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319780",
    "content": "This paper suggests an innovative randomized response model utilizing customizable random tool. The suggested model offers a general framework for some previously pioneering randomized response models and generates new efficient models. Comparison of the efficiency between one of these newly generated models and other groundbreaking models through theoretical and numerical ways, demonstrates higher efficiency for the new generated model. Additionally, ethical considerations and privacy protection of the suggested model are examined.\n\nCitation:Aboalkhair AM, Zayed MA, Elbayoumi T, Alnefaie A, Alrawad M, Elshehawey AM (2025) An innovative randomized response model based on a customizable random tool. PLoS ONE 20(4):\n           e0319780.\n        \n        https://doi.org/10.1371/journal.pone.0319780\n\nEditor:Sara Hemati, SKUMS: Shahrekord University of Medical Science, IRAN, ISLAMIC REPUBLIC OF\n\nReceived:November 4, 2024;Accepted:February 9, 2025;Published:April 18, 2025\n\nCopyright:© 2025 Aboalkhair et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the paper and itsSupporting Informationfiles.\n\nFunding:This research was funded through the annual funding track by the Deanship of Scientific Research, from the vice presidency for graduate studies and scientific research, King Faisal University, Saudi Arabia [KFU250553].\n\nCompeting interests:The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\nSample surveys may present situations where individuals would rather withhold or provide false information about certain questions when dealing with an interviewer, like cases of drug use, psychiatric conditions, infidelity issues, delinquency, criminal abortion, illegitimacy details and even political party affiliation. Evasive response bias could indeed be challenging to evaluate. Warner [1] came up with a proposal that could help reduce this bias— and that is ensuring privacy for the interviewee by using randomized responses technique (RRT). In such setups, individuals are at liberty to keep their personal information private by giving responses in a random manner, which helps address the issue of evasive response bias.\n\nThe RRT in surveys aims to minimize or avoid response errors when questioning individuals about delicate topics. The basic idea behind a design of randomized response is that information will be collected indirectly from interviewees by asking questions whose answers cannot be known with certainty by an interviewer. Thus, in RRT usage it is believed that interviewees provide truthful information that can aid in estimation.\n\nEven though Warner’s technique enables collecting answers on delicate matters while upholding anonymity, its estimations have a raised standard error because of utilizing the random tool. Following Warner’s initial suggestion, many researchers have expanded the RRT in different dimensions. Their focus, however, has always revolved around curtailing estimation variance and bolstering model efficiency; this they achieve through various means such as proposing parameters selection based on specific criteria aimed at minimizing variance and resorting to alternative estimation methods— but primarily by suggesting design modifications to Warner’s original model.\n\nDesign modification is the primary approach taken by the majority of studies to improve the efficiency of RRT. Several authors have suggested different modifications to Warner’s model with the goal of enhancing its efficacy [2–19].\n\nAboalkhair et al. [20] brought in an innovative effective model through a design modification approach based on three randomizing devices. In their work, Aboalkhair et al. [20] showed that their method is an efficient substitute for models introduced by Mangat & Singh and Warner. The study established that using a randomized multi-stage instrument, especially with a higher number of stages, raises the chance of the sensitive question being chosen without significantly impacting interviewee’ trust in the tool or their honesty hence, it led to the effectiveness of the RR technique is enhanced. The inspiration for this research comes from previous research, and its aim is to create a generalized randomized response model.\n\nThe groundbreaking RR model is suggested by Warner [1] to estimate the percentage of individuals who possess delicate attributes π. According to Warner’s model, the estimation of π with suitable changes of notation is:\n\nand variance given by:\n\nMangat & Singh [5] introduced an efficient two-stage RR model. The estimate of π in Mangat & Singh’s design is:\n\nwith variance given by:\n\nMangat & Singh [5] demonstrated that, their model outperforms the original Warner’s model by appropriately selecting any feasible values ofand.\n\nAboalkhair [20] suggested an efficient model utilizing a three-stage random tool. Utilizing a random sample of n interviewees, Aboalkhair’s estimate of π and its variance with appropriate changes of notation are:\n\nand,\n\nIn the following section, we propose a generalized version of Aboalkhair’s model that incorporates previous models, such as that suggested by Mangat & Singh and Warner as special cases, from which new efficient RR models can be generated.\n\nTo estimateπthe proportion of individuals that have a delicate attribute (D) in specific population, each interviewee in a selected random sample is provided with a customizable random tool with j-stage as depicted inFig 1. At the onset (in stage-one (S1)), the interviewee randomly chooses between two options: the first option being a yes/no query that determines if he/she has the delicate attribute, while the second option instructs them to proceed to the subsequent stage Si, (where i ranges from 2 to j-1). If he/she proceeds to (Si), he/she is given the same previous choice. If the interviewee reaches to the final stage (Sj), he/she is given a yes/no query about the sensitive attribute, similar to the original Warner’s model.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319780.g001\n\nThe probability of “Yes” () will be:\n\nwhere:\n\n: The probability of the question that determines if the interviewee has a specific delicate attribute or not shows up at stage g, as g =  1,2,3,…,j and.\n\nThe estimator ofπis as follows:\n\nwheredenotes the ratio of ‘yes’ answers in the sample and.\n\nCustomizeinEq. (8)we get\n\nwhich coincides withEq. (1). If we customize, we get\n\nwhich is coincide withEq. (3)and if set, we getEq. (5).\n\nSince, thereforeis an unbiased estimator ofα, and the variance ofis:\n\nTheorem 1.The proposed estimator variance is\n\nProof.UtilizingEq. (8),is\n\nAs, then\n\nSubstitute byEq. (11)inEq. (10)then,\n\nUsingEq. (7),can be calculated as,\n\nThen,Eq. (9)is obtained via substituting inEq. (12)byEq. (13).\n\nSet, inEq. (9)we get\n\nWhich is coincide withEq. (2), if we customize, we get\n\nWhich is coincide withEq. (4)and if we customize, we getEq. (6).\n\nTheorem 2.has an unbiased estimator given by\n\nProof.The result holds by taking the expected value ofEq. (14).\n\nThe proposed model with j-stage outperforms the model with j-g-stage,in terms of efficiency iff:\n\nIn the randomized response technique, all types of models are subject to several ethical considerations. The main purpose of them is to empower researchers to find the balance between their need to elicit sensitive information and the ethical treatment of participants. First, the respondents must voluntarily and explicitly agree to participate, being informed about the nature and manner of implementation of the RR technique, its purpose, and their freedom to refuse to take part. The researcher has to make the details of data gathering and publication evident by describing the purpose of the study and how it will be shared.\n\nFurthermore, researchers need to consider the possible effects of asking sensitive questions on participants and try to minimize associated harm or distress resulting from responding to them. All studies using Randomized Response techniques have to receive ethical approval from institutional review boards or ethics committees so that research is conducted in line with the ethical standards giving consideration to protecting the rights and welfare of the research participants. Individual responses will be anonymous and untraceable, with a special focus on privacy protection for respondents.\n\nOne of the fundamental aspects of the randomized response technique is preserving interviewee ‘s privacy. Several privacy measures are suggested by researchers such as Anderson [21], Lanke [22], Leysieffer and Warner [23], and Zhimin & Zaizai [24]. Based on the latter approach, the privacy measure for Warner’s model is:\n\nAlso, the measure of privacy protection for Mangat & Singh’s model can be expressed as follows:\n\nand for Aboalkhair’s model:\n\nAnd for suggested model the design probabilities are:\n\nand\n\nThen, the privacy protection measure is:\n\nwhere\n\nTo verify the validity ofEq. (19), set j = 1, j = 2 and j = 3 the measure of protection for Warner’s estimate, Mangat & Singh’s estimate and Aboalkhair’s estimate are obtained, as indicated byEq. (16),Eq. (17), andEq. (18)respectively.\n\nA correlation between the privacy protection measure discussed earlier and the efficiency of each of the four models can be established. These correlation relationships are outlined as follows:\n\nIt is clear fromEqs (20–23) that as the values ofdecrease, the efficiency ofalso decreases. Moreover, Zhimin & Zaizai [24] demonstrated that a higher level of privacy protection for interviewees is achieved when their measure of privacy protection has smaller values. A balance act is required.\n\nTo get a particular meaning for the suggested model with j-stage random tool, we consider the scenario where the number of stages is customized to be four (j = 4). In the initial stage (S1), the interviewee chooses between two options randomly: the first option being a yes/no query that determines if he/she has the delicate attribute, while the second option instructs them to proceed to the subsequent stage Si, (Si, where i takes values of 2 and 3), he/she is given the same choice as in the first stage. If the interviewee reaches the final stage (S4), he/she is given a yes/no query about the sensitive attribute, similar to the original Warner’s model.\n\nThe probability of receiving a “Yes” response (α) can be:\n\nwhere:\n\n: The probability of the question that determines if the interviewee has a delicate attribute shows up at stage g, as s =  1,2,3,4 and.\n\nThe estimator suggested foris:\n\nwhereis the proportion of ‘yes’ answer in the sample.\n\nCorollary 1.The proposed estimator varianceis\n\nCorollary 2.has an unbiased estimator given by\n\nIn this context, our aim is to show the particular circumstances in which the suggested estimator, with four-stage random tool, surpasses estimators that suggested by Warner, Mangat & Singh, and Aboalkhair.\n\nThe suggested model is more effective than Warner’s model iff:\n\nThis is achievable by selecting appropriate values forwhile maintaining a suitable practicable value for.\n\nThe difference in efficiency between the suggested estimator (P) and Warner’s estimator (W) across feasiblevalues and varyingandvalues is illustrated inFig 2a–2d. The vertical axis indicates efficiency difference, and the other two axes indicate the values ofand. Parts a,b,c,d of the figure are forrepectively and for practical values of(less than 0.5). Positive values indicate a clear advantage in favor of the suggested estimator in all cases.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319780.g002\n\nIt can be noted that (Fig 2a–2d):\n\nThe suggested model is more effective than Mangat & Singh’s model (MS) if:\n\nThis is achievable by selecting appropriate values forwhile maintaining a suitable practicable value forand.\n\nThe difference in efficiency between the suggested estimator (P) and Mangat & Singh’s estimator (MS) across feasiblevalues and varyingandvalues is illustrated inFig 3(a–d). Same settings as inFig 2are used for. Positive values indicate the advantage of the suggested estimator in terms of efficiency.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319780.g003\n\nIt can be noted that (Fig 3a–3d):\n\nThe suggested estimator is more effective than Aboalkhair’s estimator iff:\n\nThis is achievable by selecting appropriate values forwhile maintaining a suitable practicable value for,and.\n\nThe difference in efficiency between the suggested estimator (P) and Aboalkhair’s estimator (AK) across feasiblevalues and varyingandvalues is illustrated inFig 4a–4d. In this comparison as well, all differences were positive in favor of the proposed estimator.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319780.g004\n\nIt can be noted that (Fig 4a–4d):\n\nTo demonstrate the process of estimating the proportion of individuals possessing a sensitive trait using the proposed model in real-world contexts, let’s say with a four-stage random tool, the following practical guidelines are recommended to be followed:\n\nComparisons of efficiency indicate that the suggested RR model with a four-stage random tool offers a more effective substitute for all of Warner [1], Mangat & Singh [5], and Aboalkhair [20] models. Furthermore, Aboalkhair’s model proves to be a more effective substitute for models suggested by Warner and Mangat & Singh. Similarly, Mangat & Singh’s model offers a more effective substitute for Warner’s model.\n\nSetting value 0.1 for each of the probabilitiesappears to be the most efficient, and the least favorable, in laying the foundation of privacy protection. On the other hand, set value 0.9 for each of the probabilitiesappears as the optimal value for protecting privacy as it is the lowest value for efficiency. Hence, opting for any of the combinations 0.5, 0.5, 0.5, 0.8; 0.5, 0.5, 0.8, 0.5; 0.5, 0.8, 0.5, 0.5; or 0.8, 0.5, 0.5, 0.5 as values for the probabilitiesandis quite rational. This selection will make sure that both the privacy and efficiency of the suggested model are comparable to the model that suggested by Warner when. Furthermore, it is more likely to achieve the desirable result of targeting specific questions containing sensitive information without making interviewees too suspicious and to contribute to their cooperation.\n\nFromFig 5, it can be deduced that the suggested model exhibits superior efficiency compared to those of Mangat & Singh [5] and Aboalkhair [20] when, regardless of the value of. Also, whenand, the suggested model efficiency equivalent to the efficiency of Warner’s model at, Mangat & Singh’s model at, and Aboalkhair’s model at. These outcomes confirm the core idea of the generalized suggested model, which aims at increasing efficiency, suggesting the utilization of an increasing number of random devices while assigning low probability for choosing the sensitive question.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319780.g005\n\nA possible limitation of the suggested model is that it views a general framework for some earlier models and generator of new efficient models in situations where complete honesty is expected. However, when it comes to highly delicate matters, then the probability of incomplete truthfulness arises. Which in turn opens up a future avenue to revise this model to comply with a scenario of incomplete truthfulness, and hence make it more suitable for accurately determining extremely sensitive characteristics.\n\nhttps://doi.org/10.1371/journal.pone.0319780.s001\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0319780.s002\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0319780.s003\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0319780.s004\n\n(XLSX)\n\nhttps://doi.org/10.1371/journal.pone.0319780.s005\n\n(XLSX)",
    "category": "social_sciences"
  },
  {
    "title": "Long-term outcomes after revascularization surgery for adult moyamoya disease: Protocol for systematic review and meta-analysis",
    "authors": "Sha Wang, Jingjin Zhao, Xinzhu Chen, Liangzhen Zhou, Wenyao Cui, (PLOS)",
    "publish_date": "2025-04-17",
    "doi": "https://doi.org/10.1371/journal.pone.0318370",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0318370",
    "content": "Moyamoya disease (MMD) commonly presents with cerebral ischemia or hemorrhage. Revascularization surgery, including direct, indirect, and combined bypasses, remains the mainstay of MMD treatment aiming to reduce stroke recurrence. However, the long-term outcomes of these interventions are still controversial. Herein, we designed the protocol for a systematic review and meta-analysis comparing the three different revascularization surgeries in adult MMD patients for more than 5 years long-term outcomes.\n\nOur systematic review and meta-analysis protocol follows the PRISMA-P guidelines. Bypass surgeries for MMD will be included only if the follow-up time is more than 5 years. The primary outcome is the incidence of recurrent cerebral ischemia or hemorrhage. The secondary outcomes include functional outcomes evaluated by the Moyamoya Disease outcome category, mortality, and angiographic outcomes such as bypass patency, and collateral formation.\n\nStudies on the postoperative outcomes of revascularization surgeries to treat adult MMD patients will be included and analyzed. This systematic review and meta-analysis will offer evidence to clinicians and researchers on the long-term outcomes of revascularization surgeries in adult MMD patients and help to optimize the selection of bypass modality.\n\nCitation:Wang S, Zhao J, Chen X, Zhou L, Cui W (2025) Long-term outcomes after revascularization surgery for adult moyamoya disease: Protocol for systematic review and meta-analysis. PLoS ONE 20(4):\n           e0318370.\n        \n        https://doi.org/10.1371/journal.pone.0318370\n\nEditor:Haipeng Liu, Coventry University, UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\n\nReceived:March 4, 2024;Accepted:January 14, 2025;Published:April 17, 2025\n\nCopyright:© 2025 Wang et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:No datasets were generated or analysed during the current study. All relevant data from this study will be made available upon study completion.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nMoyamoya disease (MMD), also known as spontaneous steno-occlusion of the circle of Willis, is a cerebrovascular disease characterized by slow progressive narrowing leading to occlusion of the bilateral terminus of the internal carotid arteries and/or the initial segments of the anterior and middle cerebral arteries, with the appearance of compensatory abnormal vascular networks at the base of the brain [1,2]. The annual incidence of moyamoya disease ranges from 0.5 to 1.5 per 100,000 individuals in East Asian nations, while it is as low as 0.1 per 100,000 in other regions [3]. Due to the unclear pathogenesis of MMD, there is a current absence of specific pharmacological treatments available for MMD. Antiplatelet therapy is one of the most promising treatment options but randomized controlled trials are still necessary to confirm its effectiveness [4]. Thus, surgical procedures for intracranial and extracranial blood flow reconstruction remain the mainstay of clinical intervention for MMD [5].\n\nDespite several studies addressing the efficacy of bypass surgery in mitigating recurrent strokes among adult moyamoya patients, the benefits of these interventions remain controversial [6–8]. The notion that revascularization procedures effectively enhance cerebral blood flow, thereby reducing the incidence of ischemic strokes, has been widely accepted by most scholars. However, a recent review denoted that surgery is not superior to medical management in patients presenting with cerebral ischemia [9]. JAM trial is the only single randomized control study of MMD, that compared revascularization with conservative treatment in patients with hemorrhagic MMD, showing substantially fewer recurrent hemorrhages in surgical patients [10]. The trial was criticized for unmasked outcome evaluation, low enrollment, and no postoperative complication which was too good to be true [11]. Several meta-analyses have been performed to elucidate the beneficial effects of revascularization surgery [12–16]. The limitations of these meta-analyses were pointed out by Moussouttas et al. [9], such as no specific data regarding the outcome types of hemorrhagic or ischemic events, and no mortality information. Moreover, the follow-up period varied greatly for each included study of meta-analysis, making outcome assessments difficult to compare.\n\nIt was concluded that the natural history of hemorrhagic MMD remains dynamic with cumulative risk of rebleeding being 7.8% at 5 years, 22.6% at 10 years, and 35.9% at 15 years, requiring long-term follow-up to fully understand the risk of rebleeding [17]. Similarly, Morioka et al. [18] reported that there is a higher risk of rebleeding in the first 6 years after initial hemorrhage. In 2016, a meta-analysis attempted to determine the best surgical management for adults with MMD by comparing long-term outcomes but with just more than 30 days of follow-up after surgery among direct, indirect, and combined bypass types [19]. In 2018, a long-term good functional outcome rate of 82% was achieved after revascularization in a meta-analysis where the long-term follow-up time was defined as at least 6 months [16]. Most of the existing systematic reviews defined events after 30 days or 6 months as late outcomes, but long-term retrospective studies have demonstrated that the incidence of adverse events is gradually increasing until 36 months after surgery, and some studies have reported that different surgical methods appear late crossovers on the bleeding free survival curve at 36 months after surgery. The considerable heterogeneity and inconsistent definitions of long-term outcomes may result in a lack of overall credibility in these findings. In a 10-year follow-up study, investigators observed a higher frequency of rebleeding cases during the 5–10 years after indirect revascularization for adult hemorrhagic moyamoya disease compared with the first 5 years after the procedure [20]. The long-term follow-up results after combined revascularization surgery also indicated a decreasing trend in cerebral blood flow in the territory of the middle cerebral artery (MCA) in the operated hemispheres as the follow-up period progresses [21]. Overall, the current results strongly suggest that the evaluation of postoperative outcomes following revascularization surgery should be extended to 5 years or even longer to reflect the long-term benefits or risks for patients. However, there is still insufficient evidence regarding long-term follow-up.\n\nWe design to conduct a systematic review and meta-analysis to clarify the long-term angiographic and functional outcomes with at least 5 years of follow-up under the uniform outcome measurement tools. Direct, indirect, and combined bypasses will be compared regarding the specific hemorrhagic or ischemic events or mortality rate in adults with MMD. Accordingly, we aim to summarize existing knowledge regarding the effect of surgery on MMD outcomes and guide the selection of surgical approaches to achieve long-term comprehensive clinical outcomes for patients.\n\nThis systematic review aims to assess the postoperative long-term outcomes after revascularization surgery of MMD in adult patients (aged 18 or older, with no limitations on sex and race). We seek to answer the following questions:\n\nWhat is the overall incidence of angiographic and functional outcomes among adult patients who underwent revascularization surgery of MMD in the postoperative long-term period?\n\nIs there a trend in the incidence of adverse events after surgery over time or in different regions of the world?\n\nWhat is the relevance between revascularization bypass types and postoperative long-term adverse events among adult patients with MMD, and how to determine the best surgical management for adults with MMD?\n\nOur systematic review and meta-analysis protocol follows the PRISMA-P guidelines (S1 Table) [22]. This protocol has been registered on the PROSPERO (registration number ID: CRD42024550222). Since this investigation will not involve disclosure of patient information, ethics approval is waived. The PRISMA flow diagram will be used to record every step of the review process (Fig 1).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0318370.g001\n\nRandomized controlled trials (RCT), observational studies (cohort studies, and case-control studies [CCS]) will be included while case reports and letters to editors will be excluded.\n\nWe will include adult patients diagnosed with MMD according to the current guideline, including those without a history of stroke or transient ischemic attack (TIA). We will exclude patients with moyamoya syndrome, i.e., ICA stenosis or occlusion due to known reasons, for example, atherosclerosis, trauma, or radiation. Due to possible variations in disease diagnosis, the definition of “MMD” will be extracted from included studies.\n\nPatients underwent revascularization surgery either by direct bypass, indirect bypass, or combined bypass.\n\nWe will search the following five electronic databases: PubMed, Cochrane Library, MEDLINE Ovid, Embase Ovid, and Web of Science. The literature search will include studies published from the inception of the database to the date of the commencement of the review.Table 1shows the initial draft search strategy for PubMed. The search strategies for other databases are shown inS1 Appendix. In addition, we will use the Cited Reference Search within Web of Science to check the bibliographies of included studies and any relevant systemic reviews for further references to relevant trials and search Google Scholar (scholar.google.co.uk/) to forward-track relevant references. If trial reports are unclear, we will contact the original authors for clarification and further data.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0318370.t001\n\nThe results of the literature search will be imported into an EndNote V.X9.3.3 database, and duplicates will be removed. We will next establish several independent groups for each selecting stage in the EndNote database. Two independent investigators will screen the literatures in two stages. At first, they will review the titles and abstracts retrieved from database searches to evaluate all studies that meet the inclusion criteria. Next, they will retrieve the full-text articles for the remaining references and review authors will independently screen the full-text articles, identify studies for inclusion, and identify and record reasons for exclusion of the ineligible studies. All discrepancies will be resolved by consultation with a third investigator. For studies that share the same data source, we will prioritize studies with larger sample size and longer study durations in the meta-analysis.\n\nWe will design a form to extract data which will include the following details: (1) study authors; (2) research period and publication year; (3) study design; (4) country and continent of the study; (5) data source; (6) study population and inclusion criteria; (7) definition of “adult” and diagnostic criteria for “MMD”; (8) number of patients included in the adult group; (9) preoperative Suzuki angiographic stage of hemispheres; (10) outcome measurement; (11) follow-up time; (12) rates of prespecified long-term outcomes. Two review authors will extract data using the agreed form. Discrepancies will be solved through discussion. Data are about to be entered into Review Manager software (RevMan 2014) and checked for accuracy.\n\nThe long-term outcome measures include rates of long-term angiographic or functional outcomes events occurring more than 5 years after bypass and rates of favorable outcomes at the last follow-up. Definitions of favorable outcomes varied among studies; both clinical improvement and angiographic improvement will be included in our definition of favorable outcomes.\n\nIn this study, we will use the guidance from the Grading of Recommendations Assessment, Development, and Evaluation (GRADE) working group to assess the quality of evidence for the primary outcome. The GRADE summary of findings table will be produced using the GradePRO software. We will evaluate evidence quality based on the domains of risk of bias, consistency, directness, precision, and publication bias. Additional domains may be considered as needed. Quality will be categorized as high, moderate, low, or very low.\n\nTo assess the risk of bias for RCTs and non-RCTs, the Risk Of Bias In Non-randomised Studies - of Interventions (ROBINS-I) tool and a revised tool for assessing risk of bias in randomised trials (RoB 2) will be used. For non-RCTs, evaluators will assess the level of bias risk in 7 domains in ROBINS-I and give a risk assessment of “low, moderate, serious, critical, or no information” for each domain. Based on the assessment of all individual domains, an overall assessment of “overall bias” will be made according to the following rules: if all seven domains have a low bias risk, the overall bias risk is “low”; if all seven domains have a low or moderate risk of bias, the overall bias risk is “moderate”; if at least one domain has a high risk of bias but no evaluation field has an extremely high risk of bias, the overall bias risk is “high”; if at least one domain has an extremely high risk of bias, the overall bias risk is “critical”; if there is no relevant information on key domains, the overall bias risk is “no information”. With respect to RCTs, each domain in RoB 2.0 will be characterized as at low risk of bias; causing some concerns; or at high risk of bias. If the assessment results in all five domains are low risk, the study will be determined as “low risk of bias”; if any domain report a high risk or multiple domains report “causing some concerns”, it is determined as “high risk of bias”; RCTs other than the above two situations are determined as “some concerns”.\n\nPublication bias will be assessed using contour-enhanced funnel plots. The presence of missing studies in areas of the plot without significant differences suggests that the funnel plot asymmetry may be due to publication bias; the presence of missing studies in areas with significant differences suggests that the asymmetry may be due to other causes, such as heterogeneity, rather than publication bias.\n\nWe will carry out statistical analysis using the Review Manager software (RevMan 2014). Heterogeneity will be assessed using the I² statistic, with values ≤ 50% being regarded as indicating low heterogeneity, in which case, we will use fixed-effect meta-analysis for combining data where it is reasonable to assume that studies were estimating the same underlying treatment effect: i.e., where trials were examining the same intervention, and the trials’ populations and methods were judged sufficiently similar. Values of I² > 50%, however, are considered to indicate significant heterogeneity, in which case we will use random-effects meta-analysis to produce an overall summary and conduct subgroup analyses to investigate the sources of the heterogeneity. For studies with highly significant heterogeneity (I² > 75%), we will conduct a manual review to identify potential issues such as small sample size, study design flaws, or poor data quality. If such issues are identified, the study will be excluded, and the overall heterogeneity will be assessed again. Sensitivity analysis will be performed by removing each study individually to assess the consistency and quality of the results regarding different surgical procedures and the incidence of primary outcomes.\n\nThe dichotomous variables outcomes will be assessed as an odds ratio (OR) and 95% confidence interval (CI). Kim et al. categorized Moyamoya Disease favorable functional outcomes into Excellent (symptoms resolved without neurological deficits) and Good (symptoms resolved with neurological deficits) [23]. In this study, single group rates of these favorable outcomes will undergo variance-stabilizing Freeman-Tukey arcsine transformation and transformed rates and errors will be re-converted for meta-analysis, generating mean weighted probability (MWP) and 95% CI in a random-effects model [16]. In the subgroup analyses, we will firstly group studies according to different characteristics of the original study (control set, severity of disease, comorbidities, etc.), compare the combined effect size between the groups, and test for inter-group and intra-group heterogeneity. If there are sufficient studies included, we will next undertake subgroup analyses for the primary outcomes by ethnicity, age groups, preoperative Suzuki stages, different subtypes of MMD, surgical procedure. P value < 0.05 will be considered significant for all analyses.\n\nMMD remains a disease of low incidence, especially in Western countries. There are huge heterogeneities regarding the age, population, clinical presentation, and possible prognosis between western and eastern regions [4]. In addition, surgical modality of revascularization varied across different medical centers with inconsistent efficacy reported. Therefore, it is quite urgent but difficult to perform prospective or even randomized control studies to illustrate the best treatment.\n\nThe long-term treatment efficacy of bypass surgery depends on the hemodynamic change and bypass geometry. Computational fluid dynamics (CFD) simulation is a simple, low-cost, noninvasive tool in evaluating the efficacy of STA-MCA bypass from hemodynamic perspectives [24]. It was reported that bypass vessel remodeling occurred, resulting in an increased driving pressure and greater blood flow through the bypass after surgery in most cases [25]. Occasionally, bypass geometry variations, such as tortuosity and stenosis in STA, could significantly increase flow resistance, reducing the distal branch flow rate [26]. However, postoperative stenosis of the STA-MCA bypass is not necessarily negative. The postoperative improvement of distal hemodynamic environment can lead to the generation of collaterals, which might take over bypass function in the long term [27]. The efficacy and outcome of revascularization have been investigated in previous meta-analyses. However, to the best of our knowledge, no systematic review was reported to focus on the long-term outcome beyond 5 years follow-up which is crucial in the precise and comprehensive prognostic evaluation as the chronic hemodynamic changes of MMD and the recurrence of hemorrhage or infarction remain versatile after surgery [28]. We believe our data will be of vital importance in future clinical practice and research.\n\nThis study has several limitations. First, the pooled analysis will include both prospective and retrospective studies, the resulting bias in the retrospective studies might impact our overall conclusions. In addition, patients’ conditions on admission are not matched among the different groups, which might have biased our results. Besides, indications for revascularization surgeries could not be standardized.\n\nhttps://doi.org/10.1371/journal.pone.0318370.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0318370.s002\n\n(PDF)\n\nWe greatly thank Dr. Chuanyuan Tao for his valuable advice on developing this protocol.",
    "category": "statistics"
  },
  {
    "title": "Application of alternative nonlinear models to predict growth curve in partridges",
    "authors": "Navid Ghavi Hossein-Zadeh, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321680",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321680",
    "content": "This study aimed to describe the growth pattern in partridges using nonlinear models. Eight nonlinear mathematical functions (Bridges, Janoschek, Richards, Schumacher, Morgan, Lomolino, Sinusoidal, and Weibull) were used. The parameters of nonlinear models were estimated by fitting the models to partridge body weight records using the NLIN and MODEL procedures in the SAS program. Model performance was assessed and model behavior was examined during the process of fitting nonlinear regression curves. The overall goodness of fit of each model to various data profiles was assessed using the adjusted coefficient of determination, root mean square error, Akaike’s information criterion, and Bayesian information criterion. The adjusted coefficient of determination values for each model are generally high, indicating that the models fit the data well overall. Based on goodness of fit criteria, the Morgan model was found to be the most appropriate function for fitting the growth curve of male and female partridges. Furthermore, the Lomolino model had the worst fit to the growth curves of male and female partridges. While the predictions of the final body weight from all the models were good, the Morgan function outperformed the others in this regard. Based on the first derivative of the Morgan model, the absolute growth rates for male and female partridges as a function of time revealed that these values gradually increased with increasing age until 42 and 35 days of age, respectively, and then declined. The Morgan function is a useful replacement for conventional growth functions when describing the growth curves of different partridge breeds.\n\nCitation:Ghavi Hossein-Zadeh N (2025) Application of alternative nonlinear models to predict growth curve in partridges. PLoS ONE 20(4):\n           e0321680.\n        \n        https://doi.org/10.1371/journal.pone.0321680\n\nEditor:Wenpeng You, The University of Adelaide - North Terrace Campus: The University of Adelaide, AUSTRALIA\n\nReceived:August 14, 2024;Accepted:March 10, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Ghavi Hossein-Zadeh. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nIn an attempt to duplicate the advantages of animals raised in the wild, like increased productivity and better flavor, humans have had difficulty raising hunting animals in controlled environments. Scientists are searching for novel approaches to raise various game animals for meat as a result of this struggle. The two main game animals that are raised intensively these days are partridges and pheasants [1–2]. Partridges are game birds found in the wild and are primarily raised for meat production, hunting tourism, and environmental conservation [2–4]. When they reach a certain weight and age, partridges bred for hunting tourism or maintaining natural balance are released into hunting areas or the wild [5]. Partridges play a key role in the rural economy, particularly in regions where hunting tourism contributes significantly to local income. In these areas, farms specifically breed partridges for release into hunting reserves, contributing to both conservation efforts and economic sustainability. Partridges are ideal for commercial production due to their rapid growth, high productivity, efficient feed conversion, and exceptional meat quality. Partridges are considered a premium source of protein in the market due to their lean, flavorful, and nutritious meat, which has led to a global increase in demand for wild birds [6]. In captivity, partridges are an adaptable breed that work well in commercial production [7]. This has led to an increase in the number of businesses that raise partridges for meat. Partridges have similar breeding and feeding practices to other species of poultry [8]. These characteristics have led to an increase in partridge breeding and current research aims to improve productivity and growth characteristics to meet the growing demand for wild birds in the food and tourism sectors.\n\nThe potential of partridges for further domestication and genetic development also allows their productivity to be maximized and strengthens their importance in industrial poultry farming systems.\n\nGrowth is defined as changes in live weight and proportionate body component growth influenced by environmental factors and genotype; growth curves are defined as changes in growth that occur over time [9]. Growth curves are the mathematical representation of growth, and their main use is to summarize data collected at various ages. Despite their difficulty, there are a few parameters that can be understood in the context of biology [10–11]. Growth curves can be used to find the best age to slaughter, identify a measurable growth trait, learn more about the health of the living thing, and assess how selection has affected the growth curve’s parameters [12–13]. Comprehending the partridge’s growth curve parameters could aid scientists in initiating animal breeding initiatives [5].\n\nWhen examining the growth curve of farm animals, there are a number of reasons to think about utilizing alternative models rather than traditional ones. The complex and non-linear growth trajectories seen in farm animals may not be sufficiently captured by conventional models, which frequently assume linear growth patterns. Different models are more capable of explaining differences in growth rates at various developmental stages. Alternative models allow for more customization and flexibility when fitting growth data, making it possible to capture distinct growth patterns unique to various farm animal species or breeds. By accounting for variables that can affect growth rates, such as genetic influences, environmental factors, and feed quality, alternative models may offer a more accurate depiction of growth trajectories. Alternative models might produce more accurate growth performance forecasts, empowering farmers to choose the best breeding selection, feed plans, and general management techniques [14]. In general, alternative models can provide a more thorough and nuanced approach to analyzing farm animal growth curves than conventional models, which can enhance insights and decision-making in animal production systems [14]. Several asymptotic-mechanistic models have been developed using various mathematical functions to simulate livestock growth. These models incorporate functions based on the biological growth of the animal [15]. Parameterizing mathematical models of partridge growth and assessing alternative management and feeding strategies are necessary for optimizing partridge production systems. Nevertheless, only a few studies have described the growth curves of different partridge breeds [5,7,8,16–20], and most of these studies used traditional nonlinear models such as Brody, Gompertz, logistic, Von Bertalanffy, and Richards. Although these models are well established and used successfully to describe the growth of various livestock species, they may not fully capture the complexity and variability of growth patterns, particularly in species such as partridges. The key limitation of these traditional models is their relatively rigid structure, which may not take into account the different growth phases or environmental interactions that are important in more nuanced growth studies. Consequently, there are very few studies on partridge growth curves in the literature, particularly when using alternative models such as Schumacher, Morgan, Lomolino, Weibull, and sinusoidal. Therefore, this study aimed to evaluate the suitability of eight nonlinear models (Bridges, Janoschek, Richards, Schumacher, Morgan, Lomolino, Sinusoidal, and Weibull) to describe the growth pattern of partridges to incorporate alternative functions into the study and production of partridges. By evaluating a greater variety of nonlinear models, this study fills the gaps left by traditional models. This method provides greater flexibility in documenting the different growth stages of partridges and allows for a more thorough study of growth patterns. By comparing alternative models, this study provided a clearer understanding of which models are best for predicting partridge growth, which could improve breeding and management strategies. Furthermore, this study contributed to the literature by expanding the set of tools available for modeling partridge growth, going beyond the limitations of previous work that focused exclusively on traditional models.\n\nThis study utilizes data previously collected and published in existing literature. Given that the data is publicly available, no additional ethics approval was required for this study.\n\nRecords of body weight of chukar partridges (Alectoris chukar) from hatching to 140 days of age are from the study of Iqbal et al. [8] and used in the current study (S1 Table). A total of 72 male and 108 female partridge chicks were weighed individually and had their wings banded. Every week, a digital scale with a sensitivity of 0.01 g was used to weigh them. Detailed information on the housing and management of the birds can be found in a study reported by Sariyel et al. [5]. Sariyel et al. [5] compared the goodness of fit of the Brody, Gompertz, Logistic, and von Bertalanffy growth curve models in this data set. Also, Iqbal et al. [8] fitted the Gompertz, Brody, Logistic, and von Bertalanffy growth models on the same data set using a Bayesian approach.\n\nTable 1displays the nonlinear models that were utilized to explain the growth curves. To model the relationship between body weight and age, the following models were fitted to the data: Bridges, Janoschek, Schumacher, Richards, Morgan, Lomolino, sinusoidal, and Weibull.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321680.t001\n\nThe parameters of eight nonlinear models were estimated by independently fitting the models to partridge body weight records using the NLIN and MODEL procedures in SAS 9.1 [29]. Iteration techniques for fitting non-linear functions were based on the Gauss-Newton method. Before beginning this process, the NLIN and MODEL procedures evaluates the starting value specifications for the parameters. The initial values of the parameters had to be supplied for the iterative process to work. The final estimates were unaffected by the initial values that were chosen.\n\nUsing the adjusted coefficient of determination (), residual standard deviation or root means square error (RMSE), Durbin-Watson statistic (DW), Akaike’s information criterion (AIC), and Bayesian information criterion (BIC), the quality of the predictions, or goodness of fit, was assessed for each model.\n\nThe following formula was used to calculate:\n\nWhere, the multiple coefficient of determination is denoted by(), n denotes the number of observations (data points), p denotes the number of parameters, RSS stands for residual sum of squares, and TSS stands for total sum of squares. Thevalue is used to determine how much of the total variation around the mean of the trait can be attributed to the growth curve model. Thealways falls within the range of 0–1, with the model considered satisfactory whenis close to 1.\n\nRMSE is a form of standard deviation that is calculated in the following way:\n\nThe residual sum of squares (RSS) represents the error in the data, with n being the number of observations and p being the number of parameters in the equation. The RMSE value is a critical factor in evaluating the appropriateness of growth curve models, with the most favorable model being the one with the lowest RMSE.\n\nTo assess the normality of the residuals of the fitted nonlinear models, the Shapiro-Wilk test was used. This test is commonly used to examine whether the residuals follow a normal distribution. A significantP-value (P<0.05) indicates deviations from normality. To check the assumption of constant variance in the residuals, the White’s test was also used. White’s test is a common statistical test for heteroscedasticity that evaluates whether the variance of the residuals remains stable across different levels of the independent variable. A non-significant result of the White’s test (P> 0.05) would indicate that the homoscedasticity assumption is met, supporting the validity of the regression models. The Durbin-Watson (DW) statistic was utilized to investigate the residuals from the regression analysis for the existence of autocorrelation. Given the presence of autocorrelated residuals, it is possible that the function is inappropriate for the given data. The DW statistic has values between 0 and 4. Autocorrelation is absent when the value is close to two, positive when the value is close to zero, and negative when the value is close to four [30]. The significance of the DW values was tested using R software version 4.4.2. A significant autocorrelation in the residuals (P< 0.05) would indicate that the model may not adequately capture the temporal structure of the data. The following formula was used to determine DW:\n\nWhere,denotes the residual at time e, andpresents residual at time t-1.\n\nUsing the following equation [31], AIC was calculated:\n\nThe AIC statistic is useful when comparing models with different levels of complexity because it adjusts the RSS based on the model’s parameter count. A better fit is indicated by a lower AIC number value in the model comparison.\n\nBIC integrates maximum likelihood (data fitting) and model selection by penalizing the (log) maximum likelihood with a term related to model complexity:\n\nWhen comparing models, a lower BIC number denotes a better fit. In general, AIC and BIC are good criteria for comparing models that have different numbers of parameters.\n\nOnce the optimal function was chosen, the absolute growth rate, or AGR, was calculated using the function’s first derivative with respect to time (). AGR or average growth rate of animals per unit time is a useful tool for calculating the average growth rate of a population. In this case, this indicates the approximate daily weight gain during a growth phase [32]. In addition, the inflection point (IP) was calculated using the second derivative of the best function with respect to time [33–34]. As stated by Mischan et al. [33], IP is the value at which the growth model’s second derivative is set to zero. The first and second derivatives of the best function were calculated using R software version 4.4.0.\n\nTable 2displays estimated parameters of the nonlinear growth models for male and female partridges. InTable 3, goodness of fit statistics for the eight growth models fitted to body weight records are also presented. All models provided highvalues, and although there were minimal differences invalues between the models, the Morgan model had the highestvalue for male partridges, and the Bridges, Janoschek, Morgan, and Weibull models had the highest values for female partridges. However, the Lomolino model produced the smallest values offor male and female partridges. DW values ranged from 0.93 (for Lomolino) to 1.39 (for sinusoidal) in male partridges and from 0.97 (for Lomolino) to 1.32 (for Morgan) in female partridges. Therefore, positive autocorrelation was observed for all models (P< 0.05). For male and female partridges, with the exception of the Schumacher model, other functions had a normal residual distribution (P>0.05). The results of White’s test examining the assumption of constant variance in the residuals confirmed residual homogeneity for all models in male partridges (P> 0.05), but the results showed that, with the exception of the sine model, other models provided residual homogeneity in female partridges (Table 3). For male partridges, the Morgan and Lomolino models provided the lowest and highest RMSE values, respectively. However, the Bridges, Janoschek, and Weibull models provided the lowest RMSE values for female partridges, but the Lomolino function had the highest value. Moreover, Morgan function had the lowest AIC and BIC values for male and female partridges, but the Lomolino model had the highest AIC and BIC values. Therefore, the Morgan model was determined to be the best function for fitting the growth curve of male and female partridges. After Morgan model, the Schumacher and sinusoidal functions provided the best fit of growth curve in male pertridges, respectively. But, after Morgan model, Schumacher model provided the best fit of growth curve in female partridges. Moreover, the Lomolino model had the worst fit to the growth curve of male and female partridges.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321680.t002\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321680.t003\n\nAccording to Iqbal et al. [8], partridge body weights were found to increase with age during the study period, with males becoming noticeably heavier than females after 140 days of age. For male and female partridges, the Lomolino, Morgan, and sinusoidal functions provided underestimated initial body weights. However, other models predicted initial body weights close to the actual value. There existed magnitude differences between the various functions for the final or asymptotic body weights. All models provided a good prediction of final body weight, but the Morgan function provided the best prediction of final body weight compared to other models. In general, initial and final body weights predicted by different models were typically greater for male partridges compared with female partridges.Fig 1shows predicted body weights for male and female partridges as a function of age, calculated using different nonlinear models.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321680.g001\n\nFig 2displays the AGR values for male and female partridges as a function of time, based on the first derivative of the Morgan model. For male and female partridges, AGR values progressively rose with increasing age until 42 and 35 days of age, and then declined, respectively. For male and female partridges, based on the second derivative of the Morgan function, the IP was determined to be 42 and 35 days old, respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321680.g002\n\nThis study presents a novel approach to modeling the growth curve of partridges by applying a wider range of nonlinear models than previously investigated, including less common models such as the Morgan, Lomolino, and sinusoidal functions. While traditional models such as Gompertz and logistic are widely used in poultry species, this study evaluates eight models using a comprehensive set of fitting criteria to provide a robust comparison. Traditional growth models are typically those that are widely used in livestock growth research and have proven themselves over many years. A relatively fixed biological interpretation of growth phases, fewer parameters and simpler mathematical structures are some of the well-known features of these models (such as the Brody, Gompertz, Logistic, and von Bertalanffy models). Because of their widespread use and ease of use, they are commonly referred to as “conventional”. In contrast, modern growth models (sometimes referred to as alternative or advanced models) are those that have been developed or adapted more recently to handle more complex or species-specific growth patterns. These models (such as the Morgan, Lomolino, Schumacher, and Weibull) tend to offer greater flexibility by incorporating additional parameters or more sophisticated mathematical functions. Modern models can better take nonlinear and irregular growth pattern into account, enabling more individual adaptation to species with complex or variable growth stages. The results showed that the Morgan model provided the most accurate fit for both male and female partridges, an important contribution that advances growth modeling for this species. By identifying this model as the best alternative to traditional models, the study fills a gap in the existing literature and provides a more precise tool for predicting growth dynamics. Additionally, this research extends the application of growth models beyond commercial production to conservation efforts and highlights the dual potential for optimizing breeding programs and managing game bird populations. Thus, the study makes a significant contribution by improving the accuracy of growth predictions in partridges and expanding the scope of growth modeling in both agricultural and ecological contexts. By maximizing breeding and release tactics and ensuring that birds are released into the wild at the best time for their survival, growth models contribute to partridge conservation. To improve bird health, they provide guidance on optimal rearing techniques, such as nutritional management. Growth models ensure a balanced gene pool through targeted breeding, which further promotes genetic diversity. They also enable adaptive management in response to changing environmental conditions and balance conservation goals with business objectives, for example in agricultural environments, ensuring both sustainability and species productivity. The use of body weight data from a previous study (Iqbal et al. [8]) is one of the potential limitations of the study, potentially limiting the applicability of the results to different partridge populations or environmental conditions. Even though the sample size was adequate, it could still limit wider use. Although the Morgan model best fits the data, it has not been tested for other species or conditions. Furthermore, the study’s dependence on specific management and husbandry conditions (according to Sariyel et al. [5]) could limit its suitability for use in different rearing situations. Although the accuracy of the body weight measurements is sufficient, there may be slight fluctuations. Finally, the eight nonlinear models tested may not cover all possible growth patterns, particularly under more complex or variable conditions.\n\nAccurately fitting growth curves and analyzing their parameters are essential for improving breeding and production in livestock and poultry [16]. This study aimed to identify the best model to describe partridge live weight data, which is critical for understanding growth dynamics, optimizing feeding strategies, and determining the ideal age for slaughter. Additionally, the growth curve can help evaluate genetic quality, nutrition, and management practices. The Morgan model emerged as the most appropriate function, based on its superior fit and ability to capture the growth trajectory of both male and female partridges. While all models performed well, the Morgan model’s parameters best represented the biological processes of growth, though the choice of model should always consider both statistical fit and biological relevance [35–36].\n\nThus far, nonlinear models have been used by some researchers to examine the growth curves of various partridge breeds. Cetin et al. [17] used the growth profiles of male and female partridges to compare the growth models (Gompertz, Logistic, and Richards). Their results showed that the Gompertz model more accurately covers the data for both male and female partridges. Also, Tholon et al. [18] used the Gompertz model in partridge research. Tholon and Queiroz [19] concluded that the Gompertz model was the most effective model to describe tinamous partridge growth due to the highest coefficients of determination, easy convergence, lower mean square predicted error, and simplicity of biological parameter interpretation. Balcioglu et al. [7] compared the growth data of male and female partridges using Gompertz, logistic, and von Bertalanffy models. Aourir et al. [20] investigated Barbary partridges (Alectoris barbara) using the Gompertz model. Sariyel et al. [5] analyzed growth data of partridges and concluded that the Gompertz model was most effective in determining the growth pattern. Wen et al. [16] found that the Weibull-type model explained partridge live weight data the best. Iqbal et al. [8] found that the von Bertalanffy model offered the best growth curve fit when utilizing a Bayesian approach to describe the growth of Chukar partridges. Compared with the results of Sariyel et al. [5] and Iqbal et al. [8], the results of the current study suggest a better fit of alternative nonlinear models used to describe the growth curve of partridges based on goodness of fit criteria. The Morgan model has a flexible inflection point and removes the limitation of fixed inflection point growth models such as the Gompertz equation.\n\nThe varying degrees of goodness of fit among different breeds of partridge can be attributed to differences in growth curve properties. The discrepancies in model fit seen in various studies may be the result of variations in factors such as animal breeds, body weight records, data points, and mathematical forms of the models. These variations in growth curves can be influenced by both genetic and environmental factors.\n\nThe detection of positive autocorrelations, also known as serial correlation, among the residuals in all models suggests underlying patterns not fully captured by the nonlinear growth models used in this study [30]. These autocorrelations could stem from factors such as unmodeled genetic influences, environmental variables, or time-dependent trends that affect partridge growth. Positive autocorrelation indicates that growth dynamics may be influenced by latent variables, underscoring the complexity of accurately modeling biological growth processes in this species. Importantly, the presence of autocorrelation in the residuals signals potential model misspecification or the omission of key growth-related variables, a challenge that has been similarly observed in other poultry species. This study highlights the need for advanced modeling techniques, such as the inclusion of first-order autoregressive (AR (1)) models, to account for residual dependence. Implementing AR (1) corrections could improve the precision of parameter estimates and enhance the reliability of growth predictions by addressing serial dependencies in the data [37]. By directly confronting autocorrelation, the study offers a path forward for refining growth curve modeling in partridges and possibly other poultry species, emphasizing the importance of selecting models that balance fit with biological accuracy.\n\nThe analysis of AGR provides a dynamic view of how partridges grow over time, revealing periods of rapid growth as well as slower phases. Rather than relying solely on static weight measurements, AGR allows for a deeper understanding of growth trajectories, helping to identify critical growth stages such as the inflection point (IP), where growth peaks before tapering off [14,38]. This study found that both male and female partridges reached their maximum growth rates at the IP, after which the rate of weight gain steadily declined. This trend highlights the need for targeted management interventions at key growth stages, such as adjusting feed or monitoring health, to optimize weight gain during periods of rapid growth. The later occurrence of the IP in males compared to females underscores the impact of sexual dimorphism on growth patterns in partridges. Males typically grow larger and take longer to reach full maturity, which may explain the delayed peak in their growth rate. Recognizing these differences can guide more precise nutritional strategies, allowing farmers to tailor feeding schedules to the specific needs of males and females, ultimately improving feed efficiency and reducing waste [39]. By tracking changes in AGR, producers can better understand the growth potential of their flock and make informed decisions to maximize productivity, particularly during critical growth periods when management adjustments can have the greatest impact.\n\nIn this study, the performance of eight nonlinear models in predicting the growth curves of partridges was successfully evaluated, with the aim of identifying the most suitable model for this species. Among the models analyzed, the Morgan model was found to be the most suitable for describing the growth patterns of both male and female partridges due to its superior goodness of fit criteria (e.g., RMSE, AIC, BIC, and). The Morgan model’s accuracy in predicting growth curves provides valuable insights into optimizing partridge management and breeding, enabling more precise estimates of growth rates and final body weight. These results highlight the importance of selecting a robust and flexible model that can be adapted to different growth profiles in commercial and conservation environments. However, it is critical to validate the performance of the Morgan model with larger data sets that are measured more frequently to ensure its accuracy and reliability under a wider range of conditions. Additionally, future research should explore the application of this model to different breeds and environmental conditions to further validate its versatility and usefulness in poultry growth studies.\n\nhttps://doi.org/10.1371/journal.pone.0321680.s001\n\n(DOCX)",
    "category": "statistics"
  },
  {
    "title": "Predicting diabetes mellitus metabolic goals and chronic complications transitions—analysis based on natural language processing and machine learning models",
    "authors": "Claudia C. Colmenares-Mejia, Andrés F. García-Suaza, Paul Rodríguez-Lesmes, Christian Lochmuller, Sara C. Atehortúa, J.E. Camacho-Cogollo, Juan P. Martínez, Juliana Rincón, Yohan R. Céspedes, Esteban Morales-Mendoza, Mario A. Isaza-Ruget, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0321258",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321258",
    "content": "To estimate Diabetes mellitus (DM) progression at one and two years in terms of glycemic targets and development of complications.\n\nWe analyzed a retrospective cohort of adult DM patients treated in a Health Maintenance Organization in Colombia, including those with at least one glycosylated hemoglobin (HbA1c) measurement in 2018, 2019, and 2020. We defined four disease transition stages based on metabolic goals according to HbA1c levels and complications: 1. Within HbA1c goals and without complications; 2. Outside goals and without complications, 3. Within goals, but with complications, and 4. Outside goals and with complications. We applied Natural Language Processing (NLP) techniques to extract relevant clinical information from Electronic Health Records. Machine learning (ML) models were used to predict patient progression.\n\nA total of 23,802 patients were included. Despite achieving initial glycemic control, more than 60% of patients who started within HbA1c targets and without complications developed chronic complications within two years. Our models, which achieved up to 80% accuracy and F1 scores above 74%, identified key predictors of disease progression. Adherence to dyslipidemia treatment guidelines significantly reduced the likelihood of HbA1c deterioration and complications, whereas non-adherence to pharmacological treatments increased the risk of complications. These findings suggest that HbA1c control alone is insufficient to prevent disease progression and that a more comprehensive management approach—including lipid control, kidney function monitoring, and improved adherence to clinical guidelines—is necessary.\n\nPatient compliance with pharmacological treatments, professional adherence to clinical practice guidelines, and lifestyle interventions play a crucial role in diabetes progression. While our models provide strong predictive capabilities, improving data quality and integration remains essential for better forecasting and intervention strategies.\n\nCitation:Colmenares-Mejia CC, García-Suaza AF, Rodríguez-Lesmes P, Lochmuller C, Atehortúa SC, Camacho-Cogollo J, et al.  (2025) Predicting diabetes mellitus metabolic goals and chronic complications transitions—analysis based on natural language processing and machine learning models. PLoS ONE 20(4):\n           e0321258.\n        \n        https://doi.org/10.1371/journal.pone.0321258\n\nEditor:Ozra Tabatabaei-Malazy, Endocrinology and Metabolism Population Sciences Institute, Tehran University of Medical Sciences, IRAN, ISLAMIC REPUBLIC OF\n\nReceived:May 8, 2024;Accepted:March 4, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Colmenares-Mejia et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All the code required to reuse the algorithms and replicate the results with the original data is available in the following repository:https://github.com/androdri1/diabetesprogression. The original data that support the findings of this study are available from EPS Sanitas. Restrictions apply to the availability of these data due to the involvement of sensible personal data (electronic health records), which were used under license for this study and under the authorization of the Unisanitas Ethics and Research Board. Any researcher that would like to get access to the dataset will be required to apply for access by discussing it with Unisanitas and EPS Sanitas research offices: investigaciones@unisanitas.edu.co.\n\nFunding:This study was supported by the Ministry of Science, Technology and Innovation (Minciencias) of Colombia. Grant Number: 138-2021. Andrés García and Paul Rodríguez acknowledge support by Fulbright-Colciencias and Colombia Cientifica – Alianza EFI 60185 contract FP44842- 220-2018, funded by The World Bank through the Scientific Ecosystems, managed by the Colombian Ministry of Science, Technology and Innovation (MINCIENCIAS). The funders had no role in study design, data collection and analysis, decision to publish, or manuscript preparation.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nDiabetes mellitus (DM) constitutes a chronic and long-term disease responsible for morbimortality worldwide; in 2019, it was reported to be accountable for 1.5 million direct deaths and 460,000 indirect, mainly through kidney disease complications [1]. Additionally, it is estimated that 534.6 million people were suffering from DM in 2021, and the number of people with this condition will rise to 783.2 million by 2045 [2]. DM significantly increases medical costs, causes loss of productivity, premature mortality, and other effects such as reduced quality of life [3]. For example, in 2019, diabetes-related healthcare expenditure was around USD 760 billion for adults aged 20–79 years worldwide, and it will be approximately USD 845 billion by 2045 [4].\n\nHealthcare systems implement comprehensive care pathways through evidence-based Clinical Practice Guidelines (CPG), and adherence to these recommendations by patients and their families, physicians, and institutions is critical to reducing DM’s short- and long-term complications. However, several barriers have been identified, such as health system management, lack of clarity and credibility of guidelines, knowledge of the health professionals, and patient’s knowledge and sociocultural beliefs [5]. To tackle barriers from an institutional flank, it is possible to develop clinical tools that include structured information and unstructured data from Electronic Health Records (EHR) to support clinical decision-making to predict DM progression.\n\nThe literature usually develops predictive models using socio-demographic characteristics and biomarkers as standard predictors of diabetes-CKD progression [6–14]. These models typically consider only progression to CKD or development of some particular complication, but do not consider whether the patient is meeting HbA1c targets. Moreover, these models typically do not consider the health professional’s adherence to CPG recommendations as an attribute, especially in recommendations on lifestyle changes and patients’ attitudes and support networks. This is because, among other things, health professional and patient adherence is typically registered within the EHR’s free text (instead of structured fields). The closest study, extracts information on past history of diseases in the context of a CKD progression model [15].\n\nOur objectives are two. First, using Natural Language Processing (NLP) techniques and data from the EHR of a Health Maintenance Organization (HMO) in Colombia, we reached information not only on the patient’s characteristics but also on their pharmacological compliance and the professional’s adherence to the care pathways (non-pharmacological and pharmacological recommendations). Second, we develop machine learning (ML) models to estimate the progression of DM, in terms of metabolic goals and the development of complications, at one and two years and to determine critical variables in such transitions.\n\nA retrospective cohort study was conducted. Population belongs to a Colombian HMO with extensive coverage in the national territory. EHR records of patients with a confirmed diagnosis of DM and with at least one Glycosylated hemoglobin (HbA1c) measurement for 2018, 2019, and 2020 were included. We utilized ICD-10 codes registered in the EHR to identify patients with a diagnosis of diabetes mellitus type 1 or type 2, excluding gestational diabetes cases. Furthermore, to ensure accuracy, the status of these diagnoses was cross-checked by the auditing department of the Health Maintenance Organization (HMO). We received approval by UNISANITAS Ethics and Research Board (CEIFUS 2116–21; October 29, 2021). Consent was not obtained as the data was analyzed anonymously, and was provided by the insurance company on March 25, 2022.\n\nWe proposed a theoretical disease progression model with four stages based on metabolic goals defined by HbA1c levels (<6.5, <7.0, <7.5 according to patients’ characteristics) suggested by the American Diabetes Association standards and the presence of chronic complications (retinopathy, cerebrovascular disease, and chronic kidney disease) [16]. According to the model, a patient with DM can be in four basic stages at the beginning of follow-up: 1. Within HbA1c goals without complications (ON-NOT), 2. Outside goals without complications (OUT-NOT), 3. Within goals, but with complications (ON-YES), and 4. Out of goals and with complications (OUT-YES). The patients can move from stages with no complications to stages with complications in a unidirectional way; that is, once they develop one of the complications, they are in the stage with complications and cannot return to a stage without complications. In contrast, the transitions between the stages on and off-goals are bidirectional since it is determined by their HbA1c levels, as indicated by the arrows inFig 1. Likewise, a patient might remain in the same stage during the period.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.g001\n\nThe primary database comprised electronic health records (EHRs) that provided comprehensive information on outpatient care. This included demographic details such as age and sex, as well as complications like acute myocardial infarction, heart failure, peripheral vascular disease, chronic kidney disease, retinopathy, arrhythmias, and chronic obstructive pulmonary disease (COPD). Complications were documented using the International Statistical Classification of Diseases and Related Health Problems (ICD-10) (see Supplemental MaterialS1 Filefor the exact codes). It also covered measurements from physical examinations, including systolic and diastolic blood pressure, weight, height, and body mass index (BMI). Laboratory test results were part of the dataset, featuring HbA1c, LDL cholesterol, creatinine, and estimated glomerular filtration rate (eGFR) levels. The database also included information on diabetes mellitus treatment drugs, such as oral hypoglycemics and insulins, and concomitant treatments like analgesics, antacids, anticoagulants, antihypertensives, and lipid-lowering medications. Furthermore, the data encompassed referrals to specialists in ophthalmology, nutrition, psychology, and social services. It tracked professional adherence to personalized HbA1c goals, blood pressure goals, and dyslipidemia management. Additionally, free text information might provide insights into patient compliance with medication and adherence to medical recommendations for non-pharmacological interventions, including nutritional advice, physical exercise, and cessation of alcohol and tobacco use.\n\nThe information was recorded in a combination of standardized forms (structured data) and free-text fields (unstructured data), or both. Hence, before estimating transition models, we need first to consolidate a structured dataset.Table 1presents the variables that were selected for the estimation of transition models due to their availability and relevance according to the CPG, and the source of information used to construct those variables.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t001\n\nAs an example of the goal of this data processing step, theTable 2shows the information from the medical consultation of a patient. Originally, this patient had no data associated with complications or drugs in the EHR. However, free-text information has detailed information on both fields as well as information on non-adherence to drug therapy. Hence, we use NLP to classify the patient and to assemble the information on the missing fields: the patient has hypertension (bold and italic text) and is under several drugs that are typically used to treat diabetes or that are relevant for choosing a particular treatment strategy according to the guidelines (italic text). Notice that the words that indicate either health conditions or drugs may differ from the ‘tags’ that we use to identify the condition. For instance, the free text mentions “HBP” (high blood pressure) instead of using the word “hypertension”. For the case of adherence to drug therapy (bold text), the procedure is more elaborated than searching for specific words, and the algorithm for assigning the indicator needs validation by a clinical expert.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t002\n\nWe follow a three-step methodology to assign the corresponding labels to the unstructured data. We start by “cleaning” and “preparing” the data set (pre-processing). This involved removing URLs and special characters and digits, converting the text to lowercase, and removing stop words. Specific details of the pre-processing step are presented in supplemental materialS2 File. Then, we extracted the relevant characteristics to classify the information (characterization). Next, we inferred the labels assigned to the records of interest (classification). This process creates new data, initially absent in the structured EHR fields, and then integrates it into the dataset.\n\nFor the characterization and classification steps, we used two approaches to process the data: a simple search using a pipeline in which labels are generated from patterns in the free text and the Bag of Words (BoW) method [17,18]. The BoW method is ideal for scenarios where the simple search might not be straightforward (for instance, to detect if the physician considers that there is no pharmacological adherence) but where we can still rely on a pre-established “dictionary”, a set of words that are relevant. This is the case as clinical literature uses relatively standard terms that indicate health conditions, treatments, and medications, among others. When such a dictionary is not available, NLP techniques should rely on methods that guess the most relevant words from the free text (for instance the Term Frequency-Inverse Document Frequency TF-iDF method).\n\nWe created a custom medical dictionary to strengthen spelling correction, lemmatization, and stemming stages for text analysis. To construct it, we reviewed medical literature, including GPC and research articles, to ensure the vocabulary was complete and relevant to DM. Terms were carefully selected to include standard medical nomenclature, common variants, and colloquial terms that might appear in patient-reported data or EHR. The dictionary was validated by engineers and clinicians and tailored to the specific context of the DM. The Supplemental MaterialS2 Filepresents the details of how the BoW is implemented and the pre-processing steps involved.\n\nWith complete information on every field of interest in the database, we evaluated the level of adherence to the CPG recommendations. We assessed adherence in three key aspects: pharmacological, nutritional, and lifestyle recommendations such as tobacco and alcohol consumption. For medications, we considered whether the patients received adequate prescriptions for hypoglycemic agents, antihypertensives, and drugs to control cholesterolemia. Treatment inertia, the lack of a support, the attitude of the patient, or the incorrect prescription explain the discrepancies between the CPG algorithms and what is reported in the EHR. Again, we used NLP to examine these inconsistencies and have more precise patient adherence numbers.\n\nThird, to estimate the predictive model of DM progression, we followed an architecture corresponding to a nested tree model in which one multiclass classification problem is transformed into two levels of binary classifications [19,20]. In particular, outcomes are defined as the stages in the model ofFig 1. Thus, we train two models per stage and time horizon, except for the stages ON-YES and OUT-YES, which only predict if patients will be in or out of goals. We had twelve different models since we predicted one and two years forward. Initially, we modeled the transitions in a multinomial setting, but the best results regarding the metrics described above were attained with the present modeling strategy. We compared the performance of several statistical models, including ML algorithms, as alternatives. In particular, we used K-nearest neighbors (KNN), logistic regression (LR), decision trees (DT), random forest (RF), neural networks (NN), and boosting (Boost).\n\nThe selection of ML models was guided by the characteristics of the dataset and the complexity of predicting diabetes progression. Specifically, LR was included due to its interpretability, making it a valuable tool for understanding the impact of individual predictors in binary classification tasks. Additionally, RF was chosen for its robustness to overfitting and ability to handle high-dimensional clinical data with complex interactions, which are prevalent in disease progression modeling. These models complement other approaches, such as KNN for benchmarking, DT for interpretability, NN for capturing nonlinear relationships and Boosting methods for handling imbalanced datasets. Supplemental materialS3 Fileprovides a detailed justification for selecting each model.\n\nWe profited from Pycaret (an ML library in Python) for automatizing part of the preprocessing tasks and for comparing performances across models. Pycaret allowed us to build the entire ML pipeline with minimal coding and to compare the performance across architectures.\n\nFor the preprocessing stage, we oversampled unbalanced classes and performed a feature selection that removed variables with low variance and that were highly collinear. In a nutshell, iteratively runs a LightGradientBoosting Machine model on different sets of characteristics to pick the most relevant ones for classification.\n\nIn the next step, the pipeline sets up a grid of models, where each model has a parameter grid, so we perform a grid search across both models and hyperparameters to determine which is the best predictor for a specific transition and outcome. We trained twenty models with a 10-fold cross-validation strategy (StratifiedKFold) and compared their performance in the validation set. This approach ensures that the model is trained on various data set partitions while maintaining the proportion of classes in each fold. In this case, cross-validation aimed to select hyperparameters and evaluate the model’s generalization. Upon completion of the ten iterations, the model’s performance at each fold is averaged to obtain an overall estimate of its performance on the data. This strategy ensures that the results reflect an average of several data set splits, providing a more robust metric. To determine the most adequate model in the gid search we considered as performances metrics the accuracy, the F1-score, and the Area Under the Curve (AUC). Among them, we privilege the F1-score. Considering the performance metrics, a common scenario when considering imbalanced datasets is that the F1 score exhibits proficiency, while the AUC appears suboptimal. The AUC can yield a lower value due to challenges in effectively distinguishing the minority class amidst the dominance of the majority class. Supplemental material 3 includes more details about the process and alternative strategies that we considered.\n\nNotwithstanding Pycaret’s ease of use, its performance with some models was quite low, so we turn to model a neural network with three fully connected layers, each one with 256 neurons and Rectified Linear Unit activation functions (ReLU). In between each layer we input a dropout layer that helps us regularize the weights and tackle overfitting. The final layer has a sigmoid activation function for modeling the transition probability. For each model we design a hyperparameter grid that varies the regularization parameter, the learning rate, and the epochs. Finally, we estimated marginal changes in the predicted transition probability to determine the relevance of variables included in the training.\n\nThe original dataset started with 75,714 patients. Of those, only 25,320 had HbA1C measurements in the three study years, even though CPG suggest at least two measurements per year. Of those, a total 23,802 patients were included in the analysis as the remainder had missing information in some the predictor variables. These patients were dynamically distributed in the four stages (Table 3). The median age of the patients and the proportion of women in the four stages are similar. Some differences in biomarkers and results of physical examinations are explained by being at different stages. Interestingly, the proportion of compliant patients with pharmacological treatment is lower in the better scenarios (OUT-YES and ON-YES) than in the worst settings (ON-NOT and OUT-NOT). As expected, the proportion of patients treated by a professional who adhere to the HbA1c guideline is higher among those who are ON-goals than those who are out of goals. The proportion of patients receiving non-pharmacological recommendations is similar for patients ON-goals (independent of whether they have complications) and lower for those OUT-goals. In contrast, tobacco cessation recommendations seem more focused on patients with complications than patients without complications, regardless of their metabolic goals stage.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t003\n\nUsing NLP, we found that 99% of patients received nutritional recommendations, 96% received advice on physical activity, 74% on alcohol consumption, and only 14% on tobacco use. In addition, NLP helps identify text patterns when analyzing professional adherence to the metabolic control guidelines algorithms. For example,Table 4shows how the classification of patients receiving hypoglycemic treatment improved significantly after NLP (see differences between panels A and B inTable 4). Ideally, all patients would be on the diagonal of the matrix. However, in real clinical practice, patients may be reluctant to accept prescriptions, physicians may deviate from the CPG, or there may be treatment inertia instead of the CPG recommendations. With NLP, we reduced the number of patients out of the diagonal due to the lack of structured data.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t004\n\nIn general, for one-year transitions, patients tend to remain at their initial stage (see panel A inTable 5). However, at the two-year follow-up, patients without complications moved to other stages during the first year, while the transitions for patients with complications were stable (see panel B inTable 5). In particular, 18.1% of patients in the ON-YES stage moved out of goals after one year and 19% after two years. In addition, 26.9% of those who start in the OUT-YES stage tend to return to metabolic goals in the first year, and 32.9% do so in the second year, transitioning to the ON-YES stage. The second most common scenario for patients without complications and within goals is to develop some complications at one year (47.7% remain in ON-NOT, and 34.6% move to ON-YES). Analyzing two years, the scenario where the patients have complications becomes the most feasible: 52% move to the ON-YES stage, and only 26.8% remain in the ON-NOT stage. The group of patients initially in the OUT-NOT stage showed the most profound changes in transition patterns. In one year, 16.1% of them achieved goals, 40.8% remained in the same conditions, 11.9% only developed complications, and 31.1% moved to the worst scenario of OUT-YES. At two years, these percentages are 11.5%, 21%, 22.3%, and 45%, respectively.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t005\n\nTable 6presents metrics for training and testing datasets for the set of the best algorithms according to their F1 score in the testing data, for each of the 12 models.Fig 2illustrates the F1 scores for each of the models. Conditional to start in the better scenarios (ON-goals and NOT complications), the NN models have acceptable performance in predicting OUT-goals transition at one and two years (F1-scores between 0.72 and 0.76 inTable 6). For patients who start with the worst-case scenario (YES-complications), the LR fits well for predicting OUT-goals transition at one and two years (F1-scores > 0.8 for both). Predictions for those who remain in the same OUT-goals scenario were performed at one year with LR and two years with LGBoost, with good performance in both cases (F1-score of 0.83 and 0.78, respectively). The prediction of developing complications at one year was estimated using Boosting models for both ON-goals and OUT-goals starters (F1-score of 0.81 for AdaBoost and GBC). Similar predictions, but with superior performance, were made for the second year using LR (F1-score > 0.94 in both cases). The full set of results for all tested models is available in Supplemental MaterialS4 File. As discussed in the methods section, in imbalanced datasets, the F1 score gives favorable results when the predictive model excels in identifying the less prevalent but critical class (outside goals or with complications).\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.g002\n\nFinally, aiming to address the unbalanced nature of our training set, we tried two different adjustments to make all the classes equally representative. By means of the Synthetic Minority Oversampling Technique (SMOTE), (i) we upsampled the minority class, while holding the majority class constant; and (ii) we upsampled the minority class and downsampled the majority class. This was only performed on the training set while holding the test set constant. Even though there were minor gains in the cross-validation process, the testing metrics did not substantially change, as can be seen onTable 7andTable 8. Given that the processing pipeline for the initial models was relatively simpler, we preferred to maintain them.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t007\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t008\n\nTable 9presents the confusion matrix for the selected models. For its construction we selected a cutoff to translate predicted probabilities into binary predictions that maximize the kappa score in order to balance sensitivity (true positives rate) and specificity (true negatives rate). In general the resulting models perform better detecting true positives (predicting transitions that actually happened) than true negatives. In particular in the 2-year horizon, for those with complications the model has problems predicting that the patient will not move to OUT-goals, and the same for predictions into YES-complications from both ON and OUT-goals.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.t009\n\nAside from the performance metrics, from the general results from the model we can establish which factors exerted the most significant influence on predictions. Feature importance plots are provided for the models in rows two and four ofTable 6, which correspond to Logistic Regressions predicting the one-year transition of HbA1c levels. Specifically,Fig 3illustrates the most influential factors for patients without complications, whileFig 4does so for patients with complications. For patients initially without complications, staying out of target ranges is associated with receiving nutrition recommendations and not adhering to clinical guidelines. This underscores the critical role of prevention measures and proper nutrition in maintaining healthy HbA1c levels. Conversely, patients with early-stage Chronic Kidney Disease who do not follow the Cholesterol control guidelines also tend to miss their HbA1c targets. Overall, NLP-extracted features—particularly those related to nutritional habits—highlight the impact of dietary control in preventing HbA1c increases. Notably, lipid-lowering agents play a key role as well. Patients who consistently receive nutrition recommendations and take these medications often remain out of target, likely due to unchanged dietary habits.\n\n=0).\n\n=0).\n\nhttps://doi.org/10.1371/journal.pone.0321258.g003\n\n=0).\n\n=0).\n\nhttps://doi.org/10.1371/journal.pone.0321258.g004\n\nWe move from feature importance to understand the marginal effect of each variable on the transition probabilities.Figs 5and6show predictors, such as age, explaining the probability of being OUT-goals at one and two years, regardless of whether the patient has complications.Fig 7considers instead the role of predictors of developing complications at one year for patients OUT-goals, from which we highlight the importance of eGFR. This result is expected as most patients in this category develop CKD.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.g006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0321258.g007\n\nProfessional adherence to HbA1c treatment recommendations reduces the probability (between 2 pp. and 5 pp. at one year and around 2 pp. at two years) of deviating from goals as long as the patients are on goals (Figs 5and6). Adherence to the dyslipidemia treatment guidelines decreases the probability of around 5 pp. of patients with complications remaining OUT-goals at two years (Fig 6). The probability of moving outside goals for patients in the better initial stage, i.e., ON-NOT, decreases more than 10% at one year (Fig 5) and only 1 pp. at two years (Fig 6) when the physicians adhere to the cholesterol recommendations. In addition, if professionals follow such guidelines, patients are less likely (20 pp. less for those ON-goals and around 3 pp. for OUT-goals) to develop complications at two years (Fig 7).\n\nFrom the patients’ side, non-compliance to pharmacological treatments increases, by more than 5 pp., the probability of developing complications at one year for the group of patients in the better scenario (see ON-NOT inFig 7). Surprisingly, the direction of the effect of non-compliance on the probability of being out of the HbA1c goals at two years is the opposite for patients with complications compared with those without complications: the probability of being OUT-goals increases by 4 pp. if the patient belongs to the first group and decreases by around 3 pp. for the second (Fig 6).\n\nThe transitions explored in the current analysis include a critical variable for the disease’s management (metabolic goals) and dimensions involving multidimensional treatment factors. In particular, the model systematizes, in a replicable and scalable way, the information on the pharmacological compliance of the patient and the professional’s adherence to the care pathways (non-pharmacological and pharmacological). In this sense, the model’s predictions regarding the development of complications go beyond classic predictors such as age or creatinine levels, providing additional information on how institutional variables such as physicians’ adherence to metabolic control guidelines and lifestyle recommendations play an essential role in the disease progression.\n\nWe run the models using a relatively similar number of patients and follow-up time compared to other studies in the literature [21]. Our models achieve close to 80% accuracy, similar to some results reported in the literature. For example, to predict the development of diabetes in China, the accuracy of RF models reaches up to 80% and NN 78% [22], and to predict risk factors for the progression of diabetic kidney disease to end-stage renal disease in the same Chinese context, RF models show accuracy around 82% [23]. In Japan, using big data machine learning methods with EHR data on a CKD aggravation model, the AUC was 0.743 and accuracy of 71% [15]. A CKD model, using data from a biobank, that on top of the EHR incorporated novel biomarkers for predicting the deterioration of renal function, reported an AUC of 0.77 [24]. Our models even outperform a recent Chinese study that used LR, DT, RF, and extreme gradient boosting (XGBoost) to predict progression to developing DM at 1 and 2 years (Accuracy around 60% and F1-scores close to 40%) [25].\n\nThis study could impact patients and the healthcare system from a clinical perspective. The model developed might aid in identifying individuals at risk of future complications early, enabling timely preventive measures. We highlight that the incidence of complications, despite achieving glycemic control, suggests the need for more comprehensive management strategies in patients with diabetes mellitus. For example, healthcare providers could implement more frequent monitoring of renal function (as indicated by the glomerular filtration rate) and cardiovascular health, especially in older patients or those with a history of poor compliance to treatment, even when they are within HbA1c targets. Additionally, our findings support the importance of reinforcing adherence to treatment guidelines for HbA1c and dyslipidemia, as well as personalized patient education focusing on lifestyle interventions, such as diet and exercise. These interventions could lead to better management of chronic complications like cardiovascular disease and kidney failure, ultimately improving long-term health outcomes in this population.\n\nThis analysis has several limitations. First, DM is a chronic disease usually related to complications incidence for five years, and our follow-up considers only 1 and 2 years, which is too short to identify all new cases in the cohort. Our model focuses on measuring the progression of DM towards critical stages like the development of complications. However, we had no data on more decisive outcomes such as hospitalization and mortality. Second, we recognize that the retrospective nature of our study and the inclusion criteria based on the availability of HbA1c measurements could introduce selection bias. Patients with more frequent follow-ups or better adherence to treatment might be overrepresented, potentially influencing the results. In addition, if the patients with diabetes who moved were more (or less) likely to develop complications or to be out of the sample, our selection would induce a bias. The usual transfer rate of general patients between HMOs in the country was around 6% [26], but we do not have such data for the HMO studied. Third, as our study was conducted within a single HMO in Colombia, the findings may not be directly generalizable to other populations or healthcare systems. Elements such as the NLP-generated labels are typically specific to the Colombian context, and to some extent to the specific HMO. Still, the general procedure can be replicated elsewhere. For future work, we suggest validating the NLP exercise by obtaining metrics through the revision of the classifications by an independent clinical expert team in another dataset. In general, we recommend validating the presented prediction model in other populations prior to its clinical use.\n\nIn a more recent cohort of patients from the HMO studied, only 30% of patients with DM developed chronic complications, and about half were controlled. Surprisingly, we found that more than 60% of patients who start in the better scenario develop chronic complications at two years. Our result may be explained by characteristics specific to the study cohort analyzed. Considering the ML-model performance metrics, our F1 scores exhibit proficiency, while the AUC appears suboptimal and for some models the true negatives rate is not ideal. This phenomenon is observed in imbalanced datasets, where the instances of one class significantly outnumber those of the other [27].\n\nUsing NLP techniques to incorporate unstructured information, we developed an ML-based model to estimate the probability of diabetes progression over one and two years in a cohort of 23,802 patients from a large Colombian HMO. Our findings reveal that glycemic control alone does not prevent disease progression. Despite starting in the best-case scenario—on-target HbA1c and no complications—more than 60% of patients develop chronic complications within two years. This highlights the need for a more comprehensive management approach beyond glucose control.\n\nOur models also show that adherence to dyslipidemia treatment guidelines significantly reduces the likelihood of patients falling outside HbA1c targets and developing complications, while non-adherence to pharmacological treatments is a strong predictor of worsening outcomes. These results suggest that managing diabetes effectively requires enhanced monitoring of kidney and cardiovascular health, reinforcement of professional adherence to lipid and metabolic control guidelines, and improved patient education on lifestyle interventions.\n\nAlthough our models perform well compared to existing literature, the results suggest that even with highly granular patient-level data from a major insurance company, predictions remain far from ideal. This underscores the importance of improving data collection and integration, particularly regarding lifestyle factors and long-term patient behaviors. Future work should focus on validating these findings in other populations and exploring interventions that can actively improve adherence and long-term outcomes.\n\nThe analysis here is based on correlations; in this sense, adherence to recommendations may be endogenous as doctors may be more incisive depending on what they expect their patients to do [28]. Further research should include some experimental variation, for instance, on the intensity of the exposure to the recommendations from the physicians. Finally, the ML models were packaged into a calculator that can be used as a decision-support tool in clinical practice. The calculator works like a simulator, allowing physicians to enter values of clinical variables and determine in real time the probability that the patient will move to different stages. Currently, the calculator is a test prototype designed and expected to be used for research purposes.\n\nhttps://doi.org/10.1371/journal.pone.0321258.s001\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321258.s002\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321258.s003\n\n(DOCX)\n\nhttps://doi.org/10.1371/journal.pone.0321258.s004\n\n(CSV)\n\nWe would like to thank Andrés Ramírez for the provided intellectual support and technical assistance during the elaboration of this paper, and Andrea Castillo Niuman for her contribution with administrative tasks. We also thank Fundación Universitaria Sanitas in Colombia for providing the primary dataset for this research.",
    "category": "statistics"
  },
  {
    "title": "Multi-scale prototype convolutional network for few-shot semantic segmentation",
    "authors": "Ding Xu, Shun Yu, Jingxuan Zhou, Fusen Guo, Lin Li, Jishizhan Chen, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0319905",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0319905",
    "content": "Few-shot semantic segmentation aims to accurately segment objects from a limited amount of annotated data, a task complicated by intra-class variations and prototype representation challenges. To address these issues, we propose the Multi-Scale Prototype Convolutional Network (MPCN). Our approach introduces a Prior Mask Generation (PMG) module, which employs dynamic kernels of varying sizes to capture multi-scale object features. This enhances the interaction between support and query features, thereby improving segmentation accuracy. Additionally, we present a Multi-Scale Prototype Extraction (MPE) module to overcome the limitations of MAP (Mean Average Precision). By augmenting support set features, assessing spatial importance, and utilizing multi-scale downsampling, we obtain a more accurate prototype set. Extensive experiments conducted on the PASCAL-and COCO-datasets demonstrate that our method achieves superior performance in both 1-shot and 5-shot settings.\n\nCitation:Xu D, Yu S, Zhou J, Guo F, Li L, Chen J (2025) Multi-scale prototype convolutional network for few-shot semantic segmentation. PLoS ONE 20(4):\n           e0319905.\n        \n        https://doi.org/10.1371/journal.pone.0319905\n\nEditor:Haofeng Zhang, Nanjing University of Science and Technology, CHINA\n\nReceived:November 6, 2024;Accepted:February 11, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Xu et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data used in this study are derived from open-source datasets. The PASCAL-5i dataset, a variant of the PASCAL VOC dataset, and the COCO-20i dataset, derived from the COCO dataset, were used to evaluate the model’s performance. Both datasets are publicly available: PASCAL VOC can be accessed athttp://host.robots.ox. ac.uk/pascal/VOC/, and COCO athttps://cocodataset.org/.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:The authors have declared that no competing interests exist.\n\nSemantic segmentation is a fundamental and critical task in computer vision, involving the assignment of a distinct class label to each pixel within an image. This pixel-level classification provides a comprehensive interpretation of visual data, enabling machines to perceive and understand the objects within an image with high spatial accuracy. Semantic segmentation plays a pivotal role in various practical applications, such as autonomous driving, medical image analysis, and satellite imagery, where precise object delineation is essential for decision-making and further analysis. However, traditional semantic segmentation methods rely heavily on large, labeled datasets to effectively train deep learning models. These datasets require meticulous annotation to ensure that the model can accurately differentiate between various object classes. The process of collecting and labeling such vast amounts of data is resource-intensive, costly, and time-consuming. Furthermore, the complexity and variability of real-world objects, along with the diverse range of image contexts, exacerbate the challenges associated with this task [1–3].\n\nIn recent years, few-shot segmentation has emerged as a promising solution to address the limitations of traditional segmentation approaches. Few-shot segmentation aims to mitigate the scarcity of labeled data by leveraging techniques from meta-learning and few-shot learning, enabling models to generalize from a limited number of annotated examples [4–6]. This capability is particularly crucial for applications that require rapid adaptation to new, previously unseen object classes or environments. However, few-shot semantic segmentation faces significant challenges, primarily due to the limited availability of labeled data for novel categories, compounded by substantial intra-class variability and inter-class similarity among segmentation targets.\n\nCurrently, the majority of Few-Shot Segmentation (FSS) methods predominantly rely on prototype-based approaches [7,8,10,11]. These methods extract segmentation cues by applying Masked Average Pooling (MAP) to the features from the support set. The prototypes generated through this process represent typical feature samples of the target objects in the support set images, and these prototypes are subsequently used to make predictions for the objects in the query image via techniques such as cosine similarity or feature concatenation. However, the simple averaging operation used in MAP has notable limitations. Specifically, it fails to preserve the diversity information and intrinsic object details captured by the individual pixels in the support images. By averaging the features, this process smooths out fine-grained object details, resulting in the loss of critical spatial and structural information necessary for accurate segmentation. As a result, the prototypes generated through MAP may lack sufficient discriminative power, significantly undermining segmentation accuracy, particularly when dealing with complex and diverse objects. Additionally, significant scale variations and appearance changes within object classes further exacerbate the challenge, leading to coarse segmentation results that lack precision and fine detail.\n\nTo tackle these challenges, we introduce a novel framework: the Multi-Scale Prototype Convolutional Network (MSPCNet). This framework is specifically designed to mitigate intra-class variation while effectively capturing the intrinsic details of objects. A pivotal component of our approach is the Prior Mask Generation Module (PMG), which enhances interactions between the features of the support set and the query image. By generating prior masks, the PMG facilitates a more effective alignment of support and query features, guiding the segmentation process and enabling the model to focus on the most relevant regions of the query image. Specifically, we employ three dynamic kernels, each with a different sliding window size. These kernels are strategically designed to extract features at varying spatial resolutions, enabling the model to capture both fine-grained details and large-scale object characteristics. The outputs from these kernels are subsequently utilized to generate distinct query activation maps, which guide the model’s attention to the diverse scales and appearances of objects in the query image. This multi-scale interaction strategy, though conceptually simple, is crucial for achieving robust segmentation. It allows the model to adapt effectively to the wide range of object sizes and structural variations within the query image, while preserving their intrinsic details, thereby enhancing both segmentation accuracy and robustness.\n\nAdditionally, to address the issue that Masked Average Pooling fails to adequately extract segmentation priors from support images, we propose a Multi-Scale Prototype Extraction Module (MPE). Specifically, we enhance support set features using a designed feature enhancement module and evaluate the importance of each spatial position vector. We then obtain a multi-scale feature set by applying different down-sampling factors and aggregate the support set masks with the multi-scale features to derive the prototype set. This prototype set, along with the query set features, is used to generate category-aware features. Finally, we fuse the category-aware features, query activation maps, and intermediate query features to produce refined query pseudo-masks. Our main contributions are as follows:\n\nSemantic segmentation is a vital area of research in computer vision, concentrating on the task of assigning class labels to each pixel in an image for a comprehensive understanding of visual content. Few-shot segmentation seeks to tackle the challenges of image segmentation with only a limited set of labeled examples, offering a distinctive opportunity for image analysis and interpretation using minimal training data.\n\nSemantic segmentation aims to provide a comprehensive understanding of visual scenes and precise object localization. Early approaches, such as Fully Convolutional Networks (FCNs) [12], pioneered the development of end-to-end networks tailored specifically for semantic segmentation tasks. These networks utilized dense forward computation and backpropagation to generate outputs that match the input image size, effectively allowing for pixel-wise classification. By integrating semantic information from various convolutional layers, FCNs improved the accuracy of semantic segmentation networks significantly.\n\nAs the field evolved, more sophisticated architectures emerged. Encoder-decoder frameworks and dilated convolution techniques, exemplified by models like U-Net [13], SegNet [14], and the DeepLab series [15], made substantial strides in enhancing segmentation precision. These models not only excelled in detail restoration but also improved contextual understanding, which is crucial for accurately identifying and delineating objects within complex scenes. To address the inherent challenges posed by multi-scale targets—where objects may appear at various sizes—Pyramid Pooling Modules (PPM) [16] and Atrous Spatial Pyramid Pooling (ASPP) [17] were introduced. These techniques significantly bolster the extraction of global contextual features, enabling models to recognize and segment objects more effectively, regardless of their scale.\n\nSimultaneously, attention mechanisms gained traction, including spatial attention and both position and channel attention modules [18–20]. These mechanisms are instrumental in enhancing the aggregation of long-range contextual information, thereby enriching the model’s ability to represent semantic information more robustly.\n\nDespite these advancements, traditional semantic segmentation methods encounter significant challenges, particularly in scenarios where annotated data is scarce or when there is a need to adapt to new categories that were not included in the training dataset. This dependency on large-scale annotated datasets constrains the scalability and generalization capabilities of these models, prompting researchers to explore alternative strategies such as Few-Shot Segmentation (FSS). FSS techniques aim to bridge this gap by enabling effective segmentation with minimal labeled examples, thus broadening the applicability of semantic segmentation in real-world scenarios.\n\nFew-shot segmentation overcomes the limitations of traditional methods by enabling segmentation of objects using a minimal number of annotated examples for each class. The primary goal is to generalise from a small support set (labelled examples) to accurately classify objects within a query image.\n\nRecent years have seen substantial advancements in prototype-based semantic segmentation for few-shot images [21,22].The SG-One network [23] optimizes feature maps and segmentation loss by utilizing two branches of shared convolutional layers. It employs Masked Average Pooling to extract prototype features from support images, measuring the prototype distance between support and query images using cosine similarity. The PANet [24] framework leverages prototype-based metric learning and incorporates prototype alignment regularization to maximize the information derived from support images. ASGNet [25] introduces a superpixel-guided clustering approach, which extracts multiple prototypes from support images and reconstructs their feature maps through a novel assignment strategy, thereby enhancing semantic extraction and representation. PFENet [26] aggregates multi-scale information from input samples to capture global feature information, significantly improving the model’s predictive capability. To address information loss issues, HSNet [27] focuses on feature interrelationships, converting dense feature-related tensors into segmentation results through high-dimensional convolutions. Additionally, advancements in attention mechanisms have further improved few-shot segmentation models. DENet [28] introduces a novel attention module that enhances algorithm generalization by adjusting the weights of the metric classifier. MCE [39] enhances few-shot segmentation by capturing shared visual properties and learning inter-image dependencies, improving pixel-wise labeling of unseen classes with limited annotated images. BAM [29] optimizes prediction results through a fully supervised semantic segmentation model, discarding erroneous predictions and proposing a new model based on base classes. The methods mentioned above primarily rely on prototype-based approaches, where features are extracted and prototypes are generated using Masked Average Pooling (MAP). However, the averaging operation in MAP fails to preserve the details and diversity information in the support set images, leading to the loss of fine spatial and structural information. As a result, the generated prototypes lack sufficient discriminative power. These methods often lead to a reduction in segmentation accuracy when dealing with complex and highly variable objects, particularly in cases where there are significant changes in object scale and appearance, causing the segmentation results to lack fine-grained details.\n\nTo address the limitations of current Few-Shot Segmentation (FSS) methods, we propose the Multi-Scale Prototype Convolutional Network (MPCN). The MPCN enhances feature interaction between the support set and query images through the PMG module, utilizing dynamic kernels at multiple scales to capture fine details and large-scale object features, thereby improving segmentation accuracy and robustness. Subsequently, the MPE module is employed to strengthen the support set features, apply downsampling to generate multi-scale features, and refine prototypes to achieve better query segmentation, thus overcoming the limitations of Masked Average Pooling (MAP).\n\nThe task of few-shot segmentation aims to address image segmentation challenges under conditions of limited annotated data. In a typical few-shot semantic segmentation dataset, the data is divided into training samplesand test samples, with the classes inandbeing mutually exclusive, i.e.,. During the training phase, the few-shot semantic segmentation model is trained on a large set of annotated training samples, under the guidance of the ground truth labelsfor query images. The goal is to construct a segmentation modelf(S,Q)  that can utilizeKannotated imagesand their corresponding support set masksto perform semantic segmentation on query images, producing predictionsthat approximate the ground truth(whereSandQrepresent the support and query sets, respectively). Consequently, during the inference phase, the model is able to rapidly generalize to new class datausing the limited annotated data, thereby alleviating the dependency on extensive labeled datasets.\n\nAs illustrated inFig 1, our Multi-Scale Prototype Convolutional Network comprises two key modules: the Prior Mask Generation (PMG) module and the Multi-Scale Prototype Extraction (MPE) module. Specifically, given the support and query images,and, we employ a shared-weight backbone to extract mid-level and high-level features. The PMG module subsequently generates an initial maskfor the target object in the query image and applies foreground filtering to the query set features. Subsequently, the MPE module extracts support prototypes and generates similarity map by matching these prototypes with the filtered query features. This process produces category-aware prototypes with contextual dependencies and rich semantics. During the decoder stage, we fuse the category-aware features, query activation maps, and intermediate query features to generate a refined query pseudo-mask. The technical specifics of each module will be addressed in the subsequent sections.\n\nInitially, high-level support and query features are fed into the Prior Mask Generation (PMG) module to generate the initial mask for the query image, which is then used to perform foreground filtering on intermediate query set features. Subsequently, the Multi-Scale Prototype Extraction (MPE) module extracts support prototypes and matches these prototypes with the filtered query features to generate a similarity map and category-aware prototypes. Finally, category-aware features, query activation maps, and intermediate query features are fused to produce a refined query pseudo-mask.\n\nInitially, high-level support and query features are fed into the Prior Mask Generation (PMG) module to generate the initial mask for the query image, which is then used to perform foreground filtering on intermediate query set features. Subsequently, the Multi-Scale Prototype Extraction (MPE) module extracts support prototypes and matches these prototypes with the filtered query features to generate a similarity map and category-aware prototypes. Finally, category-aware features, query activation maps, and intermediate query features are fused to produce a refined query pseudo-mask.\n\nhttps://doi.org/10.1371/journal.pone.0319905.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319905.g002\n\nTo align the features of the support set and query set, and to guide the segmentation model to focus on the most relevant regions in the query image, we introduce the PMG module. Specifically, we first use the high-level features from both the support set and the query set to generate a prior mask [8]. This prior mask, typically a matching between feature maps, represents an approximate location of the target object without considering the overall contextual relationships. To address this, we employ three sliding windows to achieve global and regional matching, as shown inFig 2. Specifically, we utilize the high-level features from the support set and query set, denoted asand, alongside binary masksas inputs. Here,Crepresents the channel dimension, whileanddenote the height and width of the support and query features, respectively. We then extract the regional featuresandusing the designed sliding windows:\n\nwhere  ⊗  denotes the Hadamard product,Wrepresents the sliding window operation, andU,Vare the height and width of the windows. We use three multi-scale windows, specifically (1,1), (3,3), and (5,5), to capture features corresponding to small, medium, and large objects. We then compute the cross-correlation featuresbased on similarity ofand:\n\nwhereEindenotes the Einstein summation convention [9],icjrepresents the index of, andickrepresents the index of; the final cross-correlation featurehas the indexijk, which indicates summation over indexc. Finally, we average and normalize the cross-correlation featuresto obtain the activation maps for the target object masks. Given that we use three different windows to obtain,, and, we average these to produce, which represents the approximate location of the target object in the query image.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319905.g003\n\nThe initial mask from the previous section only provides an approximate location of the target object. To capture more details, we construct a Multi-Scale Prototype Extraction (MPE) module to generate sufficiently informative and scale-sensitive support prototypes, and use a similarity spectrum module to filter out background from the query features, retaining the foreground to produce the final query class semantic feature. Specifically, to mitigate interference from irrelevant classes, we perform a pixel-wise multiplication between the initial maskand the query image featuresto obtain. Similarly, we multiply the support maskwith the support image featuresto obtain. The MS-CPE module then extracts rich semantic information from, as shown inFig 3.\n\nFirst, we apply average pooling to, followed by convolutional layers and activation functions to obtain the semantic-enhanced features:\n\nwheredenotes the support features after average pooling,represents the convolutional layers and a rule layer, andσis the Sigmoid function. To address the challenge of scale diversity within class samples, we obtain multi-scale feature setsby applying different down-sampling factorsr∈ { 1 , 2 , 4 } . Next, using, we retain the foreground features inand flatten them into a set of feature vectors:\n\nwhere  (x,y)  denotes spatial positions,Iis the indicator function that outputs 1 if the input condition is met and 0 otherwise, andrepresents the set of foreground feature vectors derived from the support image. Unlike methods that use direct mask average pooling, we use average pooling to extract general features, maximum pooling to retain significant features, and average the two pooled vectors to obtain the initial support prototype:\n\nwhere Avg and Max denote average pooling and maximum pooling, respectively.effectively summarizes the class semantic information. To achieve pixel-level predictions, we use a prototype matching model to construct a non-parametric similarity measure across spatial locations.\n\nFirst, we calculate the cosine similarity between the feature vectorat each spatial location and the support prototype. The cosine similarity is used as the exponent in an exponential function to obtain the similarity spectrumS:\n\nwhereexp⁡   andcos⁡  -simi denote the exponential function and cosine similarity, respectively;  (x,y)  represents the spatial location;denotes the feature vector ofat the location  (x,y) ; andS(x,y)  represents the similarity score betweenand. We use the similarity spectrumSto reweight the query image features, enhancing the foreground regions while suppressing the background, to obtain the category-aware feature:\n\nFinally, the category-aware feature, the query activation maps, and the intermediate query featuresare reshaped to the same spatial dimensions and fused together to produce the output feature:\n\nwheredenotes concatenation along the channel dimension. The final outputis then input to the decoder to generate the segmentation maskfor the query image:\n\nwhere,, andare the consecutive modules constituting the decoder.\n\nInspired by previous work [8,30,31], we employ the Binary Cross-Entropy (BCE) loss between the predicted maskof the query imageand the ground truth maskas the primary loss function for our model:\n\nAdditionally, to ensure that the multi-scale contextual prototype extraction module generates more accurate support prototypes, we introduce an auxiliary loss. This auxiliary loss is computed by predicting the support maskusing the corresponding query prediction mask, with the generation ofbeing similar to the method described in Equation (10):\n\nHere,represents the BCE loss betweenand. Thus, the final loss function is:\n\nwhereλis a balancing factor between the segmentation lossand the auxiliary loss. In our experiments,λis set to 1.0.\n\nPASCAL-[32] is a few-shot segmentation variant derived from the PASCAL VOC dataset [33], designed to evaluate the performance of few-shot learning methods. It divides the 20 object categories covered by the PASCAL dataset into 4 subsets, with each subset containing 5 classes for testing and the remaining 15 classes for training.\n\nCOCO-[34] is a variant of the COCO dataset [35] specifically designed for few-shot segmentation tasks. It partitions the 80 object categories in the COCO dataset into 4 subsets, with each subset containing 20 classes for testing and the remaining 60 classes for training.\n\nMetrics and Evaluation.Consistent with previous work, we utilize mean intersection over union (mIoU) and foreground-background IoU (FB-IoU) as our evaluation metrics. mIoU is a widely accepted standard for assessing segmentation performance, as it computes the ratio of the intersection to the union of predicted and ground truth regions for each category, averaging the results across all categories to gauge overall performance.\n\nwhereNis the number of categories,is the ground truth for categoryi, andis the prediction for categoryi. Moreover, FB-IoU offers a comprehensive assessment of the model’s segmentation capabilities by calculating the IoU between the predicted foreground and background regions and their corresponding ground truth segments. This metric provides a more precise evaluation of the model’s performance in managing complex scenes.\n\nwhereandrepresent the foreground and background in the ground truth, respectively, andandare the corresponding predictions for the foreground and background.\n\nImplementation Details.In our few-shot segmentation experiments, we selected VGG-16 [36] and ResNet-50 [37] as backbone networks, both pretrained on the ImageNet classification task, with their weights fixed during training. The implementation was carried out using PyTorch 1.9.0, and experiments were executed on an NVIDIA RTX 3090 GPU. All images were cropped to a size of 473 × 473 pixels for training. We utilized stochastic gradient descent (SGD) for optimization, setting the initial learning rate to 0.005, a batch size of 8, weight decay to 0.0001, and momentum to 0.9. Within the PMG module, sliding window sizes were configured to (1,1), (3,3), and (5,5). For the MPE module, downsampling factorsr∈ { 1 , 2 , 4 }  were employed. Training was conducted for 200 epochs on the PASCAL-5idataset and for 50 epochs on the COCO-20idataset.\n\nPASCAL-:Table 1provides a comparison of our model, MPCN, with various state-of-the-art methods on the PASCAL-dataset. Using the VGG16 backbone, MPCN surpasses most of the evaluated methods, attaining 63.2% mIoU and 75.6% FB-IoU in the 1-shot setting, and 68.6% mIoU and 79.1% FB-IoU in the 5-shot setting. Likewise, with the ResNet50 backbone, MPCN exhibits notable improvements. When compared to the most recent methods, SiGCN and MCE, MPCN achieves the highest mIoU and FB-IoU scores with the ResNet50 backbone. In the 1-shot setting, MPCN enhances mIoU by 2.3% compared to SiGCN and by 1.7% relative to MCE. In the 5-shot setting, MPCN increases mIoU by 2.6% compared to SiGCN and by 1.1% compared to MCE. Notably, MPCN also showed the highest foreground-to-background intersection ratio (FB-IoU) value, further emphasizing its effectiveness in distinguishing between foreground and background.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319905.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319905.t002\n\nCOCO-: COCO-presents a more challenging environment, featuring a greater number of categories and more complex scenes.Table 2illustrates the performance of MPCN in comparison to other methods on the COCO-dataset. Notably, MPCN excels in both the 1-shot and 5-shot settings. Using the VGG16 backbone, MPCN achieves an average Intersection over Union (mIoU) of 42.4% in the 1-shot setting and 47.8% in the 5-shot setting, significantly outperforming other methods such as DPCN and BAM. When using the ResNet50 backbone, MPCN’s performance is even more pronounced. In the 1-shot setting, MPCN reaches an average mIoU of 45.1%, outperforming SiGCN and MCE by 3.7% and 0.9%, respectively. In the 5-shot setting, MPCN achieves an average mIoU of 52.3%, exceeding SiGCN and MCE by 4.3% and 1.3%, respectively. Additionally, MPCN excels in FB-IoU, with scores of 69.4% and 71.2% in the corresponding settings.\n\nThe Multi-Scale Prototype Convolutional Network (MPCN) addresses intra-class variability and prototype representation issues through the Prior Mask Generation (PMG) and Multi-Scale Prototype Extraction (MPE) modules, achieving significant improvements in segmentation performance on the PASCAL-and COCO-datasets. However, the use of multiple dynamic kernels with varying sliding window sizes and multi-scale feature extraction may lead to a substantial increase in computational cost and memory usage.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319905.t003\n\nTo assess the impact of various modules on the model’s performance, we conducted an ablation study utilizing the ResNet-50 backbone in the 1-shot setting on the PASCAL-dataset. As presented inTable 3, the baseline model, which excludes the two modules (configuration (a)), achieves an mIoU of 63.4% and an FB-IoU of 74.6%. Introducing only the PMG module (configuration (b)) increases the average mIoU to 65.1% and the average FB-IoU to 76.3%. Adding only the MPE module (configuration (c)) further improves the average mIoU to 66.0% and the FB-IoU to 77.4%. The most notable performance enhancement occurs when both the PMG and MPE modules are utilized together (configuration (d)), resulting in a 4.2% increase in mIoU and a 4.1% rise in FB-IoU compared to the baseline model. The ablation study results indicate that both the PMG and MPE modules significantly enhance the performance of the MPCN model. While each module individually contributes to improving the mIoU and FB-IoU metrics, their combined application yields the highest performance.\n\nIn this subsection, we provide a detailed explanation of the selection of key hyperparameters, as well as a comparison with other refinement methods to highlight the advantages of the MPE module.\n\nFig 4ainvestigates the impact of different sliding window sizes on model performance. A1 represents the use of a sliding window of size (3,3), A2 represents a sliding window of size (5,5), A3 represents a sliding window of size (7,7), and A4 corresponds to the original configuration with sliding windows of sizes (1,1), (3,3), and (5,5). As shown inFig 4a, the A4 configuration achieves the optimal result, demonstrating that the multi-scale sliding window setting significantly enhances the model’s performance.\n\nFig 4bexplores the impact of different downsampling factor combinations on model performance. InFig 4b, B1 represents the use of downsampling factors [1,2,4], B2 uses [1,4,4], B3 uses [1,4,8], and B4 employs [1,8,8]. As observed fromFig 4b, the B1 configuration yields the best performance, indicating that this downsampling factor setting allows the model to effectively capture the key features of the data, thus improving performance.\n\nAdditionally,Fig 4cshows a comparison between MPE and other refinement methods. Here, DCM [8] represents dynamic convolution techniques, SGC [46] refers to superpixel-guided clustering, and PAM [47] corresponds to prototype activation methods. As seen inFig 4c, our method achieves the best mIoU results. Compared to dynamic and weighted adaptive clustering techniques such as DCM, SGC, and PAM, the MPE module significantly improves segmentation accuracy. By leveraging dynamic kernels for multi-scale feature extraction, our approach not only enhances feature alignment but also adapts more effectively to variations in object size and structure.\n\nFig 5illustrates the segmentation results of MPCN in comparison to the baseline model on the PASCAL-and COCO-datasets. As depicted, MPCN demonstrates greater accuracy in segmenting target objects and captures finer details more effectively than the baseline model. Specifically, in columns 1, 3, 4, and 6 ofFig 5, our proposed MPCN accurately segments the target objects, whereas the baseline model incorrectly includes irrelevant background elements in the segmentation.\n\nAs shown inFig 6we Visualization of different ablative results on the PASCAL-and COCO-datasets and compare the comparative results of the other methods. It can be seen that by adding PMG and MPG modules to the baseline model, the network can filter out irrelevant background regions and discover more target parts. For example, adding the fifth line of MPG removes the redundancy of the segmentation of birds and cars compared to the base prediction. In addition, adding the MPG module results in a more refined segmentation. For example, compared to the base prediction, the sixth row can filter out a large number of irrelevant background regions and localize the target object accurately. Finally, we compare our method with MCE, and as shown inFig 6, our approach accurately segments the bird and the car. In contrast, MCE erroneously includes the nearby motorcycle in its vehicle segmentation and fails to fully capture the car as a whole.\n\nIn this study, we tackle the challenges of few-shot semantic segmentation by proposing the Multi-Scale Prototype Convolutional Network (MPCN), which incorporates two innovative modules: Prior Mask Generation (PMG) and Multi-Scale Prototype Extraction (MPE). Our approach effectively addresses intra-class variability and prototype representation issues by utilizing dynamic kernels of varying sizes to capture multi-scale features and enhance feature interactions. The PMG module refines query predictions, thereby improving segmentation precision. Meanwhile, the MPE module addresses the limitations of traditional Masked Average Pooling by generating a more accurate prototype set through enhanced feature augmentation and multi-scale analysis. Extensive experiments conducted on the PASCAL-and COCO-datasets demonstrate that our method achieves substantial improvements in segmentation performance, surpassing existing techniques in both the 1-shot and 5-shot settings.\n\nFigure (b) explores the effect of various downsampling factor combinations on the model’s performance. Figure (c) presents a comparison of MPE with other refinement methods. All experiments were conducted under the PASCAL-1-shot setting.\n\nFigure (b) explores the effect of various downsampling factor combinations on the model’s performance. Figure (c) presents a comparison of MPE with other refinement methods. All experiments were conducted under the PASCAL-1-shot setting.\n\nhttps://doi.org/10.1371/journal.pone.0319905.g004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319905.g005\n\n\n\nhttps://doi.org/10.1371/journal.pone.0319905.g006",
    "category": "statistics"
  },
  {
    "title": "Assessing the feasibility of large language models to identify top research priorities in enhanced external counterpulsation",
    "authors": "Shengkun Gai, Fangwan Huang, Xuanyun Liu, Ryan G. Benton, Glen M. Borchert, Jingshan Huang, Xiuyu Leng, (PLOS)",
    "publish_date": "2025-04-15",
    "doi": "https://doi.org/10.1371/journal.pone.0305442",
    "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0305442",
    "content": "Enhanced External Counterpulsation (EECP), as a non-invasive, cost-effective, and efficient adjunctive circulatory technique, has been widely applied in in the cardiovascular field. Numerous studies and clinical observations have confirmed the obvious advantages of EECP in promoting blood flow perfusion to vital organs such as the heart, brain, and kidneys. However, many potential mechanisms of EECP remain insufficiently validated, necessitating researchers to dedicate substantial time and effort to in-depth investigations. In this work, large language models (such as ChatGPT and Ernie Bot) were used to identify top research priorities in five key topics in the field of EECP: mechanisms, device improvements, cardiovascular applications, neurological applications, and other applications. After generating specific research priorities in each domain through language models, a panel of nine experienced EECP experts was invited to independently evaluate and score them based on four parameters: relevance, originality, clarity, and specificity. Notably, high average and median scores for these evaluation parameters were obtained, indicating a strong endorsement from experts in the EECP field. This study preliminarily suggests that large language models like ChatGPT and Ernie Bot could serve as powerful tools for identifying and prioritizing research priorities in the EECP domain.\n\nCitation:Gai S, Huang F, Liu X, Benton RG, Borchert GM, Huang J, et al.  (2025) Assessing the feasibility of large language models to identify top research priorities in enhanced external counterpulsation. PLoS ONE 20(4):\n           e0305442.\n        \n        https://doi.org/10.1371/journal.pone.0305442\n\nEditor:Asim Mehmood, Jazan University, Saudi Arabia\n\nReceived:May 30, 2024;Accepted:February 23, 2025;Published:April 15, 2025\n\nCopyright:© 2025 Gai et al. This is an open access article distributed under the terms of theCreative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\nData Availability:All relevant data are within the manuscript and itsSupporting Informationfiles.\n\nFunding:The author(s) received no specific funding for this work.\n\nCompeting interests:NO authors have competing interests.\n\nEnhanced External Counterpulsation (EECP) is a non-invasive adjunctive circulatory technique that inflates and deflates cuffs wrapped around the limbs and buttocks in sync with the cardiac cycle under electrocardiographic gating control. EECP has been clinically demonstrated to significantly improve organ perfusion, regulate endothelial function, combat coronary artery atherosclerosis, treat complications of diabetes and sudden sensorineural hearing loss, among other benefits [1–3]. Although many evidences suggest there is a great deal of untapped potential for external counterpulsation, traditional approaches to identifying research priorities for EECP mainly rely on expert opinion and consensus building which are often labor-intensive and biased. In recent years, natural language processing (NLP) technology [4] has been increasingly recognized as a new means of identifying research priorities. Large language models (LLMs) such as ChatGPT [5] and Ernie Bot [6], which are trained on extensive text data, possess the ability to understand human-like language and have demonstrated significant potential in proposing and prioritizing research priorities [7]. In the medical domain, LLMs have shown promising results in various tasks, including disease diagnosis, medical record automation, literature retrieval, and patient education [8]. Adi Lahat et al. assessed the effectiveness of ChatGPT in generating research questions within gastroenterology and concluded that ChatGPT could be used to produce high-quality research inquiries [9]. Building on the recognition of NLP technology and the potential of large language models like ChatGPT and Ernie Bot to identify research priorities, their effectiveness in determining primary research priorities related to EECP technology were specifically evaluated in this work. Five key areas were examined: mechanisms, device enhancements, cardiovascular applications, neurological applications, and other applications. Utilizing ChatGPT and Ernie Bot, specific research priorities in these domains were generated, after which they were reviewed by experienced EECP experts and then rated to assess their relevance and importance.\n\nLarge language models have shown broad applicability in entertainment, education, and customer service, but their potential in the medical field remains largely untapped. Given the high standards for information quality and communication reliability in medicine, the application of large language models requires careful consideration. In recent years, scholars have begun to explore the use of large language models in medicine, yielding promising results. In the field of cardiology, Gala et al. [10] believed that LLMs can be utilized to analyze a large number of academy papers and medical record resources to help clinicians keep up with the latest advances in cardiology. Nevertheless, they also pointed to the limitations of LLMs in explaining cultural or emotional factors that may influence medical practice. Cascella et al. [11] explored the reasoning abilities of ChatGPT on public health topics. Through a question-and-answer session, ChatGPT listed four possible research topics. While some of the responses of ChatGPT may be stereotyped and depend on the prompts, it can be used to summarize the scientific literature and generate new research hypotheses. Additionally, George et al. [12] proposed that large language models could serve as a supplementary resource to traditional medical tools, improving the efficiency and productivity of medical practices. Unfortunately, these studies do not provide a quantitative assessment of the ability of LLMs to identify medical research priorities.\n\nImportantly, in order to assess the effectiveness of LLMs in the medical domain, it is essential to conduct statistical analyses on numerical results obtained from experiments and/or surveys. In evaluating the pertinent literature on LLMs, Tang et al. [13] invited field experts to assess the summary quality of LLMs by using a five-point Likert scale along four dimensions: coherence, factual consistency, comprehensiveness, and harmfulness. Man-Whitney U test was used to assess the differences in response between GPT-3.5 and ChatGPT. Michael et al. [14] employed average scoring and fixed-effects consistency to calculate the Intraclass Correlation Coefficient (ICC), investigating the potential application of artificial intelligence-based LLMs in the realm of medical ethics. Similarly, Dave et al. [15] utilized Pearson and Spearman coefficients to juxtapose the assessment outcomes of large language models against the evaluations of medical professionals, thereby further substantiating their dependability. Furthermore, besides correlation analysis, similarity metrics are frequently utilized to gauge the efficacy of LLMs. For example, in 2024, Sebastian et al. [16] evaluated the pairwise accuracy between LLMs and human assessments by analyzing the cosine similarity matrix. In measuring factual knowledge within LLMs, Pezeshkpour [17] successfully utilized Kullback-Leibler (KL) divergence to analyze the predictive probability distributions of the model before and after instilling target knowledge. In investigating bias issues within large pre-trained language models, Guo et al. [18] used the Jensen-Shannon (JS) divergence to measure the consistency between different demographic distributions, offering a robust tool for reducing human-like biases and unwanted societal stereotypes. JS divergence is an improved version of KL divergence, whereas the KL scatter is asymmetric, making the JS scatter more accurate in identifying similarities.\n\nChatGPT (based on GPT-3.5) and Ernie Bot 3.5 to generate research priorities in five key topics (Tables 1and2, respectively) pertaining were leveraged to EECP mechanisms [1,19], structural enhancements, applications in cardiovascular domains [3,20,21], neurological applications [22,23], and other applications [3,24,25].\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.t001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.t002\n\nThe expert evaluation panel was comprised of nine highly experienced EECP specialists as evidenced by panelists having authored an average of twenty relevant research publications in the field. They gained their expertise through clinical practice and made significant contributions to academic research, and experts have published at least five scholarly articles related to EECP. Furthermore, they have actively contributed to the development of guidelines in the EECP field. Panelists reviewed and assessed the inquiries presented by ChatGPT and Ernie Bot independently. Experts rated five priorities on four parameters (relevance, originality, clarity, and specificity) using a 1–5 scale with 5 representing the highest score. The a priori relationships generated by ChatGPT and Ernie Bot were then compared to current EECP research queries identified through a manual literature review. Importantly, in order to ensure the objectivity and relevance of responses, ChatGPT and Ernie Bot were instructed to treat each key topic as an independent query, thereby eliminating potential biases that may have existed in previous conversations.\n\nData were collected and analyzed using standard statistical methods, and all statistical analyses were conducted using IBM SPSS Statistics version 25 and Python 3.10. Initially, descriptive statistical methods were employed to provide a summary of the data, including measures such as mean, standard deviation (SD), and median. Afterwards, “divergence” was adopted to assess the similarity between ratings provided by experts in EECP and queries generated by two large language models. In the realm of data mining, JS divergence was computed to evaluate the similarity of ratings among evaluators using a rating table structured with evaluators as column attributes. JS divergence values from 0 to 1, with smaller values indicating greater similarity between ratings. Additionally, Spearman’s rank correlation coefficient and Kendall’s τ coefficient were also used to evaluate pairwise correlations between parameters. Positive coefficients indicate a positive correlation, while negative coefficients imply a negative correlation. The closer the coefficient is to 1 the stronger the correlation.\n\nThe statistical analysis shows high reliability for the questionnaires assessing ChatGPT and Ernie Bot, with Cronbach’s alpha coefficients of 0.978 and 0.971, respectively. Both coefficients exceed the 0.8 threshold, indicating strong survey reliability. This suggests that the questionnaires effectively reflect the proficiency of ChatGPT and Ernie Bot in determining research priorities for EECP.\n\nBased on this, the study conducted data analysis on the ratings provided by the 9 evaluators from three perspectives: (1) descriptive statistics; (2) similarity of ratings among evaluators; and (3) rank correlation of evaluation metrics. The data analysis tools utilized were IBM SPSS Statistics Version 25 and Python 3.10.\n\nThree score tables for each large language model were constructed, featuring evaluation metrics, evaluators, and topics as column attributes. For example, in the score table with five topics as column attributes, each column represents the scores from nine evaluators on four evaluation indicators for five research priorities within a specific topic. As shown inTables 3–5, the results were derived from descriptive statistics applied to these three score tables. Since the mean and standard deviation have been commonly used to describe normal or approximately normal distributions, the quartiles inTables 3–5were considered to accurately reflect potential non-normal distributions. It is believed that the combination of mean/standard deviation and quartiles effectively reduces the impact of extreme values that may not fully represent the actual situation. FromTable 3, it is clear that the two large language models excel in relevance, with originality following closely behind. In-depth descriptive statistical analyses of evaluation metrics are presented inTables 3–5. The major models performed best in relevance, with originality close behind. Although originality exhibited the largest standard deviation, suggesting significant variation in expert opinions regarding originality, clarity demonstrated the smallest standard deviation, indicating minimal fluctuations in scores for each question. Additionally, variations in performance between the two models (ChatGPT and Ernie Bot) across different evaluation metrics and topics can be observed. Concerning relevance, Ernie Bot’s average score slightly exceeds ChatGPT’s, suggesting a slight advantage in addressing user-related questions, although this was not statistically significant. In terms of originality, ChatGPT’s score was slightly less than Ernie Bot’s, with a higher fluctuation in scoring standard deviation, indicating some disagreement among experts regarding the originality of ChatGPT’s queries. Both models demonstrate similar performance in clarity and specificity, indicating their similarity in providing clear and specific answers. Results of scores from EECP experts for all priorities are visually presented inFig 1with the outermost rings corresponding to the highest score of 5 and inner rings indicating lower scores.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.t003\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.g001\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.t004\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.t005\n\nTable 4presents the scores given by different raters for the ChatGPT and Ernie Bot models. The analysis shows that in the evaluations of most raters, ChatGPT and Ernie Bot have similar average scores indicating a certain level of competitiveness in overall performance. However, it is worth noting that in the ratings of Rater3 and Rater4, Ernie Bot’s average score was clearly higher than ChatGPT’s, reflecting a more outstanding performance of Ernie Bot from the perspectives of these two raters. In terms of score stability, there were differences between the two models among different raters. Specifically, in the evaluations of Rater3 and Rater4, Ernie Bot had a lower standard deviation, indicating more stable scores and consistent performance. Conversely, Rater8’s Ernie Bot scores demonstrated significantly higher standard deviation. In contrast, although overall score stability was slightly inferior to Ernie Bot’s performance for a subset of raters, ChatGPT’s standard deviation among multiple raters was relatively more consistent. These differences in evaluation may stem from personal preferences, evaluation criteria, and model performance across different topics.\n\nIn all topics (Table 5), Ernie Bot consistently received higher average scores than ChatGPT, suggesting a relative advantage in overall performance. Although their performances in terms of median scores were similar, Ernie Bot achieved an upper quartile score of 5.00 in specific topics such as mechanisms, device improvements and applications in neurology, indicating higher recognition in these areas. Meanwhile ChatGPT’s standard deviation across multiple topics was slightly lower than Ernie Bot’s, suggesting relatively better score stability. However, this difference was not significant. Notably, clear domain-specific differences were observed, while Ernie Bot’s average score significantly surpassed ChatGPT’s in structural improvements and applications in neurology domains, ChatGPT demonstrated superior performance in other domains.\n\nRegarding the similarity of raters’ scores, the JS divergence of scores between each pair of raters for ChatGPT and Ernie Bot was calculated (Fig 2). The results indicate that the JS divergence range of scores for ChatGPT is [0, 0.102], while for Ernie Bot, it is [0, 0.148]. Since a smaller JS divergence value indicates higher similarity, it can be concluded that the evaluations of these two large language models by raters exhibit relatively high consistency. It is worth noting that, for both ChatGPT and Ernie Bot, the similarity of scores between rater 8 and other raters is the lowest. FromFig 1, it is evident that the scores given by rater 8 are significantly lower than those given by other raters. Further analysis of the data inTable 4reveals that the average scores given by rater 8 for both ChatGPT and Ernie Bot are the lowest (2.20 and 2.44 respectively). Besides, they have the highest standard deviations (0.80 and 1.21 respectively). Excluding the influence of rater 8’s scores, the upper limit of the JS divergence of scores for ChatGPT would decrease from 0.102 to 0.052, and from 0.148 to 0.063 for Ernie Bot.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.g002\n\nIn terms of the correlation of evaluation metrics, we calculated both the Spearman [26] and Kendall [27] coefficients between pairs of evaluation metrics in the scoring results for ChatGPT and Ernie Bot (seeTables 6and7). These analyses passed significance tests, with all p-values below 0.01 indicating a significant positive correlation between relevance, originality, clarity, and specificity. This implies that when evaluating these two models, the score trends among these metrics were consistent, demonstrating high consistency and reliability. That said, ChatGPT exhibited a lower correlation between originality and relevance, while Ernie Bot showed a lower correlation in the analysis of specificity and relevance. The clarity of both models was highly correlated with relevance and/or specificity.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.t006\n\n\n\nhttps://doi.org/10.1371/journal.pone.0305442.t007\n\nHere, the ability of ChatGPT and Ernie Bot was evaluated to generate research priorities in the field of EECP, covering mechanisms, structural improvements, applications in cardiology, applications in neurology, and applications in other fields. Both models demonstrated significant potential in consistently generating relevant and clear research priorities, which could offer valuable new tools for EECP research. Both scored relatively low in specificity, possibly due to limitations in handling domain-specific knowledge, indicating a need for improvement in accuracy and precision. To enhance their performance, fine-tuning with domain-specific data and expert knowledge will likely be required. While both models lacked originality in their responses, relying heavily on learned information and language patterns, future research should focus on enhancing their creativity to generate more unique research questions in the EECP field.\n\nNotably, the performances of Ernie Bot and ChatGPT, two prominent language systems were compared. Ernie Bot demonstrated a slight but definitive advantage in terms of relevance, possibly due to its more precise semantic understanding and higher matching with user needs. In terms of originality, ChatGPT scored slightly lower with more fluctuation, indicating some disagreement among evaluators regarding its ability to offer novel and unique perspectives. This variance might stem from differences in the models’ performance across different contexts or from evaluators’ subjective criteria, such as their acceptance of research priorities that challenge existing cognitive frameworks or their willingness to explore unknown areas of study. In contrast, Ernie Bot received more consistent recognition for its originality, likely due to its more flexible and innovative thinking patterns. Regarding clarity and specificity, both models performed equally well, demonstrating high levels of proficiency. This suggests that they excel in providing clear, understandable responses and specific, detailed explanations, which are equally important for large language models as users often expect answers that are both clear and specific to better understand and apply the provided information.\n\nFrom the evaluators’ perspective, most evaluators held similar views on the performance of the two models. However, in certain specific cases, such as Rater3 and Rater4, Ernie Bot received higher scores. Additionally, as compared to other raters, Rater8’s scores were significantly lower and deviated more substantially, and exclusion of Rater8 increased the performance of both models.\n\nIn certain specific topics such as mechanisms, applications in neurology, and cardiovascular applications, Ernie Bot performed better whereas ChatGPT’s performance slightly surpassed that of Ernie Bot in others, indicating that each model has its strengths and weaknesses in different domains and application scenarios.\n\nConsequently, future research should be performed explore how to effectively integrate the strengths of both models to improve the performance and efficacy of large language models in real-world applications.\n\nOur study applied ChatGPT and ERNIE Bot in the field of EECP to identify high-quality research priorities for the first time. It also offers a cross-disciplinary examination of the potential applications of EECP in neurology, metabolism, orthopedics, nephrology, and other areas. Furthermore, combining expert evaluations with statistical analysis enhances the scientific rigor and accuracy of our findings. This novel approach not only advances the development and refinement of EECP technology but also opens up new possibilities for patient treatment.\n\nAlthough this study presents promising outcomes, there are also some limitations in this study. Firstly, the expert panels involved may not fully represent the broader research community, which could have influenced the evaluation results. Secondly, the use of subjective ratings may introduce bias and variability in assessing the performance of ChatGPT and Ernie Bot. Lastly, the models may not have access to the latest biomedical literature, which could affect the quality of question generation. If this is the case, integrating domain-specific APIs with up-to-date information could enhance research quality. For future work, key directions include improving expert panel representation, optimizing large language models with more domain-specific training data, enhancing data transparency, applying more robust statistical methods, and fostering interdisciplinary collaboration. These efforts aim to address the identified limitations and promote innovation and advancement in EECP research.\n\nOverall, this assessment of ChatGPT and Ernie Bot as generators of research priorities for Enhanced External Counterpulsation (mechanisms, device improvements, applications in cardiovascular medicine, applications in neurology, and applications in other non-cardiovascular and non-neurological fields) produced some promising results. Both models have demonstrated the capacity to generate high-quality research priorities in these areas, indicating their potential value as tools to drive research not only in EECP but also in broader medical fields through streamlining the process of identifying crucial research priorities and thereby save considerable time and effort. While there is room for improvement in terms of specificity and originality, both models have shown a capability to produce diverse, relevant, and coherent research priorities, likely aiding advancements in EECP research. Each model has its strengths in various domains and application scenarios, and further exploration could focus on leveraging these strengths to enhance the overall effectiveness of large language models in practical settings. In conclusion, our findings suggest that ChatGPT and Ernie Bot are poised to become valuable assistants for researchers in the EECP field and likely other medical domains, offering new momentum for scientific progress.\n\nhttps://doi.org/10.1371/journal.pone.0305442.s001\n\n(ZIP)",
    "category": "statistics"
  }
]